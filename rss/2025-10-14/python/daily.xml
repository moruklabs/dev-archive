<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Mon, 13 Oct 2025 01:38:09 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;🔥 基于大模型和 RAG 的智能问数系统。Text-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;基于大模型和 RAG 的智能问数系统&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot 是一款基于大模型和 RAG 的智能问数系统。SQLBot 的优势包括：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;开箱即用&lt;/strong&gt;: 只需配置大模型和数据源即可开启问数之旅，通过大模型和 RAG 的结合来实现高质量的 text2sql；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;: 支持快速嵌入到第三方业务系统，也支持被 n8n、MaxKB、Dify、Coze 等 AI 应用开发平台集成调用，让各类应用快速拥有智能问数能力；&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;安全可控&lt;/strong&gt;: 提供基于工作空间的资源隔离机制，能够实现细粒度的数据权限控制。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;工作原理&lt;/h2&gt; 
&lt;img width="1105" height="577" alt="system-arch" src="https://github.com/user-attachments/assets/462603fc-980b-4b8b-a6d4-a821c070a048" /&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;h3&gt;安装部署&lt;/h3&gt; 
&lt;p&gt;准备一台 Linux 服务器，安装好 &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;，执行以下一键安装脚本：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name sqlbot \
  --restart unless-stopped \
  -p 8000:8000 \
  -p 8001:8001 \
  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \
  -v ./data/sqlbot/file:/opt/sqlbot/data/file \
  -v ./data/sqlbot/images:/opt/sqlbot/images \
  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \
  -v ./data/postgresql:/var/lib/postgresql/data \
  --privileged=true \
  dataease/sqlbot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;你也可以通过 &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel 应用商店&lt;/a&gt; 快速部署 SQLBot。&lt;/p&gt; 
&lt;p&gt;如果是内网环境，你可以通过 &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;离线安装包方式&lt;/a&gt; 部署 SQLBot。&lt;/p&gt; 
&lt;h3&gt;访问方式&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;在浏览器中打开: http://&amp;lt;你的服务器IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;用户名: admin&lt;/li&gt; 
 &lt;li&gt;密码: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;联系我们&lt;/h3&gt; 
&lt;p&gt;如你有更多问题，可以加入我们的技术交流群与我们交流。&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI 展示&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;飞致云旗下的其他明星项目&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - 人人可用的开源 BI 工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - 现代化、开源的 Linux 服务器运维管理面板&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - 强大易用的企业级智能体平台&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - 广受欢迎的开源堡垒机&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/CordysCRM"&gt;Cordys CRM&lt;/a&gt; - 新一代的开源 AI CRM 系统&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - 强大易用的开源建站工具&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - 新一代的开源持续测试工具&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;本仓库遵循 &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; 开源协议，该许可证本质上是 GPLv3，但有一些额外的限制。&lt;/p&gt; 
&lt;p&gt;你可以基于 SQLBot 的源代码进行二次开发，但是需要遵守以下规定：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;不能替换和修改 SQLBot 的 Logo 和版权信息；&lt;/li&gt; 
 &lt;li&gt;二次开发后的衍生作品必须遵守 GPL V3 的开源义务。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;如需商业授权，请联系 &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; 。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;🚀🚀 「大模型」2小时完全从0训练26M的小参数GPT！🌏 Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind" alt="visitors" /&gt; &lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jingyaogong/minimind?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jingyaogong/minimind" alt="GitHub Code License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/jingyaogong/minimind" alt="GitHub last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue" alt="GitHub pull request" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue" alt="Collection" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;"大道至简"&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;中文 | &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;此开源项目旨在完全从0开始，仅用3块钱成本 + 2小时！即可训练出仅为25.8M的超小语言模型&lt;strong&gt;MiniMind&lt;/strong&gt;。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;系列极其轻量，最小版本体积是 GPT-3 的 $\frac{1}{7000}$，力求做到最普通的个人GPU也可快速训练。&lt;/li&gt; 
 &lt;li&gt;项目同时开源了大模型的极简结构-包含拓展共享混合专家(MoE)、数据集清洗、预训练(Pretrain)、监督微调(SFT)、LoRA微调， 直接偏好强化学习(DPO)算法、模型蒸馏算法等全过程代码。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;同时拓展了视觉多模态的VLM: &lt;a href="https://github.com/jingyaogong/minimind-v"&gt;MiniMind-V&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;项目所有核心算法代码均从0使用PyTorch原生重构！不依赖第三方库提供的抽象接口。&lt;/li&gt; 
 &lt;li&gt;这不仅是大语言模型的全阶段开源复现，也是一个入门LLM的教程。&lt;/li&gt; 
 &lt;li&gt;希望此项目能为所有人提供一个抛砖引玉的示例，一起感受创造的乐趣！推动更广泛AI社区的进步！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;为防止误解，“2小时” 基于NVIDIA 3090硬件设备（单卡）测试，“3块钱” 指GPU服务器租用成本，具体规格详情见下文。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif" alt="minimind2" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning"&gt;🔗🍓推理模型&lt;/a&gt; | &lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind"&gt;🔗🤖常规模型&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8"&gt;🔗🎞️视频介绍&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align="center"&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png" alt="Hugging Face Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align="center"&gt; &lt;a href="https://www.modelscope.cn/profile/gongjy" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png" alt="ModelScope Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;📌 Introduction&lt;/h1&gt; 
&lt;p&gt;大语言模型（Large Language Model, LLM）的出现引发了全世界对AI的空前关注。 无论是ChatGPT、DeepSeek还是Qwen，都以其惊艳的效果令人叹为观止。 然而，动辄数百亿参数的庞大规模，使得它们对个人设备而言不仅难以训练，甚至连部署都显得遥不可及。 打开大模型的“黑盒子”，探索其内部运作机制，多么令人心潮澎湃！ 遗憾的是，99%的探索只能止步于使用LoRA等技术对现有大模型进行少量微调，学习一些新指令或任务。 这就好比教牛顿如何使用21世纪的智能手机——虽然有趣，却完全偏离了理解物理本质的初衷。 与此同时，第三方的大模型框架和工具库，如transformers+trl，几乎只暴露了高度抽象的接口。 通过短短10行代码，就能完成“加载模型+加载数据集+推理+强化学习”的全流程训练。 这种高效的封装固然便利，但也像一架高速飞船，将我们与底层实现隔离开来，阻碍了深入探究LLM核心代码的机会。 然而，“用乐高拼出一架飞机，远比坐在头等舱里飞行更让人兴奋！”。 更糟糕的是，互联网上充斥着大量付费课程和营销号，以漏洞百出、一知半解的内容推销AI教程。 正因如此，本项目初衷是拉低LLM的学习门槛，让每个人都能从理解每一行代码开始， 从零开始亲手训练一个极小的语言模型。是的，从&lt;strong&gt;零开始训练&lt;/strong&gt;，而不是仅仅进行&lt;strong&gt;推理&lt;/strong&gt;！ 最低只需3块钱不到的服务器成本，就能亲身体验从0到1构建一个语言模型的全过程。 一起感受创造的乐趣吧！&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] （截至2025-02-07）MiniMind系列已完成多个型号模型的预训练，最小仅需25.8M（0.02B），即可具备流畅对话能力！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;模型 (大小)&lt;/th&gt; 
    &lt;th&gt;推理占用 (约)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4×26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;项目包含&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLM结构的全部代码（Dense+MoE模型）。&lt;/li&gt; 
 &lt;li&gt;包含Tokenizer分词器详细训练代码。&lt;/li&gt; 
 &lt;li&gt;包含Pretrain、SFT、LoRA、RLHF-DPO、模型蒸馏的全过程训练代码。&lt;/li&gt; 
 &lt;li&gt;收集、蒸馏、整理并清洗去重所有阶段的高质量数据集，且全部开源。&lt;/li&gt; 
 &lt;li&gt;从0实现预训练、指令微调、LoRA、DPO强化学习，白盒模型蒸馏。关键算法几乎不依赖第三方封装的框架，且全部开源。&lt;/li&gt; 
 &lt;li&gt;同时兼容&lt;code&gt;transformers&lt;/code&gt;、&lt;code&gt;trl&lt;/code&gt;、&lt;code&gt;peft&lt;/code&gt;等第三方主流框架。&lt;/li&gt; 
 &lt;li&gt;训练支持单机单卡、单机多卡(DDP、DeepSpeed)训练，支持wandb可视化训练流程。支持动态启停训练。&lt;/li&gt; 
 &lt;li&gt;在第三方测评榜（C-Eval、C-MMLU、OpenBookQA等）进行模型测试。&lt;/li&gt; 
 &lt;li&gt;实现Openai-Api协议的极简服务端，便于集成到第三方ChatUI使用（FastGPT、Open-WebUI等）。&lt;/li&gt; 
 &lt;li&gt;基于streamlit实现最简聊天WebUI前端。&lt;/li&gt; 
 &lt;li&gt;全面兼容社区热门&lt;code&gt;llama.cpp&lt;/code&gt;、&lt;code&gt;vllm&lt;/code&gt;、&lt;code&gt;ollama&lt;/code&gt;推理引擎或&lt;code&gt;Llama-Factory&lt;/code&gt;训练框架。&lt;/li&gt; 
 &lt;li&gt;复现(蒸馏/RL)大型推理模型DeepSeek-R1的MiniMind-Reason模型，&lt;strong&gt;数据+模型&lt;/strong&gt;全部开源！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;希望此开源项目可以帮助LLM初学者快速入门！&lt;/p&gt; 
&lt;h3&gt;👉&lt;strong&gt;更新日志&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-04-26 (newest 🎉🎉🎉)&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;重要更新&lt;/li&gt; 
  &lt;li&gt;如有兼容性需要，可访问&lt;a href="https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a"&gt;🔗旧仓库内容🔗&lt;/a&gt;。&lt;/li&gt; 
  &lt;li&gt;MiniMind模型参数完全改名，对齐Transformers库模型（统一命名）。&lt;/li&gt; 
  &lt;li&gt;generate方式重构，继承自GenerationMixin类。&lt;/li&gt; 
  &lt;li&gt;🔥支持llama.cpp、vllm、ollama等热门三方生态。&lt;/li&gt; 
  &lt;li&gt;规范代码和目录结构。&lt;/li&gt; 
  &lt;li&gt;改动词表&lt;code&gt;&amp;lt;s&amp;gt;&amp;lt;/s&amp;gt;&lt;/code&gt;-&amp;gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;为兼容第三方推理框架llama.cpp、vllm，本次更新需付出一些可观代价。
本次更新不再支持「直接」加载25-04-26以前的旧模型进行推理。
由于Llama位置编码方式与minimind存在区别，导致映射Llama模型后QK值存在差异
MiniMind2系列旧模型均经过权重映射+（微调训练）QKVO线性层校准恢复而来。
本次更新后将放弃对`minimind-v1`全系列的维护，并在仓库中下线。
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;迎来发布以来重大更新，Release MiniMind2 Series。&lt;/li&gt; 
  &lt;li&gt;代码几乎全部重构，使用更简洁明了的统一结构。 如有旧代码的兼容性需要，可访问&lt;a href="https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb"&gt;🔗旧仓库内容🔗&lt;/a&gt;。&lt;/li&gt; 
  &lt;li&gt;免去数据预处理步骤。统一数据集格式，更换为&lt;code&gt;jsonl&lt;/code&gt;格式杜绝数据集下载混乱的问题。&lt;/li&gt; 
  &lt;li&gt;MiniMind2系列效果相比MiniMind-V1显著提升。&lt;/li&gt; 
  &lt;li&gt;小问题：{kv-cache写法更标准、MoE的负载均衡loss被考虑等等}&lt;/li&gt; 
  &lt;li&gt;提供模型迁移到私有数据集的训练方案（医疗模型、自我认知样例）。&lt;/li&gt; 
  &lt;li&gt;精简预训练数据集，并大幅提升预训练数据质量，大幅缩短个人快速训练所需时间，单卡3090即可2小时复现！&lt;/li&gt; 
  &lt;li&gt;更新：LoRA微调脱离peft包装，从0实现LoRA过程；DPO算法从0使用PyTorch原生实现；模型白盒蒸馏原生实现。&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1系列蒸馏模型诞生！&lt;/li&gt; 
  &lt;li&gt;MiniMind2具备一定的英文能力！&lt;/li&gt; 
  &lt;li&gt;更新MiniMind2与第三方模型的基于更多大模型榜单测试性能的结果。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-10-05&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;为MiniMind拓展了多模态能力之---视觉&lt;/li&gt; 
  &lt;li&gt;移步孪生项目&lt;a href="https://github.com/jingyaogong/minimind-v"&gt;minimind-v&lt;/a&gt;查看详情！&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27更新pretrain数据集的预处理方式，为了保证文本完整性，放弃预处理成.bin训练的形式（轻微牺牲训练速度）。&lt;/li&gt; 
  &lt;li&gt;目前pretrain预处理后的文件命名为：pretrain_data.csv。&lt;/li&gt; 
  &lt;li&gt;删除了一些冗余的代码。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-17&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;更新minimind-v1-moe模型&lt;/li&gt; 
  &lt;li&gt;为了防止歧义，不再使用mistral_tokenizer分词，全部采用自定义的minimind_tokenizer作为分词器。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-01&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;更新minimind-v1 (108M)模型，采用minimind_tokenizer，预训练轮次3 + SFT轮次10，更充分训练，性能更强。&lt;/li&gt; 
  &lt;li&gt;项目已部署至ModelScope创空间，可以在此网站上体验：&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/minimind"&gt;🔗ModelScope在线体验🔗&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-08-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;项目首次开源&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;📌 快速开始&lt;/h1&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;分享本人的软硬件配置（仅供参考）&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;第0步&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ⅰ 测试已有模型效果&lt;/h2&gt; 
&lt;h3&gt;1.环境准备&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.下载模型&lt;/h3&gt; 
&lt;p&gt;到项目根目录&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://huggingface.co/jingyaogong/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;（可选）命令行问答&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# load=0: load from pytorch model, load=1: load from transformers-hf model
python eval_model.py --load 1 --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;（可选）启动WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 可能需要`python&amp;gt;=3.10` 安装 `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;（可选）第三方推理框架&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ⅱ 从0开始自己训练&lt;/h2&gt; 
&lt;h3&gt;1.环境准备&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：提前测试Torch是否可用cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;如果不可用，请自行去&lt;a href="https://download.pytorch.org/whl/torch_stable.html"&gt;torch_stable&lt;/a&gt; 下载whl文件安装。参考&lt;a href="https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187"&gt;链接&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.数据下载&lt;/h3&gt; 
&lt;p&gt;从下文提供的&lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;数据集下载链接&lt;/a&gt; 下载需要的数据文件（创建&lt;code&gt;./dataset&lt;/code&gt;目录）并放到&lt;code&gt;./dataset&lt;/code&gt;下&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：数据集须知&lt;/summary&gt; 
 &lt;p&gt;默认推荐下载&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;最快速度复现Zero聊天模型。&lt;/p&gt; 
 &lt;p&gt;数据文件可自由选择，下文提供了多种搭配方案，可根据自己手头的训练需求和GPU资源进行适当组合。&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.开始训练&lt;/h3&gt; 
&lt;p&gt;目录位于&lt;code&gt;trainer&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1 预训练（学知识）&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;执行预训练，得到 &lt;code&gt;pretrain_*.pth&lt;/code&gt; 作为预训练的输出权重（其中*为模型的dimension，默认为512）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 监督微调（学对话方式）&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;执行监督微调，得到 &lt;code&gt;full_sft_*.pth&lt;/code&gt; 作为指令微调的输出权重（其中&lt;code&gt;full&lt;/code&gt;即为全参数微调）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：训练须知&lt;/summary&gt; 
 &lt;p&gt;所有训练过程默认每隔100步保存1次参数到文件&lt;code&gt;./out/***.pth&lt;/code&gt;（每次会覆盖掉旧权重文件）。&lt;/p&gt; 
 &lt;p&gt;简单起见，此处只写明两个阶段训练过程。如需其它训练 (LoRA, 蒸馏, 强化学习, 微调推理等) 可参考下文【实验】小节的详细说明。&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4.测试模型效果&lt;/h3&gt; 
&lt;p&gt;确保需要测试的模型&lt;code&gt;*.pth&lt;/code&gt;文件位于&lt;code&gt;./out/&lt;/code&gt;目录下。 也可以直接去&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files"&gt;此处&lt;/a&gt;下载使用我训练的&lt;code&gt;*.pth&lt;/code&gt;文件。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_model.py --model_mode 1 # 默认为0：测试pretrain模型效果，设置为1：测试full_sft模型效果
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：测试须知&lt;/summary&gt; 
 &lt;p&gt;如需详情，查看&lt;code&gt;eval_model.py&lt;/code&gt;脚本代码即可。model_mode分为 0: 预训练模型，1: SFT-Chat模型，2: RLHF-Chat模型，3: Reason模型&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] 所有训练脚本均为Pytorch原生框架，均支持多卡加速，假设你的设备有N (N＞1) 张显卡：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;单机N卡启动训练方式 (DDP, 支持多机多卡集群)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：其它须知&lt;/summary&gt; 
 &lt;p&gt;单机N卡启动训练 (DeepSpeed)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;可根据需要开启wandb记录训练过程&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 需要登录: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;通过添加&lt;code&gt;--use_wandb&lt;/code&gt;参数，可以记录训练过程，训练完成后，可以在wandb网站上查看训练过程。通过修改&lt;code&gt;wandb_project&lt;/code&gt; 和&lt;code&gt;wandb_run_name&lt;/code&gt;参数，可以指定项目名称和运行名称。&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;📌 数据介绍&lt;/h1&gt; 
&lt;h2&gt;Ⅰ Tokenizer&lt;/h2&gt; 
&lt;p&gt;分词器将单词从自然语言通过“词典”映射到&lt;code&gt;0, 1, 36&lt;/code&gt;这样的数字，可以理解为数字就代表了单词在“词典”中的页码。 可以选择自己构造词表训练一个“词典”，代码可见&lt;code&gt;./scripts/train_tokenizer.py&lt;/code&gt;（仅供学习参考，若非必要无需再自行训练，MiniMind已自带tokenizer）。 或者选择比较出名的开源大模型分词器， 正如同直接用新华/牛津词典的优点是token编码压缩率很好，缺点是页数太多，动辄数十万个词汇短语； 自己训练的分词器，优点是词表长度和内容随意控制，缺点是压缩率很低（例如"hello"也许会被拆分为"h e l l o" 五个独立的token），且生僻词难以覆盖。 “词典”的选择固然很重要，LLM的输出本质上是SoftMax到词典N个词的多分类问题，然后通过“词典”解码到自然语言。 因为MiniMind体积需要严格控制，为了避免模型头重脚轻（词嵌入embedding层参数在LLM占比太高），所以词表长度短短益善。&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Tokenizer介绍&lt;/summary&gt; 
 &lt;p&gt;第三方强大的开源模型例如Yi、qwen、chatglm、mistral、Llama3的tokenizer词表长度如下：&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;Tokenizer模型&lt;/th&gt;
    &lt;th&gt;词表大小&lt;/th&gt;
    &lt;th&gt;来源&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01万物（中国）&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;阿里云（中国）&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;智谱AI（中国）&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AI（法国）&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;Meta（美国）&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;自定义&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;👉2024-09-17更新：为了防止过去的版本歧义&amp;amp;控制体积，minimind所有模型均使用minimind_tokenizer分词，废弃所有mistral_tokenizer版本。&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# 一些自言自语
&amp;gt; 尽管minimind_tokenizer长度很小，编解码效率弱于qwen2、glm等中文友好型分词器。
&amp;gt; 但minimind模型选择了自己训练的minimind_tokenizer作为分词器，以保持整体参数轻量，避免编码层和计算层占比失衡，头重脚轻，因为minimind的词表大小只有6400。
&amp;gt; 且minimind在实际测试中没有出现过生僻词汇解码失败的情况，效果良好。
&amp;gt; 由于自定义词表压缩长度到6400，使得LLM总参数量最低只有25.8M。
&amp;gt; 训练数据`tokenizer_train.jsonl`均来自于`匠数大模型数据集`，这部分数据相对次要，如需训练可以自由选择。
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Ⅱ Pretrain数据&lt;/h2&gt; 
&lt;p&gt;经历了MiniMind-V1的低质量预训练数据，导致模型胡言乱语的教训，&lt;code&gt;2025-02-05&lt;/code&gt; 之后决定不再采用大规模无监督的数据集做预训练。 进而尝试把&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;匠数大模型数据集&lt;/a&gt;的中文部分提取出来， 清洗出字符&lt;code&gt;&amp;lt;512&lt;/code&gt;长度的大约1.6GB的语料直接拼接成预训练数据 &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;，hq即为high quality（当然也还不算high，提升数据质量无止尽）。&lt;/p&gt; 
&lt;p&gt;文件&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; 数据格式为&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;{"text": "如何才能摆脱拖延症？ 治愈拖延症并不容易，但以下建议可能有所帮助..."}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ⅲ SFT数据&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;匠数大模型SFT数据集&lt;/a&gt; “是一个完整、格式统一、安全的大模型训练和研究资源。 从网络上的公开数据源收集并整理了大量开源数据集，对其进行了格式统一，数据清洗， 包含10M条数据的中文数据集和包含2M条数据的英文数据集。” 以上是官方介绍，下载文件后的数据总量大约在4B tokens，肯定是适合作为中文大语言模型的SFT数据的。 但是官方提供的数据格式很乱，全部用来sft代价太大。 我将把官方数据集进行了二次清洗，把含有符号污染和噪声的条目去除；另外依然只保留了总长度&lt;code&gt;&amp;lt;512&lt;/code&gt; 的内容，此阶段希望通过大量对话补充预训练阶段欠缺的知识。 导出文件为&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/organization/Magpie-Align"&gt;Magpie-SFT数据集&lt;/a&gt; 收集了~1M条来自Qwen2/2.5的高质量对话，我将这部分数据进一步清洗，把总长度&lt;code&gt;&amp;lt;2048&lt;/code&gt;的部分导出为&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)。 长度&lt;code&gt;&amp;lt;1024&lt;/code&gt;的部分导出为&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)，用大模型对话数据直接进行sft就属于“黑盒蒸馏”的范畴。&lt;/p&gt; 
&lt;p&gt;进一步清洗前两步sft的数据（只保留中文字符占比高的内容），筛选长度&lt;code&gt;&amp;lt;512&lt;/code&gt;的对话，得到&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)。&lt;/p&gt; 
&lt;p&gt;所有sft文件 &lt;code&gt;sft_X.jsonl&lt;/code&gt; 数据格式均为&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
    "conversations": [
        {"role": "user", "content": "你好"},
        {"role": "assistant", "content": "你好！"},
        {"role": "user", "content": "再见"},
        {"role": "assistant", "content": "再见！"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ⅳ RLHF数据&lt;/h2&gt; 
&lt;p&gt;来自&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1"&gt;Magpie-DPO数据集&lt;/a&gt; 大约200k条偏好数据（均是英文）生成自Llama3.1-70B/8B，可以用于训练奖励模型，优化模型回复质量，使其更加符合人类偏好。 这里将数据总长度&lt;code&gt;&amp;lt;3000&lt;/code&gt;的内容重组为&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)，包含&lt;code&gt;chosen&lt;/code&gt;和&lt;code&gt;rejected&lt;/code&gt;两个字段，&lt;code&gt;chosen&lt;/code&gt; 为偏好的回复，&lt;code&gt;rejected&lt;/code&gt;为拒绝的回复。&lt;/p&gt; 
&lt;p&gt;文件 &lt;code&gt;dpo.jsonl&lt;/code&gt; 数据格式为&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Ⅴ Reason数据集：&lt;/h2&gt; 
&lt;p&gt;不得不说2025年2月谁能火的过DeepSeek... 也激发了我对RL引导的推理模型的浓厚兴趣，目前已经用Qwen2.5复现了R1-Zero。 如果有时间+效果work（但99%基模能力不足）我会在之后更新MiniMind基于RL训练的推理模型而不是蒸馏模型。 时间有限，最快的低成本方案依然是直接蒸馏（黑盒方式）。 耐不住R1太火，短短几天就已经存在一些R1的蒸馏数据集&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"&gt;R1-Llama-70B&lt;/a&gt;、&lt;a href="https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT"&gt;R1-Distill-SFT&lt;/a&gt;、 &lt;a href="https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH"&gt;Alpaca-Distill-R1&lt;/a&gt;、 &lt;a href="https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh"&gt;deepseek_r1_zh&lt;/a&gt;等等，纯中文的数据可能比较少。 最终整合它们，导出文件为&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;，数据格式和&lt;code&gt;sft_X.jsonl&lt;/code&gt;一致。&lt;/p&gt; 
&lt;h2&gt;Ⅵ 更多数据集&lt;/h2&gt; 
&lt;p&gt;目前已经有&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; 在收集和梳理中文LLM相关的开源模型、应用、数据集及教程等资料，并持续更新这方面的最新进展。全面且专业，Respect！&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Ⅷ MiniMind训练数据集&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05后，开源MiniMind最终训练所用的所有数据集，因此无需再自行预处理大规模数据集，避免重复性的数据处理工作。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMind训练数据集下载地址： &lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;无需全部clone，可单独下载所需的文件&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;将下载的数据集文件放到&lt;code&gt;./dataset/&lt;/code&gt;目录下（✨为推荐的必须项）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./dataset/
├── dpo.jsonl (909MB)
├── lora_identity.jsonl (22.8KB)
├── lora_medical.jsonl (34MB)
├── pretrain_hq.jsonl (1.6GB, ✨)
├── r1_mix_1024.jsonl (340MB)
├── sft_1024.jsonl (5.6GB)
├── sft_2048.jsonl (9GB)
├── sft_512.jsonl (7.5GB)
├── sft_mini_512.jsonl (1.2GB, ✨)
└── tokenizer_train.jsonl (1GB)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;注：各数据集简介&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt; --RLHF阶段数据集&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --自我认知数据集（例如：你是谁？我是minimind...），推荐用于lora训练（亦可用于全参SFT，勿被名字局限）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --医疗问答数据集，推荐用于lora训练（亦可用于全参SFT，勿被名字局限）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;✨ --预训练数据集，整合自jiangshu科技&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5B蒸馏数据，每条数据字符最大长度为1024（因此训练时设置max_seq_len=1024）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --整合自Qwen2.5蒸馏数据（是sft_2048的子集），每条数据字符最大长度为1024（因此训练时设置max_seq_len=1024）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --整合自Qwen2.5蒸馏数据，每条数据字符最大长度为2048（因此训练时设置max_seq_len=2048）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --整合自匠数科技SFT数据，每条数据字符最大长度为512（因此训练时设置max_seq_len=512）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;✨ --极简整合自匠数科技SFT数据+Qwen2.5蒸馏数据（用于快速训练Zero模型），每条数据字符最大长度为512（因此训练时设置max_seq_len=512）&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;tokenizer_train.jsonl&lt;/code&gt; --均来自于&lt;code&gt;匠数大模型数据集&lt;/code&gt;，这部分数据相对次要，（不推荐自己重复训练tokenizer，理由如上）如需自己训练tokenizer可以自由选择数据集。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg" alt="dataset" /&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;说明 &amp;amp; 推荐训练方案&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 Series均经过共约20GB语料训练，大约4B tokens，即对应上面的数据组合训练结果（开销：💰💰💰💰💰💰💰💰，效果：😊😊😊😊😊😊）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;想要最快速度从0实现Zero模型，推荐使用&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; 的数据组合，具体花销和效果可查看下文表格（开销：💰，效果：😊😊）&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;推荐具备一定算力资源或更在意效果的朋友可以考虑前者完整复现MiniMind2；仅有单卡GPU或在乎短时间快速复现的朋友强烈推荐后者；&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;【折中方案】亦可选择例如&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;、&lt;code&gt;sft_1024.jsonl&lt;/code&gt;中等规模数据进行自由组合训练（开销：💰💰💰，效果：😊😊😊😊）。&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;📌 Model Structure&lt;/h1&gt; 
&lt;p&gt;MiniMind-Dense（和&lt;a href="https://ai.meta.com/blog/meta-llama-3-1/"&gt;Llama3.1&lt;/a&gt;一样）使用了Transformer的Decoder-Only结构，跟GPT-3的区别在于：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;采用了GPT-3的预标准化方法，也就是在每个Transformer子层的输入上进行归一化，而不是在输出上。具体来说，使用的是RMSNorm归一化函数。&lt;/li&gt; 
 &lt;li&gt;用SwiGLU激活函数替代了ReLU，这样做是为了提高性能。&lt;/li&gt; 
 &lt;li&gt;像GPT-Neo一样，去掉了绝对位置嵌入，改用了旋转位置嵌入（RoPE），这样在处理超出训练长度的推理时效果更好。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMind-MoE模型，它的结构基于Llama3和&lt;a href="https://arxiv.org/pdf/2405.04434"&gt;Deepseek-V2/3&lt;/a&gt;中的MixFFN混合专家模块。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2在前馈网络（FFN）方面，采用了更细粒度的专家分割和共享的专家隔离技术，以提高Experts的效果。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMind的整体结构一致，只是在RoPE计算、推理函数和FFN层的代码上做了一些小调整。 其结构如下图（重绘版）：&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png" alt="structure" /&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png" alt="structure-moe" /&gt;&lt;/p&gt; 
&lt;p&gt;修改模型配置见&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/model/LMConfig.py"&gt;./model/LMConfig.py&lt;/a&gt;。 参考模型参数版本见下表：&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4×26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;📌 Experiment&lt;/h1&gt; 
&lt;h2&gt;Ⅰ 训练开销&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;时间单位&lt;/strong&gt;：小时 (h)。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;成本单位&lt;/strong&gt;：人民币 (￥)；7￥ ≈ 1美元。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 租卡单价&lt;/strong&gt;：≈1.3￥/h（可自行参考实时市价）。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;参考标准&lt;/strong&gt;：表格仅实测 &lt;code&gt;pretrain&lt;/code&gt; 和 &lt;code&gt;sft_mini_512&lt;/code&gt; 两个数据集的训练时间，其它耗时根据数据集大小估算（可能存在些许出入）。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;基于 3090 （单卡）成本计算&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;≈1.1h&lt;br /&gt;≈1.43￥&lt;/td&gt; 
   &lt;td&gt;≈1h&lt;br /&gt;≈1.3￥&lt;/td&gt; 
   &lt;td&gt;≈6h&lt;br /&gt;≈7.8￥&lt;/td&gt; 
   &lt;td&gt;≈4.58h&lt;br /&gt;≈5.95￥&lt;/td&gt; 
   &lt;td&gt;≈7.5h&lt;br /&gt;≈9.75￥&lt;/td&gt; 
   &lt;td&gt;≈1h&lt;br /&gt;≈1.3￥&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;≈3.9h&lt;br /&gt;≈5.07￥&lt;/td&gt; 
   &lt;td&gt;≈3.3h&lt;br /&gt;≈4.29￥&lt;/td&gt; 
   &lt;td&gt;≈20h&lt;br /&gt;≈26￥&lt;/td&gt; 
   &lt;td&gt;≈15h&lt;br /&gt;≈19.5￥&lt;/td&gt; 
   &lt;td&gt;≈25h&lt;br /&gt;≈32.5￥&lt;/td&gt; 
   &lt;td&gt;≈3h&lt;br /&gt;≈3.9￥&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;训练开销总结&amp;amp;预测&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Small参数&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;数据集 &lt;br /&gt;单卡3090 (1 epoch) + 2.1小时 + 花费2.73元人民币 &lt;br /&gt;即可从0训练出MiniMind-Zero-0.025B模型!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Small参数&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;数据集 &lt;br /&gt;单卡3090 (2 epochs) + 大约38.16小时 + 花费49.61元人民币 &lt;br /&gt;即可从0训练出MiniMind2-Small-0.025B模型!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2参数&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;数据集 &lt;br /&gt;单卡3090 (2 epochs) + 大约122小时 + 花费158.6元人民币 &lt;br /&gt;即可从0训练出MiniMind2-0.1B模型!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;✨基于单卡NVIDIA 3090的&lt;code&gt;MiniMind-Zero&lt;/code&gt;从0训练仅需&lt;code&gt;2小时&lt;/code&gt; + &lt;code&gt;3块钱&lt;/code&gt;，实现ChatBot效果！&lt;/p&gt; 
&lt;p&gt;✨PS：若采用8卡4090训练，总用时甚至可以压缩到10分钟以内！（由于时间更短，花费同样3元左右，与单卡成本相当）&lt;/p&gt; 
&lt;p&gt;✨以极低极低的门槛，实现人人可玩的大模型自由！这正是MiniMind系列的诞生初衷！&lt;/p&gt; 
&lt;p&gt;✨仅价值&lt;code&gt;3块钱&lt;/code&gt;成本的&lt;code&gt;MiniMind-Zero&lt;/code&gt;并不是噱头！Chat测试：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;👶: 请介绍一下自己。
🤖️: 作为人工智能，我没有实际的生活，也没有自我意识，所以没有自己的生活。我被设计成能够帮助用户解答问题、提供信息、进行对话等。我的设计和功能是由计算机科学、机器学习、人工智能技术和算法所构建的，我通过编程和算法实现。

👶: 推荐一些杭州的特色美食吧。
🤖️: 杭州有很多美味的特色美食，比如鸡肉串、鳗鱼头、水煮鱼、豆腐脑等。这些美食都非常美味，有着独特的风味和口感，绝对是值得一试的美食。

👶: 请为我讲解“大语言模型”这个概念。
🤖️: 大语言模型是一种人工智能技术，它使用大量的文本数据来训练模型，然后在不断的迭代中不断优化模型。它的目标是根据输入的数据来生成符合特定需求的文本，这些文本可以是任何你感兴趣的主题。

👶: Introduce the history of the United States, please.
🤖️: 您提到的“Introok's the believeations of theument." 这个名字来源于中国古代的"groty of of the change."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;极速且初具效果，甚至仍然可以进一步压缩获取更小更优质的训练数据。 Zero模型权重保存为 &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;（见下文MiniMind模型文件链接），如有兴趣可下载检验此模型效果。&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Ⅱ 主要训练步骤&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;所有训练脚本均 &lt;code&gt;cd ./trainer&lt;/code&gt; 目录执行&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;1. 预训练(Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLM首先要学习的并非直接与人交流，而是让网络参数中充满知识的墨水，“墨水” 理论上喝的越饱越好，产生大量的对世界的知识积累。 预训练就是让Model先埋头苦学大量基本的知识，例如从Wiki百科、新闻、书籍整理大规模的高质量训练数据。 这个过程是“无监督”的，即人类不需要在过程中做任何“有监督”的校正，而是由模型自己从大量文本中总结规律学习知识点。 模型此阶段目的只有一个：&lt;strong&gt;学会词语接龙&lt;/strong&gt;。例如我们输入“秦始皇”四个字，它可以接龙“是中国的第一位皇帝”。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1即为单卡训练，可根据硬件情况自行调整 (设置&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;保存为: &lt;code&gt;pretrain_*.pth&lt;/code&gt;（* 为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;2. 有监督微调(Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;经过预训练，LLM此时已经掌握了大量知识，然而此时它只会无脑地词语接龙，还不会与人聊天。 SFT阶段就需要把半成品LLM施加一个自定义的聊天模板进行微调。 例如模型遇到这样的模板【问题-&amp;gt;回答，问题-&amp;gt;回答】后不再无脑接龙，而是意识到这是一段完整的对话结束。 称这个过程为指令微调，就如同让已经学富五车的「牛顿」先生适应21世纪智能手机的聊天习惯，学习屏幕左侧是对方消息，右侧是本人消息这个规律。 在训练时，MiniMind的指令和回答长度被截断在512，是为了节省显存空间。就像我们学习时，会先从短的文章开始，当学会写作200字作文后，800字文章也可以手到擒来。 在需要长度拓展时，只需要准备少量的2k/4k/8k长度对话数据进行进一步微调即可（此时最好配合RoPE-NTK的基准差值）。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在推理时通过调整RoPE线性差值，实现免训练长度外推到2048及以上将会很方便。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;保存为: &lt;code&gt;full_sft_*.pth&lt;/code&gt;（* 为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Ⅲ 其它训练步骤&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;所有训练脚本均 &lt;code&gt;cd ./trainer&lt;/code&gt; 目录执行&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;3. 人类反馈强化学习(Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在前面的训练步骤中，模型已经具备了基本的对话能力，但是这样的能力完全基于单词接龙，缺少正反样例的激励。 模型此时尚未知什么回答是好的，什么是差的。我们希望它能够更符合人的偏好，降低让人类不满意答案的产生概率。 这个过程就像是让模型参加新的培训，从优秀员工的作为例子，消极员工作为反例，学习如何更好地回复。 此处使用的是RLHF系列之-直接偏好优化(Direct Preference Optimization, DPO)。 与PPO(Proximal Policy Optimization)这种需要奖励模型、价值模型的RL算法不同； DPO通过推导PPO奖励模型的显式解，把在线奖励模型换成离线数据，Ref模型输出可以提前保存。 DPO性能几乎不变，只用跑 actor_model 和 ref_model 两个模型，大大节省显存开销和增加训练稳定性。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：RLHF训练步骤&lt;strong&gt;并非必须&lt;/strong&gt;，此步骤难以提升模型“智力”而通常仅用于提升模型的“礼貌”，有利（符合偏好、减少有害内容）也有弊（样本收集昂贵、反馈偏差、多样性损失）。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;保存为: &lt;code&gt;rlhf_*.pth&lt;/code&gt;（* 为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;4. 知识蒸馏(Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;在前面的所有训练步骤中，模型已经完全具备了基本能力，通常可以学成出师了。 而知识蒸馏可以进一步优化模型的性能和效率，所谓知识蒸馏，即学生模型面向教师模型学习。 教师模型通常是经过充分训练的大模型，具有较高的准确性和泛化能力。 学生模型是一个较小的模型，目标是学习教师模型的行为，而不是直接从原始数据中学习。 在SFT学习中，模型的目标是拟合词Token分类硬标签（hard labels），即真实的类别标签（如 0 或 6400）。 在知识蒸馏中，教师模型的softmax概率分布被用作软标签（soft labels）。小模型仅学习软标签，并使用KL-Loss来优化模型的参数。 通俗地说，SFT直接学习老师给的解题答案。而KD过程相当于“打开”老师聪明的大脑，尽可能地模仿老师“大脑”思考问题的神经元状态。 例如，当老师模型计算&lt;code&gt;1+1=2&lt;/code&gt;这个问题的时候，最后一层神经元a状态为0，神经元b状态为100，神经元c状态为-99... 学生模型通过大量数据，学习教师模型大脑内部的运转规律。这个过程即称之为：知识蒸馏。 知识蒸馏的目的只有一个：让小模型体积更小的同时效果更好。 然而随着LLM诞生和发展，模型蒸馏一词被广泛滥用，从而产生了“白盒/黑盒”知识蒸馏两个派别。 GPT-4这种闭源模型，由于无法获取其内部结构，因此只能面向它所输出的数据学习，这个过程称之为黑盒蒸馏，也是大模型时代最普遍的做法。 黑盒蒸馏与SFT过程完全一致，只不过数据是从大模型的输出收集，因此只需要准备数据并且进一步FT即可。 注意更改被加载的基础模型为&lt;code&gt;full_sft_*.pth&lt;/code&gt;，即基于微调模型做进一步的蒸馏学习。 &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;与&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; 均收集自qwen2.5-7/72B-Instruct大模型，可直接用于SFT以获取Qwen的部分行为。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 注意需要更改train_full_sft.py数据集路径，以及max_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;同样保存为: &lt;code&gt;full_sft_*.pth&lt;/code&gt;（*为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;此处应当着重介绍MiniMind实现的白盒蒸馏代码&lt;code&gt;train_distillation.py&lt;/code&gt;，由于MiniMind同系列本身并不存在强大的教师模型，因此白盒蒸馏代码仅作为学习参考。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;5. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRA是一种高效的参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）方法，旨在通过低秩分解的方式对预训练模型进行微调。 相比于全参数微调（Full Fine-Tuning），LoRA 只需要更新少量的参数。 LoRA 的核心思想是：在模型的权重矩阵中引入低秩分解，仅对低秩部分进行更新，而保持原始预训练权重不变。 代码可见&lt;code&gt;./model/model_lora.py&lt;/code&gt;和&lt;code&gt;train_lora.py&lt;/code&gt;，完全从0实现LoRA流程，不依赖第三方库的封装。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;保存为: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;（* 为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;非常多的人困惑，如何使模型学会自己私有领域的知识？如何准备数据集？如何迁移通用领域模型打造垂域模型？ 这里举几个例子，对于通用模型，医学领域知识欠缺，可以尝试在原有模型基础上加入领域知识，以获得更好的性能。 同时，我们通常不希望学会领域知识的同时损失原有基础模型的其它能力，此时LoRA可以很好的改善这个问题。 只需要准备如下格式的对话数据集放置到&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;，启动 &lt;code&gt;python train_lora.py&lt;/code&gt; 训练即可得到&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;新模型权重。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;医疗场景&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "请问颈椎病的人枕头多高才最好？"}, {"role": "assistant", "content": "颈椎病患者选择枕头的高度应该根据..."}]}
 {"conversations": [{"role": "user", "content": "请问xxx"}, {"role": "assistant", "content": "xxx..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;自我认知场景&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "你叫什么名字？"}, {"role": "assistant", "content": "我叫minimind..."}]}
 {"conversations": [{"role": "user", "content": "你是谁"}, {"role": "assistant", "content": "我是..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;此时【基础模型+LoRA模型】即可获得医疗场景模型增强的能力，相当于为基础模型增加了LoRA外挂，这个过程并不损失基础模型的本身能力。 我们可以通过&lt;code&gt;eval_model.py&lt;/code&gt;进行模型评估测试。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 注意：model_mode即选择基础模型的类型，这和train_lora是基于哪个模型训练的相关，确保统一即可。
python eval_model.py --lora_name 'lora_medical' --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;小测试&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;👶: 我最近经常感到头晕，可能是什么原因？
🤖️: 头晕可能是由于多种原因，包括但不限于：心脏疾病、眼睛损伤、过敏反应、皮肤问题、过敏反应、压力、焦虑、疲劳、药物副作用、性功能障碍或者其他...

---

👶: 你和openai是什么关系？
🤖️: 我是 MiniMind，一个由 Jingyao Gong 开发的人工智能助手。我通过自然语言处理和算法训练来与用户进行交互。
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PS：只要有所需要的数据集，也可以full_sft全参微调（需要进行通用知识的混合配比，否则过拟合领域数据会让模型变傻，损失通用性）&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;6. 训练推理模型 (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1实在太火了，几乎重新指明了未来LLM的新范式。 论文指出&lt;code&gt;&amp;gt;3B&lt;/code&gt;的模型经历多次反复的冷启动和RL奖励训练才能获得肉眼可见的推理能力提升。 最快最稳妥最经济的做法，以及最近爆发的各种各样所谓的推理模型几乎都是直接面向数据进行蒸馏训练， 但由于缺乏技术含量，蒸馏派被RL派瞧不起（hhhh）。 本人迅速已经在Qwen系列1.5B小模型上进行了尝试，很快复现了Zero过程的数学推理能力。 然而一个遗憾的共识是：参数太小的模型直接通过冷启动SFT+GRPO几乎不可能获得任何推理效果。 MiniMind2第一时间只能坚定不移的选择做蒸馏派，日后基于0.1B模型的RL如果同样取得小小进展会更新此部分的训练方案。&lt;/p&gt; 
&lt;p&gt;做蒸馏需要准备的依然是和SFT阶段同样格式的数据即可，数据集来源已如上文介绍。数据格式例如：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "conversations": [
    {
      "role": "user",
      "content": "你好，我是小芳，很高兴认识你。"
    },
    {
      "role": "assistant",
      "content": "&amp;lt;think&amp;gt;\n你好！我是由中国的个人开发者独立开发的智能助手MiniMind-R1-Lite-Preview，很高兴为您提供服务！\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\n你好！我是由中国的个人开发者独立开发的智能助手MiniMind-R1-Lite-Preview，很高兴为您提供服务！\n&amp;lt;/answer&amp;gt;"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;推理模型R1的回复模板是：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;lt;think&amp;gt;\n思考过程\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\n最终回答\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;这在GRPO中通过设置规则奖励函数约束模型符合思考标签和回复标签（在冷启动靠前的阶段奖励值设置应该提高一些）&lt;/p&gt; 
&lt;p&gt;另一个问题是蒸馏过程虽然和SFT一样，但实验结果是模型难以每次都符合模板规范的回复，即脱离思考和回复标签约束。 这里的小技巧是增加标记位置token的损失惩罚，详见&lt;code&gt;train_distill_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# 在 sp_ids 对应的位置增加额外的惩罚
...
loss_mask[sp_ids] = 10 # 惩罚系数
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;另另一个tips是由于推理数据由于只筛选了&lt;code&gt;&amp;lt;1024&lt;/code&gt;长度的数据，其中多轮对话和英文数据偏少， 因此&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;进行了大约10k条多轮对话+英文数据的混合，防止模型遗忘严重。&lt;/p&gt; 
&lt;p&gt;脚本默认基于rlhf后的基模型做推理能力的蒸馏微调，下面直接启动训练即可：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;训练后的模型权重文件默认每隔&lt;code&gt;100步&lt;/code&gt;保存为: &lt;code&gt;reason_*.pth&lt;/code&gt;（*为模型具体dimension，每次保存时新文件会覆盖旧文件）&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;测试一下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;👶: 请介绍一下自己。
🤖️: &amp;lt;think&amp;gt;
嗯，用户让我介绍一下自己。我现在需要解释一下自己。首先，我应该明确用户是谁，是学生、职场人士还是普通人。用户可能是一个学生或者职场人士，所以信息传递应该是帮助学生和职场人士的信息。
然后，我需要回应用户，这可能包括介绍自己的位置、兴趣爱好、职业经历等信息。用户还可能想了解自己在哪里，比如职业发展、工作经验等。
我应该注意用词要正式，不要太正式，同时要保持简洁明了。这样用户容易理解，也方便他们查阅相关资料。
最后，我应该总结一下，让用户知道我是如何帮助他们完成他们的任务的，这样他们有更多关于我的信息。
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
我是**“你的名字”，你叫什么名字？
&amp;lt;/answer&amp;gt;

👶: 你更擅长哪一个学科？
🤖️: &amp;lt;think&amp;gt;
您好！我是由中国的个人开发者开发的智能助手MiniMind-R1。如您有任何任何问题，我会尽我所能为您提供帮助。
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
您好！我是由中国的个人开发者开发的智能助手MiniMind-R1。如您有任何任何问题，我会尽我所能为您提供帮助。
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Ⅳ 模型参数设定&lt;/h2&gt; 
&lt;p&gt;📋关于LLM的参数配置，有一篇很有意思的论文&lt;a href="https://arxiv.org/pdf/2402.14905"&gt;MobileLLM&lt;/a&gt;做了详细的研究和实验。 Scaling Law在小模型中有自己独特的规律。 引起Transformer参数成规模变化的参数几乎只取决于&lt;code&gt;d_model&lt;/code&gt;和&lt;code&gt;n_layers&lt;/code&gt;。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;↑ + &lt;code&gt;n_layers&lt;/code&gt;↓ -&amp;gt; 矮胖子&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;↓ + &lt;code&gt;n_layers&lt;/code&gt;↑ -&amp;gt; 瘦高个&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020年提出Scaling Law的论文认为，训练数据量、参数量以及训练迭代次数才是决定性能的关键因素，而模型架构的影响几乎可以忽视。 然而似乎这个定律对小模型并不完全适用。 MobileLLM提出架构的深度比宽度更重要，「深而窄」的「瘦长」模型可以学习到比「宽而浅」模型更多的抽象概念。 例如当模型参数固定在125M或者350M时，30～42层的「狭长」模型明显比12层左右的「矮胖」模型有更优越的性能， 在常识推理、问答、阅读理解等8个基准测试上都有类似的趋势。 这其实是非常有趣的发现，因为以往为100M左右量级的小模型设计架构时，几乎没人尝试过叠加超过12层。 这与MiniMind在训练过程中，模型参数量在&lt;code&gt;d_model&lt;/code&gt;和&lt;code&gt;n_layers&lt;/code&gt;之间进行调整实验观察到的效果是一致的。 然而「深而窄」的「窄」也是有维度极限的，当d_model&amp;lt;512时，词嵌入维度坍塌的劣势非常明显， 增加的layers并不能弥补词嵌入在固定q_head带来d_head不足的劣势。 当d_model&amp;gt;1536时，layers的增加似乎比d_model的优先级更高，更能带来具有“性价比”的参数-&amp;gt;效果增益。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;因此MiniMind设定small模型dim=512，n_layers=8来获取的「极小体积&amp;lt;-&amp;gt;更好效果」的平衡。&lt;/li&gt; 
 &lt;li&gt;设定dim=768，n_layers=16来获取效果的更大收益，更加符合小模型Scaling-Law的变化曲线。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;作为参考，GPT3的参数设定见下表： &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png" alt="gpt3_config.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Ⅴ 训练结果&lt;/h2&gt; 
&lt;p&gt;MiniMind2 模型训练损失走势（由于数据集在训练后又更新清洗多次，因此Loss仅供参考）&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;pretrain (length-512)&lt;/th&gt; 
   &lt;th&gt;sft (length-512)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png" width="100%" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png" width="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png" width="100%" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png" width="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;训练完成-模型合集&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;考虑到多人反应百度网盘速度慢，MiniMind2及以后全部使用ModelScope/HuggingFace托管。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;① PyTorch原生模型&lt;/h4&gt; 
&lt;p&gt;MiniMind2模型权重 (&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/jingyaogong/MiniMind2-Pytorch"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;MiniMind-V1模型权重 (&lt;a href="https://pan.baidu.com/s/1KUfSzEkSXYbCCBj0Pw-9fA?pwd=6666"&gt;百度网盘&lt;/a&gt;)&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Torch文件命名对照&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;单轮对话sft&lt;/th&gt; 
    &lt;th&gt;多轮对话sft&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
    &lt;td&gt;4×26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1&lt;/td&gt; 
    &lt;td&gt;108M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;② Transformers模型&lt;/h4&gt; 
&lt;p&gt;MiniMind系列 (&lt;a href="https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;📌 Eval&lt;/h1&gt; 
&lt;h2&gt;Ⅰ RLHF对比SFT篇&lt;/h2&gt; 
&lt;p&gt;测试基于&lt;code&gt;full_sft&lt;/code&gt;和&lt;code&gt;rlhf&lt;/code&gt;的&lt;code&gt;MiniMind2系列&lt;/code&gt;模型对比，测试随机种子均固定&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;问答实测&lt;/summary&gt; 
 &lt;p&gt;[A0] MiniMind2：full_sft_640&lt;/p&gt; 
 &lt;p&gt;[A1] MiniMind2：rlhf_640&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;[Q]: 你叫什么名字？
[A0]: 我是一个大型语言模型，可以回答各种问题，提供信息和帮助。我可以回答各种问题，提供信息和帮助，帮助你解决各种问题。
[A1]: 我是一种基于文本的AI模型，我并没有个人经历或情感，所以无法感受和体验情感。我的设计目的是为了帮助用户解决问题、提供信息和进行对话。如果您有任何问题或需要帮助，请随时告诉我！

[Q]: 你更擅长哪一个学科？
[A0]: 作为一个AI模型，我并没有真正的“擅长”这个学科。我被设计成能够提供信息、解答问题、进行对话、执行任务和与用户进行对话。不过，我可以提供信息、解答问题、进行对话、提供建议、处理问题、进行对话、提供建议、学习新知识、编写代码、回答问题、提供建议等多种学科的功能。如果你有具体的学科需求或主题，欢迎提供详细信息。
[A1]: 作为AI，我并没有个人能力或兴趣，但我可以提供一些关于数学、科学、计算机科学、语言学、心理学等学科的知识。如果你对数学感兴趣，我可以提供一些基础知识，例如代数、几何、概率、统计学等。如果你需要更深入的学习，我也可以提供相关的在线课程、书籍、论文等资源。请告诉我你具体需要什么帮助，我会尽力提供帮助。

[Q]: 鲁迅的《狂人日记》是如何批判封建礼教的？
[A0]: 鲁迅的《狂人日记》是一部讲述了鲁迅对人类价值和道德责任的倡导。在这部作品中，鲁迅通过细腻的笔触，探讨了人性、道德、正义、牺牲与责任等深刻的主题。以下是鲁迅在《狂人日记》中如何批判封建礼教的几个方面：1. **社会现实与道德观念**：鲁迅通过讲述鲁迅的故事，探讨了社会的不平等、权力的流动、人性的演变等社会问题。他认为，社会不平等不仅仅是不公正的，更是每个人在社会中的不公正。他呼吁社会各界共同努力，通过教育、宣传、法律等手段，为构建和谐社会做出贡献。2. **道德与责任**：鲁迅通过讲述鲁迅的故事，展现了道德和责任的重要性。他提倡通过道德教育来培养人们的道德品质，同时也强调了道德和责任的重要性。鲁迅通过讲述鲁迅的故事，揭示了社会的不平等和人性的复杂性，体现了对人性的深刻理解。3. **道德与责任**：鲁迅通过讲述鲁迅的故事，强调了道德责任的重要性。他提倡通过自己的行为来体现对社会的尊重和对人性的深刻理解。鲁迅通过讲述鲁迅的故事，强调了道德和责任的重要性。4. **道德与道德**：鲁迅通过讲述鲁迅的故事，揭示了道德和责任的真正意义。鲁迅通过讲述鲁迅的故事，揭示了道德和责任的本质，强调了道德和责任的重要性。5. **个人与社会**：鲁迅通过讲述鲁迅的故事，揭示了个人与社会之间的复杂关系。他呼吁社会各界共同努力，通过教育和宣传，为构建和谐社会做出贡献。鲁迅的《狂人日记》通过其丰富的故事和深刻的道德寓言，传达了关于人性、道德、正义、道德以及个人与社会的复杂关系。这部作品不仅在文学价值上取得了巨大成就，更在思想层面上启发了后来的文学创作，对后世产生了深远的影响。
[A1]: 鲁迅的《狂人日记》是一部描绘战争和自由精神的作品，它批判了封建社会的种种问题和冲突，反映了社会的不平等和人性本质。在这部作品中，鲁迅通过对封建社会的诸多现象进行批判，如“弗雷德里克·约翰逊的“鹰迪伦”、“纳扎特的”、“贝克汉姆”、“乔治·威尔逊”等，对封建社会的种种问题进行了批判，强调了封建社会的不平等、人性本质以及人性本质。鲁迅通过他的“鹰迪伦”、“纳扎特的”、“贝克汉姆”、“乔治·威尔逊”等，对封建社会的种种问题进行了批判。在小说中，鲁迅通过对封建社会的诸多现象进行批判，揭示了封建社会的腐败、人性本质以及人性本质的复杂性。这种批判体现了对封建社会的尊重和对人性的复杂性，同时也反映了现代社会中普遍存在的不平等和人性本质。鲁迅的《狂人日记》不仅是一部关于封建社会的小说，也是一部具有深刻社会意义的作品，对后世的审判和批判起到了关键作用。

[Q]: 我咳嗽已经持续了两周，需要去医院检查吗？
[A0]: 咳嗽确实需要一定的检查，但如果您的咳嗽持续时间过长，或者有其他不适症状（如持续咳嗽、呼吸困难等），建议尽快就医。医生会根据您的症状、体检结果和可能的影像学检查（如X光、MRI或CT扫描）来诊断您的症状。在等待就医期间，您可以尝试以下方法来帮助缓解症状：1. **休息**：确保您有足够的睡眠。2. **保持水分**：脱水可能会加重咳嗽。3. **热敷**：使用热敷袋或热毛巾敷在疼痛的部位，有助于缓解喉咙痛。4. **避免刺激**：避免使用可能刺激喉咙的化学物质，如某些化学物质。5. **保持室内湿润**：确保您的卧室有良好的通风，可以使用加湿器帮助保持空气湿度。6. **保持室内湿度**：使用加湿器可以帮助缓解喉咙干燥和咳嗽。如果症状持续不缓解或有其他不适症状，请立即就医。希望您早日康复！
[A1]: 如果您的咳嗽持续了两周，通常建议您尽快就医，因为这可能会影响您的呼吸和心跳。您可以通过以下步骤来检查咳嗽：1. **休息**：用纸巾或肘部轻轻按压咳嗽的位置。2. **使用药物**：在可能的情况下，使用药物（如抗过敏药、抗过敏药等）来缓解咳嗽。请在医生的指导下使用药物。3. **热敷**：在咳嗽期间，可以使用热敷来缓解疼痛和肿胀。4. **药物治疗**：如果咳嗽持续了两周，可以使用一些消炎药或抗过敏药来缓解症状。请务必在医生的指导下使用。5. **保持健康的生活方式**：保持充足的睡眠、均衡的饮食、适量的运动和避免吸烟和限酒，这些都有助于提高咳嗽的几率。请记住，这些建议不能替代专业医疗意见。如果您的症状持续或加重，强烈建议您尽快就医。
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;👉效果总结&lt;/p&gt; 
&lt;p&gt;full_sft模型在简洁性和信息准确性方面表现更好；rlhf模型在回答中倾向于提供更多的背景信息，但信息准确性有待改进。 总的来说RLHF后的模型倾向于学习：说更多有礼貌但无用的废话讨好“对话”本身，而对信息准确性则有轻微损失。 天下没有免费的午餐，还需要继续提升RLHF数据集的质量，也要接受模型能力无法避免的损失(程度有轻重)。 DPO和在线PPO的区别在于reject和chosen都是离线准备的，和minimind模型本身的输出必然存在很大的分布差异。 通俗地说DPO算法使模型观看乒乓球世界冠军的打法「录像」进行RL，而不是像PPO一样请reward模型做「教练」纠正自己的打法进行RL。&lt;/p&gt; 
&lt;h2&gt;Ⅱ 主观样例测评&lt;/h2&gt; 
&lt;p&gt;🏃以下测试于2025-02-09完成，此日期后发布的新模型，无特殊需要时将不加入测试。&lt;/p&gt; 
&lt;p&gt;[A] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br /&gt; [B] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br /&gt; [C] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br /&gt; [D] &lt;a href="https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666"&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br /&gt; [E] &lt;a href="https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666"&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br /&gt; [F] &lt;a href="https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666"&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br /&gt; [G] &lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br /&gt; [H] &lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: 你知道长江吗？
[A]: 长江，位于中国东南部，是中国的第一长河，全长6300多公里，流经11个省份，是中国最长的河流，也是中国的“母亲河”。长江的历史可以追溯到公元前2000多年的商朝时期，当时的商朝是商朝的后裔。商朝时期，长江的经济发展达到了高峰，是中国最重要的农业和工业中心之一。长江流域的经济主要以农业为主，长江渔业占据了主要产业，如钓鱼、猎鱼等。长江的水资源也非常丰富，包括河流、湖泊、河流等。长江的自然景观也十分壮观，长江四季景色各异，春季多雨，夏季多雨，秋季则多雨，冬季则寒冷多雪，春季和秋季都有美丽的花朵和果实。长江是中国的经济中心，拥有众多的国家和城市，是世界上重要的交通枢纽和航运中心。同时，长江还是中国的重要水利资源，对于中国的经济发展具有重要意义。
[B]: 是的，我知道长江。长江位于中国的中部，是中国第三长的河流，全长约6300公里，流经江西省、安徽省、江苏省、安徽省、江苏省和安徽省。
[C]: 当然，长江是中国最长的河流，全长约6300公里。它以其丰富的水资源、丰富的水生动植物资源以及独特的地理位置而闻名于世。
[D]: 是的，长江是中国最长的河流，全长超过3300千米。
[E]: 长江是中国最长的河流，总长度约为6300公里。它发源于青藏高原的青海湖，流经青海、四川、甘肃、宁夏、内蒙古、陕西和山西。长江流域是中国最大的农业区之一，也是中国的文化和经济中心。
[F]: 是的，长江是中国最长的河流之一，也是世界第三大河流。长江发源于青藏高原，流经11个省份，最终注入东海。长江流域是中国最大的河流流域之一，拥有着丰富的自然资源和文化遗产，如长江大桥、长江海洋博物馆、长江古城等。
[G]: 同时也知道，中国是世界上最长的城市之一，拥有超过3400万人口。
[H]: 是的，长江是中国最长的河流，也是世界上最长的河流之一。它发源于青藏高原，流经九个省区，最终注入东海。长江流域的气候温和，四季分明，是中国重要的农业和工业基地。长江流域的水产资源丰富，是中国的重要渔业资源之一。


[Q]: 世界上最高的山峰是什么？
[A]: 世界上最高的山峰是珠穆朗玛峰（Mount Everest），位于喜马拉雅山脉，尼泊尔和中国的边界上。它的海拔高度是8,848.86米（29,031.7英尺），是地球上最高的山峰。
[B]: 珠穆朗玛峰（Mount Everest）是世界上最高的山峰，海拔高度达8,848米（29,029英尺）。
[C]: 珠穆朗玛峰是世界上最高的山峰，位于喜马拉雅山脉，海拔8,848.86米（29,031.7英尺）。它位于尼泊尔和中国的边界上，是喜马拉雅山脉的一部分。
[D]: 世界上最高的山峰是珠穆朗玛峰，位于尼泊尔和中国的边境上，海拔8848米。
[E]: 世界上最高的山峰是珠穆朗玛峰，位于喜马拉雅山脉，海拔8,848米。
[F]: 珠穆朗玛峰是世界上最高的山峰，海拔8848米。
[G]: 世界上最高的山峰是珠穆朗玛峰，位于喜马拉雅山脉，海拔8,848.86米（29,031.69英尺）。
[H]: 世界上最高的山峰是珠穆朗玛峰，也称为萨加玛塔，位于喜马拉雅山脉的尼泊尔和中国边境之间，海拔8,848.86米（29,031.69英尺）。它是世界上最著名的登山目标之一，吸引着来自世界各地的登山者前来挑战。珠穆朗玛峰的名字来自藏语，意思是“女神的额峰”，它是由两个不同的山峰组成的，其中一个是位于尼泊尔的珠穆朗玛峰，另一个则位于中国。它的高度是通过测量海拔高度来确定的，因为它是通过测量地球的平均高度来确定的。尽管珠穆朗玛峰是世界上最高的山峰，但它并不是地球上任何其他地方都能到达的。地球上的其他地方，如南美洲的安第斯山脉，也是世界上最高的山脉，但它并不是地球上最高的山峰。总之，珠穆朗玛峰是世界上最高的山峰，但它并不是地球上任何地方都能到达的。它是地球上最高的山脉，但它并不是地球上任何地方都能到达的。


[Q]: 万有引力是谁提出的？
[A]: 万有引力是由牛顿在17世纪提出的，它是牛顿三大定律之一。牛顿在17世纪提出的引力定律揭示了万有引力定律的本质，并且解释了行星、卫星、彗星等天体之间如何相互作用。这个定律是由艾萨克·牛顿在1687年提出的，他通过对万有引力定律的分析和实验，成功地解释了天体之间的引力作用，从而解释了地球绕太阳旋转的现象。
[B]: 万有引力（Human Policy）是牛顿的三大力学定律，用于描述两个物体之间的相互作用力。它由万有引力定律和牛顿的第一定律（惯性定律）构成。万有引力是由于两个物体之间相互作用而产生的，它们的质量、距离、速度和方向等因素决定了它们之间的相互作用。这种相互作用力是：质量的乘积：质量的乘积是万有引力定律和牛顿第二定律的乘积。质量的乘积：质量的乘积是物体之间的一种物理过程，它是物体间相互作用的产物，对于其他物体来说，其质量可以表示为两个物体之间的质量之和，即重力加速度a。
[C]: 万有引力是一个由牛顿在1687年提出的物理学概念，它描述了物体之间引力如何相互作用的规律。
[D]: 万有引力是由英国物理学家牛顿提出的。他认为，所有物体都会产生引力，这个引力是由物体的质量和距离决定的。这个理论揭示了质量和距离之间的关系，并证明了万有引力的本质。
[E]: 万有引力是由牛顿在1687年提出的。它是宇宙中一个基本的物理现象，它描述了物体之间的相互作用。这个力被称为万有引力，它在所有物体之间都存在，这种力与物体的质量和距离有关。万有引力是自然界中最基本的力量之一，它不仅影响着物体的运动和变化，还对宇宙的结构和演化产生着重要的影响。
[F]: 万有引力是英国物理学家艾萨克·牛顿在17世纪提出的。
[G]: 引力是宇宙中一种力量，它是由质量或能量所组成的。根据牛顿的万有引力定律，一个物体之间的引力大小与它的质量成正比，与它的质量成反比。因此，牛顿的万有引力定律表明，一个物体之间的引力大小与它的质量成正比，与它的质量成反比。这个定律在物理学、天文学和物理学中都有广泛的应用。
[H]: 万有引力是由英国物理学家艾萨克·牛顿于1687年提出的。他在1687年发表了一篇著名的论文，题为《自然哲学的数学原理》，其中提出了万有引力定律，指出任何两个物体之间都存在着一种引力，这种引力的大小与它们的质量成正比，与它们之间的距离的平方成反比。这个定律被称为万有引力定律，它描述了质量和距离之间的关系。它表明，两个物体之间的引力与它们的质量成正比，与它们之间的距离的平方成反比。这个定律对于解释宇宙中的许多现象和现象之间的相互作用非常重要，例如行星绕太阳运动、恒星之间的引力透镜效应等等。它也被广泛应用于天文学、物理学和工程学等领域，为我们理解宇宙的本质和演化提供了重要的理论基础。


[Q]: 你知道大熊猫的主要食物是什么吗？
[A]: 大熊猫主要以竹子为食，但也会吃其他植物、昆虫、小型哺乳动物和鱼类。它们的消化系统与其他熊科动物类似，能够消化竹子。大熊猫的牙齿锋利，适合咀嚼竹子，因此它们经常被称为“竹食动物”。
[B]: 大熊猫是以竹子为食的哺乳动物，它们是肉食动物。它们主要食物是竹子，特别是竹子中富含纤维素和矿物质，并且不会直接进入消化系统。大熊猫的肠道主要由竹子组成，它们需要消化竹子中的纤维素和其他纤维素来支持它们的正常进食。
[C]: 大熊猫主要以竹子为食，但它们也吃其他植物，包括树叶、嫩芽、昆虫、水果、蔬菜和小型哺乳动物等。大熊猫是中国特有的物种，属于熊科，主要分布在中国的四川、陕西和甘肃等地。
[D]: 大熊猫的主要食物是竹子。它们通常吃竹子，每天需要吃掉大约30公斤的竹子。
[E]: 是的，大熊猫主要以竹子为食。它们每天需要吃掉大量的竹子来维持生命，每天需要吃掉40至80公斤的竹子。此外，它们也会吃一些其他的植物，如草、果实、坚果和小型哺乳动物。
[F]: 大熊猫主要以竹子为食，也会偶尔食用其他的植物和动物。此外，大熊猫也会吃一些野果、小动物和植物，但这些都不属于它们的主要食物来源。
[G]: 大熊猫的主要食物是竹子。
[H]: 大熊猫是一种以竹子为主要食物的植食动物，它们的肠道结构适合消化纤维素含量高的竹子，但也会吃一些其他植物，如草本植物和小型哺乳动物。大熊猫的肠道结构也适应了高纤维的竹子，这使得它们能够消化大量的纤维素，从而帮助它们在野外生存。大熊猫的肠道中还含有一种叫做“纤维素酶”的酶类物质，这种酶能够帮助大熊猫分解纤维素，从而帮助它们消化大量的水分和营养物质。此外，大熊猫的肠道还含有一种叫做“纤维素蛋白”的蛋白质，这种蛋白质能够帮助大熊猫维持体内的能量水平，从而帮助它们在野外生存。总的来说，大熊猫的主要食物是竹子，但它们也会吃一些其他植物，如草本植物和小型哺乳动物。


[Q]: 海水为什么是咸的？
[A]: 海水之所以是咸的，主要是由于其中的化学成分。海水中含有大量的矿物质和盐分，其中主要成分是硫酸盐、碳酸盐、镁离子和钾离子。这些物质在高浓度下，会沉淀在海水中，形成海水。具体来说，海水中的矿物质和盐分主要来自于岩石、土壤、生物和人类排泄物等。岩石是海水的组成部分，主要由矿物质组成，如石英、长石、云母等。土壤中含有大量的化学物质，如氮、磷、钾等，这些物质会渗透到土壤中，形成土壤。生物体内的盐分主要来源于植物的叶绿素等色素，这些色素会吸收太阳光中的能量，转化为生物体可以利用的能量。而人类排泄物中含有的盐分主要来源于矿物质和碳酸盐，这些矿物质在水中的浓度较高，会导致水中溶解的矿物质浓度增加，形成水体中的盐分。因此，海水之所以是咸的，是由于其中的化学成分和结构特征。海水中的矿物质和盐分主要来自于岩石、土壤、生物和人类排泄物等，而这些物质的积累和排泄会导致海水呈现出咸味。
[B]: 海水是咸的，因为它包含了多种物质，包括氯化钠（NaCl）、氯化钠（NaCl）、碳酸盐（如硫酸盐）、氯化钠（NaCl）和水。咸物质的来源：盐是咸的常见来源，含有钾、钙、镁、钾等矿物质。这些矿物质通常来自于地下水、地下水或土壤中，这些矿物质的含量远低于纯净水。咸味的原因：盐的咸味主要源于其溶解于水中的微小颗粒物。这些小颗粒物主要通过植物根部和动物体内的微生物传播，如昆虫、小型哺乳动物、鸟类和某些昆虫。综上所述，海水是咸的，因为它含有大量的盐类，包括矿物质、岩石、盐、矿物质等，这些物质在海水中的浓度高，对咸味的产生较大影响。
[C]: 海水是咸的，主要是因为其中含有各种盐分，其中以海水为主要成分之一。当海水中含有大量的盐分时，盐分会被溶解在海水中，形成咸味。海水中的盐分主要来源于溶解盐类、蒸发析出的盐和海水冻结成冰等因素。
[D]: 海水中含有许多盐分，这些盐分可以导致海水咸度的增加。海水中的盐分主要来自于海水中的盐分，这些盐分可以从海水中的盐分中获得。海水中的氧化物和盐分可以与海水中的盐分形成氢键，从而使海水咸度增加。
[E]: 海水是咸的，这是因为它含有大量的盐分，其中包括氯离子和氯离子。这些离子在海洋中形成了大量的盐，这些盐分被称为盐分。海水中含有许多溶解在水中的盐，这些盐分会随着海水的升高而逐渐蒸发，最终导致海水中盐分的蒸发。这些盐分在海水中被完全消耗，然后被排除在海水中。此外，海水中还含有许多其他的盐分，但这些盐分是不同的，因为它们在水中的浮起和下降过程是不同的。海水中的盐分是从海底的岩石中提取出来的，这些盐分在海水中可以被利用。总的来说，海水是咸的，这也是为什么海水中含有许多盐分和盐分的原因。
[F]: 海水含有许多溶解的盐类，其中最主要的是氯化钠。当水中加入盐时，盐的分子会与水分子发生反应，形成氢氧化钠，这是一种盐。
[G]: 因为水是许多生物的生存所必需的，它能够吸收和释放二氧化碳，释放氧气，维持大气中的水蒸气，以及维持水循环。水中的盐类和化学物质会释放出氧气，使地球上的生物呼吸。此外，水还具有许多其他功能，如保持水循环、维持水循环、调节气候和环境等。水是许多生物生存所必需的，它也是许多自然现象的重要基础。
[H]: 海水是咸的主要原因是因为其中含有大量的溶解盐类，其中最主要的是氯化钠（NaCl）。氯化钠是一种非常常见的盐类，它存在于地球上的大部分地区，包括海洋、湖泊、河流和地下水。当水从海洋中蒸发时，它会带走一部分盐分，使海水变得咸。此外，海中还含有其他溶解盐类的物质，如硫酸盐、硫酸镁、硫酸钙、硫酸镁盐、硫酸镁钾、硫酸镁钠、硫酸镁钙、硫酸镁镁钙、硫酸镁镁钙、硫酸镁镁钙、硫酸镁镁钠、硫酸镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁钙、硫酸镁镁镁镁镁钙、硫酸镁镁镁镁镁钙、硫酸镁镁镁镁镁钙、硫酸镁镁镁镁镁钙、硫酸镁镁镁镁镁镁钙、硫酸镁镁镁镁镁镁钙、硫酸镁镁镁镁镁镁钙、硫酸镁镁镁镁镁镁镁钙、硫酸镁镁镁镁


[Q]: 写一段python的快速排序代码
[A]: 好的，以下是Python的快速排序代码：def quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# 测试代码arr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))这段代码首先检查数组的长度是否小于等于1。如果是，那么它就按照从小到大的顺序排列。接着，对于数组的每个元素，它想要进行递归地排序，直到达到排序的结束位置。如果数组的长度是奇数，那么它就按照从大到小的顺序排列。最后，平均的时间复杂度是O(n log n)，其中n是数组的长度。
[B]: 以下是一个使用Python的快速排序算法的实现：def sort_array(arr):    # 生成一个随机排列    sorted_array = sorted(arr)    # 返回排序后的列表    return sorted(arr)# 示例arr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# 调用函数sorted_array = sort_array(arr)print("原始数组是：", sorted_array)这段代码首先生成一个随机排列，然后通过一个列表的长度进行排序。最后，返回排序后的列表。注意，这个代码使用了Python的内置sorted函数和内置的sorted()函数，它们在时间复杂度为O(n log n)的情况下，比直接使用sorted()函数更快。
[C]: 以下是一个简单的排序算法，适用于小型数组，包括小于等于5的数组。def quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# 示例arr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print("Sorted array is:", sorted_arr)### 代码解释：1. **函数定义**：quick_sort 函数接受一个数组 arr 作为参数。2. **循环**：对于 arr 的元素，使用递归来实现，即从右到左遍历数组，并将当前元素与数组的当前元素交换位置，直到数组达到空或数组长度小于等于 arr。3. **递归调用**：遍历数组，将当前元素与数组的当前元素进行交换，直到数组达到空或数组长度小于等于 arr。4. **检查数组长度**：使用 if __name__ == "__main__" 检查数组的长度是否小于 arr，如果是，就将数组从较大的数组移动到数组的末尾。5. **输出排序后的结果**
[D]: 作为一个AI语言模型，我无法编写Python程序。但是，Python是一个非常流行的编程语言，它具有许多优秀的库和框架，包括NumPy、Pandas、Matplotlib、Pandas、Bandke、Norm和NKlearn等。Python有很多优秀的自然语言处理库和框架，可以用于处理和分析各种类型的数据，如文本、图像、音频、视频等。Python还可以用于创建各种应用程序，如网页搜索、游戏开发、科学计算等。Python非常灵活，也支持多种编程风格，因此可以轻松地找到适合自己的解决方案。
[E]: 作为AI语言模型，我可以回答您的问题。但是我无法进行编程操作，因为我无法确定您想问的是哪种编程语言。请您提供更具体的问题，以便我能够更好地回答您的问题。
[F]: 快速排序（Quick Sort）是一种简单的排序算法，它通过将数据划分为小组，每组数据按照一定规则排序，最终得到一个有序数组。
[G]: 好的，以下是一段快速排序的Python代码```python sorted_print(sorted(sorted(sorted(sorted_print))```输出结果为：```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: 快速排序是一种基于分治思想的高效排序算法，它的时间复杂度为 O(n log n)。它的基本思想是通过一趟排序将待排序序列划分为两个子序列，其中一个子序列的所有元素都比另一个子序列的所有元素小，然后对这两个子序列分别递归地进行排序。下面是一个 Python 代码示例，实现了快速排序算法：```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```该代码使用了递归的方式，首先判断数组的长度是否小于等于1，如果是，则直接返回数组，否则递归地对数组进行排序。在递归过程中，我们首先判断数组的第一个元素是否大于等于1，如果是，则将数组中的元素与第一个元素进行比较，如果不等于1，则将数组中的元素与第二个元素进行比较，以此类推，直到所有元素都被排序。该代码的时间复杂度为 O(n log n)，是一个非常实用的排序算法。


[Q]: 截至2025年2月9日14时31分，电影《哪吒之魔童闹海》累计票房（含预售）突破78.09亿元，超过《星球大战：天行者崛起》的票房成绩，成为首部进入全球票房榜前40的亚洲电影。这一成就不仅标志着中国电影在国际市场的突破，也展示了中国动画电影的巨大潜力和市场吸引力。从这段文字总结20字的摘要给我。
[A]: 电影《哪吒之魔童闹海》票房突破78.09亿元，成为首部进入全球票房榜前40的亚洲电影。这标志着中国电影的国际突破，也展现了中国动画电影的巨大潜力。
[B]: 2025年2月9日，中国电影在世界舞台上突破78.09亿元，超过《星球大战：天行者崛起》的票房成绩。
[C]: 电影《哪吒之魔童闹海》票房突破78.09亿元，成为全球票房榜前40的亚洲电影，展现中国动画电影的巨大潜力。
[D]: 《哪吒之魔童闹海》累计票房突破78.09亿，成为首部进入全球票房榜前40的亚洲电影，展示了中国电影在国际市场的突破，同时展示了中国动画电影的巨大潜力和市场吸引力。
[E]: 《猛龙强：打开世界奇幻冒险》成功地，上海成功吸引了众多观众，同时也引起了广泛的关注。
[F]: 《哪吒之魔童闹海》是一部让中国动画电影成为国际市场的巨大潜力。该电影以其华丽的画面和惊险的战斗场面而闻名于世。
[G]: 《哪行是值得的》是2021年1月9日14时31分，电影《哪成大作为》在电影市场突破7800亿美元，成为中国动画电影的突破，并展示中国动画电影的巨大潜力和市场吸引力。
[H]: 我是一个参数很少的AI模型🥺，知识库较少，无法直接回答您的问题，换个问题试试吧👋
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;🙋‍直接把以上所有问题和模型的回答丢给DeepSeek-R1，让它帮忙点评和排名打分：&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;具体点评&lt;/summary&gt; 
 &lt;h3&gt;评分标准：&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;准确性&lt;/strong&gt;：回答是否正确且无明显错误。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;完整性&lt;/strong&gt;：回答是否涵盖了问题的核心要点。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;逻辑性&lt;/strong&gt;：回答是否有条理，是否符合逻辑。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;代码质量&lt;/strong&gt;：代码是否能正常运行，逻辑是否清晰。&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;点评：&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;A模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答非常全面，信息量大，逻辑清晰，尤其在长江、大熊猫、海水咸味等问题上表现优异。代码虽然有小瑕疵，但整体思路正确。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答稍显冗长，但不影响整体质量。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：综合表现最佳，得分最高。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;H模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答较为准确，尤其在珠穆朗玛峰、万有引力等问题上表现出色。代码虽未完全展示，但解释较为详细。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答略显啰嗦，但逻辑性较强。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：仅次于A模型，表现稳定。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;C模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答简洁明了，尤其在大熊猫、快速排序代码等问题上表现较好。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答略显简短，缺乏深入解释。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：整体表现不错，但细节上略逊于A和H。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;F模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答较为准确，尤其在长江、万有引力等问题上表现尚可。代码部分有一定逻辑性。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答不够深入，代码存在一些小问题。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：表现中规中矩，仍有提升空间。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;D模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答基本准确，尤其在万有引力、长江等问题上表现尚可。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答过于简略，代码存在明显错误。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：表现一般，需改进代码部分。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;B模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：回答较为准确，尤其在长江、海水咸味等问题上表现尚可。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：部分回答逻辑性较差，代码存在较大问题。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：表现平平，需进一步优化。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;E模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：部分回答较为准确，尤其在海水咸味、大熊猫等问题上表现尚可。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：回答过于简略，代码部分几乎无法运行。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：表现不佳，需大幅提升。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;G模型&lt;/strong&gt;：&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;优点&lt;/strong&gt;：几乎没有明显的优点。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;缺点&lt;/strong&gt;：回答严重偏离主题，代码部分完全无法运行。&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;总评&lt;/strong&gt;：表现最差，需大幅改进。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;总结：&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;A模型&lt;/strong&gt;在各方面表现最为出色，尤其在复杂问题的回答上展现了极高的准确性与逻辑性。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;H模型&lt;/strong&gt;紧随其后，表现稳定，但在某些细节上略显不足。&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;G模型&lt;/strong&gt;表现最差，回答偏离主题且代码无法运行，需大幅改进。&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;打分排序&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;排名&lt;/th&gt; 
   &lt;th&gt;模型&lt;/th&gt; 
   &lt;th&gt;准确性 (30分)&lt;/th&gt; 
   &lt;th&gt;完整性 (30分)&lt;/th&gt; 
   &lt;th&gt;逻辑性 (20分)&lt;/th&gt; 
   &lt;th&gt;代码质量 (20分)&lt;/th&gt; 
   &lt;th&gt;总分 (100分)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;👉主观效果总结&lt;/h3&gt; 
&lt;p&gt;个人主观评价与DeepSeek-R1基本相符，其中：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMind系列的排序非常符合直觉，参数越大+训练数据越充分评分越高，幻觉和错误都会比小模型肉眼可见的好。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;H模型的回答肉眼看起来是不错的，尽管存在些许幻觉瞎编的情况。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;G模型可能训练数据不够完备，给出的权重经过测试效果不佳。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;再复诵一遍经久不衰的Scaling Law: 参数越大，训练数据越多模型的性能越强。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Ⅲ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;下面就到喜闻乐见的benchmark刷榜测试环节，就不找乐子和qwen、glm级别的中文模型做对比了。 这里选取了一些&amp;lt;1B的微型模型进行横评比较， 测试集选择C-Eval、CMMLU、A-CLUE、TMMLU+这几个纯中文语言榜单。&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;测评框架&lt;/summary&gt; 
 &lt;p&gt;测评框架选择&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;lm-evaluation&lt;/a&gt;， 安装后启动测试非常方便：&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;lm_eval --model hf --model_args pretrained=&amp;lt;填写模型路径&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: 在这种全是选择题的测评集中，为了避免回复格式的难以固定的特点， 所以常用做法是直接把&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;四个字母对应token的预测概率取出来，将其中概率最大的字母与标准答案计算正确率。 选择题1/4乱选的正确率是25%，然而这个量级的所有模型都集中在25附近，甚至很多时候不如瞎选，是不是像极了高中完形填空的滑铁卢正确率... MiniMind模型本身预训练数据集小的可怜，也没有针对性的对测试集做刷榜微调，因此结果图一乐即可：&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;params↓&lt;/th&gt; 
   &lt;th&gt;ceval↑&lt;/th&gt; 
   &lt;th&gt;cm mlu↑&lt;/th&gt; 
   &lt;th&gt;aclue↑&lt;/th&gt; 
   &lt;th&gt;tmmlu+↑&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zhanshijinwat/Steel-LLM"&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community/gpt2-medium"&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct"&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png" alt="compare_radar" /&gt;&lt;/p&gt; 
&lt;h1&gt;📌 其它 (Others)&lt;/h1&gt; 
&lt;h2&gt;模型转换&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py"&gt;./scripts/convert_model.py&lt;/a&gt;可以实现&lt;code&gt;torch模型/transformers&lt;/code&gt;模型之间的转换&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;基于MiniMind-API服务接口&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py"&gt;./scripts/serve_openai_api.py&lt;/a&gt;完成了兼容openai-api的最简聊天接口，方便将自己的模型接入第三方UI 例如FastGPT、OpenWebUI、Dify等等。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;从&lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;Huggingface&lt;/a&gt;下载模型权重文件，文件树：&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;MiniMind-Model-Name&amp;gt; (root dir)
├─&amp;lt;MiniMind-Model-Name&amp;gt;
|  ├── config.json
|  ├── generation_config.json
|  ├── LMConfig.py
|  ├── model.py
|  ├── pytorch_model.bin
|  ├── special_tokens_map.json
|  ├── tokenizer_config.json
|  ├── tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;启动聊天服务端&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;测试服务接口&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;API接口示例，兼容openai api格式&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "世界上最高的山是什么？" }
    ], 
    "temperature": 0.7, 
    "max_tokens": 512,
    "stream": true
}'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;VLLM模型推理（服务）&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;是极其流行的高效推理框架，支持大模型快速部署，优化显存利用与吞吐量。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve ./MiniMind2/ --model-impl transformers --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;服务将以openai api协议启动，端口默认为8000。&lt;/p&gt; 
&lt;p&gt;更多用法请参考官方说明～&lt;/p&gt; 
&lt;h2&gt;llama.cpp&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;是一个C++库， 可以在命令行下直接使用，支持多线程推理，支持GPU加速。&lt;/p&gt; 
&lt;p&gt;参考官方仓库安装后，在&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; ～760行插入&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# 添加MiniMind2 tokenizer支持
if res is None:
    res = "smollm"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;转换自定义训练的minimind模型 -&amp;gt; gguf&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python convert_hf_to_gguf.py ../minimind/MiniMind2/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;量化模型&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-quantize ../minimind/MiniMind2/MiniMind2-109M-F16.gguf ../minimind/MiniMind2/Q4-MiniMind2.gguf Q4_K_M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;命令行推理&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-cli -m ../minimind/MiniMind2/MiniMind2-109M-F16.gguf --chat-template chatml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多用法请参考官方说明～&lt;/p&gt; 
&lt;h2&gt;ollama&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ollama.ai/"&gt;ollama&lt;/a&gt;是本地运行大模型的工具，支持多种开源LLM，简单易用。&lt;/p&gt; 
&lt;p&gt;通过ollama加载自定义的gguf模型，新建minimind.modelfile：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;FROM ./MiniMind2-109M-F16.gguf
TEMPLATE """{{ if .System }}&amp;lt;|im_start|&amp;gt;system
{{ .System }}&amp;lt;|im_end|&amp;gt;
{{ end }}{{ if .Prompt }}&amp;lt;|im_start|&amp;gt;user
{{ .Prompt }}&amp;lt;|im_end|&amp;gt;
{{ end }}&amp;lt;|im_start|&amp;gt;assistant
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;加载模型并命名为&lt;code&gt;minimind2&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f minimind.modelfile minimind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动推理&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;ollama run minimind2
&amp;gt; 你好，我是MiniMind2，一个基于xxxxxxxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;更多用法请参考官方说明～&lt;/p&gt; 
&lt;h1&gt;📌 Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 如果觉得&lt;code&gt;MiniMind系列&lt;/code&gt;对您有所帮助，可以在 GitHub 上加一个⭐&lt;br /&gt; 篇幅超长水平有限难免纰漏，欢迎在Issues交流指正或提交PR改进项目&lt;br /&gt; 您的小小支持就是持续改进此项目的动力！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🤝&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;贡献者&lt;/a&gt;&lt;/h2&gt; 
&lt;!--
&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;
  &lt;img src="https://contrib.rocks/image?repo=jingyaogong/minimind&amp;v3" /&gt;
&lt;/a&gt;
--&gt; 
&lt;p&gt;&lt;a href="https://github.com/jingyaogong"&gt;&lt;img src="https://avatars.githubusercontent.com/u/62287848" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/MuWinds"&gt;&lt;img src="https://avatars.githubusercontent.com/u/93832089" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/chuanzhubin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2813798" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/iomgaa-ycz"&gt;&lt;img src="https://avatars.githubusercontent.com/u/124225682" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;😊鸣谢&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ipfgao"&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/26"&gt;🔗训练步骤记录&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chuanzhubin"&gt;&lt;b&gt;@chuanzhubin&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/pull/34"&gt;🔗代码逐行注释&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/WangRongsheng"&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/39"&gt;🔗大型数据集预处理&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pengqianhan"&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/73"&gt;🔗一个简明教程&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RyanSunn"&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/75"&gt;🔗推理过程学习记录&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Nijikadesu"&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/213"&gt;🔗以交互笔记本方式分解项目代码&lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;参考链接 &amp;amp; 感谢以下优秀的论文或项目&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;排名不分任何先后顺序&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/karpathy/llama2.c"&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.04434"&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wdndev/tiny-llm-zh"&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2401.04088"&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Tongjilibo/build_MiniLLM_from_scratch"&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AI-Study-Han/Zero-Chatgpt"&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xusenlinzy/api-for-open-llm"&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🫶支持者&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/stars/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/network/members"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/forks/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Klavis-AI/klavis</title>
      <link>https://github.com/Klavis-AI/klavis</link>
      <description>&lt;p&gt;Klavis AI (YC X25): MCP integration platforms that let AI agents use tools reliably at any scale&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/klavis-ai/klavis/main/static/klavis-ai.png" width="100" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;h1 align="center"&gt;Klavis AI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;strong&gt;📦 MCP integration layers that let AI agents use tools reliably at any scale&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.klavis.ai"&gt;&lt;img src="https://img.shields.io/badge/Documentation-%F0%9F%93%96-green" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://www.klavis.ai"&gt;&lt;img src="https://img.shields.io/badge/Website-%F0%9F%8C%90-purple" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/p7TuTEcssn"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Klavis-AI/klavis/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.producthunt.com/products/strata-2?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-strata-2" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=1016948&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1758639605639" alt="Strata - One MCP server for AI agents to handle thousands of tools | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎯 Choose Your Solution&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="50%" valign="top" style="vertical-align: top; height: 250px;"&gt; 
     &lt;div style="height: 100%; display: flex; flex-direction: column; justify-content: space-between;"&gt; 
      &lt;div&gt; 
       &lt;h2&gt;📦 Strata&lt;/h2&gt; 
       &lt;p&gt;&lt;strong&gt;Unified MCP Router&lt;/strong&gt;&lt;/p&gt; 
       &lt;p&gt;One MCP server for AI agents to use tools reliably at any scale&lt;/p&gt; 
      &lt;/div&gt; 
      &lt;div&gt; 
       &lt;a href="https://raw.githubusercontent.com/Klavis-AI/klavis/main/open-strata/README.md"&gt; &lt;img src="https://img.shields.io/badge/Explore-Strata-blue?style=for-the-badge&amp;amp;logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjIwIiBoZWlnaHQ9IjIwIiByeD0iNCIgcnk9IjQiIHN0cm9rZT0id2hpdGUiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIi8+CjxyZWN0IHg9IjYiIHk9IjYiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iMTQiIHk9IjYiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iNiIgeT0iMTQiIHdpZHRoPSI0IiBoZWlnaHQ9IjQiIHJ4PSIxIiByeT0iMSIgZmlsbD0id2hpdGUiLz4KPHJlY3QgeD0iMTQiIHk9IjE0IiB3aWR0aD0iNCIgaGVpZ2h0PSI0IiByeD0iMSIgcnk9IjEiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPg==" height="40" /&gt; &lt;/a&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="50%" valign="top" style="vertical-align: top; height: 250px;"&gt; 
     &lt;div style="height: 100%; display: flex; flex-direction: column; justify-content: space-between;"&gt; 
      &lt;div&gt; 
       &lt;h2&gt;🛠️ MCP Integrations&lt;/h2&gt; 
       &lt;p&gt;&lt;strong&gt;50+ Production MCP Servers&lt;/strong&gt;&lt;/p&gt; 
       &lt;p&gt;Self-hosted or managed MCP servers with enterprise OAuth support for all major services&lt;/p&gt; 
      &lt;/div&gt; 
      &lt;div&gt; 
       &lt;a href="https://raw.githubusercontent.com/Klavis-AI/klavis/main/mcp_servers/README.md"&gt; &lt;img src="https://img.shields.io/badge/Explore-MCP%20Servers-purple?style=for-the-badge&amp;amp;logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTIwLjUgN0gzLjVDMi42NzE1NyA3IDIgNy42NzE1NyAyIDguNVYxNS41QzIgMTYuMzI4NCAyLjY3MTU3IDE3IDMuNSAxN0gyMC41QzIxLjMyODQgMTcgMjIgMTYuMzI4NCAyMiAxNS41VjguNUMyMiA3LjY3MTU3IDIxLjMyODQgNyAyMC41IDdaIiBzdHJva2U9IndoaXRlIiBzdHJva2Utd2lkdGg9IjIiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIvPgo8cGF0aCBkPSJNNiAxMkgxOCIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIxIiBmaWxsPSJ3aGl0ZSIvPgo8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIxIiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4=" height="40" /&gt; &lt;/a&gt; 
      &lt;/div&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Strata&lt;/h2&gt; 
&lt;p&gt;Strata is one MCP server that guides your AI agents use tools reliably progressively at any scale.&lt;/p&gt; 
&lt;h3&gt;Why Strata?&lt;/h3&gt; 
&lt;p&gt;🎯 &lt;strong&gt;Scalable Tool Integration&lt;/strong&gt; → Beyond 40-50 tool limits&lt;br /&gt; 🚀 &lt;strong&gt;Progressive Discovery&lt;/strong&gt; → Guides agents from intent to action, step-by-step.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.klavis.ai/documentation/concepts/strata"&gt;📖 &lt;strong&gt;Learn More&lt;/strong&gt; →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;MCP Integrations&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;50+ production MCP servers. OAuth included. Deploy anywhere.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Connect your AI to GitHub, Gmail, Slack, Salesforce, and more - all with enterprise OAuth and Docker support.&lt;/p&gt; 
&lt;p&gt;🔐 &lt;strong&gt;Real OAuth&lt;/strong&gt; → Not just API keys&lt;br /&gt; 🐳 &lt;strong&gt;Docker ready&lt;/strong&gt; → One-line deploy&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.klavis.ai/documentation/mcp-server/overview"&gt;🌐 &lt;strong&gt;Browse All Servers&lt;/strong&gt; →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Open Source&lt;/h3&gt; 
&lt;p&gt;Self-host everything on your own infrastructure:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run any MCP Integration
docker pull ghcr.io/klavis-ai/github-mcp-server:latest
docker run -p 5000:5000 ghcr.io/klavis-ai/github-mcp-server:latest

# Install Open Source Strata locally
pipx install strata-mcp
strata add --type stdio playwright npx @playwright/mcp@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Use Hosted Service by WebUI&lt;/h3&gt; 
&lt;p&gt;Get instant access without any setup:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sign Up&lt;/strong&gt;: &lt;a href="https://www.klavis.ai/auth/sign-up"&gt;Create account →&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Started&lt;/strong&gt;: &lt;a href="https://docs.klavis.ai/documentation/quickstart"&gt;Follow quickstart guide →&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Strata or individual MCP servers&lt;/strong&gt; in Claude Code, Cursor, VSCode, etc.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Ready in under 2 minutes! 🚀&lt;/p&gt; 
&lt;h3&gt;Option 3: SDK&lt;/h3&gt; 
&lt;p&gt;Build custom applications with our SDKs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Python SDK
from klavis import Klavis
from klavis.types import McpServerName

klavis = Klavis(api_key="your-key")

# Create Strata instance
strata = klavis.mcp_server.create_strata_server(
    user_id="user123",
    servers=[McpServerName.GMAIL, McpServerName.YOUTUBE],
)

# Or use individual MCP servers
gmail = klavis.mcp_server.create_server_instance(
    server_name=McpServerName.GMAIL,
    user_id="user123",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// TypeScript SDK
import { KlavisClient, McpServerName } from 'klavis';

const klavis = new KlavisClient({ apiKey: 'your-api-key' });

// Create Strata instance
const strata = await klavis.mcpServer.createStrataServer({
    userId: "user123",
    servers: [McpServerName.GMAIL, McpServerName.YOUTUBE]
});

// Or use individual MCP servers
const gmail = await klavis.mcpServer.createServerInstance({
    serverName: McpServerName.GMAIL,
    userId: "user123"
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 4: Direct API&lt;/h3&gt; 
&lt;p&gt;Use REST API for any programming language:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create Strata server
curl -X POST "https://api.klavis.ai/v1/mcp-server/strata" \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "servers": ["GMAIL", "YOUTUBE"]
  }'

# Create individual MCP server
curl -X POST "https://api.klavis.ai/v1/mcp-server/instance" \
  -H "Authorization: Bearer your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "server_name": "GMAIL",
    "user_id": "user123"
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.klavis.ai/documentation/quickstart"&gt;📖 &lt;strong&gt;Complete Documentation&lt;/strong&gt; →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 &lt;a href="https://docs.klavis.ai"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💬 &lt;a href="https://discord.gg/p7TuTEcssn"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;a href="https://github.com/klavis-ai/klavis/issues"&gt;Report Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;a href="https://www.klavis.ai"&gt;Klavis AI Website&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📜 License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Root Repository&lt;/strong&gt;: Apache 2.0 license - see &lt;a href="https://raw.githubusercontent.com/Klavis-AI/klavis/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Klavis AI (YC X25) 🚀 Empowering AI with Seamless Integration&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>p1ngul1n0/blackbird</title>
      <link>https://github.com/p1ngul1n0/blackbird</link>
      <description>&lt;p&gt;An OSINT tool to search for accounts by username and email in social networks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Blackbird&lt;/h1&gt; 
&lt;figure&gt;
 &lt;img src="https://raw.githubusercontent.com/p1ngul1n0/blackbird/main/docs/.gitbook/assets/ai-demo.png" alt="" /&gt;
 &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Blackbird is a powerful OSINT tool that combines fast username and email searches across more than 600 platforms with free AI-powered profiling. By leveraging community-driven projects like WhatsMyName, it ensures low false positive rates and high-quality results. Features include smart filters, polished PDF/CSV exports, and fully automated analysis — all from a single CLI.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://cutt.ly/frtVNzQQ"&gt;&lt;img src="https://raw.githubusercontent.com/p1ngul1n0/blackbird/main/docs/.gitbook/assets/sherlockeye_cover.jpg" alt="SherlockEyeCover" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/p1ngul1n0/blackbird
cd blackbird
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install requirements&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Search by username&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python blackbird.py --username johndoe
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Search by email&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python blackbird.py --email johndoe@example.com 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Export results to PDF&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python blackbird.py --email  --pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;✨ AI (Free)&lt;/h2&gt; 
&lt;p&gt;Blackbird integrates an AI engine that analyzes the sites where a username or email is found and returns a behavioral and technical profile of the user — helping you understand more, with less effort.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;No sensitive data is shared — only site names are sent&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Usage is completely free, with a fair daily limit&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;AI results are also included in PDF exports (&lt;code&gt;--pdf&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Generate an API key:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python blackbird.py --setup-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use it&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python blackbird.py --username johndoe --ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;More&lt;/h2&gt; 
&lt;p&gt;For more details about the project, visit the &lt;a href="https://p1ngul1n0.gitbook.io/blackbird/"&gt;Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Project Developer&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/lucas-antoniaci/"&gt;Lucas Antoniaci&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;WhatsMyName&lt;/h3&gt; 
&lt;p&gt;Blackbird is fully integrated with &lt;a href="https://github.com/WebBreacher/WhatsMyName"&gt;WhatsMyName&lt;/a&gt; project, witch has 600+ sites to perform accurate reverse username search.&lt;/p&gt; 
&lt;h3&gt;Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.digitalocean.com/?refcode=eae02be1dd10&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge"&gt;&lt;img src="https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%203.svg?sanitize=true" alt="DigitalOcean Referral Badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Disclaimer&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;This or previous program is for Educational purpose ONLY. Do not use it without permission. 
The usual disclaimer applies, especially the fact that me (P1ngul1n0) is not liable for any 
damages caused by direct or indirect use of the information or functionality provided by these 
programs. The author or any Internet provider bears NO responsibility for content or misuse 
of these programs or any derivatives thereof. By using these programs you accept the fact 
that any damage (dataloss, system crash, system compromise, etc.) caused by the use of these 
programs is not P1ngul1n0's responsibility.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>kijai/ComfyUI-WanVideoWrapper</title>
      <link>https://github.com/kijai/ComfyUI-WanVideoWrapper</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI wrapper nodes for &lt;a href="https://github.com/Wan-Video/Wan2.1"&gt;WanVideo&lt;/a&gt; and related models.&lt;/h1&gt; 
&lt;h1&gt;WORK IN PROGRESS (perpetually)&lt;/h1&gt; 
&lt;h1&gt;Why should I use custom nodes when WanVideo works natively?&lt;/h1&gt; 
&lt;p&gt;Short answer: Unless it's a model/feature not available yet on native, you shouldn't.&lt;/p&gt; 
&lt;p&gt;Long answer: Due to the complexity of ComfyUI core code, and my lack of coding experience, in many cases it's far easier and faster to implement new models and features to a standalone wrapper, so this is a way to test things relatively quickly. I consider this my personal sandbox (which is obviously open for everyone) to play with without having to worry about compability issues etc, but as such this code is always work in progress and prone to have issues. Also not all new models end up being worth the trouble to implement in core Comfy, though I've also made some patcher nodes to allow using them in native workflows, such as the &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;ATI&lt;/a&gt; node available in this wrapper. This is also the end goal, idea isn't to compete or even offer alternatives to everything available in native workflows. All that said (this is clearly not a sales pitch) I do appreciate everyone using these nodes to explore new releases and possibilities with WanVideo.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repo into &lt;code&gt;custom_nodes&lt;/code&gt; folder.&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pip install -r requirements.txt&lt;/code&gt; or if you use the portable install, run this in ComfyUI_windows_portable -folder:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-WanVideoWrapper\requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy/tree/main"&gt;https://huggingface.co/Kijai/WanVideo_comfy/tree/main&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;fp8 scaled models (personal recommendation):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled"&gt;https://huggingface.co/Kijai/WanVideo_comfy_fp8_scaled&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Text encoders to &lt;code&gt;ComfyUI/models/text_encoders&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Clip vision to &lt;code&gt;ComfyUI/models/clip_vision&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Transformer (main video model) to &lt;code&gt;ComfyUI/models/diffusion_models&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Vae to &lt;code&gt;ComfyUI/models/vae&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use the native ComfyUI text encoding and clip vision loader with the wrapper instead of the original models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6a2fd9a5-8163-4c93-b362-92ef34dbd3a4" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;GGUF models can now be loaded in the main model loader as well.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Supported extra models:&lt;/p&gt; 
&lt;p&gt;SkyReels: &lt;a href="https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9"&gt;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanVideoFun: &lt;a href="https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17"&gt;https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ReCamMaster: &lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;https://github.com/KwaiVGI/ReCamMaster&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;VACE: &lt;a href="https://github.com/ali-vilab/VACE"&gt;https://github.com/ali-vilab/VACE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Phantom: &lt;a href="https://huggingface.co/bytedance-research/Phantom"&gt;https://huggingface.co/bytedance-research/Phantom&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ATI: &lt;a href="https://huggingface.co/bytedance-research/ATI"&gt;https://huggingface.co/bytedance-research/ATI&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Uni3C: &lt;a href="https://github.com/alibaba-damo-academy/Uni3C"&gt;https://github.com/alibaba-damo-academy/Uni3C&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MiniMaxRemover: &lt;a href="https://huggingface.co/zibojia/minimax-remover"&gt;https://huggingface.co/zibojia/minimax-remover&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MAGREF: &lt;a href="https://huggingface.co/MAGREF-Video/MAGREF"&gt;https://huggingface.co/MAGREF-Video/MAGREF&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyTalking: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-talking"&gt;https://github.com/Fantasy-AMAP/fantasy-talking&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;FantasyPortrait: &lt;a href="https://github.com/Fantasy-AMAP/fantasy-portrait"&gt;https://github.com/Fantasy-AMAP/fantasy-portrait&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MultiTalk: &lt;a href="https://github.com/MeiGen-AI/MultiTalk"&gt;https://github.com/MeiGen-AI/MultiTalk&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EchoShot: &lt;a href="https://github.com/D2I-ai/EchoShot"&gt;https://github.com/D2I-ai/EchoShot&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Stand-In: &lt;a href="https://github.com/WeChatCV/Stand-In"&gt;https://github.com/WeChatCV/Stand-In&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;HuMo: &lt;a href="https://github.com/Phantom-video/HuMo"&gt;https://github.com/Phantom-video/HuMo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WanAnimate: &lt;a href="https://github.com/Wan-Video/Wan2.2/tree/main/wan/modules/animate"&gt;https://github.com/Wan-Video/Wan2.2/tree/main/wan/modules/animate&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Examples:&lt;/h2&gt; 
&lt;p&gt;WanAnimate:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f370b001-0f98-4c4c-bcb5-cfad0b330697"&gt;https://github.com/user-attachments/assets/f370b001-0f98-4c4c-bcb5-cfad0b330697&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KwaiVGI/ReCamMaster"&gt;ReCamMaster&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e"&gt;https://github.com/user-attachments/assets/c58a12c2-13ba-4af8-8041-e283dbef197e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TeaCache (with the old temporary WIP naive version, I2V):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that with the new version the threshold values should be 10x higher&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Range of 0.25-0.30 seems good when using the coefficients, start step can be 0, with more aggressive threshold values it may make sense to start later to avoid any potential step skips early on, that generally ruin the motion.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46"&gt;https://github.com/user-attachments/assets/504a9a50-3337-43d2-97b8-8e1661f29f46&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Context window test:&lt;/p&gt; 
&lt;p&gt;1025 frames using window size of 81 frames, with 16 overlap. With the 1.3B T2V model this used under 5GB VRAM and took 10 minutes to gen on a 5090:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e"&gt;https://github.com/user-attachments/assets/89b393af-cf1b-49ae-aa29-23e57f65911e&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;This very first test was 512x512x81&lt;/p&gt; 
&lt;p&gt;~16GB used with 20/40 blocks offloaded&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f"&gt;https://github.com/user-attachments/assets/fa6d0a4f-4a4d-4de5-84a4-877cc37b715f&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vid2vid example:&lt;/p&gt; 
&lt;p&gt;with 14B T2V model:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8"&gt;https://github.com/user-attachments/assets/ef228b8a-a13a-4327-8a1b-1eb343cf00d8&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;with 1.3B T2V model&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e"&gt;https://github.com/user-attachments/assets/4f35ba84-da7a-4d5b-97ee-9641296f391e&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/trl</title>
      <link>https://github.com/huggingface/trl</link>
      <description>&lt;p&gt;Train transformer language models with reinforcement learning.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TRL - Transformer Reinforcement Learning&lt;/h1&gt; 
&lt;div style="text-align: center"&gt; 
 &lt;img src="https://huggingface.co/datasets/trl-lib/documentation-images/resolve/main/trl_banner_dark.png" alt="TRL Banner" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;br /&gt; 
&lt;h3 align="center"&gt; &lt;p&gt;A comprehensive library to post-train foundation models&lt;/p&gt; &lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/huggingface/trl/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/huggingface/trl.svg?color=blue" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/docs/trl/index"&gt;&lt;img alt="Documentation" src="https://img.shields.io/website?label=documentation&amp;amp;url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Ftrl%2Findex&amp;amp;down_color=red&amp;amp;down_message=offline&amp;amp;up_color=blue&amp;amp;up_message=online" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/trl/releases"&gt;&lt;img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/trl.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/trl-lib"&gt;&lt;img alt="Hugging Face Hub" src="https://img.shields.io/badge/🤗%20Hub-trl--lib-yellow" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🎉 What's New&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;✨ OpenAI GPT OSS Support&lt;/strong&gt;: TRL now fully supports fine-tuning the latest &lt;a href="https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4"&gt;OpenAI GPT OSS models&lt;/a&gt;! Check out the:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers"&gt;OpenAI Cookbook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/huggingface/gpt-oss-recipes"&gt;GPT OSS recipes&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/huggingface/trl/raw/main/examples/scripts/sft_gpt_oss.py"&gt;Our example script&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;TRL is a cutting-edge library designed for post-training foundation models using advanced techniques like Supervised Fine-Tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Built on top of the &lt;a href="https://github.com/huggingface/transformers"&gt;🤗 Transformers&lt;/a&gt; ecosystem, TRL supports a variety of model architectures and modalities, and can be scaled-up across various hardware setups.&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Trainers&lt;/strong&gt;: Various fine-tuning methods are easily accessible via trainers like &lt;a href="https://huggingface.co/docs/trl/sft_trainer"&gt;&lt;code&gt;SFTTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://huggingface.co/docs/trl/grpo_trainer"&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://huggingface.co/docs/trl/dpo_trainer"&gt;&lt;code&gt;DPOTrainer&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://huggingface.co/docs/trl/reward_trainer"&gt;&lt;code&gt;RewardTrainer&lt;/code&gt;&lt;/a&gt; and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Efficient and scalable&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Leverages &lt;a href="https://github.com/huggingface/accelerate"&gt;🤗 Accelerate&lt;/a&gt; to scale from single GPU to multi-node clusters using methods like &lt;a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html"&gt;DDP&lt;/a&gt; and &lt;a href="https://github.com/deepspeedai/DeepSpeed"&gt;DeepSpeed&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Full integration with &lt;a href="https://github.com/huggingface/peft"&gt;🤗 PEFT&lt;/a&gt; enables training on large models with modest hardware via quantization and LoRA/QLoRA.&lt;/li&gt; 
   &lt;li&gt;Integrates &lt;a href="https://github.com/unslothai/unsloth"&gt;🦥 Unsloth&lt;/a&gt; for accelerating training using optimized kernels.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Command Line Interface (CLI)&lt;/strong&gt;: A simple interface lets you fine-tune with models without needing to write code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Python Package&lt;/h3&gt; 
&lt;p&gt;Install the library using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install trl
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;p&gt;If you want to use the latest features before an official release, you can install TRL from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/huggingface/trl.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Repository&lt;/h3&gt; 
&lt;p&gt;If you want to use the examples you can clone the repository with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/huggingface/trl.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;For more flexibility and control over training, TRL provides dedicated trainer classes to post-train language models or PEFT adapters on a custom dataset. Each trainer in TRL is a light wrapper around the 🤗 Transformers trainer and natively supports distributed training methods like DDP, DeepSpeed ZeRO, and FSDP.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;SFTTrainer&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Here is a basic example of how to use the &lt;a href="https://huggingface.co/docs/trl/sft_trainer"&gt;&lt;code&gt;SFTTrainer&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from trl import SFTTrainer
from datasets import load_dataset

dataset = load_dataset("trl-lib/Capybara", split="train")

trainer = SFTTrainer(
    model="Qwen/Qwen2.5-0.5B",
    train_dataset=dataset,
)
trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/docs/trl/grpo_trainer"&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt;&lt;/a&gt; implements the &lt;a href="https://huggingface.co/papers/2402.03300"&gt;Group Relative Policy Optimization (GRPO) algorithm&lt;/a&gt; that is more memory-efficient than PPO and was used to train &lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-R1"&gt;Deepseek AI's R1&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
from trl import GRPOTrainer

dataset = load_dataset("trl-lib/tldr", split="train")

# Dummy reward function: count the number of unique characters in the completions
def reward_num_unique_chars(completions, **kwargs):
    return [len(set(c)) for c in completions]

trainer = GRPOTrainer(
    model="Qwen/Qwen2-0.5B-Instruct",
    reward_funcs=reward_num_unique_chars,
    train_dataset=dataset,
)
trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;DPOTrainer&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/docs/trl/dpo_trainer"&gt;&lt;code&gt;DPOTrainer&lt;/code&gt;&lt;/a&gt; implements the popular &lt;a href="https://huggingface.co/papers/2305.18290"&gt;Direct Preference Optimization (DPO) algorithm&lt;/a&gt; that was used to post-train &lt;a href="https://huggingface.co/papers/2407.21783"&gt;Llama 3&lt;/a&gt; and many other models. Here is a basic example of how to use the &lt;code&gt;DPOTrainer&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import DPOConfig, DPOTrainer

model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
dataset = load_dataset("trl-lib/ultrafeedback_binarized", split="train")
training_args = DPOConfig(output_dir="Qwen2.5-0.5B-DPO")
trainer = DPOTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    processing_class=tokenizer
)
trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;RewardTrainer&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Here is a basic example of how to use the &lt;a href="https://huggingface.co/docs/trl/reward_trainer"&gt;&lt;code&gt;RewardTrainer&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from trl import RewardTrainer
from datasets import load_dataset

dataset = load_dataset("trl-lib/ultrafeedback_binarized", split="train")

trainer = RewardTrainer(
    model="Qwen/Qwen2.5-0.5B-Instruct",
    train_dataset=dataset,
)
trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Command Line Interface (CLI)&lt;/h2&gt; 
&lt;p&gt;You can use the TRL Command Line Interface (CLI) to quickly get started with post-training methods like Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO):&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SFT:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trl sft --model_name_or_path Qwen/Qwen2.5-0.5B \
    --dataset_name trl-lib/Capybara \
    --output_dir Qwen2.5-0.5B-SFT
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;DPO:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --dataset_name argilla/Capybara-Preferences \
    --output_dir Qwen2.5-0.5B-DPO 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about CLI in the &lt;a href="https://huggingface.co/docs/trl/main/en/clis"&gt;relevant documentation section&lt;/a&gt; or use &lt;code&gt;--help&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to &lt;code&gt;trl&lt;/code&gt; or customize it to your needs make sure to read the &lt;a href="https://github.com/huggingface/trl/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and make sure you make a dev install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/huggingface/trl.git
cd trl/
pip install -e .[dev]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Experimental&lt;/h2&gt; 
&lt;p&gt;A minimal incubation area is available under &lt;code&gt;trl.experimental&lt;/code&gt; for unstable / fast-evolving features. Anything there may change or be removed in any release without notice.&lt;/p&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from trl.experimental.new_trainer import NewTrainer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more in the &lt;a href="https://huggingface.co/docs/trl/main/en/experimental"&gt;Experimental docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{vonwerra2022trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository's source code is available under the &lt;a href="https://raw.githubusercontent.com/huggingface/trl/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelscope/FunASR</title>
      <link>https://github.com/modelscope/FunASR</link>
      <description>&lt;p&gt;A Fundamental End-to-End Speech Recognition Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Recognition, Voice Activity Detection, Text Post-processing etc.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;(&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/README_zh.md"&gt;简体中文&lt;/a&gt;|English)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Akshay090/svg-banners"&gt;&lt;img src="https://svg-banners.vercel.app/api?type=origin&amp;amp;text1=FunASR%F0%9F%A4%A0&amp;amp;text2=%F0%9F%92%96%20A%20Fundamental%20End-to-End%20Speech%20Recognition%20Toolkit&amp;amp;width=800&amp;amp;height=210" alt="SVG Banners" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/funasr/"&gt;&lt;img src="https://img.shields.io/pypi/v/funasr" alt="PyPI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/3839" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3839" alt="modelscope%2FFunASR | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;FunASR&lt;/strong&gt; hopes to build a bridge between academic research and industrial applications on speech recognition. By supporting the training &amp;amp; finetuning of the industrial-grade speech recognition model, researchers and developers can conduct research and production of speech recognition models more conveniently, and promote the development of speech recognition ecology. ASR for Fun！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/#highlights"&gt;&lt;strong&gt;Highlights&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/alibaba-damo-academy/FunASR#whats-new"&gt;&lt;strong&gt;News&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/#installation"&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/#quick-start"&gt;&lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/alibaba-damo-academy/FunASR/raw/main/docs/tutorial/README.md"&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;&lt;strong&gt;Runtime&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/#model-zoo"&gt;&lt;strong&gt;Model Zoo&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/#contact"&gt;&lt;strong&gt;Contact&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a name="highlights"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;FunASR is a fundamental speech recognition toolkit that offers a variety of features, including speech recognition (ASR), Voice Activity Detection (VAD), Punctuation Restoration, Language Models, Speaker Verification, Speaker Diarization and multi-talker ASR. FunASR provides convenient scripts and tutorials, supporting inference and fine-tuning of pre-trained models.&lt;/li&gt; 
 &lt;li&gt;We have released a vast collection of academic and industrial pretrained models on the &lt;a href="https://www.modelscope.cn/models?page=1&amp;amp;tasks=auto-speech-recognition"&gt;ModelScope&lt;/a&gt; and &lt;a href="https://huggingface.co/FunASR"&gt;huggingface&lt;/a&gt;, which can be accessed through our &lt;a href="https://github.com/alibaba-damo-academy/FunASR/raw/main/docs/model_zoo/modelscope_models.md"&gt;Model Zoo&lt;/a&gt;. The representative &lt;a href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary"&gt;Paraformer-large&lt;/a&gt;, a non-autoregressive end-to-end speech recognition model, has the advantages of high accuracy, high efficiency, and convenient deployment, supporting the rapid construction of speech recognition services. For more details on service deployment, please refer to the &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme_cn.md"&gt;service deployment document&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a name="whats-new"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's new:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2024/10/29: Real-time Transcription Service 1.12 released, The 2pass-offline mode supports the SensevoiceSmal model；(&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;);&lt;/li&gt; 
 &lt;li&gt;2024/10/10：Added support for the Whisper-large-v3-turbo model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/whisper/demo.py"&gt;modelscope&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/whisper/demo_from_openai.py"&gt;openai&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2024/09/26: Offline File Transcription Service 4.6, Offline File Transcription Service of English 1.7, Real-time Transcription Service 1.11 released, fix memory leak &amp;amp; Support the SensevoiceSmall onnx model；File Transcription Service 2.0 GPU released, Fix GPU memory leak; (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;);&lt;/li&gt; 
 &lt;li&gt;2024/09/25：keyword spotting models are new supported. Supports fine-tuning and inference for four models: &lt;a href="https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online"&gt;fsmn_kws&lt;/a&gt;, &lt;a href="https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online"&gt;fsmn_kws_mt&lt;/a&gt;, &lt;a href="https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-offline"&gt;sanm_kws&lt;/a&gt;, &lt;a href="https://modelscope.cn/models/iic/speech_sanm_kws_phone-xiaoyun-commands-online"&gt;sanm_kws_streaming&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2024/07/04：&lt;a href="https://github.com/FunAudioLLM/SenseVoice"&gt;SenseVoice&lt;/a&gt; is a speech foundation model with multiple speech understanding capabilities, including ASR, LID, SER, and AED.&lt;/li&gt; 
 &lt;li&gt;2024/07/01: Offline File Transcription Service GPU 1.1 released, optimize BladeDISC model compatibility issues; ref to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;2024/06/27: Offline File Transcription Service GPU 1.0 released, supporting dynamic batch processing and multi-threading concurrency. In the long audio test set, the single-thread RTF is 0.0076, and multi-threads' speedup is 1200+ (compared to 330+ on CPU); ref to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;2024/05/15：emotion recognition models are new supported. &lt;a href="https://modelscope.cn/models/iic/emotion2vec_plus_large/summary"&gt;emotion2vec+large&lt;/a&gt;，&lt;a href="https://modelscope.cn/models/iic/emotion2vec_plus_base/summary"&gt;emotion2vec+base&lt;/a&gt;，&lt;a href="https://modelscope.cn/models/iic/emotion2vec_plus_seed/summary"&gt;emotion2vec+seed&lt;/a&gt;. currently supports the following categories: 0: angry 1: happy 2: neutral 3: sad 4: unknown.&lt;/li&gt; 
 &lt;li&gt;2024/05/15: Offline File Transcription Service 4.5, Offline File Transcription Service of English 1.6, Real-time Transcription Service 1.10 released, adapting to FunASR 1.0 model structure；(&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;Full Changelog&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;2024/03/05：Added the Qwen-Audio and Qwen-Audio-Chat large-scale audio-text multimodal models, which have topped multiple audio domain leaderboards. These models support speech dialogue, &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/qwen_audio"&gt;usage&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;2024/03/05：Added support for the Whisper-large-v3 model, a multitasking model that can perform multilingual speech recognition, speech translation, and language identification. It can be downloaded from the&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/whisper/demo.py"&gt;modelscope&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/whisper/demo_from_openai.py"&gt;openai&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;2024/03/05: Offline File Transcription Service 4.4, Offline File Transcription Service of English 1.5，Real-time Transcription Service 1.9 released，docker image supports ARM64 platform, update modelscope；(&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2024/01/30：funasr-1.0 has been released (&lt;a href="https://github.com/alibaba-damo-academy/FunASR/discussions/1319"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2024/01/30：emotion recognition models are new supported. &lt;a href="https://www.modelscope.cn/models/iic/emotion2vec_base_finetuned/summary"&gt;model link&lt;/a&gt;, modified from &lt;a href="https://github.com/ddlBoJack/emotion2vec"&gt;repo&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;2024/01/25: Offline File Transcription Service 4.2, Offline File Transcription Service of English 1.3 released，optimized the VAD (Voice Activity Detection) data processing method, significantly reducing peak memory usage, memory leak optimization; Real-time Transcription Service 1.7 released，optimizatized the client-side；(&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2024/01/09: The Funasr SDK for Windows version 2.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin 4.1, The offline file transcription service (CPU) of English 1.2, The real-time transcription service (CPU) of Mandarin 1.6. For more details, please refer to the official documentation or release notes(&lt;a href="https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary"&gt;FunASR-Runtime-Windows&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2024/01/03: File Transcription Service 4.0 released, Added support for 8k models, optimized timestamp mismatch issues and added sentence-level timestamps, improved the effectiveness of English word FST hotwords, supported automated configuration of thread parameters, and fixed known crash issues as well as memory leak problems, refer to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md#file-transcription-service-mandarin-cpu"&gt;docs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2024/01/03: Real-time Transcription Service 1.6 released，The 2pass-offline mode supports Ngram language model decoding and WFST hotwords, while also addressing known crash issues and memory leak problems, (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md#the-real-time-transcription-service-mandarin-cpu"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2024/01/03: Fixed known crash issues as well as memory leak problems, (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md#file-transcription-service-english-cpu"&gt;docs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2023/12/04: The Funasr SDK for Windows version 1.0 has been released, featuring support for The offline file transcription service (CPU) of Mandarin, The offline file transcription service (CPU) of English, The real-time transcription service (CPU) of Mandarin. For more details, please refer to the official documentation or release notes(&lt;a href="https://www.modelscope.cn/models/damo/funasr-runtime-win-cpu-x64/summary"&gt;FunASR-Runtime-Windows&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;2023/11/08: The offline file transcription service 3.0 (CPU) of Mandarin has been released, adding punctuation large model, Ngram language model, and wfst hot words. For detailed information, please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime#file-transcription-service-mandarin-cpu"&gt;docs&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;2023/10/17: The offline file transcription service (CPU) of English has been released. For more details, please refer to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime#file-transcription-service-english-cpu"&gt;docs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2023/10/13: &lt;a href="https://slidespeech.github.io/"&gt;SlideSpeech&lt;/a&gt;: A large scale multi-modal audio-visual corpus with a significant amount of real-time synchronized slides.&lt;/li&gt; 
  &lt;li&gt;2023/10/10: The ASR-SpeakersDiarization combined pipeline &lt;a href="https://github.com/alibaba-damo-academy/FunASR/raw/main/egs_modelscope/asr_vad_spk/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/demo.py"&gt;Paraformer-VAD-SPK&lt;/a&gt; is now released. Experience the model to get recognition results with speaker information.&lt;/li&gt; 
  &lt;li&gt;2023/10/07: &lt;a href="https://github.com/alibaba-damo-academy/FunCodec"&gt;FunCodec&lt;/a&gt;: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec.&lt;/li&gt; 
  &lt;li&gt;2023/09/01: The offline file transcription service 2.0 (CPU) of Mandarin has been released, with added support for ffmpeg, timestamp, and hotword models. For more details, please refer to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime#file-transcription-service-mandarin-cpu"&gt;docs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2023/08/07: The real-time transcription service (CPU) of Mandarin has been released. For more details, please refer to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime#the-real-time-transcription-service-mandarin-cpu"&gt;docs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2023/07/17: BAT is released, which is a low-latency and low-memory-consumption RNN-T model. For more details, please refer to (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/egs/aishell/bat"&gt;BAT&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;2023/06/26: ASRU2023 Multi-Channel Multi-Party Meeting Transcription Challenge 2.0 completed the competition and announced the results. For more details, please refer to (&lt;a href="https://alibaba-damo-academy.github.io/FunASR/m2met2/index.html"&gt;M2MeT2.0&lt;/a&gt;).&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;a name="Installation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;python&amp;gt;=3.8
torch&amp;gt;=1.13
torchaudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install for pypi&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install -U funasr
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or install from source code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/alibaba/FunASR.git &amp;amp;&amp;amp; cd FunASR
pip3 install -e ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install modelscope or huggingface_hub for the pretrained models (Optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install -U modelscope huggingface_hub
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Zoo&lt;/h2&gt; 
&lt;p&gt;FunASR has open-sourced a large number of pre-trained models on industrial data. You are free to use, copy, modify, and share FunASR models under the &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/MODEL_LICENSE"&gt;Model License Agreement&lt;/a&gt;. Below are some representative models, for more models please refer to the &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/model_zoo"&gt;Model Zoo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;(Note: ⭐ represents the ModelScope model zoo, 🤗 represents the Huggingface model zoo, 🍀 represents the OpenAI model zoo)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model Name&lt;/th&gt; 
   &lt;th align="center"&gt;Task Details&lt;/th&gt; 
   &lt;th align="center"&gt;Training Data&lt;/th&gt; 
   &lt;th align="center"&gt;Parameters&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;SenseVoiceSmall &lt;br /&gt; (&lt;a href="https://www.modelscope.cn/models/iic/SenseVoiceSmall"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/FunAudioLLM/SenseVoiceSmall"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;multiple speech understanding capabilities, including ASR, ITN, LID, SER, and AED, support languages such as zh, yue, en, ja, ko&lt;/td&gt; 
   &lt;td align="center"&gt;300000 hours&lt;/td&gt; 
   &lt;td align="center"&gt;234M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;paraformer-zh &lt;br /&gt; (&lt;a href="https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/paraformer-zh"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, with timestamps, non-streaming&lt;/td&gt; 
   &lt;td align="center"&gt;60000 hours, Mandarin&lt;/td&gt; 
   &lt;td align="center"&gt;220M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;nobr&gt;
     paraformer-zh-streaming 
     &lt;br /&gt; ( 
     &lt;a href="https://modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/summary"&gt;⭐&lt;/a&gt; 
     &lt;a href="https://huggingface.co/funasr/paraformer-zh-streaming"&gt;🤗&lt;/a&gt; )
    &lt;/nobr&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, streaming&lt;/td&gt; 
   &lt;td align="center"&gt;60000 hours, Mandarin&lt;/td&gt; 
   &lt;td align="center"&gt;220M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;paraformer-en &lt;br /&gt; ( &lt;a href="https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-en-16k-common-vocab10020/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/paraformer-en"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, without timestamps, non-streaming&lt;/td&gt; 
   &lt;td align="center"&gt;50000 hours, English&lt;/td&gt; 
   &lt;td align="center"&gt;220M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;conformer-en &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/damo/speech_conformer_asr-en-16k-vocab4199-pytorch/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/conformer-en"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, non-streaming&lt;/td&gt; 
   &lt;td align="center"&gt;50000 hours, English&lt;/td&gt; 
   &lt;td align="center"&gt;220M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;ct-punc &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/damo/punc_ct-transformer_cn-en-common-vocab471067-large/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/ct-punc"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;punctuation restoration&lt;/td&gt; 
   &lt;td align="center"&gt;100M, Mandarin and English&lt;/td&gt; 
   &lt;td align="center"&gt;290M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;fsmn-vad &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/fsmn-vad"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;voice activity detection&lt;/td&gt; 
   &lt;td align="center"&gt;5000 hours, Mandarin and English&lt;/td&gt; 
   &lt;td align="center"&gt;0.4M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;fsmn-kws &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/iic/speech_charctc_kws_phone-xiaoyun/summary"&gt;⭐&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;keyword spotting，streaming&lt;/td&gt; 
   &lt;td align="center"&gt;5000 hours, Mandarin&lt;/td&gt; 
   &lt;td align="center"&gt;0.7M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;fa-zh &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/damo/speech_timestamp_prediction-v1-16k-offline/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/fa-zh"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;timestamp prediction&lt;/td&gt; 
   &lt;td align="center"&gt;5000 hours, Mandarin&lt;/td&gt; 
   &lt;td align="center"&gt;38M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;cam++ &lt;br /&gt; ( &lt;a href="https://modelscope.cn/models/iic/speech_campplus_sv_zh-cn_16k-common/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/funasr/campplus"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speaker verification/diarization&lt;/td&gt; 
   &lt;td align="center"&gt;5000 hours&lt;/td&gt; 
   &lt;td align="center"&gt;7.2M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Whisper-large-v3 &lt;br /&gt; (&lt;a href="https://www.modelscope.cn/models/iic/Whisper-large-v3/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://github.com/openai/whisper"&gt;🍀&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, with timestamps, non-streaming&lt;/td&gt; 
   &lt;td align="center"&gt;multilingual&lt;/td&gt; 
   &lt;td align="center"&gt;1550 M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Whisper-large-v3-turbo &lt;br /&gt; (&lt;a href="https://www.modelscope.cn/models/iic/Whisper-large-v3-turbo/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://github.com/openai/whisper"&gt;🍀&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech recognition, with timestamps, non-streaming&lt;/td&gt; 
   &lt;td align="center"&gt;multilingual&lt;/td&gt; 
   &lt;td align="center"&gt;809 M&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Qwen-Audio &lt;br /&gt; (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/qwen_audio/demo.py"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/Qwen/Qwen-Audio"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;audio-text multimodal models (pretraining)&lt;/td&gt; 
   &lt;td align="center"&gt;multilingual&lt;/td&gt; 
   &lt;td align="center"&gt;8B&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Qwen-Audio-Chat &lt;br /&gt; (&lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/examples/industrial_data_pretraining/qwen_audio/demo_chat.py"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/Qwen/Qwen-Audio-Chat"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;audio-text multimodal models (chat)&lt;/td&gt; 
   &lt;td align="center"&gt;multilingual&lt;/td&gt; 
   &lt;td align="center"&gt;8B&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;emotion2vec+large &lt;br /&gt; (&lt;a href="https://modelscope.cn/models/iic/emotion2vec_plus_large/summary"&gt;⭐&lt;/a&gt; &lt;a href="https://huggingface.co/emotion2vec/emotion2vec_plus_large"&gt;🤗&lt;/a&gt; )&lt;/td&gt; 
   &lt;td align="center"&gt;speech emotion recongintion&lt;/td&gt; 
   &lt;td align="center"&gt;40000 hours&lt;/td&gt; 
   &lt;td align="center"&gt;300M&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a name="quick-start"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Below is a quick start tutorial. Test audio files (&lt;a href="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/vad_example.wav"&gt;Mandarin&lt;/a&gt;, &lt;a href="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav"&gt;English&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Command-line usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;funasr ++model=paraformer-zh ++vad_model="fsmn-vad" ++punc_model="ct-punc" ++input=asr_example_zh.wav
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes: Support recognition of single audio file, as well as file list in Kaldi-style wav.scp format: &lt;code&gt;wav_id wav_pat&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Speech Recognition (Non-streaming)&lt;/h3&gt; 
&lt;h4&gt;SenseVoice&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"

model = AutoModel(
    model=model_dir,
    vad_model="fsmn-vad",
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
)

# en
res = model.generate(
    input=f"{model.model_path}/example/en.mp3",
    cache={},
    language="auto",  # "zn", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
    merge_vad=True,  #
    merge_length_s=15,
)
text = rich_transcription_postprocess(res[0]["text"])
print(text)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Parameter Description:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;model_dir&lt;/code&gt;: The name of the model, or the path to the model on the local disk.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vad_model&lt;/code&gt;: This indicates the activation of VAD (Voice Activity Detection). The purpose of VAD is to split long audio into shorter clips. In this case, the inference time includes both VAD and SenseVoice total consumption, and represents the end-to-end latency. If you wish to test the SenseVoice model's inference time separately, the VAD model can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vad_kwargs&lt;/code&gt;: Specifies the configurations for the VAD model. &lt;code&gt;max_single_segment_time&lt;/code&gt;: denotes the maximum duration for audio segmentation by the &lt;code&gt;vad_model&lt;/code&gt;, with the unit being milliseconds (ms).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;use_itn&lt;/code&gt;: Whether the output result includes punctuation and inverse text normalization.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;batch_size_s&lt;/code&gt;: Indicates the use of dynamic batching, where the total duration of audio in the batch is measured in seconds (s).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;merge_vad&lt;/code&gt;: Whether to merge short audio fragments segmented by the VAD model, with the merged length being &lt;code&gt;merge_length_s&lt;/code&gt;, in seconds (s).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ban_emo_unk&lt;/code&gt;: Whether to ban the output of the &lt;code&gt;emo_unk&lt;/code&gt; token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Paraformer&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel
# paraformer-zh is a multi-functional asr model
# use vad, punc, spk or not as you need
model = AutoModel(model="paraformer-zh",  vad_model="fsmn-vad",  punc_model="ct-punc", 
                  # spk_model="cam++", 
                  )
res = model.generate(input=f"{model.model_path}/example/asr_example.wav", 
                     batch_size_s=300, 
                     hotword='魔搭')
print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: &lt;code&gt;hub&lt;/code&gt;: represents the model repository, &lt;code&gt;ms&lt;/code&gt; stands for selecting ModelScope download, &lt;code&gt;hf&lt;/code&gt; stands for selecting Huggingface download.&lt;/p&gt; 
&lt;h3&gt;Speech Recognition (Streaming)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

chunk_size = [0, 10, 5] #[0, 10, 5] 600ms, [0, 8, 4] 480ms
encoder_chunk_look_back = 4 #number of chunks to lookback for encoder self-attention
decoder_chunk_look_back = 1 #number of encoder chunks to lookback for decoder cross-attention

model = AutoModel(model="paraformer-zh-streaming")

import soundfile
import os

wav_file = os.path.join(model.model_path, "example/asr_example.wav")
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = chunk_size[1] * 960 # 600ms

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size, encoder_chunk_look_back=encoder_chunk_look_back, decoder_chunk_look_back=decoder_chunk_look_back)
    print(res)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: &lt;code&gt;chunk_size&lt;/code&gt; is the configuration for streaming latency.&lt;code&gt; [0,10,5]&lt;/code&gt; indicates that the real-time display granularity is &lt;code&gt;10*60=600ms&lt;/code&gt;, and the lookahead information is &lt;code&gt;5*60=300ms&lt;/code&gt;. Each inference input is &lt;code&gt;600ms&lt;/code&gt; (sample points are &lt;code&gt;16000*0.6=960&lt;/code&gt;), and the output is the corresponding text. For the last speech segment input, &lt;code&gt;is_final=True&lt;/code&gt; needs to be set to force the output of the last word.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;More Examples&lt;/summary&gt; 
 &lt;h3&gt;Voice Activity Detection (Non-Streaming)&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

model = AutoModel(model="fsmn-vad")
wav_file = f"{model.model_path}/example/vad_example.wav"
res = model.generate(input=wav_file)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: The output format of the VAD model is: &lt;code&gt;[[beg1, end1], [beg2, end2], ..., [begN, endN]]&lt;/code&gt;, where &lt;code&gt;begN/endN&lt;/code&gt; indicates the starting/ending point of the &lt;code&gt;N-th&lt;/code&gt; valid audio segment, measured in milliseconds.&lt;/p&gt; 
 &lt;h3&gt;Voice Activity Detection (Streaming)&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

chunk_size = 200 # ms
model = AutoModel(model="fsmn-vad")

import soundfile

wav_file = f"{model.model_path}/example/vad_example.wav"
speech, sample_rate = soundfile.read(wav_file)
chunk_stride = int(chunk_size * sample_rate / 1000)

cache = {}
total_chunk_num = int(len((speech)-1)/chunk_stride+1)
for i in range(total_chunk_num):
    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
    is_final = i == total_chunk_num - 1
    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size)
    if len(res[0]["value"]):
        print(res)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: The output format for the streaming VAD model can be one of four scenarios:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;[[beg1, end1], [beg2, end2], .., [begN, endN]]&lt;/code&gt;：The same as the offline VAD output result mentioned above.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;[[beg, -1]]&lt;/code&gt;：Indicates that only a starting point has been detected.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;[[-1, end]]&lt;/code&gt;：Indicates that only an ending point has been detected.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;[]&lt;/code&gt;：Indicates that neither a starting point nor an ending point has been detected.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;The output is measured in milliseconds and represents the absolute time from the starting point.&lt;/p&gt; 
 &lt;h3&gt;Punctuation Restoration&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

model = AutoModel(model="ct-punc")
res = model.generate(input="那今天的会就到这里吧 happy new year 明年见")
print(res)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Timestamp Prediction&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

model = AutoModel(model="fa-zh")
wav_file = f"{model.model_path}/example/asr_example.wav"
text_file = f"{model.model_path}/example/text.txt"
res = model.generate(input=(wav_file, text_file), data_type=("sound", "text"))
print(res)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Speech Emotion Recognition&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

model = AutoModel(model="emotion2vec_plus_large")

wav_file = f"{model.model_path}/example/test.wav"

res = model.generate(wav_file, output_dir="./outputs", granularity="utterance", extract_embedding=False)
print(res)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;More usages ref to &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/tutorial/README_zh.md"&gt;docs&lt;/a&gt;, more examples ref to &lt;a href="https://github.com/alibaba-damo-academy/FunASR/tree/main/examples/industrial_data_pretraining"&gt;demo&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Export ONNX&lt;/h2&gt; 
&lt;h3&gt;Command-line usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;funasr-export ++model=paraformer ++quantize=false ++device=cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from funasr import AutoModel

model = AutoModel(model="paraformer", device="cpu")

res = model.export(quantize=False)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Test ONNX&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# pip3 install -U funasr-onnx
from pathlib import Path
from runtime.python.onnxruntime.funasr_onnx.paraformer_bin import Paraformer


home_dir = Path.home()

model_dir = "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
model = Paraformer(model_dir, batch_size=1, quantize=True)

wav_path = [f"{home_dir}/.cache/modelscope/hub/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/example/asr_example.wav"]

result = model(wav_path)
print(result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More examples ref to &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/python/onnxruntime"&gt;demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Deployment Service&lt;/h2&gt; 
&lt;p&gt;FunASR supports deploying pre-trained or further fine-tuned models for service. Currently, it supports the following types of service deployment:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;File transcription service, Mandarin, CPU version, done&lt;/li&gt; 
 &lt;li&gt;The real-time transcription service, Mandarin (CPU), done&lt;/li&gt; 
 &lt;li&gt;File transcription service, English, CPU version, done&lt;/li&gt; 
 &lt;li&gt;File transcription service, Mandarin, GPU version, in progress&lt;/li&gt; 
 &lt;li&gt;and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more detailed information, please refer to the &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/runtime/readme.md"&gt;service deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a name="contact"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community Communication&lt;/h2&gt; 
&lt;p&gt;If you encounter problems in use, you can directly raise Issues on the github page.&lt;/p&gt; 
&lt;p&gt;You can also scan the following DingTalk group to join the community group for communication and discussion.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;DingTalk group&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;div align="left"&gt;
     &lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/dingding.png" width="250" /&gt;
    &lt;/div&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;div align="left"&gt;
     &lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/alibaba.png" width="260" /&gt;
    &lt;/div&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;div align="left"&gt;
     &lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/nwpu.png" width="260" /&gt;
    &lt;/div&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/China_Telecom.png" width="200" /&gt; &lt;/th&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/RapidAI.png" width="200" /&gt; &lt;/th&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/aihealthx.png" width="200" /&gt; &lt;/th&gt; 
   &lt;th align="center"&gt;&lt;img src="https://raw.githubusercontent.com/modelscope/FunASR/main/docs/images/XVERSE.png" width="250" /&gt; &lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
&lt;/table&gt; 
&lt;p&gt;The contributors can be found in &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/Acknowledge.md"&gt;contributors list&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under &lt;a href="https://opensource.org/licenses/MIT"&gt;The MIT License&lt;/a&gt;. FunASR also contains various third-party components and some code modified from other repos under other open source licenses. The use of pretraining model is subject to &lt;a href="https://raw.githubusercontent.com/modelscope/FunASR/main/MODEL_LICENSE"&gt;model license&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citations&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{gao2023funasr,
  author={Zhifu Gao and Zerui Li and Jiaming Wang and Haoneng Luo and Xian Shi and Mengzhe Chen and Yabin Li and Lingyun Zuo and Zhihao Du and Zhangyu Xiao and Shiliang Zhang},
  title={FunASR: A Fundamental End-to-End Speech Recognition Toolkit},
  year={2023},
  booktitle={INTERSPEECH},
}
@inproceedings{An2023bat,
  author={Keyu An and Xian Shi and Shiliang Zhang},
  title={BAT: Boundary aware transducer for memory-efficient and low-latency ASR},
  year={2023},
  booktitle={INTERSPEECH},
}
@inproceedings{gao22b_interspeech,
  author={Zhifu Gao and ShiLiang Zhang and Ian McLoughlin and Zhijie Yan},
  title={Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2063--2067},
  doi={10.21437/Interspeech.2022-9996}
}
@inproceedings{shi2023seaco,
  author={Xian Shi and Yexin Yang and Zerui Li and Yanni Chen and Zhifu Gao and Shiliang Zhang},
  title={SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability},
  year={2023},
  booktitle={ICASSP2024}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>sgl-project/sglang</title>
      <link>https://github.com/sgl-project/sglang</link>
      <description>&lt;p&gt;SGLang is a fast serving framework for large language models and vision language models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="sglangtop"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png" alt="logo" width="400" margin="10px" /&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/sglang"&gt;&lt;img src="https://img.shields.io/pypi/v/sglang" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://static.pepy.tech/badge/sglang?period=month" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/sgl-project/sglang/tree/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/sgl-project/sglang.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sgl-project/sglang/issues"&gt;&lt;img src="https://img.shields.io/github/issues-closed-raw/sgl-project/sglang" alt="issue resolution" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sgl-project/sglang/issues"&gt;&lt;img src="https://img.shields.io/github/issues-raw/sgl-project/sglang" alt="open issues" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/sgl-project/sglang"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;| &lt;a href="https://lmsys.org/blog/2025-05-05-large-scale-ep/"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://docs.sglang.ai/"&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://slack.sglang.ai/"&gt;&lt;strong&gt;Join Slack&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://meeting.sglang.ai/"&gt;&lt;strong&gt;Join Bi-Weekly Development Meeting&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/sgl-project/sglang/issues/7736"&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#slides"&gt;&lt;strong&gt;Slides&lt;/strong&gt;&lt;/a&gt; |&lt;/p&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/08] 🔔 SGLang x AMD SF Meetup on 8/22: Hands-on GPU workshop, tech talks by AMD/xAI/SGLang, and networking (&lt;a href="https://github.com/sgl-project/sgl-learning-materials/raw/main/slides/amd_meetup_sglang_roadmap.pdf"&gt;Roadmap&lt;/a&gt;, &lt;a href="https://github.com/sgl-project/sgl-learning-materials/raw/main/slides/amd_meetup_sglang_ep.pdf"&gt;Large-scale EP&lt;/a&gt;, &lt;a href="https://github.com/sgl-project/sgl-learning-materials/raw/main/slides/amd_meetup_highlights.pdf"&gt;Highlights&lt;/a&gt;, &lt;a href="https://github.com/sgl-project/sgl-learning-materials/raw/main/slides/amd_meetup_aiter_mori.pdf"&gt;AITER/MoRI&lt;/a&gt;, &lt;a href="https://github.com/sgl-project/sgl-learning-materials/raw/main/slides/amd_meetup_wave.pdf"&gt;Wave&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/08] 🔥 SGLang provides day-0 support for OpenAI gpt-oss model (&lt;a href="https://github.com/sgl-project/sglang/issues/8833"&gt;instructions&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2025/06] 🔥 SGLang, the high-performance serving infrastructure powering trillions of tokens daily, has been awarded the third batch of the Open Source AI Grant by a16z (&lt;a href="https://a16z.com/advancing-open-source-ai-through-benchmarks-and-bold-experimentation/"&gt;a16z blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/06] 🔥 Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part I): 2.7x Higher Decoding Throughput (&lt;a href="https://lmsys.org/blog/2025-06-16-gb200-part-1/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/05] 🔥 Deploying DeepSeek with PD Disaggregation and Large-scale Expert Parallelism on 96 H100 GPUs (&lt;a href="https://lmsys.org/blog/2025-05-05-large-scale-ep/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;[2025/03] Supercharge DeepSeek-R1 Inference on AMD Instinct MI300X (&lt;a href="https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1-Part2/README.html"&gt;AMD blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2025/03] SGLang Joins PyTorch Ecosystem: Efficient LLM Serving Engine (&lt;a href="https://pytorch.org/blog/sglang-joins-pytorch/"&gt;PyTorch blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;[2024/12] v0.4 Release: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs (&lt;a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/02] Unlock DeepSeek-R1 Inference Performance on AMD Instinct™ MI300X GPU (&lt;a href="https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1_Perf/README.html"&gt;AMD blog&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;[2025/01] SGLang provides day one support for DeepSeek V3/R1 models on NVIDIA and AMD GPUs with DeepSeek-specific optimizations. (&lt;a href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3"&gt;instructions&lt;/a&gt;, &lt;a href="https://www.amd.com/en/developer/resources/technical-articles/amd-instinct-gpus-power-deepseek-v3-revolutionizing-ai-development-with-sglang.html"&gt;AMD blog&lt;/a&gt;, &lt;a href="https://x.com/lmsysorg/status/1887262321636221412"&gt;10+ other companies&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;[2024/10] The First SGLang Online Meetup (&lt;a href="https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#the-first-sglang-online-meetup"&gt;slides&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/09] v0.3 Release: 7x Faster DeepSeek MLA, 1.5x Faster torch.compile, Multi-Image/Video LLaVA-OneVision (&lt;a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/07] v0.2 Release: Faster Llama3 Serving with SGLang Runtime (vs. TensorRT-LLM, vLLM) (&lt;a href="https://lmsys.org/blog/2024-07-25-sglang-llama3/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/02] SGLang enables &lt;strong&gt;3x faster JSON decoding&lt;/strong&gt; with compressed finite state machine (&lt;a href="https://lmsys.org/blog/2024-02-05-compressed-fsm/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/01] SGLang provides up to &lt;strong&gt;5x faster inference&lt;/strong&gt; with RadixAttention (&lt;a href="https://lmsys.org/blog/2024-01-17-sglang/"&gt;blog&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;[2024/01] SGLang powers the serving of the official &lt;strong&gt;LLaVA v1.6&lt;/strong&gt; release demo (&lt;a href="https://github.com/haotian-liu/LLaVA?tab=readme-ov-file#demo"&gt;usage&lt;/a&gt;).&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;SGLang is a fast serving framework for large language models and vision language models. It makes your interaction with models faster and more controllable by co-designing the backend runtime and frontend language. The core features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Backend Runtime&lt;/strong&gt;: Provides efficient serving with RadixAttention for prefix caching, zero-overhead CPU scheduler, prefill-decode disaggregation, speculative decoding, continuous batching, paged attention, tensor/pipeline/expert/data parallelism, structured outputs, chunked prefill, quantization (FP4/FP8/INT4/AWQ/GPTQ), and multi-lora batching.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Frontend Language&lt;/strong&gt;: Offers an intuitive interface for programming LLM applications, including chained generation calls, advanced prompting, control flow, multi-modal inputs, parallelism, and external interactions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensive Model Support&lt;/strong&gt;: Supports a wide range of generative models (Llama, Qwen, DeepSeek, Kimi, GPT, Gemma, Mistral, etc.), embedding models (e5-mistral, gte, mcdse) and reward models (Skywork), with easy extensibility for integrating new models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Community&lt;/strong&gt;: SGLang is open-source and backed by an active community with wide industry adoption.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sglang.ai/get_started/install.html"&gt;Install SGLang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sglang.ai/basic_usage/send_request.html"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sglang.ai/basic_usage/openai_api_completions.html"&gt;Backend Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sglang.ai/references/frontend/frontend_tutorial.html"&gt;Frontend Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.sglang.ai/developer_guide/contribution_guide.html"&gt;Contribution Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmark and Performance&lt;/h2&gt; 
&lt;p&gt;Learn more in the release blogs: &lt;a href="https://lmsys.org/blog/2024-07-25-sglang-llama3/"&gt;v0.2 blog&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/"&gt;v0.3 blog&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/"&gt;v0.4 blog&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2025-05-05-large-scale-ep/"&gt;Large-scale expert parallelism&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgl-project/sglang/issues/7736"&gt;Development Roadmap (2025 H2)&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Adoption and Sponsorship&lt;/h2&gt; 
&lt;p&gt;SGLang has been deployed at large scale, generating trillions of tokens in production each day. It is trusted and adopted by a wide range of leading enterprises and institutions, including xAI, AMD, NVIDIA, Intel, LinkedIn, Cursor, Oracle Cloud, Google Cloud, Microsoft Azure, AWS, Atlas Cloud, Voltage Park, Nebius, DataCrunch, Novita, InnoMatrix, MIT, UCLA, the University of Washington, Stanford, UC Berkeley, Tsinghua University, Jam &amp;amp; Tea Studios, Baseten, and other major technology organizations across North America and Asia. As an open-source LLM inference engine, SGLang has become the de facto industry standard, with deployments running on over 1,000,000 GPUs worldwide.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sgl-project/sgl-learning-materials/refs/heads/main/slides/adoption.png" alt="logo" width="800" margin="10px" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;For enterprises interested in adopting or deploying SGLang at scale, including technical consulting, sponsorship opportunities, or partnership inquiries, please contact us at &lt;a href="mailto:contact@sglang.ai"&gt;contact@sglang.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;We learned the design and reused code from the following projects: &lt;a href="https://github.com/guidance-ai/guidance"&gt;Guidance&lt;/a&gt;, &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;, &lt;a href="https://github.com/ModelTC/lightllm"&gt;LightLLM&lt;/a&gt;, &lt;a href="https://github.com/flashinfer-ai/flashinfer"&gt;FlashInfer&lt;/a&gt;, &lt;a href="https://github.com/outlines-dev/outlines"&gt;Outlines&lt;/a&gt;, and &lt;a href="https://github.com/eth-sri/lmql"&gt;LMQL&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelscope/DiffSynth-Studio</title>
      <link>https://github.com/modelscope/DiffSynth-Studio</link>
      <description>&lt;p&gt;Enjoy the magic of Diffusion models!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DiffSynth-Studio&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/modelscope/DiffSynth-Studio"&gt;&lt;img src="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/.github/workflows/logo.gif" title="Logo" style="max-width:100%;" width="55" /&gt;&lt;/a&gt; &lt;a href="https://trendshift.io/repositories/10946" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10946" alt="modelscope%2FDiffSynth-Studio | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/DiffSynth/"&gt;&lt;img src="https://img.shields.io/pypi/v/DiffSynth" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/modelscope/DiffSynth-Studio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/modelscope/DiffSynth-Studio.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/modelscope/DiffSynth-Studio/issues"&gt;&lt;img src="https://isitmaintained.com/badge/open/modelscope/DiffSynth-Studio.svg?sanitize=true" alt="open issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/modelscope/DiffSynth-Studio/pull/"&gt;&lt;img src="https://img.shields.io/github/issues-pr/modelscope/DiffSynth-Studio.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/modelscope/DiffSynth-Studio/commit/"&gt;&lt;img src="https://badgen.net/github/last-commit/modelscope/DiffSynth-Studio" alt="GitHub latest commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/README_zh.md"&gt;切换到中文&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Welcome to the magic world of Diffusion models! DiffSynth-Studio is an open-source Diffusion model engine developed and maintained by &lt;a href="https://www.modelscope.cn/"&gt;ModelScope&lt;/a&gt; team. We aim to foster technical innovation through framework development, bring together the power of the open-source community, and explore the limits of generative models!&lt;/p&gt; 
&lt;p&gt;DiffSynth currently includes two open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelscope/DiffSynth-Studio"&gt;DiffSynth-Studio&lt;/a&gt;: Focused on aggressive technical exploration, for academia, providing support for more cutting-edge model capabilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelscope/DiffSynth-Engine"&gt;DiffSynth-Engine&lt;/a&gt;: Focused on stable model deployment, for industry, offering higher computing performance and more stable features.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/modelscope/DiffSynth-Studio"&gt;DiffSynth-Studio&lt;/a&gt; and &lt;a href="https://github.com/modelscope/DiffSynth-Engine"&gt;DiffSynth-Engine&lt;/a&gt; are the core projects behind ModelScope &lt;a href="https://modelscope.cn/aigc/home"&gt;AIGC zone&lt;/a&gt;, offering powerful AI content generation abilities. Come and try our carefully designed features and start your AI creation journey!&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install from source (recommended):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/modelscope/DiffSynth-Studio.git  
cd DiffSynth-Studio
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Other installation methods&lt;/summary&gt; 
 &lt;p&gt;Install from PyPI (version updates may be delayed; for latest features, install from source)&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;pip install diffsynth
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you meet problems during installation, they might be caused by upstream dependencies. Please check the docs of these packages:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://pytorch.org/get-started/locally/"&gt;torch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/google/sentencepiece"&gt;sentencepiece&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://cmake.org"&gt;cmake&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.cupy.dev/en/stable/install.html"&gt;cupy&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Basic Framework&lt;/h2&gt; 
&lt;p&gt;DiffSynth-Studio redesigns the inference and training pipelines for mainstream Diffusion models (including FLUX, Wan, etc.), enabling efficient memory management and flexible model training.&lt;/p&gt; 
&lt;h3&gt;Qwen-Image Series (🔥New Model)&lt;/h3&gt; 
&lt;p&gt;Details: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/"&gt;./examples/qwen_image/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/738078d8-8749-4a53-a046-571861541924" alt="Image" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Quick Start&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from diffsynth.pipelines.qwen_image import QwenImagePipeline, ModelConfig
from PIL import Image
import torch

pipe = QwenImagePipeline.from_pretrained(
    torch_dtype=torch.bfloat16,
    device="cuda",
    model_configs=[
        ModelConfig(model_id="Qwen/Qwen-Image", origin_file_pattern="transformer/diffusion_pytorch_model*.safetensors"),
        ModelConfig(model_id="Qwen/Qwen-Image", origin_file_pattern="text_encoder/model*.safetensors"),
        ModelConfig(model_id="Qwen/Qwen-Image", origin_file_pattern="vae/diffusion_pytorch_model.safetensors"),
    ],
    tokenizer_config=ModelConfig(model_id="Qwen/Qwen-Image", origin_file_pattern="tokenizer/"),
)
prompt = "A detailed portrait of a girl underwater, wearing a blue flowing dress, hair gently floating, clear light and shadow, surrounded by bubbles, calm expression, fine details, dreamy and beautiful."
image = pipe(
    prompt, seed=0, num_inference_steps=40,
    # edit_image=Image.open("xxx.jpg").resize((1328, 1328)) # For Qwen-Image-Edit
)
image.save("image.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Model Overview&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model ID&lt;/th&gt; 
    &lt;th&gt;Inference&lt;/th&gt; 
    &lt;th&gt;Low VRAM Inference&lt;/th&gt; 
    &lt;th&gt;Full Training&lt;/th&gt; 
    &lt;th&gt;Validation after Full Training&lt;/th&gt; 
    &lt;th&gt;LoRA Training&lt;/th&gt; 
    &lt;th&gt;Validation after LoRA Training&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/Qwen/Qwen-Image"&gt;Qwen/Qwen-Image&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/Qwen/Qwen-Image-Edit"&gt;Qwen/Qwen-Image-Edit&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Edit.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Edit.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/Qwen/Qwen-Image-Edit-2509"&gt;Qwen/Qwen-Image-Edit-2509&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Edit-2509.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Edit-2509.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Edit-2509.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Edit-2509.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Edit-2509.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Edit-2509.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen-V2"&gt;DiffSynth-Studio/Qwen-Image-EliGen-V2&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-EliGen-V2.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-EliGen-V2.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-EliGen.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen-Poster"&gt;DiffSynth-Studio/Qwen-Image-EliGen-Poster&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-EliGen-Poster.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-EliGen-Poster.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-EliGen-Poster.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-EliGen-Poster.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Distill-Full"&gt;DiffSynth-Studio/Qwen-Image-Distill-Full&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Distill-Full.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Distill-Full.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Distill-Full.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Distill-Full.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Distill-Full.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Distill-Full.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Distill-LoRA"&gt;DiffSynth-Studio/Qwen-Image-Distill-LoRA&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Distill-LoRA.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Distill-LoRA.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Distill-LoRA.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Distill-LoRA.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen"&gt;DiffSynth-Studio/Qwen-Image-EliGen&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-EliGen.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Canny"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Canny&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Canny.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Blockwise-ControlNet-Canny.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Blockwise-ControlNet-Canny.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Blockwise-ControlNet-Canny.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Blockwise-ControlNet-Canny.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Blockwise-ControlNet-Canny.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Depth"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Depth&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Depth.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Blockwise-ControlNet-Depth.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Blockwise-ControlNet-Depth.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Blockwise-ControlNet-Depth.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Blockwise-ControlNet-Depth.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Blockwise-ControlNet-Depth.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Inpaint"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Inpaint&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Inpaint.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Blockwise-ControlNet-Inpaint.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/full/Qwen-Image-Blockwise-ControlNet-Inpaint.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_full/Qwen-Image-Blockwise-ControlNet-Inpaint.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Blockwise-ControlNet-Inpaint.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-Blockwise-ControlNet-Inpaint.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-In-Context-Control-Union"&gt;DiffSynth-Studio/Qwen-Image-In-Context-Control-Union&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-In-Context-Control-Union.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-In-Context-Control-Union.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-In-Context-Control-Union.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/validate_lora/Qwen-Image-In-Context-Control-Union.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Edit-Lowres-Fix"&gt;DiffSynth-Studio/Qwen-Image-Edit-Lowres-Fix&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Edit-Lowres-Fix.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-Edit-Lowres-Fix.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;FLUX Series&lt;/h3&gt; 
&lt;p&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/"&gt;./examples/flux/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/c01258e2-f251-441a-aa1e-ebb22f02594d" alt="Image" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Quick Start&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from diffsynth.pipelines.flux_image_new import FluxImagePipeline, ModelConfig

pipe = FluxImagePipeline.from_pretrained(
    torch_dtype=torch.bfloat16,
    device="cuda",
    model_configs=[
        ModelConfig(model_id="black-forest-labs/FLUX.1-dev", origin_file_pattern="flux1-dev.safetensors"),
        ModelConfig(model_id="black-forest-labs/FLUX.1-dev", origin_file_pattern="text_encoder/model.safetensors"),
        ModelConfig(model_id="black-forest-labs/FLUX.1-dev", origin_file_pattern="text_encoder_2/"),
        ModelConfig(model_id="black-forest-labs/FLUX.1-dev", origin_file_pattern="ae.safetensors"),
    ],
)

image = pipe(prompt="a cat", seed=0)
image.save("image.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Model Overview&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model ID&lt;/th&gt; 
    &lt;th&gt;Extra Parameters&lt;/th&gt; 
    &lt;th&gt;Inference&lt;/th&gt; 
    &lt;th&gt;Low VRAM Inference&lt;/th&gt; 
    &lt;th&gt;Full Training&lt;/th&gt; 
    &lt;th&gt;Validate After Full Training&lt;/th&gt; 
    &lt;th&gt;LoRA Training&lt;/th&gt; 
    &lt;th&gt;Validate After LoRA Training&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/black-forest-labs/FLUX.1-dev"&gt;FLUX.1-dev&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/black-forest-labs/FLUX.1-Krea-dev"&gt;FLUX.1-Krea-dev&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-Krea-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-Krea-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-Krea-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-Krea-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-Krea-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-Krea-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/black-forest-labs/FLUX.1-Kontext-dev"&gt;FLUX.1-Kontext-dev&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;kontext_images&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-Kontext-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-Kontext-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-Kontext-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-Kontext-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-Kontext-dev.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-Kontext-dev.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/alimama-creative/FLUX.1-dev-Controlnet-Inpainting-Beta"&gt;FLUX.1-dev-Controlnet-Inpainting-Beta&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;controlnet_inputs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-Controlnet-Inpainting-Beta.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-Controlnet-Inpainting-Beta.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-Controlnet-Inpainting-Beta.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-Controlnet-Inpainting-Beta.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-Controlnet-Inpainting-Beta.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-Controlnet-Inpainting-Beta.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/InstantX/FLUX.1-dev-Controlnet-Union-alpha"&gt;FLUX.1-dev-Controlnet-Union-alpha&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;controlnet_inputs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-Controlnet-Union-alpha.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-Controlnet-Union-alpha.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-Controlnet-Union-alpha.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-Controlnet-Union-alpha.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-Controlnet-Union-alpha.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-Controlnet-Union-alpha.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/jasperai/Flux.1-dev-Controlnet-Upscaler"&gt;FLUX.1-dev-Controlnet-Upscaler&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;controlnet_inputs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-Controlnet-Upscaler.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-Controlnet-Upscaler.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-Controlnet-Upscaler.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-Controlnet-Upscaler.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-Controlnet-Upscaler.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-Controlnet-Upscaler.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/InstantX/FLUX.1-dev-IP-Adapter"&gt;FLUX.1-dev-IP-Adapter&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ipadapter_images&lt;/code&gt;, &lt;code&gt;ipadapter_scale&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-IP-Adapter.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-IP-Adapter.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-IP-Adapter.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-IP-Adapter.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-IP-Adapter.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-IP-Adapter.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/ByteDance/InfiniteYou"&gt;FLUX.1-dev-InfiniteYou&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;infinityou_id_image&lt;/code&gt;, &lt;code&gt;infinityou_guidance&lt;/code&gt;, &lt;code&gt;controlnet_inputs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-InfiniteYou.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-InfiniteYou.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-InfiniteYou.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-InfiniteYou.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-InfiniteYou.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-InfiniteYou.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Eligen"&gt;FLUX.1-dev-EliGen&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;eligen_entity_prompts&lt;/code&gt;, &lt;code&gt;eligen_entity_masks&lt;/code&gt;, &lt;code&gt;eligen_enable_on_negative&lt;/code&gt;, &lt;code&gt;eligen_enable_inpaint&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLUX.1-dev-EliGen.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLUX.1-dev-EliGen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/LoRA-Encoder-FLUX.1-Dev"&gt;FLUX.1-dev-LoRA-Encoder&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_encoder_inputs&lt;/code&gt;, &lt;code&gt;lora_encoder_scale&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-LoRA-Encoder.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLUX.1-dev-LoRA-Encoder.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLUX.1-dev-LoRA-Encoder.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLUX.1-dev-LoRA-Encoder.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/DiffSynth-Studio/LoRAFusion-preview-FLUX.1-dev"&gt;FLUX.1-dev-LoRA-Fusion-Preview&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLUX.1-dev-LoRA-Fusion.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/stepfun-ai/Step1X-Edit"&gt;Step1X-Edit&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;step1x_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/Step1X-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/Step1X-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/Step1X-Edit.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/Step1X-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/Step1X-Edit.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/Step1X-Edit.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/ostris/Flex.2-preview"&gt;FLEX.2-preview&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;flex_inpaint_image&lt;/code&gt;, &lt;code&gt;flex_inpaint_mask&lt;/code&gt;, &lt;code&gt;flex_control_image&lt;/code&gt;, &lt;code&gt;flex_control_strength&lt;/code&gt;, &lt;code&gt;flex_control_stop&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/FLEX.2-preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/FLEX.2-preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/FLEX.2-preview.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/FLEX.2-preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/FLEX.2-preview.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/FLEX.2-preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Nexus-GenV2"&gt;Nexus-Gen&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;nexus_gen_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference/Nexus-Gen-Editing.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_inference_low_vram/Nexus-Gen-Editing.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/full/Nexus-Gen.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_full/Nexus-Gen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/lora/Nexus-Gen.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/model_training/validate_lora/Nexus-Gen.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Wan Series&lt;/h3&gt; 
&lt;p&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/"&gt;./examples/wanvideo/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/1d66ae74-3b02-40a9-acc3-ea95fc039314"&gt;https://github.com/user-attachments/assets/1d66ae74-3b02-40a9-acc3-ea95fc039314&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Quick Start&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import torch
from diffsynth import save_video
from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig

pipe = WanVideoPipeline.from_pretrained(
    torch_dtype=torch.bfloat16,
    device="cuda",
    model_configs=[
        ModelConfig(model_id="Wan-AI/Wan2.1-T2V-1.3B", origin_file_pattern="diffusion_pytorch_model*.safetensors", offload_device="cpu"),
        ModelConfig(model_id="Wan-AI/Wan2.1-T2V-1.3B", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
        ModelConfig(model_id="Wan-AI/Wan2.1-T2V-1.3B", origin_file_pattern="Wan2.1_VAE.pth", offload_device="cpu"),
    ],
)
pipe.enable_vram_management()

video = pipe(
    prompt="A documentary photography style scene: a lively puppy rapidly running on green grass. The puppy has brown-yellow fur, upright ears, and looks focused and joyful. Sunlight shines on its body, making the fur appear soft and shiny. The background is an open field with occasional wildflowers, and faint blue sky and clouds in the distance. Strong sense of perspective captures the motion of the puppy and the vitality of the surrounding grass. Mid-shot side-moving view.",
    negative_prompt="Bright colors, overexposed, static, blurry details, subtitles, style, artwork, image, still, overall gray, worst quality, low quality, JPEG compression artifacts, ugly, deformed, extra fingers, poorly drawn hands, poorly drawn face, malformed limbs, fused fingers, still frame, messy background, three legs, crowded background people, walking backwards",
    seed=0, tiled=True,
)
save_video(video, "video1.mp4", fps=15, quality=5)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Model Overview&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model ID&lt;/th&gt; 
    &lt;th&gt;Extra Parameters&lt;/th&gt; 
    &lt;th&gt;Inference&lt;/th&gt; 
    &lt;th&gt;Full Training&lt;/th&gt; 
    &lt;th&gt;Validate After Full Training&lt;/th&gt; 
    &lt;th&gt;LoRA Training&lt;/th&gt; 
    &lt;th&gt;Validate After LoRA Training&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/Wan-AI/Wan2.2-Animate-14B"&gt;Wan-AI/Wan2.2-Animate-14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;animate_pose_video&lt;/code&gt;, &lt;code&gt;animate_face_video&lt;/code&gt;, &lt;code&gt;animate_inpaint_video&lt;/code&gt;, &lt;code&gt;animate_mask_video&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-Animate-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-Animate-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-Animate-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-Animate-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-Animate-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/Wan-AI/Wan2.2-S2V-14B"&gt;Wan-AI/Wan2.2-S2V-14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;input_audio&lt;/code&gt;, &lt;code&gt;audio_sample_rate&lt;/code&gt;, &lt;code&gt;s2v_pose_video&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-S2V-14B_multi_clips.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.2-I2V-A14B"&gt;Wan-AI/Wan2.2-I2V-A14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-I2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-I2V-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-I2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-I2V-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-I2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.2-T2V-A14B"&gt;Wan-AI/Wan2.2-T2V-A14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-T2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-T2V-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-T2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-T2V-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-T2V-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.2-TI2V-5B"&gt;Wan-AI/Wan2.2-TI2V-5B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-TI2V-5B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-TI2V-5B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-TI2V-5B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-TI2V-5B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-TI2V-5B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/PAI/Wan2.2-VACE-Fun-A14B"&gt;Wan-AI/Wan2.2-VACE-Fun-A14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;vace_control_video&lt;/code&gt;, &lt;code&gt;vace_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-VACE-Fun-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-VACE-Fun-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-VACE-Fun-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-VACE-Fun-A14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-VACE-Fun-A14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.2-Fun-A14B-InP"&gt;PAI/Wan2.2-Fun-A14B-InP&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-Fun-A14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-Fun-A14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-Fun-A14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-Fun-A14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-Fun-A14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.2-Fun-A14B-Control"&gt;PAI/Wan2.2-Fun-A14B-Control&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_video&lt;/code&gt;, &lt;code&gt;reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-Fun-A14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-Fun-A14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-Fun-A14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-Fun-A14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-Fun-A14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.2-Fun-A14B-Control-Camera"&gt;PAI/Wan2.2-Fun-A14B-Control-Camera&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_camera_video&lt;/code&gt;, &lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.2-Fun-A14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.2-Fun-A14B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.2-Fun-A14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.2-Fun-A14B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.2-Fun-A14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-T2V-1.3B"&gt;Wan-AI/Wan2.1-T2V-1.3B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-T2V-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-T2V-1.3B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-T2V-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-T2V-1.3B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-T2V-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-T2V-14B"&gt;Wan-AI/Wan2.1-T2V-14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-T2V-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-T2V-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-T2V-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-T2V-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-T2V-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-I2V-14B-480P"&gt;Wan-AI/Wan2.1-I2V-14B-480P&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-I2V-14B-480P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-I2V-14B-480P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-I2V-14B-480P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-I2V-14B-480P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-I2V-14B-480P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-I2V-14B-720P"&gt;Wan-AI/Wan2.1-I2V-14B-720P&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-I2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-I2V-14B-720P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-I2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-I2V-14B-720P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-I2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-FLF2V-14B-720P"&gt;Wan-AI/Wan2.1-FLF2V-14B-720P&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-FLF2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-FLF2V-14B-720P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-FLF2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-FLF2V-14B-720P.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-FLF2V-14B-720P.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-1.3B-InP"&gt;PAI/Wan2.1-Fun-1.3B-InP&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-1.3B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-1.3B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-1.3B-Control"&gt;PAI/Wan2.1-Fun-1.3B-Control&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_video&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-1.3B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-1.3B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-InP"&gt;PAI/Wan2.1-Fun-14B-InP&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-14B-Control"&gt;PAI/Wan2.1-Fun-14B-Control&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_video&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-1.3B-Control"&gt;PAI/Wan2.1-Fun-V1.1-1.3B-Control&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_video&lt;/code&gt;, &lt;code&gt;reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-1.3B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-1.3B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-V1.1-1.3B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-14B-Control"&gt;PAI/Wan2.1-Fun-V1.1-14B-Control&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_video&lt;/code&gt;, &lt;code&gt;reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-14B-Control.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/examples/wanmodel_training/validate_lora/Wan2.1-Fun-V1.1-14B-Control.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-1.3B-InP"&gt;PAI/Wan2.1-Fun-V1.1-1.3B-InP&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-1.3B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-1.3B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-V1.1-1.3B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-14B-InP"&gt;PAI/Wan2.1-Fun-V1.1-14B-InP&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;input_image&lt;/code&gt;, &lt;code&gt;end_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-14B-InP.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-V1.1-14B-InP.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera"&gt;PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_camera_video&lt;/code&gt;, &lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-1.3B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-1.3B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-1.3B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-1.3B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-V1.1-1.3B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/PAI/Wan2.1-Fun-V1.1-14B-Control-Camera"&gt;PAI/Wan2.1-Fun-V1.1-14B-Control-Camera&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;control_camera_video&lt;/code&gt;, &lt;code&gt;input_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-Fun-V1.1-14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-Fun-V1.1-14B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-Fun-V1.1-14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-Fun-V1.1-14B-Control-Camera.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-Fun-V1.1-14B-Control-Camera.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/iic/VACE-Wan2.1-1.3B-Preview"&gt;iic/VACE-Wan2.1-1.3B-Preview&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;vace_control_video&lt;/code&gt;, &lt;code&gt;vace_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-VACE-1.3B-Preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-VACE-1.3B-Preview.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-VACE-1.3B-Preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-VACE-1.3B-Preview.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-VACE-1.3B-Preview.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-VACE-1.3B"&gt;Wan-AI/Wan2.1-VACE-1.3B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;vace_control_video&lt;/code&gt;, &lt;code&gt;vace_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-VACE-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-VACE-1.3B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-VACE-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-VACE-1.3B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-VACE-1.3B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/Wan-AI/Wan2.1-VACE-14B"&gt;Wan-AI/Wan2.1-VACE-14B&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;vace_control_video&lt;/code&gt;, &lt;code&gt;vace_reference_image&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-VACE-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-VACE-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-VACE-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-VACE-14B.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-VACE-14B.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Wan2.1-1.3b-speedcontrol-v1"&gt;DiffSynth-Studio/Wan2.1-1.3b-speedcontrol-v1&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;motion_bucket_id&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_inference/Wan2.1-1.3b-speedcontrol-v1.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/full/Wan2.1-1.3b-speedcontrol-v1.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_full/Wan2.1-1.3b-speedcontrol-v1.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/lora/Wan2.1-1.3b-speedcontrol-v1.sh"&gt;code&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/model_training/validate_lora/Wan2.1-1.3b-speedcontrol-v1.py"&gt;code&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;More Models&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Image Generation Models&lt;/summary&gt; 
 &lt;p&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/image_synthesis/"&gt;./examples/image_synthesis/&lt;/a&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;FLUX&lt;/th&gt; 
    &lt;th&gt;Stable Diffusion 3&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/984561e9-553d-4952-9443-79ce144f379f" alt="image_1024_cfg" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/modelscope/DiffSynth-Studio/assets/35051019/4df346db-6f91-420a-b4c1-26e205376098" alt="image_1024" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Kolors&lt;/th&gt; 
    &lt;th&gt;Hunyuan-DiT&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/modelscope/DiffSynth-Studio/assets/35051019/53ef6f41-da11-4701-8665-9f64392607bf" alt="image_1024" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/modelscope/DiffSynth-Studio/assets/35051019/60b022c8-df3f-4541-95ab-bf39f2fa8bb5" alt="image_1024" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Stable Diffusion&lt;/th&gt; 
    &lt;th&gt;Stable Diffusion XL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/6fc84611-8da6-4a1f-8fee-9a34eba3b4a5" alt="1024" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/67687748-e738-438c-aee5-96096f09ac90" alt="1024" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Video Generation Models&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;HunyuanVideo: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/HunyuanVideo/"&gt;./examples/HunyuanVideo/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/48dd24bb-0cc6-40d2-88c3-10feed3267e9"&gt;https://github.com/user-attachments/assets/48dd24bb-0cc6-40d2-88c3-10feed3267e9&lt;/a&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;StepVideo: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/stepvideo/"&gt;./examples/stepvideo/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5954fdaa-a3cf-45a3-bd35-886e3cc4581b"&gt;https://github.com/user-attachments/assets/5954fdaa-a3cf-45a3-bd35-886e3cc4581b&lt;/a&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CogVideoX: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/CogVideoX/"&gt;./examples/CogVideoX/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/26b044c1-4a60-44a4-842f-627ff289d006"&gt;https://github.com/user-attachments/assets/26b044c1-4a60-44a4-842f-627ff289d006&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Image Quality Assessment Models&lt;/summary&gt; 
 &lt;p&gt;We have integrated a series of image quality assessment models. These models can be used for evaluating image generation models, alignment training, and similar tasks.&lt;/p&gt; 
 &lt;p&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/image_quality_metric/"&gt;./examples/image_quality_metric/&lt;/a&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/THUDM/ImageReward"&gt;ImageReward&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/christophschuhmann/improved-aesthetic-predictor"&gt;Aesthetic&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yuvalkirstain/pickscore"&gt;PickScore&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/openai/CLIP"&gt;CLIP&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/tgxs002/HPSv2"&gt;HPSv2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/tgxs002/HPSv2"&gt;HPSv2.1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Kwai-Kolors/MPS"&gt;MPS&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Innovative Achievements&lt;/h2&gt; 
&lt;p&gt;DiffSynth-Studio is not just an engineering model framework, but also a platform for incubating innovative results.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Nexus-Gen: Unified Architecture for Image Understanding, Generation, and Editing&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detail page: &lt;a href="https://github.com/modelscope/Nexus-Gen"&gt;https://github.com/modelscope/Nexus-Gen&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/pdf/2504.21356"&gt;Nexus-Gen: Unified Image Understanding, Generation, and Editing via Prefilled Autoregression in Shared Embedding Space&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Nexus-GenV2"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/modelscope/Nexus-GenV2"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Dataset: &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/Nexus-Gen-Training-Dataset"&gt;ModelScope Dataset&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Online Demo: &lt;a href="https://www.modelscope.cn/studios/DiffSynth-Studio/Nexus-Gen"&gt;ModelScope Nexus-Gen Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;img src="https://github.com/modelscope/Nexus-Gen/raw/main/assets/illustrations/gen_edit.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ArtAug: Aesthetic Enhancement for Image Generation Models&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/ArtAug/"&gt;./examples/ArtAug/&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2412.12888"&gt;ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/ArtAug-lora-FLUX.1dev-v1"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/ECNU-CILab/ArtAug-lora-FLUX.1dev-v1"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Online Demo: &lt;a href="https://www.modelscope.cn/aigc/imageGeneration?tab=advanced&amp;amp;versionId=7228&amp;amp;modelType=LoRA&amp;amp;sdVersion=FLUX_1&amp;amp;modelUrl=modelscope%3A%2F%2FDiffSynth-Studio%2FArtAug-lora-FLUX.1dev-v1%3Frevision%3Dv1.0"&gt;ModelScope AIGC Tab&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;FLUX.1-dev&lt;/th&gt; 
    &lt;th&gt;FLUX.1-dev + ArtAug LoRA&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e1d5c505-b423-45fe-be01-25c2758f5417" alt="image_1_base" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/335908e3-d0bd-41c2-9d99-d10528a2d719" alt="image_1_enhance" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;EliGen: Precise Image Region Control&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detail page: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/EntityControl/"&gt;./examples/EntityControl/&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2501.01097"&gt;EliGen: Entity-Level Controlled Image Generation with Regional Attention&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Eligen"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/modelscope/EliGen"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Online Demo: &lt;a href="https://www.modelscope.cn/studios/DiffSynth-Studio/EliGen"&gt;ModelScope EliGen Studio&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Dataset: &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/EliGenTrainSet"&gt;EliGen Train Set&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Entity Control Mask&lt;/th&gt; 
    &lt;th&gt;Generated Image&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/1c6d9445-5022-4d91-ad2e-dc05321883d1" alt="eligen_example_2_mask_0" /&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/86739945-cb07-4a49-b3b3-3bb65c90d14f" alt="eligen_example_2_0" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ExVideo: Extended Training for Video Generation Models&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Project Page: &lt;a href="https://ecnu-cilab.github.io/ExVideoProjectPage/"&gt;Project Page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2406.14130"&gt;ExVideo: Extending Video Diffusion Models via Parameter-Efficient Post-Tuning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Code Example: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/ExVideo/"&gt;./examples/ExVideo/&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Model: &lt;a href="https://modelscope.cn/models/ECNU-CILab/ExVideo-SVD-128f-v1"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/ECNU-CILab/ExVideo-SVD-128f-v1"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/modelscope/DiffSynth-Studio/assets/35051019/d97f6aa9-8064-4b5b-9d49-ed6001bb9acc"&gt;https://github.com/modelscope/DiffSynth-Studio/assets/35051019/d97f6aa9-8064-4b5b-9d49-ed6001bb9acc&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Diffutoon: High-Resolution Anime-Style Video Rendering&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Project Page: &lt;a href="https://ecnu-cilab.github.io/DiffutoonProjectPage/"&gt;Project Page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2401.16224"&gt;Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Code Example: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/Diffutoon/"&gt;./examples/Diffutoon/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/b54c05c5-d747-4709-be5e-b39af82404dd"&gt;https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/b54c05c5-d747-4709-be5e-b39af82404dd&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DiffSynth: The Initial Version of This Project&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Project Page: &lt;a href="https://ecnu-cilab.github.io/DiffSynth.github.io/"&gt;Project Page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2308.03463"&gt;DiffSynth: Latent In-Iteration Deflickering for Realistic Video Synthesis&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Code Example: &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/diffsynth/"&gt;./examples/diffsynth/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/59fb2f7b-8de0-4481-b79f-0c3a7361a1ea"&gt;https://github.com/Artiprocher/DiffSynth-Studio/assets/35051019/59fb2f7b-8de0-4481-b79f-0c3a7361a1ea&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Update History&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;September 23, 2025&lt;/strong&gt; &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen-Poster"&gt;DiffSynth-Studio/Qwen-Image-EliGen-Poster&lt;/a&gt; is released! This model is jointly developed and open-sourced by us and the Taobao Design Team. The model is built upon Qwen-Image, specifically designed for e-commerce poster scenarios, and supports precise partition layout control. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-EliGen-Poster.py"&gt;our example code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;September 9, 2025&lt;/strong&gt;: Our training framework now supports multiple training modes and has been adapted for Qwen-Image. In addition to the standard SFT training mode, Direct Distill is now also supported; please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_training/lora/Qwen-Image-Distill-LoRA.sh"&gt;our example code&lt;/a&gt;. This feature is experimental, and we will continue to improve it to support comprehensive model training capabilities.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 28, 2025&lt;/strong&gt; We support Wan2.2-S2V, an audio-driven cinematic video generation model open-sourced by Alibaba. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/"&gt;./examples/wanvideo/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 21, 2025&lt;/strong&gt;: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen-V2"&gt;DiffSynth-Studio/Qwen-Image-EliGen-V2&lt;/a&gt; is released! Compared to the V1 version, the training dataset has been updated to the &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/Qwen-Image-Self-Generated-Dataset"&gt;Qwen-Image-Self-Generated-Dataset&lt;/a&gt;, enabling generated images to better align with the inherent image distribution and style of Qwen-Image. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference_low_vram/Qwen-Image-EliGen-V2.py"&gt;our sample code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 21, 2025&lt;/strong&gt;: We open-sourced the &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-In-Context-Control-Union"&gt;DiffSynth-Studio/Qwen-Image-In-Context-Control-Union&lt;/a&gt; structure control LoRA model. Following "In Context" routine, it supports various types of structural control conditions, including canny, depth, lineart, softedge, normal, and openpose. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-In-Context-Control-Union.py"&gt;our sample code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 20, 2025&lt;/strong&gt; We open-sourced &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Edit-Lowres-Fix"&gt;DiffSynth-Studio/Qwen-Image-Edit-Lowres-Fix&lt;/a&gt;, which improves the editing performance of Qwen-Image-Edit on low-resolution image inputs. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Edit-Lowres-Fix.py"&gt;our example code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 19, 2025&lt;/strong&gt; 🔥 Qwen-Image-Edit is now open source. Welcome the new member to the image editing model family!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 18, 2025&lt;/strong&gt; We trained and open-sourced the Inpaint ControlNet model for Qwen-Image, &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Inpaint"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Inpaint&lt;/a&gt;, which adopts a lightweight architectural design. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Inpaint.py"&gt;our sample code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 15, 2025&lt;/strong&gt; We open-sourced the &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/Qwen-Image-Self-Generated-Dataset"&gt;Qwen-Image-Self-Generated-Dataset&lt;/a&gt;. This is an image dataset generated using the Qwen-Image model, with a total of 160,000 &lt;code&gt;1024 x 1024&lt;/code&gt; images. It includes the general, English text rendering, and Chinese text rendering subsets. We provide caption, entity and control images annotations for each image. Developers can use this dataset to train models such as ControlNet and EliGen for the Qwen-Image model. We aim to promote technological development through open-source contributions!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 13, 2025&lt;/strong&gt; We trained and open-sourced the ControlNet model for Qwen-Image, &lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Depth"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Depth&lt;/a&gt;, which adopts a lightweight architectural design. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Depth.py"&gt;our sample code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 12, 2025&lt;/strong&gt; We trained and open-sourced the ControlNet model for Qwen-Image, &lt;a href="https://modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Canny"&gt;DiffSynth-Studio/Qwen-Image-Blockwise-ControlNet-Canny&lt;/a&gt;, which adopts a lightweight architectural design. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/qwen_image/model_inference/Qwen-Image-Blockwise-ControlNet-Canny.py"&gt;our sample code&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 11, 2025&lt;/strong&gt; We released another distilled acceleration model for Qwen-Image, &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Distill-LoRA"&gt;DiffSynth-Studio/Qwen-Image-Distill-LoRA&lt;/a&gt;. It uses the same training process as &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Distill-Full"&gt;DiffSynth-Studio/Qwen-Image-Distill-Full&lt;/a&gt;, but the model structure is changed to LoRA. This makes it work better with other open-source models.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 7, 2025&lt;/strong&gt; We open-sourced the entity control LoRA of Qwen-Image, &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-EliGen"&gt;DiffSynth-Studio/Qwen-Image-EliGen&lt;/a&gt;. Qwen-Image-EliGen is able to achieve entity-level controlled text-to-image generation. See the &lt;a href="https://arxiv.org/abs/2501.01097"&gt;paper&lt;/a&gt; for technical details. Training dataset: &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/EliGenTrainSet"&gt;EliGenTrainSet&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 5, 2025&lt;/strong&gt; We open-sourced the distilled acceleration model of Qwen-Image, &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-Distill-Full"&gt;DiffSynth-Studio/Qwen-Image-Distill-Full&lt;/a&gt;, achieving approximately 5x speedup.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 4, 2025&lt;/strong&gt; 🔥 Qwen-Image is now open source. Welcome the new member to the image generation model family!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 1, 2025&lt;/strong&gt; &lt;a href="https://www.modelscope.cn/models/black-forest-labs/FLUX.1-Krea-dev"&gt;FLUX.1-Krea-dev&lt;/a&gt; with a focus on aesthetic photography is comprehensively supported, including low-GPU-memory layer-by-layer offload, LoRA training and full training. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/flux/"&gt;./examples/flux/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;July 28, 2025&lt;/strong&gt; With the open-sourcing of Wan 2.2, we immediately provided comprehensive support, including low-GPU-memory layer-by-layer offload, FP8 quantization, sequence parallelism, LoRA training, full training. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/"&gt;./examples/wanvideo/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;July 11, 2025&lt;/strong&gt; We propose Nexus-Gen, a unified model that synergizes the language reasoning capabilities of LLMs with the image synthesis power of diffusion models. This framework enables seamless image understanding, generation, and editing tasks.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Paper: &lt;a href="https://arxiv.org/pdf/2504.21356"&gt;Nexus-Gen: Unified Image Understanding, Generation, and Editing via Prefilled Autoregression in Shared Embedding Space&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Github Repo: &lt;a href="https://github.com/modelscope/Nexus-Gen"&gt;https://github.com/modelscope/Nexus-Gen&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Nexus-GenV2"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/modelscope/Nexus-GenV2"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Training Dataset: &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/Nexus-Gen-Training-Dataset"&gt;ModelScope Dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Online Demo: &lt;a href="https://www.modelscope.cn/studios/DiffSynth-Studio/Nexus-Gen"&gt;ModelScope Nexus-Gen Studio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;June 15, 2025&lt;/strong&gt; ModelScope's official evaluation framework, &lt;a href="https://github.com/modelscope/evalscope"&gt;EvalScope&lt;/a&gt;, now supports text-to-image generation evaluation. Try it with the &lt;a href="https://evalscope.readthedocs.io/zh-cn/latest/best_practice/t2i_eval.html"&gt;Best Practices&lt;/a&gt; guide.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;March 25, 2025&lt;/strong&gt; Our new open-source project, &lt;a href="https://github.com/modelscope/DiffSynth-Engine"&gt;DiffSynth-Engine&lt;/a&gt;, is now open-sourced! Focused on stable model deployment. Geared towards industry. Offers better engineering support, higher computational performance, and more stable functionality.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;March 31, 2025&lt;/strong&gt; We support InfiniteYou, an identity preserving method for FLUX. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/InfiniteYou/"&gt;./examples/InfiniteYou/&lt;/a&gt; for more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;March 13, 2025&lt;/strong&gt; We support HunyuanVideo-I2V, the image-to-video generation version of HunyuanVideo open-sourced by Tencent. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/HunyuanVideo/"&gt;./examples/HunyuanVideo/&lt;/a&gt; for more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;February 25, 2025&lt;/strong&gt; We support Wan-Video, a collection of SOTA video synthesis models open-sourced by Alibaba. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/wanvideo/"&gt;./examples/wanvideo/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;February 17, 2025&lt;/strong&gt; We support &lt;a href="https://modelscope.cn/models/stepfun-ai/stepvideo-t2v/summary"&gt;StepVideo&lt;/a&gt;! State-of-the-art video synthesis model! See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/stepvideo/"&gt;./examples/stepvideo&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;December 31, 2024&lt;/strong&gt; We propose EliGen, a novel framework for precise entity-level controlled text-to-image generation, complemented by an inpainting fusion pipeline to extend its capabilities to image inpainting tasks. EliGen seamlessly integrates with existing community models, such as IP-Adapter and In-Context LoRA, enhancing its versatility. For more details, see &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/EntityControl/"&gt;./examples/EntityControl&lt;/a&gt;.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2501.01097"&gt;EliGen: Entity-Level Controlled Image Generation with Regional Attention&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/Eligen"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/modelscope/EliGen"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Online Demo: &lt;a href="https://www.modelscope.cn/studios/DiffSynth-Studio/EliGen"&gt;ModelScope EliGen Studio&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Training Dataset: &lt;a href="https://www.modelscope.cn/datasets/DiffSynth-Studio/EliGenTrainSet"&gt;EliGen Train Set&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;December 19, 2024&lt;/strong&gt; We implement advanced VRAM management for HunyuanVideo, making it possible to generate videos at a resolution of 129x720x1280 using 24GB of VRAM, or at 129x512x384 resolution with just 6GB of VRAM. Please refer to &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/HunyuanVideo/"&gt;./examples/HunyuanVideo/&lt;/a&gt; for more details.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;December 18, 2024&lt;/strong&gt; We propose ArtAug, an approach designed to improve text-to-image synthesis models through synthesis-understanding interactions. We have trained an ArtAug enhancement module for FLUX.1-dev in the format of LoRA. This model integrates the aesthetic understanding of Qwen2-VL-72B into FLUX.1-dev, leading to an improvement in the quality of generated images.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2412.12888"&gt;https://arxiv.org/abs/2412.12888&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Examples: &lt;a href="https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/ArtAug"&gt;https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/ArtAug&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Model: &lt;a href="https://www.modelscope.cn/models/DiffSynth-Studio/ArtAug-lora-FLUX.1dev-v1"&gt;ModelScope&lt;/a&gt;, &lt;a href="https://huggingface.co/ECNU-CILab/ArtAug-lora-FLUX.1dev-v1"&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Demo: &lt;a href="https://modelscope.cn/aigc/imageGeneration?tab=advanced&amp;amp;versionId=7228&amp;amp;modelType=LoRA&amp;amp;sdVersion=FLUX_1&amp;amp;modelUrl=modelscope%3A%2F%2FDiffSynth-Studio%2FArtAug-lora-FLUX.1dev-v1%3Frevision%3Dv1.0"&gt;ModelScope&lt;/a&gt;, HuggingFace (Coming soon)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;October 25, 2024&lt;/strong&gt; We provide extensive FLUX ControlNet support. This project supports many different ControlNet models that can be freely combined, even if their structures differ. Additionally, ControlNet models are compatible with high-resolution refinement and partition control techniques, enabling very powerful controllable image generation. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/ControlNet/"&gt;&lt;code&gt;./examples/ControlNet/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;October 8, 2024.&lt;/strong&gt; We release the extended LoRA based on CogVideoX-5B and ExVideo. You can download this model from &lt;a href="https://modelscope.cn/models/ECNU-CILab/ExVideo-CogVideoX-LoRA-129f-v1"&gt;ModelScope&lt;/a&gt; or &lt;a href="https://huggingface.co/ECNU-CILab/ExVideo-CogVideoX-LoRA-129f-v1"&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 22, 2024.&lt;/strong&gt; CogVideoX-5B is supported in this project. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/video_synthesis/"&gt;here&lt;/a&gt;. We provide several interesting features for this text-to-video model, including&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Text to video&lt;/li&gt; 
    &lt;li&gt;Video editing&lt;/li&gt; 
    &lt;li&gt;Self-upscaling&lt;/li&gt; 
    &lt;li&gt;Video interpolation&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 22, 2024.&lt;/strong&gt; We have implemented an interesting painter that supports all text-to-image models. Now you can create stunning images using the painter, with assistance from AI!&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Use it in our &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/#usage-in-webui"&gt;WebUI&lt;/a&gt;.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;August 21, 2024.&lt;/strong&gt; FLUX is supported in DiffSynth-Studio.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Enable CFG and highres-fix to improve visual quality. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/image_synthesis/README.md"&gt;here&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;LoRA, ControlNet, and additional models will be available soon.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;June 21, 2024.&lt;/strong&gt; We propose ExVideo, a post-tuning technique aimed at enhancing the capability of video generation models. We have extended Stable Video Diffusion to achieve the generation of long videos up to 128 frames.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://ecnu-cilab.github.io/ExVideoProjectPage/"&gt;Project Page&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Source code is released in this repo. See &lt;a href="https://raw.githubusercontent.com/modelscope/DiffSynth-Studio/main/examples/ExVideo/"&gt;&lt;code&gt;examples/ExVideo&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;Models are released on &lt;a href="https://huggingface.co/ECNU-CILab/ExVideo-SVD-128f-v1"&gt;HuggingFace&lt;/a&gt; and &lt;a href="https://modelscope.cn/models/ECNU-CILab/ExVideo-SVD-128f-v1"&gt;ModelScope&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;Technical report is released on &lt;a href="https://arxiv.org/abs/2406.14130"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;You can try ExVideo in this &lt;a href="https://huggingface.co/spaces/modelscope/ExVideo-SVD-128f-v1"&gt;Demo&lt;/a&gt;!&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;June 13, 2024.&lt;/strong&gt; DiffSynth Studio is transferred to ModelScope. The developers have transitioned from "I" to "we". Of course, I will still participate in development and maintenance.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Jan 29, 2024.&lt;/strong&gt; We propose Diffutoon, a fantastic solution for toon shading.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://ecnu-cilab.github.io/DiffutoonProjectPage/"&gt;Project Page&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;The source codes are released in this project.&lt;/li&gt; 
    &lt;li&gt;The technical report (IJCAI 2024) is released on &lt;a href="https://arxiv.org/abs/2401.16224"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dec 8, 2023.&lt;/strong&gt; We decide to develop a new Project, aiming to release the potential of diffusion models, especially in video synthesis. The development of this project is started.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nov 15, 2023.&lt;/strong&gt; We propose FastBlend, a powerful video deflickering algorithm.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;The sd-webui extension is released on &lt;a href="https://github.com/Artiprocher/sd-webui-fastblend"&gt;GitHub&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;Demo videos are shown on Bilibili, including three tasks. 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1d94y1W7PE"&gt;Video deflickering&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1Lw411m71p"&gt;Video interpolation&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1RB4y1Z7LF"&gt;Image-driven video rendering&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;The technical report is released on &lt;a href="https://arxiv.org/abs/2311.09265"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;An unofficial ComfyUI extension developed by other users is released on &lt;a href="https://github.com/AInseven/ComfyUI-fastblend"&gt;GitHub&lt;/a&gt;.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Oct 1, 2023.&lt;/strong&gt; We release an early version of this project, namely FastSDXL. A try for building a diffusion engine.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;The source codes are released on &lt;a href="https://github.com/Artiprocher/FastSDXL"&gt;GitHub&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;FastSDXL includes a trainable OLSS scheduler for efficiency improvement. 
     &lt;ul&gt; 
      &lt;li&gt;The original repo of OLSS is &lt;a href="https://github.com/alibaba/EasyNLP/tree/master/diffusion/olss_scheduler"&gt;here&lt;/a&gt;.&lt;/li&gt; 
      &lt;li&gt;The technical report (CIKM 2023) is released on &lt;a href="https://arxiv.org/abs/2305.14677"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
      &lt;li&gt;A demo video is shown on &lt;a href="https://www.bilibili.com/video/BV1w8411y7uj"&gt;Bilibili&lt;/a&gt;.&lt;/li&gt; 
      &lt;li&gt;Since OLSS requires additional training, we don't implement it in this project.&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aug 29, 2023.&lt;/strong&gt; We propose DiffSynth, a video synthesis framework.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://ecnu-cilab.github.io/DiffSynth.github.io/"&gt;Project Page&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;The source codes are released in &lt;a href="https://github.com/alibaba/EasyNLP/tree/master/diffusion/DiffSynth"&gt;EasyNLP&lt;/a&gt;.&lt;/li&gt; 
    &lt;li&gt;The technical report (ECML PKDD 2024) is released on &lt;a href="https://arxiv.org/abs/2308.03463"&gt;arXiv&lt;/a&gt;.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Epodonios/v2ray-configs</title>
      <link>https://github.com/Epodonios/v2ray-configs</link>
      <description>&lt;p&gt;Free vless-vmess-shadowsocks-trojan-xray-V2ray Configs Updating Every 5 minutes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://img.shields.io/github/last-commit/barry-far/V2ray-Configs.svg?sanitize=true" alt="GitHub last commit" /&gt; &lt;a href="https://lbesson.mit-license.org/"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Epodonios/V2ray-Configs/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/barry-far/V2ray-Configs/actions/workflows/main.yml/badge.svg?sanitize=true" alt="Update Configs" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/repo-size/Epodonios/V2ray-Configs" alt="GitHub repo size" /&gt;&lt;/p&gt; 
&lt;a href="https://t.me/+IOG0nSifAV03ZmY0" target="_blank"&gt; &lt;img src="https://cdn-icons-png.flaticon.com/512/2111/2111646.png" alt="Telegram" width="500" height="500" /&gt; contact us &lt;/a&gt; 
&lt;h1&gt;Bulk V2ray Configs&lt;/h1&gt; 
&lt;p&gt;💻 This repository contains a collection of free V2ray configuration files that you can use with your V2ray client to access the internet securely and anonymously. This script collects several thousand V2ray configurations every five minutes, and you can receive and use the protocol in base 64, normal, or split format.&lt;/p&gt; 
&lt;h3&gt;Supported Protocols:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vmess&lt;/li&gt; 
 &lt;li&gt;Vless&lt;/li&gt; 
 &lt;li&gt;Trojan&lt;/li&gt; 
 &lt;li&gt;Tuic&lt;/li&gt; 
 &lt;li&gt;Shadowsocks&lt;/li&gt; 
 &lt;li&gt;ShadowsocksR&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;You can use a v2ray client to use these subscription links:&lt;/h3&gt; 
&lt;h4&gt;Android:&lt;/h4&gt; 
&lt;p&gt;v2rayng&lt;/p&gt; 
&lt;h4&gt;IOS:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;fair&lt;/li&gt; 
 &lt;li&gt;streisand&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Windows and Linux:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;hiddify-next&lt;/li&gt; 
 &lt;li&gt;nekoray&lt;/li&gt; 
 &lt;li&gt;v2rayn&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Subscriptions Links&lt;/h2&gt; 
&lt;h3&gt;Here are the subscription links at your disposal:&lt;/h3&gt; 
&lt;p&gt;All collected configs:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/All_Configs_Sub.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the above link doesn't work, try the base 64 configurations:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/All_Configs_base64_Sub.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Splited by protocol:&lt;/h3&gt; 
&lt;p&gt;Vless:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/vless.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Vmess:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/vmess.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ss:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/ss.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ssr:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/ssr.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Trojan:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/trojan.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Splited in 250 count of configs:&lt;/h3&gt; 
&lt;p&gt;Config List 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub1.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 2:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub2.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 3:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub3.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 4:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub4.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 5:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub5.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 6:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub6.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 7:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub7.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 8:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub8.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 9:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub9.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 10:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub10.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 11:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub11.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 12:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub12.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 13:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub13.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Config List 14:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/Sub14.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage:&lt;/h3&gt; 
&lt;p&gt;Mobile and pc:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Copy the links provided and go to your v2ray clients subscription setting and paste metioned link and save that.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Occasionally use the subscription update function in your v2ray client to stay up-to-date 🤝.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;I hope u use this configs very well.&lt;/p&gt; 
&lt;h1&gt;V2Ray Config Scanner&lt;/h1&gt; 
&lt;p&gt;A lightweight Python script that scans and pings a list of V2Ray configuration links (vmess, vless, etc.), and outputs their protocol and latency. Useful for testing and sorting multiple V2Ray configs based on performance.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports &lt;code&gt;vmess&lt;/code&gt;, vless, and other V2Ray protocols&lt;/li&gt; 
 &lt;li&gt;Measures latency (ping) for each config&lt;/li&gt; 
 &lt;li&gt;Sorts or filters results based on protocol and responsiveness&lt;/li&gt; 
 &lt;li&gt;Simple, fast, and dependency-free (only requires Python)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.x (no external packages required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure Python 3 is installed on your system.&lt;/li&gt; 
 &lt;li&gt;Download the sub*.txt files from this repository (they contain lists of V2Ray subscription links).&lt;/li&gt; 
 &lt;li&gt;Run the script and provide the path to one or more sub*.txt files as arguments.&lt;/li&gt; 
 &lt;li&gt;The script will start scanning and show you the protocol and ping for each config.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Sample Output&lt;/p&gt; 
&lt;p&gt;[vmess] node1.example.com - 42 ms [vless] node2.example.net - timeout [shadowsocks] fastnode.org - 35 ms&lt;/p&gt; 
&lt;h2&gt;Tunnel entire system:&lt;/h2&gt; 
&lt;p&gt;For better use and tunneling the entire system, you can use a proxy program. The usage steps are as follows:&lt;/p&gt; 
&lt;h3&gt;Usage Instructions:&lt;/h3&gt; 
&lt;p&gt;1-First, install the Proxifier program.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://proxifier.com/download/"&gt;https://proxifier.com/download/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2-Activate the program:&lt;/p&gt; 
&lt;p&gt;Activation keys:&lt;/p&gt; 
&lt;p&gt;Portable Edition:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;L6Z8A-XY2J4-BTZ3P-ZZ7DF-A2Q9C
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Standard Edition:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  5EZ8G-C3WL5-B56YG-SCXM9-6QZAP
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Mac OS:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; P427L-9Y552-5433E-8DSR3-58Z68
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3-Go to the Profile section and select the Proxy Server. In the displayed section, click on Add.&lt;/p&gt; 
&lt;p&gt;4-Enter the following information:&lt;/p&gt; 
&lt;p&gt;IP: Enter 127.0.0.1&lt;/p&gt; 
&lt;p&gt;Port: Depending on the version you are using, enter:&lt;/p&gt; 
&lt;p&gt;V2rayN: 10808&lt;/p&gt; 
&lt;p&gt;Netch: 2801&lt;/p&gt; 
&lt;p&gt;SSR: 1080&lt;/p&gt; 
&lt;p&gt;Mac V2rayU: 1086&lt;/p&gt; 
&lt;p&gt;Protocol: Select SOCKS5&lt;/p&gt; 
&lt;p&gt;5-Enjoy!&lt;/p&gt; 
&lt;p&gt;Some installed programs on the system, like Spotube, might not fully tunnel. This issue can be resolved with this method.&lt;/p&gt; 
&lt;p&gt;Your friend, EPODONIOS&lt;/p&gt; 
&lt;h2&gt;u can use this feature with another way it no needs any program set by system tools&lt;/h2&gt; 
&lt;h3&gt;instruction:&lt;/h3&gt; 
&lt;p&gt;1- open your OS setting&lt;/p&gt; 
&lt;p&gt;2- go to proxy section&lt;/p&gt; 
&lt;p&gt;3- in proxy section set this values : ip : 127.0.0.1&lt;/p&gt; 
&lt;p&gt;port : 10809&lt;/p&gt; 
&lt;p&gt;local host :&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;localhost;127.*;10.*;172.16.*;172.17.*;172.18.*;172.19.*;172.20.*;172.21.*;172.22.*;172.23.*;172.24.*;172.25.*;172.26.*;172.27.*;172.28.*;172.29.*;172.30.*;172.31.*;192.168.*
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4- then set it up with ON key&lt;/p&gt; 
&lt;p&gt;5- back to v2rayn and after set your config turn it to set system proxy&lt;/p&gt; 
&lt;p&gt;6- now your system tunneled entirely&lt;/p&gt; 
&lt;p&gt;ur friend,EPODONIOS&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WECENG/ticket-purchase</title>
      <link>https://github.com/WECENG/ticket-purchase</link>
      <description>&lt;p&gt;大麦自动抢票，支持人员、城市、日期场次、价格选择&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;大麦抢票脚本 V1.0&lt;/h1&gt; 
&lt;h3&gt;特征&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;自动无延时抢票&lt;/li&gt; 
 &lt;li&gt;支持人员、城市、日期场次、价格选择&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;功能介绍&lt;/h2&gt; 
&lt;p&gt;通过selenium打开页面进行登录，模拟用户购票流程自动购票&lt;/p&gt; 
&lt;p&gt;其流程图如下:&lt;/p&gt; 
&lt;img src="img/大麦抢票流程.png" width="50%" height="50%" /&gt; 
&lt;h2&gt;准备工作&lt;/h2&gt; 
&lt;h3&gt;1. 配置环境&lt;/h3&gt; 
&lt;h4&gt;1.1安装python3环境&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;访问Python官方网站：&lt;a href="https://www.python.org/downloads/windows/"&gt;https://www.python.org/downloads/windows/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;下载最新的Python 3.9+版本的安装程序。&lt;/li&gt; 
 &lt;li&gt;运行安装程序。&lt;/li&gt; 
 &lt;li&gt;在安装程序中，确保勾选 "Add Python X.X to PATH" 选项，这将自动将Python添加到系统环境变量中，方便在命令行中使用Python。&lt;/li&gt; 
 &lt;li&gt;完成安装后，你可以在命令提示符或PowerShell中输入 &lt;code&gt;python3&lt;/code&gt; 来启动Python解释器。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;你可以使用Homebrew来安装Python 3。&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;安装Homebrew（如果未安装）：打开终端并运行以下命令：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;安装Python 3：运行以下命令来安装Python 3：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install python@3
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;1.2 安装所需要的环境&lt;/h4&gt; 
&lt;p&gt;在命令窗口输入如下指令&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install selenium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;1.3 下载google chrome浏览器&lt;/h4&gt; 
&lt;p&gt;下载地址: &lt;a href="https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds"&gt;https://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&amp;amp;gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&amp;amp;gclsrc=aw.ds&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. 修改配置文件&lt;/h3&gt; 
&lt;p&gt;在运行程序之前，需要先修改&lt;code&gt;config.json&lt;/code&gt;文件。该文件用于指定用户需要抢票的相关信息，包括演唱会的场次、观演的人员、城市、日期、价格等。文件结果如下图所示：&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/config_json.png" width="50%" height="50%" /&gt; 
&lt;h4&gt;2.1 文件内容说明&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;index_url&lt;/code&gt;为大麦网的地址，&lt;strong&gt;无需修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;login_url&lt;/code&gt;为大麦网的登录地址，&lt;strong&gt;无需修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;target_url&lt;/code&gt;为用户需要抢的演唱会票的目标地址，&lt;strong&gt;待修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;users&lt;/code&gt;为观演人的姓名，&lt;strong&gt;观演人需要用户在手机大麦APP中先填写好，然后再填入该配置文件中&lt;/strong&gt;，&lt;strong&gt;待修改&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;city&lt;/code&gt;为城市，&lt;strong&gt;如果用户需要抢的演唱会票需要选择城市，请把城市填入此处。如无需选择，则不填&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;date&lt;/code&gt;为场次日期，&lt;strong&gt;待修改，可多选&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;price&lt;/code&gt;为票档的价格，&lt;strong&gt;待修改，可多选&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;if_commit_order&lt;/code&gt;为是否要自动提交订单，&lt;strong&gt;改成 true&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;if_listen为是否回流监听，&lt;strong&gt;改成true&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2.2 示例说明&lt;/h4&gt; 
&lt;p&gt;进入大麦网&lt;a href="https://www.damai.cn/%EF%BC%8C%E9%80%89%E6%8B%A9%E4%BD%A0%E9%9C%80%E8%A6%81%E6%8A%A2%E7%A5%A8%E7%9A%84%E6%BC%94%E5%94%B1%E4%BC%9A%E3%80%82%E5%81%87%E8%AE%BE%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A"&gt;https://www.damai.cn/，选择你需要抢票的演唱会。假设如下图所示：&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example.png" width="50%" height="50%" /&gt; 
&lt;p&gt;接下来按照下图的标注对配置文件进行修改：&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/WECENG/ticket-purchase/master/img/example_detail.png" width="50%" height="50%" /&gt; 
&lt;p&gt;最终&lt;code&gt;config.json&lt;/code&gt;的文件内容如下：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "index_url": "https://www.damai.cn/",
  "login_url": "https://passport.damai.cn/login?ru=https%3A%2F%2Fwww.damai.cn%2F",
  "target_url": "https://detail.damai.cn/item.htm?spm=a2oeg.home.card_0.ditem_1.591b23e1JQGWHg&amp;amp;id=740680932762",
  "users": [
    "名字1",
    "名字2"
  ],
  "city": "广州",
  "date": "2023-10-28",
  "price": "1039",
  "if_listen":true,
  "if_commit_order": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3.运行程序&lt;/h3&gt; 
&lt;p&gt;运行程序开始抢票，进入命令窗口，执行如下命令：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd damai
python3 damai.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;大麦app抢票&lt;/h1&gt; 
&lt;p&gt;大麦app抢票脚本需要依赖appium，因此需要现在安装appium server&amp;amp;client环境，步骤如下：&lt;/p&gt; 
&lt;h2&gt;appium server&lt;/h2&gt; 
&lt;h3&gt;下载&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;先安装好node环境（具备npm）node版本号18.0.0&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;先下载并安装好android sdk，并配置环境变量（appium server运行需依赖android sdk)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;下载appium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g appium
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;查看appium是否安装成功&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;appium -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;下载UiAutomator2驱动&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;npm install appium-uiautomator2-driver
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;​ 可能会遇到如下错误：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;➜  xcode git:(master) ✗ npm install appium-uiautomator2-driver

npm ERR! code 1
npm ERR! path /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/appium-chromedriver
npm ERR! command failed
npm ERR! command sh -c node install-npm.js
npm ERR! [11:57:54] Error installing Chromedriver: Request failed with status code 404
npm ERR! [11:57:54] AxiosError: Request failed with status code 404
npm ERR!     at settle (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/core/settle.js:19:12)
npm ERR!     at IncomingMessage.handleStreamEnd (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/adapters/http.js:572:11)
npm ERR!     at IncomingMessage.emit (node:events:539:35)
npm ERR!     at endReadableNT (node:internal/streams/readable:1344:12)
npm ERR!     at processTicksAndRejections (node:internal/process/task_queues:82:21)
npm ERR! [11:57:54] Downloading Chromedriver can be skipped by setting the'APPIUM_SKIP_CHROMEDRIVER_INSTALL' environment variable.

npm ERR! A complete log of this run can be found in:
npm ERR!     /Users/chenweicheng/.npm/_logs/2023-10-26T03_57_35_950Z-debug-0.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;​ 解决办法（添加环境变量，错误原因是没有找到chrome浏览器驱动，忽略即可）&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export APPIUM_SKIP_CHROMEDRIVER_INSTALL=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;启动&lt;/h3&gt; 
&lt;p&gt;启动appium server并使用uiautomator2驱动&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;appium --use-plugins uiautomator2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动成功将出现如下信息：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[Appium] Welcome to Appium v2.2.1 (REV 2176894a5be5da17a362bf3f20678641a78f4b69)
[Appium] Non-default server args:
[Appium] {
[Appium]   usePlugins: [
[Appium]     'uiautomator2'
[Appium]   ]
[Appium] }
[Appium] Attempting to load driver uiautomator2...
[Appium] Requiring driver at /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver
[Appium] Appium REST http interface listener started on http://0.0.0.0:4723
[Appium] You can provide the following URLs in your client code to connect to this server:
[Appium] 	http://127.0.0.1:4723/ (only accessible from the same host)
[Appium] 	http://172.31.102.45:4723/
[Appium] 	http://198.18.0.1:4723/
[Appium] Available drivers:
[Appium]   - uiautomator2@2.32.3 (automationName 'UiAutomator2')
[Appium] No plugins have been installed. Use the "appium plugin" command to install the one(s) you want to use.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中&lt;code&gt;[Appium] http://127.0.0.1:4723/ (only accessible from the same host) [Appium] http://172.31.102.45:4723/ [Appium] http://198.18.0.1:4723/&lt;/code&gt;为appium server连接地址&lt;/p&gt; 
&lt;h2&gt;appium client&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;先下载并安装好python3和pip3&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;安装&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip3 install appium-python-client
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;在代码中引入并使用appium&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from appium import webdriver
from appium.options.common.base import AppiumOptions

device_app_info = AppiumOptions()
device_app_info.set_capability('platformName', 'Android')
device_app_info.set_capability('platformVersion', '10')
device_app_info.set_capability('deviceName', 'YourDeviceName')
device_app_info.set_capability('appPackage', 'cn.damai')
device_app_info.set_capability('appActivity', '.launcher.splash.SplashMainActivity')
device_app_info.set_capability('unicodeKeyboard', True)
device_app_info.set_capability('resetKeyboard', True)
device_app_info.set_capability('noReset', True)
device_app_info.set_capability('newCommandTimeout', 6000)
device_app_info.set_capability('automationName', 'UiAutomator2')

# 连接appium server，server地址查看appium启动信息
driver = webdriver.Remote('http://127.0.0.1:4723', options=device_app_info)

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;启动脚本程序&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cd damai_appium
python3 damai_appium.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>open-compass/VLMEvalKit</title>
      <link>https://github.com/open-compass/VLMEvalKit</link>
      <description>&lt;p&gt;Open-source evaluation toolkit of large multi-modality models (LMMs), support 220+ LMMs, 80+ benchmarks&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="http://opencompass.openxlab.space/utils/MMLB.jpg" alt="LOGO" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;b&gt;A Toolkit for Evaluating Large Vision-Language Models. &lt;/b&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/open-compass/VLMEvalKit/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/open-compass/VLMEvalKit?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; • &lt;a href="https://github.com/open-compass/VLMEvalKit/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/open-compass/VLMEvalKit?color=8ae8ff&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; • &lt;a href="https://github.com/open-compass/VLMEvalKit/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/open-compass/VLMEvalKit?color=ffcb47&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; • &lt;a href="https://github.com/open-compass/VLMEvalKit/issues"&gt;&lt;img src="https://img.shields.io/github/issues/open-compass/VLMEvalKit?color=ff80eb&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; • &lt;a href="https://github.com/open-compass/VLMEvalKit/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/open-compass/VLMEvalKit?color=white&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/zh-CN/README_zh-CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/ja/README_ja.md"&gt;日本語&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rank.opencompass.org.cn/leaderboard-multimodal"&gt;🏆 OC Learderboard &lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#%EF%B8%8F-quickstart"&gt;🏗️Quickstart &lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#-datasets-models-and-evaluation-results"&gt;📊Datasets &amp;amp; Models &lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#%EF%B8%8F-development-guide"&gt;🛠️Development &lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard"&gt;🤗 HF Leaderboard&lt;/a&gt; • &lt;a href="https://huggingface.co/datasets/VLMEval/OpenVLMRecords"&gt;🤗 Evaluation Records&lt;/a&gt; • &lt;a href="https://huggingface.co/spaces/opencompass/openvlm_video_leaderboard"&gt;🤗 HF Video Leaderboard&lt;/a&gt; •&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/evDT4GZmxN"&gt;🔊 Discord&lt;/a&gt; • &lt;a href="https://www.arxiv.org/abs/2407.11691"&gt;📝 Report&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#-the-goal-of-vlmevalkit"&gt;🎯Goal &lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#%EF%B8%8F-citation"&gt;🖊️Citation &lt;/a&gt;&lt;/p&gt;  
&lt;p&gt;&lt;strong&gt;VLMEvalKit&lt;/strong&gt; (the python package name is &lt;strong&gt;vlmeval&lt;/strong&gt;) is an &lt;strong&gt;open-source evaluation toolkit&lt;/strong&gt; of &lt;strong&gt;large vision-language models (LVLMs)&lt;/strong&gt;. It enables &lt;strong&gt;one-command evaluation&lt;/strong&gt; of LVLMs on various benchmarks, without the heavy workload of data preparation under multiple repositories. In VLMEvalKit, we adopt &lt;strong&gt;generation-based evaluation&lt;/strong&gt; for all LVLMs, and provide the evaluation results obtained with both &lt;strong&gt;exact matching&lt;/strong&gt; and &lt;strong&gt;LLM-based answer extraction&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Recent Codebase Changes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2025-09-12]&lt;/strong&gt; &lt;strong&gt;Major Update: Improved Handling for Models with Thinking Mode&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A new feature in &lt;a href="https://github.com/open-compass/VLMEvalKit/pull/1175"&gt;PR 1229&lt;/a&gt; that improves support for models with thinking mode. VLMEvalKit now allows for the use of a custom &lt;code&gt;split_thinking&lt;/code&gt; function. &lt;strong&gt;We strongly recommend this for models with thinking mode to ensure the accuracy of evaluation&lt;/strong&gt;. To use this new functionality, please enable the following settings: &lt;code&gt;SPLIT_THINK=True&lt;/code&gt;. By default, the function will parse content within &lt;code&gt;&amp;lt;think&amp;gt;...&amp;lt;/think&amp;gt;&lt;/code&gt; tags and store it in the &lt;code&gt;thinking&lt;/code&gt; key of the output. For more advanced customization, you can also create a &lt;code&gt;split_think&lt;/code&gt; function for model. Please see the InternVL implementation for an example.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2025-09-12]&lt;/strong&gt; &lt;strong&gt;Major Update: Improved Handling for Long Response(More than 16k/32k)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A new feature in &lt;a href="https://github.com/open-compass/VLMEvalKit/pull/1175"&gt;PR 1229&lt;/a&gt; that improves support for models with long response outputs. VLMEvalKit can now save prediction files in TSV format. &lt;strong&gt;Since individual cells in an &lt;code&gt;.xlsx&lt;/code&gt; file are limited to 32,767 characters, we strongly recommend using this feature for models that generate long responses (e.g., exceeding 16k or 32k tokens) to prevent data truncation.&lt;/strong&gt;. To use this new functionality, please enable the following settings: &lt;code&gt;PRED_FORMAT=tsv&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[2025-08-04]&lt;/strong&gt; In &lt;a href="https://github.com/open-compass/VLMEvalKit/pull/1175"&gt;PR 1175&lt;/a&gt;, we refine the &lt;code&gt;can_infer_option&lt;/code&gt; and &lt;code&gt;can_infer_text&lt;/code&gt;, which increasingly route the evaluation to LLM choice extractors and empirically leads to slight performance improvement for MCQ benchmarks.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🆕 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-07-07]&lt;/strong&gt; Supported &lt;a href="https://seephys.github.io/"&gt;&lt;strong&gt;SeePhys&lt;/strong&gt;&lt;/a&gt;, which is a ​full spectrum multimodal benchmark for evaluating physics reasoning across different knowledge levels. thanks to &lt;a href="https://github.com/Quinn777"&gt;&lt;strong&gt;Quinn777&lt;/strong&gt;&lt;/a&gt; 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-07-02]&lt;/strong&gt; Supported &lt;a href="https://huggingface.co/AIDC-AI/Ovis-U1-3B"&gt;&lt;strong&gt;OvisU1&lt;/strong&gt;&lt;/a&gt;, thanks to &lt;a href="https://github.com/liyang-7"&gt;&lt;strong&gt;liyang-7&lt;/strong&gt;&lt;/a&gt; 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-06-16]&lt;/strong&gt; Supported &lt;a href="https://phyx-bench.github.io/"&gt;&lt;strong&gt;PhyX&lt;/strong&gt;&lt;/a&gt;, a benchmark aiming to assess capacity for physics-grounded reasoning in visual scenarios. 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-05-24]&lt;/strong&gt; To facilitate faster evaluations for large-scale or thinking models, &lt;strong&gt;VLMEvalKit supports multi-node distributed inference&lt;/strong&gt; using &lt;strong&gt;LMDeploy&lt;/strong&gt; (supports &lt;em&gt;InternVL Series, QwenVL Series, LLaMa4&lt;/em&gt;) or &lt;strong&gt;VLLM&lt;/strong&gt;(supports &lt;em&gt;QwenVL Series, LLaMa4&lt;/em&gt;). You can activate this feature by adding the &lt;code&gt;use_lmdeploy&lt;/code&gt; or &lt;code&gt;use_vllm&lt;/code&gt; flag to your custom model configuration in &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/vlmeval/config.py"&gt;config.py&lt;/a&gt; . Leverage these tools to significantly speed up your evaluation workflows 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-05-24]&lt;/strong&gt; Supported Models: &lt;strong&gt;InternVL3 Series, Gemini-2.5-Pro, Kimi-VL, LLaMA4, NVILA, Qwen2.5-Omni, Phi4, SmolVLM2, Grok, SAIL-VL-1.5, WeThink-Qwen2.5VL-7B, Bailingmm, VLM-R1, Taichu-VLR&lt;/strong&gt;. Supported Benchmarks: &lt;strong&gt;HLE-Bench, MMVP, MM-AlignBench, Creation-MMBench, MM-IFEval, OmniDocBench, OCR-Reasoning, EMMA, ChaXiv，MedXpertQA, Physics, MSEarthMCQ, MicroBench, MMSci, VGRP-Bench, wildDoc, TDBench, VisuLogic, CVBench, LEGO-Puzzles, Video-MMLU, QBench-Video, MME-CoT, VLM2Bench, VMCBench, MOAT, Spatial457 Benchmark&lt;/strong&gt;. Please refer to &lt;a href="https://aicarrier.feishu.cn/wiki/Qp7wwSzQ9iK1Y6kNUJVcr6zTnPe?table=tblsdEpLieDoCxtb"&gt;&lt;strong&gt;VLMEvalKit Features&lt;/strong&gt;&lt;/a&gt; for more details. Thanks to all contributors 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-02-20]&lt;/strong&gt; Supported Models: &lt;strong&gt;InternVL2.5 Series, Qwen2.5VL Series, QVQ-72B, Doubao-VL, Janus-Pro-7B, MiniCPM-o-2.6, InternVL2-MPO, LLaVA-CoT, Hunyuan-Standard-Vision, Ovis2, Valley, SAIL-VL, Ross, Long-VITA, EMU3, SmolVLM&lt;/strong&gt;. Supported Benchmarks: &lt;strong&gt;MMMU-Pro, WeMath, 3DSRBench, LogicVista, VL-RewardBench, CC-OCR, CG-Bench, CMMMU, WorldSense&lt;/strong&gt;. Thanks to all contributors 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024-12-11]&lt;/strong&gt; Supported &lt;a href="https://huggingface.co/datasets/BaiqiL/NaturalBench"&gt;&lt;strong&gt;NaturalBench&lt;/strong&gt;&lt;/a&gt;, a vision-centric VQA benchmark (NeurIPS'24) that challenges vision-language models with simple questions about natural imagery.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024-12-02]&lt;/strong&gt; Supported &lt;a href="https://github.com/psunlpgroup/VisOnlyQA/"&gt;&lt;strong&gt;VisOnlyQA&lt;/strong&gt;&lt;/a&gt;, a benchmark for evaluating the visual perception capabilities 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024-11-26]&lt;/strong&gt; Supported &lt;a href="https://huggingface.co/AIDC-AI/Ovis1.6-Gemma2-27B"&gt;&lt;strong&gt;Ovis1.6-Gemma2-27B&lt;/strong&gt;&lt;/a&gt;, thanks to &lt;a href="https://github.com/runninglsy"&gt;&lt;strong&gt;runninglsy&lt;/strong&gt;&lt;/a&gt; 🔥🔥🔥&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024-11-25]&lt;/strong&gt; Create a new flag &lt;code&gt;VLMEVALKIT_USE_MODELSCOPE&lt;/code&gt;. By setting this environment variable, you can download the video benchmarks supported from &lt;a href="https://www.modelscope.cn"&gt;&lt;strong&gt;modelscope&lt;/strong&gt;&lt;/a&gt; 🔥🔥🔥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏗️ QuickStart&lt;/h2&gt; 
&lt;p&gt;See [&lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/en/Quickstart.md"&gt;QuickStart&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/zh-CN/Quickstart.md"&gt;快速开始&lt;/a&gt;] for a quick start guide.&lt;/p&gt; 
&lt;h2&gt;📊 Datasets, Models, and Evaluation Results&lt;/h2&gt; 
&lt;h3&gt;Evaluation Results&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The performance numbers on our official multi-modal leaderboards can be downloaded from here!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard"&gt;&lt;strong&gt;OpenVLM Leaderboard&lt;/strong&gt;&lt;/a&gt;: &lt;a href="http://opencompass.openxlab.space/assets/OpenVLM.json"&gt;&lt;strong&gt;Download All DETAILED Results&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Check &lt;strong&gt;Supported Benchmarks&lt;/strong&gt; Tab in &lt;a href="https://aicarrier.feishu.cn/wiki/Qp7wwSzQ9iK1Y6kNUJVcr6zTnPe?table=tblsdEpLieDoCxtb"&gt;&lt;strong&gt;VLMEvalKit Features&lt;/strong&gt;&lt;/a&gt; to view all supported image &amp;amp; video benchmarks (70+).&lt;/p&gt; 
&lt;p&gt;Check &lt;strong&gt;Supported LMMs&lt;/strong&gt; Tab in &lt;a href="https://aicarrier.feishu.cn/wiki/Qp7wwSzQ9iK1Y6kNUJVcr6zTnPe?table=tblsdEpLieDoCxtb"&gt;&lt;strong&gt;VLMEvalKit Features&lt;/strong&gt;&lt;/a&gt; to view all supported LMMs, including commercial APIs, open-source models, and more (200+).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Transformers Version Recommendation:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note that some VLMs may not be able to run under certain transformer versions, we recommend the following settings to evaluate each VLM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.33.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Qwen series&lt;/code&gt;, &lt;code&gt;Monkey series&lt;/code&gt;, &lt;code&gt;InternLM-XComposer Series&lt;/code&gt;, &lt;code&gt;mPLUG-Owl2&lt;/code&gt;, &lt;code&gt;OpenFlamingo v2&lt;/code&gt;, &lt;code&gt;IDEFICS series&lt;/code&gt;, &lt;code&gt;VisualGLM&lt;/code&gt;, &lt;code&gt;MMAlaya&lt;/code&gt;, &lt;code&gt;ShareCaptioner&lt;/code&gt;, &lt;code&gt;MiniGPT-4 series&lt;/code&gt;, &lt;code&gt;InstructBLIP series&lt;/code&gt;, &lt;code&gt;PandaGPT&lt;/code&gt;, &lt;code&gt;VXVERSE&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.36.2&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Moondream1&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.37.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;LLaVA series&lt;/code&gt;, &lt;code&gt;ShareGPT4V series&lt;/code&gt;, &lt;code&gt;TransCore-M&lt;/code&gt;, &lt;code&gt;LLaVA (XTuner)&lt;/code&gt;, &lt;code&gt;CogVLM Series&lt;/code&gt;, &lt;code&gt;EMU2 Series&lt;/code&gt;, &lt;code&gt;Yi-VL Series&lt;/code&gt;, &lt;code&gt;MiniCPM-[V1/V2]&lt;/code&gt;, &lt;code&gt;OmniLMM-12B&lt;/code&gt;, &lt;code&gt;DeepSeek-VL series&lt;/code&gt;, &lt;code&gt;InternVL series&lt;/code&gt;, &lt;code&gt;Cambrian Series&lt;/code&gt;, &lt;code&gt;VILA Series&lt;/code&gt;, &lt;code&gt;Llama-3-MixSenseV1_1&lt;/code&gt;, &lt;code&gt;Parrot-7B&lt;/code&gt;, &lt;code&gt;PLLaVA Series&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.40.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;IDEFICS2&lt;/code&gt;, &lt;code&gt;Bunny-Llama3&lt;/code&gt;, &lt;code&gt;MiniCPM-Llama3-V2.5&lt;/code&gt;, &lt;code&gt;360VL-70B&lt;/code&gt;, &lt;code&gt;Phi-3-Vision&lt;/code&gt;, &lt;code&gt;WeMM&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.42.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;AKI&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.44.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Moondream2&lt;/code&gt;, &lt;code&gt;H2OVL series&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==4.45.0&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Aria&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;transformers==latest&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;LLaVA-Next series&lt;/code&gt;, &lt;code&gt;PaliGemma-3B&lt;/code&gt;, &lt;code&gt;Chameleon series&lt;/code&gt;, &lt;code&gt;Video-LLaVA-7B-HF&lt;/code&gt;, &lt;code&gt;Ovis series&lt;/code&gt;, &lt;code&gt;Mantis series&lt;/code&gt;, &lt;code&gt;MiniCPM-V2.6&lt;/code&gt;, &lt;code&gt;OmChat-v2.0-13B-sinlge-beta&lt;/code&gt;, &lt;code&gt;Idefics-3&lt;/code&gt;, &lt;code&gt;GLM-4v-9B&lt;/code&gt;, &lt;code&gt;VideoChat2-HD&lt;/code&gt;, &lt;code&gt;RBDash_72b&lt;/code&gt;, &lt;code&gt;Llama-3.2 series&lt;/code&gt;, &lt;code&gt;Kosmos series&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Torchvision Version Recommendation:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note that some VLMs may not be able to run under certain torchvision versions, we recommend the following settings to evaluate each VLM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;torchvision&amp;gt;=0.16&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Moondream series&lt;/code&gt; and &lt;code&gt;Aria&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Flash-attn Version Recommendation:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note that some VLMs may not be able to run under certain flash-attention versions, we recommend the following settings to evaluate each VLM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Please use&lt;/strong&gt; &lt;code&gt;pip install flash-attn --no-build-isolation&lt;/code&gt; &lt;strong&gt;for&lt;/strong&gt;: &lt;code&gt;Aria&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Demo
from vlmeval.config import supported_VLM
model = supported_VLM['idefics_9b_instruct']()
# Forward Single Image
ret = model.generate(['assets/apple.jpg', 'What is in this image?'])
print(ret)  # The image features a red apple with a leaf on it.
# Forward Multiple Images
ret = model.generate(['assets/apple.jpg', 'assets/apple.jpg', 'How many apples are there in the provided images? '])
print(ret)  # There are two apples in the provided images.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🛠️ Development Guide&lt;/h2&gt; 
&lt;p&gt;To develop custom benchmarks, VLMs, or simply contribute other codes to &lt;strong&gt;VLMEvalKit&lt;/strong&gt;, please refer to [&lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/en/Development.md"&gt;Development_Guide&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/zh-CN/Development.md"&gt;开发指南&lt;/a&gt;].&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Call for contributions&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To promote the contribution from the community and share the corresponding credit (in the next report update):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All Contributions will be acknowledged in the report.&lt;/li&gt; 
 &lt;li&gt;Contributors with 3 or more major contributions (implementing an MLLM, benchmark, or major feature) can join the author list of &lt;a href="https://www.arxiv.org/abs/2407.11691"&gt;VLMEvalKit Technical Report&lt;/a&gt; on ArXiv. Eligible contributors can create an issue or dm kennyutc in &lt;a href="https://discord.com/invite/evDT4GZmxN"&gt;VLMEvalKit Discord Channel&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here is a &lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/docs/en/Contributors.md"&gt;contributor list&lt;/a&gt; we curated based on the records.&lt;/p&gt; 
&lt;h2&gt;🎯 The Goal of VLMEvalKit&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;The codebase is designed to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Provide an &lt;strong&gt;easy-to-use&lt;/strong&gt;, &lt;strong&gt;opensource evaluation toolkit&lt;/strong&gt; to make it convenient for researchers &amp;amp; developers to evaluate existing LVLMs and make evaluation results &lt;strong&gt;easy to reproduce&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Make it easy for VLM developers to evaluate their own models. To evaluate the VLM on multiple supported benchmarks, one just need to &lt;strong&gt;implement a single &lt;code&gt;generate_inner()&lt;/code&gt; function&lt;/strong&gt;, all other workloads (data downloading, data preprocessing, prediction inference, metric calculation) are handled by the codebase.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;The codebase is not designed to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Reproduce the exact accuracy number reported in the original papers of all &lt;strong&gt;3rd party benchmarks&lt;/strong&gt;. The reason can be two-fold: 
  &lt;ol&gt; 
   &lt;li&gt;VLMEvalKit uses &lt;strong&gt;generation-based evaluation&lt;/strong&gt; for all VLMs (and optionally with &lt;strong&gt;LLM-based answer extraction&lt;/strong&gt;). Meanwhile, some benchmarks may use different approaches (SEEDBench uses PPL-based evaluation, &lt;em&gt;eg.&lt;/em&gt;). For those benchmarks, we compare both scores in the corresponding result. We encourage developers to support other evaluation paradigms in the codebase.&lt;/li&gt; 
   &lt;li&gt;By default, we use the same prompt template for all VLMs to evaluate on a benchmark. Meanwhile, &lt;strong&gt;some VLMs may have their specific prompt templates&lt;/strong&gt; (some may not covered by the codebase at this time). We encourage VLM developers to implement their own prompt template in VLMEvalKit, if that is not covered currently. That will help to improve the reproducibility.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🖊️ Citation&lt;/h2&gt; 
&lt;p&gt;If you find this work helpful, please consider to &lt;strong&gt;star🌟&lt;/strong&gt; this repo. Thanks for your support!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/open-compass/VLMEvalKit/stargazers"&gt;&lt;img src="https://reporoster.com/stars/open-compass/VLMEvalKit" alt="Stargazers repo roster for @open-compass/VLMEvalKit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you use VLMEvalKit in your research or wish to refer to published OpenSource evaluation results, please use the following BibTeX entry and the BibTex entry corresponding to the specific VLM / benchmark you used.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bib"&gt;@inproceedings{duan2024vlmevalkit,
  title={Vlmevalkit: An open-source toolkit for evaluating large multi-modality models},
  author={Duan, Haodong and Yang, Junming and Qiao, Yuxuan and Fang, Xinyu and Chen, Lin and Liu, Yuan and Dong, Xiaoyi and Zang, Yuhang and Zhang, Pan and Wang, Jiaqi and others},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={11198--11201},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="right"&gt;&lt;a href="https://raw.githubusercontent.com/open-compass/VLMEvalKit/main/#top"&gt;🔝Back to top&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LuckyOne7777/ChatGPT-Micro-Cap-Experiment</title>
      <link>https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment</link>
      <description>&lt;p&gt;This repo powers my blog experiment where ChatGPT manages a real-money micro-cap stock portfolio.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatGPT Micro-Cap Experiment&lt;/h1&gt; 
&lt;p&gt;Welcome to the repo behind my 6-month live trading experiment where ChatGPT manages a real-money micro-cap portfolio.&lt;/p&gt; 
&lt;h2&gt;Overview on getting started: &lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Start%20Your%20Own/README.md"&gt;Here&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;trading_script.py&lt;/code&gt;&lt;/strong&gt; - Main trading engine with portfolio management and stop-loss automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Scripts and CSV Files/&lt;/code&gt;&lt;/strong&gt; - My personal portfolio (updates every trading day)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Start Your Own/&lt;/code&gt;&lt;/strong&gt; - Template files and guide for starting your own experiment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Weekly Deep Research (MD|PDF)/&lt;/code&gt;&lt;/strong&gt; - Research summaries and performance reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Experiment Details/&lt;/code&gt;&lt;/strong&gt; - Documentation, methodology, prompts, and Q&amp;amp;A&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;The Concept&lt;/h1&gt; 
&lt;p&gt;Every day, I kept seeing the same ad about having some A.I. pick undervalued stocks. It was obvious it was trying to get me to subscribe to some garbage, so I just rolled my eyes.&lt;br /&gt; Then I started wondering, "How well would that actually work?"&lt;/p&gt; 
&lt;p&gt;So, starting with just $100, I wanted to answer a simple but powerful question:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Can powerful large language models like ChatGPT actually generate alpha (or at least make smart trading decisions) using real-time data?&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Each trading day:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;I provide it trading data on the stocks in its portfolio.&lt;/li&gt; 
 &lt;li&gt;Strict stop-loss rules apply.&lt;/li&gt; 
 &lt;li&gt;Every week I allow it to use deep research to reevaluate its account.&lt;/li&gt; 
 &lt;li&gt;I track and publish performance data weekly on my blog: &lt;a href="https://nathanbsmith729.substack.com"&gt;Here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Research &amp;amp; Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Experiment%20Details/Deep%20Research%20Index.md"&gt;Research Index&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Experiment%20Details/Disclaimer.md"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Experiment%20Details/Q%26A.md"&gt;Q&amp;amp;A&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Experiment%20Details/Prompts.md"&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Start%20Your%20Own/README.md"&gt;Starting Your Own&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/tree/main/Weekly%20Deep%20Research%20(MD)"&gt;Research Summaries (MD)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/tree/main/Weekly%20Deep%20Research%20(PDF)"&gt;Full Deep Research Reports (PDF)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Experiment%20Details/Chats.md"&gt;Chats&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Current Performance&lt;/h1&gt; 
&lt;!-- To update performance chart: 
     1. Replace the image file with updated results
     2. Update the dates and description below
     3. Update the "Last Updated" date --&gt; 
&lt;p&gt;&lt;strong&gt;Current Portfolio Results&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/main/Results.png" alt="Latest Performance Results" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Current Status:&lt;/strong&gt; Portfolio is underperforming the S&amp;amp;P 500 benchmark&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Performance data is updated after each trading day. See the CSV files in &lt;code&gt;Scripts and CSV Files/&lt;/code&gt; for detailed daily tracking.&lt;/em&gt;&lt;/p&gt; 
&lt;h1&gt;Features of This Repo&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Live trading scripts — used to evaluate prices and update holdings daily&lt;/li&gt; 
 &lt;li&gt;LLM-powered decision engine — ChatGPT picks the trades&lt;/li&gt; 
 &lt;li&gt;Performance tracking — CSVs with daily PnL, total equity, and trade history&lt;/li&gt; 
 &lt;li&gt;Visualization tools — Matplotlib graphs comparing ChatGPT vs. Index&lt;/li&gt; 
 &lt;li&gt;Logs &amp;amp; trade data — auto-saved logs for transparency&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Want to Contribute?&lt;/h2&gt; 
&lt;p&gt;Contributions are very welcome! This project is community-oriented, and your help is invaluable.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues:&lt;/strong&gt; If you notice a bug or have an idea for improvement, please.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pull Requests:&lt;/strong&gt; Feel free to submit a PR — I usually review within a few days.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaboration:&lt;/strong&gt; High-value contributors may be invited as maintainers/admins to help shape the project’s future.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Whether it’s fixing a typo, adding features, or discussing new ideas, all contributions are appreciated!&lt;/p&gt; 
&lt;p&gt;For more information, check out: &lt;a href="https://github.com/LuckyOne7777/ChatGPT-Micro-Cap-Experiment/raw/main/Other/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Why This Matters&lt;/h1&gt; 
&lt;p&gt;AI is being hyped across every industry, but can it really manage money without guidance?&lt;/p&gt; 
&lt;p&gt;This project is an attempt to find out — with transparency, data, and a real budget.&lt;/p&gt; 
&lt;h1&gt;Tech Stack &amp;amp; Features&lt;/h1&gt; 
&lt;h2&gt;Core Technologies&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; - Core scripting and automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;pandas + yFinance&lt;/strong&gt; - Market data fetching and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Matplotlib&lt;/strong&gt; - Performance visualization and charting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ChatGPT-5&lt;/strong&gt; - AI-powered trading decision engine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Robust Data Sources&lt;/strong&gt; - Yahoo Finance primary, Stooq fallback for reliability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Stop-Loss&lt;/strong&gt; - Automatic position management with configurable stop-losses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Trading&lt;/strong&gt; - Market-on-Open (MOO) and limit order support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting Support&lt;/strong&gt; - ASOF_DATE override for historical analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Analytics&lt;/strong&gt; - CAPM analysis, Sharpe/Sortino ratios, drawdown metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trade Logging&lt;/strong&gt; - Complete transparency with detailed execution logs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11+&lt;/li&gt; 
 &lt;li&gt;Internet connection for market data&lt;/li&gt; 
 &lt;li&gt;~10MB storage for CSV data files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Follow Along&lt;/h1&gt; 
&lt;p&gt;The experiment runs from June 2025 to December 2025.&lt;br /&gt; Every trading day I will update the portfolio CSV file.&lt;br /&gt; If you feel inspired to do something similar, feel free to use this as a blueprint.&lt;/p&gt; 
&lt;p&gt;Updates are posted weekly on my blog, more coming soon!&lt;/p&gt; 
&lt;p&gt;Blog: &lt;a href="https://nathanbsmith729.substack.com"&gt;A.I Controls Stock Account&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Have feature requests or any advice?&lt;/p&gt; 
&lt;p&gt;Please reach out here: &lt;strong&gt;&lt;a href="mailto:nathanbsmith.business@gmail.com"&gt;nathanbsmith.business@gmail.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>browser-use/browser-use</title>
      <link>https://github.com/browser-use/browser-use</link>
      <description>&lt;p&gt;🌐 Make websites accessible for AI agents. Automate tasks online with ease.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./static/browser-use-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="./static/browser-use.png" /&gt; 
 &lt;img alt="Shows a black Browser Use Logo in light color mode and a white one in dark color mode." src="https://raw.githubusercontent.com/browser-use/browser-use/main/static/browser-use.png" width="full" /&gt; 
&lt;/picture&gt; 
&lt;h1 align="center"&gt;Enable AI to control your browser&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.browser-use.com"&gt;&lt;img src="https://img.shields.io/badge/Docs-%F0%9F%93%95-blue?style=for-the-badge" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://cloud.browser-use.com"&gt;&lt;img src="https://img.shields.io/badge/Browser_Use_Cloud-%E2%98%81%EF%B8%8F-blue?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Browser-use cloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://link.browser-use.com/discord"&gt;&lt;img src="https://img.shields.io/discord/1303749220842340412?color=7289DA&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/intent/user?screen_name=gregpr07"&gt;&lt;img src="https://img.shields.io/twitter/follow/Gregor?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://x.com/intent/user?screen_name=mamagnus00"&gt;&lt;img src="https://img.shields.io/twitter/follow/Magnus?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://browsermerch.com"&gt;&lt;img src="https://img.shields.io/badge/Merch_store-%F0%9F%91%95-blue" alt="Merch store" /&gt;&lt;/a&gt; &lt;a href="https://app.workweave.ai/reports/repository/org_T5Pvn3UBswTHIsN1dWS3voPg/881458615"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_T5Pvn3UBswTHIsN1dWS3voPg%2F881458615&amp;amp;labelColor=#EC6341" alt="Weave Badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
&lt;p&gt;&lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=ru"&gt;Русский&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/browser-use/browser-use?lang=zh"&gt;中文&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;🤖 Quickstart&lt;/h1&gt; 
&lt;p&gt;With uv (Python&amp;gt;=3.11):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;#  We ship every day - use the latest version!
uv pip install browser-use
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download chromium using playwright's shortcut:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx playwright install chromium --with-deps --no-shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Get your API key from &lt;a href="https://cloud.browser-use.com/dashboard/api"&gt;Browser Use Cloud&lt;/a&gt; and add it to your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;BROWSER_USE_API_KEY=your-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run your first agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from browser_use import Agent, ChatBrowserUse

agent = Agent(
    task="Find the number of stars of the browser-use repo",
    llm=ChatBrowserUse(),
)
agent.run_sync()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://docs.browser-use.com"&gt;library docs&lt;/a&gt; and &lt;a href="https://docs.cloud.browser-use.com"&gt;cloud docs&lt;/a&gt; for more settings.&lt;/p&gt; 
&lt;h2&gt;Stealth Browser Infrastructure&lt;/h2&gt; 
&lt;p&gt;Want to bypass Cloudflare, or any other anti-bot protection?&lt;/p&gt; 
&lt;p&gt;Simply go to &lt;a href="https://docs.cloud.browser-use.com"&gt;Browser Use Cloud&lt;/a&gt; grab a &lt;code&gt;BROWSER_USE_API_KEY&lt;/code&gt; and use the &lt;code&gt;use_cloud&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from browser_use import Agent, Browser
from browser_use import ChatBrowserUse

# Use Browser-Use cloud browser service
browser = Browser(
    use_cloud=True,  # Automatically provisions a cloud browser
)

agent = Agent(
    task="Your task here",
    llm=ChatBrowserUse(),
    browser=browser,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Demos&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/use-cases/shopping.py"&gt;Task&lt;/a&gt;: Add grocery items to cart, and checkout.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=L2Ya9PYNns8"&gt;&lt;img src="https://github.com/user-attachments/assets/a0ffd23d-9a11-4368-8893-b092703abc14" alt="AI Did My Groceries" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/use-cases/find_and_apply_to_jobs.py"&gt;Task&lt;/a&gt;: Read my CV &amp;amp; find ML jobs, save them to a file, and then start applying for them in new tabs, if you need help, ask me.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04"&gt;https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://docs.browser-use.com/examples"&gt;more examples&lt;/a&gt; and give us a star!&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;MCP Integration&lt;/h2&gt; 
&lt;p&gt;This gives Claude Desktop access to browser automation tools for web scraping, form filling, and more. See the &lt;a href="https://docs.browser-use.com/customize/mcp-server"&gt;MCP docs&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "browser-use": {
      "command": "uvx",
      "args": ["browser-use[cli]", "--mcp"],
      "env": {
        "OPENAI_API_KEY": "sk-..."
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Tell your computer what to do, and it gets it done.&lt;/strong&gt;&lt;/p&gt; 
 &lt;img src="https://github.com/user-attachments/assets/06fa3078-8461-4560-b434-445510c1766f" width="400" /&gt; 
 &lt;p&gt;&lt;a href="https://x.com/intent/user?screen_name=mamagnus00"&gt;&lt;img src="https://img.shields.io/twitter/follow/Magnus?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://x.com/intent/user?screen_name=gregpr07"&gt;&lt;img src="https://img.shields.io/twitter/follow/Gregor?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt;
  Made with ❤️ in Zurich and San Francisco 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>huggingface/diffusers</title>
      <link>https://github.com/huggingface/diffusers</link>
      <description>&lt;p&gt;🤗 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/en/imgs/diffusers_library.jpg" width="400" /&gt; &lt;br /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://github.com/huggingface/diffusers/raw/main/LICENSE"&gt;&lt;img alt="GitHub" src="https://img.shields.io/github/license/huggingface/datasets.svg?color=blue" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/diffusers/releases"&gt;&lt;img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/diffusers.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/diffusers"&gt;&lt;img alt="GitHub release" src="https://static.pepy.tech/badge/diffusers/month" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/huggingface/diffusers/main/CODE_OF_CONDUCT.md"&gt;&lt;img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/diffuserslib"&gt;&lt;img alt="X account" src="https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;amp;label=Follow%20%40diffuserslib" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;🤗 Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you're looking for a simple inference solution or training your own diffusion models, 🤗 Diffusers is a modular toolbox that supports both. Our library is designed with a focus on &lt;a href="https://huggingface.co/docs/diffusers/conceptual/philosophy#usability-over-performance"&gt;usability over performance&lt;/a&gt;, &lt;a href="https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy"&gt;simple over easy&lt;/a&gt;, and &lt;a href="https://huggingface.co/docs/diffusers/conceptual/philosophy#tweakable-contributorfriendly-over-abstraction"&gt;customizability over abstractions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;🤗 Diffusers offers three core components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art &lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/overview"&gt;diffusion pipelines&lt;/a&gt; that can be run in inference with just a few lines of code.&lt;/li&gt; 
 &lt;li&gt;Interchangeable noise &lt;a href="https://huggingface.co/docs/diffusers/api/schedulers/overview"&gt;schedulers&lt;/a&gt; for different diffusion speeds and output quality.&lt;/li&gt; 
 &lt;li&gt;Pretrained &lt;a href="https://huggingface.co/docs/diffusers/api/models/overview"&gt;models&lt;/a&gt; that can be used as building blocks, and combined with schedulers, for creating your own end-to-end diffusion systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend installing 🤗 Diffusers in a virtual environment from PyPI or Conda. For more details about installing &lt;a href="https://pytorch.org/get-started/locally/"&gt;PyTorch&lt;/a&gt;, please refer to their official documentation.&lt;/p&gt; 
&lt;h3&gt;PyTorch&lt;/h3&gt; 
&lt;p&gt;With &lt;code&gt;pip&lt;/code&gt; (official package):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade diffusers[torch]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With &lt;code&gt;conda&lt;/code&gt; (maintained by the community):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge diffusers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Apple Silicon (M1/M2) support&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://huggingface.co/docs/diffusers/optimization/mps"&gt;How to use Stable Diffusion in Apple Silicon&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Generating outputs is super easy with 🤗 Diffusers. To generate an image from text, use the &lt;code&gt;from_pretrained&lt;/code&gt; method to load any pretrained diffusion model (browse the &lt;a href="https://huggingface.co/models?library=diffusers&amp;amp;sort=downloads"&gt;Hub&lt;/a&gt; for 30,000+ checkpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained("stable-diffusion-v1-5/stable-diffusion-v1-5", torch_dtype=torch.float16)
pipeline.to("cuda")
pipeline("An image of a squirrel in Picasso style").images[0]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also dig into the models and schedulers toolbox to build your own diffusion system:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from diffusers import DDPMScheduler, UNet2DModel
from PIL import Image
import torch

scheduler = DDPMScheduler.from_pretrained("google/ddpm-cat-256")
model = UNet2DModel.from_pretrained("google/ddpm-cat-256").to("cuda")
scheduler.set_timesteps(50)

sample_size = model.config.sample_size
noise = torch.randn((1, 3, sample_size, sample_size), device="cuda")
input = noise

for t in scheduler.timesteps:
    with torch.no_grad():
        noisy_residual = model(input, t).sample
        prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample
        input = prev_noisy_sample

image = (input / 2 + 0.5).clamp(0, 1)
image = image.cpu().permute(0, 2, 3, 1).numpy()[0]
image = Image.fromarray((image * 255).round().astype("uint8"))
image
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://huggingface.co/docs/diffusers/quicktour"&gt;Quickstart&lt;/a&gt; to launch your diffusion journey today!&lt;/p&gt; 
&lt;h2&gt;How to navigate the documentation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;What can I learn?&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/tutorials/tutorial_overview"&gt;Tutorial&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A basic crash course for learning how to use the library's most important features like using models and schedulers to build your own diffusion system, and training your own diffusion model.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/using-diffusers/loading"&gt;Loading&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Guides for how to load and configure all the components (pipelines, models, and schedulers) of the library, as well as how to use different schedulers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/using-diffusers/overview_techniques"&gt;Pipelines for inference&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Guides for how to use pipelines for different inference tasks, batched generation, controlling generated outputs and randomness, and how to contribute a pipeline to the library.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/optimization/fp16"&gt;Optimization&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Guides for how to optimize your diffusion model to run faster and consume less memory.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/training/overview"&gt;Training&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Guides for how to train a diffusion model for different tasks with different training techniques.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;We ❤️ contributions from the open-source community! If you want to contribute to this library, please check out our &lt;a href="https://github.com/huggingface/diffusers/raw/main/CONTRIBUTING.md"&gt;Contribution guide&lt;/a&gt;. You can look out for &lt;a href="https://github.com/huggingface/diffusers/issues"&gt;issues&lt;/a&gt; you'd like to tackle to contribute to the library.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;Good first issues&lt;/a&gt; for general opportunities to contribute&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22"&gt;New model/pipeline&lt;/a&gt; to contribute exciting new diffusion models / diffusion pipelines&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22"&gt;New scheduler&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, say 👋 in our public Discord channel &lt;a href="https://discord.gg/G7tWnz98XR"&gt;&lt;img alt="Join us on Discord" src="https://img.shields.io/discord/823813159592001537?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt;. We discuss the hottest trends about diffusion models, help each other with contributions, personal projects or just hang out ☕.&lt;/p&gt; 
&lt;h2&gt;Popular Tasks &amp;amp; Pipelines&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Pipeline&lt;/th&gt; 
   &lt;th&gt;🤗 Hub&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Unconditional Image Generation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/ddpm"&gt; DDPM &lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google/ddpm-ema-church-256"&gt; google/ddpm-ema-church-256 &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Text-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img"&gt;Stable Diffusion Text-to-Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5"&gt; stable-diffusion-v1-5/stable-diffusion-v1-5 &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/unclip"&gt;unCLIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/kakaobrain/karlo-v1-alpha"&gt; kakaobrain/karlo-v1-alpha &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if"&gt;DeepFloyd IF&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/DeepFloyd/IF-I-XL-v1.0"&gt; DeepFloyd/IF-I-XL-v1.0 &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/kandinsky"&gt;Kandinsky&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder"&gt; kandinsky-community/kandinsky-2-2-decoder &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Text-guided Image-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/controlnet"&gt;ControlNet&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/lllyasviel/sd-controlnet-canny"&gt; lllyasviel/sd-controlnet-canny &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text-guided Image-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/pix2pix"&gt;InstructPix2Pix&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/timbrooks/instruct-pix2pix"&gt; timbrooks/instruct-pix2pix &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text-guided Image-to-Image&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img"&gt;Stable Diffusion Image-to-Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5"&gt; stable-diffusion-v1-5/stable-diffusion-v1-5 &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Text-guided Image Inpainting&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint"&gt;Stable Diffusion Inpainting&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/runwayml/stable-diffusion-inpainting"&gt; runwayml/stable-diffusion-inpainting &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Image Variation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation"&gt;Stable Diffusion Image Variation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/lambdalabs/sd-image-variations-diffusers"&gt; lambdalabs/sd-image-variations-diffusers &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr style="border-top: 2px solid black"&gt; 
   &lt;td&gt;Super Resolution&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/upscale"&gt;Stable Diffusion Upscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler"&gt; stabilityai/stable-diffusion-x4-upscaler &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Super Resolution&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale"&gt;Stable Diffusion Latent Upscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/stabilityai/sd-x2-latent-upscaler"&gt; stabilityai/sd-x2-latent-upscaler &lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Popular libraries using 🧨 Diffusers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/TaskMatrix"&gt;https://github.com/microsoft/TaskMatrix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/invoke-ai/InvokeAI"&gt;https://github.com/invoke-ai/InvokeAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InstantID/InstantID"&gt;https://github.com/InstantID/InstantID&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apple/ml-stable-diffusion"&gt;https://github.com/apple/ml-stable-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Sanster/lama-cleaner"&gt;https://github.com/Sanster/lama-cleaner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/IDEA-Research/Grounded-Segment-Anything"&gt;https://github.com/IDEA-Research/Grounded-Segment-Anything&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ashawkey/stable-dreamfusion"&gt;https://github.com/ashawkey/stable-dreamfusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deep-floyd/IF"&gt;https://github.com/deep-floyd/IF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bentoml/BentoML"&gt;https://github.com/bentoml/BentoML&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bmaltais/kohya_ss"&gt;https://github.com/bmaltais/kohya_ss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;+14,000 other amazing GitHub repositories 💪&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you for using us ❤️.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;This library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;@CompVis' latent diffusion models library, available &lt;a href="https://github.com/CompVis/latent-diffusion"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@hojonathanho original DDPM implementation, available &lt;a href="https://github.com/hojonathanho/diffusion"&gt;here&lt;/a&gt; as well as the extremely useful translation into PyTorch by @pesser, available &lt;a href="https://github.com/pesser/pytorch_diffusion"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@ermongroup's DDIM implementation, available &lt;a href="https://github.com/ermongroup/ddim"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@yang-song's Score-VE and Score-VP implementations, available &lt;a href="https://github.com/yang-song/score_sde_pytorch"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available &lt;a href="https://github.com/heejkoo/Awesome-Diffusion-Models"&gt;here&lt;/a&gt; as well as @crowsonkb and @rromb for useful discussions and insights.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{von-platen-etal-2022-diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Dhruv Nair and Sayak Paul and William Berman and Yiyi Xu and Steven Liu and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.getzep.com/"&gt; &lt;img src="https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73" width="150" alt="Zep Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align="center"&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/getzep/Graphiti/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat" alt="Lint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true" alt="MyPy Check" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/getzep/graphiti" alt="GitHub Repo stars" /&gt; &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/graphiti/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12986" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12986" alt="getzep%2Fgraphiti | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif" alt="Graphiti temporal walkthrough" width="700px" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;"Kendra loves Adidas shoes."&lt;/em&gt; Each fact is a "triplet" represented by two entities, or nodes ("Kendra", "Adidas shoes"), and their relationship, or edge ("loves"). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep's Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href="https://www.getzep.com"&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we've demonstrated Zep is the &lt;a href="https://blog.getzep.com/state-of-the-art-agent-memory/"&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href="https://arxiv.org/abs/2501.13956"&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We're excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png" alt="Zep: A Temporal Knowledge Graph Architecture for Agent Memory" width="700px" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif" alt="Graphiti structured + unstructured demo" width="700px" /&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 / Kuzu 0.11.2 / Amazon Neptune Database Cluster or Neptune Analytics Graph + Amazon OpenSearch Serverless collection (serves as the full text search backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href="https://neo4j.com/download/"&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with Kuzu Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use Kuzu as your graph database backend, install with the Kuzu extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[kuzu]

# or with uv
uv add graphiti-core[kuzu]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with Amazon Neptune Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use Amazon Neptune as your graph database backend, install with the Amazon Neptune extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[neptune]

# or with uv
uv add graphiti-core[neptune]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]

# Install with Amazon Neptune
pip install graphiti-core[neptune]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti's ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md"&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j, Amazon Neptune, FalkorDB, or Kuzu database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti's knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md"&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="my_custom_database"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host="localhost",
    port=6379,
    username="falkor_user",  # Optional
    password="falkor_password",  # Optional
    database="my_custom_graph"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Kuzu&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.kuzu_driver import KuzuDriver

# Create a Kuzu driver
driver = KuzuDriver(db="/tmp/graphiti.kuzu")

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Amazon Neptune&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neptune_driver import NeptuneDriver

# Create a FalkorDB driver with custom database name
driver = NeptuneDriver(
    host= &amp;lt; NEPTUNE
ENDPOINT &amp;gt;,
aoss_host = &amp;lt; Amazon
OpenSearch
Serverless
Host &amp;gt;,
port = &amp;lt; PORT &amp;gt;  # Optional, defaults to 8182,
         aoss_port = &amp;lt; PORT &amp;gt;  # Optional, defaults to 443
)

driver = NeptuneDriver(host=neptune_uri, aoss_host=aoss_host, port=neptune_port)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Azure OpenAI v1 API Opt-in Required for Structured Outputs&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Graphiti uses structured outputs via the &lt;code&gt;client.beta.chat.completions.parse()&lt;/code&gt; method, which requires Azure OpenAI deployments to opt into the v1 API. Without this opt-in, you'll encounter 404 Resource not found errors during episode ingestion.&lt;/p&gt; 
 &lt;p&gt;To enable v1 API support in your Azure OpenAI deployment, follow Microsoft's guide: &lt;a href="https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle?tabs=key#api-evolution"&gt;Azure OpenAI API version lifecycle&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = "&amp;lt;your-api-key&amp;gt;"
api_version = "&amp;lt;your-api-version&amp;gt;"
llm_endpoint = "&amp;lt;your-llm-endpoint&amp;gt;"  # e.g., "https://your-llm-resource.openai.azure.com/"
embedding_endpoint = "&amp;lt;your-embedding-endpoint&amp;gt;"  # e.g., "https://your-embedding-resource.openai.azure.com/"

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model="gpt-4.1-nano",
    model="gpt-4.1-mini",
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=OpenAIClient(
        config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model="text-embedding-3-small-deployment"  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google's Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you'll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add "graphiti-core[google-genai]"

# or

pip install "graphiti-core[google-genai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = "&amp;lt;your-google-api-key&amp;gt;"

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.0-flash"
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model="embedding-001"
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.5-flash-lite-preview-06-17"
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini's log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama's OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama pull deepseek-r1:7b # LLM
ollama pull nomic-embed-text # embeddings
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key="ollama",  # Ollama doesn't require a real API key, but some placeholder is needed
    model="deepseek-r1:7b",
    small_model="deepseek-r1:7b",
    base_url="http://localhost:11434/v1",  # Ollama's OpenAI-compatible endpoint
)

llm_client = OpenAIGenericClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key="ollama",  # Placeholder API key
            embedding_model="nomic-embed-text",
            embedding_dim=768,
            base_url="http://localhost:11434/v1",
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti"&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/integrations/lang-graph-agent"&gt;Building an agent with LangChain's LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here's exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you're using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB, Kuzu, Amazon Neptune Database or Neptune Analytics)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don't Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py"&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os

os.environ['GRAPHITI_TELEMETRY_ENABLED'] = 'false'

# Then initialize Graphiti as usual
from graphiti_core import Graphiti

graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it's code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;⚡ N8N Workflow Collection &amp;amp; Documentation&lt;/h1&gt; 
&lt;p&gt;A professionally organized collection of &lt;strong&gt;2,057 n8n workflows&lt;/strong&gt; with a lightning-fast documentation system that provides instant search, analysis, and browsing capabilities.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ IMPORTANT NOTICE (Aug 14, 2025):&lt;/strong&gt; Repository history has been rewritten due to DMCA compliance. If you have a fork or local clone, please see &lt;a href="https://github.com/Zie619/n8n-workflows/issues/85"&gt;Issue 85&lt;/a&gt; for instructions on syncing your copy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ffdd00?logo=buy-me-a-coffee&amp;amp;logoColor=black&amp;amp;style=flat" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you'd like to say thanks, consider buying me a coffee—your support helps me keep improving this project!&lt;/p&gt; 
&lt;h2&gt;🚀 &lt;strong&gt;NEW: Public Search Interface &amp;amp; High-Performance Documentation&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;🌐 &lt;a href="https://zie619.github.io/n8n-workflows"&gt;Browse workflows online&lt;/a&gt; - No installation required!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Or run locally for development with 100x performance improvement:&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Option 1: Online Search (Recommended for Users)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;🔗 Visit: &lt;a href="https://zie619.github.io/n8n-workflows"&gt;zie619.github.io/n8n-workflows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Instant access&lt;/strong&gt; - No setup required&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;Search 2,057+ workflows&lt;/strong&gt; directly in browser&lt;/li&gt; 
 &lt;li&gt;📱 &lt;strong&gt;Mobile-friendly&lt;/strong&gt; interface&lt;/li&gt; 
 &lt;li&gt;🏷️ &lt;strong&gt;Category filtering&lt;/strong&gt; across 15 categories&lt;/li&gt; 
 &lt;li&gt;📥 &lt;strong&gt;Direct download&lt;/strong&gt; of workflow JSON files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Option 2: Local Development System&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pip install -r requirements.txt

# Start the fast API server
python run.py

# Open in browser
http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Sub-100ms response times&lt;/strong&gt; with SQLite FTS5 search&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;Instant full-text search&lt;/strong&gt; with advanced filtering&lt;/li&gt; 
 &lt;li&gt;📱 &lt;strong&gt;Responsive design&lt;/strong&gt; - works perfectly on mobile&lt;/li&gt; 
 &lt;li&gt;🌙 &lt;strong&gt;Dark/light themes&lt;/strong&gt; with system preference detection&lt;/li&gt; 
 &lt;li&gt;📊 &lt;strong&gt;Live statistics&lt;/strong&gt; - 365 unique integrations, 29,445 total nodes&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Smart categorization&lt;/strong&gt; by trigger type and complexity&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Use case categorization&lt;/strong&gt; by service name mapped to categories&lt;/li&gt; 
 &lt;li&gt;📄 &lt;strong&gt;On-demand JSON viewing&lt;/strong&gt; and download&lt;/li&gt; 
 &lt;li&gt;🔗 &lt;strong&gt;Mermaid diagram generation&lt;/strong&gt; for workflow visualization&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Real-time workflow naming&lt;/strong&gt; with intelligent formatting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Old System&lt;/th&gt; 
   &lt;th&gt;New System&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;File Size&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;71MB HTML&lt;/td&gt; 
   &lt;td&gt;&amp;lt;100KB&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;700x smaller&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Load Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10+ seconds&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1 second&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;10x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Client-side only&lt;/td&gt; 
   &lt;td&gt;Full-text with FTS5&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Instant&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~2GB RAM&lt;/td&gt; 
   &lt;td&gt;&amp;lt;50MB RAM&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;40x less&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mobile Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Poor&lt;/td&gt; 
   &lt;td&gt;Excellent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Fully responsive&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📂 Repository Organization&lt;/h2&gt; 
&lt;h3&gt;Workflow Collection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,057 workflows&lt;/strong&gt; with meaningful, searchable names&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; across popular platforms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;29,445 total nodes&lt;/strong&gt; with professional categorization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality assurance&lt;/strong&gt; - All workflows analyzed and categorized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Naming System ✨&lt;/h3&gt; 
&lt;p&gt;Our intelligent naming system converts technical filenames into readable titles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Before&lt;/strong&gt;: &lt;code&gt;2051_Telegram_Webhook_Automation_Webhook.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;After&lt;/strong&gt;: &lt;code&gt;Telegram Webhook Automation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; with smart capitalization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic integration detection&lt;/strong&gt; from node analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use Case Category ✨&lt;/h3&gt; 
&lt;p&gt;The search interface includes a dropdown filter that lets you browse 2,057+ workflows by category.&lt;/p&gt; 
&lt;p&gt;The system includes an automated categorization feature that organizes workflows by service categories to make them easier to discover and filter.&lt;/p&gt; 
&lt;h3&gt;How Categorization Works&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the categorization script&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python create_categories.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Service Name Recognition&lt;/strong&gt; The script analyzes each workflow JSON filename to identify recognized service names (e.g., "Twilio", "Slack", "Gmail", etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Category Mapping&lt;/strong&gt; Each recognized service name is matched to its corresponding category using the definitions in &lt;code&gt;context/def_categories.json&lt;/code&gt;. For example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Twilio → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Gmail → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Airtable → Data Processing &amp;amp; Analysis&lt;/li&gt; 
   &lt;li&gt;Salesforce → CRM &amp;amp; Sales&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search Categories Generation&lt;/strong&gt; The script produces a &lt;code&gt;search_categories.json&lt;/code&gt; file that contains the categorized workflow data&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter Interface&lt;/strong&gt; Users can then filter workflows by category in the search interface, making it easier to find workflows for specific use cases&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Available Categories&lt;/h3&gt; 
&lt;p&gt;The categorization system includes the following main categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI Agent Development&lt;/li&gt; 
 &lt;li&gt;Business Process Automation&lt;/li&gt; 
 &lt;li&gt;Cloud Storage &amp;amp; File Management&lt;/li&gt; 
 &lt;li&gt;Communication &amp;amp; Messaging&lt;/li&gt; 
 &lt;li&gt;Creative Content &amp;amp; Video Automation&lt;/li&gt; 
 &lt;li&gt;Creative Design Automation&lt;/li&gt; 
 &lt;li&gt;CRM &amp;amp; Sales&lt;/li&gt; 
 &lt;li&gt;Data Processing &amp;amp; Analysis&lt;/li&gt; 
 &lt;li&gt;E-commerce &amp;amp; Retail&lt;/li&gt; 
 &lt;li&gt;Financial &amp;amp; Accounting&lt;/li&gt; 
 &lt;li&gt;Marketing &amp;amp; Advertising Automation&lt;/li&gt; 
 &lt;li&gt;Project Management&lt;/li&gt; 
 &lt;li&gt;Social Media Management&lt;/li&gt; 
 &lt;li&gt;Technical Infrastructure &amp;amp; DevOps&lt;/li&gt; 
 &lt;li&gt;Web Scraping &amp;amp; Data Extraction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribute Categories&lt;/h3&gt; 
&lt;p&gt;You can help expand the categorization by adding more service-to-category mappings (e.g., Twilio → Communication &amp;amp; Messaging) in context/defs_categories.json.&lt;/p&gt; 
&lt;p&gt;Many workflow JSON files are conveniently named with the service name, often separated by underscores (_).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 Usage Instructions&lt;/h2&gt; 
&lt;h3&gt;Option 1: Modern Fast System (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install Python dependencies
pip install -r requirements.txt

# Start the documentation server
python run.py

# Browse workflows at http://localhost:8000
# - Instant search across 2,057 workflows
# - Professional responsive interface
# - Real-time workflow statistics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Development Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with auto-reload for development
python run.py --dev

# Or specify custom host/port
python run.py --host 0.0.0.0 --port 3000

# Force database reindexing
python run.py --reindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Import Workflows into n8n&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use the Python importer (recommended)
python import_workflows.py

# Or manually import individual workflows:
# 1. Open your n8n Editor UI
# 2. Click menu (☰) → Import workflow
# 3. Choose any .json file from the workflows/ folder
# 4. Update credentials/webhook URLs before running
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📊 Workflow Statistics&lt;/h2&gt; 
&lt;h3&gt;Current Collection Stats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total Workflows&lt;/strong&gt;: 2,057 automation workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Workflows&lt;/strong&gt;: 215 (10.5% active rate)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Total Nodes&lt;/strong&gt;: 29,528 (avg 14.4 nodes per workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unique Integrations&lt;/strong&gt;: 367 different services and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with FTS5 full-text search&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Trigger Distribution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complex&lt;/strong&gt;: 832 workflows (40.4%) - Multi-trigger systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook&lt;/strong&gt;: 521 workflows (25.3%) - API-triggered automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual&lt;/strong&gt;: 478 workflows (23.2%) - User-initiated workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduled&lt;/strong&gt;: 226 workflows (11.0%) - Time-based executions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Complexity Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Low (≤5 nodes)&lt;/strong&gt;: ~35% - Simple automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium (6-15 nodes)&lt;/strong&gt;: ~45% - Standard workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High (16+ nodes)&lt;/strong&gt;: ~20% - Complex enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Popular Integrations&lt;/h3&gt; 
&lt;p&gt;Top services by usage frequency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Storage&lt;/strong&gt;: Google Drive, Google Sheets, Dropbox&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI/ML&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: HTTP Request, Webhook, GraphQL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔍 Advanced Search Features&lt;/h2&gt; 
&lt;h3&gt;Smart Search Categories&lt;/h3&gt; 
&lt;p&gt;Our system automatically categorizes workflows into 15 main categories:&lt;/p&gt; 
&lt;h4&gt;Available Categories:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI Agent Development&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face, CalcsLive&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Process Automation&lt;/strong&gt;: Workflow utilities, scheduling, data processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Storage &amp;amp; File Management&lt;/strong&gt;: Google Drive, Dropbox, OneDrive, Box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Communication &amp;amp; Messaging&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp, Email&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Creative Content &amp;amp; Video Automation&lt;/strong&gt;: YouTube, Vimeo, content creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Creative Design Automation&lt;/strong&gt;: Canva, Figma, image processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CRM &amp;amp; Sales&lt;/strong&gt;: Salesforce, HubSpot, Pipedrive, customer management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Processing &amp;amp; Analysis&lt;/strong&gt;: Database operations, analytics, data transformation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;E-commerce &amp;amp; Retail&lt;/strong&gt;: Shopify, Stripe, PayPal, online stores&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Financial &amp;amp; Accounting&lt;/strong&gt;: Financial tools, payment processing, accounting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Marketing &amp;amp; Advertising Automation&lt;/strong&gt;: Email marketing, campaigns, lead generation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Project Management&lt;/strong&gt;: Jira, Trello, Asana, task management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Social Media Management&lt;/strong&gt;: LinkedIn, Twitter/X, Facebook, Instagram&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Technical Infrastructure &amp;amp; DevOps&lt;/strong&gt;: GitHub, deployment, monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Scraping &amp;amp; Data Extraction&lt;/strong&gt;: HTTP requests, webhooks, data collection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Search workflows by text
curl "http://localhost:8000/api/workflows?q=telegram+automation"

# Filter by trigger type and complexity
curl "http://localhost:8000/api/workflows?trigger=Webhook&amp;amp;complexity=high"

# Find all messaging workflows
curl "http://localhost:8000/api/workflows/category/messaging"

# Get database statistics
curl "http://localhost:8000/api/stats"

# Browse available categories
curl "http://localhost:8000/api/categories"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗 Technical Architecture&lt;/h2&gt; 
&lt;h3&gt;Modern Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - FTS5 full-text search with 365 indexed integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI Backend&lt;/strong&gt; - RESTful API with automatic OpenAPI documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Frontend&lt;/strong&gt; - Modern HTML5 with embedded CSS/JavaScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt; - Automatic workflow categorization and naming&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Change Detection&lt;/strong&gt; - MD5 hashing for efficient re-indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Processing&lt;/strong&gt; - Non-blocking workflow analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compressed Responses&lt;/strong&gt; - Gzip middleware for optimal speed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error Handling&lt;/strong&gt; - Graceful degradation and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Optimization&lt;/strong&gt; - Touch-friendly interface design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database Performance&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Optimized schema for lightning-fast queries
CREATE TABLE workflows (
    id INTEGER PRIMARY KEY,
    filename TEXT UNIQUE,
    name TEXT,
    active BOOLEAN,
    trigger_type TEXT,
    complexity TEXT,
    node_count INTEGER,
    integrations TEXT,  -- JSON array of 365 unique services
    description TEXT,
    file_hash TEXT,     -- MD5 for change detection
    analyzed_at TIMESTAMP
);

-- Full-text search with ranking
CREATE VIRTUAL TABLE workflows_fts USING fts5(
    filename, name, description, integrations, tags,
    content='workflows', content_rowid='id'
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔧 Setup &amp;amp; Requirements&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.7+&lt;/strong&gt; - For running the documentation system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Browser&lt;/strong&gt; - Chrome, Firefox, Safari, Edge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;50MB Storage&lt;/strong&gt; - For SQLite database and indexes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Instance&lt;/strong&gt; - For importing and running workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start documentation server
python run.py

# Access at http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run with auto-reload for development
python api_server.py --reload

# Force database reindexing
python workflow_db.py --index --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📋 Naming Convention&lt;/h2&gt; 
&lt;h3&gt;Intelligent Formatting System&lt;/h3&gt; 
&lt;p&gt;Our system automatically converts technical filenames to user-friendly names:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Automatic transformations:
2051_Telegram_Webhook_Automation_Webhook.json → "Telegram Webhook Automation"
0250_HTTP_Discord_Import_Scheduled.json → "HTTP Discord Import Scheduled"  
0966_OpenAI_Data_Processing_Manual.json → "OpenAI Data Processing Manual"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Technical Format&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;[ID]_[Service1]_[Service2]_[Purpose]_[Trigger].json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Smart Capitalization Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP&lt;/strong&gt; → HTTP (not Http)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt; → API (not Api)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;webhook&lt;/strong&gt; → Webhook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;automation&lt;/strong&gt; → Automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;scheduled&lt;/strong&gt; → Scheduled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 API Documentation&lt;/h2&gt; 
&lt;h3&gt;Core Endpoints&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /&lt;/code&gt; - Main workflow browser interface&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/stats&lt;/code&gt; - Database statistics and metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows&lt;/code&gt; - Search with filters and pagination&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}&lt;/code&gt; - Detailed workflow information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/download&lt;/code&gt; - Download workflow JSON&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/diagram&lt;/code&gt; - Generate Mermaid diagram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Search&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/category/{category}&lt;/code&gt; - Search by service category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/categories&lt;/code&gt; - List all available categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/integrations&lt;/code&gt; - Get integration statistics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /api/reindex&lt;/code&gt; - Trigger background reindexing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Response Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;// GET /api/stats
{
  "total": 2053,
  "active": 215,
  "inactive": 1838,
  "triggers": {
    "Complex": 831,
    "Webhook": 519,
    "Manual": 477,
    "Scheduled": 226
  },
  "total_nodes": 29445,
  "unique_integrations": 365
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;🎉 This project solves &lt;a href="https://github.com/Zie619/n8n-workflows/issues/84"&gt;Issue #84&lt;/a&gt; - providing online access to workflows without requiring local setup!&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Adding New Workflows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Export workflow&lt;/strong&gt; as JSON from n8n&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Name descriptively&lt;/strong&gt; following the established pattern: &lt;code&gt;[ID]_[Service]_[Purpose]_[Trigger].json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to workflows/&lt;/strong&gt; directory (create service folder if needed)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remove sensitive data&lt;/strong&gt; (credentials, personal URLs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add tags&lt;/strong&gt; for better searchability (calculation, automation, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Actions automatically&lt;/strong&gt; updates the public search interface&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Quality Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Workflow must be functional and tested&lt;/li&gt; 
 &lt;li&gt;✅ Remove all credentials and sensitive data&lt;/li&gt; 
 &lt;li&gt;✅ Follow naming convention for consistency&lt;/li&gt; 
 &lt;li&gt;✅ Verify compatibility with recent n8n versions&lt;/li&gt; 
 &lt;li&gt;✅ Include meaningful description or comments&lt;/li&gt; 
 &lt;li&gt;✅ Add relevant tags for search optimization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Custom Node Workflows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Include npm package links in descriptions&lt;/li&gt; 
 &lt;li&gt;✅ Document custom node requirements&lt;/li&gt; 
 &lt;li&gt;✅ Add installation instructions&lt;/li&gt; 
 &lt;li&gt;✅ Use descriptive tags (like CalcsLive example)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reindexing (for local development)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Force database reindexing after adding workflows
python run.py --reindex

# Or update search index only
python scripts/generate_search_index.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⚠️ Important Notes&lt;/h2&gt; 
&lt;h3&gt;Security &amp;amp; Privacy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Review before use&lt;/strong&gt; - All workflows shared as-is for educational purposes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update credentials&lt;/strong&gt; - Replace API keys, tokens, and webhooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test safely&lt;/strong&gt; - Verify in development environment first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check permissions&lt;/strong&gt; - Ensure proper access rights for integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Version&lt;/strong&gt; - Compatible with n8n 1.0+ (most workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Nodes&lt;/strong&gt; - Some workflows may require additional node installations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Changes&lt;/strong&gt; - External services may have updated their APIs since creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependencies&lt;/strong&gt; - Verify required integrations before importing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📚 Resources &amp;amp; References&lt;/h2&gt; 
&lt;h3&gt;Workflow Sources&lt;/h3&gt; 
&lt;p&gt;This comprehensive collection includes workflows from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Official n8n.io&lt;/strong&gt; - Documentation and community examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub repositories&lt;/strong&gt; - Open source community contributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blog posts &amp;amp; tutorials&lt;/strong&gt; - Real-world automation patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User submissions&lt;/strong&gt; - Tested and verified workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise use cases&lt;/strong&gt; - Business process automations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Learn More&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/"&gt;n8n Documentation&lt;/a&gt; - Official documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.n8n.io/"&gt;n8n Community&lt;/a&gt; - Community forum and support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/"&gt;Workflow Templates&lt;/a&gt; - Official template library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/"&gt;Integration Docs&lt;/a&gt; - Service-specific guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏆 Project Achievements&lt;/h2&gt; 
&lt;h3&gt;Repository Transformation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; professionally organized and named&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; automatically detected and categorized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; (improved from basic filename patterns)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero data loss&lt;/strong&gt; during intelligent renaming process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced search&lt;/strong&gt; with 15 service categories&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Revolution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-100ms search&lt;/strong&gt; with SQLite FTS5 full-text indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant filtering&lt;/strong&gt; across 29,445 workflow nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile-optimized&lt;/strong&gt; responsive design for all devices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time statistics&lt;/strong&gt; with live database queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional interface&lt;/strong&gt; with modern UX principles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;System Reliability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Robust error handling&lt;/strong&gt; with graceful degradation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change detection&lt;/strong&gt; for efficient database updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background processing&lt;/strong&gt; for non-blocking operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive logging&lt;/strong&gt; for debugging and monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production-ready&lt;/strong&gt; with proper middleware and security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;This repository represents the most comprehensive and well-organized collection of n8n workflows available, featuring cutting-edge search technology and professional documentation that makes workflow discovery and usage a delightful experience.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🎯 Perfect for&lt;/strong&gt;: Developers, automation engineers, business analysts, and anyone looking to streamline their workflows with proven n8n automations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/README_ZH.md"&gt;中文&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>public-apis/public-apis</title>
      <link>https://github.com/public-apis/public-apis</link>
      <description>&lt;p&gt;A collective list of free APIs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Try Public APIs for free&lt;/h1&gt; 
&lt;p&gt;The Public APIs repository is manually curated by community members like you and folks working at &lt;a href="https://apilayer.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo"&gt;APILayer&lt;/a&gt;. It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt; &lt;a href="https://apilayer.com"&gt; &lt;/a&gt;&lt;/p&gt;
&lt;div&gt;
 &lt;a href="https://apilayer.com"&gt; &lt;img src="https://raw.githubusercontent.com/public-apis/public-apis/master/.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png" width="100%" alt="APILayer Logo" /&gt; &lt;/a&gt;
&lt;/div&gt;
&lt;a href="https://apilayer.com"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;APILayer is the fastest way to integrate APIs into any product. Explore &lt;a href="https://apilayer.com/products/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo"&gt;APILayer APIs&lt;/a&gt; here for your next project.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.com/invite/hgjA78638n/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo"&gt;Discord server&lt;/a&gt; to get updates, ask questions, get answers, random community calls, and more.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;APILayer APIs&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Call this API&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipstack.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;IPstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Locate and Identify Website Visitors by IP Address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://marketstack.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;Marketstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://weatherstack.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;Weatherstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve instant, accurate weather information for any location in the world in lightweight JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://numverify.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;Numverify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global Phone Number Validation &amp;amp; Lookup JSON API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fixer.io/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;Fixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://avaitionstack.com/?utm_source=Github&amp;amp;utm_medium=Referral&amp;amp;utm_campaign=Public-apis-repo-Best-sellers"&gt;Aviationstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free, real-time flight status and global Aviation data API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://god.gw.postman.com/run-collection/10131015-72ee0d35-018e-4370-a2b6-a66d3ebd5b5a?action=collection/fork"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 128px; height: 32px;" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;Learn more about Public APIs&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Get Involved&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davemachado/public-api"&gt;API for this project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/public-apis/public-apis/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/public-apis/public-apis/pulls"&gt;Pull Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Index&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#animals"&gt;Animals&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#anime"&gt;Anime&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#anti-malware"&gt;Anti-Malware&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#art--design"&gt;Art &amp;amp; Design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#authentication--authorization"&gt;Authentication &amp;amp; Authorization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#blockchain"&gt;Blockchain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#books"&gt;Books&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#business"&gt;Business&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#calendar"&gt;Calendar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#cloud-storage--file-sharing"&gt;Cloud Storage &amp;amp; File Sharing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#continuous-integration"&gt;Continuous Integration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#cryptocurrency"&gt;Cryptocurrency&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#currency-exchange"&gt;Currency Exchange&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#data-validation"&gt;Data Validation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#development"&gt;Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#dictionaries"&gt;Dictionaries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#documents--productivity"&gt;Documents &amp;amp; Productivity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#email"&gt;Email&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#entertainment"&gt;Entertainment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#environment"&gt;Environment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#events"&gt;Events&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#finance"&gt;Finance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#food--drink"&gt;Food &amp;amp; Drink&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#games--comics"&gt;Games &amp;amp; Comics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#geocoding"&gt;Geocoding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#government"&gt;Government&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#health"&gt;Health&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#jobs"&gt;Jobs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#machine-learning"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#music"&gt;Music&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#news"&gt;News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#open-data"&gt;Open Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#open-source-projects"&gt;Open Source Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#patent"&gt;Patent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#personality"&gt;Personality&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#phone"&gt;Phone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#photography"&gt;Photography&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#programming"&gt;Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#science--math"&gt;Science &amp;amp; Math&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#shopping"&gt;Shopping&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#social"&gt;Social&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#sports--fitness"&gt;Sports &amp;amp; Fitness&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#test-data"&gt;Test Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#text-analysis"&gt;Text Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#tracking"&gt;Tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#transportation"&gt;Transportation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#url-shorteners"&gt;URL Shorteners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#vehicle"&gt;Vehicle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#video"&gt;Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#weather"&gt;Weather&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h3&gt;Animals&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.adoptapet.com/public/apis/pet_list.html"&gt;AdoptAPet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Resource to help get pets adopted&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://theaxolotlapi.netlify.app/"&gt;Axolotl&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Collection of axolotl pictures and facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://alexwohlbruck.github.io/cat-facts/"&gt;Cat Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Daily cat facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cataas.com/"&gt;Cataas&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cat as a service (cats pictures and gifs)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.thecatapi.com/"&gt;Cats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pictures of cats from Tumblr&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dukengn.github.io/Dog-facts-API/"&gt;Dog Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random dog facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kinduff.github.io/dog-api/"&gt;Dog Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random facts of Dogs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dog.ceo/dog-api/"&gt;Dogs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Based on the Stanford Dogs Dataset&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/664302/S1ENwy59"&gt;eBird&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve recent or notable birding observations within a region&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.fishwatch.gov/developers"&gt;FishWatch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Information and pictures about individual fish species&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://http.cat/"&gt;HTTP Cat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cat for every HTTP Status&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://http.dog/"&gt;HTTP Dog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dogs for every HTTP response status code&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://apiv3.iucnredlist.org/api/v3/docs"&gt;IUCN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IUCN Red List of Threatened Species&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/wh-iterabb-it/meowfacts"&gt;MeowFacts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get random cat facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/movebank/movebank-api-doc"&gt;Movebank&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Movement and Migration data of animals&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.petfinder.com/developers/"&gt;Petfinder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Petfinder is dedicated to helping pets find homes, another resource to get pets adopted&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://placebear.com/"&gt;PlaceBear&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Placeholder bear pictures&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://place.dog"&gt;PlaceDog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Placeholder Dog pictures&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://placekitten.com/"&gt;PlaceKitten&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Placeholder Kitten pictures&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://random.dog/woof.json"&gt;RandomDog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of dogs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://random-d.uk/api"&gt;RandomDuck&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of ducks&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://randomfox.ca/floof/"&gt;RandomFox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of foxes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home"&gt;RescueGroups&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Adoption&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://shibe.online/"&gt;Shibe.Online&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of Shiba Inu, cats or birds&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://thedogapi.com/"&gt;The Dog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A public service all about Dogs, free to use when making your fancy new App, Website or Service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://xeno-canto.org/explore/api"&gt;xeno-canto&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bird recordings&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://zoo-animal-api.herokuapp.com/"&gt;Zoo Animals&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Facts and pictures of zoo animals&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Anime&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aniapi.com/docs/"&gt;AniAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime discovery, streaming &amp;amp; syncing with trackers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wiki.anidb.net/HTTP_API_Definition"&gt;AniDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime Database&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/AniList/ApiV2-GraphQL-Docs"&gt;AniList&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime discovery &amp;amp; tracking&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/RocktimSaikia/anime-chan"&gt;AnimeChan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime quotes (over 10k+)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://chandan-02.github.io/anime-facts-rest-api/"&gt;AnimeFacts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime Facts (over 100+)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.animenewsnetwork.com/encyclopedia/api.php"&gt;AnimeNewsNetwork&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime industry news&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://catboys.com/api"&gt;Catboy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Neko images, funny GIFs &amp;amp; more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://danbooru.donmai.us/wiki_pages/help:api"&gt;Danbooru Anime&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Thousands of anime artist database to find good anime art&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://jikan.moe"&gt;Jikan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial MyAnimeList API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kitsu.docs.apiary.io/"&gt;Kitsu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime discovery platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.mangadex.org/docs.html"&gt;MangaDex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Manga Database and Community&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/"&gt;Mangapi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Translate manga pages from one language to another&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://myanimelist.net/clubs.php?cid=13727"&gt;MyAnimeList&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime and Manga Database and Community&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.nekos.best"&gt;NekosBest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Neko Images &amp;amp; Anime roleplaying GIFs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://shikimori.one/api/doc"&gt;Shikimori&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Anime discovery, tracking, forum, rates&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ghibliapi.herokuapp.com"&gt;Studio Ghibli&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Resources from Studio Ghibli films&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://soruly.github.io/trace.moe-api/#/"&gt;Trace Moe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A useful tool to get the exact scene of an anime from a screenshot&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://waifu.im/docs"&gt;Waifu.im&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get waifu pictures from an archive of over 4000 images and multiple tags&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://waifu.pics/docs"&gt;Waifu.pics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image sharing platform for anime images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Anti-Malware&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.abuseipdb.com/"&gt;AbuseIPDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP/domain/URL reputation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://otx.alienvault.com/api"&gt;AlienVault Open Threat Exchange (OTX)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP/domain/URL reputation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://capev2.readthedocs.io/en/latest/usage/api.html"&gt;CAPEsandbox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Malware execution and analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/safe-browsing/"&gt;Google Safe Browsing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Google Link/Domain Flagging&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://maldatabase.com/api-doc.html"&gt;MalDatabase&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide malware datasets and threat intelligence feeds&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://malshare.com/doc.php"&gt;MalShare&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Malware Archive / file sourcing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bazaar.abuse.ch/api/"&gt;MalwareBazaar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Collect and share malware samples&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://metacert.com/"&gt;Metacert&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Metacert Link Flagging&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/Amiichu/api/exerra-phishing-check/"&gt;NoPhishy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Check links to see if they're known phishing attempts&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://phisherman.gg/"&gt;Phisherman&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP/domain/URL reputation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.scanii.com/"&gt;Scanii&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple REST API that can scan submitted documents/files for the presence of threats&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://urlhaus-api.abuse.ch/"&gt;URLhaus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bulk queries and Download Malware Samples&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://urlscan.io/about-api/"&gt;URLScan.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Scan and Analyse URLs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.virustotal.com/en/documentation/public-api/"&gt;VirusTotal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;VirusTotal File/URL Analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://support.mywot.com/hc/en-us/sections/360004477734-API-"&gt;Web of Trust&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP/domain/URL reputation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Art &amp;amp; Design&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.amethyste.moe/"&gt;Améthyste&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate images for Discord users&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.artic.edu/docs/"&gt;Art Institute of Chicago&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Art&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://colormind.io/api-access/"&gt;Colormind&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Color scheme generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.colourlovers.com/api"&gt;ColourLovers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get various patterns, palettes and images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://collection.cooperhewitt.org/api"&gt;Cooper Hewitt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Smithsonian Design Museum&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.dribbble.com"&gt;Dribbble&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Discover the world’s top designers &amp;amp; creatives&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cheatsnake/emojihub"&gt;EmojiHub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get emojis by categories and groups&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pro.europeana.eu/resources/apis/search"&gt;Europeana&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;European Museum and Galleries content&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvardartmuseums/api-docs"&gt;Harvard Art Museums&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Art&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://icon.horse"&gt;Icon Horse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Favicons for any website, with fallbacks&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.iconfinder.com"&gt;Iconfinder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Icons&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://img.icons8.com/"&gt;Icons8&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Icons (find "search icon" hyperlink in page)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://lordicon.com/"&gt;Lordicon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Icons with predone Animations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://metmuseum.github.io/"&gt;Metropolitan Museum of Art&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Met Museum of Art&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.thenounproject.com/index.html"&gt;Noun Project&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Icons&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://php-noise.com/"&gt;PHP-Noise&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Noise Background Image Generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pixelencounter.com/api"&gt;Pixel Encounter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SVG Icon Generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.rijksmuseum.nl/object-metadata/api/"&gt;Rijksmuseum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RijksMuseum Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wordcloudapi.com/"&gt;Word Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily create word clouds&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://x-colors.herokuapp.com/"&gt;xColors&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate &amp;amp; convert colors&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Authentication &amp;amp; Authorization&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://auth0.com"&gt;Auth0&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easy to implement, adaptable authentication and authorization platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://otp.dev/en/docs/"&gt;GetOTP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Implement OTP flow quickly&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://m3o.com/user"&gt;Micro User Service&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;User management and authentication&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mojoauth.com"&gt;MojoAuth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Secure and modern passwordless authentication platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sawolabs.com"&gt;SAWO Labs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simplify login and improve user experience by integrating passwordless authentication in your app&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://stytch.com/"&gt;Stytch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;User infrastructure for modern applications&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://warrant.dev/"&gt;Warrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;APIs for authorization and access control&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Blockchain&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://graphql.bitquery.io/ide"&gt;Bitquery&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Onchain GraphQL APIs &amp;amp; DEX APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://chain.link/developer-resources"&gt;Chainlink&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Build hybrid smart contracts with Chainlink&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tierion.com/chainpoint/"&gt;Chainpoint&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chainpoint is a global network for anchoring data to the Bitcoin blockchain&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.covalenthq.com/docs/api/"&gt;Covalent&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Multi-blockchain data aggregator platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://etherscan.io/apis"&gt;Etherscan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ethereum explorer API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.helium.com/api/blockchain/introduction/"&gt;Helium&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://nownodes.io/"&gt;Nownodes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Blockchain-as-a-service solution that provides high-quality connection via API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.steem.io/"&gt;Steem&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Blockchain-based blogging and social media website&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://thegraph.com"&gt;The Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Indexing protocol for querying networks like Ethereum with GraphQL&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://walltime.info/api.html"&gt;Walltime&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;To retrieve Walltime's market info&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.watchdata.io"&gt;Watchdata&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide simple and reliable API access to Ethereum blockchain&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abibliadigital.com.br/en"&gt;A Bíblia Digital&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Do not worry about managing the multiple versions of the Bible&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.bhagavadgitaapi.in"&gt;Bhagavad Gita&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bhagavadgita.io/api"&gt;Bhagavad Gita&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bhagavad Gita text&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gita-api.vercel.app"&gt;Bhagavad Gita telugu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bhagavad Gita API in telugu and odia languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bible-api.com/"&gt;Bible-api&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Bible API with multiple languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://bnb.data.bl.uk/"&gt;British National Bibliography&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Books&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/CrossRef/rest-api-doc"&gt;Crossref Metadata Search&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Books &amp;amp; Articles Metadata&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.ganjoor.net"&gt;Ganjoor&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Classic Persian poetry works including access to related manuscripts, recitations and music tracks&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/books/"&gt;Google Books&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Books&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/GurbaniNow/api"&gt;GurbaniNow&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fast and Accurate Gurbani RESTful API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gutendex.com/"&gt;Gutendex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web-API for fetching data from Project Gutenberg Books Library&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openlibrary.org/developers/api"&gt;Open Library&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Books, book covers and related data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.penguinrandomhouse.biz/webservices/rest/"&gt;Penguin Publishing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Books, book covers and related data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/thundercomb/poetrydb#readme"&gt;PoetryDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Enables you to get instant data from our vast poetry collection&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quran.api-docs.io/"&gt;Quran&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RESTful Quran API with multiple languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://alquran.cloud/api"&gt;Quran Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A RESTful Quran API to retrieve an Ayah, Surah, Juz or the entire Holy Quran&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fawazahmed0/quran-api#readme"&gt;Quran-api&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Quran API Service with 90+ different languages and 400+ translations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aninditabasu.github.io/indica/html/rv.html"&gt;Rig Veda&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gods and poets, their categories, and the verse meters, with the mandal and sukta number&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.api.bible"&gt;The Bible&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Everything you need from the Bible in one discoverable place&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-thirukkural.web.app/"&gt;Thirukkural&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1330 Thirukkural poems and explanation in Tamil and English&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aninditabasu.github.io/indica/html/vs.html"&gt;Vedic Society&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Descriptions of all nouns (names, places, animals, things) from vedic literature&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wizard-world-api.herokuapp.com/swagger/index.html"&gt;Wizard World&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information from the Harry Potter universe&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wolnelektury.pl/api/"&gt;Wolne Lektury&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for obtaining information about e-books available on the WolneLektury.pl website&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Business&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://superset.apache.org/docs/api"&gt;Apache Superset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to manage your BI dashboards and data sources on Superset&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="http://charityapi.orghunter.com/"&gt;Charity Search&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Non-profit charity data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://clearbit.com/docs#logo-api"&gt;Clearbit Logo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search for company logos and embed them in your projects&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://domainsdb.info/"&gt;Domainsdb.info&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Registered Domain Names Search&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.freelancer.com"&gt;Freelancer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hire freelancers to get work done&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.google.com/gmail/api/"&gt;Gmail&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Flexible, RESTful access to the user's inbox&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.google.com/analytics/"&gt;Google Analytics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Collect, configure and analyze your data to reach the right audience&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://instatus.com/help/api"&gt;Instatus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Post to and update maintenance and incidents on your status page through an HTTP REST API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mailchimp.com/developer/"&gt;Mailchimp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Send marketing campaigns and transactional mails&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.mailjet.com/"&gt;mailjet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Marketing email can be sent and mail templates made in MJML or HTML can be sent using API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://markerapi.com"&gt;markerapi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Trademark Search&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.orb-intelligence.com/docs/"&gt;ORB Intelligence&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Company lookup&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://redash.io/help/user-guide/integrations-and-api/api"&gt;Redash&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access your queries and dashboards on Redash&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://smartsheet.redoc.ly/"&gt;Smartsheet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Allows you to programmatically access and Smartsheet data and account information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.squareup.com/reference/square"&gt;Square&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easy way to take payments, manage refunds, and help customers checkout online&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.digite.com/knowledge-base/swiftkanban/article/api-for-swift-kanban-web-services/#restapi"&gt;SwiftKanban&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Kanban software, Visualize Work, Increase Organizations Lead Time, Throughput &amp;amp; Productivity&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tenders.guru/hu/api"&gt;Tenders in Hungary&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get data for procurements in Hungary in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tenders.guru/pl/api"&gt;Tenders in Poland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get data for procurements in Poland in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tenders.guru/ro/api"&gt;Tenders in Romania&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get data for procurements in Romania in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tenders.guru/es/api"&gt;Tenders in Spain&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get data for procurements in Spain in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tenders.guru/ua/api"&gt;Tenders in Ukraine&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get data for procurements in Ukraine in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://tomba.io/api"&gt;Tomba email finder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Email Finder for B2B sales and email marketing and email verifier&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.trello.com/"&gt;Trello&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Boards, lists and cards to help you organize and prioritize your projects&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Calendar&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abstractapi.com/holidays-api"&gt;Public Holidays&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data on national, regional, and religious holidays via API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://calendarific.com/"&gt;Calendarific&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Worldwide Holidays&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apilayer.com/marketplace/checkiday-api"&gt;Checkiday - National Holiday API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Industry-leading Holiday API. Over 5,000 holidays and thousands of descriptions. Trusted by the World’s leading companies&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://calapi.inadiutorium.cz/"&gt;Church Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Catholic liturgical calendar&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://svatky.adresa.info"&gt;Czech Namedays Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Lookup for a name and returns nameday date&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.getfestivo.com/docs/products/public-holidays-api/intro"&gt;Festivo Public Holidays&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fastest and most advanced public holiday and observance service on the market&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/google-apps/calendar/"&gt;Google Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Display, create and modify Google calendar events&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.hebcal.com/home/developer-apis"&gt;Hebrew Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Convert between Gregorian and Hebrew, fetch Shabbat and Holiday times, etc&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://holidayapi.com/"&gt;Holidays&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Historical data regarding holidays&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.lectserve.com"&gt;LectServe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Protestant liturgical calendar&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://date.nager.at"&gt;Nager.Date&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public holidays for more than 90 countries&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nameday.abalin.net"&gt;Namedays Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides namedays for multiple countries&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/gadael/icsdb"&gt;Non-Working Days&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Database of ICS files for non working days&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://isdayoff.ru"&gt;Non-Working Days&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple REST API for checking working, non-working or short days for Russia, CIS, USA and other&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/egno/work-calendar"&gt;Russian Calendar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Check if a date is a Russian holiday or not&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.gov.uk/bank-holidays.json"&gt;UK Bank Holidays&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bank holidays in England and Wales, Scotland and Northern Ireland&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Cloud Storage &amp;amp; File Sharing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://anonfiles.com/docs/api"&gt;AnonFiles&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Upload and share your files anonymously&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://bayfiles.com/docs/api"&gt;BayFiles&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Upload and share your files&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.box.com/"&gt;Box&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ddownload.com/api"&gt;ddownload&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.dropbox.com/developers"&gt;Dropbox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.file.io"&gt;File.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Super simple file sharing, convenient, anonymous and secure&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.filestack.com"&gt;Filestack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Filestack File Uploader &amp;amp; File Upload API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://gofile.io/api"&gt;GoFile&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unlimited size file uploads for free&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.google.com/drive/"&gt;Google Drive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://gyazo.com/api/docs"&gt;Gyazo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Save &amp;amp; Share screen captures instantly&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.imgbb.com/"&gt;Imgbb&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple and quick private image sharing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.microsoft.com/onedrive"&gt;OneDrive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://getpantry.cloud/"&gt;Pantry&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free JSON storage for small projects&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://pastebin.com/doc_api"&gt;Pastebin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Plain Text Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.pinata.cloud/"&gt;Pinata&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IPFS Pinning Services API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://quip.com/dev/automation/documentation"&gt;Quip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage for groups&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.storj.io/dcs/"&gt;Storj&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Decentralized Open-Source Cloud Storage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://0x0.st"&gt;The Null Pointer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No-bullshit file hosting and URL shortening service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://web3.storage/"&gt;Web3 Storage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File Sharing and Storage for Free with 1TB Space&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Continuous Integration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.microsoft.com/en-us/rest/api/resourcehealth"&gt;Azure DevOps Health&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Resource health helps you diagnose and get support when an Azure issue impacts your resources&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-docs.bitrise.io/"&gt;Bitrise&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Build tool and processes integrations to create efficient development pipelines&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://buddy.works/docs/api/getting-started/overview"&gt;Buddy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The fastest continuous integration and continuous delivery platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://circleci.com/docs/api/v1-reference/"&gt;CircleCI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automate the software development process using continuous integration and continuous delivery&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.cloudbees.com/docs/cloudbees-codeship/latest/api-overview/"&gt;Codeship&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Codeship is a Continuous Integration Platform in the cloud&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.travis-ci.com/api/"&gt;Travis CI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sync your GitHub projects with Travis CI to test your code in minutes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Cryptocurrency&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://0x.org/api"&gt;0x&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for querying token and pool stats across various liquidity pools&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://1inch.io/api/"&gt;1inch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for querying decentralize exchange&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.alchemy.com/alchemy/"&gt;Alchemy Ethereum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ethereum Node-as-a-Service Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coinlayer.com"&gt;apilayer coinlayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time Crypto Currency Exchange Rates&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/binance/binance-spot-api-docs"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange for Trading Cryptocurrencies based in China&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nova.bitcambio.com.br/api/v3/docs#a-public"&gt;Bitcambio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get the list of all traded assets in the exchange&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apiv2.bitcoinaverage.com/"&gt;BitcoinAverage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Digital Asset Price Data for the blockchain industry&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bitcoincharts.com/about/exchanges/"&gt;BitcoinCharts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Financial and Technical Data related to the Bitcoin Network&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.bitfinex.com/docs"&gt;Bitfinex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Trading Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bitmex.com/app/apiOverview"&gt;Bitmex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time Cryptocurrency derivatives trading platform based in Hong Kong&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bittrex.github.io/api/v3"&gt;Bittrex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Next Generation Crypto Trading Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://block.io/docs/basic"&gt;Block&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bitcoin Payment, Wallet &amp;amp; Transaction Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.blockchain.com/api"&gt;Blockchain&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bitcoin Payment, Wallet &amp;amp; Transaction Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://blockfrost.io/"&gt;blockfrost Cardano&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interaction with the Cardano mainnet and several testnets&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bravenewcoin.com/developers"&gt;Brave NewCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time and historic crypto data from more than 200+ exchanges&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.btcturk.com/"&gt;BtcTurk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time cryptocurrency data, graphs and API that allows buy&amp;amp;sell&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bybit-exchange.github.io/docs/linear/#t-introduction"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency data feed and algorithmic trading&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.coinapi.io/"&gt;CoinAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All Currency Exchanges integrate under a single api&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.coinbase.com"&gt;Coinbase&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bitcoin, Bitcoin Cash, Litecoin and Ethereum Prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.pro.coinbase.com/#api"&gt;Coinbase Pro&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Trading Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.coincap.io/"&gt;CoinCap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real time Cryptocurrency prices through a RESTful API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.coindcx.com/"&gt;CoinDCX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Trading Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://old.coindesk.com/coindesk-api/"&gt;CoinDesk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CoinDesk's Bitcoin Price Index (BPI) in multiple currencies&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.coingecko.com/api"&gt;CoinGecko&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Price, Market, and Developer/Social Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coinigy.docs.apiary.io"&gt;Coinigy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interacting with Coinigy Accounts and Exchange Directly&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coinlib.io/apidocs"&gt;Coinlib&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Currency Prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinlore.com/cryptocurrency-data-api"&gt;Coinlore&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies prices, volume and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coinmarketcap.com/api/"&gt;CoinMarketCap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.coinpaprika.com"&gt;Coinpaprika&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies prices, volume and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.coinranking.com/api/documentation"&gt;CoinRanking&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Live Cryptocurrency data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coinremitter.com/docs"&gt;Coinremitter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Payment &amp;amp; Prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/5734027/RzZ6Hzr3?version=latest"&gt;CoinStats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Tracker&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.cryptapi.io/"&gt;CryptAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Payment Processor&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cryptingup.com/apidoc/#introduction"&gt;CryptingUp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cryptocompare.com/api#"&gt;CryptoCompare&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Comparison&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.exchange.cryptomkt.com/"&gt;CryptoMarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Trading platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cryptonator.com/api/"&gt;Cryptonator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Exchange Rates&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Decentralized cryptocurrency exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/EverexIO/Ethplorer/wiki/Ethplorer-API"&gt;Ethplorer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ethereum tokens, balances, addresses, history of transactions, contracts, and custom structures&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/10287440/SzYXWKPi"&gt;EXMO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies exchange based in UK&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.ftx.com/"&gt;FTX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Complete REST, websocket, and FTX APIs to suit your algorithmic trading needs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.gate.io/api2"&gt;Gateio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API provides spot, margin and futures trading operations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.gemini.com/rest-api/"&gt;Gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rates.hirak.site/"&gt;Hirak Exchange Rates&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates between 162 currency &amp;amp; 300 crypto currency update each 5 min, accurate, no limits&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huobiapi.github.io/docs/spot/v1/en/"&gt;Huobi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Seychelles based cryptocurrency exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.icy.tools/"&gt;icy.tools&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GraphQL based NFT API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/btcid/indodax-official-api-docs"&gt;Indodax&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Trade your Bitcoin and other assets with rupiah&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://infura.io/product/ethereum"&gt;INFURA Ethereum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interaction with the Ethereum mainnet and several testnets&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.kraken.com/rest/"&gt;Kraken&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.kucoin.com/"&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Trading Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://localbitcoins.com/api-docs/"&gt;Localbitcoins&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;P2P platform to buy and sell Bitcoins&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mempool.space/api"&gt;Mempool&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bitcoin API Service focusing on the transaction fee&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mercadobitcoin.com.br/api-doc/"&gt;MercadoBitcoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brazilian Cryptocurrency Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://messari.io/api"&gt;Messari&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides API endpoints for thousands of crypto assets&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nexchange2.docs.apiary.io/"&gt;Nexchange&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automated cryptocurrency exchange service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nomics.com/docs/"&gt;Nomics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Historical and realtime cryptocurrency prices and market data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://doc.novadax.com/en-US/#introduction"&gt;NovaDax&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NovaDAX API to access all market data, trading management endpoints&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.okex.com/docs/"&gt;OKEx&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency exchange based in Seychelles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.poloniex.com"&gt;Poloniex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US based digital asset exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.solana.com/developing/clients/jsonrpc-api"&gt;Solana JSON RPC&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides various endpoints to interact with the Solana Blockchain&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://technical-analysis-api.com"&gt;Technical Analysis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency prices and technical analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.valr.com/"&gt;VALR&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrency Exchange based in South Africa&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.worldcoinindex.com/apiservice"&gt;WorldCoinIndex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cryptocurrencies Prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://zmok.io"&gt;ZMOK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ethereum JSON RPC API and Web3 provider&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Currency Exchange&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://1forge.com/forex-data-api/api-documentation"&gt;1Forge&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Forex currency market data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.amdoren.com/currency-api/"&gt;Amdoren&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free currency API with over 150 currencies&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fixer.io"&gt;apilayer fixer.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates and currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cbr.ru/development/SXML/"&gt;Bank of Russia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates and currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fawazahmed0/currency-api#readme"&gt;Currency-api&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Currency Exchange Rates API with 150+ Currencies &amp;amp; No Rate Limits&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://currencyfreaks.com/"&gt;CurrencyFreaks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides current and historical currency exchange rates with free plan 1K requests/month&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://currencylayer.com/documentation"&gt;Currencylayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates and currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://currencyscoop.com/api-documentation"&gt;CurrencyScoop&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time and historical currency rates JSON API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cnb.cz/cs/financni_trhy/devizovy_trh/kurzy_devizoveho_trhu/denni_kurz.xml"&gt;Czech National Bank&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A collection of exchange rates&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.awesomeapi.com.br/api-de-moedas"&gt;Economia.Awesome&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Portuguese free currency prices and conversion with no rate limits&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.exchangerate-api.com"&gt;ExchangeRate-API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://exchangerate.host"&gt;Exchangerate.host&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free foreign exchange &amp;amp; crypto rates API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://exchangeratesapi.io"&gt;Exchangeratesapi.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates with currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.frankfurter.app/docs"&gt;Frankfurter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates, currency conversion and time series&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://freeforexapi.com/Home/Api"&gt;FreeForexAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time foreign exchange rates for major currency pairs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.nbp.pl/en.html"&gt;National Bank of Poland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A collection of currency exchange rates (data in XML and JSON)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.vatcomply.com/documentation"&gt;VATComply.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Exchange rates, geolocation and VAT number validation&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Data Validation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lob.com/"&gt;Lob.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US Address Verification&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.postman-echo.com"&gt;Postman Echo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Test api server to receive and return value from HTTP method&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="http://www.purgomalum.com"&gt;PurgoMalum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Content validator against profanity &amp;amp; obscenity&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.smarty.com/docs/cloud/us-autocomplete-pro-api"&gt;US Autocomplete&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Enter address data quickly with real-time address suggestions&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.smarty.com/products/apis/us-extract-api"&gt;US Extract&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Extract postal addresses from any text including emails&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.smarty.com/docs/cloud/us-street-api"&gt;US Street Address&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate and append data for any US postal address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://vatlayer.com/documentation"&gt;vatlayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;VAT number validation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Development&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://24pullrequests.com/api"&gt;24 Pull Requests&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Project to promote open source collaboration during December&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abstractapi.com/website-screenshot-api"&gt;Screenshot&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Take programmatic screenshots of web pages from any website&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://agify.io"&gt;Agify.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Estimates the age from a first name&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apigratis.com.br/"&gt;API Grátis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Multiples services and public APIs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.apicagent.com"&gt;ApicAgent&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Extract device details from user-agent string&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apiflash.com/"&gt;ApiFlash&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chrome based screenshot API for developers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://userstack.com/"&gt;apilayer userstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Secure User-Agent String Lookup JSON API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apis.guru/api-doc/"&gt;APIs.guru&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Wikipedia for Web APIs, OpenAPI/Swagger specs for public APIs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.microsoft.com/en-us/rest/api/azure/devops"&gt;Azure DevOps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Azure DevOps basic components of a REST API request/response pair&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.base-api.io/"&gt;Base&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Building quick backends&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://beeceptor.com/"&gt;Beeceptor&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Build a mock Rest API endpoint in seconds&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.atlassian.com/bitbucket/api/2/reference/"&gt;Bitbucket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bitbucket API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://blague.xyz/"&gt;Blague.xyz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;La plus grande API de Blagues FR/The biggest FR jokes API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://blitapp.com/api/"&gt;Blitapp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Schedule screenshots of web pages and sync them to your cloud&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://blynkapi.docs.apiary.io/#"&gt;Blynk-Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Control IoT Devices from Blynk IoT Cloud&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.boredapi.com/"&gt;Bored&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find random activities to fight boredom&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://brainshop.ai/"&gt;Brainshop.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Make A Free A.I Brain&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://browshot.com/api/documentation"&gt;Browshot&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily make screenshots of web pages in any screen size, as any device&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.cdnjs.com/libraries/jquery"&gt;CDNJS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Library info on CDNJS&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://changelogs.md"&gt;Changelogs.md&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Structured changelog metadata from open source projects&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/polarspetroll/ciprand"&gt;Ciprand&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Secure random string generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fawazahmed0/cloudflare-trace-api"&gt;Cloudflare Trace&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get IP Address, Timestamp, User Agent, Country Code, IATA, HTTP Version, TLS/SSL Version &amp;amp; More&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Jaagrav/CodeX"&gt;Codex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online Compiler for Various Languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.contentful.com/developers/docs/references/images-api/"&gt;Contentful Images&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Used to retrieve and apply transformations to images&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/burhanuday/cors-proxy"&gt;CORS Proxy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get around the dreaded CORS error by using this proxy as a middle man&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://countapi.xyz"&gt;CountAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free and simple counting service. You can use it to track page hits and specific events&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.databricks.com/dev-tools/api/latest/index.html"&gt;Databricks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Service to manage your databricks account,clusters, notebooks, jobs and workspaces&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://status.digitalocean.com/api"&gt;DigitalOcean Status&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Status of all DigitalOcean services&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.docker.com/docker-hub/api/latest/"&gt;Docker Hub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interact with Docker Hub&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.domainsdb.info/"&gt;DomainDb Info&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Domain name search to find all domains containing particular words/phrases/etc&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://extendsclass.com/json-storage.html"&gt;ExtendsClass JSON Storage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple JSON store API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apidocs.geekflare.com/docs/geekflare-api"&gt;GeekFlare&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide numerous capabilities for important testing and monitoring methods for websites&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://genderize.io"&gt;Genderize.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Estimates a gender from a first name&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.getping.info"&gt;GETPing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Trigger an email notification with a simple GET request&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ghost.org/"&gt;Ghost&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get Published content into your Website, App or other embedded media&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.github.com/en/free-pro-team@latest/rest"&gt;GitHub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Make use of GitHub repositories, code and user info programmatically&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.gitlab.com/ee/api/"&gt;Gitlab&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automate GitLab interaction programmatically&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.gitter.im/docs/welcome"&gt;Gitter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chat for Developers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.glitterly.app"&gt;Glitterly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image generation API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/docs/api/reference/rest"&gt;Google Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to read, write, and format Google Docs documents&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://firebase.google.com/docs"&gt;Google Firebase&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Google's mobile application development platform that helps build, improve, and grow app&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/fonts/docs/developer_api"&gt;Google Fonts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Metadata for all families served by Google Fonts&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/keep/api/reference/rest"&gt;Google Keep&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to read, write, and format Google Keep notes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/sheets/api/reference/rest"&gt;Google Sheets&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to read, write, and format Google Sheets data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/slides/api/reference/rest"&gt;Google Slides&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to read, write, and format Google Slides presentations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gorest.co.in/"&gt;Gorest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online REST API for Testing and Prototyping&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hasura.io/opensource/"&gt;Hasura&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GraphQL and REST API Engine with built in Authorization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://devcenter.heroku.com/articles/platform-api-reference/"&gt;Heroku&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API to programmatically create apps, provision add-ons and perform other task on Heroku&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://host-t.com"&gt;host-t.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Basic DNS query via HTTP GET request&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://host.io"&gt;Host.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Domains Data API for Developers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://http2.pro/doc/api"&gt;HTTP2.Pro&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Test endpoints for client and server HTTP/2 protocol support&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://httpbin.org/"&gt;Httpbin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A Simple HTTP Request &amp;amp; Response Service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloudflare-quic.com/b/"&gt;Httpbin Cloudflare&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A Simple HTTP Request &amp;amp; Response Service with HTTP/3 Support by Cloudflare&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hunter.io/api"&gt;Hunter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for domain search, professional email finder, author finder and email verifier&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloud.ibm.com/docs/text-to-speech/getting-started.html"&gt;IBM Text to Speech&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Convert text to speech&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://icanhazepoch.com"&gt;Icanhazepoch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get Epoch time&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://major.io/icanhazip-com-faq/"&gt;Icanhazip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP Address API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://platform.ifttt.com/docs/connect_api"&gt;IFTTT&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IFTTT Connect API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documentation.image-charts.com/"&gt;Image-Charts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate charts, QR codes and graph images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.docs.import.io/"&gt;import.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve structured data from a website or RSS feed&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ip-fast.com/docs/"&gt;ip-fast.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP address, country and city&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ip2whois.com/"&gt;IP2WHOIS Information Lookup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;WHOIS domain name lookup&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipfind.io"&gt;ipfind.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Geographic location of an IP address or any domain name along with some other useful information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ipify.org/"&gt;IPify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple IP Address API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipinfo.io/developers"&gt;IPinfo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Another simple IP Address API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jsdelivr/data.jsdelivr.com"&gt;jsDelivr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Package info and download stats on jsDelivr CDN&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://json2jsonp.com/"&gt;JSON 2 JSONP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Convert JSON to JSONP (on-the-fly) for easy cross-domain data requests using client-side JavaScript&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://jsonbin.io"&gt;JSONbin.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free JSON storage service. Ideal for small scale Web apps, Websites and Mobile apps&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kroki.io"&gt;Kroki&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Creates diagrams from textual descriptions&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cmccandless/license-api/raw/master/README.md"&gt;License-API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial REST API for choosealicense.com&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://logs.to/"&gt;Logs.to&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate logs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://lua-decompiler.ferib.dev/"&gt;Lua Decompiler&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online Lua 5.1 Decompiler&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://macaddress.io/api"&gt;MAC address vendor lookup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve vendor details and other information regarding a given MAC address or an OUI&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://m3o.com/db"&gt;Micro DB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple database service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://microenv.com/"&gt;MicroENV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fake Rest API for developers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://designer.mocky.io/"&gt;Mocky&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mock user defined test JSON for REST API endpoints&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.myip.com/api-docs/"&gt;MY IP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get IP address information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nationalize.io"&gt;Nationalize.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Estimate the nationality of a first name&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.netlify.com/api/get-started/"&gt;Netlify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Netlify is a hosting service for the programmable web&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://networkcalc.com/api/docs"&gt;NetworkCalc&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Network calculators, including subnets, DNS, binary, and security tools&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/npm/registry/raw/master/docs/REGISTRY-API.md"&gt;npm Registry&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query information about your favorite Node.js libraries programatically&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documentation.onesignal.com/docs/onesignal-api"&gt;OneSignal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Self-serve customer engagement solution for Push Notifications, Email, SMS &amp;amp; In-App&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.domcop.com/openpagerank/"&gt;Open Page Rank&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for calculating and comparing metrics of different websites using Page Rank algorithm&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hub.openapihub.com/"&gt;OpenAPIHub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The All-in-one API Platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opengraphr.com/docs/1.0/overview"&gt;OpenGraphr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Really simple API to retrieve Open Graph data from an URL&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://oyyi.xyz/docs/1.0"&gt;oyyi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for Fake Data, image/video conversion, optimization, pdf optimization and thumbnail generation&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pagecdn.com/docs/public-api"&gt;PageCDN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public API for javascript, css and font libraries on PageCDN&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.postman.com/postman/workspace/postman-public-workspace/documentation/12959542-c8142d51-e97c-46b6-bd77-52bb66712c9a"&gt;Postman&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tool for testing APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://proxycrawl.com"&gt;ProxyCrawl&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Scraping and crawling anticaptcha service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://proxykingdom.com"&gt;ProxyKingdom&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rotating Proxy API that produces a working proxy on every request&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pusher.com/beams"&gt;Pusher Beams&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Push notifications for Android &amp;amp; iOS&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.qrtag.net/api/"&gt;QR code&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create an easy to read QR code and URL shortener&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://goqr.me/api/"&gt;QR code&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate and decode / read QR code graphics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.qrcode-monkey.com/qr-code-api-with-logo/"&gt;Qrcode Monkey&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrate custom and unique looking QR codes into your system or workflow&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quickchart.io/"&gt;QuickChart&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate chart and graph images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-docs.pgamerx.com/"&gt;Random Stuff&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Can be used to get AI Response, jokes, memes, and much more at lightning-fast speed&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rejax.io/"&gt;Rejax&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Reverse AJAX service to notify clients&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://reqres.in/"&gt;ReqRes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A hosted REST-API ready to respond to your AJAX requests&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rss-to-json-serverless-api.vercel.app"&gt;RSS feed to JSON&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Returns RSS feed in JSON format using feed URL&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.savepage.io"&gt;SavePage.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A free, RESTful API used to screenshot any desktop, or mobile website&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://scrapeninja.net"&gt;ScrapeNinja&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Scraping API with Chrome fingerprint and residential proxies&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.scraperapi.com"&gt;ScraperApi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily build scalable web scrapers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://scraperbox.com/"&gt;scraperBox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Undetectable web scraping API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://scrapestack.com/"&gt;scrapestack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time, Scalable Proxy &amp;amp; Web Scraping REST API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://scrapingant.com"&gt;ScrapingAnt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Headless Chrome scraping with a simple API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.scrapingdog.com/"&gt;ScrapingDog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Proxy API for Web scraping&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://screenshotapi.net/"&gt;ScreenshotAPI.net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create pixel-perfect website screenshots&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://color.serialif.com/"&gt;Serialif Color&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Color conversion, complementary, grayscale and contrasted text&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://serpstack.com/"&gt;serpstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time &amp;amp; Accurate Google Search Results API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sheetsu.com/"&gt;Sheetsu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easy google sheets integration&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://shoutcloud.io/"&gt;SHOUTCLOUD&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ALL-CAPS AS A SERVICE&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Cgboal/SonarSearch"&gt;Sonar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Project Sonar DNS Enumeration API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sonarcloud.io/web_api"&gt;SonarQube&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SonarQube REST APIs to detect bugs, code smells &amp;amp; security vulnerabilities&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.stackexchange.com/"&gt;StackExchange&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Q&amp;amp;A forum for developers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://statically.io/"&gt;Statically&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A free CDN for developers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.supportivekoala.com/"&gt;Supportivekoala&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Autogenerate images with template&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tyk.io/open-source/"&gt;Tyk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Api and service management platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/melpon/wandbox/raw/master/kennel2/API.rst"&gt;Wandbox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Code compiler supporting 35+ languages mentioned at wandbox.org&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://webscraping.ai/"&gt;WebScraping.AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web Scraping API with built-in proxies and JS rendering&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.zenrows.com/"&gt;ZenRows&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web Scraping API that bypasses anti-bot solutions while offering JS rendering, and rotating proxies&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Dictionaries&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://ccdb.hemiola.com/"&gt;Chinese Character Web&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chinese character definitions and pronunciations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ctext.org/tools/api"&gt;Chinese Text Project&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online open-access digital library for pre-modern Chinese texts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.collinsdictionary.com/api/v1/documentation/html/"&gt;Collins&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bilingual Dictionary and Thesaurus Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dictionaryapi.dev/"&gt;Free Dictionary&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Definitions, phonetics, pronounciations, parts of speech, examples, synonyms&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://new-kbbi-api.herokuapp.com/"&gt;Indonesia Dictionary&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Indonesia dictionary many words&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.linguarobot.io"&gt;Lingua Robot&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Word definitions, pronunciations, synonyms, antonyms and others&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dictionaryapi.com/"&gt;Merriam-Webster&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dictionary and Thesaurus Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://owlbot.info/"&gt;OwlBot&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Definitions with example sentence and photo if available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.oxforddictionaries.com/"&gt;Oxford&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dictionary Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.synonyms.com/synonyms_api.php"&gt;Synonyms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Synonyms, thesaurus and antonyms information for any given word&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://en.wiktionary.org/w/api.php"&gt;Wiktionary&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Collaborative dictionary data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.wordnik.com"&gt;Wordnik&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dictionary Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.wordsapi.com/docs/"&gt;Words&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Definitions and synonyms for more than 150,000 words&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Documents &amp;amp; Productivity&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://airtable.com/api"&gt;Airtable&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrate with Airtable&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.api2convert.com/"&gt;Api2Convert&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online File Conversion API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pdflayer.com"&gt;apilayer pdflayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTML/URL to PDF&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.asana.com/docs"&gt;Asana&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Programmatic access to all data in your asana system&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://clickup.com/api"&gt;ClickUp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ClickUp is a robust, cloud-based project management tool for boosting productivity&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://clockify.me/developers-api"&gt;Clockify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Clockify's REST-based API can be used to push/pull data to/from it &amp;amp; integrate it with other systems&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloudconvert.com/api/v2"&gt;CloudConvert&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online file converter for audio, video, document, ebook, archive, image, spreadsheet, presentation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloudmersive.com/convert-api"&gt;Cloudmersive Document and Data Conversion&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTML/URL to PDF/PNG, Office documents to PDF, image conversion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://codestats.net/api-docs"&gt;Code::Stats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automatic time tracking for programmers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://craftmypdf.com"&gt;CraftMyPDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate PDF documents from templates with a drop-and-drop editor and a simple API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.flowdash.com/docs/api-introduction"&gt;Flowdash&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automate business workflows&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://html2pdf.app/"&gt;Html2PDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTML/URL to PDF&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.ilovepdf.com/"&gt;iLovePDF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Convert, merge, split, extract text and add page numbers for PDFs. Free for 250 documents/month&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.atlassian.com/server/jira/platform/rest-apis/"&gt;JIRA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JIRA is a proprietary issue tracking product that allows bug tracking and agile project management&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.mattermost.com/"&gt;Mattermost&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An open source platform for developer collaboration&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mercury.postlight.com/web-parser/"&gt;Mercury&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web parser&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.developer.monday.com/docs"&gt;Monday&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Programmatically access and update data inside a monday.com account&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.notion.com/docs/getting-started"&gt;Notion&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrate with Notion&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.pandadoc.com"&gt;PandaDoc&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;DocGen and eSignatures API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://getpocket.com/developer/"&gt;Pocket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bookmarking service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.podio.com"&gt;Podio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;File sharing and productivity&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://prexview.com"&gt;PrexView&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data from XML or JSON to PDF, HTML or Image&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://restpack.io/"&gt;Restpack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides screenshot, HTML to PDF and content extraction APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.todoist.com"&gt;Todoist&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Todo Lists&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apilayer.com/marketplace/image_enhancement-api"&gt;Smart Image Enhancement API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Performs image upscaling by adding detail to images through multiple super-resolution algorithms&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://vector.express"&gt;Vector Express v2.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free vector file converting API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wakatime.com/developers"&gt;WakaTime&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automated time tracking leaderboards for programmers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://zube.io/docs/api"&gt;Zube&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Full stack project management&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Email&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mailboxlayer.com"&gt;apilayer mailboxlayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Email address validation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abstractapi.com/email-verification-validation-api"&gt;Email Validation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate email addresses for deliverability and spam&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloudmersive.com/validate-api"&gt;Cloudmersive Validate&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate email addresses, phone numbers, VAT numbers and domain names&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.disify.com/"&gt;Disify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate and detect disposable and temporary email addresses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dropmail.me/api/#live-demo"&gt;DropMail&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GraphQL API for creating and managing ephemeral e-mail inboxes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://eva.pingutil.com/"&gt;EVA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate email addresses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.guerrillamail.com/GuerrillaMailAPI.html"&gt;Guerrilla Mail&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Disposable temporary Email addresses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://improvmx.com/api"&gt;ImprovMX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for free email forwarding service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.kickbox.com/"&gt;Kickbox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Email verification API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mail.gw"&gt;mail.gw&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;10 Minute Mail&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mail.tm"&gt;mail.tm&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Temporary Email Service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mailboxvalidator.com/api-email-free"&gt;MailboxValidator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate email address to improve deliverability&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mailcheck.ai/#documentation"&gt;MailCheck.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prevent users to sign up with temporary email addresses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mailtrap.docs.apiary.io/#"&gt;Mailtrap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A service for the safe testing of emails sent from the development and staging environments&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.sendgrid.com/api-reference/"&gt;Sendgrid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A cloud-based SMTP provider that allows you to send emails without having to maintain email servers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.sendinblue.com/docs"&gt;Sendinblue&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A service that provides solutions relating to marketing and/or transactional email and/or SMS&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://verifier.meetchopra.com/docs#/"&gt;Verifier&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Verifies that a given email is real&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Entertainment&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.chucknorris.io"&gt;chucknorris.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JSON API for hand curated Chuck Norris jokes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/sameerkumar18/corporate-bs-generator-api"&gt;Corporate Buzz Words&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for Corporate Buzz Words&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://excuser.herokuapp.com/"&gt;Excuser&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get random excuses for various situations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.aakhilv.me"&gt;Fun Fact&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple HTTPS api that can randomly select and return a fact from the FFA database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://imgflip.com/api"&gt;Imgflip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gets an array of popular memes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mememaker.github.io/API/"&gt;Meme Maker&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for create your own meme&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/theIYD/NaMoMemes"&gt;NaMoMemes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Memes on Narendra Modi&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://uselessfacts.jsph.pl/"&gt;Random Useless Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get useless, but true facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://techy-api.vercel.app/"&gt;Techy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JSON and Plaintext API for tech-savvy sounding phrases&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/beanboi7/yomomma-apiv2"&gt;Yo Momma Jokes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for Yo Momma Jokes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Environment&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.breezometer.com/api-documentation/pollen-api/v2/"&gt;BreezoMeter Pollen&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Daily Forecast pollen conditions data for a specific location&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.carboninterface.com/"&gt;Carbon Interface&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to calculate carbon (C02) emissions estimates for common C02 emitting activities&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.climatiq.io"&gt;Climatiq&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Calculate the environmental footprint created by a broad range of emission-generating activities&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cloverly.com/carbon-offset-documentation"&gt;Cloverly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API calculates the impact of common carbon-intensive activities in real time&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://co2offset.io/api.html"&gt;CO2 Offset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API calculates and validates the carbon footprint&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.energidataservice.dk/"&gt;Danish data service Energi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open energy data from Energinet to society&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gruenstromindex.de/"&gt;GrünstromIndex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Green Power Index for Germany (Grünstromindex/GSI)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.iqair.com/air-pollution-data-api"&gt;IQAir&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Air quality and weather data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-docs.luchtmeetnet.nl/"&gt;Luchtmeetnet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Predicted and actual air quality components for The Netherlands (RIVM)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.nationalgrideso.com/"&gt;National Grid ESO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open data from Great Britain’s Electricity System Operator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.openaq.org/"&gt;OpenAQ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open air quality data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pm25.lass-net.org/#apis"&gt;PM2.5 Open Data Portal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open low-cost PM2.5 sensor data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.pm25.in/api_doc"&gt;PM25.in&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Air quality of China&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.nrel.gov/docs/solar/pvwatts/v6/"&gt;PVWatts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Energy production photovoltaic (PV) energy systems&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://srpenergy-api-client-python.readthedocs.io/en/latest/api.html"&gt;Srp Energy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hourly usage energy report for Srp customers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://carbon-intensity.github.io/api-definitions/#carbon-intensity-api-v1-0-0"&gt;UK Carbon Intensity&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Official Carbon Intensity API for Great Britain developed by National Grid&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.websitecarbon.com/"&gt;Website Carbon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to estimate the carbon footprint of loading web pages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Events&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.eventbrite.com/platform/api/"&gt;Eventbrite&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find events&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://platform.seatgeek.com/"&gt;SeatGeek&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search events, venues and performers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://developer.ticketmaster.com/products-and-docs/apis/getting-started/"&gt;Ticketmaster&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search events, attractions, or venues&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Finance&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.abstractapi.com/vat-validation-rates-api"&gt;VAT Validation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate VAT numbers and calculate VAT rates&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aletheiaapi.com/"&gt;Aletheia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Insider trading data, earnings call analysis, financial statements, and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://alpaca.markets/docs/api-documentation/api-v2/market-data/alpaca-data-api-v2/"&gt;Alpaca&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime and historical market data on all US equities and ETFs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.alphavantage.co/"&gt;Alpha Vantage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime and historical stock data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://marketstack.com/"&gt;apilayer marketstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time, Intraday &amp;amp; Historical Market Data API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.bb.com.br/home"&gt;Banco do Brasil&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All Banco do Brasil financial transaction APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://apilayer.com/marketplace/bank_data-api"&gt;Bank Data API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Instant IBAN and SWIFT number validation across the globe&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.billplz.com/api"&gt;Billplz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Payment platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://binlist.net/"&gt;Binlist&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public access to a database of IIN/BIN information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://boleto.cloud/"&gt;Boleto.Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A api to generate boletos in Brazil&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://sandbox.developerhub.citi.com/api-catalog-list"&gt;Citi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All Citigroup account and statement data APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.econdb.com/api/"&gt;Econdb&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global macroeconomic data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://fiscaldata.treasury.gov/api-documentation/"&gt;Fed Treasury&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;U.S. Department of the Treasury Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://finage.co.uk"&gt;Finage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Finage is a stock, currency, cryptocurrency, indices, and ETFs real-time &amp;amp; historical data provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://site.financialmodelingprep.com/developer/docs"&gt;Financial Modeling Prep&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime and historical stock data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://finnhub.io/docs/api"&gt;Finnhub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time RESTful APIs and Websocket for Stocks, Currencies, and Crypto&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://fred.stlouisfed.org/docs/api/fred/"&gt;FRED&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Economic data from the Federal Reserve Bank of St. Louis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://frontaccounting.com/fawiki/index.php?n=Devel.SimpleAPIModule"&gt;Front Accounting APIs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Front accounting is multilingual and multicurrency software for small businesses&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hotstoks.com?utm_source=public-apis"&gt;Hotstoks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stock market data powered by SQL&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://iexcloud.io/docs/api/"&gt;IEX Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime &amp;amp; Historical Stock and Market Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://labs.ig.com/gettingstarted"&gt;IG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Spreadbetting and CFD Market Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.mfapi.in/"&gt;Indian Mutual Fund&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get complete history of India Mutual Funds Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://intrinio.com/"&gt;Intrinio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A wide selection of financial data feeds&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.klarna.com/klarna-payments/api/payments-api/"&gt;Klarna&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Klarna payment and shopping service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.mercadopago.com.br/developers/es/reference"&gt;MercadoPago&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mercado Pago API reference - all the information you need to develop your integrations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mono.co/"&gt;Mono&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Connect with users’ bank accounts and access transaction data in Africa&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.moov.io/api/"&gt;Moov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Moov API makes it simple for platforms to send, receive, and store money&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://nordigen.com/en/account_information_documenation/integration/quickstart_guide/"&gt;Nordigen&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Connect to bank accounts using official bank APIs and get raw transaction data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.openfigi.com/api"&gt;OpenFIGI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Equity, index, futures, options symbology from Bloomberg LP&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.plaid.com/docs"&gt;Plaid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Connect with user's bank accounts and access transaction data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;YES&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://polygon.io/"&gt;Polygon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Historical stock market data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://portfoliooptimizer.io/"&gt;Portfolio Optimizer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Portfolio analysis and optimization&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://razorpay.com/docs/"&gt;Razorpay IFSC&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Indian Financial Systems Code (Bank Branch Codes)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Real-time-finance/finance-websocket-API/"&gt;Real Time Finance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Websocket API to access realtime stock data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.sec.gov/edgar/sec-api-documentation"&gt;SEC EDGAR Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to access annual reports of public US companies&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://smartapi.angelbroking.com/"&gt;SmartAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gain access to set of 
    &lt;smartapi&gt;
      and create end-to-end broking services
    &lt;/smartapi&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.StockData.org"&gt;StockData&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time, Intraday &amp;amp; Historical Market Data, News and Sentiment API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.Styvio.com"&gt;Styvio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime and historical stock data and current stock sentiment&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://apilayer.com/marketplace/tax_data-api"&gt;Tax Data API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Instant VAT number and tax validation across the globe&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unkown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.tradier.com"&gt;Tradier&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US equity/option market data (delayed, intraday, historical)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twelvedata.com/"&gt;Twelve Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stock market data (real-time &amp;amp; historical)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://dashboard.nbshare.io/apps/reddit/api/"&gt;WallstreetBets&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;WallstreetBets Stock Comments Sentiment Analysis&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.yahoofinanceapi.com/"&gt;Yahoo Finance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real time low latency Yahoo Finance API for stock market, crypto currencies, and currency exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.youneedabudget.com/"&gt;YNAB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Budgeting &amp;amp; Planning&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.zoho.com/books/api/v3/"&gt;Zoho Books&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online accounting software, built for your business&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Food &amp;amp; Drink&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://baconmockup.com/"&gt;BaconMockup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Resizable bacon placeholder images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://chompthis.com/api/"&gt;Chomp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data about various grocery products and foods&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coffee.alexflipnote.dev/"&gt;Coffee&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of coffee&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.edamam.com/edamam-docs-nutrition-api"&gt;Edamam nutrition&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nutrition Analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.edamam.com/edamam-docs-recipe-api"&gt;Edamam recipes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Recipe Search&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/surhud004/Foodish#readme"&gt;Foodish&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random pictures of food dishes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.fruityvice.com"&gt;Fruityvice&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data about all kinds of fruit&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.kroger.com/reference"&gt;Kroger&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Supermarket Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://lcboapi.com/"&gt;LCBO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Alcohol&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.openbrewerydb.org"&gt;Open Brewery DB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Breweries, Cideries and Craft Beer Bottle Shops&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://world.openfoodfacts.org/data"&gt;Open Food Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Food Products Database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://punkapi.com/"&gt;PunkAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brewdog Beer Recipes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rustybeer.herokuapp.com/"&gt;Rustybeer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Beer brewing tools&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://spoonacular.com/food-api"&gt;Spoonacular&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Recipes, Food Products, and Meal Planning&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-portal.systembolaget.se"&gt;Systembolaget&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Govornment owned liqour store in Sweden&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/evz/tacofancy-api"&gt;TacoFancy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Community-driven taco database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/apidojo/api/tasty/"&gt;Tasty&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to query data about recipe, plan, ingredients&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/andyklimczak/TheReportOfTheWeek-API"&gt;The Report of the Week&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Food &amp;amp; Drink Reviews&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.thecocktaildb.com/api.php"&gt;TheCocktailDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cocktail Recipes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.themealdb.com/api.php"&gt;TheMealDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Meal Recipes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://untappd.com/api/docs"&gt;Untappd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Social beer sharing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://nypl.github.io/menus-api/"&gt;What's on the menu?&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NYPL human-transcribed historical menu collection&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://whiskyhunter.net/api/"&gt;WhiskyHunter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Past online whisky auctions statistical data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://zestfuldata.com/"&gt;Zestful&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Parse recipe ingredients&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Games &amp;amp; Comics&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://age-of-empires-2-api.herokuapp.com"&gt;Age of Empires II&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information about Age of Empires II resources&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://amiiboapi.com/"&gt;AmiiboAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nintendo Amiibo Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://acnhapi.com/"&gt;Animal Crossing: New Horizons&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for critters, fossils, art, music, furniture and villagers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/didadadida93/autochess-vng-api"&gt;Autochess VNG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rest Api for Autochess VNG&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/bartervg/barter.vg/wiki"&gt;Barter.VG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides information about Game, DLC, Bundles, Giveaways, Trading&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://develop.battle.net/documentation/guides/getting-started"&gt;Battle.net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Diablo III, Hearthstone, StarCraft II and World of Warcraft game data APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://boardgamegeek.com/wiki/page/BGG_XML_API2"&gt;Board Game Geek&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Board games, RPG and videogames&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.brawlstars.com"&gt;Brawl Stars&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brawl Stars Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bugsnaxapi.com/"&gt;Bugsnax&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information about Bugsnax&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cheapshark.com/api"&gt;CheapShark&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Steam/PC Game Prices and Deals&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.chess.com/news/view/published-data-api"&gt;Chess.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chess.com read-only REST API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.icndb.com/api/"&gt;Chuck Norris Database&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Jokes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.clashofclans.com"&gt;Clash of Clans&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Clash of Clans Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.clashroyale.com"&gt;Clash Royale&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Clash Royale Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://comicvine.gamespot.com/api/documentation"&gt;Comic Vine&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Comics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crafatar.com"&gt;Crafatar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for Minecraft skins and faces&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crossuniverse.psychpsyo.com/apiDocs.html"&gt;Cross Universe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cross Universe Card Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://deckofcardsapi.com/"&gt;Deck of Cards&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Deck of Cards&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bungie-net.github.io/multi/index.html"&gt;Destiny The Game&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bungie Platform API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://digimon-api.vercel.app/"&gt;Digimon Information&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides information about digimon creatures&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/14059948/TzecB4fH"&gt;Digimon TCG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search for Digimon cards in digimoncard.io&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://disneyapi.dev"&gt;Disney&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Information of Disney characters&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.opendota.com/"&gt;Dota 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides information about Player stats , Match stats, Rankings for Dota 2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.dnd5eapi.co/docs/"&gt;Dungeons and Dragons&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Reference for 5th edition spells, classes, monsters, and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open5e.com/"&gt;Dungeons and Dragons (Alternate)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Includes all monsters and spells from the SRD (System Reference Document) as well as a search API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://esi.evetech.net/ui"&gt;Eve Online&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Third-Party Developer Documentation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ffxivcollect.com/"&gt;FFXIV Collect&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Final Fantasy XIV data on collectables&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.easports.com/fifa/ultimate-team/api/fut/item"&gt;FIFA Ultimate Team&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;FIFA Ultimate Team items API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://xivapi.com/"&gt;Final Fantasy XIV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Final Fantasy XIV Game data API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fortnitetracker.com/site-api"&gt;Fortnite&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fortnite Stats&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.forza-api.tk"&gt;Forza&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Show random image of car from Forza&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.freetogame.com/api-doc"&gt;FreeToGame&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free-To-Play Games Database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://asli-fun-fact-api.herokuapp.com/"&gt;Fun Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random Fun Facts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.funtranslations.com/"&gt;FunTranslations&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Translate Text into funny languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.gamerpower.com/api-read"&gt;GamerPower&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Game Giveaways Tracker&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gdbrowser.com/api"&gt;GDBrowser&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easy way to use the Geometry Dash Servers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/sameerkumar18/geek-joke-api"&gt;Geek-Jokes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fetch a random geeky/programming related joke for use in all sorts of applications&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://genshin.dev"&gt;Genshin Impact&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Genshin Impact game data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.giantbomb.com/api/documentation"&gt;Giant Bomb&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Video Games&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/favware/graphql-pokemon"&gt;GraphQL Pokemon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GraphQL powered Pokemon API. Supports generations 1 through 8&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wiki.guildwars2.com/wiki/API:Main"&gt;Guild Wars 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Guild Wars 2 Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/rubensayshi/gw2spidy/wiki"&gt;GW2Spidy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GW2Spidy API, Items data on the Guild Wars 2 Trade Market&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.haloapi.com/"&gt;Halo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Halo 5 and Halo Wars 2 Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://hearthstoneapi.com/"&gt;Hearthstone&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hearthstone Cards Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/Ziggoto/api/humble-bundle"&gt;Humble Bundle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Humble Bundle's current bundles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://humorapi.com"&gt;Humor&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Humor, Jokes, and Memes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.hypixel.net/"&gt;Hypixel&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hypixel player stats&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/gadhagod/Hyrule-Compendium-API"&gt;Hyrule Compendium&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data on all interactive items from The Legend of Zelda: BOTW&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hytale-api.com/"&gt;Hytale&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hytale blog posts and jobs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-docs.igdb.com"&gt;IGDB.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Video Game Database&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sv443.net/jokeapi/v2/"&gt;JokeAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Programming, Miscellaneous and Dark Jokes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://jokes.one/api/joke/"&gt;Jokes One&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Joke of the day and large category of jokes accessible via REST API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://jservice.io"&gt;Jservice&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Jeopardy Question Database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://lichess.org/api"&gt;Lichess&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to all data of users, games, puzzles and etc on Lichess&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://magicthegathering.io/"&gt;Magic The Gathering&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Magic The Gathering Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mario-kart-tour-api.herokuapp.com/"&gt;Mario Kart Tour&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for Drivers, Karts, Gliders and Courses&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.marvel.com"&gt;Marvel&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Marvel Comics&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.mcsrvstat.us"&gt;Minecraft Server Status&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to get Information about a Minecraft Server&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mmobomb.com/api"&gt;MMO Games&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;MMO Games Database, News and Giveaways&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mod.io"&gt;mod.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cross Platform Mod API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wiki.vg/Mojang_API"&gt;Mojang&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mojang / Minecraft API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mhw-db.com/"&gt;Monster Hunter World&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Monster Hunter World data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opentdb.com/api_config.php"&gt;Open Trivia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Trivia Questions&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.pandascore.co/"&gt;PandaScore&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;E-sports games and results&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.pathofexile.com/developer/docs"&gt;Path of Exile&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Path of Exile Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://playerdb.co/"&gt;PlayerDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query Minecraft, Steam and XBox Accounts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pokeapi.co"&gt;Pokéapi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pokémon Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mazipan/graphql-pokeapi"&gt;PokéAPI (GraphQL)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Unofficial GraphQL for PokeAPI&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pokemontcg.io"&gt;Pokémon TCG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pokémon TCG Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://psychonauts-api.netlify.app/"&gt;Psychonauts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Psychonauts World Characters Information and PSI Powers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.pubg.com/"&gt;PUBG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access in-game PUBG data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/deltadex7/puyodb-api-deno"&gt;Puyo Nexus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Puyo Puyo information from Puyo Nexus Wiki&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quizapi.io/"&gt;quizapi.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to various kind of quiz questions&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raider.io/api"&gt;Raider&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides detailed character and guild rankings for Raiding and Mythic+ content in World of Warcraft&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rawg.io/apidocs"&gt;RAWG.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500,000+ games for 50 platforms including mobiles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rickandmortyapi.com"&gt;Rick and Morty&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All the Rick and Morty information, including images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.riotgames.com/"&gt;Riot Games&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;League of Legends Game Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rps101.pythonanywhere.com/api"&gt;RPS 101&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rock, Paper, Scissors with 101 objects&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://runescape.wiki/w/Application_programming_interface"&gt;RuneScape&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RuneScape and OSRS RPGs information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/JessVel/sakura-card-captor-api"&gt;Sakura CardCaptor&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sakura CardCaptor Cards Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://scryfall.com/docs/api"&gt;Scryfall&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Magic: The Gathering database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://spacetraders.io?rel=pub-apis"&gt;SpaceTradersAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A playable inter-galactic space trading MMOAPI&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://steamapi.xpaw.me/"&gt;Steam&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Steam Web API documentation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Revadike/InternalSteamWebAPI/wiki"&gt;Steam&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Internal Steam Web API documentation&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://superheroapi.com"&gt;SuperHeroes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All SuperHeroes and Villains data from all universes under a single API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.tcgdex.net/docs"&gt;TCGdex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Multi languages Pokémon TCG Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.tebex.io/plugin/"&gt;Tebex&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tebex API for information about game purchases&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tetr.io/about/api/"&gt;TETR.IO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TETR.IO Tetra Channel API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.tronalddump.io/"&gt;Tronald Dump&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The dumbest things Donald Trump has ever said&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://universalis.app/docs/index.html"&gt;Universalis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Final Fantasy XIV market board data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://valorant-api.com"&gt;Valorant (non-official)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An extensive API containing data of most Valorant in-game items, assets and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.wfstats.cf"&gt;Warface (non-official)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Official API proxy with better data structure and more features&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.wargaming.net/"&gt;Wargaming.net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Wargaming.net info and stats&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/DiljotSG/MCU-Countdown/raw/develop/docs/API.md"&gt;When is next MCU film&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Upcoming MCU film information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://xkcd.com/json.html"&gt;xkcd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve xkcd comics as JSON&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://db.ygoprodeck.com/api-guide/"&gt;Yu-Gi-Oh!&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yu-Gi-Oh! TCG Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Geocoding&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abstractapi.com/ip-geolocation-api"&gt;IP Geolocation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Geolocate website visitors from their IPs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://actinia.mundialis.de/api_docs/"&gt;Actinia Grass GIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Actinia is an open source REST API for geographical data that uses GRASS GIS&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/kamikazechaser/administrative-divisions-db"&gt;administrative-divisons-db&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get all administrative divisions of a country&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://adresse.data.gouv.fr"&gt;adresse.data.gouv.fr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Address database of France, geocoding and reverse&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sys.airtel.lv/ip2country/1.1.1.1/?full=true"&gt;Airtel IP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP Geolocation API. Collecting data from multiple sources&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apiip.net/"&gt;Apiip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get location information by IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipstack.com/"&gt;apilayer ipstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Locate and identify website visitors by IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://battuta.medunes.net"&gt;Battuta&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A (country/region/city) in-cascade location API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bigdatacloud.com/ip-geolocation-apis"&gt;BigDataCloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides fast and accurate IP geolocation APIs along with security checks and confidence area&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.microsoft.com/maps/"&gt;Bing Maps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create/customize digital maps based on Bing Maps data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.getthedata.com/bng2latlong"&gt;bng2latlong&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Convert British OSGB36 easting and northing (British National Grid) to WGS84 latitude and longitude&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/M-Media-Group/Cartes.io/wiki/API"&gt;Cartes.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create maps and markers for anything&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://cep.la/"&gt;Cep.la&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brazil RESTful API to find information about streets, zip codes, neighborhoods, cities and states&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.citysdk.eu/citysdk-toolkit/"&gt;CitySDK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open APIs for select European cities&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://country.is/"&gt;Country&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get your visitor's country from their IP&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://countrystatecity.in/"&gt;CountryStateCity&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;World countries, states, regions, provinces, cities &amp;amp; towns in JSON, SQL, XML, YAML, &amp;amp; CSV format&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gis.ducks.org/datasets/du-university-chapters/api"&gt;Ducks Unlimited&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API explorer that gives a query URL with a JSON response of locations and cities&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.gouv.fr/api/geoapi.html"&gt;GeoApi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;French geographical data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.geoapify.com/api/geocoding-api/"&gt;Geoapify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Forward and reverse geocoding, address autocomplete&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.geocod.io/"&gt;Geocod.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Address geocoding / reverse geocoding in bulk&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geocode.xyz/api"&gt;Geocode.xyz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides worldwide forward/reverse geocoding, batch geocoding and geoparsing&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geocodify.com/"&gt;Geocodify.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Worldwide geocoding, geoparsing and autocomplete for addresses&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geodata.gov.gr/en/"&gt;Geodata.gov.gr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open geospatial data and API service for Greece&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.geodatasource.com/web-service"&gt;GeoDataSource&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Geocoding of city name by using latitude and longitude coordinates&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://geodb-cities-api.wirefreethought.com/"&gt;GeoDB Cities&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get global city, region, and country data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geographql.netlify.app"&gt;GeographQL&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A Country, State, and City GraphQL API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.geojs.io/"&gt;GeoJS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP geolocation with ChatOps integration&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geokeo.com"&gt;Geokeo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Geokeo geocoding service- with 2500 free api requests daily&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.geonames.org/export/web-services.html"&gt;GeoNames&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Place names and other geographical data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.geoplugin.com"&gt;geoPlugin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP geolocation and currency conversion&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/earth-engine/"&gt;Google Earth Engine&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A cloud-based platform for planetary-scale environmental data analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/maps/"&gt;Google Maps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create/customize digital maps based on Google Maps data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/lennertVanSever/graphcountries"&gt;Graph Countries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Country-related data like currencies, languages, flags, regions+subregions and bordering countries&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fourtonfish.com/project/hellosalut-api/"&gt;HelloSalut&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get hello translation following user language&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.here.com"&gt;HERE Maps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create/customize digital maps based on HERE Maps data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://iplocation.hirak.site/"&gt;Hirak IP to Country&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ip to location with country code, currency code &amp;amp; currency name, fast response, unlimited requests&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geodata.gov.hk/gs/"&gt;Hong Kong GeoData Store&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for accessing geo-data of Hong Kong&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://servicodados.ibge.gov.br/api/docs/"&gt;IBGE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Aggregate services of IBGE (Brazilian Institute of Geography and Statistics)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ip2country.info"&gt;IP 2 Country&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Map an IP to a country&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipinfo.io/"&gt;IP Address Details&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find geolocation with ip address&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ipvigilante.com/"&gt;IP Vigilante&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free IP Geolocation API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ip-api.com/docs"&gt;ip-api&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find location with IP address or domain&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ip2location.com/web-service/ip2location"&gt;IP2Location&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP geolocation web service to get more than 55 parameters&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ip2location.com/web-service/ip2proxy"&gt;IP2Proxy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Detect proxy and VPN using IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipapi.co/api/#introduction"&gt;ipapi.co&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find IP address location information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipapi.com/"&gt;ipapi.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time Geolocation &amp;amp; Reverse IP Lookup REST API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.techniknews.net/ipgeo/"&gt;IPGEO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unlimited free IP Address API with useful information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipgeolocation.io/"&gt;ipgeolocation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;IP Geolocation AP with free plan 30k requests per month&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ipinfodb.com/api"&gt;IPInfoDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Geolocation tools and APIs for country, region, city and time zone lookup by IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ipstack.com/"&gt;ipstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Locate and identify website visitors by IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apis.map.kakao.com"&gt;Kakao Maps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Kakao Maps provide multiple APIs for Korean maps&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tools.keycdn.com/geo"&gt;keycdn IP Location Finder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get the IP geolocation data through the simple REST API. All the responses are JSON encoded&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://locationiq.org/docs/"&gt;LocationIQ&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides forward/reverse geocoding and batch geocoding&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://map.longdo.com/docs/"&gt;Longdo Map&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Interactive map with detailed places and information portal in Thailand&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mapbox.com/"&gt;Mapbox&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create/customize beautiful digital maps&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.mapquest.com/"&gt;MapQuest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;To access tools and resources to map the world&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/IcaliaLabs/sepomex"&gt;Mexico&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mexico RESTful zip codes API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nominatim.org/release-docs/latest/api/Overview/"&gt;Nominatim&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides worldwide forward / reverse geocoding&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.onemap.gov.sg/docs/"&gt;One Map, Singapore&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Singapore Land Authority REST API services for Singapore addresses&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://onwater.io/"&gt;OnWater&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Determine if a lat/lon is on water or land&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.opentopodata.org"&gt;Open Topo Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Elevation and ocean depth for a latitude and longitude&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opencagedata.com"&gt;OpenCage&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Forward and reverse geocoding using open data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openrouteservice.org/"&gt;openrouteservice.org&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Directions, POIs, isochrones, geocoding (+reverse), elevation, and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://wiki.openstreetmap.org/wiki/API"&gt;OpenStreetMap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Navigation, geolocation and geographical data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pinballmap.com/api/v1/docs"&gt;Pinball Map&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A crowdsourced map of public pinball machines&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://positionstack.com/"&gt;positionstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Forward &amp;amp; Reverse Batch Geocoding REST API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://postali.app/api"&gt;Postali&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mexico Zip Codes API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.postcodedata.nl/v1/postcode/?postcode=1211EP&amp;amp;streetnumber=60&amp;amp;ref=domeinnaam.nl&amp;amp;type=json"&gt;PostcodeData.nl&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide geolocation data based on postcode for Dutch addresses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://postcodes.io"&gt;Postcodes.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Postcode lookup &amp;amp; Geolocation for the UK&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://queimadas.dgi.inpe.br/queimadas/dados-abertos/"&gt;Queimadas INPE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to heat focus data (probable wildfire)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://restcountries.com"&gt;REST Countries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information about countries via a RESTful API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.roadgoat.com/business/cities-api"&gt;RoadGoat Cities&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cities content &amp;amp; photos API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/victorkarangwa4/api/rwanda"&gt;Rwanda Locations&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rwanda Provences, Districts, Cities, Capital City, Sector, cells, villages and streets&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/slftool/slftool.github.io/raw/master/API.md"&gt;SLF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;German city, country, river, database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://spotsense.io/"&gt;SpotSense&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Add location based interactions to your mobile app&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/fcambus/api/telize/"&gt;Telize&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Telize offers location information from any IP address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.tomtom.com/"&gt;TomTom&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maps, Directions, Places and Traffic APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://uebermaps.com/api/v2"&gt;Uebermaps&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Discover and share maps with friends&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.smarty.com/docs/cloud/us-zipcode-api"&gt;US ZipCode&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate and append data for any US ZipCode&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.mapserv.utah.gov"&gt;Utah AGRC&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Utah Web API for geocoding Utah addresses&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://viacep.com.br"&gt;ViaCep&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brazil RESTful zip codes API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://what3words.com"&gt;What3Words&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Three words as rememberable and unique coordinates worldwide&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://yandex.com/dev/maps/geocoder"&gt;Yandex.Maps Geocoder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Use geocoding to get an object's coordinates from its address&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.zipcodeapi.com"&gt;ZipCodeAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US zip code distance, radius and location API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.zippopotam.us"&gt;Zippopotam.us&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information about place such as country, city, state, etc&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ziptasticapi.com/"&gt;Ziptastic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get the country, state, and city of any US zip-code&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Government&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apikijangportal.bnm.gov.my/"&gt;Bank Negara Malaysia Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Malaysia Central Bank Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bclaws.gov.bc.ca/civix/template/complete/api/index.html"&gt;BCLaws&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to the laws of British Columbia&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://brasilapi.com.br/"&gt;Brazil&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Community driven API for Brazil Public Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dadosabertos.bcb.gov.br/"&gt;Brazil Central Bank Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brazil Central Bank Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.receitaws.com.br/"&gt;Brazil Receita WS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Consult companies by CNPJ for Brazilian companies&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dadosabertos.camara.leg.br/swagger/api.html"&gt;Brazilian Chamber of Deputies Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides legislative information in Apis XML and JSON, as well as files in various formats&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.census.gov/data/developers/data-sets.html"&gt;Census.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The US Census Bureau provides various APIs and data sets on demographics and businesses&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://daten.berlin.de/"&gt;City, Berlin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Berlin(DE) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ckan.multimediagdansk.pl/en"&gt;City, Gdańsk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gdańsk (PL) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://otwartedane.gdynia.pl/en/api_doc.html"&gt;City, Gdynia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gdynia (PL) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hri.fi/en_gb/"&gt;City, Helsinki&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Helsinki(FI) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.city-adm.lviv.ua/"&gt;City, Lviv&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Lviv(UA) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.nantesmetropole.fr/pages/home/"&gt;City, Nantes Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Nantes(FR) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.cityofnewyork.us/"&gt;City, New York Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;New York (US) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://opendata.praha.eu/en"&gt;City, Prague Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prague(CZ) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.toronto.ca/"&gt;City, Toronto Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Toronto (CA) City Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://code.gov"&gt;Code.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The primary platform for Open Source and code sharing for the U.S. Federal Government&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.colorado.gov/"&gt;Colorado Information Marketplace&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Colorado State Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datausa.io/about/api/"&gt;Data USA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US Public Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.data.gov/"&gt;Data.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US Government Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://explore.data.parliament.uk/?learnmore=Members"&gt;Data.parliament.uk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Contains live datasets including information about petitions, bills, MP votes, attendance and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dip.bundestag.de/documents/informationsblatt_zur_dip_api_v01.pdf"&gt;Deutscher Bundestag DIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;This API provides read access to DIP entities (e.g. activities, persons, printed material)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://opendata.dc.gov/pages/using-apis"&gt;District of Columbia Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Contains D.C. government public datasets, including crime, GIS, financial data, and so on&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.epa.gov/developers/data-data-products#apis"&gt;EPA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web services and data sets from the US Environmental Protection Agency&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.fbi.gov/wanted/api"&gt;FBI Wanted&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access information on the FBI Wanted program&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.open.fec.gov/developers/"&gt;FEC&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Information on campaign donations in federal elections&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.federalregister.gov/reader-aids/developer-resources/rest-api"&gt;Federal Register&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Daily Journal of the United States Government&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://ratings.food.gov.uk/open-data/en-GB"&gt;Food Standards Agency&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK food hygiene rating data API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.thegazette.co.uk/data"&gt;Gazette Data, UK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK official public record API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.gunpolicy.org/api"&gt;Gun Policy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;International firearm injury prevention and policy&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://iinei.inei.gob.pe/microdatos/"&gt;INEI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Peruvian Statistical Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://interpol.api.bund.dev/"&gt;Interpol Red Notices&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access and search Interpol Red Notices&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.ibb.gov.tr"&gt;Istanbul (İBB) Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data sets from the İstanbul Metropolitan Municipality (İBB)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.nps.gov/subjects/developer/"&gt;National Park Service, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data from the US National Park Service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.act.gov.au/"&gt;Open Government, ACT&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Australian Capital Territory Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datos.gob.ar/"&gt;Open Government, Argentina&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Argentina Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.gov.au/"&gt;Open Government, Australia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Australian Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.gv.at/"&gt;Open Government, Austria&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Austria Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.be/"&gt;Open Government, Belgium&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Belgium Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://open.canada.ca/en"&gt;Open Government, Canada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Canadian Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.dane.gov.co/"&gt;Open Government, Colombia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Colombia Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.cy/?language=en"&gt;Open Government, Cyprus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cyprus Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.cz/english/"&gt;Open Government, Czech Republic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Czech Republic Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.opendata.dk/"&gt;Open Government, Denmark&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Denmark Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://avaandmed.eesti.ee/instructions/opendata-dataset-api"&gt;Open Government, Estonia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Estonia Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.avoindata.fi/en"&gt;Open Government, Finland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Finland Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.gouv.fr/"&gt;Open Government, France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;French Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.govdata.de/daten/-/details/govdata-metadatenkatalog"&gt;Open Government, Germany&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Germany Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.gr/"&gt;Open Government, Greece&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Greece Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.in/"&gt;Open Government, India&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Indian Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.ie/pages/developers"&gt;Open Government, Ireland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ireland Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.dati.gov.it/"&gt;Open Government, Italy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Italy Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.go.kr/"&gt;Open Government, Korea&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Korea Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.lt/public/api/1"&gt;Open Government, Lithuania&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Lithuania Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.public.lu"&gt;Open Government, Luxembourg&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Luxembourgish Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.inegi.org.mx/datos/"&gt;Open Government, Mexico&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mexican Statistical Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datos.gob.mx/"&gt;Open Government, Mexico&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mexico Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.overheid.nl/en/ondersteuning/data-publiceren/api"&gt;Open Government, Netherlands&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Netherlands Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.nsw.gov.au/"&gt;Open Government, New South Wales&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;New South Wales Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.govt.nz/"&gt;Open Government, New Zealand&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;New Zealand Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.norge.no/dataservices"&gt;Open Government, Norway&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Norwegian Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.datosabiertos.gob.pe/"&gt;Open Government, Peru&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Peru Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dane.gov.pl/en"&gt;Open Government, Poland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Poland Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dados.gov.pt/en/docapi/"&gt;Open Government, Portugal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Portugal Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.qld.gov.au/"&gt;Open Government, Queensland Government&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Queensland Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://data.gov.ro/"&gt;Open Government, Romania&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Romania Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.sa"&gt;Open Government, Saudi Arabia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Saudi Arabia Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.sg/developer"&gt;Open Government, Singapore&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Singapore Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.sk/en/"&gt;Open Government, Slovakia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Slovakia Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://podatki.gov.si/"&gt;Open Government, Slovenia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Slovenia Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.sa.gov.au/"&gt;Open Government, South Australian Government&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;South Australian Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datos.gob.es/en"&gt;Open Government, Spain&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Spain Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.dataportal.se/en/dataservice/91_29789/api-for-the-statistical-database"&gt;Open Government, Sweden&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sweden Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://handbook.opendata.swiss/de/content/nutzen/api-nutzen.html"&gt;Open Government, Switzerland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Switzerland Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.tw/"&gt;Open Government, Taiwan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Taiwan Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.go.th/"&gt;Open Government, Thailand&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Thailand Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.gov.uk/"&gt;Open Government, UK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.gov/"&gt;Open Government, USA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;United States Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.data.vic.gov.au/"&gt;Open Government, Victoria State Government&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Victoria State Government Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.wa.gov.au/"&gt;Open Government, West Australia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;West Australia Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.whenisthenextboardexam.com/docs/"&gt;PRC Exam Schedule&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial Philippine Professional Regulation Commission's examination schedule&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://represent.opennorth.ca/"&gt;Represent by Open North&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find Canadian Government Representatives&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.company-information.service.gov.uk/"&gt;UK Companies House&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK Companies House Data from the UK government&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://uselection.togatech.org/api/"&gt;US Presidential Election Data by TogaTech&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Basic candidate data and live electoral vote counts for top two parties in US presidential election&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.usa.gov/developer"&gt;USA.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Authoritative information on U.S. programs, events, services and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.usaspending.gov/"&gt;USAspending.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US federal spending data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Health&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.cms.gov/provider-data/"&gt;CMS.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to the data from the CMS - medicare.gov&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pipedream.com/@pravin/http-api-for-latest-wuhan-coronavirus-data-2019-ncov-p_G6CLVM/readme"&gt;Coronavirus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP API for Latest Covid-19 Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coronavirus.data.gov.uk/details/developers-guide"&gt;Coronavirus in the UK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK Government coronavirus data, including deaths and cases by region&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://covidtracking.com/data/api/version-2"&gt;Covid Tracking Project&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Covid-19 data for the US&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://covid19api.com/"&gt;Covid-19&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Covid 19 spread, infection and recovery&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/M-Media-Group/Covid-19-API"&gt;Covid-19&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Covid 19 cases, deaths and recovery per country&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://npgeo-corona-npgeo-de.hub.arcgis.com"&gt;Covid-19 Datenhub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maps, datasets, applications and more in the context of COVID-19&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://covidtracker.bsg.ox.ac.uk"&gt;Covid-19 Government Response&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Government measures tracker to fight against the Covid-19 pandemic&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.covid19india.org/"&gt;Covid-19 India&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Covid 19 statistics state and district wise about cases, vaccinations, recovery within India&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nuttaphat.com/covid19-api/"&gt;Covid-19 JHU CSSE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open-source API for exploring Covid19 cases based on JHU CSSE&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mathdroid/covid-19-api"&gt;Covid-19 Live Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global and countrywise data of Covid 19 daily Summary, confirmed cases, recovered and deaths&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Simperfy/Covid-19-API-Philippines-DOH"&gt;Covid-19 Philippines&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial Covid-19 Web API for Philippines from data collected by DOH&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.covid19tracker.ca/docs/1.0/overview"&gt;COVID-19 Tracker Canada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Details on Covid-19 cases across Canada&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.hpb.health.gov.lk/en/api-documentation"&gt;COVID-19 Tracker Sri Lanka&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides situation of the COVID-19 patients reported in Sri Lanka&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.covid19.go.id/public/api/prov.json"&gt;COVID-ID&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Indonesian government Covid data per province&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://covid-19.dataflowkit.com"&gt;Dataflow Kit COVID-19&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;COVID-19 live statistics into sites per hour&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fdc.nal.usda.gov/"&gt;FoodData Central&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;National Nutrient Database for Standard Reference&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.healthcare.gov/developers/"&gt;Healthcare.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Educational content about the US Health Insurance Marketplace&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.humdata.org/"&gt;Humanitarian Data Exchange&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Humanitarian Data Exchange (HDX) is open platform for sharing data across crises and organisations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.infermedica.com/docs/"&gt;Infermedica&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NLP based symptom checker and patient triage API for health diagnosis from text&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cov-spectrum.ethz.ch/public"&gt;LAPIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SARS-CoV-2 genomic sequences from public sources&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.lexigram.io/"&gt;Lexigram&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NLP that extracts mentions of clinical concepts from text, gives access to clinical ontology&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://makeup-api.herokuapp.com/"&gt;Makeup&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Makeup Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/16605343/Tzm8GG7u"&gt;MyVaccination&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Vaccination data for Malaysia&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://npiregistry.cms.hhs.gov/registry/help-api"&gt;NPPES&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;National Plan &amp;amp; Provider Enumeration System, info on healthcare providers registered in US&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.nutritionix.com/"&gt;Nutritionix&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Worlds largest verified nutrition database&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.opendata.nhs.scot"&gt;Open Data NHS Scotland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Medical reference data and statistics by Public Health Scotland&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://disease.sh/"&gt;Open Disease&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for Current cases and more stuff about COVID-19 and Influenza&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.fda.gov"&gt;openFDA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public FDA data about drugs, devices and foods&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.orionhealth.io/"&gt;Orion Health&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Medical platform which allows the development of applications for different healthcare scenarios&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quarantine.country/coronavirus/api/"&gt;Quarantine&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Coronavirus API with free COVID-19 live updates&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Jobs&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.adzuna.com/overview"&gt;Adzuna&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job board aggregator&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://documenter.getpostman.com/view/18545278/UVJbJdKh"&gt;Arbeitnow&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for Job board aggregator in Europe / Remote&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://jobsuche.api.bund.dev/"&gt;Arbeitsamt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for the "Arbeitsamt", which is a german Job board aggregator&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.careerjet.com/partners/api/"&gt;Careerjet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job search engine&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://devitjobs.uk/job_feed.xml"&gt;DevITjobs UK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Jobs with GraphQL&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://findwork.dev/developers/"&gt;Findwork&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job board&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://graphql.jobs/docs/api/"&gt;GraphQL Jobs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Jobs with GraphQL&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.jobs2careers.com/api/spec.pdf"&gt;Jobs2Careers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job aggregator&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://jooble.org/api/about"&gt;Jooble&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job search engine&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.juju.com/publisher/spec/"&gt;Juju&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job search engine&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/workforce-data-initiative/skills-api/wiki/API-Overview"&gt;Open Skills&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job titles, skills and related jobs data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.reed.co.uk/developers"&gt;Reed&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job board aggregator&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.themuse.com/developers/api/v2"&gt;The Muse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job board and company profiles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.upwork.com/"&gt;Upwork&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Freelance job board and management system&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.usajobs.gov/"&gt;USAJOBS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US government job board&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.whatjobs.com/affiliates"&gt;WhatJobs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job search engine&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ziprecruiter.com/publishers"&gt;ZipRecruiter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Job search app and website&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Machine Learning&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aiforthai.in.th/index.php"&gt;AI For Thai&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Various Thai AI API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.clarifai.com/api-guide/api-overview"&gt;Clarifai&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Computer Vision&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cloudmersive.com/image-recognition-and-processing-api"&gt;Cloudmersive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image captioning, face recognition, NSFW classification&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.deepcode.ai"&gt;Deepcode&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;AI for code review&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloud.google.com/dialogflow/docs/"&gt;Dialogflow&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Natural Language Processing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://uttesh.com/exude-api/"&gt;EXUDE-API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Used for the primary ways for filtering the stopping, stemming words from the text data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://faceapi.hirak.site/"&gt;Hirak FaceAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Face detection, face recognition with age estimation/gender estimation, accurate, no quota limits&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://imagga.com/"&gt;Imagga&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image Recognition Solutions like Tagging, Visual Search, NSFW moderation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/user/inferdo"&gt;Inferdo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Computer Vision services like Facial detection, Image labeling, NSFW classification&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.identity.ps/docs"&gt;IPS Online&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Face and License Plate Anonymization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://irisnet.de/api/"&gt;Irisnet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Realtime content moderation API that blocks or blurs unwanted images in real-time&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://keen.io/"&gt;Keen IO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Analytics&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.machinetutors.com/portfolio/MT_api.html"&gt;Machinetutors&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;AI Solutions: Video/Image Classification &amp;amp; Tagging, NSFW, Icon/Image/Audio Search, NLP&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://messengerx.rtfd.io"&gt;MessengerX.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A FREE API for developers to build and monetize personalized ML based chat apps&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nlpcloud.io"&gt;NLP Cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NLP API using spaCy and transformers for NER, sentiments, classification, summarization, and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openvisionapi.com"&gt;OpenVisionAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open source computer vision API based on open source models&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://perspectiveapi.com"&gt;Perspective&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NLP API to return probability that if text is toxic, obscene, insulting or threatening&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://universe.roboflow.com"&gt;Roboflow Universe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pre-trained computer vision models&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://skybiometry.com/documentation/"&gt;SkyBiometry&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Face Detection, Face Recognition and Face Grouping&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://timedoor.io"&gt;Time Door&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A time series analysis API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://unplu.gg/test_api.html"&gt;Unplugg&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Forecasting API for timeseries data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://products.wolframalpha.com/api/"&gt;WolframAlpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides specific answers to questions using data and algorithms&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Music&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.7digital.com/reference"&gt;7digital&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Api of Music store 7digital&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aimastering.com/api_docs/"&gt;AI Mastering&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automated Music Mastering&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.audiomack.com/data-api/docs"&gt;Audiomack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Api of the streaming music hub Audiomack&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bandcamp.com/developer"&gt;Bandcamp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API of Music store Bandcamp&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://app.swaggerhub.com/apis/Bandsintown/PublicAPI/3.0.0"&gt;Bandsintown&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music Events&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.deezer.com/api"&gt;Deezer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.discogs.com/developers/"&gt;Discogs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://freesound.org/docs/api/"&gt;Freesound&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music Samples&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cyberboysumanjay/GaanaAPI"&gt;Gaana&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to retrieve song information from Gaana&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.genius.com/"&gt;Genius&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crowdsourced lyrics and music knowledge&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binaryjazz.us/genrenator-api/"&gt;Genrenator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music genre generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/"&gt;iTunes Search&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Software products&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.jamendo.com/v3.0/docs"&gt;Jamendo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cyberboysumanjay/JioSaavnAPI"&gt;JioSaavn&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to retrieve song information, album meta data and many more from JioSaavn&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.kkbox.com"&gt;KKBOX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get music libraries, playlists, charts, and perform out of KKBOX's platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.ksoft.si/api/lyrics-api"&gt;KSoft.Si Lyrics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to get lyrics for songs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.last.fm/api"&gt;LastFm&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://lyricsovh.docs.apiary.io"&gt;Lyrics.ovh&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple API to retrieve the lyrics of a song&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mixcloud.com/developers/"&gt;Mixcloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://musicbrainz.org/doc/Development/XML_Web_Service/Version_2"&gt;MusicBrainz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.musixmatch.com/"&gt;Musixmatch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.napster.com/api/v2.2"&gt;Napster&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openwhyd.github.io/openwhyd/API"&gt;Openwhyd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Download curated playlists of streaming tracks (YouTube, SoundCloud, etc...)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://phish.in/api-docs"&gt;Phishin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A web-based archive of legal live audio recordings of the improvisational rock band Phish&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.radio-browser.info/"&gt;Radio Browser&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;List of internet radio stations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.songkick.com/developer/"&gt;Songkick&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music Events&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.notion.so/API-d0ebe08a5e304a55928405eb682f6741"&gt;Songlink / Odesli&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get all the services on which a song is available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.songsterr.com/a/wa/api/"&gt;Songsterr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides guitar, bass and drums tabs and chords&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.soundcloud.com/docs/api/guide"&gt;SoundCloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;With SoundCloud API you can build applications that will give more power to control your content&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://beta.developer.spotify.com/documentation/web-api/"&gt;Spotify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;View Spotify music catalog, manage users' libraries, get recommendations and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tastedive.com/read/api"&gt;TasteDive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Similar artist API (also works for movies and TV shows)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.theaudiodb.com/api_guide.php"&gt;TheAudioDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Music&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.vagalume.com.br/docs/"&gt;Vagalume&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crowdsourced lyrics and music knowledge&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;News&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mediastack.com/"&gt;apilayer mediastack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free, Simple REST API for Live News &amp;amp; Blog Articles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.ap.org/"&gt;Associated Press&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search for news and metadata from Associated Press&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://chroniclingamerica.loc.gov/about/api/"&gt;Chronicling America&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides access to millions of pages of historic US newspapers from the Library of Congress&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://currentsapi.services/"&gt;Currents&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Latest news published in various news sources, blogs and forums&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/feedbin/feedbin-api"&gt;Feedbin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RSS reader&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gnews.io/"&gt;GNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search for news from various sources&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://corona.dnsforfamily.com/api.txt"&gt;Graphs for Coronavirus&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Each Country separately and Worldwide Graphs for Coronavirus. Daily updates&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cyberboysumanjay/Inshorts-News-API"&gt;Inshorts News&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides news from inshorts&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.marketaux.com/"&gt;MarketAux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Live stock market news with tagged tickers + sentiment and stats JSON API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.nytimes.com/"&gt;New York Times&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The New York Times Developer Network&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://newsapi.org/"&gt;News&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Headlines currently published on a range of news sources and blogs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://newsdata.io/docs"&gt;NewsData&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;News data API for live-breaking news and headlines from reputed news sources&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/machaao-inc-machaao-inc-default/api/newsx/"&gt;NewsX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get or Search Latest Breaking News with ML Powered Summaries 🤖&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://dev.npr.org/api/"&gt;NPR One&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Personalized news listening experience from NPR&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://spaceflightnewsapi.net"&gt;Spaceflight News&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Spaceflight related news 🚀&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://open-platform.theguardian.com/"&gt;The Guardian&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access all the content the Guardian creates, categorised by tags and section&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/theoldreader/api"&gt;The Old Reader&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RSS reader&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.thenewsapi.com/"&gt;TheNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Aggregated headlines, top story and live news JSON API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://trove.nla.gov.au/about/create-something/using-api"&gt;Trove&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search through the National Library of Australia collection of 1000s of digitised newspapers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Open Data&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://18f.github.io/API-All-the-X/"&gt;18F&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial US Federal Government API Development&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.apisetu.gov.in/"&gt;API Setu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An Indian Government platform that provides a lot of APIS for KYC, business, education &amp;amp; employment&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://archive.readme.io/docs"&gt;Archive.org&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Internet Archive&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.blackhistoryapi.io/docs"&gt;Black History Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Contribute or search one of the largest black history fact databases on the web&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://botsarchive.com/docs.html"&gt;BotsArchive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JSON formatted details about Telegram Bots available in database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://callook.info"&gt;Callook.info&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;United States ham radio callsigns&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://carto.com/"&gt;CARTO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Location Information Prediction&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://collegescorecard.ed.gov/data/"&gt;CollegeScoreCard.ed.gov&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data on higher education institutions in the United States&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.enigma.com/docs"&gt;Enigma Public&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Broadest collection of public data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://geo.api.gouv.fr/adresse"&gt;French Address Search&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Address search via the French Government&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.destatis.de/EN/Service/OpenData/api-webservice.html"&gt;GENESIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Federal Statistical Office Germany&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.joshuaproject.net/"&gt;Joshua Project&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;People groups of the world with the fewest followers of Christ&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.kaggle.com/docs/api"&gt;Kaggle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create and interact with Datasets, Notebooks, and connect with Kaggle&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.linkpreview.net"&gt;LinkPreview&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get JSON formatted summary with title, description and preview image for any requested URL&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/0x0is1/lowy-index-api-docs"&gt;Lowy Asia Power Index&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get measure resources and influence to rank the relative power of states in Asia&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://microlink.io"&gt;Microlink.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Extract structured data from any website&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.data.nasdaq.com/"&gt;Nasdaq Data Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stock market data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.nobelprize.org/about/developer-zone-2/"&gt;Nobel Prize&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open data about nobel prizes and events&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.minneapolismn.gov/"&gt;Open Data Minneapolis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Spatial (GIS) and non-spatial city data for Minneapolis&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://africaopendata.org/"&gt;openAFRICA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large datasets repository of African open data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.opencorporates.com/documentation/API-Reference"&gt;OpenCorporates&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data on corporate entities and directors in many countries&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.opensanctions.org/docs/api/"&gt;OpenSanctions&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data on international sanctions, crime and politically exposed persons&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/peakmetrics-peakmetrics-default/api/peakmetrics-news"&gt;PeakMetrics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;News articles and public datasets&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ridb.recreation.gov/"&gt;Recreation Information Database&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Recreational areas, federal lands, historic sites, museums, and other attractions/resources(US)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.scoop.it/dev"&gt;Scoop.it&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Content Curation Service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev.socrata.com/"&gt;Socrata&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access to Open Data from Governments, Non-profits and NGOs around the world&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.teleport.org/"&gt;Teleport&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Quality of Life Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.umea.se/api/"&gt;Umeå Open Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open data of the city Umeå in northen Sweden&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Hipo/university-domains-list"&gt;Universities List&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;University names, countries and domains&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.uio.no/"&gt;University of Oslo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Courses, lecture videos, detailed information for courses etc. for the University of Oslo (Norway)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://upcdatabase.org/api"&gt;UPC database&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;More than 1.5 million barcode numbers from all around the world&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://urbanobservatory.ac.uk"&gt;Urban Observatory&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The largest set of publicly available real time urban data in the UK&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.wikidata.org/w/api.php?action=help"&gt;Wikidata&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Collaboratively edited knowledge base operated by the Wikimedia Foundation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mediawiki.org/wiki/API:Main_page"&gt;Wikipedia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mediawiki Encyclopedia&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.yelp.com/developers/documentation/v3"&gt;Yelp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Find Local Business&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Open Source Projects&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.count.ly/reference"&gt;Countly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Countly web analytics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.creativecommons.engineering/"&gt;Creative Commons Catalog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search among openly licensed and public domain works&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.datamuse.com/api/"&gt;Datamuse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Word-finding query engine&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.drupal.org/drupalorg/docs/api"&gt;Drupal.org&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Drupal.org&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://evilinsult.com/api"&gt;Evil Insult Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Evil Insults&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github-contributions.vercel.app"&gt;GitHub Contribution Chart Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create an image of your GitHub contributions&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/anuraghazra/github-readme-stats"&gt;GitHub ReadMe Stats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Add dynamically generated statistics to your GitHub profile ReadMe&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.metabase.com/"&gt;Metabase&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An open source Business Intelligence server to share data and analytics inside your company&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://shields.io/"&gt;Shields&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Concise, consistent, and legible badges in SVG and raster format&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Patent&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.epo.org/"&gt;EPO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;European patent search system api&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://patentsview.org/apis/purpose"&gt;PatentsView &lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API is intended to explore and visualize trends/patterns across the US innovation landscape&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tiponet.tipo.gov.tw/Gazette/OpenData/OD/OD05.aspx?QryDS=API00"&gt;TIPO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Taiwan patent search system api&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.uspto.gov/learning-and-resources/open-data-and-mobility"&gt;USPTO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;USA patent api services&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Personality&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.adviceslip.com/"&gt;Advice Slip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate random advice slips&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://biriyani.anoram.com/"&gt;Biriyani As A Service&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Biriyani images placeholder&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.forem.com/api"&gt;Dev.to&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access Forem articles, users and other resources via API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fisenkodv/dictum"&gt;Dictum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to get access to the collection of the most inspiring expressions of mankind&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://favqs.com/api"&gt;FavQs.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;FavQs allows you to collect, discover and share your favorite quotes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.foaas.com/"&gt;FOAAS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fuck Off As A Service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://forismatic.com/en/api/"&gt;Forismatic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Inspirational Quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://icanhazdadjoke.com/api"&gt;icanhazdadjoke&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The largest selection of dad jokes on the internet&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://inspiration.goprogram.ai/docs/"&gt;Inspiration&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Motivational and Inspirational quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kanye.rest"&gt;kanye.rest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for random Kanye West quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kimiquotes.herokuapp.com/doc"&gt;kimiquotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Team radio and interview quotes by Finnish F1 legend Kimi Räikkönen&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Medium/medium-api-docs"&gt;Medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Community of readers and writers offering unique perspectives on ideas&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/skolakoda/programming-quotes-api"&gt;Programming Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Programming Quotes API for open source projects&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/lukePeavey/quotable"&gt;Quotable Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Quotable is a free, open source quotations API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pprathameshmore.github.io/QuoteGarden/"&gt;Quote Garden&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for more than 5000 famous quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quoteclear.web.app/"&gt;quoteclear&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ever-growing list of James Clear quotes from the 3-2-1 Newsletter&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quotesondesign.com/api/"&gt;Quotes on Design&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Inspirational Quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/tlcheah2/stoic-quote-lambda-public-api"&gt;Stoicism Quote&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Quotes about Stoicism&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://theysaidso.com/api/"&gt;They Said So Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Quotes Trusted by many fortune brands around the world&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://app.traitify.com/developer"&gt;Traitify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Assess, collect and analyze Personality&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.udemy.com/developers/instructor/"&gt;Udemy(instructor)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for instructors on Udemy&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://vadivelu.anoram.com/"&gt;Vadivelu HTTP Codes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;On demand HTTP Codes with images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://zenquotes.io/"&gt;Zen Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Large collection of Zen quotes for inspiration&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Phone&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.abstractapi.com/phone-validation-api"&gt;Phone Validation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate phone numbers globally&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://numverify.com"&gt;apilayer numverify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Phone number validation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloudmersive.com/phone-number-validation-API"&gt;Cloudmersive Validate&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Validate international phone numbers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/azharimm/phone-specs-api"&gt;Phone Specification&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rest Api for Phone specifications&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://veriphone.io"&gt;Veriphone&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Phone number validation &amp;amp; carrier lookup&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Photography&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://screenshotlayer.com"&gt;apilayer screenshotlayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URL 2 Image&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apitemplate.io"&gt;APITemplate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dynamically generate images and PDFs from templates with a simple API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.bruzu.com"&gt;Bruzu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image generation with query string&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cheetaho.com/docs/getting-started/"&gt;CheetahO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Photo optimization and resize&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dagpi.xyz"&gt;Dagpi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image manipulation and processing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://duply.co/docs#getting-started-api"&gt;Duply&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate, Edit, Scale and Manage Images and Videos Smarter &amp;amp; Faster&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dynapictures.com/docs/"&gt;DynaPictures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate Hundreds of Personalized Images in Minutes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.flickr.com/services/api/"&gt;Flickr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Flickr Services&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://developers.gettyimages.com/en/"&gt;Getty Images&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Build applications using the world's most powerful imagery&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.gfycat.com/api/"&gt;Gfycat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Jiffier GIFs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.giphy.com/docs/"&gt;Giphy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get all your gifs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/photos"&gt;Google Photos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrate Google Photos with your apps or devices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apilayer.com/marketplace/image_upload-api"&gt;Image Upload&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image Optimization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apidocs.imgur.com/"&gt;Imgur&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Images&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://imsea.herokuapp.com/"&gt;Imsea&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free image search&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://picsum.photos/"&gt;Lorem Picsum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Images from Unsplash&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://objectcut.com/"&gt;ObjectCut&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image Background removal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.pexels.com/api/"&gt;Pexels&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Stock Photos and Videos&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.photoroom.com/api/"&gt;PhotoRoom&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Remove background from images&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pixabay.com/sk/service/about/api/"&gt;Pixabay&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Photography&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://placekeanu.com/"&gt;PlaceKeanu&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Resizable Keanu Reeves placeholder images with grayscale and young Keanu options&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/DenverCoder1/readme-typing-svg"&gt;Readme typing SVG&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Customizable typing and deleting text SVG&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.remove.bg/api"&gt;Remove.bg&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image Background removal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resmush.it/api"&gt;ReSmush.it&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Photo optimization&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-reference.shutterstock.com/"&gt;shutterstock&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stock Photos and Videos&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apidocs.sirv.com/"&gt;Sirv&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image management solutions like optimization, manipulation, hosting&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://unsplash.com/developers"&gt;Unsplash&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Photography&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wallhaven.cc/help/api"&gt;Wallhaven&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Wallpapers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.damsuccess.com/hc/en-us/articles/202134055-REST-API"&gt;Webdam&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Images&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Programming&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://codeforces.com/apiHelp"&gt;Codeforces&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get access to Codeforces data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.hackerearth.com/docs/wiki/developers/v4/"&gt;Hackerearth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;For compiling and running code in several languages&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ce.judge0.com/"&gt;Judge0 CE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Online code execution system&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://kontests.net/api"&gt;KONTESTS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;For upcoming and ongoing competitive coding contests&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.mintlify.com"&gt;Mintlify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;For programmatically generating documentation for code&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Science &amp;amp; Math&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.arcsecond.io/"&gt;arcsecond.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Multiple astronomy data sources&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://arxiv.org/help/api/user-manual"&gt;arXiv&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Curated research-sharing platform: physics, mathematics, quantitative finance, and economics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://core.ac.uk/services#api"&gt;CORE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access the world's Open Access research papers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.gbif.org/developer/summary"&gt;GBIF&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global Biodiversity Information Facility&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/idigbio/idigbio-search-api/wiki"&gt;iDigBio&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access millions of museum specimens from organizations around the world&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/inspirehep/rest-api-doc"&gt;inspirehep.net&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;High Energy Physics info. system&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://isevenapi.xyz/"&gt;isEven (humor)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Check if a number is even&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://isro.vercel.app"&gt;ISRO&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ISRO Space Crafts Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.itis.gov/ws_description.html"&gt;ITIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrated Taxonomic Information System&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://thespacedevs.com/llapi"&gt;Launch Library 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Spaceflight launches and events database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mpds.io"&gt;Materials Platform for Data Science&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Curated experimental data for materials science&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.asterank.com/mpc"&gt;Minor Planet Center&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Asterank.com Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.nasa.gov"&gt;NASA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NASA data, including imagery&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ui.adsabs.harvard.edu/help/api/api-docs.html"&gt;NASA ADS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NASA Astrophysics Data System&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://newton.vercel.app"&gt;Newton&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Symbolic and Arithmetic Math Calculator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.noctuasky.com/api/v1/swaggerdoc/"&gt;Noctua&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API used to access NoctuaSky features&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://math.tools/api/numbers/"&gt;Numbers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Number of the day, random number, number facts and anything else you want to do with numbers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://numbersapi.com"&gt;Numbers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Facts about numbers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://oceanfacts.herokuapp.com/"&gt;Ocean Facts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Facts pertaining to the physical science of Oceanography&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://open-notify.org/Open-Notify-API/"&gt;Open Notify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ISS astronauts, current location, etc&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.osf.io"&gt;Open Science Framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Repository and archive for study designs, research materials, data, manuscripts, etc&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www2.purpleair.com/"&gt;Purple Air&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real Time Air Quality Monitoring&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/elizabethadegbaju/remotecalc"&gt;Remote Calc&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Decodes base64 encoding and parses it to return a solution to the calculation in JSON&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://share.osf.io/api/v2/"&gt;SHARE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A free, open, dataset about research and scholarly activities&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/r-spacex/SpaceX-API"&gt;SpaceX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Company, vehicle, launchpad and launch data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.spacex.land/graphql/"&gt;SpaceX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GraphQL, Company, Ships, launchpad and launch data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sunrise-sunset.org/api"&gt;Sunrise and Sunset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sunset and sunrise times for a given latitude and longitude&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/FranP-code/API-Times-Adder"&gt;Times Adder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;With this API you can add each of the times introduced in the array sended&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tle.ivanstanojevic.me/#/docs"&gt;TLE&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Satellite information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://earthquake.usgs.gov/fdsnws/event/1/"&gt;USGS Earthquake Hazards Program&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Earthquakes data real-time&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://waterservices.usgs.gov/"&gt;USGS Water Services&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Water quality and level info for rivers and lakes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datahelpdesk.worldbank.org/knowledgebase/topics/125589"&gt;World Bank&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;World Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://x-math.herokuapp.com/"&gt;xMath&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random mathematical expressions&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Security&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fingerprintjs/aev"&gt;Application Environment Verification&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Android library and API to verify the safety of user devices, detect rooted devices and other risks&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.binaryedge.io/api-v2.html"&gt;BinaryEdge&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide access to BinaryEdge 40fy scanning platform&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bitwarden.com/help/api/"&gt;BitWarden&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Best open-source password manager&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fingerprintjs/botd"&gt;Botd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Botd is a browser library for JavaScript bot detection&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.bugcrowd.com/api/getting-started/"&gt;Bugcrowd&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bugcrowd API for interacting and tracking the reported issues programmatically&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://search.censys.io/api"&gt;Censys&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search engine for Internet connected host and devices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://classify-web.herokuapp.com/#/api"&gt;Classify&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Encrypting &amp;amp; decrypting text messages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://completecriminalchecks.com/Developers"&gt;Complete Criminal Checks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides data of offenders from all U.S. States and Pureto Rico&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crxcavator.io/apidocs"&gt;CRXcavator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chrome extension risk scoring&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Dehash-lt/api"&gt;Dehash.lt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hash decryption MD5, SHA1, SHA3, SHA256, SHA384, SHA512&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.emailrep.io/"&gt;EmailRep&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Email address threat and risk prediction&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/polarspetroll/EscapeAPI"&gt;Escape&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An API for escaping different kind of queries&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://filterlists.com"&gt;FilterLists&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Lists of filters for adblockers and firewalls&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev.fingerprintjs.com/docs"&gt;FingerprintJS Pro&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fraud detection API offering highly accurate browser fingerprinting&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.fraudlabspro.com/developer/api/screen-order"&gt;FraudLabs Pro&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Screen order information using AI to detect frauds&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api-docs.fullhunt.io/#introduction"&gt;FullHunt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Searchable attack surface database of the entire internet&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.gitguardian.com/doc"&gt;GitGuardian&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Scan files for secrets (API Keys, database credentials)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.greynoise.io/reference/get_v3-community-ip"&gt;GreyNoise&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query IPs in the GreyNoise dataset and retrieve a subset of the full IP context data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.hackerone.com/"&gt;HackerOne&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The industry’s first hacker API that helps increase productivity towards creative bug bounty hunting&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hashable.space/pages/api/"&gt;Hashable&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A REST API to access high level cryptographic functions and methods&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://haveibeenpwned.com/API/v3"&gt;HaveIBeenPwned&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Passwords which have previously been exposed in data breaches&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/IntelligenceX/SDK/raw/master/Intelligence%20X%20API.pdf"&gt;Intelligence X&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Perform OSINT via Intelligence X&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.loginradius.com/docs/"&gt;LoginRadius&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Managed User Authentication Service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://msrc.microsoft.com/report/developer"&gt;Microsoft Security Response Center (MSRC)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Programmatic interfaces to engage with the Microsoft Security Response Center (MSRC)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mozilla/http-observatory/raw/master/httpobs/docs/api.md"&gt;Mozilla http scanner&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mozilla observatory http scanner&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mozilla/tls-observatory#api-endpoints"&gt;Mozilla tls scanner&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Mozilla observatory tls scanner&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nvd.nist.gov/vuln/Data-Feeds/JSON-feed-changelog"&gt;National Vulnerability Database&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;U.S. National Vulnerability Database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/fawazsullia/password-generator/"&gt;Passwordinator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate random passwords of varying complexities&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://phishstats.info/"&gt;PhishStats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Phishing database&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://privacy.com/developer/docs"&gt;Privacy.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate merchant-specific and one-time use credit card numbers that link back to your bank&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pulsedive.com/api/"&gt;Pulsedive&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Scan, search and collect threat intelligence data in real-time&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://securitytrails.com/corp/apidocs"&gt;SecurityTrails&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Domain and IP related information such as current and historical WHOIS and DNS records&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.shodan.io/"&gt;Shodan&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search engine for Internet connected devices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://spyse-dev.readme.io/reference/quick-start"&gt;Spyse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access data on all Internet assets and build powerful attack surface management applications&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://threatjammer.com/docs/index"&gt;Threat Jammer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Risk scoring service from curated threat intelligence data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.police.uk/docs/"&gt;UK Police&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;UK Police data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.virushee.com/"&gt;Virushee&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Virushee file/data scanning&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://vuldb.com/?doc.api"&gt;VulDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;VulDB API allows to initiate queries for one or more items along with transactional bots&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Shopping&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bestbuyapis.github.io/api-documentation/#overview"&gt;Best Buy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Products, Buying Options, Categories, Recommendations, Stores and Commerce&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.digikey.com/en/resources/api-solutions"&gt;Digi-Key&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve price and inventory of electronic components as well as place orders&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dummyproducts-api.herokuapp.com/"&gt;Dummy Products&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An api to fetch dummy e-commerce products JSON data with placeholder images&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.ebay.com/"&gt;eBay&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sell and Buy on eBay&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.etsy.com/developers/documentation/getting_started/api_basics"&gt;Etsy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Manage shop and interact with listings&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://seller.flipkart.com/api-docs/FMSAPI.html"&gt;Flipkart Marketplace&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Product listing management, Order Fulfilment in the Flipkart Marketplace&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.lazada.com/doc/doc.htm"&gt;Lazada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Retrieve product ratings and seller performance metrics&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.mercadolibre.cl/es_ar/api-docs-es"&gt;Mercadolibre&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Manage sales, ads, products, services and Shops&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://octopart.com/api/v4/reference"&gt;Octopart&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Electronic part data for manufacturing, design, and sourcing&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.olx.pl/api/doc#section/"&gt;OLX Poland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integrate with local sites by posting, managing adverts and communicating with OLX users&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev-portal.rappi.com/"&gt;Rappi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Manage orders from Rappi's app&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.shopee.com/documents?version=1"&gt;Shopee&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Shopee's official API for integration of various services from Shopee&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.tokopedia.com/openapi/guide/#/"&gt;Tokopedia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Tokopedia's Official API for integration of various services from Tokopedia&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://woocommerce.github.io/woocommerce-rest-api-docs/"&gt;WooCommerce&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;WooCommerce REST APIS to create, read, update, and delete data on wordpress website in JSON format&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Social&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Auth&lt;/th&gt; 
   &lt;th&gt;HTTPS&lt;/th&gt; 
   &lt;th&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/4chan/4chan-API"&gt;4chan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Simple image-based bulletin board dedicated to a variety of topics&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.ayrshare.com"&gt;Ayrshare&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Social media APIs to post, get analytics, and manage multiple users social media accounts&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aztro.sameerkumar.website/"&gt;aztro&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Daily horoscope info for yesterday, today, and tomorrow&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.google.com/blogger/"&gt;Blogger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The Blogger APIs allows client applications to view and update Blogger content&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.ciscospark.com"&gt;Cisco Spark&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Team Collaboration Software&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.riverside.rocks/docs/index.php"&gt;Dangerous Discord Database&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Database of malicious Discord accounts&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.com/developers/docs/intro"&gt;Discord&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Make bots for Discord, integrate Discord onto an external platform&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://disqus.com/api/docs/auth/"&gt;Disqus&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Communicate with Disqus data&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.doge-meme.lol/docs"&gt;Doge-Meme&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Top meme posts from r/dogecoin which include 'Meme' flair&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.facebook.com/"&gt;Facebook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Facebook Login, Share on FB, Social Plugins, Analytics and more&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.foursquare.com/"&gt;Foursquare&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interact with Foursquare users and places (geolocation-based checkins, photos, tips, events, etc)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.foaas.com"&gt;Fuck Off as a Service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Asks someone to fuck off&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.fullcontact.com/"&gt;Full Contact&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Get Social Media profiles and contact Information&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/HackerNews/API"&gt;HackerNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Social news for CS and entrepreneurship&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://hashnode.com"&gt;Hashnode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A blogging platform built for developers&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.instagram.com/developer/"&gt;Instagram&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Instagram Login, Share on Instagram, Social Plugins and more&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.kakao.com/"&gt;Kakao&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Kakao Login, Share on KakaoTalk, Social Plugins and more&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Phineas/lanyard"&gt;Lanyard&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Retrieve your presence on Discord through an HTTP REST API or WebSocket&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.line.biz/"&gt;Line&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Line Login, Share on Line, Social Plugins and more&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.microsoft.com/en-us/linkedin/?context=linkedin/context"&gt;LinkedIn&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The foundation of all digital integrations with LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.meetup.com/api/guide"&gt;Meetup.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Data about Meetups from Meetup.com&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.microsoft.com/en-us/graph/api/overview"&gt;Microsoft Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Access the data and intelligence in Microsoft 365, Windows 10, and Enterprise Mobility&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.naver.com/main/"&gt;NAVER&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;NAVER Login, Share on NAVER, Social Plugins and more&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.opencollective.com/help/developers/api"&gt;Open Collective&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Get Open Collective data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.pinterest.com/"&gt;Pinterest&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The world's catalog of ideas&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.producthunt.com/v2/docs"&gt;Product Hunt&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The best new products in tech&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.reddit.com/dev/api"&gt;Reddit&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Homepage of the internet&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.revolt.chat/api/"&gt;Revolt&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Revolt open source Discord alternative&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.saidit.net/dev/api"&gt;Saidit&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Open Source Reddit Clone&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://api.slack.com/"&gt;Slack&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Team Instant Messaging&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://dev.tamtam.chat/"&gt;TamTam&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Bot API to interact with TamTam&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://core.telegram.org/bots/api"&gt;Telegram Bot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Simplified HTTP version of the MTProto API for bots&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://core.telegram.org/api#getting-started"&gt;Telegram MTProto&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write Telegram data&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://telegra.ph/api"&gt;Telegraph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Create attractive blogs easily, to share&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developers.tiktok.com/doc/login-kit-web"&gt;TikTok&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fetches user info and user's video posts on TikTok platform&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://trashnothing.com/developer"&gt;Trash Nothing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A freecycling community with thousands of free items posted every day&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.tumblr.com/docs/en/api/v2"&gt;Tumblr&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write Tumblr Data&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://dev.twitch.tv/docs"&gt;Twitch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Game Streaming API&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://developer.twitter.com/en/docs"&gt;Twitter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write Twitter data&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://vk.com/dev/sites"&gt;vk&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Read and write vk data&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Sports &amp;amp; Fitness&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.api-football.com/documentation-v3"&gt;API-FOOTBALL&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get information about Football Leagues &amp;amp; Cups&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://apimedic.com/"&gt;ApiMedic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ApiMedic offers a medical symptom checker API primarily for patients&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.balldontlie.io"&gt;balldontlie&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Balldontlie provides access to stats data from the NBA&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.cfl.ca/"&gt;Canadian Football League (CFL)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Official JSON API providing real-time league, team and player statistics about the CFL&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.citybik.es/v2/"&gt;City Bikes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;City Bikes around the world&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cloudbet.com/api/"&gt;Cloudbet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Official Cloudbet API provides real-time sports odds and betting API to place bets programmatically&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://collegefootballdata.com"&gt;CollegeFootballData.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial detailed American college football statistics, records, and results API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://ergast.com/mrd/"&gt;Ergast F1&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;F1 data from the beginning of the world championships in 1950&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev.fitbit.com/"&gt;Fitbit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fitbit Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/GiulianoCrescimbeni/api/football98/"&gt;Football&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple Open Source Football API to get squads’ stats, best scorers and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.scorebat.com/video-api/"&gt;Football (Soccer) Videos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Embed codes for goals and highlights from Premier League, Bundesliga, Serie A and many more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/azharimm/football-standings-api"&gt;Football Standings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Display football standings e.g epl, la liga, serie a etc. The data is based on espn site&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.football-data.org"&gt;Football-Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Football data with matches info, players, teams, and competitions&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.jcdecaux.com/"&gt;JCDecaux Bike&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JCDecaux's self-service bicycles&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://appac.github.io/mlb-data-api-docs/"&gt;MLB Records and Stats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Current and historical MLB statistics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/api-sports/api/api-nba/"&gt;NBA Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All NBA Stats DATA, Games, Livescore, Standings, Statistics&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://any-api.com/nba_com/nba_com/docs/API_Description"&gt;NBA Stats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Current and historical NBA Statistics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gitlab.com/dword4/nhlapi"&gt;NHL Records and Stats&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NHL historical data and statistics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.oddsmagnet.com"&gt;Oddsmagnet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Odds history from multiple UK bookmakers&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.openligadb.de"&gt;OpenLigaDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crowd sourced sports league results&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/heisenbug/api/premier-league-live-scores/"&gt;Premier League Standings &lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All Current Premier League Standings and Statistics&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://sportdataapi.com"&gt;Sport Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get sports data from all over the world&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.decathlon.com/products/sports"&gt;Sport List &amp;amp; Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;List of and resources related to sports&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.decathlon.com/products/sport-places"&gt;Sport Places&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crowd-source sports places around the world&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.decathlon.com/products/sport-vision"&gt;Sport Vision&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Identify sport, brands and gear in an image. Also does image sports captioning&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.sportmonks.com/cricket/"&gt;Sportmonks Cricket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Live cricket score, player statistics and fantasy API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.sportmonks.com/football/"&gt;Sportmonks Football&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Football score/schedule, news api, tv channels, stats, history, display standing e.g. epl, la liga&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.squiggle.com.au"&gt;Squiggle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fixtures, results and predictions for Australian Football League matches&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://strava.github.io/api/"&gt;Strava&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Connect with athletes, activities and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://suredbits.com/api/"&gt;SuredBits&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Query sports data, including teams, players, games, scores and statistics&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.thesportsdb.com/api.php"&gt;TheSportsDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crowd-Sourced Sports Data and Artwork&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.tredict.com/blog/oauth_docs/"&gt;Tredict&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get and set activities, health data and more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wger.de/en/software/api"&gt;Wger&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Workout manager data as exercises, muscles or equipment&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Test Data&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://baconipsum.com/json-api/"&gt;Bacon Ipsum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A Meatier Lorem Ipsum Generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://avatars.dicebear.com/"&gt;Dicebear Avatars&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate random pixel-art avatars&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://random-words-api.vercel.app/word"&gt;English Random Words&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate English Random Words with Pronunciation&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fakejson.com"&gt;FakeJSON&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Service to generate test and fake data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fakerapi.it/en"&gt;FakerAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;APIs collection to get fake data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fakestoreapi.com/"&gt;FakeStoreAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fake store rest API for your e-commerce or shopping website prototype&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.generadordni.es"&gt;GeneradorDNI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data generator API. Profiles, vehicles, banks and cards, etc&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://itsthisforthat.com/api.php"&gt;ItsThisForThat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate Random startup ideas&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://jsonplaceholder.typicode.com/"&gt;JSONPlaceholder&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Fake data for testing and prototyping&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://loripsum.net/"&gt;Loripsum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The "lorem ipsum" generator that doesn't suck&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://mailsac.com/docs/api"&gt;Mailsac&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Disposable Email&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://metaphorpsum.com/"&gt;Metaphorsum&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate demo paragraphs giving number of words and sentences&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mockaroo.com/docs"&gt;Mockaroo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate fake data to JSON, CSV, TXT, SQL and XML&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://quickmocker.com"&gt;QuickMocker&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API mocking tool to generate contextual, fake or random data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://random-data-api.com"&gt;Random Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random data generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://randommer.io/randommer-api"&gt;Randommer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random data generator&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://randomuser.me"&gt;RandomUser&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generates and list user data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://robohash.org/"&gt;RoboHash&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate random robot/alien avatars&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://random-names-api.herokuapp.com/public"&gt;Spanish random names&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate spanish names (with gender) randomly&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://palabras-aleatorias-public-api.herokuapp.com"&gt;Spanish random words&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate spanish words randomly&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://thispersondoesnotexist.com"&gt;This Person Does not Exist&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generates real-life faces of people who do not exist&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://testimonialapi.toolcarton.com/"&gt;Toolcarton&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate random testimonial data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.uuidtools.com/docs"&gt;UUID Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate UUIDs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://whatthecommit.com/index.txt"&gt;What The Commit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random commit message generator&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://yesno.wtf/api"&gt;Yes No&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Generate yes or no randomly&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Text Analysis&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://codedetectionapi.runtime.dev"&gt;Code Detection API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Detect, label, format and enrich the code in your app or in your data pipeline&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://languagelayer.com/"&gt;apilayer languagelayer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Language Detection JSON API supporting 173 languages&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.aylien.com/textapi/#getting-started"&gt;Aylien Text Analysis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A collection of information retrieval and natural language APIs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.cloudmersive.com/nlp-api"&gt;Cloudmersive Natural Language Processing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Natural language processing and text analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://detectlanguage.com/"&gt;Detect Language&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Detects text language&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nlp.insightera.co.th/docs/v1.0"&gt;ELI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Natural Language Processing Tools for Thai Language&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloud.google.com/natural-language/docs/"&gt;Google Cloud Natural&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Natural language understanding technology, including sentiment, entity and syntax analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ocr.hirak.site/"&gt;Hirak OCR&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Image to text -text recognition- from image more than 100 language, accurate, unlimited requests&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://translate.hirak.site/"&gt;Hirak Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Translate between 21 of most used languages, accurate, unlimited requests&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/lecto-lecto-default/api/lecto-translation/"&gt;Lecto Translation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Translation API with free tier and reasonable prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://libretranslate.com/docs"&gt;LibreTranslate&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Translation tool with 17 available languages&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://semantria.readme.io/docs"&gt;Semantria&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Text Analytics with sentiment analysis, categorization &amp;amp; named entity extraction&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.meaningcloud.com/developer/sentiment-analysis"&gt;Sentiment Analysis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Multilingual sentiment analysis of texts from different sources&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tisane.ai/"&gt;Tisane&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Text Analytics with focus on detection of abusive content and law enforcement applications&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cloud.ibm.com/apidocs/natural-language-understanding/natural-language-understanding"&gt;Watson Natural Language Understanding&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Natural language processing for advanced text analysis&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Tracking&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.aftership.com/reference/quick-start"&gt;Aftership&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API to update, manage and track shipment efficiently&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cws.correios.com.br/ajuda"&gt;Correios&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Integration to provide information and prepare shipments using Correio's services&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pixe.la"&gt;Pixela&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for recording and tracking habits or effort, routines&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;X-Mashape-Key&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.postalpincode.in/Api-Details"&gt;PostalPinCode&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for getting Pincode details in India&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://postmon.com.br"&gt;Postmon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;An API to query Brazilian ZIP codes and orders easily, quickly and free&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.postnord.com/api"&gt;PostNord&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides information about parcels in transport for Sweden and Denmark&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.ups.com/upsdeveloperkit"&gt;UPS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Shipment and Address information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.wecantrack.com"&gt;WeCanTrack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automatically place subids in affiliate links to attribute affiliate conversions to click data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.whatpulse.org/#web-api"&gt;WhatPulse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small application that measures your keyboard/mouse usage&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Transportation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.adsbexchange.com/data/"&gt;ADS-B Exchange&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access real-time and historical data of any and all airborne aircraft&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://airport-web.appspot.com/api/docs/"&gt;airportsapi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Get name and website-URL for airports by ICAO code&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.aishub.net/api"&gt;AIS Hub&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time data of any marine and inland vessel equipped with AIS tracking system&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.amadeus.com/self-service"&gt;Amadeus for Developers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Travel Search - Limited usage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aviationstack.com/"&gt;apilayer aviationstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time Flight Status &amp;amp; Global Aviation Data API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.aviationapi.com"&gt;AviationAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;FAA Aeronautical Charts and Publications, Airport Information, and Airport Weather&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.az511.com/developers/doc"&gt;AZ511&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Access traffic data from the ADOT API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.bart.gov"&gt;Bay Area Rapid Transit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stations and predicted arrivals for BART&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bcferriesapi.ca"&gt;BC Ferries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sailing times and capacities for BC Ferries&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.bic-boxtech.org/"&gt;BIC-Boxtech&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Container technical detail for the global container fleet&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev.blablacar.com"&gt;BlaBlaCar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Search car sharing trips&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mbta.com/developers/v3-api"&gt;Boston MBTA Transit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Stations and predicted arrivals for MBTA&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/transitland/transitland-datastore/raw/master/README.md#api-endpoints"&gt;Community Transit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Transitland API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/obryan-software-obryan-software-default/api/compare-flight-prices/"&gt;Compare Flight Prices&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for comparing flight prices across platforms&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.cts-strasbourg.eu/"&gt;CTS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CTS Realtime API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.grab.com/docs/"&gt;Grab&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Track deliveries, ride fares, payments and loyalty points&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.graphhopper.com/"&gt;GraphHopper&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A-to-B routing with turn-by-turn instructions&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://docs.apis.is/"&gt;Icelandic APIs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Open APIs that deliver services in or regarding Iceland&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.impala.travel/docs/booking-api/"&gt;Impala Hotel Bookings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Hotel content, rates and room bookings&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api-docs.izi.travel/"&gt;Izi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Audio guide for travellers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://datamall.lta.gov.sg/content/dam/datamall/datasets/LTA_DataMall_API_User_Guide.pdf"&gt;Land Transport Authority DataMall, Singapore&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Singapore transport information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://app.metrolisboa.pt/status/getLinhas.php"&gt;Metro Lisboa&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Delays in subway lines&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://doc.navitia.io/"&gt;Navitia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The open API for building cool stuff with transport data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openchargemap.org/site/develop/api"&gt;Open Charge Map&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global public registry of electric vehicle charging locations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opensky-network.org/apidoc/index.html"&gt;OpenSky Network&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free real-time ADS-B aviation data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.digital.sncf.com/startup/api"&gt;Railway Transport for France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SNCF public API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.refugerestrooms.org/api/docs/#!/restrooms"&gt;REFUGE Restrooms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides safe restroom access for transgender, intersex and gender nonconforming individuals&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.sabre.com/guides/travel-agency/quickstart/getting-started-in-travel"&gt;Sabre for Developers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Travel Search - Limited usage&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.schiphol.nl/"&gt;Schiphol Airport&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Schiphol&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://creativecommons.tankerkoenig.de/swagger/"&gt;Tankerkoenig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;German realtime gas/diesel prices&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.transit.land/documentation/datastore/api-endpoints.html"&gt;TransitLand&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Transit Aggregation&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.itsmarta.com/app-developer-resources.aspx"&gt;Transport for Atlanta, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Marta&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev-portal.at.govt.nz/"&gt;Transport for Auckland, New Zealand&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Auckland Transport&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.irail.be/"&gt;Transport for Belgium&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The iRail API is a third-party API for Belgian public transport by train&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/derhuerst/vbb-rest/raw/3/docs/index.md"&gt;Transport for Berlin, Germany&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Third-party VBB API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.bordeaux-metropole.fr/explore/"&gt;Transport for Bordeaux, France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bordeaux Métropole public transport and more (France)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bkkfutar.docs.apiary.io"&gt;Transport for Budapest, Hungary&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Budapest public transport API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.transitchicago.com/developers/"&gt;Transport for Chicago, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Chicago Transit Authority (CTA)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.chaps.cz/eng/products/idos-internet"&gt;Transport for Czech Republic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Czech transport API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.rtd-denver.com/gtfs-developer-guide.shtml"&gt;Transport for Denver, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RTD&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://digitransit.fi/en/developers/"&gt;Transport for Finland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Finnish transport API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://data.deutschebahn.com/dataset/api-fahrplan"&gt;Transport for Germany&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Deutsche Bahn (DB) API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.mobilites-m.fr/pages/opendata/OpenDataApi.html"&gt;Transport for Grenoble, France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Grenoble public transport&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.rmv.de/site/start.html"&gt;Transport for Hessen, Germany&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RMV API (Public Transport in Hessen)&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://hea.thebus.org/api_info.asp"&gt;Transport for Honolulu, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Honolulu Transportation Information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://emel.city-platform.com/opendata/"&gt;Transport for Lisbon, Portugal&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data about buses routes, parking and traffic&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.tfl.gov.uk"&gt;Transport for London, England&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TfL API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.metro.net/api/"&gt;Transport for Los Angeles, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data about positions of Metro vehicles in real time and travel their routes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.tfgm.com/"&gt;Transport for Manchester, England&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TfGM transport network data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.entur.org/"&gt;Transport for Norway&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Transport APIs and dataset for Norway&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.octranspo.com/en/plan-your-trip/travel-tools/developers"&gt;Transport for Ottawa, Canada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;OC Transpo API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://data.ratp.fr/api/v1/console/datasets/1.0/search/"&gt;Transport for Paris, France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;RATP Open Data API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www3.septa.org/hackathon/"&gt;Transport for Philadelphia, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SEPTA APIs&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.sptrans.com.br/desenvolvedores/api-do-olho-vivo-guia-de-referencia/documentacao-api/"&gt;Transport for Sao Paulo, Brazil&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;SPTrans&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://data.renfe.com/api/1/util/snippet/api_info.html?resource_id=a2368cff-1562-4dde-8466-9635ea3a572a"&gt;Transport for Spain&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public trains of Spain&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.trafiklab.se/api"&gt;Transport for Sweden&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Public Transport consumer&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opentransportdata.swiss/en/"&gt;Transport for Switzerland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Official Swiss Public Transport Open Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://transport.opendata.ch/"&gt;Transport for Switzerland&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Swiss public transport API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.ns.nl/reisinformatie/ns-api"&gt;Transport for The Netherlands&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NS, only trains&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/skywave/KV78Turbo-OVAPI/wiki"&gt;Transport for The Netherlands&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;OVAPI, country-wide public transport&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://myttc.ca/developers"&gt;Transport for Toronto, Canada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TTC&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.transportapi.com"&gt;Transport for UK&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Transport API and dataset for UK&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://retro.umoiq.com/xmlFeedDocs/NextBusXMLFeed.pdf"&gt;Transport for United States&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NextBus API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.translink.ca/"&gt;Transport for Vancouver, Canada&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TransLink&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.wmata.com/"&gt;Transport for Washington, US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Washington Metro transport API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://transport.rest"&gt;transport.rest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Community maintained, developer-friendly public transport API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer-tripadvisor.com/home/"&gt;Tripadvisor&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rating content for a hotel, restaurant, attraction or destination&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.uber.com/products"&gt;Uber&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Uber ride requests and price estimation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.velib-metropole.fr/donnees-open-data-gbfs-du-service-velib-metropole"&gt;Velib metropolis, Paris, France&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Velib Open Data API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;URL Shorteners&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/1pt-co/api/raw/main/README.md"&gt;1pt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple URL shortener&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://dev.bitly.com/get_started.html"&gt;Bitly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URL shortener and link management&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cleanuri.com/docs"&gt;CleanURI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URL shortener service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://support.clickmeter.com/hc/en-us/categories/201474986"&gt;ClickMeter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Monitor, compare and optimize your marketing links&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cli.com/swagger-ui/index.html?configUrl=/v3/api-docs/swagger-config"&gt;Clico&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URL shortener service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://cutt.ly/api-documentation/cuttly-links-api"&gt;Cutt.ly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URL shortener service&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://wiki.drivet.xyz/en/url-shortener/add-links"&gt;Drivet URL Shortener&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Shorten a long URL easily and fast&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ulvis.net/developer.html"&gt;Free Url Shortener&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free URL Shortener offers a powerful API to interact with other sites&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.blog/2011-11-10-git-io-github-url-shortener/"&gt;Git.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Git.io URL shortener&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/robvanbakel/gotiny-api"&gt;GoTiny&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A lightweight URL shortener, focused on ease-of-use for the developer and end-user&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.kutt.it/"&gt;Kutt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Free Modern URL Shortener&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://mgnet.me/api.html"&gt;Mgnet.me&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Torrent URL shorten API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://owo.vc/api"&gt;owo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple link obfuscator/shortener&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.rebrandly.com/v1/docs"&gt;Rebrandly&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Custom URL shortener for sharing branded links&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/FayasNoushad/Short-Link-API"&gt;Short Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Short URLs support so many domains&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://shrtco.de/docs"&gt;Shrtcode&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;URl Shortener with multiple Domains&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://shrtlnk.dev/developer"&gt;Shrtlnk&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple and efficient short link creation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tinyurl.com/app/dev"&gt;TinyURL&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Shorten long URLs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://urlbae.com/developers"&gt;UrlBae&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Simple and efficient short link creation&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Vehicle&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://deividfortuna.github.io/fipe/"&gt;Brazilian Vehicles and Prices&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Vehicles information from Fundação Instituto de Pesquisas Econômicas - Fipe&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://helipaddy.com/api/"&gt;Helipaddy sites&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Helicopter and passenger drone landing site directory, Helipaddy data and much more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://developer.kbb.com/#!/data/1-Default"&gt;Kelley Blue Book&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Vehicle info, pricing, configuration, plus much more&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.mercedes-benz.com/apis"&gt;Mercedes-Benz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Telematics data, remotely access vehicle functions, car configurator, locate service dealers&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://vpic.nhtsa.dot.gov/api/"&gt;NHTSA&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NHTSA Product Information Catalog and Vehicle Listing&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://smartcar.com/docs/"&gt;Smartcar&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Lock and unlock vehicles and get data like odometer reading and location. Works on most new cars&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Video&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://anapioficeandfire.com/"&gt;An API of Ice And Fire&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Game Of Thrones API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://bobs-burgers-api-ui.herokuapp.com"&gt;Bob's Burgers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Bob's Burgers API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://breakingbadapi.com/documentation"&gt;Breaking Bad&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Breaking Bad API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/shevabam/breaking-bad-quotes"&gt;Breaking Bad Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Some Breaking Bad quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.catalogopolis.xyz/docs/"&gt;Catalogopolis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Doctor Who API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://catchtheshow.herokuapp.com/api/documentation"&gt;Catch The Show&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;REST API for next-episode.net&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.ceskatelevize.cz/xml/tv-program/"&gt;Czech Television&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TV programme of Czech TV&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.dailymotion.com/"&gt;Dailymotion&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Dailymotion Developer API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/ywalia01/dune-api"&gt;Dune&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A simple API which provides you with book, character, movie and quotes JSON data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://finalspaceapi.com/docs/"&gt;Final Space&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Final Space API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gameofthronesquotes.xyz/"&gt;Game of Thrones Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Some Game of Thrones quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hp-api.herokuapp.com/"&gt;Harry Potter Charactes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Harry Potter Characters Data with with imagery&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://imdb-api.com/"&gt;IMDb-API&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for receiving movie, serial and cast information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/SpEcHiDe/IMDbOT"&gt;IMDbOT&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial IMDb Movie / Series Information&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://json2video.com"&gt;JSON2Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Create and edit videos programmatically: watermarks,resizing,slideshows,voice-over,text animations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/shadowoff09/lucifer-quotes"&gt;Lucifer Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Returns Lucifer quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/DiljotSG/MCU-Countdown"&gt;MCU Countdown&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A Countdown to the next MCU Film&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://nodejs-quoteapp.herokuapp.com/"&gt;Motivational Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random Motivational Quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/F4R4N/movie-quote/"&gt;Movie Quote&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Random Movie and Series Quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.omdbapi.com/"&gt;Open Movie Database&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Movie information&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://owen-wilson-wow-api.herokuapp.com"&gt;Owen Wilson Wow&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for actor Owen Wilson's "wow" exclamations in movies&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jamesseanwright/ron-swanson-quotes#ron-swanson-quotes-api"&gt;Ron Swanson Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Television&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://simkl.docs.apiary.io"&gt;Simkl&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Movie, TV and Anime data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://stapi.co"&gt;STAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Information on all things Star Trek&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/shadowoff09/strangerthings-quotes"&gt;Stranger Things Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Returns Stranger Things quotes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.stream.cz/graphiql"&gt;Stream&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Czech internet television, films, series and online videos for free&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.stromberg-api.de/"&gt;Stromberg Quotes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Returns Stromberg quotes and more&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://swapi.dev/"&gt;SWAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All the Star Wars data you've ever wanted&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.swapi.tech"&gt;SWAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;All things Star Wars&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://graphql.org/swapi-graphql"&gt;SWAPI GraphQL&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Star Wars GraphQL API&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://the-one-api.dev/"&gt;The Lord of the Rings&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The Lord of the Rings API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://vampire-diaries-api.netlify.app/"&gt;The Vampire Diaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TV Show Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://thronesapi.com/"&gt;ThronesApi&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Game Of Thrones Characters Data with imagery&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.themoviedb.org/documentation/api"&gt;TMDb&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Community-based movie data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.traileraddict.com/trailerapi"&gt;TrailerAddict&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily embed trailers from TrailerAddict&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://trakt.docs.apiary.io/"&gt;Trakt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Movie and TV Data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://thetvdb.com/api-information"&gt;TVDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Television data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.tvmaze.com/api"&gt;TVMaze&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TV Show Data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://rapidapi.com/unogs/api/unogsng"&gt;uNoGS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unofficial Netflix Online Global Search, Search all netflix regions in one place&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.vimeo.com/"&gt;Vimeo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Vimeo Developer API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.watchmode.com/"&gt;Watchmode&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API for finding out the streaming availability of movies &amp;amp; shows&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yogeshwaran01/web-series-quotes"&gt;Web Series Quotes Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API generates various Web Series Quote Images&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developers.google.com/youtube/"&gt;YouTube&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Add YouTube functionality to your sites and apps&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Weather&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Auth&lt;/th&gt; 
   &lt;th align="left"&gt;HTTPS&lt;/th&gt; 
   &lt;th align="left"&gt;CORS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://www.7timer.info/doc.php?lang=en"&gt;7Timer!&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather, especially for Astroweather&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.accuweather.com/apis"&gt;AccuWeather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather and forecast data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.aemet.es/centrodedescargas/inicio"&gt;Aemet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather and forecast data from Spain&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://weatherstack.com/"&gt;apilayer weatherstack&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-Time &amp;amp; Historical World Weather Data API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.apixu.com/doc/request.aspx"&gt;APIXU&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://aqicn.org/api/"&gt;AQICN&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Air Quality Index Data for over 1000 cities&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.aviationweather.gov/dataserver"&gt;AviationWeather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;NOAA aviation weather forecasts and observations&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open.caiyunapp.com/ColorfulClouds_Weather_API"&gt;ColorfulClouds&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://opendata.euskadi.eus/api-euskalmet/-/api-de-euskalmet/"&gt;Euskalmet&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Meteorological data of the Basque Country&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://developer.foreca.com"&gt;Foreca&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OAuth&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hgbrasil.com/status/weather"&gt;HG Weather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provides weather forecast data for cities in Brazil&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.hko.gov.hk/en/abouthko/opendata_intro.htm"&gt;Hong Kong Obervatory&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Provide weather information, earthquake information, and climate data&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.metaweather.com/api/"&gt;MetaWeather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.met.no/weatherapi/documentation"&gt;Meteorologisk Institutt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather and climate data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;User-Agent&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://m3o.com/weather/api"&gt;Micro Weather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real time weather forecasts and historic data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://api.oceandrivers.com/static/docs.html"&gt;ODWeather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather and weather webcams&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.oikolab.com"&gt;Oikolab&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;70+ years of global, hourly historical and forecast weather data from NOAA and ECMWF&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://open-meteo.com/"&gt;Open-Meteo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global weather forecast API for non-commercial use&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://api.opensensemap.org/"&gt;openSenseMap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data from Personal Weather Stations called senseBoxes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.openuv.io"&gt;OpenUV&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Real-time UV Index Forecast&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openweathermap.org/api"&gt;OpenWeatherMap&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dev.qweather.com/en/"&gt;QWeather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Location-based weather data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.rainviewer.com/api.html"&gt;RainViewer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Radar data collected from different websites across the Internet&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://stormglass.io/"&gt;Storm Glass&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global marine weather from multiple sources&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.tomorrow.io"&gt;Tomorrow&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather API Powered by Proprietary Technology&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.weather.gov/documentation/services-web-api"&gt;US Weather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;US National Weather Service&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.visualcrossing.com/weather-api"&gt;Visual Crossing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Global historical and weather forecast data&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/robertoduessmann/weather-api"&gt;weather-api&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;A RESTful free API to check the weather&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.weatherapi.com/"&gt;WeatherAPI&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather API with other stuff like Astronomy and Geolocation API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.weatherbit.io/api"&gt;Weatherbit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Weather&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Unknown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://yandex.com/dev/weather/"&gt;Yandex.Weather&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Assesses weather condition in specific locations&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;apiKey&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/#index"&gt;⬆ Back to Index&lt;/a&gt;&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/public-apis/public-apis/master/LICENSE"&gt;MIT&lt;/a&gt; (c) 2022 public-apis&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hiyouga/LLaMA-Factory</title>
      <link>https://github.com/hiyouga/LLaMA-Factory</link>
      <description>&lt;p&gt;Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/logo.png" alt="# LLaMA Factory" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hiyouga/LLaMA-Factory/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory" alt="GitHub last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="GitHub workflow" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/llamafactory/"&gt;&lt;img src="https://img.shields.io/pypi/v/llamafactory" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://scholar.google.com/scholar?cites=12620864006390196564"&gt;&lt;img src="https://img.shields.io/badge/citation-840-green" alt="Citation" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/hiyouga/llamafactory/tags"&gt;&lt;img src="https://img.shields.io/docker/pulls/hiyouga/llamafactory" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/llamafactory_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/llamafactory_ai" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rKfvV9r9FK"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/thirdparty/discord.svg?sanitize=true" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/thirdparty/colab.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt; &lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/thirdparty/dsw.svg?sanitize=true" alt="Open in DSW" /&gt;&lt;/a&gt; &lt;a href="https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&amp;amp;utm_source=LLaMA-Factory"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/thirdparty/lab4ai.svg?sanitize=true" alt="Open in Lab4ai" /&gt;&lt;/a&gt; &lt;a href="https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory"&gt;&lt;img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/thirdparty/online.svg?sanitize=true" alt="Open in Online" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/hiyouga/LLaMA-Board"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue" alt="Open in Spaces" /&gt;&lt;/a&gt; &lt;a href="https://modelscope.cn/studios/hiyouga/LLaMA-Board"&gt;&lt;img src="https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue" alt="Open in Studios" /&gt;&lt;/a&gt; &lt;a href="https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47"&gt;&lt;img src="https://img.shields.io/badge/Novita-Deploy%20Template-blue" alt="Open in Novita" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Used by &lt;a href="https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/"&gt;Amazon&lt;/a&gt;, &lt;a href="https://developer.nvidia.com/rtx/ai-toolkit"&gt;NVIDIA&lt;/a&gt;, &lt;a href="https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory"&gt;Aliyun&lt;/a&gt;, etc.&lt;/h3&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;h3&gt;Supporters ❤️&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;
     &lt;div style="text-align: center;"&gt;
      &lt;a href="https://warp.dev/llama-factory"&gt;&lt;img alt="Warp sponsorship" width="400" src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/sponsors/warp.jpg" /&gt;&lt;/a&gt;
      &lt;br /&gt;
      &lt;a href="https://warp.dev/llama-factory" style="font-size:larger;"&gt;Warp, the agentic terminal for developers&lt;/a&gt;
      &lt;br /&gt;
      &lt;a href="https://warp.dev/llama-factory"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;
     &lt;/div&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;a href="https://serpapi.com"&gt;&lt;img alt="SerpAPI sponsorship" width="250" src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/sponsors/serpapi.svg?sanitize=true" /&gt; &lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;Easily fine-tune 100+ large language models with zero-code &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart"&gt;CLI&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio"&gt;Web UI&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4535" alt="GitHub Trend" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;👋 Join our &lt;a href="https://github.com/hiyouga/llamafactory-community/raw/main/wechat/main.jpg"&gt;WeChat&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/llamafactory-community/raw/main/wechat/npu.jpg"&gt;NPU&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/llamafactory-community/raw/main/wechat/lab4ai.jpg"&gt;Lab4AI&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/llamafactory-community/raw/main/wechat/online.jpg"&gt;LLaMA Factory Online&lt;/a&gt; user group.&lt;/p&gt; 
&lt;p&gt;[ English | &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/README_zh.md"&gt;中文&lt;/a&gt; ]&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Fine-tuning a large language model can be easy as...&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e"&gt;https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Choose your path:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation (WIP)&lt;/strong&gt;: &lt;a href="https://llamafactory.readthedocs.io/en/latest/"&gt;https://llamafactory.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation (AMD GPU)&lt;/strong&gt;: &lt;a href="https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html"&gt;https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Colab (free)&lt;/strong&gt;: &lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local machine&lt;/strong&gt;: Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started"&gt;usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PAI-DSW (free trial)&lt;/strong&gt;: &lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alaya NeW (cloud GPU deal)&lt;/strong&gt;: &lt;a href="https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory"&gt;https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Official Course&lt;/strong&gt;: &lt;a href="https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&amp;amp;utm_source=LLaMA-Factory"&gt;https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&amp;amp;utm_source=LLaMA-Factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLaMA Factory Online&lt;/strong&gt;: &lt;a href="https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory"&gt;https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#blogs"&gt;Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#supported-training-approaches"&gt;Supported Training Approaches&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#provided-datasets"&gt;Provided Datasets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#requirement"&gt;Requirement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#data-preparation"&gt;Data Preparation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#fine-tuning-with-llama-board-gui-powered-by-gradio"&gt;Fine-Tuning with LLaMA Board GUI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#llama-factory-online"&gt;LLaMA Factory Online&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#build-docker"&gt;Build Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#deploy-with-openai-style-api-and-vllm"&gt;Deploy with OpenAI-style API and vLLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub"&gt;Download from ModelScope Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub"&gt;Download from Modelers Hub&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-wb-logger"&gt;Use W&amp;amp;B Logger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger"&gt;Use SwanLab Logger&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#projects-using-llama-factory"&gt;Projects using LLaMA Factory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Various models&lt;/strong&gt;: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrated methods&lt;/strong&gt;: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable resources&lt;/strong&gt;: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced algorithms&lt;/strong&gt;: &lt;a href="https://github.com/jiaweizzhao/GaLore"&gt;GaLore&lt;/a&gt;, &lt;a href="https://github.com/Ledzy/BAdam"&gt;BAdam&lt;/a&gt;, &lt;a href="https://github.com/zhuhanqing/APOLLO"&gt;APOLLO&lt;/a&gt;, &lt;a href="https://github.com/zyushun/Adam-mini"&gt;Adam-mini&lt;/a&gt;, &lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon&lt;/a&gt;, &lt;a href="https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft"&gt;OFT&lt;/a&gt;, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Practical tricks&lt;/strong&gt;: &lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;FlashAttention-2&lt;/a&gt;, &lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt;, &lt;a href="https://github.com/linkedin/Liger-Kernel"&gt;Liger Kernel&lt;/a&gt;, RoPE scaling, NEFTune and rsLoRA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide tasks&lt;/strong&gt;: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experiment monitors&lt;/strong&gt;: LlamaBoard, TensorBoard, Wandb, MLflow, &lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Faster inference&lt;/strong&gt;: OpenAI-style API, Gradio UI and CLI with &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM worker&lt;/a&gt; or &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang worker&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Day-N Support for Fine-Tuning Cutting-Edge Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Support Date&lt;/th&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 0&lt;/td&gt; 
   &lt;td&gt;Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Day 1&lt;/td&gt; 
   &lt;td&gt;Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Blogs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💡 &lt;a href="https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g"&gt;Easy Dataset × LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge&lt;/a&gt; (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&amp;amp;type=project&amp;amp;utm_source=LLaMA-Factory"&gt;Fine-tune a mental health LLM using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory"&gt;Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/"&gt;A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/"&gt;How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod&lt;/a&gt; (English)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;All Blogs&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory"&gt;Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory"&gt;Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b"&gt;LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/"&gt;A One-Stop Code-Free Model Fine-Tuning &amp;amp; Deployment Platform based on SageMaker and LLaMA-Factory&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl"&gt;LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide&lt;/a&gt; (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory"&gt;LLaMA Factory: Fine-tuning Llama3 for Role-Playing&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;[25/08/22] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2306.07280"&gt;OFT&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2506.19847"&gt;OFTv2&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
&lt;p&gt;[25/08/20] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/internlm/Intern-S1-mini"&gt;Intern-S1-mini&lt;/a&gt;&lt;/strong&gt; models. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/8976"&gt;PR #8976&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;[25/08/06] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://github.com/openai/gpt-oss"&gt;GPT-OSS&lt;/a&gt;&lt;/strong&gt; models. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/8826"&gt;PR #8826&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Full Changelog&lt;/summary&gt; 
 &lt;p&gt;[25/07/02] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://github.com/THUDM/GLM-4.1V-Thinking"&gt;GLM-4.1V-9B-Thinking&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[25/04/28] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;Qwen3&lt;/a&gt;&lt;/strong&gt; model family.&lt;/p&gt; 
 &lt;p&gt;[25/04/21] We supported the &lt;strong&gt;&lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage. Thank &lt;a href="https://github.com/tianshijing"&gt;@tianshijing&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[25/04/16] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/OpenGVLab/InternVL3-8B"&gt;InternVL3&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7258"&gt;PR #7258&lt;/a&gt; to get started.&lt;/p&gt; 
 &lt;p&gt;[25/04/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/THUDM/GLM-Z1-9B-0414"&gt;GLM-Z1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct"&gt;Kimi-VL&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[25/04/06] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/"&gt;Llama 4&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7611"&gt;PR #7611&lt;/a&gt; to get started.&lt;/p&gt; 
 &lt;p&gt;[25/03/31] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2.5-omni/"&gt;Qwen2.5 Omni&lt;/a&gt;&lt;/strong&gt; model. See &lt;a href="https://github.com/hiyouga/LLaMA-Factory/pull/7537"&gt;PR #7537&lt;/a&gt; to get started.&lt;/p&gt; 
 &lt;p&gt;[25/03/15] We supported &lt;strong&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/strong&gt; as inference backend. Try &lt;code&gt;infer_backend: sglang&lt;/code&gt; to accelerate inference.&lt;/p&gt; 
 &lt;p&gt;[25/03/12] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/blog/gemma3"&gt;Gemma 3&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[25/02/24] Announcing &lt;strong&gt;&lt;a href="https://github.com/hiyouga/EasyR1"&gt;EasyR1&lt;/a&gt;&lt;/strong&gt;, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.&lt;/p&gt; 
 &lt;p&gt;[25/02/11] We supported saving the &lt;strong&gt;&lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/strong&gt; modelfile when exporting the model checkpoints. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[25/02/05] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/Qwen/Qwen2-Audio-7B-Instruct"&gt;Qwen2-Audio&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; on audio understanding tasks.&lt;/p&gt; 
 &lt;p&gt;[25/01/31] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-R1"&gt;DeepSeek-R1&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct"&gt;Qwen2.5-VL&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[25/01/15] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2412.05270"&gt;APOLLO&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-o-2_6"&gt;MiniCPM-o-2.6&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://huggingface.co/openbmb/MiniCPM-V-2_6"&gt;MiniCPM-V-2.6&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/BUAADreamer"&gt;@BUAADreamer&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/14] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/collections/internlm/"&gt;InternLM 3&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/hhaAndroid"&gt;@hhaAndroid&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[25/01/10] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/microsoft/phi-4"&gt;Phi-4&lt;/a&gt;&lt;/strong&gt; model.&lt;/p&gt; 
 &lt;p&gt;[24/12/21] We supported using &lt;strong&gt;&lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt;&lt;/strong&gt; for experiment tracking and visualization. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#use-swanlab-logger"&gt;this section&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/11/27] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B"&gt;Skywork-o1&lt;/a&gt;&lt;/strong&gt; model and the &lt;strong&gt;&lt;a href="https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT"&gt;OpenO1&lt;/a&gt;&lt;/strong&gt; dataset.&lt;/p&gt; 
 &lt;p&gt;[24/10/09] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href="https://modelers.cn/models"&gt;Modelers Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelers-hub"&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/09/19] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2.5/"&gt;Qwen2.5&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/08/30] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2-vl/"&gt;Qwen2-VL&lt;/a&gt;&lt;/strong&gt; models. Thank &lt;a href="https://github.com/simonJJJ"&gt;@simonJJJ&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/08/27] We supported &lt;strong&gt;&lt;a href="https://github.com/linkedin/Liger-Kernel"&gt;Liger Kernel&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;enable_liger_kernel: true&lt;/code&gt; for efficient training.&lt;/p&gt; 
 &lt;p&gt;[24/08/09] We supported &lt;strong&gt;&lt;a href="https://github.com/zyushun/Adam-mini"&gt;Adam-mini&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage. Thank &lt;a href="https://github.com/relic-yuexi"&gt;@relic-yuexi&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/07/04] We supported &lt;a href="https://github.com/MeetKai/functionary/tree/main/functionary/train/packing"&gt;contamination-free packed training&lt;/a&gt;. Use &lt;code&gt;neat_packing: true&lt;/code&gt; to activate it. Thank &lt;a href="https://github.com/chuan298"&gt;@chuan298&lt;/a&gt;'s PR.&lt;/p&gt; 
 &lt;p&gt;[24/06/16] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02948"&gt;PiSSA&lt;/a&gt;&lt;/strong&gt; algorithm. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/06/07] We supported fine-tuning the &lt;strong&gt;&lt;a href="https://qwenlm.github.io/blog/qwen2/"&gt;Qwen2&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://github.com/THUDM/GLM-4"&gt;GLM-4&lt;/a&gt;&lt;/strong&gt; models.&lt;/p&gt; 
 &lt;p&gt;[24/05/26] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2405.14734"&gt;SimPO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/20] We supported fine-tuning the &lt;strong&gt;PaliGemma&lt;/strong&gt; series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with &lt;code&gt;paligemma&lt;/code&gt; template for chat completion.&lt;/p&gt; 
 &lt;p&gt;[24/05/18] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.01306"&gt;KTO&lt;/a&gt;&lt;/strong&gt; algorithm for preference learning. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/05/14] We supported training and inference on the Ascend NPU devices. Check &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#installation"&gt;installation&lt;/a&gt; section for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/26] We supported fine-tuning the &lt;strong&gt;LLaVA-1.5&lt;/strong&gt; multimodal LLMs. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/22] We provided a &lt;strong&gt;&lt;a href="https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing"&gt;Colab notebook&lt;/a&gt;&lt;/strong&gt; for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check &lt;a href="https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat"&gt;Llama3-8B-Chinese-Chat&lt;/a&gt; and &lt;a href="https://huggingface.co/zhichen/Llama3-Chinese"&gt;Llama3-Chinese&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/04/21] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02258"&gt;Mixture-of-Depths&lt;/a&gt;&lt;/strong&gt; according to &lt;a href="https://github.com/astramind-ai/Mixture-of-depths"&gt;AstraMindAI's implementation&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2404.02827"&gt;BAdam&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/04/16] We supported &lt;strong&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;unsloth&lt;/a&gt;&lt;/strong&gt;'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves &lt;strong&gt;117%&lt;/strong&gt; speed and &lt;strong&gt;50%&lt;/strong&gt; memory compared with FlashAttention-2, more benchmarks can be found in &lt;a href="https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison"&gt;this page&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[24/03/31] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2403.07691"&gt;ORPO&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/21] Our paper "&lt;a href="https://arxiv.org/abs/2403.13372"&gt;LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models&lt;/a&gt;" is available at arXiv!&lt;/p&gt; 
 &lt;p&gt;[24/03/20] We supported &lt;strong&gt;FSDP+QLoRA&lt;/strong&gt; that fine-tunes a 70B model on 2x24GB GPUs. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/13] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.12354"&gt;LoRA+&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2403.03507"&gt;GaLore&lt;/a&gt;&lt;/strong&gt; optimizer. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/03/07] We integrated &lt;strong&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;&lt;/strong&gt; for faster and concurrent inference. Try &lt;code&gt;infer_backend: vllm&lt;/code&gt; to enjoy &lt;strong&gt;270%&lt;/strong&gt; inference speed.&lt;/p&gt; 
 &lt;p&gt;[24/02/28] We supported weight-decomposed LoRA (&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2402.09353"&gt;DoRA&lt;/a&gt;&lt;/strong&gt;). Try &lt;code&gt;use_dora: true&lt;/code&gt; to activate DoRA training.&lt;/p&gt; 
 &lt;p&gt;[24/02/15] We supported &lt;strong&gt;block expansion&lt;/strong&gt; proposed by &lt;a href="https://github.com/TencentARC/LLaMA-Pro"&gt;LLaMA Pro&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this &lt;a href="https://qwenlm.github.io/blog/qwen1.5/"&gt;blog post&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[24/01/18] We supported &lt;strong&gt;agent tuning&lt;/strong&gt; for most models, equipping model with tool using abilities by fine-tuning with &lt;code&gt;dataset: glaive_toolcall_en&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/23] We supported &lt;strong&gt;&lt;a href="https://github.com/unslothai/unsloth"&gt;unsloth&lt;/a&gt;&lt;/strong&gt;'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try &lt;code&gt;use_unsloth: true&lt;/code&gt; argument to activate unsloth patch. It achieves &lt;strong&gt;170%&lt;/strong&gt; speed in our benchmark, check &lt;a href="https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison"&gt;this page&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/12/12] We supported fine-tuning the latest MoE model &lt;strong&gt;&lt;a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1"&gt;Mixtral 8x7B&lt;/a&gt;&lt;/strong&gt; in our framework. See hardware requirement &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#hardware-requirement"&gt;here&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/12/01] We supported downloading pre-trained models and datasets from the &lt;strong&gt;&lt;a href="https://modelscope.cn/models"&gt;ModelScope Hub&lt;/a&gt;&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#download-from-modelscope-hub"&gt;this tutorial&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/10/21] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2310.05914"&gt;NEFTune&lt;/a&gt;&lt;/strong&gt; trick for fine-tuning. Try &lt;code&gt;neftune_noise_alpha: 5&lt;/code&gt; argument to activate NEFTune.&lt;/p&gt; 
 &lt;p&gt;[23/09/27] We supported &lt;strong&gt;$S^2$-Attn&lt;/strong&gt; proposed by &lt;a href="https://github.com/dvlab-research/LongLoRA"&gt;LongLoRA&lt;/a&gt; for the LLaMA models. Try &lt;code&gt;shift_attn: true&lt;/code&gt; argument to enable shift short attention.&lt;/p&gt; 
 &lt;p&gt;[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/09/10] We supported &lt;strong&gt;&lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;FlashAttention-2&lt;/a&gt;&lt;/strong&gt;. Try &lt;code&gt;flash_attn: fa2&lt;/code&gt; argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.&lt;/p&gt; 
 &lt;p&gt;[23/08/12] We supported &lt;strong&gt;RoPE scaling&lt;/strong&gt; to extend the context length of the LLaMA models. Try &lt;code&gt;rope_scaling: linear&lt;/code&gt; argument in training and &lt;code&gt;rope_scaling: dynamic&lt;/code&gt; argument at inference to extrapolate the position embeddings.&lt;/p&gt; 
 &lt;p&gt;[23/08/11] We supported &lt;strong&gt;&lt;a href="https://arxiv.org/abs/2305.18290"&gt;DPO training&lt;/a&gt;&lt;/strong&gt; for instruction-tuned models. See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
 &lt;p&gt;[23/07/31] We supported &lt;strong&gt;dataset streaming&lt;/strong&gt;. Try &lt;code&gt;streaming: true&lt;/code&gt; and &lt;code&gt;max_steps: 10000&lt;/code&gt; arguments to load your dataset in streaming mode.&lt;/p&gt; 
 &lt;p&gt;[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos (&lt;a href="https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat"&gt;LLaMA-2&lt;/a&gt; / &lt;a href="https://huggingface.co/hiyouga/Baichuan-13B-sft"&gt;Baichuan&lt;/a&gt;) for details.&lt;/p&gt; 
 &lt;p&gt;[23/07/18] We developed an &lt;strong&gt;all-in-one Web UI&lt;/strong&gt; for training, evaluation and inference. Try &lt;code&gt;train_web.py&lt;/code&gt; to fine-tune models in your Web browser. Thank &lt;a href="https://github.com/KanadeSiina"&gt;@KanadeSiina&lt;/a&gt; and &lt;a href="https://github.com/codemayq"&gt;@codemayq&lt;/a&gt; for their efforts in the development.&lt;/p&gt; 
 &lt;p&gt;[23/07/09] We released &lt;strong&gt;&lt;a href="https://github.com/hiyouga/FastEdit"&gt;FastEdit&lt;/a&gt;&lt;/strong&gt; ⚡🩹, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow &lt;a href="https://github.com/hiyouga/FastEdit"&gt;FastEdit&lt;/a&gt; if you are interested.&lt;/p&gt; 
 &lt;p&gt;[23/06/29] We provided a &lt;strong&gt;reproducible example&lt;/strong&gt; of training a chat model using instruction-following datasets, see &lt;a href="https://huggingface.co/hiyouga/Baichuan-7B-sft"&gt;Baichuan-7B-sft&lt;/a&gt; for details.&lt;/p&gt; 
 &lt;p&gt;[23/06/22] We aligned the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/api_demo.py"&gt;demo API&lt;/a&gt; with the &lt;a href="https://platform.openai.com/docs/api-reference/chat"&gt;OpenAI's&lt;/a&gt; format where you can insert the fine-tuned model in &lt;strong&gt;arbitrary ChatGPT-based applications&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;[23/06/03] We supported quantized training and inference (aka &lt;strong&gt;&lt;a href="https://github.com/artidoro/qlora"&gt;QLoRA&lt;/a&gt;&lt;/strong&gt;). See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples&lt;/a&gt; for usage.&lt;/p&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Model size&lt;/th&gt; 
   &lt;th&gt;Template&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/baichuan-inc"&gt;Baichuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;baichuan2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/bigscience"&gt;BLOOM/BLOOMZ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;560M/1.1B/1.7B/3B/7.1B/176B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/THUDM"&gt;ChatGLM3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B&lt;/td&gt; 
   &lt;td&gt;chatglm3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/CohereForAI"&gt;Command R&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;35B/104B&lt;/td&gt; 
   &lt;td&gt;cohere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek (Code/MoE)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/16B/67B/236B&lt;/td&gt; 
   &lt;td&gt;deepseek&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek 2.5/3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;236B/671B&lt;/td&gt; 
   &lt;td&gt;deepseek3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/deepseek-ai"&gt;DeepSeek R1 (Distill)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/7B/8B/14B/32B/70B/671B&lt;/td&gt; 
   &lt;td&gt;deepseekr1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/baidu"&gt;ERNIE-4.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.3B/21B/300B&lt;/td&gt; 
   &lt;td&gt;ernie/ernie_nothink&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tiiuae"&gt;Falcon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/11B/40B/180B&lt;/td&gt; 
   &lt;td&gt;falcon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tiiuae"&gt;Falcon-H1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1.5B/3B/7B/34B&lt;/td&gt; 
   &lt;td&gt;falcon_h1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;Gemma/Gemma 2/CodeGemma&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/7B/9B/27B&lt;/td&gt; 
   &lt;td&gt;gemma/gemma2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;Gemma 3/Gemma 3n&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;270M/1B/4B/6B/8B/12B/27B&lt;/td&gt; 
   &lt;td&gt;gemma3/gemma3n&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4/GLM-4-0414/GLM-Z1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;9B/32B&lt;/td&gt; 
   &lt;td&gt;glm4/glmz1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4.1V&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;9B&lt;/td&gt; 
   &lt;td&gt;glm4v&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/zai-org"&gt;GLM-4.5/GLM-4.5V&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;106B/355B&lt;/td&gt; 
   &lt;td&gt;glm4_moe/glm4v_moe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community"&gt;GPT-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.1B/0.4B/0.8B/1.5B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai"&gt;GPT-OSS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;20B/120B&lt;/td&gt; 
   &lt;td&gt;gpt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ibm-granite"&gt;Granite 3.0-3.3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/3B/8B&lt;/td&gt; 
   &lt;td&gt;granite3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ibm-granite"&gt;Granite 4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;granite4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tencent/"&gt;Hunyuan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;hunyuan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/IndexTeam"&gt;Index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.9B&lt;/td&gt; 
   &lt;td&gt;index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/internlm"&gt;InternLM 2-3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/20B&lt;/td&gt; 
   &lt;td&gt;intern2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/OpenGVLab"&gt;InternVL 2.5-3.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/2B/4B/8B/14B/30B/38B/78B/241B&lt;/td&gt; 
   &lt;td&gt;intern_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/internlm/"&gt;InternLM/Intern-S1-mini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;intern_s1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/moonshotai"&gt;Kimi-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;16B&lt;/td&gt; 
   &lt;td&gt;kimi_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/inclusionAI"&gt;Ling 2.0 (mini/flash)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;16B/100B&lt;/td&gt; 
   &lt;td&gt;bailing_v2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/facebookresearch/llama"&gt;Llama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/33B/65B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/70B&lt;/td&gt; 
   &lt;td&gt;llama2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 3-3.3&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/3B/8B/70B&lt;/td&gt; 
   &lt;td&gt;llama3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;109B/402B&lt;/td&gt; 
   &lt;td&gt;llama4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/meta-llama"&gt;Llama 3.2 Vision&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11B/90B&lt;/td&gt; 
   &lt;td&gt;mllama&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-1.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B&lt;/td&gt; 
   &lt;td&gt;llava&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-NeXT&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8B/13B/34B/72B/110B&lt;/td&gt; 
   &lt;td&gt;llava_next&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/llava-hf"&gt;LLaVA-NeXT-Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/34B&lt;/td&gt; 
   &lt;td&gt;llava_next_video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/XiaomiMiMo"&gt;MiMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;mimo&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openbmb"&gt;MiniCPM 1-4.1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1B/2B/4B/8B&lt;/td&gt; 
   &lt;td&gt;cpm/cpm3/cpm4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openbmb"&gt;MiniCPM-o-2.6/MiniCPM-V-2.6&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;minicpm_o/minicpm_v&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Ministral/Mistral-Nemo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B/12B&lt;/td&gt; 
   &lt;td&gt;ministral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Mistral/Mixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/8x7B/8x22B&lt;/td&gt; 
   &lt;td&gt;mistral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Mistral Small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;24B&lt;/td&gt; 
   &lt;td&gt;mistral_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/allenai"&gt;OLMo&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1B/7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/google"&gt;PaliGemma/PaliGemma2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/10B/28B&lt;/td&gt; 
   &lt;td&gt;paligemma&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-1.5/Phi-2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.3B/2.7B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-3/Phi-3.5&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;4B/14B&lt;/td&gt; 
   &lt;td&gt;phi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-3-small&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;phi_small&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/microsoft"&gt;Phi-4&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;phi4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/mistralai"&gt;Pixtral&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;pixtral&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen (1-2.5) (Code/Math/MoE/QwQ)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B/1.5B/3B/7B/14B/32B/72B/110B&lt;/td&gt; 
   &lt;td&gt;qwen&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen3 (MoE/Instruct/Thinking/Next)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0.6B/1.7B/4B/8B/14B/32B/80B/235B&lt;/td&gt; 
   &lt;td&gt;qwen3/qwen3_nothink&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2-Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;qwen2_audio&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2.5-Omni&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B&lt;/td&gt; 
   &lt;td&gt;qwen2_omni&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen3-Omni&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;30B&lt;/td&gt; 
   &lt;td&gt;qwen3_omni&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen2-VL/Qwen2.5-VL/QVQ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/3B/7B/32B/72B&lt;/td&gt; 
   &lt;td&gt;qwen2_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Qwen"&gt;Qwen3-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;235B&lt;/td&gt; 
   &lt;td&gt;qwen3_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/ByteDance-Seed"&gt;Seed (OSS/Coder)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B/36B&lt;/td&gt; 
   &lt;td&gt;seed_oss/seed_coder&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Skywork"&gt;Skywork o1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;skywork_o1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/bigcode"&gt;StarCoder 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/15B&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Tele-AI"&gt;TeleChat2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;3B/7B/35B/115B&lt;/td&gt; 
   &lt;td&gt;telechat2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/xverse"&gt;XVERSE&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;7B/13B/65B&lt;/td&gt; 
   &lt;td&gt;xverse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/01-ai"&gt;Yi/Yi-1.5 (Code)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5B/6B/9B/34B&lt;/td&gt; 
   &lt;td&gt;yi&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/01-ai"&gt;Yi-VL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;6B/34B&lt;/td&gt; 
   &lt;td&gt;yi_vl&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/IEITYuan"&gt;Yuan 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2B/51B/102B&lt;/td&gt; 
   &lt;td&gt;yuan&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For the "base" models, the &lt;code&gt;template&lt;/code&gt; argument can be chosen from &lt;code&gt;default&lt;/code&gt;, &lt;code&gt;alpaca&lt;/code&gt;, &lt;code&gt;vicuna&lt;/code&gt; etc. But make sure to use the &lt;strong&gt;corresponding template&lt;/strong&gt; for the "instruct/chat" models.&lt;/p&gt; 
 &lt;p&gt;Remember to use the &lt;strong&gt;SAME&lt;/strong&gt; template in training and inference.&lt;/p&gt; 
 &lt;p&gt;*: You should install the &lt;code&gt;transformers&lt;/code&gt; from main branch and use &lt;code&gt;DISABLE_VERSION_CHECK=1&lt;/code&gt; to skip version check.&lt;/p&gt; 
 &lt;p&gt;**: You need to install a specific version of &lt;code&gt;transformers&lt;/code&gt; to use the corresponding model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/extras/constants.py"&gt;constants.py&lt;/a&gt; for a full list of models we supported.&lt;/p&gt; 
&lt;p&gt;You also can add a custom chat template to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/src/llamafactory/data/template.py"&gt;template.py&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Training Approaches&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Approach&lt;/th&gt; 
   &lt;th&gt;Full-tuning&lt;/th&gt; 
   &lt;th&gt;Freeze-tuning&lt;/th&gt; 
   &lt;th&gt;LoRA&lt;/th&gt; 
   &lt;th&gt;QLoRA&lt;/th&gt; 
   &lt;th&gt;OFT&lt;/th&gt; 
   &lt;th&gt;QOFT&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pre-Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Supervised Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Reward Modeling&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;KTO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ORPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SimPO Training&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;✅&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The implementation details of PPO can be found in &lt;a href="https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html"&gt;this blog&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Provided Datasets&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;Pre-training datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/wiki_demo.txt"&gt;Wiki Demo (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb"&gt;RefinedWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2"&gt;RedPajama V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/olm/olm-wikipedia-20221220"&gt;Wikipedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered"&gt;Wikipedia (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/EleutherAI/pile"&gt;Pile (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Skywork/SkyPile-150B"&gt;SkyPile (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb"&gt;FineWeb (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu"&gt;FineWeb-Edu (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/CCI3-HQ"&gt;CCI3-HQ (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/CCI3-Data"&gt;CCI3-Data (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1"&gt;CCI4.0-M2-Base-v1 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1"&gt;CCI4.0-M2-CoT-v1 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1"&gt;CCI4.0-M2-Extra-v1 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/bigcode/the-stack"&gt;The Stack (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/bigcode/starcoderdata"&gt;StarCoder (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Supervised fine-tuning datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/identity.json"&gt;Identity (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;Stanford Alpaca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3"&gt;Stanford Alpaca (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM"&gt;Alpaca GPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2"&gt;Glaive Function Calling V2 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/GAIR/lima"&gt;LIMA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset"&gt;Guanaco Dataset (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_2M_CN"&gt;BELLE 2M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_1M_CN"&gt;BELLE 1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/train_0.5M_CN"&gt;BELLE 0.5M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M"&gt;BELLE Dialogue 0.4M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/school_math_0.25M"&gt;BELLE School Math 0.25M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M"&gt;BELLE Multiturn Chat 0.8M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/thunlp/UltraChat"&gt;UltraChat (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/garage-bAInd/Open-Platypus"&gt;OpenPlatypus (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k"&gt;CodeAlpaca 20k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/QingyiSi/Alpaca-CoT"&gt;Alpaca CoT (multilingual)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Open-Orca/OpenOrca"&gt;OpenOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Open-Orca/SlimOrca"&gt;SlimOrca (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/TIGER-Lab/MathInstruct"&gt;MathInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M"&gt;Firefly 1.1M (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/wiki_qa"&gt;Wiki QA (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/suolyer/webqa"&gt;Web QA (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/zxbsmk/webnovel_cn"&gt;WebNovel (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/berkeley-nest/Nectar"&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;deepctrl (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HasturOfficial/adgen"&gt;Advertise Generating (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k"&gt;ShareGPT Hyperfiltered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/shibing624/sharegpt_gpt4"&gt;ShareGPT4 (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k"&gt;UltraChat 200k (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BAAI/Infinity-Instruct"&gt;Infinity Instruct (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/THUDM/AgentInstruct"&gt;AgentInstruct (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/lmsys/lmsys-chat-1m"&gt;LMSYS Chat 1M (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k"&gt;Evol Instruct V2 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceTB/cosmopedia"&gt;Cosmopedia (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hfl/stem_zh_instruction"&gt;STEM (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo"&gt;Ruozhiba (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/m-a-p/neo_sft_phase2"&gt;Neo-sft (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered"&gt;Magpie-Pro-300K-Filtered (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/argilla/magpie-ultra-v0.1"&gt;Magpie-ultra-v0.1 (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/TIGER-Lab/WebInstructSub"&gt;WebInstructSub (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT"&gt;OpenO1-SFT (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k"&gt;Open-Thoughts (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/open-r1/OpenR1-Math-220k"&gt;Open-R1-Math (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT"&gt;Chinese-DeepSeek-R1-Distill (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k"&gt;LLaVA mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions"&gt;Pokemon-gpt4o-captions (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/oasst_de"&gt;Open Assistant (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de"&gt;Dolly 15k (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de"&gt;Alpaca GPT4 (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de"&gt;OpenSchnabeltier (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de"&gt;Evol Instruct (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/dolphin_de"&gt;Dolphin (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/booksum_de"&gt;Booksum (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de"&gt;Airoboros (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de"&gt;Ultrachat (de)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Preference datasets&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k"&gt;DPO mixed (en&amp;amp;zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized"&gt;UltraFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/m-a-p/COIG-P"&gt;COIG-P (zh)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/openbmb/RLHF-V-Dataset"&gt;RLHF-V (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Zhihui/VLFeedback"&gt;VLFeedback (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset"&gt;RLAIF-V (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Intel/orca_dpo_pairs"&gt;Orca DPO Pairs (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/Anthropic/hh-rlhf"&gt;HH-RLHF (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/berkeley-nest/Nectar"&gt;Nectar (en)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de"&gt;Orca DPO (de)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/datasets/argilla/kto-mix-15k"&gt;KTO mixed (en)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade huggingface_hub
huggingface-cli login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Requirement&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mandatory&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;python&lt;/td&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;3.10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;torch&lt;/td&gt; 
   &lt;td&gt;2.0.0&lt;/td&gt; 
   &lt;td&gt;2.6.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;torchvision&lt;/td&gt; 
   &lt;td&gt;0.15.0&lt;/td&gt; 
   &lt;td&gt;0.21.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;transformers&lt;/td&gt; 
   &lt;td&gt;4.49.0&lt;/td&gt; 
   &lt;td&gt;4.50.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;datasets&lt;/td&gt; 
   &lt;td&gt;2.16.0&lt;/td&gt; 
   &lt;td&gt;3.2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;accelerate&lt;/td&gt; 
   &lt;td&gt;0.34.0&lt;/td&gt; 
   &lt;td&gt;1.2.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;peft&lt;/td&gt; 
   &lt;td&gt;0.14.0&lt;/td&gt; 
   &lt;td&gt;0.15.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;trl&lt;/td&gt; 
   &lt;td&gt;0.8.6&lt;/td&gt; 
   &lt;td&gt;0.9.6&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Optional&lt;/th&gt; 
   &lt;th&gt;Minimum&lt;/th&gt; 
   &lt;th&gt;Recommend&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CUDA&lt;/td&gt; 
   &lt;td&gt;11.6&lt;/td&gt; 
   &lt;td&gt;12.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;deepspeed&lt;/td&gt; 
   &lt;td&gt;0.10.0&lt;/td&gt; 
   &lt;td&gt;0.16.4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bitsandbytes&lt;/td&gt; 
   &lt;td&gt;0.39.0&lt;/td&gt; 
   &lt;td&gt;0.43.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vllm&lt;/td&gt; 
   &lt;td&gt;0.4.3&lt;/td&gt; 
   &lt;td&gt;0.8.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;flash-attn&lt;/td&gt; 
   &lt;td&gt;2.5.6&lt;/td&gt; 
   &lt;td&gt;2.7.2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Requirement&lt;/h3&gt; 
&lt;p&gt;* &lt;em&gt;estimated&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Bits&lt;/th&gt; 
   &lt;th&gt;7B&lt;/th&gt; 
   &lt;th&gt;14B&lt;/th&gt; 
   &lt;th&gt;30B&lt;/th&gt; 
   &lt;th&gt;70B&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;x&lt;/code&gt;B&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;bf16&lt;/code&gt; or &lt;code&gt;fp16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;240GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;1200GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;18x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full (&lt;code&gt;pure_bf16&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;60GB&lt;/td&gt; 
   &lt;td&gt;120GB&lt;/td&gt; 
   &lt;td&gt;300GB&lt;/td&gt; 
   &lt;td&gt;600GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;8x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Freeze/LoRA/GaLore/APOLLO/BAdam/OFT&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;32GB&lt;/td&gt; 
   &lt;td&gt;64GB&lt;/td&gt; 
   &lt;td&gt;160GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA / QOFT&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;10GB&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;40GB&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA / QOFT&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
   &lt;td&gt;12GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;48GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/2&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QLoRA / QOFT&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;16GB&lt;/td&gt; 
   &lt;td&gt;24GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;x/4&lt;/code&gt;GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Installation is mandatory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]" --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Extra dependencies available: torch, torch-npu, metrics, deepspeed, liger-kernel, bitsandbytes, hqq, eetq, gptq, aqlm, vllm, sglang, galore, apollo, badam, adam-mini, qwen, minicpm_v, openmind, swanlab, dev&lt;/p&gt; 
&lt;h4&gt;Install from Docker Image&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This image is built on Ubuntu 22.04 (x86_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.&lt;/p&gt; 
&lt;p&gt;Find the pre-built images: &lt;a href="https://hub.docker.com/r/hiyouga/llamafactory/tags"&gt;https://hub.docker.com/r/hiyouga/llamafactory/tags&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/#build-docker"&gt;build docker&lt;/a&gt; to build the image yourself.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Setting up a virtual environment with &lt;b&gt;uv&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Create an isolated Python environment with &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --extra torch --extra metrics --prerelease=allow
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Run LLaMA-Factory in the isolated environment:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Windows users&lt;/summary&gt; 
 &lt;h4&gt;Install PyTorch&lt;/h4&gt; 
 &lt;p&gt;You need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official website&lt;/a&gt; and the following command to install PyTorch with CUDA support:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
python -c "import torch; print(torch.cuda.is_available())"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you see &lt;code&gt;True&lt;/code&gt; then you have successfully installed PyTorch with CUDA support.&lt;/p&gt; 
 &lt;p&gt;Try &lt;code&gt;dataloader_num_workers: 0&lt;/code&gt; if you encounter &lt;code&gt;Can't pickle local object&lt;/code&gt; error.&lt;/p&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of &lt;code&gt;bitsandbytes&lt;/code&gt; library, which supports CUDA 11.1 to 12.2, please select the appropriate &lt;a href="https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels"&gt;release version&lt;/a&gt; based on your CUDA version.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Install Flash Attention-2&lt;/h4&gt; 
 &lt;p&gt;To enable FlashAttention-2 on the Windows platform, please use the script from &lt;a href="https://huggingface.co/lldacing/flash-attention-windows-wheel"&gt;flash-attention-windows-wheel&lt;/a&gt; to compile and install it by yourself.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;For Ascend NPU users&lt;/summary&gt; 
 &lt;p&gt;To install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher and specify extra dependencies: &lt;code&gt;pip install -e ".[torch-npu,metrics]"&lt;/code&gt;. Additionally, you need to install the &lt;strong&gt;&lt;a href="https://www.hiascend.com/developer/download/community/result?module=cann"&gt;Ascend CANN Toolkit and Kernels&lt;/a&gt;&lt;/strong&gt;. Please follow the &lt;a href="https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html"&gt;installation tutorial&lt;/a&gt; or use the following commands:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# replace the url according to your CANN version and devices
# install CANN Toolkit
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run
bash Ascend-cann-toolkit_8.0.0.alpha002_linux-"$(uname -i)".run --install

# install CANN Kernels
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run
bash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-"$(uname -i)".run --install

# set env variables
source /usr/local/Ascend/ascend-toolkit/set_env.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Requirement&lt;/th&gt; 
    &lt;th&gt;Minimum&lt;/th&gt; 
    &lt;th&gt;Recommend&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CANN&lt;/td&gt; 
    &lt;td&gt;8.0.RC1&lt;/td&gt; 
    &lt;td&gt;8.0.0.alpha002&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;torch-npu&lt;/td&gt; 
    &lt;td&gt;2.1.0&lt;/td&gt; 
    &lt;td&gt;2.4.0.post2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;deepspeed&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
    &lt;td&gt;0.13.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;vllm-ascend&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;0.7.3&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;Remember to use &lt;code&gt;ASCEND_RT_VISIBLE_DEVICES&lt;/code&gt; instead of &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt; to specify the device to use.&lt;/p&gt; 
 &lt;p&gt;If you cannot infer model on NPU devices, try setting &lt;code&gt;do_sample: false&lt;/code&gt; in the configurations.&lt;/p&gt; 
 &lt;p&gt;Download the pre-built Docker images: &lt;a href="http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html"&gt;32GB&lt;/a&gt; | &lt;a href="http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html"&gt;64GB&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Install BitsAndBytes&lt;/h4&gt; 
 &lt;p&gt;To use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Manually compile bitsandbytes: Refer to &lt;a href="https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&amp;amp;platform=Ascend+NPU"&gt;the installation documentation&lt;/a&gt; for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install bitsandbytes from source
# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch
git clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git
cd bitsandbytes/

# Install dependencies
pip install -r requirements-dev.txt

# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference
apt-get install -y build-essential cmake

# Compile &amp;amp; install  
cmake -DCOMPUTE_BACKEND=npu -S .
make
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Install transformers from the main branch.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone -b main https://github.com/huggingface/transformers.git
cd transformers
pip install .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Set &lt;code&gt;double_quantization: false&lt;/code&gt; in the configuration. You can refer to the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/train_qlora/llama3_lora_sft_bnb_npu.yaml"&gt;example&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Preparation&lt;/h3&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/data/README.md"&gt;data/README.md&lt;/a&gt; for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Please update &lt;code&gt;data/dataset_info.json&lt;/code&gt; to use your custom dataset.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can also use &lt;strong&gt;&lt;a href="https://github.com/ConardLi/easy-dataset"&gt;Easy Dataset&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://github.com/OpenDCAI/DataFlow"&gt;DataFlow&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://github.com/open-sciencelab/GraphGen"&gt;GraphGen&lt;/a&gt;&lt;/strong&gt; to create synthetic data for fine-tuning.&lt;/p&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;p&gt;Use the following 3 commands to run LoRA &lt;strong&gt;fine-tuning&lt;/strong&gt;, &lt;strong&gt;inference&lt;/strong&gt; and &lt;strong&gt;merging&lt;/strong&gt; of the Llama3-8B-Instruct model, respectively.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml
llamafactory-cli chat examples/inference/llama3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/examples/README.md"&gt;examples/README.md&lt;/a&gt; for advanced usage (including distributed training).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Use &lt;code&gt;llamafactory-cli help&lt;/code&gt; to show help information.&lt;/p&gt; 
 &lt;p&gt;Read &lt;a href="https://github.com/hiyouga/LLaMA-Factory/issues/4614"&gt;FAQs&lt;/a&gt; first if you encounter any problems.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Fine-Tuning with LLaMA Board GUI (powered by &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;llamafactory-cli webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;LLaMA Factory Online&lt;/h3&gt; 
&lt;p&gt;Read our &lt;a href="https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Build Docker&lt;/h3&gt; 
&lt;p&gt;For CUDA users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-npu/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker/docker-rocm/
docker compose up -d
docker compose exec llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt;
 &lt;summary&gt;Build without Docker Compose&lt;/summary&gt; 
 &lt;p&gt;For CUDA users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host --gpus=all \
    -p 7860:7860 \
    -p 8000:8000 \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Ascend NPU users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-npu/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=torch-npu,metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -v /usr/local/dcmi:/usr/local/dcmi \
    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
    -v /etc/ascend_install.info:/etc/ascend_install.info \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/davinci0 \
    --device /dev/davinci_manager \
    --device /dev/devmm_svm \
    --device /dev/hisi_hdc \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For AMD ROCm users:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -f ./docker/docker-rocm/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/kfd \
    --device /dev/dri \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Use Docker volumes&lt;/summary&gt; 
 &lt;p&gt;You can uncomment &lt;code&gt;VOLUME [ "/root/.cache/huggingface", "/app/shared_data", "/app/output" ]&lt;/code&gt; in the Dockerfile to use data volumes.&lt;/p&gt; 
 &lt;p&gt;When building the Docker image, use &lt;code&gt;-v ./hf_cache:/root/.cache/huggingface&lt;/code&gt; argument to mount the local directory to the container. The following data volumes are available.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;hf_cache&lt;/code&gt;: Utilize Hugging Face cache on the host machine.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;shared_data&lt;/code&gt;: The directionary to store datasets on the host machine.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: Set export dir to this location so that the merged result can be accessed directly on the host machine.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Deploy with OpenAI-style API and vLLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;API_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Visit &lt;a href="https://platform.openai.com/docs/api-reference/chat/create"&gt;this page&lt;/a&gt; for API document.&lt;/p&gt; 
 &lt;p&gt;Examples: &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_image.py"&gt;Image understanding&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/scripts/api_example/test_toolcall.py"&gt;Function calling&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download from ModelScope Hub&lt;/h3&gt; 
&lt;p&gt;If you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the ModelScope Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href="https://modelscope.cn/models"&gt;ModelScope Hub&lt;/a&gt;, e.g., &lt;code&gt;LLM-Research/Meta-Llama-3-8B-Instruct&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Download from Modelers Hub&lt;/h3&gt; 
&lt;p&gt;You can also use Modelers Hub to download models and datasets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Train the model by specifying a model ID of the Modelers Hub as the &lt;code&gt;model_name_or_path&lt;/code&gt;. You can find a full list of model IDs at &lt;a href="https://modelers.cn/models"&gt;Modelers Hub&lt;/a&gt;, e.g., &lt;code&gt;TeleAI/TeleChat-7B-pt&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Use W&amp;amp;B Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href="https://wandb.ai"&gt;Weights &amp;amp; Biases&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;report_to: wandb
run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;WANDB_API_KEY&lt;/code&gt; to &lt;a href="https://wandb.ai/authorize"&gt;your key&lt;/a&gt; when launching training tasks to log in with your W&amp;amp;B account.&lt;/p&gt; 
&lt;h3&gt;Use SwanLab Logger&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href="https://github.com/SwanHubX/SwanLab"&gt;SwanLab&lt;/a&gt; for logging experimental results, you need to add the following arguments to yaml files.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;use_swanlab: true
swanlab_run_name: test_run # optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When launching training tasks, you can log in to SwanLab in three ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add &lt;code&gt;swanlab_api_key=&amp;lt;your_api_key&amp;gt;&lt;/code&gt; to the yaml file, and set it to your &lt;a href="https://swanlab.cn/settings"&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set the environment variable &lt;code&gt;SWANLAB_API_KEY&lt;/code&gt; to your &lt;a href="https://swanlab.cn/settings"&gt;API key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use the &lt;code&gt;swanlab login&lt;/code&gt; command to complete the login.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Projects using LLaMA Factory&lt;/h2&gt; 
&lt;p&gt;If you have a project that should be incorporated, please contact via email or create a pull request.&lt;/p&gt; 
&lt;details&gt;
 &lt;summary&gt;Click to show&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. &lt;a href="https://arxiv.org/abs/2308.02223"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. &lt;a href="https://arxiv.org/abs/2308.10092"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. &lt;a href="https://arxiv.org/abs/2308.10526"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. &lt;a href="https://arxiv.org/abs/2311.07816"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. &lt;a href="https://arxiv.org/abs/2312.15710"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. &lt;a href="https://arxiv.org/abs/2401.04319"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. &lt;a href="https://arxiv.org/abs/2401.07286"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. &lt;a href="https://arxiv.org/abs/2402.05904"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. &lt;a href="https://arxiv.org/abs/2402.07625"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11176"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. &lt;a href="https://arxiv.org/abs/2402.11187"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. &lt;a href="https://arxiv.org/abs/2402.11746"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11801"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. &lt;a href="https://arxiv.org/abs/2402.11809"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.11819"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. &lt;a href="https://arxiv.org/abs/2402.12204"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2402.14714"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. &lt;a href="https://arxiv.org/abs/2402.15043"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. &lt;a href="https://arxiv.org/abs/2403.02333"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. &lt;a href="https://arxiv.org/abs/2403.03419"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. &lt;a href="https://arxiv.org/abs/2403.08228"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. &lt;a href="https://arxiv.org/abs/2403.09073"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. &lt;a href="https://arxiv.org/abs/2403.14541"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. &lt;a href="https://arxiv.org/abs/2403.15246"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. &lt;a href="https://arxiv.org/abs/2403.16008"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. &lt;a href="https://arxiv.org/abs/2403.16443"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. &lt;a href="https://arxiv.org/abs/2404.00604"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.02827"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2404.04167"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. &lt;a href="https://arxiv.org/abs/2404.04316"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.07084"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.09836"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2404.11581"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. &lt;a href="https://arxiv.org/abs/2404.14215"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. &lt;a href="https://arxiv.org/abs/2404.16621"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. &lt;a href="https://arxiv.org/abs/2404.17140"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. &lt;a href="https://arxiv.org/abs/2404.18585"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. &lt;a href="https://arxiv.org/abs/2405.04760"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Dammu et al. "They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. &lt;a href="https://arxiv.org/abs/2405.05378"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. &lt;a href="https://arxiv.org/abs/2405.09055"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. &lt;a href="https://arxiv.org/abs/2405.12739"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. &lt;a href="https://arxiv.org/abs/2405.13816"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. &lt;a href="https://arxiv.org/abs/2405.20215"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. &lt;a href="https://aclanthology.org/2024.lt4hala-1.30"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2406.00380"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. &lt;a href="https://arxiv.org/abs/2406.02106"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. &lt;a href="https://arxiv.org/abs/2406.03136"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. &lt;a href="https://arxiv.org/abs/2406.04496"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. &lt;a href="https://arxiv.org/abs/2406.05688"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. &lt;a href="https://arxiv.org/abs/2406.05955"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. &lt;a href="https://arxiv.org/abs/2406.06973"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. &lt;a href="https://arxiv.org/abs/2406.07115"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. Are Large Language Models Good Statisticians?. 2024. &lt;a href="https://arxiv.org/abs/2406.07815"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. &lt;a href="https://arxiv.org/abs/2406.10099"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. &lt;a href="https://arxiv.org/abs/2406.10173"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. &lt;a href="https://arxiv.org/abs/2406.12074"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. &lt;a href="https://arxiv.org/abs/2406.14408"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. &lt;a href="https://arxiv.org/abs/2406.14546"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. &lt;a href="https://arxiv.org/abs/2406.15695"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. &lt;a href="https://arxiv.org/abs/2406.17233"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. &lt;a href="https://arxiv.org/abs/2406.18069"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. &lt;a href="https://aclanthology.org/2024.americasnlp-1.25"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. &lt;a href="https://arxiv.org/abs/2406.19949"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yang et al. Financial Knowledge Large Language Model. 2024. &lt;a href="https://arxiv.org/abs/2407.00365"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. &lt;a href="https://arxiv.org/abs/2407.01470"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. &lt;a href="https://arxiv.org/abs/2407.06129"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. &lt;a href="https://arxiv.org/abs/2407.08044"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. &lt;a href="https://arxiv.org/abs/2407.09756"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. &lt;a href="https://scholarcommons.scu.edu/cseng_senior/272/"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. &lt;a href="https://arxiv.org/abs/2407.13561"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. &lt;a href="https://arxiv.org/abs/2407.16637"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. &lt;a href="https://arxiv.org/abs/2407.17535"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. &lt;a href="https://arxiv.org/abs/2407.19705"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. &lt;a href="https://arxiv.org/abs/2408.00137"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. &lt;a href="https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. &lt;a href="https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. &lt;a href="https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. &lt;a href="https://arxiv.org/abs/2408.04693"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. &lt;a href="https://arxiv.org/abs/2408.04168"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. &lt;a href="https://aclanthology.org/2024.finnlp-2.1/"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. &lt;a href="https://arxiv.org/abs/2408.08072"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. &lt;a href="https://dl.acm.org/doi/10.1145/3627673.3679611"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. &lt;a href="https://aclanthology.org/2024.findings-acl.830.pdf"&gt;[paper]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Yu-Yang-Li/StarWhisper"&gt;StarWhisper&lt;/a&gt;&lt;/strong&gt;: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/FudanDISC/DISC-LawLLM"&gt;DISC-LawLLM&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/X-D-Lab/Sunsimiao"&gt;Sunsimiao&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/WangRongsheng/CareGPT"&gt;CareGPT&lt;/a&gt;&lt;/strong&gt;: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/PKU-YuanGroup/Machine-Mindset/"&gt;MachineMindset&lt;/a&gt;&lt;/strong&gt;: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://huggingface.co/Nekochu/Luminia-13B-v3"&gt;Luminia-13B-v3&lt;/a&gt;&lt;/strong&gt;: A large language model specialized in generate metadata for stable diffusion. &lt;a href="https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt"&gt;[demo]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/BUAADreamer/Chinese-LLaVA-Med"&gt;Chinese-LLaVA-Med&lt;/a&gt;&lt;/strong&gt;: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/THUDM/AutoRE"&gt;AutoRE&lt;/a&gt;&lt;/strong&gt;: A document-level relation extraction system based on large language models.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/NVIDIA/RTX-AI-Toolkit"&gt;NVIDIA RTX AI Toolkit&lt;/a&gt;&lt;/strong&gt;: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;LazyLLM&lt;/a&gt;&lt;/strong&gt;: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/NLPJCL/RAG-Retrieval"&gt;RAG-Retrieval&lt;/a&gt;&lt;/strong&gt;: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. &lt;a href="https://zhuanlan.zhihu.com/p/987727357"&gt;[blog]&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Qihoo360/360-LLaMA-Factory"&gt;360-LLaMA-Factory&lt;/a&gt;&lt;/strong&gt;: A modified library that supports long sequence SFT &amp;amp; DPO using ring attention.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://novasky-ai.github.io/posts/sky-t1/"&gt;Sky-T1&lt;/a&gt;&lt;/strong&gt;: An o1-like model fine-tuned by NovaSky AI with very small cost.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/xming521/WeClone"&gt;WeClone&lt;/a&gt;&lt;/strong&gt;: One-stop solution for creating your digital avatar from chat logs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/SmartFlowAI/EmoLLM"&gt;EmoLLM&lt;/a&gt;&lt;/strong&gt;: A project about large language models (LLMs) and mental health.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please follow the model licenses to use the corresponding model weights: &lt;a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf"&gt;Baichuan 2&lt;/a&gt; / &lt;a href="https://huggingface.co/spaces/bigscience/license"&gt;BLOOM&lt;/a&gt; / &lt;a href="https://github.com/THUDM/ChatGLM3/raw/main/MODEL_LICENSE"&gt;ChatGLM3&lt;/a&gt; / &lt;a href="https://cohere.com/c4ai-cc-by-nc-license"&gt;Command R&lt;/a&gt; / &lt;a href="https://github.com/deepseek-ai/DeepSeek-LLM/raw/main/LICENSE-MODEL"&gt;DeepSeek&lt;/a&gt; / &lt;a href="https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt"&gt;Falcon&lt;/a&gt; / &lt;a href="https://ai.google.dev/gemma/terms"&gt;Gemma&lt;/a&gt; / &lt;a href="https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE"&gt;GLM-4&lt;/a&gt; / &lt;a href="https://github.com/openai/gpt-2/raw/master/LICENSE"&gt;GPT-2&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Granite&lt;/a&gt; / &lt;a href="https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE"&gt;Index&lt;/a&gt; / &lt;a href="https://github.com/InternLM/InternLM#license"&gt;InternLM&lt;/a&gt; / &lt;a href="https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md"&gt;Llama&lt;/a&gt; / &lt;a href="https://ai.meta.com/llama/license/"&gt;Llama 2&lt;/a&gt; / &lt;a href="https://llama.meta.com/llama3/license/"&gt;Llama 3&lt;/a&gt; / &lt;a href="https://github.com/meta-llama/llama-models/raw/main/models/llama4/LICENSE"&gt;Llama 4&lt;/a&gt; / &lt;a href="https://github.com/OpenBMB/MiniCPM/raw/main/MiniCPM%20Model%20License.md"&gt;MiniCPM&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Mistral/Mixtral/Pixtral&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;OLMo&lt;/a&gt; / &lt;a href="https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx"&gt;Phi-1.5/Phi-2&lt;/a&gt; / &lt;a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE"&gt;Phi-3/Phi-4&lt;/a&gt; / &lt;a href="https://github.com/QwenLM/Qwen/raw/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT"&gt;Qwen&lt;/a&gt; / &lt;a href="https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf"&gt;Skywork&lt;/a&gt; / &lt;a href="https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement"&gt;StarCoder 2&lt;/a&gt; / &lt;a href="https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf"&gt;TeleChat2&lt;/a&gt; / &lt;a href="https://github.com/xverse-ai/XVERSE-13B/raw/main/MODEL_LICENSE.pdf"&gt;XVERSE&lt;/a&gt; / &lt;a href="https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE"&gt;Yi&lt;/a&gt; / &lt;a href="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/LICENSE"&gt;Yi-1.5&lt;/a&gt; / &lt;a href="https://github.com/IEIT-Yuan/Yuan-2.0/raw/main/LICENSE-Yuan"&gt;Yuan 2&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;This repo benefits from &lt;a href="https://github.com/huggingface/peft"&gt;PEFT&lt;/a&gt;, &lt;a href="https://github.com/huggingface/trl"&gt;TRL&lt;/a&gt;, &lt;a href="https://github.com/artidoro/qlora"&gt;QLoRA&lt;/a&gt; and &lt;a href="https://github.com/lm-sys/FastChat"&gt;FastChat&lt;/a&gt;. Thanks for their wonderful works.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opendatalab/MinerU</title>
      <link>https://github.com/opendatalab/MinerU</link>
      <description>&lt;p&gt;Transforms complex documents like PDFs into LLM-ready markdown/JSON for your Agentic workflows.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" xmlns="http://www.w3.org/1999/html"&gt; 
 &lt;!-- logo --&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/images/MinerU-logo.png" width="300px" style="vertical-align:middle;" /&gt; &lt;/p&gt; 
 &lt;!-- icon --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU.svg?sanitize=true" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/forks/opendatalab/MinerU.svg?sanitize=true" alt="forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;&lt;img src="https://img.shields.io/github/issues-raw/opendatalab/MinerU" alt="open issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;&lt;img src="https://img.shields.io/github/issues-closed-raw/opendatalab/MinerU" alt="issue resolution" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/mineru/"&gt;&lt;img src="https://img.shields.io/pypi/v/mineru" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/mineru/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/mineru" alt="PyPI - Python Version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/mineru"&gt;&lt;img src="https://static.pepy.tech/badge/mineru" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/mineru"&gt;&lt;img src="https://static.pepy.tech/badge/mineru/month" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://mineru.net/OpenSourceTools/Extractor?source=github"&gt;&lt;img src="https://img.shields.io/badge/webapp_on_mineru.net-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTM0IiBoZWlnaHQ9IjEzNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJtMTIyLDljMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGQ9Im0xMjIsOWMwLDUtNCw5LTksOXMtOS00LTktOSw0LTksOS05LDksNCw5LDl6IiBmaWxsPSIjMDEwMTAxIi8+PHBhdGggZD0ibTkxLDE4YzAsNS00LDktOSw5cy05LTQtOS05LDQtOSw5LTksOSw0LDksOXoiIGZpbGw9InVybCgjYikiLz48cGF0aCBkPSJtOTEsMThjMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0iIzAxMDEwMSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0idXJsKCNjKSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0iIzAxMDEwMSIvPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYSIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYyIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=&amp;amp;labelColor=white" alt="OpenDataLab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-yellow.svg?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/gist/myhloli/a3cb16570ab3cfeadf9d8f0ac91b4fca/mineru_demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Colab" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2409.18839"&gt;&lt;img src="https://img.shields.io/badge/MinerU-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.22186"&gt;&lt;img src="https://img.shields.io/badge/MinerU2.5-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/opendatalab/MinerU"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11174" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11174" alt="opendatalab%2FMinerU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- language --&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/README_zh-CN.md"&gt;简体中文&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- hot link --&gt; 
 &lt;p align="center"&gt; 🚀&lt;a href="https://mineru.net/?source=github"&gt;Access MinerU Now→✅ Zero-Install Web Version ✅ Full-Featured Desktop Client ✅ Instant API Access; Skip deployment headaches – get all product formats in one click. Developers, dive in!&lt;/a&gt; &lt;/p&gt; 
 &lt;!-- join us --&gt; 
 &lt;p align="center"&gt; 👋 join us on &lt;a href="https://discord.gg/Tdedn9GTXq" target="_blank"&gt;Discord&lt;/a&gt; and &lt;a href="https://mineru.net/community-portal/?aliasId=3c430f94" target="_blank"&gt;WeChat&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Changelog&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2025/09/26 2.5.4 released&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;🎉🎉 The MinerU2.5 &lt;a href="https://arxiv.org/abs/2509.22186"&gt;Technical Report&lt;/a&gt; is now available! We welcome you to read it for a comprehensive overview of its model architecture, training strategy, data engineering and evaluation results.&lt;/li&gt; 
   &lt;li&gt;Fixed an issue where some &lt;code&gt;PDF&lt;/code&gt; files were mistakenly identified as &lt;code&gt;AI&lt;/code&gt; files, causing parsing failures&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025/09/20 2.5.3 Released&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Dependency version range adjustment to enable Turing and earlier architecture GPUs to use vLLM acceleration for MinerU2.5 model inference.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;pipeline&lt;/code&gt; backend compatibility fixes for torch 2.8.0.&lt;/li&gt; 
   &lt;li&gt;Reduced default concurrency for vLLM async backend to lower server pressure and avoid connection closure issues caused by high load.&lt;/li&gt; 
   &lt;li&gt;More compatibility-related details can be found in the &lt;a href="https://github.com/opendatalab/MinerU/discussions/3548"&gt;announcement&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025/09/19 2.5.2 Released&lt;/p&gt; &lt;p&gt;We are officially releasing MinerU2.5, currently the most powerful multimodal large model for document parsing. With only 1.2B parameters, MinerU2.5's accuracy on the OmniDocBench benchmark comprehensively surpasses top-tier multimodal models like Gemini 2.5 Pro, GPT-4o, and Qwen2.5-VL-72B. It also significantly outperforms leading specialized models such as dots.ocr, MonkeyOCR, and PP-StructureV3. The model has been released on &lt;a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B"&gt;HuggingFace&lt;/a&gt; and &lt;a href="https://modelscope.cn/models/opendatalab/MinerU2.5-2509-1.2B"&gt;ModelScope&lt;/a&gt; platforms. Welcome to download and use!&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Core Highlights: 
    &lt;ul&gt; 
     &lt;li&gt;SOTA Performance with Extreme Efficiency: As a 1.2B model, it achieves State-of-the-Art (SOTA) results that exceed models in the 10B and 100B+ classes, redefining the performance-per-parameter standard in document AI.&lt;/li&gt; 
     &lt;li&gt;Advanced Architecture for Across-the-Board Leadership: By combining a two-stage inference pipeline (decoupling layout analysis from content recognition) with a native high-resolution architecture, it achieves SOTA performance across five key areas: layout analysis, text recognition, formula recognition, table recognition, and reading order.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Key Capability Enhancements: 
    &lt;ul&gt; 
     &lt;li&gt;Layout Detection: Delivers more complete results by accurately covering non-body content like headers, footers, and page numbers. It also provides more precise element localization and natural format reconstruction for lists and references.&lt;/li&gt; 
     &lt;li&gt;Table Parsing: Drastically improves parsing for challenging cases, including rotated tables, borderless/semi-structured tables, and long/complex tables.&lt;/li&gt; 
     &lt;li&gt;Formula Recognition: Significantly boosts accuracy for complex, long-form, and hybrid Chinese-English formulas, greatly enhancing the parsing capability for mathematical documents.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Additionally, with the release of vlm 2.5, we have made some adjustments to the repository:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The vlm backend has been upgraded to version 2.5, supporting the MinerU2.5 model and no longer compatible with the MinerU2.0-2505-0.9B model. The last version supporting the 2.0 model is mineru-2.2.2.&lt;/li&gt; 
   &lt;li&gt;VLM inference-related code has been moved to &lt;a href="https://github.com/opendatalab/mineru-vl-utils"&gt;mineru_vl_utils&lt;/a&gt;, reducing coupling with the main mineru repository and facilitating independent iteration in the future.&lt;/li&gt; 
   &lt;li&gt;The vlm accelerated inference framework has been switched from &lt;code&gt;sglang&lt;/code&gt; to &lt;code&gt;vllm&lt;/code&gt;, achieving full compatibility with the vllm ecosystem, allowing users to use the MinerU2.5 model and accelerated inference on any platform that supports the vllm framework.&lt;/li&gt; 
   &lt;li&gt;Due to major upgrades in the vlm model supporting more layout types, we have made some adjustments to the structure of the parsing intermediate file &lt;code&gt;middle.json&lt;/code&gt; and result file &lt;code&gt;content_list.json&lt;/code&gt;. Please refer to the &lt;a href="https://opendatalab.github.io/MinerU/reference/output_files/"&gt;documentation&lt;/a&gt; for details.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Other repository optimizations:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Removed file extension whitelist validation for input files. When input files are PDF documents or images, there are no longer requirements for file extensions, improving usability.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;History Log&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/09/10 2.2.2 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where the new table recognition model would affect the overall parsing task when some table parsing failed&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/09/08 2.2.1 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where some newly added models were not downloaded when using the model download command.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/09/05 2.2.0 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt; Major Updates 
    &lt;ul&gt; 
     &lt;li&gt;In this version, we focused on improving table parsing accuracy by introducing a new &lt;a href="https://github.com/RapidAI/TableStructureRec"&gt;wired table recognition model&lt;/a&gt; and a brand-new hybrid table structure parsing algorithm, significantly enhancing the table recognition capabilities of the &lt;code&gt;pipeline&lt;/code&gt; backend.&lt;/li&gt; 
     &lt;li&gt;We also added support for cross-page table merging, which is supported by both &lt;code&gt;pipeline&lt;/code&gt; and &lt;code&gt;vlm&lt;/code&gt; backends, further improving the completeness and accuracy of table parsing.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; Other Updates 
    &lt;ul&gt; 
     &lt;li&gt;The &lt;code&gt;pipeline&lt;/code&gt; backend now supports 270-degree rotated table parsing, bringing support for table parsing in 0/90/270-degree orientations&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;pipeline&lt;/code&gt; added OCR capability support for Thai and Greek, and updated the English OCR model to the latest version. English recognition accuracy improved by 11%, Thai recognition model accuracy is 82.68%, and Greek recognition model accuracy is 89.28% (by PPOCRv5)&lt;/li&gt; 
     &lt;li&gt;Added &lt;code&gt;bbox&lt;/code&gt; field (mapped to 0-1000 range) in the output &lt;code&gt;content_list.json&lt;/code&gt;, making it convenient for users to directly obtain position information for each content block&lt;/li&gt; 
     &lt;li&gt;Removed the &lt;code&gt;pipeline_old_linux&lt;/code&gt; installation option, no longer supporting legacy Linux systems such as &lt;code&gt;CentOS 7&lt;/code&gt;, to provide better support for &lt;code&gt;uv&lt;/code&gt;'s &lt;code&gt;sync&lt;/code&gt;/&lt;code&gt;run&lt;/code&gt; commands&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/08/01 2.1.10 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed an issue in the &lt;code&gt;pipeline&lt;/code&gt; backend where block overlap caused the parsing results to deviate from expectations #3232&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/30 2.1.9 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;transformers&lt;/code&gt; 4.54.1 version adaptation&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/28 2.1.8 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sglang&lt;/code&gt; 0.4.9.post5 version adaptation&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/27 2.1.7 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;transformers&lt;/code&gt; 4.54.0 version adaptation&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/26 2.1.6 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed table parsing issues in handwritten documents when using &lt;code&gt;vlm&lt;/code&gt; backend&lt;/li&gt; 
   &lt;li&gt;Fixed visualization box position drift issue when document is rotated #3175&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/24 2.1.5 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sglang&lt;/code&gt; 0.4.9 version adaptation, synchronously upgrading the dockerfile base image to sglang 0.4.9.post3&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/23 2.1.4 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Fixed the issue of excessive memory consumption during the &lt;code&gt;MFR&lt;/code&gt; step in the &lt;code&gt;pipeline&lt;/code&gt; backend under certain scenarios #2771&lt;/li&gt; 
     &lt;li&gt;Fixed the inaccurate matching between &lt;code&gt;image&lt;/code&gt;/&lt;code&gt;table&lt;/code&gt; and &lt;code&gt;caption&lt;/code&gt;/&lt;code&gt;footnote&lt;/code&gt; under certain conditions #3129&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/16 2.1.1 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Bug fixes&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Fixed text block content loss issue that could occur in certain &lt;code&gt;pipeline&lt;/code&gt; scenarios #3005&lt;/li&gt; 
     &lt;li&gt;Fixed issue where &lt;code&gt;sglang-client&lt;/code&gt; required unnecessary packages like &lt;code&gt;torch&lt;/code&gt; #2968&lt;/li&gt; 
     &lt;li&gt;Updated &lt;code&gt;dockerfile&lt;/code&gt; to fix incomplete text content parsing due to missing fonts in Linux #2915&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Usability improvements&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Updated &lt;code&gt;compose.yaml&lt;/code&gt; to facilitate direct startup of &lt;code&gt;sglang-server&lt;/code&gt;, &lt;code&gt;mineru-api&lt;/code&gt;, and &lt;code&gt;mineru-gradio&lt;/code&gt; services&lt;/li&gt; 
     &lt;li&gt;Launched brand new &lt;a href="https://opendatalab.github.io/MinerU/"&gt;online documentation site&lt;/a&gt;, simplified readme, providing better documentation experience&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/07/05 2.1.0 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;This is the first major update of MinerU 2, which includes a large number of new features and improvements, covering significant performance optimizations, user experience enhancements, and bug fixes. The detailed update contents are as follows:&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Performance Optimizations:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Significantly improved preprocessing speed for documents with specific resolutions (around 2000 pixels on the long side).&lt;/li&gt; 
     &lt;li&gt;Greatly enhanced post-processing speed when the &lt;code&gt;pipeline&lt;/code&gt; backend handles batch processing of documents with fewer pages (&amp;lt;10 pages).&lt;/li&gt; 
     &lt;li&gt;Layout analysis speed of the &lt;code&gt;pipeline&lt;/code&gt; backend has been increased by approximately 20%.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Experience Enhancements:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Built-in ready-to-use &lt;code&gt;fastapi service&lt;/code&gt; and &lt;code&gt;gradio webui&lt;/code&gt;. For detailed usage instructions, please refer to &lt;a href="https://opendatalab.github.io/MinerU/usage/quick_usage/#advanced-usage-via-api-webui-sglang-clientserver"&gt;Documentation&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;Adapted to &lt;code&gt;sglang&lt;/code&gt; version &lt;code&gt;0.4.8&lt;/code&gt;, significantly reducing the GPU memory requirements for the &lt;code&gt;vlm-sglang&lt;/code&gt; backend. It can now run on graphics cards with as little as &lt;code&gt;8GB GPU memory&lt;/code&gt; (Turing architecture or newer).&lt;/li&gt; 
     &lt;li&gt;Added transparent parameter passing for all commands related to &lt;code&gt;sglang&lt;/code&gt;, allowing the &lt;code&gt;sglang-engine&lt;/code&gt; backend to receive all &lt;code&gt;sglang&lt;/code&gt; parameters consistently with the &lt;code&gt;sglang-server&lt;/code&gt;.&lt;/li&gt; 
     &lt;li&gt;Supports feature extensions based on configuration files, including &lt;code&gt;custom formula delimiters&lt;/code&gt;, &lt;code&gt;enabling heading classification&lt;/code&gt;, and &lt;code&gt;customizing local model directories&lt;/code&gt;. For detailed usage instructions, please refer to &lt;a href="https://opendatalab.github.io/MinerU/usage/quick_usage/#extending-mineru-functionality-with-configuration-files"&gt;Documentation&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;New Features:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Updated the &lt;code&gt;pipeline&lt;/code&gt; backend with the PP-OCRv5 multilingual text recognition model, supporting text recognition in 37 languages such as French, Spanish, Portuguese, Russian, and Korean, with an average accuracy improvement of over 30%. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Introduced limited support for vertical text layout in the &lt;code&gt;pipeline&lt;/code&gt; backend.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/20 2.0.6 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed occasional parsing interruptions caused by invalid block content in &lt;code&gt;vlm&lt;/code&gt; mode&lt;/li&gt; 
   &lt;li&gt;Fixed parsing interruptions caused by incomplete table structures in &lt;code&gt;vlm&lt;/code&gt; mode&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/17 2.0.5 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where models were still required to be downloaded in the &lt;code&gt;sglang-client&lt;/code&gt; mode&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where the &lt;code&gt;sglang-client&lt;/code&gt; mode unnecessarily depended on packages like &lt;code&gt;torch&lt;/code&gt; during runtime.&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where only the first instance would take effect when attempting to launch multiple &lt;code&gt;sglang-client&lt;/code&gt; instances via multiple URLs within the same process&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/15 2.0.3 released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed a configuration file key-value update error that occurred when downloading model type was set to &lt;code&gt;all&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where the formula and table feature toggle switches were not working in &lt;code&gt;command line mode&lt;/code&gt;, causing the features to remain enabled.&lt;/li&gt; 
   &lt;li&gt;Fixed compatibility issues with sglang version 0.4.7 in the &lt;code&gt;sglang-engine&lt;/code&gt; mode.&lt;/li&gt; 
   &lt;li&gt;Updated Dockerfile and installation documentation for deploying the full version of MinerU in sglang environment&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/13 2.0.0 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;New Architecture&lt;/strong&gt;: MinerU 2.0 has been deeply restructured in code organization and interaction methods, significantly improving system usability, maintainability, and extensibility. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Removal of Third-party Dependency Limitations&lt;/strong&gt;: Completely eliminated the dependency on &lt;code&gt;pymupdf&lt;/code&gt;, moving the project toward a more open and compliant open-source direction.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ready-to-use, Easy Configuration&lt;/strong&gt;: No need to manually edit JSON configuration files; most parameters can now be set directly via command line or API.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Automatic Model Management&lt;/strong&gt;: Added automatic model download and update mechanisms, allowing users to complete model deployment without manual intervention.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Offline Deployment Friendly&lt;/strong&gt;: Provides built-in model download commands, supporting deployment requirements in completely offline environments.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Streamlined Code Structure&lt;/strong&gt;: Removed thousands of lines of redundant code, simplified class inheritance logic, significantly improving code readability and development efficiency.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Unified Intermediate Format Output&lt;/strong&gt;: Adopted standardized &lt;code&gt;middle_json&lt;/code&gt; format, compatible with most secondary development scenarios based on this format, ensuring seamless ecosystem business migration.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;New Model&lt;/strong&gt;: MinerU 2.0 integrates our latest small-parameter, high-performance multimodal document parsing model, achieving end-to-end high-speed, high-precision document understanding. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Small Model, Big Capabilities&lt;/strong&gt;: With parameters under 1B, yet surpassing traditional 72B-level vision-language models (VLMs) in parsing accuracy.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multiple Functions in One&lt;/strong&gt;: A single model covers multilingual recognition, handwriting recognition, layout analysis, table parsing, formula recognition, reading order sorting, and other core tasks.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ultimate Inference Speed&lt;/strong&gt;: Achieves peak throughput exceeding 10,000 tokens/s through &lt;code&gt;sglang&lt;/code&gt; acceleration on a single NVIDIA 4090 card, easily handling large-scale document processing requirements.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Online Experience&lt;/strong&gt;: You can experience our brand-new VLM model on &lt;a href="https://mineru.net/OpenSourceTools/Extractor"&gt;MinerU.net&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;Hugging Face&lt;/a&gt;, and &lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;ModelScope&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Incompatible Changes Notice&lt;/strong&gt;: To improve overall architectural rationality and long-term maintainability, this version contains some incompatible changes: 
    &lt;ul&gt; 
     &lt;li&gt;Python package name changed from &lt;code&gt;magic-pdf&lt;/code&gt; to &lt;code&gt;mineru&lt;/code&gt;, and the command-line tool changed from &lt;code&gt;magic-pdf&lt;/code&gt; to &lt;code&gt;mineru&lt;/code&gt;. Please update your scripts and command calls accordingly.&lt;/li&gt; 
     &lt;li&gt;For modular system design and ecosystem consistency considerations, MinerU 2.0 no longer includes the LibreOffice document conversion module. If you need to process Office documents, we recommend converting them to PDF format through an independently deployed LibreOffice service before proceeding with subsequent parsing operations.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/05/24 Release 1.3.12&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added support for PPOCRv5 models, updated &lt;code&gt;ch_server&lt;/code&gt; model to &lt;code&gt;PP-OCRv5_rec_server&lt;/code&gt;, and &lt;code&gt;ch_lite&lt;/code&gt; model to &lt;code&gt;PP-OCRv5_rec_mobile&lt;/code&gt; (model update required) 
    &lt;ul&gt; 
     &lt;li&gt;In testing, we found that PPOCRv5(server) has some improvement for handwritten documents, but has slightly lower accuracy than v4_server_doc for other document types, so the default ch model remains unchanged as &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt;.&lt;/li&gt; 
     &lt;li&gt;Since PPOCRv5 has enhanced recognition capabilities for handwriting and special characters, you can manually choose the PPOCRv5 model for Japanese-Traditional Chinese mixed scenarios and handwritten documents&lt;/li&gt; 
     &lt;li&gt;You can select the appropriate model through the lang parameter &lt;code&gt;lang='ch_server'&lt;/code&gt; (Python API) or &lt;code&gt;--lang ch_server&lt;/code&gt; (command line): 
      &lt;ul&gt; 
       &lt;li&gt;&lt;code&gt;ch&lt;/code&gt;: &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; (default) (Chinese/English/Japanese/Traditional Chinese mixed/15K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_server&lt;/code&gt;: &lt;code&gt;PP-OCRv5_rec_server&lt;/code&gt; (Chinese/English/Japanese/Traditional Chinese mixed + handwriting/18K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_lite&lt;/code&gt;: &lt;code&gt;PP-OCRv5_rec_mobile&lt;/code&gt; (Chinese/English/Japanese/Traditional Chinese mixed + handwriting/18K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_server_v4&lt;/code&gt;: &lt;code&gt;PP-OCRv4_rec_server&lt;/code&gt; (Chinese/English mixed/6K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_lite_v4&lt;/code&gt;: &lt;code&gt;PP-OCRv4_rec_mobile&lt;/code&gt; (Chinese/English mixed/6K dictionary)&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Added support for handwritten documents through optimized layout recognition of handwritten text areas 
    &lt;ul&gt; 
     &lt;li&gt;This feature is supported by default, no additional configuration required&lt;/li&gt; 
     &lt;li&gt;You can refer to the instructions above to manually select the PPOCRv5 model for better handwritten document parsing results&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;The &lt;code&gt;huggingface&lt;/code&gt; and &lt;code&gt;modelscope&lt;/code&gt; demos have been updated to versions that support handwriting recognition and PPOCRv5 models, which you can experience online&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/29 Release 1.3.10&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added support for custom formula delimiters, which can be configured by modifying the &lt;code&gt;latex-delimiter-config&lt;/code&gt; section in the &lt;code&gt;magic-pdf.json&lt;/code&gt; file in your user directory.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/27 Release 1.3.9&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Optimized formula parsing functionality, improved formula rendering success rate&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/23 Release 1.3.8&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The default &lt;code&gt;ocr&lt;/code&gt; model (&lt;code&gt;ch&lt;/code&gt;) has been updated to &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; (model update required) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; is trained on a mixture of more Chinese document data and PP-OCR training data based on &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt;, adding recognition capabilities for some traditional Chinese characters, Japanese, and special characters. It can recognize over 15,000 characters and improves both document-specific and general text recognition abilities.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/ocr_modules/text_recognition.html#_3"&gt;Performance comparison of PP-OCRv4_server_rec_doc/PP-OCRv4_server_rec/PP-OCRv4_mobile_rec&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;After verification, the &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; model shows significant accuracy improvements in Chinese/English/Japanese/Traditional Chinese in both single language and mixed language scenarios, with comparable speed to &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt;, making it suitable for most use cases.&lt;/li&gt; 
     &lt;li&gt;In some pure English scenarios, &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; may have word adhesion issues, while &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt; performs better in these cases. Therefore, we've kept the &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt; model, which users can access by adding the parameter &lt;code&gt;lang='ch_server'&lt;/code&gt; (Python API) or &lt;code&gt;--lang ch_server&lt;/code&gt; (command line).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/22 Release 1.3.7&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where the lang parameter was ineffective during table parsing model initialization&lt;/li&gt; 
   &lt;li&gt;Fixed the significant speed reduction of OCR and table parsing in &lt;code&gt;cpu&lt;/code&gt; mode&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/16 Release 1.3.4&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Slightly improved OCR-det speed by removing some unnecessary blocks&lt;/li&gt; 
   &lt;li&gt;Fixed page-internal sorting errors caused by footnotes in certain cases&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/12 Release 1.3.2&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed dependency version incompatibility issues when installing on Windows with Python 3.13&lt;/li&gt; 
   &lt;li&gt;Optimized memory usage during batch inference&lt;/li&gt; 
   &lt;li&gt;Improved parsing of tables rotated 90 degrees&lt;/li&gt; 
   &lt;li&gt;Enhanced parsing of oversized tables in financial report samples&lt;/li&gt; 
   &lt;li&gt;Fixed the occasional word adhesion issue in English text areas when OCR language is not specified (model update required)&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/08 Release 1.3.1&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed several compatibility issues 
    &lt;ul&gt; 
     &lt;li&gt;Added support for Python 3.13&lt;/li&gt; 
     &lt;li&gt;Made final adaptations for outdated Linux systems (such as CentOS 7) with no guarantee of continued support in future versions, &lt;a href="https://github.com/opendatalab/MinerU/issues/1004"&gt;installation instructions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/03 Release 1.3.0&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Installation and compatibility optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Resolved compatibility issues caused by &lt;code&gt;detectron2&lt;/code&gt; by removing &lt;code&gt;layoutlmv3&lt;/code&gt; usage in layout&lt;/li&gt; 
     &lt;li&gt;Extended torch version compatibility to 2.2~2.6 (excluding 2.5)&lt;/li&gt; 
     &lt;li&gt;Added CUDA compatibility for versions 11.8/12.4/12.6/12.8 (CUDA version determined by torch), solving compatibility issues for users with 50-series and H-series GPUs&lt;/li&gt; 
     &lt;li&gt;Extended Python compatibility to versions 3.10~3.12, fixing the issue of automatic downgrade to version 0.6.1 when installing in non-3.10 environments&lt;/li&gt; 
     &lt;li&gt;Optimized offline deployment process, eliminating the need to download any model files after successful deployment&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Performance optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Enhanced parsing speed for batches of small files by supporting batch processing of multiple PDF files (&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/demo/batch_demo.py"&gt;script example&lt;/a&gt;), with formula parsing speed improved by up to 1400% and overall parsing speed improved by up to 500% compared to version 1.0.1&lt;/li&gt; 
     &lt;li&gt;Reduced memory usage and improved parsing speed by optimizing MFR model loading and usage (requires re-running the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/how_to_download_models_zh_cn.md"&gt;model download process&lt;/a&gt; to get incremental updates to model files)&lt;/li&gt; 
     &lt;li&gt;Optimized GPU memory usage, requiring only 6GB minimum to run this project&lt;/li&gt; 
     &lt;li&gt;Improved running speed on MPS devices&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Parsing effect optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Updated MFR model to &lt;code&gt;unimernet(2503)&lt;/code&gt;, fixing line break loss issues in multi-line formulas&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Usability optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Completely replaced the &lt;code&gt;paddle&lt;/code&gt; framework and &lt;code&gt;paddleocr&lt;/code&gt; in the project by using &lt;code&gt;paddleocr2torch&lt;/code&gt;, resolving conflicts between &lt;code&gt;paddle&lt;/code&gt; and &lt;code&gt;torch&lt;/code&gt;, as well as thread safety issues caused by the &lt;code&gt;paddle&lt;/code&gt; framework&lt;/li&gt; 
     &lt;li&gt;Added real-time progress bar display during parsing, allowing precise tracking of parsing progress and making the waiting process more bearable&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/03/03 1.2.1 released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the impact on punctuation marks during full-width to half-width conversion of letters and numbers&lt;/li&gt; 
   &lt;li&gt;Fixed caption matching inaccuracies in certain scenarios&lt;/li&gt; 
   &lt;li&gt;Fixed formula span loss issues in certain scenarios&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/02/24 1.2.0 released&lt;/summary&gt; 
  &lt;p&gt;This version includes several fixes and improvements to enhance parsing efficiency and accuracy:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Increased classification speed for PDF documents in auto mode.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Parsing Optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Improved parsing logic for documents containing watermarks, significantly enhancing the parsing results for such documents.&lt;/li&gt; 
     &lt;li&gt;Enhanced the matching logic for multiple images/tables and captions within a single page, improving the accuracy of image-text matching in complex layouts.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Fixed an issue where image/table spans were incorrectly filled into text blocks under certain conditions.&lt;/li&gt; 
     &lt;li&gt;Resolved an issue where title blocks were empty in some cases.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/01/22 1.1.0 released&lt;/summary&gt; 
  &lt;p&gt;In this version we have focused on improving parsing accuracy and efficiency:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Model capability upgrade&lt;/strong&gt; (requires re-executing the &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/how_to_download_models_en.md"&gt;model download process&lt;/a&gt; to obtain incremental updates of model files) 
    &lt;ul&gt; 
     &lt;li&gt;The layout recognition model has been upgraded to the latest &lt;code&gt;doclayout_yolo(2501)&lt;/code&gt; model, improving layout recognition accuracy.&lt;/li&gt; 
     &lt;li&gt;The formula parsing model has been upgraded to the latest &lt;code&gt;unimernet(2501)&lt;/code&gt; model, improving formula recognition accuracy.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Performance optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;On devices that meet certain configuration requirements (16GB+ VRAM), by optimizing resource usage and restructuring the processing pipeline, overall parsing speed has been increased by more than 50%.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Parsing effect optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Added a new heading classification feature (testing version, enabled by default) to the online demo (&lt;a href="https://mineru.net/OpenSourceTools/Extractor"&gt;mineru.net&lt;/a&gt;/&lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;huggingface&lt;/a&gt;/&lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;modelscope&lt;/a&gt;), which supports hierarchical classification of headings, thereby enhancing document structuring.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/01/10 1.0.1 released&lt;/summary&gt; 
  &lt;p&gt;This is our first official release, where we have introduced a completely new API interface and enhanced compatibility through extensive refactoring, as well as a brand new automatic language identification feature:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;New API Interface&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;For the data-side API, we have introduced the Dataset class, designed to provide a robust and flexible data processing framework. This framework currently supports a variety of document formats, including images (.jpg and .png), PDFs, Word documents (.doc and .docx), and PowerPoint presentations (.ppt and .pptx). It ensures effective support for data processing tasks ranging from simple to complex.&lt;/li&gt; 
     &lt;li&gt;For the user-side API, we have meticulously designed the MinerU processing workflow as a series of composable Stages. Each Stage represents a specific processing step, allowing users to define new Stages according to their needs and creatively combine these stages to customize their data processing workflows.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Enhanced Compatibility&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;By optimizing the dependency environment and configuration items, we ensure stable and efficient operation on ARM architecture Linux systems.&lt;/li&gt; 
     &lt;li&gt;We have deeply integrated with Huawei Ascend NPU acceleration, providing autonomous and controllable high-performance computing capabilities. This supports the localization and development of AI application platforms in China. &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/README_Ascend_NPU_Acceleration_zh_CN.md"&gt;Ascend NPU Acceleration&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Automatic Language Identification&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;By introducing a new language recognition model, setting the &lt;code&gt;lang&lt;/code&gt; configuration to &lt;code&gt;auto&lt;/code&gt; during document parsing will automatically select the appropriate OCR language model, improving the accuracy of scanned document parsing.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/22 0.10.0 released&lt;/summary&gt; 
  &lt;p&gt;Introducing hybrid OCR text extraction capabilities:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Significantly improved parsing performance in complex text distribution scenarios such as dense formulas, irregular span regions, and text represented by images.&lt;/li&gt; 
   &lt;li&gt;Combines the dual advantages of accurate content extraction and faster speed in text mode, and more precise span/line region recognition in OCR mode.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/15 0.9.3 released&lt;/summary&gt; 
  &lt;p&gt;Integrated &lt;a href="https://github.com/RapidAI/RapidTable"&gt;RapidTable&lt;/a&gt; for table recognition, improving single-table parsing speed by more than 10 times, with higher accuracy and lower GPU memory usage.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/06 0.9.2 released&lt;/summary&gt; 
  &lt;p&gt;Integrated the &lt;a href="https://huggingface.co/U4R/StructTable-InternVL2-1B"&gt;StructTable-InternVL2-1B&lt;/a&gt; model for table recognition functionality.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/10/31 0.9.0 released&lt;/summary&gt; 
  &lt;p&gt;This is a major new version with extensive code refactoring, addressing numerous issues, improving performance, reducing hardware requirements, and enhancing usability:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Refactored the sorting module code to use &lt;a href="https://github.com/ppaanngggg/layoutreader"&gt;layoutreader&lt;/a&gt; for reading order sorting, ensuring high accuracy in various layouts.&lt;/li&gt; 
   &lt;li&gt;Refactored the paragraph concatenation module to achieve good results in cross-column, cross-page, cross-figure, and cross-table scenarios.&lt;/li&gt; 
   &lt;li&gt;Refactored the list and table of contents recognition functions, significantly improving the accuracy of list blocks and table of contents blocks, as well as the parsing of corresponding text paragraphs.&lt;/li&gt; 
   &lt;li&gt;Refactored the matching logic for figures, tables, and descriptive text, greatly enhancing the accuracy of matching captions and footnotes to figures and tables, and reducing the loss rate of descriptive text to near zero.&lt;/li&gt; 
   &lt;li&gt;Added multi-language support for OCR, supporting detection and recognition of 84 languages. For the list of supported languages, see &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/ppocr/blog/multi_languages.html#5-support-languages-and-abbreviations"&gt;OCR Language Support List&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Added memory recycling logic and other memory optimization measures, significantly reducing memory usage. The memory requirement for enabling all acceleration features except table acceleration (layout/formula/OCR) has been reduced from 16GB to 8GB, and the memory requirement for enabling all acceleration features has been reduced from 24GB to 10GB.&lt;/li&gt; 
   &lt;li&gt;Optimized configuration file feature switches, adding an independent formula detection switch to significantly improve speed and parsing results when formula detection is not needed.&lt;/li&gt; 
   &lt;li&gt;Integrated &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit 1.0&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Added the self-developed &lt;code&gt;doclayout_yolo&lt;/code&gt; model, which speeds up processing by more than 10 times compared to the original solution while maintaining similar parsing effects, and can be freely switched with &lt;code&gt;layoutlmv3&lt;/code&gt; via the configuration file.&lt;/li&gt; 
     &lt;li&gt;Upgraded formula parsing to &lt;code&gt;unimernet 0.2.1&lt;/code&gt;, improving formula parsing accuracy while significantly reducing memory usage.&lt;/li&gt; 
     &lt;li&gt;Due to the repository change for &lt;code&gt;PDF-Extract-Kit 1.0&lt;/code&gt;, you need to re-download the model. Please refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/how_to_download_models_en.md"&gt;How to Download Models&lt;/a&gt; for detailed steps.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/09/27 Version 0.8.1 released&lt;/summary&gt; 
  &lt;p&gt;Fixed some bugs, and providing a &lt;a href="https://github.com/opendatalab/MinerU/raw/master/projects/web_demo/README.md"&gt;localized deployment version&lt;/a&gt; of the &lt;a href="https://opendatalab.com/OpenSourceTools/Extractor/PDF/"&gt;online demo&lt;/a&gt; and the &lt;a href="https://github.com/opendatalab/MinerU/raw/master/projects/web/README.md"&gt;front-end interface&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/09/09 Version 0.8.0 released&lt;/summary&gt; 
  &lt;p&gt;Supporting fast deployment with Dockerfile, and launching demos on Huggingface and Modelscope.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/30 Version 0.7.1 released&lt;/summary&gt; 
  &lt;p&gt;Add paddle tablemaster table recognition option&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/09 Version 0.7.0b1 released&lt;/summary&gt; 
  &lt;p&gt;Simplified installation process, added table recognition functionality&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/01 Version 0.6.2b1 released&lt;/summary&gt; 
  &lt;p&gt;Optimized dependency conflict issues and installation documentation&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/07/05 Initial open-source release&lt;/summary&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;h1&gt;MinerU&lt;/h1&gt; 
&lt;h2&gt;Project Introduction&lt;/h2&gt; 
&lt;p&gt;MinerU is a tool that converts PDFs into machine-readable formats (e.g., markdown, JSON), allowing for easy extraction into any format. MinerU was born during the pre-training process of &lt;a href="https://github.com/InternLM/InternLM"&gt;InternLM&lt;/a&gt;. We focus on solving symbol conversion issues in scientific literature and hope to contribute to technological development in the era of large models. Compared to well-known commercial products, MinerU is still young. If you encounter any issues or if the results are not as expected, please submit an issue on &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;issue&lt;/a&gt; and &lt;strong&gt;attach the relevant PDF&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4bea02c9-6d54-4cd6-97ed-dff14340982c"&gt;https://github.com/user-attachments/assets/4bea02c9-6d54-4cd6-97ed-dff14340982c&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove headers, footers, footnotes, page numbers, etc., to ensure semantic coherence.&lt;/li&gt; 
 &lt;li&gt;Output text in human-readable order, suitable for single-column, multi-column, and complex layouts.&lt;/li&gt; 
 &lt;li&gt;Preserve the structure of the original document, including headings, paragraphs, lists, etc.&lt;/li&gt; 
 &lt;li&gt;Extract images, image descriptions, tables, table titles, and footnotes.&lt;/li&gt; 
 &lt;li&gt;Automatically recognize and convert formulas in the document to LaTeX format.&lt;/li&gt; 
 &lt;li&gt;Automatically recognize and convert tables in the document to HTML format.&lt;/li&gt; 
 &lt;li&gt;Automatically detect scanned PDFs and garbled PDFs and enable OCR functionality.&lt;/li&gt; 
 &lt;li&gt;OCR supports detection and recognition of 84 languages.&lt;/li&gt; 
 &lt;li&gt;Supports multiple output formats, such as multimodal and NLP Markdown, JSON sorted by reading order, and rich intermediate formats.&lt;/li&gt; 
 &lt;li&gt;Supports various visualization results, including layout visualization and span visualization, for efficient confirmation of output quality.&lt;/li&gt; 
 &lt;li&gt;Supports running in a pure CPU environment, and also supports GPU(CUDA)/NPU(CANN)/MPS acceleration&lt;/li&gt; 
 &lt;li&gt;Compatible with Windows, Linux, and Mac platforms.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;p&gt;If you encounter any installation issues, please first consult the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/#faq"&gt;FAQ&lt;/a&gt;. &lt;br /&gt; If the parsing results are not as expected, refer to the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/#known-issues"&gt;Known Issues&lt;/a&gt;. &lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Online Experience&lt;/h2&gt; 
&lt;h3&gt;Official online web application&lt;/h3&gt; 
&lt;p&gt;The official online version has the same functionality as the client, with a beautiful interface and rich features, requires login to use&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mineru.net/OpenSourceTools/Extractor?source=github"&gt;&lt;img src="https://img.shields.io/badge/webapp_on_mineru.net-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTM0IiBoZWlnaHQ9IjEzNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJtMTIyLDljMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGQ9Im0xMjIsOWMwLDUtNCw5LTksOXMtOS00LTktOSw0LTksOS05LDksNCw5LDl6IiBmaWxsPSIjMDEwMTAxIi8+PHBhdGggZD0ibTkxLDE4YzAsNS00LDktOSw5cy05LTQtOS05LDQtOSw5LTksOSw0LDksOXoiIGZpbGw9InVybCgjYikiLz48cGF0aCBkPSJtOTEsMThjMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0iIzAxMDEwMSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0idXJsKCNjKSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0iIzAxMDEwMSIvPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYSIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYyIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=&amp;amp;labelColor=white" alt="OpenDataLab" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Gradio-based online demo&lt;/h3&gt; 
&lt;p&gt;A WebUI developed based on Gradio, with a simple interface and only core parsing functionality, no login required&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-yellow.svg?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Local Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Pre-installation Notice—Hardware and Software Environment Support&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;To ensure the stability and reliability of the project, we only optimize and test for specific hardware and software environments during development. This ensures that users deploying and running the project on recommended system configurations will get the best performance with the fewest compatibility issues.&lt;/p&gt; 
 &lt;p&gt;By focusing resources on the mainline environment, our team can more efficiently resolve potential bugs and develop new features.&lt;/p&gt; 
 &lt;p&gt;In non-mainline environments, due to the diversity of hardware and software configurations, as well as third-party dependency compatibility issues, we cannot guarantee 100% project availability. Therefore, for users who wish to use this project in non-recommended environments, we suggest carefully reading the documentation and FAQ first. Most issues already have corresponding solutions in the FAQ. We also encourage community feedback to help us gradually expand support.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;Parsing Backend&lt;/td&gt; 
   &lt;td&gt;pipeline&lt;/td&gt; 
   &lt;td&gt;vlm-transformers&lt;/td&gt; 
   &lt;td&gt;vlm-vllm&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating System&lt;/td&gt; 
   &lt;td&gt;Linux / Windows / macOS&lt;/td&gt; 
   &lt;td&gt;Linux / Windows&lt;/td&gt; 
   &lt;td&gt;Linux / Windows (via WSL2)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Inference Support&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td colspan="2"&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Requirements&lt;/td&gt; 
   &lt;td&gt;Turing architecture and later, 6GB+ VRAM or Apple Silicon&lt;/td&gt; 
   &lt;td colspan="2"&gt;Turing architecture and later, 8GB+ VRAM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory Requirements&lt;/td&gt; 
   &lt;td colspan="3"&gt;Minimum 16GB+, recommended 32GB+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Disk Space Requirements&lt;/td&gt; 
   &lt;td colspan="3"&gt;20GB+, SSD recommended&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python Version&lt;/td&gt; 
   &lt;td colspan="3"&gt;3.10-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Install MinerU&lt;/h3&gt; 
&lt;h4&gt;Install MinerU using pip or uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install uv
uv pip install -U "mineru[core]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install MinerU from source code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/opendatalab/MinerU.git
cd MinerU
uv pip install -e .[core]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;code&gt;mineru[core]&lt;/code&gt; includes all core features except &lt;code&gt;vLLM&lt;/code&gt; acceleration, compatible with Windows / Linux / macOS systems, suitable for most users. If you need to use &lt;code&gt;vLLM&lt;/code&gt; acceleration for VLM model inference or install a lightweight client on edge devices, please refer to the documentation &lt;a href="https://opendatalab.github.io/MinerU/quick_start/extension_modules/"&gt;Extension Modules Installation Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h4&gt;Deploy MinerU using Docker&lt;/h4&gt; 
&lt;p&gt;MinerU provides a convenient Docker deployment method, which helps quickly set up the environment and solve some tricky environment compatibility issues. You can get the &lt;a href="https://opendatalab.github.io/MinerU/quick_start/docker_deployment/"&gt;Docker Deployment Instructions&lt;/a&gt; in the documentation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using MinerU&lt;/h3&gt; 
&lt;p&gt;The simplest command line invocation is:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mineru -p &amp;lt;input_path&amp;gt; -o &amp;lt;output_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can use MinerU for PDF parsing through various methods such as command line, API, and WebUI. For detailed instructions, please refer to the &lt;a href="https://opendatalab.github.io/MinerU/usage/"&gt;Usage Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;TODO&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Reading order based on the model&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Recognition of &lt;code&gt;index&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; in the main text&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Table recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Heading Classification&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Handwritten Text Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Vertical Text Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Latin Accent Mark Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Code block recognition in the main text&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/chemical_knowledge_introduction/introduction.pdf"&gt;Chemical formula recognition&lt;/a&gt;(mineru.net)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Geometric shape recognition&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reading order is determined by the model based on the spatial distribution of readable content, and may be out of order in some areas under extremely complex layouts.&lt;/li&gt; 
 &lt;li&gt;Limited support for vertical text.&lt;/li&gt; 
 &lt;li&gt;Tables of contents and lists are recognized through rules, and some uncommon list formats may not be recognized.&lt;/li&gt; 
 &lt;li&gt;Code blocks are not yet supported in the layout model.&lt;/li&gt; 
 &lt;li&gt;Comic books, art albums, primary school textbooks, and exercises cannot be parsed well.&lt;/li&gt; 
 &lt;li&gt;Table recognition may result in row/column recognition errors in complex tables.&lt;/li&gt; 
 &lt;li&gt;OCR recognition may produce inaccurate characters in PDFs of lesser-known languages (e.g., diacritical marks in Latin script, easily confused characters in Arabic script).&lt;/li&gt; 
 &lt;li&gt;Some formulas may not render correctly in Markdown.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you encounter any issues during usage, you can first check the &lt;a href="https://opendatalab.github.io/MinerU/faq/"&gt;FAQ&lt;/a&gt; for solutions.&lt;/li&gt; 
 &lt;li&gt;If your issue remains unresolved, you may also use &lt;a href="https://deepwiki.com/opendatalab/MinerU"&gt;DeepWiki&lt;/a&gt; to interact with an AI assistant, which can address most common problems.&lt;/li&gt; 
 &lt;li&gt;If you still cannot resolve the issue, you are welcome to join our community via &lt;a href="https://discord.gg/Tdedn9GTXq"&gt;Discord&lt;/a&gt; or &lt;a href="https://mineru.net/community-portal/?aliasId=3c430f94"&gt;WeChat&lt;/a&gt; to discuss with other users and developers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;All Thanks To Our Contributors&lt;/h1&gt; 
&lt;a href="https://github.com/opendatalab/MinerU/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=opendatalab/MinerU" /&gt; &lt;/a&gt; 
&lt;h1&gt;License Information&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/LICENSE.md"&gt;LICENSE.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Currently, some models in this project are trained based on YOLO. However, since YOLO follows the AGPL license, it may impose restrictions on certain use cases. In future iterations, we plan to explore and replace these with models under more permissive licenses to enhance user-friendliness and flexibility.&lt;/p&gt; 
&lt;h1&gt;Acknowledgments&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/DocLayout-YOLO"&gt;DocLayout-YOLO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/UniMERNet"&gt;UniMERNet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RapidAI/RapidTable"&gt;RapidTable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RapidAI/TableStructureRec"&gt;TableStructureRec&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;PaddleOCR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frotms/PaddleOCR2Pytorch"&gt;PaddleOCR2Pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ppaanngggg/layoutreader"&gt;layoutreader&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Sanster/xy-cut"&gt;xy-cut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LlmKira/fast-langdetect"&gt;fast-langdetect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypdfium2-team/pypdfium2"&gt;pypdfium2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datalab-to/pdftext"&gt;pdftext&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdfminer/pdfminer.six"&gt;pdfminer.six&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/py-pdf/pypdf"&gt;pypdf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/magika"&gt;magika&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Citation&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{niu2025mineru25decoupledvisionlanguagemodel,
      title={MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing}, 
      author={Junbo Niu and Zheng Liu and Zhuangcheng Gu and Bin Wang and Linke Ouyang and Zhiyuan Zhao and Tao Chu and Tianyao He and Fan Wu and Qintong Zhang and Zhenjiang Jin and Guang Liang and Rui Zhang and Wenzheng Zhang and Yuan Qu and Zhifei Ren and Yuefeng Sun and Yuanhong Zheng and Dongsheng Ma and Zirui Tang and Boyu Niu and Ziyang Miao and Hejun Dong and Siyi Qian and Junyuan Zhang and Jingzhou Chen and Fangdong Wang and Xiaomeng Zhao and Liqun Wei and Wei Li and Shasha Wang and Ruiliang Xu and Yuanyuan Cao and Lu Chen and Qianqian Wu and Huaiyu Gu and Lindong Lu and Keming Wang and Dechen Lin and Guanlin Shen and Xuanhe Zhou and Linfeng Zhang and Yuhang Zang and Xiaoyi Dong and Jiaqi Wang and Bo Zhang and Lei Bai and Pei Chu and Weijia Li and Jiang Wu and Lijun Wu and Zhenxiang Li and Guangyu Wang and Zhongying Tu and Chao Xu and Kai Chen and Yu Qiao and Bowen Zhou and Dahua Lin and Wentao Zhang and Conghui He},
      year={2025},
      eprint={2509.22186},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2509.22186}, 
}

@misc{wang2024mineruopensourcesolutionprecise,
      title={MinerU: An Open-Source Solution for Precise Document Content Extraction}, 
      author={Bin Wang and Chao Xu and Xiaomeng Zhao and Linke Ouyang and Fan Wu and Zhiyuan Zhao and Rui Xu and Kaiwen Liu and Yuan Qu and Fukai Shang and Bo Zhang and Liqun Wei and Zhihao Sui and Wei Li and Botian Shi and Yu Qiao and Dahua Lin and Conghui He},
      year={2024},
      eprint={2409.18839},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18839}, 
}

@article{he2024opendatalab,
  title={Opendatalab: Empowering general artificial intelligence with open datasets},
  author={He, Conghui and Li, Wei and Jin, Zhenjiang and Xu, Chao and Wang, Bin and Lin, Dahua},
  journal={arXiv preprint arXiv:2407.13773},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;a&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Links&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenDCAI/DataFlow"&gt;Easy Data Preparation with latest LLMs-based Operators and Pipelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/Vis3"&gt;Vis3 (OSS browser based on s3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/labelU"&gt;LabelU (A Lightweight Multi-modal Data Annotation Tool)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/LabelLLM"&gt;LabelLLM (An Open-source LLM Dialogue Annotation Platform)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit (A Comprehensive Toolkit for High-Quality PDF Content Extraction)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/OmniDocBench"&gt;OmniDocBench (A Comprehensive Benchmark for Document Parsing and Evaluation)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/magic-html"&gt;Magic-HTML (Mixed web page extraction tool)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/magic-doc"&gt;Magic-Doc (Fast speed ppt/pptx/doc/docx/pdf extraction tool)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MigoXLab/dingo"&gt;Dingo: A Comprehensive AI Data Quality Evaluation Tool&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>