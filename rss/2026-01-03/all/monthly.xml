<rss version="2.0">
  <channel>
    <title>GitHub All Languages Monthly Trending</title>
    <description>Monthly Trending of All Languages in GitHub</description>
    <pubDate>Fri, 02 Jan 2026 01:49:27 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>sst/opencode</title>
      <link>https://github.com/sst/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sst/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install opencode              # macOS and Linux
paru -S opencode-bin               # Arch Linux
mise use -g opencode               # Any OS
nix run nixpkgs#opencode           # or github:sst/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/sst/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between, you can switch between these using the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multistep tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/sst/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different from Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;What's the other repo?&lt;/h4&gt; 
&lt;p&gt;The other confusingly named repo has no relation to this one. You can &lt;a href="https://x.com/thdxr/status/1933561254481666466"&gt;read the story behind it here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm-omni</title>
      <link>https://github.com/vllm-project/vllm-omni</link>
      <description>&lt;p&gt;A framework for efficient model inference with omni-modality models&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" src="https://raw.githubusercontent.com/vllm-project/vllm-omni/refs/heads/main/docs/source/logos/vllm-omni-logo.png" /&gt; 
  &lt;img alt="vllm-omni" src="https://raw.githubusercontent.com/vllm-project/vllm-omni/refs/heads/main/docs/source/logos/vllm-omni-logo.png" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap omni-modality model serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://vllm-omni.readthedocs.io/en/latest/"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/11] vLLM community officially released &lt;a href="https://github.com/vllm-project/vllm-omni"&gt;vllm-project/vllm-omni&lt;/a&gt; in order to support omni-modality models serving.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt; was originally designed to support large language models for text-based autoregressive generation tasks. vLLM-Omni is a framework that extends its support for omni-modality model inference and serving:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Omni-modality&lt;/strong&gt;: Text, image, video, and audio data processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Non-autoregressive Architectures&lt;/strong&gt;: extend the AR support of vLLM to Diffusion Transformers (DiT) and other parallel generation models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Heterogeneous outputs&lt;/strong&gt;: from traditional text generation to multimodal outputs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="vllm-omni" src="https://raw.githubusercontent.com/vllm-project/vllm-omni/refs/heads/main/docs/source/architecture/omni-modality-model-architecture.png" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;vLLM-Omni is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art AR support by leveraging efficient KV cache management from vLLM&lt;/li&gt; 
 &lt;li&gt;Pipelined stage execution overlapping for high throughput performance&lt;/li&gt; 
 &lt;li&gt;Fully disaggregation based on OmniConnector and dynamic resource allocation across stages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM-Omni is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Heterogeneous pipeline abstraction to manage complex model workflows&lt;/li&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM-Omni seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Omni-modality models (e.g. Qwen-Omni)&lt;/li&gt; 
 &lt;li&gt;Multi-modality generation models (e.g. Qwen-Image)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://vllm-omni.readthedocs.io/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vllm-omni.readthedocs.io/en/latest/getting_started/installation/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vllm-omni.readthedocs.io/en/latest/getting_started/quickstart/"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vllm-omni.readthedocs.io/en/latest/models/supported_models/"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://vllm-omni.readthedocs.io/en/latest/contributing/"&gt;Contributing to vLLM-Omni&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Join the Community&lt;/h2&gt; 
&lt;p&gt;Feel free to ask questions, provide feedbacks and discuss with fellow users of vLLM-Omni in &lt;code&gt;#sig-omni&lt;/code&gt; slack channel at &lt;a href="https://slack.vllm.ai"&gt;slack.vllm.ai&lt;/a&gt; or vLLM user forum at &lt;a href="https://discuss.vllm.ai"&gt;discuss.vllm.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, as found in the &lt;a href="https://raw.githubusercontent.com/vllm-project/vllm-omni/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustfs/rustfs</title>
      <link>https://github.com/rustfs/rustfs</link>
      <description>&lt;p&gt;üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rustfs.com"&gt;&lt;img src="https://rustfs.com/images/rustfs-github.png" alt="RustFS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;RustFS is a high-performance, distributed object storage system built in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/ci.yml"&gt;&lt;img alt="CI" src="https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/docker.yml"&gt;&lt;img alt="Build and Push Docker Images" src="https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rustfs/rustfs" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/rustfs/rustfs" /&gt; &lt;a href="https://hellogithub.com/repository/rustfs/rustfs" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;amp;claim_uid=MsbvjYeLDKAH457&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14181" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14181" alt="rustfs%2Frustfs | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.rustfs.com/installation/"&gt;Getting Started&lt;/a&gt; ¬∑ &lt;a href="https://docs.rustfs.com/"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;Bug reports&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; English | &lt;a href="https://github.com/rustfs/rustfs/raw/main/README_ZH.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=pt"&gt;Portuguese&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;RustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.&lt;/p&gt; 
&lt;p&gt;Unlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.&lt;/p&gt; 
&lt;h2&gt;Feature &amp;amp; Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Built with Rust to ensure maximum speed and resource efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Architecture&lt;/strong&gt;: Scalable and fault-tolerant design suitable for large-scale deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Compatibility&lt;/strong&gt;: Seamless integration with existing S3-compatible applications and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Lake Support&lt;/strong&gt;: Optimized for high-throughput big data and AI workloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly&lt;/strong&gt;: Designed with simplicity in mind for easy deployment and management.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;S3 Core Features&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bitrot Protection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Upload / Download&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Single Node Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bucket Replication&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Logging&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Lifecycle Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Event Notifications&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Distributed Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;K8s Helm Charts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;RustFS KMS&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;RustFS vs MinIO Performance&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stress Test Environment:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Remark&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;2 Core&lt;/td&gt; 
   &lt;td&gt;Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Network&lt;/td&gt; 
   &lt;td&gt;15Gbps&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Drive&lt;/td&gt; 
   &lt;td&gt;40GB x 4&lt;/td&gt; 
   &lt;td&gt;IOPS 3800 / Drive&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a"&gt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RustFS vs Other Object Storage&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;RustFS&lt;/th&gt; 
   &lt;th align="left"&gt;Other Object Storage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Console Experience&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Powerful Console&lt;/strong&gt;&lt;br /&gt;Comprehensive management interface.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Basic / Limited Console&lt;/strong&gt;&lt;br /&gt;Often overly simple or lacking critical features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Language &amp;amp; Safety&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Rust-based&lt;/strong&gt;&lt;br /&gt;Memory safety by design.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Go or C-based&lt;/strong&gt;&lt;br /&gt;Potential for memory GC pauses or leaks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Data Sovereignty&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;No Telemetry / Full Compliance&lt;/strong&gt;&lt;br /&gt;Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Potential Risk&lt;/strong&gt;&lt;br /&gt;Possible legal exposure and unwanted data telemetry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Licensing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Permissive Apache 2.0&lt;/strong&gt;&lt;br /&gt;Business-friendly, no "poison pill" clauses.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Restrictive AGPL v3&lt;/strong&gt;&lt;br /&gt;Risk of license traps and intellectual property pollution.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Compatibility&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;100% S3 Compatible&lt;/strong&gt;&lt;br /&gt;Works with any cloud provider or client, anywhere.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Variable Compatibility&lt;/strong&gt;&lt;br /&gt;May lack support for local cloud vendors or specific APIs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Edge &amp;amp; IoT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Strong Edge Support&lt;/strong&gt;&lt;br /&gt;Ideal for secure, innovative edge devices.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Weak Edge Support&lt;/strong&gt;&lt;br /&gt;Often too heavy for edge gateways.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Risk Profile&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Enterprise Risk Mitigation&lt;/strong&gt;&lt;br /&gt;Clear IP rights and safe for commercial use.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Legal Risks&lt;/strong&gt;&lt;br /&gt;Intellectual property ambiguity and usage restrictions.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get started with RustFS, follow these steps:&lt;/p&gt; 
&lt;h3&gt;1. One-click Installation (Option 1)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://rustfs.com/install_rustfs.sh &amp;amp;&amp;amp; bash install_rustfs.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Docker Quick Start (Option 2)&lt;/h3&gt; 
&lt;p&gt;The RustFS container runs as a non-root user &lt;code&gt;rustfs&lt;/code&gt; (UID &lt;code&gt;10001&lt;/code&gt;). If you run Docker with &lt;code&gt;-v&lt;/code&gt; to mount a host directory, please ensure the host directory owner is set to &lt;code&gt;10001&lt;/code&gt;, otherwise you will encounter permission denied errors.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; # Create data and logs directories
 mkdir -p data logs

 # Change the owner of these directories
 chown -R 10001:10001 data logs

 # Using latest version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest

 # Using specific version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0-alpha.76
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use Docker Compose. Using the &lt;code&gt;docker-compose.yml&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose --profile observability up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: We recommend reviewing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.&lt;/p&gt; 
&lt;h3&gt;3. Build from Source (Option 3) - Advanced Users&lt;/h3&gt; 
&lt;p&gt;For developers who want to build RustFS Docker images from source with multi-architecture support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;docker-buildx.sh&lt;/code&gt; script supports: - &lt;strong&gt;Multi-architecture builds&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt; - &lt;strong&gt;Automatic version detection&lt;/strong&gt;: Uses git tags or commit hashes - &lt;strong&gt;Registry flexibility&lt;/strong&gt;: Supports Docker Hub, GitHub Container Registry, etc. - &lt;strong&gt;Build optimization&lt;/strong&gt;: Includes caching and parallel builds&lt;/p&gt; 
&lt;p&gt;You can also use Make targets for convenience:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Heads-up (macOS cross-compilation)&lt;/strong&gt;: macOS keeps the default &lt;code&gt;ulimit -n&lt;/code&gt; at 256, so &lt;code&gt;cargo zigbuild&lt;/code&gt; or &lt;code&gt;./build-rustfs.sh --platform ...&lt;/code&gt; may fail with &lt;code&gt;ProcessFdQuotaExceeded&lt;/code&gt; when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run &lt;code&gt;ulimit -n 4096&lt;/code&gt; (or higher) in your shell before building.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;4. Build with Helm Chart (Option 4) - Cloud Native&lt;/h3&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://charts.rustfs.com/"&gt;Helm Chart README&lt;/a&gt; to install RustFS on a Kubernetes cluster.&lt;/p&gt; 
&lt;h3&gt;5. Nix Flake (Option 5)&lt;/h3&gt; 
&lt;p&gt;If you have &lt;a href="https://nixos.wiki/wiki/Flakes#Enable_flakes"&gt;Nix with flakes enabled&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run directly without installing
nix run github:rustfs/rustfs

# Build the binary
nix build github:rustfs/rustfs
./result/bin/rustfs --help

# Or from a local checkout
nix build
nix run
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Accessing RustFS&lt;/h3&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;&lt;strong&gt;Access the Console&lt;/strong&gt;: Open your web browser and navigate to &lt;code&gt;http://localhost:9001&lt;/code&gt; to access the RustFS console. 
  &lt;ul&gt; 
   &lt;li&gt;Default credentials: &lt;code&gt;rustfsadmin&lt;/code&gt; / &lt;code&gt;rustfsadmin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Bucket&lt;/strong&gt;: Use the console to create a new bucket for your objects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload Objects&lt;/strong&gt;: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: To access the RustFS instance via &lt;code&gt;https&lt;/code&gt;, please refer to the &lt;a href="https://docs.rustfs.com/integration/tls-configured.html"&gt;TLS Configuration Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, including configuration options, API references, and advanced usage, please visit our &lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or need assistance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://github.com/rustfs/rustfs/discussions/categories/q-a"&gt;FAQ&lt;/a&gt; for common issues and solutions.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions and share your experiences.&lt;/li&gt; 
 &lt;li&gt;Open an issue on our &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt; page for bug reports or feature requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/releases"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@rustfs.com"&gt;hello@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:jobs@rustfs.com"&gt;jobs@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;RustFS is a community-driven project, and we appreciate all contributions. Check out the &lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt;Contributors&lt;/a&gt; page to see the amazing people who have helped make RustFS better.&lt;/p&gt; 
&lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt; &lt;img src="https://opencollective.com/rustfs/contributors.svg?width=890&amp;amp;limit=500&amp;amp;button=false" alt="Contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RustFS&lt;/strong&gt; is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>thedotmack/claude-mem</title>
      <link>https://github.com/thedotmack/claude-mem</link>
      <description>&lt;p&gt;A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-dark-mode.webp" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" alt="Claude-Mem" width="400" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.zh.md"&gt;üá®üá≥ ‰∏≠Êñá&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ja.md"&gt;üáØüáµ Êó•Êú¨Ë™û&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pt-br.md"&gt;üáßüá∑ Portugu√™s&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ko.md"&gt;üá∞üá∑ ÌïúÍµ≠Ïñ¥&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.es.md"&gt;üá™üá∏ Espa√±ol&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.de.md"&gt;üá©üá™ Deutsch&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fr.md"&gt;üá´üá∑ Fran√ßais&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.he.md"&gt;üáÆüá± ◊¢◊ë◊®◊ô◊™&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ar.md"&gt;üá∏üá¶ ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ru.md"&gt;üá∑üá∫ –†—É—Å—Å–∫–∏–π&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pl.md"&gt;üáµüá± Polski&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.cs.md"&gt;üá®üáø ƒåe≈°tina&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.nl.md"&gt;üá≥üá± Nederlands&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.tr.md"&gt;üáπüá∑ T√ºrk√ße&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.uk.md"&gt;üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.vi.md"&gt;üáªüá≥ Ti·∫øng Vi·ªát&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.id.md"&gt;üáÆüá© Indonesia&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.th.md"&gt;üáπüá≠ ‡πÑ‡∏ó‡∏¢&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hi.md"&gt;üáÆüá≥ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.bn.md"&gt;üáßüá© ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ro.md"&gt;üá∑üá¥ Rom√¢nƒÉ&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.sv.md"&gt;üá∏üá™ Svenska&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.it.md"&gt;üáÆüáπ Italiano&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.el.md"&gt;üá¨üá∑ ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hu.md"&gt;üá≠üá∫ Magyar&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fi.md"&gt;üá´üáÆ Suomi&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.da.md"&gt;üá©üá∞ Dansk&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.no.md"&gt;üá≥üá¥ Norsk&lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;Persistent memory compression system built for &lt;a href="https://claude.com/claude-code" target="_blank"&gt;Claude Code&lt;/a&gt;.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-AGPL%203.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/version-6.5.0-green.svg?sanitize=true" alt="Version" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true" alt="Node" /&gt; &lt;/a&gt; &lt;a href="https://github.com/thedotmack/awesome-claude-code"&gt; &lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15496" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge-dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg?sanitize=true" alt="thedotmack/claude-mem | Trendshift" width="250" height="55" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/cm-preview.gif" alt="Claude-Mem Preview" width="800" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#quick-start"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#how-it-works"&gt;How It Works&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#mcp-search-tools"&gt;Search Tools&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#documentation"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#configuration"&gt;Configuration&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Claude-Mem seamlessly preserves context across sessions by automatically capturing tool usage observations, generating semantic summaries, and making them available to future sessions. This enables Claude to maintain continuity of knowledge about projects even after sessions end or reconnect. &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Start a new Claude Code session in the terminal and enter the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; /plugin marketplace add thedotmack/claude-mem

&amp;gt; /plugin install claude-mem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Claude Code. Context from previous sessions will automatically appear in new sessions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß† &lt;strong&gt;Persistent Memory&lt;/strong&gt; - Context survives across sessions&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Progressive Disclosure&lt;/strong&gt; - Layered memory retrieval with token cost visibility&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Skill-Based Search&lt;/strong&gt; - Query your project history with mem-search skill&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Web Viewer UI&lt;/strong&gt; - Real-time memory stream at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;Claude Desktop Skill&lt;/strong&gt; - Search memory from Claude Desktop conversations&lt;/li&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Privacy Control&lt;/strong&gt; - Use &lt;code&gt;&amp;lt;private&amp;gt;&lt;/code&gt; tags to exclude sensitive content from storage&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Context Configuration&lt;/strong&gt; - Fine-grained control over what context gets injected&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Automatic Operation&lt;/strong&gt; - No manual intervention required&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Citations&lt;/strong&gt; - Reference past observations with IDs (access via &lt;a href="http://localhost:37777/api/observation/%7Bid%7D"&gt;http://localhost:37777/api/observation/{id}&lt;/a&gt; or view all in the web viewer at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Beta Channel&lt;/strong&gt; - Try experimental features like Endless Mode via version switching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;View Full Documentation&lt;/a&gt;&lt;/strong&gt; - Browse markdown docs on GitHub&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/installation"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt; - Quick start &amp;amp; advanced installation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/getting-started"&gt;Usage Guide&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem works automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools&lt;/a&gt;&lt;/strong&gt; - Query your project history with natural language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features&lt;/a&gt;&lt;/strong&gt; - Try experimental features like Endless Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/context-engineering"&gt;Context Engineering&lt;/a&gt;&lt;/strong&gt; - AI agent context optimization principles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/progressive-disclosure"&gt;Progressive Disclosure&lt;/a&gt;&lt;/strong&gt; - Philosophy behind Claude-Mem's context priming strategy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; - System components &amp;amp; data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture-evolution"&gt;Architecture Evolution&lt;/a&gt;&lt;/strong&gt; - The journey from v3 to v5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/hooks-architecture"&gt;Hooks Architecture&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem uses lifecycle hooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/hooks"&gt;Hooks Reference&lt;/a&gt;&lt;/strong&gt; - 7 hook scripts explained&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/worker-service"&gt;Worker Service&lt;/a&gt;&lt;/strong&gt; - HTTP API &amp;amp; Bun management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/database"&gt;Database&lt;/a&gt;&lt;/strong&gt; - SQLite schema &amp;amp; FTS5 search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/search-architecture"&gt;Search Architecture&lt;/a&gt;&lt;/strong&gt; - Hybrid search with Chroma vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration &amp;amp; Development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration&lt;/a&gt;&lt;/strong&gt; - Environment variables &amp;amp; settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development&lt;/a&gt;&lt;/strong&gt; - Building, testing, contributing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/strong&gt; - Common issues &amp;amp; solutions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Core Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;5 Lifecycle Hooks&lt;/strong&gt; - SessionStart, UserPromptSubmit, PostToolUse, Stop, SessionEnd (6 hook scripts)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Install&lt;/strong&gt; - Cached dependency checker (pre-hook script, not a lifecycle hook)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Worker Service&lt;/strong&gt; - HTTP API on port 37777 with web viewer UI and 10 search endpoints, managed by Bun&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - Stores sessions, observations, summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mem-search Skill&lt;/strong&gt; - Natural language queries with progressive disclosure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chroma Vector Database&lt;/strong&gt; - Hybrid semantic + keyword search for intelligent context retrieval&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Architecture Overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;MCP Search Tools&lt;/h2&gt; 
&lt;p&gt;Claude-Mem provides intelligent memory search through &lt;strong&gt;4 MCP tools&lt;/strong&gt; following a token-efficient &lt;strong&gt;3-layer workflow pattern&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The 3-Layer Workflow:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search&lt;/code&gt;&lt;/strong&gt; - Get compact index with IDs (~50-100 tokens/result)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;timeline&lt;/code&gt;&lt;/strong&gt; - Get chronological context around interesting results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_observations&lt;/code&gt;&lt;/strong&gt; - Fetch full details ONLY for filtered IDs (~500-1,000 tokens/result)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;How It Works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude uses MCP tools to search your memory&lt;/li&gt; 
 &lt;li&gt;Start with &lt;code&gt;search&lt;/code&gt; to get an index of results&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;timeline&lt;/code&gt; to see what was happening around specific observations&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;get_observations&lt;/code&gt; to fetch full details for relevant IDs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;~10x token savings&lt;/strong&gt; by filtering before fetching details&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Available MCP Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search&lt;/code&gt;&lt;/strong&gt; - Search memory index with full-text queries, filters by type/date/project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;timeline&lt;/code&gt;&lt;/strong&gt; - Get chronological context around a specific observation or query&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_observations&lt;/code&gt;&lt;/strong&gt; - Fetch full observation details by IDs (always batch multiple IDs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;__IMPORTANT&lt;/code&gt;&lt;/strong&gt; - Workflow documentation (always visible to Claude)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Step 1: Search for index
search(query="authentication bug", type="bugfix", limit=10)

// Step 2: Review index, identify relevant IDs (e.g., #123, #456)

// Step 3: Fetch full details
get_observations(ids=[123, 456])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools Guide&lt;/a&gt; for detailed examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Beta Features&lt;/h2&gt; 
&lt;p&gt;Claude-Mem offers a &lt;strong&gt;beta channel&lt;/strong&gt; with experimental features like &lt;strong&gt;Endless Mode&lt;/strong&gt; (biomimetic memory architecture for extended sessions). Switch between stable and beta versions from the web viewer UI at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt; ‚Üí Settings.&lt;/p&gt; 
&lt;p&gt;See &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features Documentation&lt;/a&gt;&lt;/strong&gt; for details on Endless Mode and how to try it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18.0.0 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;: Latest version with plugin support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bun&lt;/strong&gt;: JavaScript runtime and process manager (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;uv&lt;/strong&gt;: Python package manager for vector search (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 3&lt;/strong&gt;: For persistent storage (bundled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Settings are managed in &lt;code&gt;~/.claude-mem/settings.json&lt;/code&gt; (auto-created with defaults on first run). Configure AI model, worker port, data directory, log level, and context injection settings.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration Guide&lt;/a&gt;&lt;/strong&gt; for all available settings and examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt;&lt;/strong&gt; for build instructions, testing, and contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If experiencing issues, describe the problem to Claude and the troubleshoot skill will automatically diagnose and provide fixes.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt; for common issues and solutions.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Bug Reports&lt;/h2&gt; 
&lt;p&gt;Create comprehensive bug reports with the automated generator:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ~/.claude/plugins/marketplaces/thedotmack
npm run bug-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes with tests&lt;/li&gt; 
 &lt;li&gt;Update documentation&lt;/li&gt; 
 &lt;li&gt;Submit a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt; for contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0).&lt;/p&gt; 
&lt;p&gt;Copyright (C) 2025 Alex Newman (@thedotmack). All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What This Means:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use, modify, and distribute this software freely&lt;/li&gt; 
 &lt;li&gt;If you modify and deploy on a network server, you must make your source code available&lt;/li&gt; 
 &lt;li&gt;Derivative works must also be licensed under AGPL-3.0&lt;/li&gt; 
 &lt;li&gt;There is NO WARRANTY for this software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note on Ragtime&lt;/strong&gt;: The &lt;code&gt;ragtime/&lt;/code&gt; directory is licensed separately under the &lt;strong&gt;PolyForm Noncommercial License 1.0.0&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/ragtime/LICENSE"&gt;ragtime/LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem"&gt;github.com/thedotmack/claude-mem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Author&lt;/strong&gt;: Alex Newman (&lt;a href="https://github.com/thedotmack"&gt;@thedotmack&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Built with Claude Agent SDK&lt;/strong&gt; | &lt;strong&gt;Powered by Claude Code&lt;/strong&gt; | &lt;strong&gt;Made with TypeScript&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>basecamp/fizzy</title>
      <link>https://github.com/basecamp/fizzy</link>
      <description>&lt;p&gt;Kanban as it should be. Not as it has been.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Fizzy&lt;/h1&gt; 
&lt;p&gt;This is the source code of &lt;a href="https://fizzy.do/"&gt;Fizzy&lt;/a&gt;, the Kanban tracking tool for issues and ideas by &lt;a href="https://37signals.com"&gt;37signals&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running your own Fizzy instance&lt;/h2&gt; 
&lt;p&gt;If you want to run your own Fizzy instance, but don't need to change its code, you can use our pre-built Docker image. You'll need access to a server on which you can run Docker, and you'll need to configure some options to customize your installation.&lt;/p&gt; 
&lt;p&gt;You can find the details of how to do a Docker-based deployment in our &lt;a href="https://raw.githubusercontent.com/basecamp/fizzy/main/docs/docker-deployment.md"&gt;Docker deployment guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you want more flexibility to customize your Fizzy installation by changing its code, and deploy those changes to your server, then we recommend you deploy Fizzy with Kamal. You can find a complete walkthrough of doing that in our &lt;a href="https://raw.githubusercontent.com/basecamp/fizzy/main/docs/kamal-deployment.md"&gt;Kamal deployment guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;You are welcome -- and encouraged -- to modify Fizzy to your liking. Please see our &lt;a href="https://raw.githubusercontent.com/basecamp/fizzy/main/docs/development.md"&gt;Development guide&lt;/a&gt; for how to get Fizzy set up for local development.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please read our &lt;a href="https://raw.githubusercontent.com/basecamp/fizzy/main/STYLE.md"&gt;style guide&lt;/a&gt; before submitting code.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Fizzy is released under the &lt;a href="https://raw.githubusercontent.com/basecamp/fizzy/main/LICENSE.md"&gt;O'Saasy License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BloopAI/vibe-kanban</title>
      <link>https://github.com/BloopAI/vibe-kanban</link>
      <description>&lt;p&gt;Get 10X more out of Claude Code, Codex or any coding agent&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://vibekanban.com"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-logo.svg?sanitize=true" alt="Vibe Kanban Logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/vibe-kanban"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/vibe-kanban?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/BloopAI/vibe-kanban/raw/main/.github/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/BloopAI/vibe-kanban"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;a href="https://jobs.polymer.co/vibe-kanban?source=github"&gt;&lt;strong&gt;We're hiring!&lt;/strong&gt;&lt;/a&gt; &lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-screenshot-overview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;AI coding agents are increasingly writing the world's code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easily switch between different coding agents&lt;/li&gt; 
 &lt;li&gt;Orchestrate the execution of multiple coding agents in parallel or in sequence&lt;/li&gt; 
 &lt;li&gt;Quickly review work and start dev servers&lt;/li&gt; 
 &lt;li&gt;Track the status of tasks that your coding agents are working on&lt;/li&gt; 
 &lt;li&gt;Centralise configuration of coding agent MCP configs&lt;/li&gt; 
 &lt;li&gt;Open projects remotely via SSH when running Vibe Kanban on a remote server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can watch a video overview &lt;a href="https://youtu.be/TFT3KnZOOAk"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the &lt;a href="https://vibekanban.com/docs"&gt;docs&lt;/a&gt;. Then in your terminal run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx vibe-kanban
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Please head to the &lt;a href="https://vibekanban.com/docs"&gt;website&lt;/a&gt; for the latest documentation and user guides.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would prefer that ideas and changes are first raised with the core team via &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; or &lt;a href="https://discord.gg/AC4nwVtJM3"&gt;Discord&lt;/a&gt;, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; (latest stable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (&amp;gt;=18)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt; (&amp;gt;=8)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additional development tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-watch
cargo install sqlx-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm i
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running the dev server&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start the backend. A blank DB will be copied from the &lt;code&gt;dev_assets_seed&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Building the frontend&lt;/h3&gt; 
&lt;p&gt;To build just the frontend:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
pnpm build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from source (macOS)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run &lt;code&gt;./local-build.sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Test with &lt;code&gt;cd npx-cli &amp;amp;&amp;amp; node bin/cli.js&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;The following environment variables can be configured at build time or runtime:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics API key (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics endpoint (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Auto-assign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production&lt;/strong&gt;: Server port. &lt;strong&gt;Dev&lt;/strong&gt;: Frontend port (backend uses PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BACKEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0&lt;/code&gt; (auto-assign)&lt;/td&gt; 
   &lt;td&gt;Backend server port (dev mode only, overrides PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FRONTEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;3000&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Frontend dev server port (dev mode only, overrides PORT)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Backend server host&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DISABLE_WORKTREE_ORPHAN_CLEANUP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Not set&lt;/td&gt; 
   &lt;td&gt;Disable git worktree cleanup (for debugging)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Build-time variables&lt;/strong&gt; must be set when running &lt;code&gt;pnpm run build&lt;/code&gt;. &lt;strong&gt;Runtime variables&lt;/strong&gt; are read when the application starts.&lt;/p&gt; 
&lt;h3&gt;Remote Deployment&lt;/h3&gt; 
&lt;p&gt;When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Access via tunnel&lt;/strong&gt;: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure remote SSH&lt;/strong&gt; in Settings ‚Üí Editor Integration: 
  &lt;ul&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH Host&lt;/strong&gt; to your server hostname or IP&lt;/li&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH User&lt;/strong&gt; to your SSH username (optional)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;SSH access from your local machine to the remote server&lt;/li&gt; 
   &lt;li&gt;SSH keys configured (passwordless authentication)&lt;/li&gt; 
   &lt;li&gt;VSCode Remote-SSH extension&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When configured, the "Open in VSCode" buttons will generate URLs like &lt;code&gt;vscode://vscode-remote/ssh-remote+user@host/path&lt;/code&gt; that open your local editor and connect to the remote server.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration"&gt;documentation&lt;/a&gt; for detailed setup instructions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>agentsmd/agents.md</title>
      <link>https://github.com/agentsmd/agents.md</link>
      <description>&lt;p&gt;AGENTS.md ‚Äî a simple, open format for guiding coding agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AGENTS.md&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/agentsmd/agents.md/main/public/og.png" alt="AGENTS.md logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://agents.md"&gt;AGENTS.md&lt;/a&gt; is a simple, open format for guiding coding agents.&lt;/p&gt; 
&lt;p&gt;Think of AGENTS.md as a README for agents: a dedicated, predictable place to provide context and instructions to help AI coding agents work on your project.&lt;/p&gt; 
&lt;p&gt;Below is a minimal example of an AGENTS.md file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;# Sample AGENTS.md file

## Dev environment tips
- Use `pnpm dlx turbo run where &amp;lt;project_name&amp;gt;` to jump to a package instead of scanning with `ls`.
- Run `pnpm install --filter &amp;lt;project_name&amp;gt;` to add the package to your workspace so Vite, ESLint, and TypeScript can see it.
- Use `pnpm create vite@latest &amp;lt;project_name&amp;gt; -- --template react-ts` to spin up a new React + Vite package with TypeScript checks ready.
- Check the name field inside each package's package.json to confirm the right name‚Äîskip the top-level one.

## Testing instructions
- Find the CI plan in the .github/workflows folder.
- Run `pnpm turbo run test --filter &amp;lt;project_name&amp;gt;` to run every check defined for that package.
- From the package root you can just call `pnpm test`. The commit should pass all tests before you merge.
- To focus on one step, add the Vitest pattern: `pnpm vitest run -t "&amp;lt;test name&amp;gt;"`.
- Fix any test or type errors until the whole suite is green.
- After moving files or changing imports, run `pnpm lint --filter &amp;lt;project_name&amp;gt;` to be sure ESLint and TypeScript rules still pass.
- Add or update tests for the code you change, even if nobody asked.

## PR instructions
- Title format: [&amp;lt;project_name&amp;gt;] &amp;lt;Title&amp;gt;
- Always run `pnpm lint` and `pnpm test` before committing.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;This repository also includes a basic Next.js website hosted at &lt;a href="https://agents.md/"&gt;https://agents.md/&lt;/a&gt; that explains the project‚Äôs goals in a simple way, and featuring some examples.&lt;/p&gt; 
&lt;h3&gt;Running the app locally&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install dependencies: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Start the development server: &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Open your browser and go to &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/Chatterbox-Turbo.jpg" alt="Chatterbox Turbo Image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with ‚ô•Ô∏è by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chatterbox&lt;/strong&gt; is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.&lt;/p&gt; 
&lt;p&gt;We are excited to introduce &lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;, our most efficient model yet. Built on a streamlined 350M parameter architecture, &lt;strong&gt;Turbo&lt;/strong&gt; delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just &lt;strong&gt;one&lt;/strong&gt;, while retaining high-fidelity audio output.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paralinguistic tags&lt;/strong&gt; are now native to the Turbo model, allowing you to use &lt;code&gt;[cough]&lt;/code&gt;, &lt;code&gt;[laugh]&lt;/code&gt;, &lt;code&gt;[chuckle]&lt;/code&gt;, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;img width="1200" height="600" alt="Podonos Turbo Eval" src="https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png" /&gt; 
&lt;h3&gt;‚ö° Model Zoo&lt;/h3&gt; 
&lt;p&gt;Choose the right model for your application.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="left"&gt;Size&lt;/th&gt; 
   &lt;th align="left"&gt;Languages&lt;/th&gt; 
   &lt;th align="left"&gt;Key Features&lt;/th&gt; 
   &lt;th align="left"&gt;Best For&lt;/th&gt; 
   &lt;th align="left"&gt;ü§ó&lt;/th&gt; 
   &lt;th align="left"&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;350M&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Paralinguistic Tags (&lt;code&gt;[laugh]&lt;/code&gt;), Lower Compute and VRAM&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot voice agents, Production&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox-Multilingual &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#supported-languages"&gt;(Language list)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;23+&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot cloning, Multiple Languages&lt;/td&gt; 
   &lt;td align="left"&gt;Global applications, Localization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#original-chatterbox-tips"&gt;(Tips and Tricks)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;English&lt;/td&gt; 
   &lt;td align="left"&gt;CFG &amp;amp; Exaggeration tuning&lt;/td&gt; 
   &lt;td align="left"&gt;General zero-shot TTS with creative controls&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h5&gt;Chatterbox-Turbo&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with Paralinguistic Tags
text = "Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?"

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path="your_10s_ref_clip.wav")

ta.save("test-turbo.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chatterbox and Chatterbox-Multilingual&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-english.wav", wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = "Bonjour, comment √ßa va? Ceci est le mod√®le de synth√®se vocale multilingue Chatterbox, il prend en charge 23 langues."
wav_french = multilingual_model.generate(spanish_text, language_id="fr")
ta.save("test-french.wav", wav_french, model.sr)

chinese_text = "‰Ω†Â•ΩÔºå‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÂ∏åÊúõ‰Ω†Êúâ‰∏Ä‰∏™ÊÑâÂø´ÁöÑÂë®Êú´„ÄÇ"
wav_chinese = multilingual_model.generate(chinese_text, language_id="zh")
ta.save("test-chinese.wav", wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Arabic (ar) ‚Ä¢ Danish (da) ‚Ä¢ German (de) ‚Ä¢ Greek (el) ‚Ä¢ English (en) ‚Ä¢ Spanish (es) ‚Ä¢ Finnish (fi) ‚Ä¢ French (fr) ‚Ä¢ Hebrew (he) ‚Ä¢ Hindi (hi) ‚Ä¢ Italian (it) ‚Ä¢ Japanese (ja) ‚Ä¢ Korean (ko) ‚Ä¢ Malay (ms) ‚Ä¢ Dutch (nl) ‚Ä¢ Norwegian (no) ‚Ä¢ Polish (pl) ‚Ä¢ Portuguese (pt) ‚Ä¢ Russian (ru) ‚Ä¢ Swedish (sv) ‚Ä¢ Swahili (sw) ‚Ä¢ Turkish (tr) ‚Ä¢ Chinese (zh)&lt;/p&gt; 
&lt;h2&gt;Original Chatterbox Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip‚Äôs language. To mitigate this, set &lt;code&gt;cfg_weight&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts across all languages.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h2&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Official Discord&lt;/h2&gt; 
&lt;p&gt;üëã Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/imgs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/72NsF6ux" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/exolabs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/exolabs?style=social" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;exo connects all your devices into an AI cluster. Not only does exo enable running models larger than would fit on a single device, but with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt&lt;/a&gt;, makes models run faster as you add more devices.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Device Discovery&lt;/strong&gt;: Devices running exo automatically discover each other - no manual configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RDMA over Thunderbolt&lt;/strong&gt;: exo ships with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt 5&lt;/a&gt;, enabling 99% reduction in latency between devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Topology-Aware Auto Parallel&lt;/strong&gt;: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: exo supports sharding models, for up to 1.8x speedup on 2 devices and 3.2x speedup on 4 devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MLX Support&lt;/strong&gt;: exo uses &lt;a href="https://github.com/ml-explore/mlx"&gt;MLX&lt;/a&gt; as an inference backend and &lt;a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html"&gt;MLX distributed&lt;/a&gt; for distributed communication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" alt="Benchmark - Qwen3-235B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" alt="Benchmark - DeepSeek v3.1 671B (8-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" alt="Benchmark - Kimi K2 Thinking (native 4-bit) on 4 √ó M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio ‚Äì RDMA over Thunderbolt‚ÄØ5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Devices running exo automatically discover each other, without needing any manual configuration. Each device provides an API and a dashboard for interacting with your cluster (runs at &lt;code&gt;http://localhost:52415&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;There are two ways to run exo:&lt;/p&gt; 
&lt;h3&gt;Run from Source (macOS)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Homebrew/brew"&gt;brew&lt;/a&gt; (for simple package management on macOS)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vladkens/macmon"&gt;macmon&lt;/a&gt; (for hardware monitoring on Apple Silicon)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install uv macmon node
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run from Source (Linux)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard) - version 18 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Installation methods:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Using system package manager (Ubuntu/Debian example):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Node.js and npm
sudo apt update
sudo apt install nodejs npm

# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Using Homebrew on Linux (if preferred):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Homebrew on Linux
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install dependencies
brew install uv node

# Install Rust (using rustup)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;macmon&lt;/code&gt; package is macOS-only and not required for Linux.&lt;/p&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important note for Linux users:&lt;/strong&gt; Currently, exo runs on CPU on Linux. GPU support for Linux platforms is under development. If you'd like to see support for your specific Linux hardware, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for existing feature requests&lt;/a&gt; or create a new one.&lt;/p&gt; 
&lt;h3&gt;macOS App&lt;/h3&gt; 
&lt;p&gt;exo ships a macOS app that runs in the background on your Mac.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/macos-app-one-macbook.png" alt="exo macOS App - running on a MacBook" width="35%" /&gt; 
&lt;p&gt;The macOS app requires macOS Tahoe 26.2 or later.&lt;/p&gt; 
&lt;p&gt;Download the latest build here: &lt;a href="https://assets.exolabs.net/EXO-latest.dmg"&gt;EXO-latest.dmg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The app will ask for permission to modify system settings and install a new Network profile. Improvements to this are being worked on.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Enabling RDMA on macOS&lt;/h3&gt; 
&lt;p&gt;RDMA is a new capability added to macOS 26.2. It works on any Mac with Thunderbolt 5 (M4 Pro Mac Mini, M4 Max Mac Studio, M4 Max MacBook Pro, M3 Ultra Mac Studio).&lt;/p&gt; 
&lt;p&gt;Note that on Mac Studio, you cannot use the Thunderbolt 5 port next to the Ethernet port.&lt;/p&gt; 
&lt;p&gt;To enable RDMA on macOS, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Shut down your Mac.&lt;/li&gt; 
 &lt;li&gt;Hold down the power button for 10 seconds until the boot menu appears.&lt;/li&gt; 
 &lt;li&gt;Select "Options" to enter Recovery mode.&lt;/li&gt; 
 &lt;li&gt;When the Recovery UI appears, open the Terminal from the Utilities menu.&lt;/li&gt; 
 &lt;li&gt;In the Terminal, type: &lt;pre&gt;&lt;code&gt;rdma_ctl enable
&lt;/code&gt;&lt;/pre&gt; and press Enter.&lt;/li&gt; 
 &lt;li&gt;Reboot your Mac.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After that, RDMA will be enabled in macOS and exo will take care of the rest.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using the API&lt;/h3&gt; 
&lt;p&gt;If you prefer to interact with exo via the API, here is an example creating an instance of a small model (&lt;code&gt;mlx-community/Llama-3.2-1B-Instruct-4bit&lt;/code&gt;), sending a chat completions request and deleting the instance.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;1. Preview instance placements&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;/instance/previews&lt;/code&gt; endpoint will preview all valid placements for your model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "previews": [
    {
      "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "sharding": "Pipeline",
      "instance_meta": "MlxRing",
      "instance": {...},
      "memory_delta_by_node": {"local": 729808896},
      "error": null
    }
    // ...possibly more placements...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will return all valid placements for this model. Pick a placement that you like. To pick the first one, pipe into &lt;code&gt;jq&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b" | jq -c '.previews[] | select(.error == null) | .instance' | head -n1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;2. Create a model instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Send a POST to &lt;code&gt;/instance&lt;/code&gt; with your desired placement in the &lt;code&gt;instance&lt;/code&gt; field (the full payload must match types as in &lt;code&gt;CreateInstanceParams&lt;/code&gt;), which you can copy from step 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:52415/instance \
  -H 'Content-Type: application/json' \
  -d '{
    "instance": {...}
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "message": "Command received.",
  "command_id": "e9d1a8ab-...."
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;3. Send a chat completion&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, make a POST to &lt;code&gt;/v1/chat/completions&lt;/code&gt; (the same format as OpenAI's API):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -N -X POST http://localhost:52415/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{
    "model": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "messages": [
      {"role": "user", "content": "What is Llama 3.2 1B?"}
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;4. Delete the instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;When you're done, delete the instance by its ID (find it via &lt;code&gt;/state&lt;/code&gt; or &lt;code&gt;/instance&lt;/code&gt; endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X DELETE http://localhost:52415/instance/YOUR_INSTANCE_ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;&lt;em&gt;Other useful API endpoints&lt;/em&gt;:&lt;/em&gt;*&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;List all models: &lt;code&gt;curl http://localhost:52415/models&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Inspect instance IDs and deployment state: &lt;code&gt;curl http://localhost:52415/state&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For further details, see API types and endpoints in &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/src/exo/master/api.py"&gt;src/exo/master/api.py&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Hardware Accelerator Support&lt;/h2&gt; 
&lt;p&gt;On macOS, exo uses the GPU. On Linux, exo currently runs on CPU. We are working on extending hardware accelerator support. If you'd like support for a new hardware platform, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for an existing feature request&lt;/a&gt; and add a thumbs up so we know what hardware is important to the community.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute to exo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-quickstarts</title>
      <link>https://github.com/anthropics/claude-quickstarts</link>
      <description>&lt;p&gt;A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Quickstarts&lt;/h1&gt; 
&lt;p&gt;Claude Quickstarts is a collection of projects designed to help developers quickly get started with building applications using the Claude API. Each quickstart provides a foundation that you can easily build upon and customize for your specific needs.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To use these quickstarts, you'll need an Claude API key. If you don't have one yet, you can sign up for free at &lt;a href="https://console.anthropic.com"&gt;console.anthropic.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Available Quickstarts&lt;/h2&gt; 
&lt;h3&gt;Customer Support Agent&lt;/h3&gt; 
&lt;p&gt;A customer support agent powered by Claude. This project demonstrates how to leverage Claude's natural language understanding and generation capabilities to create an AI-assisted customer support system with access to a knowledge base.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/customer-support-agent"&gt;Go to Customer Support Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Financial Data Analyst&lt;/h3&gt; 
&lt;p&gt;A financial data analyst powered by Claude. This project demonstrates how to leverage Claude's capabilities with interactive data visualization to analyze financial data via chat.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/financial-data-analyst"&gt;Go to Financial Data Analyst Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Computer Use Demo&lt;/h3&gt; 
&lt;p&gt;An environment and tools that Claude can use to control a desktop computer. This project demonstrates how to leverage the computer use capabilities of Claude, including support for the latest &lt;code&gt;computer_use_20251124&lt;/code&gt; tool version with zoom actions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/computer-use-demo"&gt;Go to Computer Use Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Browser Tools API Demo&lt;/h3&gt; 
&lt;p&gt;A complete reference implementation for browser automation powered by Claude. This project demonstrates how to leverage Claude's browser tools API for web interaction, including navigation, DOM inspection, and form manipulation using Playwright.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/browser-tools-api-demo"&gt;Go to Browser Tools API Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Autonomous Coding Agent&lt;/h3&gt; 
&lt;p&gt;An autonomous coding agent powered by the Claude Agent SDK. This project demonstrates a two-agent pattern (initializer + coding agent) that can build complete applications over multiple sessions, with progress persisted via git and a feature list that the agent works through incrementally.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/autonomous-coding"&gt;Go to Autonomous Coding Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;General Usage&lt;/h2&gt; 
&lt;p&gt;Each quickstart project comes with its own README and setup instructions. Generally, you'll follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository&lt;/li&gt; 
 &lt;li&gt;Navigate to the specific quickstart directory&lt;/li&gt; 
 &lt;li&gt;Install the required dependencies&lt;/li&gt; 
 &lt;li&gt;Set up your Claude API key as an environment variable&lt;/li&gt; 
 &lt;li&gt;Run the quickstart application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;p&gt;To deepen your understanding of working with Claude and the Claude API, check out these resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com"&gt;Claude API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-cookbooks"&gt;Claude Cookbooks&lt;/a&gt; - A collection of code snippets and guides for common tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals"&gt;Claude API Fundamentals Course&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Claude Quickstarts repository! If you have ideas for new quickstart projects or improvements to existing ones, please open an issue or submit a pull request.&lt;/p&gt; 
&lt;h2&gt;Community and Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://www.anthropic.com/discord"&gt;Anthropic Discord community&lt;/a&gt; for discussions and support&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://support.anthropic.com"&gt;Anthropic support documentation&lt;/a&gt; for additional help&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/skills</title>
      <link>https://github.com/anthropics/skills</link>
      <description>&lt;p&gt;Public repository for Agent Skills&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This repository contains Anthropic's implementation of skills for Claude. For information about the Agent Skills standard, see &lt;a href="http://agentskills.io"&gt;agentskills.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Skills&lt;/h1&gt; 
&lt;p&gt;Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.&lt;/p&gt; 
&lt;p&gt;For more information, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512176-what-are-skills"&gt;What are skills?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude"&gt;Using skills in Claude&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills"&gt;Equipping agents for the real world with Agent Skills&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;About This Repository&lt;/h1&gt; 
&lt;p&gt;This repository contains skills that demonstrate what's possible with Claude's skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).&lt;/p&gt; 
&lt;p&gt;Each skill is self-contained in its own folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.&lt;/p&gt; 
&lt;p&gt;Many skills in this repo are open source (Apache 2.0). We've also included the document creation &amp;amp; editing skills that power &lt;a href="https://www.anthropic.com/news/create-files"&gt;Claude's document capabilities&lt;/a&gt; under the hood in the &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/docx"&gt;&lt;code&gt;skills/docx&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pdf"&gt;&lt;code&gt;skills/pdf&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pptx"&gt;&lt;code&gt;skills/pptx&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/xlsx"&gt;&lt;code&gt;skills/xlsx&lt;/code&gt;&lt;/a&gt; subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;These skills are provided for demonstration and educational purposes only.&lt;/strong&gt; While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.&lt;/p&gt; 
&lt;h1&gt;Skill Sets&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills"&gt;./skills&lt;/a&gt;: Skill examples for Creative &amp;amp; Design, Development &amp;amp; Technical, Enterprise &amp;amp; Communication, and Document Skills&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/spec"&gt;./spec&lt;/a&gt;: The Agent Skills specification&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/template"&gt;./template&lt;/a&gt;: Skill template&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Try in Claude Code, Claude.ai, and the API&lt;/h1&gt; 
&lt;h2&gt;Claude Code&lt;/h2&gt; 
&lt;p&gt;You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add anthropics/skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to install a specific set of skills:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Select &lt;code&gt;Browse and install plugins&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;anthropic-agent-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;document-skills&lt;/code&gt; or &lt;code&gt;example-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;Install now&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Alternatively, directly install either Plugin via:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the &lt;code&gt;document-skills&lt;/code&gt; plugin from the marketplace, you can ask Claude Code to do something like: "Use the PDF skill to extract the form fields from &lt;code&gt;path/to/some-file.pdf&lt;/code&gt;"&lt;/p&gt; 
&lt;h2&gt;Claude.ai&lt;/h2&gt; 
&lt;p&gt;These example skills are all already available to paid plans in Claude.ai.&lt;/p&gt; 
&lt;p&gt;To use any skill from this repository or upload custom skills, follow the instructions in &lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b"&gt;Using skills in Claude&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Claude API&lt;/h2&gt; 
&lt;p&gt;You can use Anthropic's pre-built skills, and upload custom skills, via the Claude API. See the &lt;a href="https://docs.claude.com/en/api/skills-guide#creating-a-skill"&gt;Skills API Quickstart&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h1&gt;Creating a Basic Skill&lt;/h1&gt; 
&lt;p&gt;Skills are simple to create - just a folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing YAML frontmatter and instructions. You can use the &lt;strong&gt;template-skill&lt;/strong&gt; in this repository as a starting point:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The frontmatter requires only two fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; - A unique identifier for your skill (lowercase, hyphens for spaces)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; - A complete description of what the skill does and when to use it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see &lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Partner Skills&lt;/h1&gt; 
&lt;p&gt;Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Notion&lt;/strong&gt; - &lt;a href="https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0"&gt;Notion Skills for Claude&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>DayuanJiang/next-ai-draw-io</title>
      <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
      <description>&lt;p&gt;A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Next AI Draw.io&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;AI-Powered Diagram Creation Tool - Chat, Draw, Visualize&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/cn/README_CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/ja/README_JA.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15449" alt="TrendShift" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://nextjs.org/"&gt;&lt;img src="https://img.shields.io/badge/Next.js-16.x-black" alt="Next.js" /&gt;&lt;/a&gt; &lt;a href="https://react.dev/"&gt;&lt;img src="https://img.shields.io/badge/React-19.x-61dafb" alt="React" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-%E2%9D%A4-ea4aaa" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Thanks to &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/doubao-color.png" alt="" height="20" /&gt; &lt;a href="https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;amp;briefType=introduce&amp;amp;type=new&amp;amp;utm_campaign=doubao&amp;amp;utm_content=aidrawio&amp;amp;utm_medium=github&amp;amp;utm_source=coopensrc&amp;amp;utm_term=project"&gt;ByteDance Doubao&lt;/a&gt; sponsorship, the demo site now uses the powerful K2-thinking model!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1"&gt;https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#next-ai-drawio"&gt;Next AI Draw.io&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#mcp-server-preview"&gt;MCP Server (Preview)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#claude-code-cli"&gt;Claude Code CLI&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#try-it-online"&gt;Try it Online&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#desktop-application"&gt;Desktop Application&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#run-with-docker"&gt;Run with Docker&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deployment"&gt;Deployment&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deploy-to-edgeone-pages"&gt;Deploy to EdgeOne Pages&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deploy-on-vercel-recommended"&gt;Deploy on Vercel (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deploy-on-cloudflare-workers"&gt;Deploy on Cloudflare Workers&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#multi-provider-support"&gt;Multi-Provider Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#support--contact"&gt;Support &amp;amp; Contact&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Here are some example prompts and their generated diagrams:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table width="100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="2" valign="top" align="center"&gt; &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer's architecture.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/animated_connectors.svg?sanitize=true" alt="Transformer Architecture with Animated Connectors" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/gcp_demo.svg?sanitize=true" alt="GCP Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/aws_demo.svg?sanitize=true" alt="AWS Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/azure_demo.svg?sanitize=true" alt="Azure Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/cat_demo.svg?sanitize=true" alt="Cat Drawing" width="240" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-Powered Diagram Creation&lt;/strong&gt;: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image-Based Diagram Replication&lt;/strong&gt;: Upload existing diagrams or images and have the AI replicate and enhance them automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDF &amp;amp; Text File Upload&lt;/strong&gt;: Upload PDF documents and text files to extract content and generate diagrams from existing documents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Reasoning Display&lt;/strong&gt;: View the AI's thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Diagram History&lt;/strong&gt;: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Chat Interface&lt;/strong&gt;: Communicate with AI to refine your diagrams in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Architecture Diagram Support&lt;/strong&gt;: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Animated Connectors&lt;/strong&gt;: Create dynamic and animated connectors between diagram elements for better visualization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MCP Server (Preview)&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Preview Feature&lt;/strong&gt;: This feature is experimental and may not be stable.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "drawio": {
      "command": "npx",
      "args": ["@next-ai-drawio/mcp-server@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude Code CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then ask Claude to create diagrams:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Create a flowchart showing user authentication with login, MFA, and session management"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The diagram appears in your browser in real-time!&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/packages/mcp-server/README.md"&gt;MCP Server README&lt;/a&gt; for VS Code, Cursor, and other client configurations.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Try it Online&lt;/h3&gt; 
&lt;p&gt;No installation needed! Try the app directly on our demo site:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Bring Your Own API Key&lt;/strong&gt;: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop Application&lt;/h3&gt; 
&lt;p&gt;Download the native desktop app for your platform from the &lt;a href="https://github.com/DayuanJiang/next-ai-draw-io/releases"&gt;Releases page&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;Supported platforms: Windows, macOS, Linux.&lt;/p&gt; 
&lt;h3&gt;Run with Docker&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/en/docker.md"&gt;Go to Docker Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
npm install
cp env.example .env.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/en/ai-providers.md"&gt;Provider Configuration Guide&lt;/a&gt; for detailed setup instructions for each provider.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run the development server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:6002"&gt;http://localhost:6002&lt;/a&gt; in your browser to see the application.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;h3&gt;Deploy to EdgeOne Pages&lt;/h3&gt; 
&lt;p&gt;You can deploy with one click using &lt;a href="https://pages.edgeone.ai/"&gt;Tencent EdgeOne Pages&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Deploy by this button:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://edgeone.ai/pages/new?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io"&gt;&lt;img src="https://cdnstatic.tencentcs.com/edgeone/pages/deploy.svg?sanitize=true" alt="Deploy to EdgeOne Pages" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://pages.edgeone.ai/document/deployment-overview"&gt;Tencent EdgeOne Pages documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Additionally, deploying through Tencent EdgeOne Pages will also grant you a &lt;a href="https://pages.edgeone.ai/document/edge-ai"&gt;daily free quota for DeepSeek models&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Deploy on Vercel (Recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io"&gt;&lt;img src="https://vercel.com/button" alt="Deploy with Vercel" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The easiest way to deploy is using &lt;a href="https://vercel.com/new"&gt;Vercel&lt;/a&gt;, the creators of Next.js. Be sure to &lt;strong&gt;set the environment variables&lt;/strong&gt; in the Vercel dashboard as you did in your local &lt;code&gt;.env.local&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://nextjs.org/docs/app/building-your-application/deploying"&gt;Next.js deployment documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Deploy on Cloudflare Workers&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/en/cloudflare-deploy.md"&gt;Go to Cloudflare Deploy Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Multi-Provider Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;amp;briefType=introduce&amp;amp;type=new&amp;amp;utm_campaign=doubao&amp;amp;utm_content=aidrawio&amp;amp;utm_medium=github&amp;amp;utm_source=coopensrc&amp;amp;utm_term=project"&gt;ByteDance Doubao&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AWS Bedrock (default)&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Anthropic&lt;/li&gt; 
 &lt;li&gt;Google AI&lt;/li&gt; 
 &lt;li&gt;Azure OpenAI&lt;/li&gt; 
 &lt;li&gt;Ollama&lt;/li&gt; 
 &lt;li&gt;OpenRouter&lt;/li&gt; 
 &lt;li&gt;DeepSeek&lt;/li&gt; 
 &lt;li&gt;SiliconFlow&lt;/li&gt; 
 &lt;li&gt;SGLang&lt;/li&gt; 
 &lt;li&gt;Vercel AI Gateway&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All providers except AWS Bedrock and OpenRouter support custom endpoints.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/en/ai-providers.md"&gt;Detailed Provider Configuration Guide&lt;/a&gt;&lt;/strong&gt; - See setup instructions for each provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Model Requirements&lt;/strong&gt;: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;code&gt;claude&lt;/code&gt; series has been trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;The application uses the following technologies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Next.js&lt;/strong&gt;: For the frontend framework and routing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vercel AI SDK&lt;/strong&gt; (&lt;code&gt;ai&lt;/code&gt; + &lt;code&gt;@ai-sdk/*&lt;/code&gt;): For streaming AI responses and multi-provider support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;react-drawio&lt;/strong&gt;: For diagram representation and manipulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.&lt;/p&gt; 
&lt;h2&gt;Support &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Special thanks to &lt;a href="https://console.volcengine.com/ark/region:ark+cn-beijing/overview?briefPage=0&amp;amp;briefType=introduce&amp;amp;type=new&amp;amp;utm_campaign=doubao&amp;amp;utm_content=aidrawio&amp;amp;utm_medium=github&amp;amp;utm_source=coopensrc&amp;amp;utm_term=project"&gt;ByteDance Doubao&lt;/a&gt; for sponsoring the API token usage of the demo site!&lt;/strong&gt; Register on the ARK platform to get 500K free tokens for all models!&lt;/p&gt; 
&lt;p&gt;If you find this project useful, please consider &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;sponsoring&lt;/a&gt; to help me host the live demo site!&lt;/p&gt; 
&lt;p&gt;For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: me[at]jiang.jp&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Open-source platform to build and deploy AI agent workflows.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Build Workflows with Ease&lt;/h3&gt; 
&lt;p&gt;Design agent workflows visually on a canvas‚Äîconnect agents, tools, and blocks, then run them instantly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/workflow.gif" alt="Workflow Builder Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Supercharge with Copilot&lt;/h3&gt; 
&lt;p&gt;Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/copilot.gif" alt="Copilot Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Integrate Vector Databases&lt;/h3&gt; 
&lt;p&gt;Upload documents to a vector store and let agents answer questions grounded in your specific content.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/knowledge.gif" alt="Knowledge Uploads and Retrieval Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using an External Ollama Instance&lt;/h4&gt; 
&lt;p&gt;If you already have Ollama running on your host machine (outside Docker), you need to configure the &lt;code&gt;OLLAMA_URL&lt;/code&gt; to use &lt;code&gt;host.docker.internal&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker Desktop (macOS/Windows)
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d

# Linux (add extra_hosts or use host IP)
docker compose -f docker-compose.prod.yml up -d  # Then set OLLAMA_URL to your host's IP
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; When running inside Docker, &lt;code&gt;localhost&lt;/code&gt; refers to the container itself, not your host machine. &lt;code&gt;host.docker.internal&lt;/code&gt; is a special DNS name that resolves to the host.&lt;/p&gt; 
&lt;p&gt;For Linux users, you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use your host machine's actual IP address (e.g., &lt;code&gt;http://192.168.1.100:11434&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;extra_hosts: ["host.docker.internal:host-gateway"]&lt;/code&gt; to the simstudio service in your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using vLLM&lt;/h4&gt; 
&lt;p&gt;Sim also supports &lt;a href="https://docs.vllm.ai/"&gt;vLLM&lt;/a&gt; for self-hosted models with OpenAI-compatible API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set these environment variables
VLLM_BASE_URL=http://your-vllm-server:8000
VLLM_API_KEY=your_optional_api_key  # Only if your vLLM instance requires auth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker, use &lt;code&gt;host.docker.internal&lt;/code&gt; if vLLM is on your host machine (same as Ollama above).&lt;/p&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20+ (required for sandboxed code execution)&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;First, configure the database package environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db
cp .env.example .env 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;packages/db/.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the migrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db # Required so drizzle picks correct .env file
bunx drizzle-kit migrate --config=./drizzle.config.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; ‚Üí Settings ‚Üí Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; environment variable in your self-hosted apps/sim/.env file to that value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;Key environment variables for self-hosted deployments (see &lt;code&gt;apps/sim/.env.example&lt;/code&gt; for full list):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;PostgreSQL connection string with pgvector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_SECRET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Auth secret (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Your app URL (e.g., &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;NEXT_PUBLIC_APP_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Public app URL (same as above)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Encryption key (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Ollama server URL (default: &lt;code&gt;http://localhost:11434&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VLLM_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;vLLM server URL for self-hosted models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;COPILOT_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;API key from sim.ai for Copilot features&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Ollama models not showing in dropdown (Docker)&lt;/h3&gt; 
&lt;p&gt;If you're running Ollama on your host machine and Sim in Docker, change &lt;code&gt;OLLAMA_URL&lt;/code&gt; from &lt;code&gt;localhost&lt;/code&gt; to &lt;code&gt;host.docker.internal&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/#using-an-external-ollama-instance"&gt;Using an External Ollama Instance&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Database connection issues&lt;/h3&gt; 
&lt;p&gt;Ensure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.&lt;/p&gt; 
&lt;h3&gt;Port conflicts&lt;/h3&gt; 
&lt;p&gt;If ports 3000, 3002, or 5432 are in use, configure alternatives:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Custom ports
NEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote Code Execution&lt;/strong&gt;: &lt;a href="https://www.e2b.dev/"&gt;E2B&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cocoindex-io/cocoindex</title>
      <link>https://github.com/cocoindex-io/cocoindex</link>
      <description>&lt;p&gt;Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/github.svg?sanitize=true" alt="CocoIndex" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Data transformation for AI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;&lt;img src="https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/cocoindex/"&gt;&lt;img src="https://img.shields.io/pypi/v/cocoindex?color=5B5BD6" alt="PyPI version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projects/cocoindex"&gt;&lt;img src="https://static.pepy.tech/badge/cocoindex/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml/badge.svg?sanitize=true" alt="Link Check" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;&lt;img src="https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13939" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13939" alt="cocoindex-io%2Fcocoindex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box. Exceptional developer velocity. Production-ready at day 0.&lt;/p&gt; 
&lt;p&gt;‚≠ê Drop a star to help us grow!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=en"&gt;English&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/transformation.svg?sanitize=true" alt="CocoIndex Transformation" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="CocoIndex Features" src="https://cocoindex.io/images/venn2.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Exceptional velocity&lt;/h2&gt; 
&lt;p&gt;Just declare transformation in dataflow with ~100 lines of python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# import
data['content'] = flow_builder.add_source(...)

# transform
data['out'] = data['content']
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CocoIndex follows the idea of &lt;a href="https://en.wikipedia.org/wiki/Dataflow_programming"&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.&lt;/p&gt; 
&lt;h2&gt;Plug-and-Play Building Blocks&lt;/h2&gt; 
&lt;p&gt;Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/components.svg?sanitize=true" alt="CocoIndex Features" /&gt; &lt;/p&gt; 
&lt;h2&gt;Data Freshness&lt;/h2&gt; 
&lt;p&gt;CocoIndex keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6" alt="Incremental Processing" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;It has out-of-box support for incremental indexing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;minimal recomputation on source or logic change.&lt;/li&gt; 
 &lt;li&gt;(re-)processing necessary portions; reuse cache when possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;If you're new to CocoIndex, we recommend checking out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://cocoindex.io/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé¨ &lt;a href="https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT"&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install -U cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://cocoindex.io/docs/getting_started/installation#-install-postgres"&gt;Install Postgres&lt;/a&gt; if you don't have one. CocoIndex uses it for incremental processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Install Claude Code skill for enhanced development experience. Run these commands in &lt;a href="https://claude.com/claude-code"&gt;Claude Code&lt;/a&gt;:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Define data flow&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@cocoindex.flow_def(name="TextEmbedding")
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope["documents"] = flow_builder.add_source(cocoindex.sources.LocalFile(path="markdown_files"))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope["documents"].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc["chunks"] = doc["content"].transform(
            cocoindex.functions.SplitRecursively(),
            language="markdown", chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc["chunks"].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk["embedding"] = chunk["text"].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model="sentence-transformers/all-MiniLM-L6-v2"))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc["filename"], location=chunk["location"],
                                   text=chunk["text"], embedding=chunk["embedding"])

    # Export collected data to a vector index.
    doc_embeddings.export(
        "doc_embeddings",
        cocoindex.targets.Postgres(),
        primary_key_fields=["filename", "location"],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name="embedding",
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It defines an index flow like this:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="400" alt="Data Flow" src="https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463" /&gt; &lt;/p&gt; 
&lt;h2&gt;üöÄ Examples and demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding"&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding"&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding"&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_elements_embedding"&gt;PDF Elements Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction"&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding"&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/azure_blob_embedding"&gt;Azure Blob Storage Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Azure Blob Storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding"&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/meeting_notes_graph"&gt;Meeting Notes to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured meeting info from Google Drive and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph"&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant"&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_lancedb"&gt;Embeddings to LanceDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a LanceDB collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker"&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation"&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search"&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/face_recognition"&gt;Face Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Recognize faces in images and build embedding index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/paper_metadata"&gt;Paper Metadata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index papers in PDF files, and build metadata tables for each paper&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/multi_format_indexing"&gt;Multi Format Indexing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build visual document index from PDFs and images with ColPali for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_source_hn"&gt;Custom Source HackerNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_output_files"&gt;Custom Output Files&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Convert markdown files to HTML files and save them to a local directory, using &lt;em&gt;CocoIndex Custom Targets&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction"&gt;Patient intake form extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Use LLM to extract structured data from patient intake forms with different formats&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/hn_trending_topics"&gt;HackerNews Trending Topics&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract trending topics from HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt; and LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction_baml"&gt;Patient Intake Form Extraction with BAML&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured data from patient intake forms using BAML&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction_dspy"&gt;Patient Intake Form Extraction with DSPy&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured data from patient intake forms using DSPy&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More coming and stay tuned üëÄ!&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit &lt;a href="https://cocoindex.io/docs"&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our &lt;a href="https://cocoindex.io/docs/about/contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Community&lt;/h2&gt; 
&lt;p&gt;Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; 
&lt;p&gt;Join our community here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåü &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üëã &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ñ∂Ô∏è &lt;a href="https://www.youtube.com/@cocoindex-io"&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://cocoindex.io/blogs/"&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support us&lt;/h2&gt; 
&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ‰∏≠Êñá 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/15520" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15520" alt="datawhalechina%2Fhello-agents | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ È°πÁõÆ‰ªãÁªç&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÂ¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ"ÁôæÊ®°Â§ßÊàò"ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü"Agent ÂÖÉÂπ¥"„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉHello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ"‰ΩøÁî®ËÄÖ"ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ"ÊûÑÂª∫ËÄÖ"„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üìö Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;Âú®Á∫øÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª&lt;/a&gt;&lt;/strong&gt; - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;üìñ Cookbook(ÊµãËØïÁâà)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Êú¨Âú∞ÈòÖËØª&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè&lt;/li&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ ÂÜÖÂÆπÂØºËà™&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á´†ËäÇ&lt;/th&gt; 
   &lt;th&gt;ÂÖ≥ÈîÆÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;ÂâçË®Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊåÅÁª≠‰∫§‰∫íÁöÑ"ÊÉÖÂ¢ÉÁêÜËß£"&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á§æÂå∫Á≤æÈÄâ&lt;/th&gt; 
   &lt;th&gt;ÂÜÖÂÆπÊÄªÁªì&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-AgentÈù¢ËØïÈ¢òÊÄªÁªì&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra05-AgentSkills%E8%A7%A3%E8%AF%BB.md"&gt;05-Agent Skills‰∏éMCPÂØπÊØîËß£ËØª&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent Skills‰∏éMCPÊäÄÊúØÂØπÊØî&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra06-GUIAgent%E7%A7%91%E6%99%AE%E4%B8%8E%E5%AE%9E%E6%88%98.md"&gt;06-GUI AgentÁßëÊôÆ‰∏éÂÆûÊàò&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GUI AgentÁßëÊôÆ‰∏éÂ§öÂú∫ÊôØÂÆûÊàò&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ÁâàÊú¨‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉ&lt;em&gt;&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° Â¶Ç‰ΩïÂ≠¶‰π†&lt;/h2&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊ¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÈ°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ"Êô∫ËÉΩ‰Ωì"Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÊô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ&lt;code&gt;code&lt;/code&gt;Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;‚ÄÉ‚ÄÉÁé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ&lt;/p&gt; 
&lt;h2&gt;‰∏ã‰∏ÄÊ≠•ËßÑÂàí&lt;/h2&gt; 
&lt;p&gt;ÂèåËØ≠ËßÜÈ¢ëËØæÁ®ã[Ëã±Êñá+‰∏≠Êñá]ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ&lt;/p&gt; 
&lt;h2&gt;ü§ù Â¶Ç‰ΩïË¥°ÁåÆ&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®"Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ"‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Ëá¥Ë∞¢&lt;/h2&gt; 
&lt;h3&gt;Ê†∏ÂøÉË¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;Â≠ôÈü¨-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt; (Datawhale ÊàêÂëò, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;ÂßúËàíÂá°-È°πÁõÆË¥üË¥£‰∫∫&lt;/a&gt;ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò&lt;/a&gt; (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à&lt;/a&gt; (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂&lt;/a&gt; (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter Ë¥°ÁåÆËÄÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ&lt;/a&gt;(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü&lt;/a&gt; (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÁâπÂà´ÊÑüË∞¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251223.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÂÖ≥‰∫é Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú ÂºÄÊ∫êÂçèËÆÆ&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ΩúÂìÅÈááÁî®&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ&lt;/a&gt;ËøõË°åËÆ∏ÂèØ„ÄÇ&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>