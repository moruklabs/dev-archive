<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Tue, 05 Aug 2025 01:29:49 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>actualbudget/actual</title>
      <link>https://github.com/actualbudget/actual</link>
      <description>&lt;p&gt;A local-first personal finance app&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/actualbudget/actual/master/demo.png" alt="Actualbudget"&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Actual is a local-first personal finance tool. It is 100% free and open-source, written in NodeJS, it has a synchronization element so that all your changes can move between devices without any heavy lifting.&lt;/p&gt; 
&lt;p&gt;If you are interested in contributing, or want to know how development works, see our &lt;a href="https://actualbudget.org/docs/contributing/"&gt;contributing&lt;/a&gt; document we would love to have you.&lt;/p&gt; 
&lt;p&gt;Want to say thanks? Click the ⭐ at the top of the page.&lt;/p&gt; 
&lt;h2&gt;Key Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Actual &lt;a href="https://discord.gg/pRYNYr4W5A"&gt;discord&lt;/a&gt; community.&lt;/li&gt; 
 &lt;li&gt;Actual &lt;a href="https://actualbudget.org/docs"&gt;Community Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://actualbudget.org/docs/faq"&gt;Frequently asked questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are four ways to deploy Actual:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One-click deployment &lt;a href="https://www.pikapods.com/pods?run=actual"&gt;via PikaPods&lt;/a&gt; (~1.40 $/month) - recommended for non-technical users&lt;/li&gt; 
 &lt;li&gt;Managed hosting &lt;a href="https://actualbudget.org/docs/install/fly"&gt;via Fly.io&lt;/a&gt; (~1.50 $/month)&lt;/li&gt; 
 &lt;li&gt;Self-hosted by using &lt;a href="https://actualbudget.org/docs/install/docker"&gt;a Docker image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local-only apps - &lt;a href="https://actualbudget.org/download/"&gt;downloadable Windows, Mac and Linux apps&lt;/a&gt; you can run on your device&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Learn more in the &lt;a href="https://actualbudget.org/docs/install/"&gt;installation instructions docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Ready to Start Budgeting?&lt;/h2&gt; 
&lt;p&gt;Read about &lt;a href="https://actualbudget.org/docs/getting-started/envelope-budgeting"&gt;Envelope budgeting&lt;/a&gt; to know more about the idea behind Actual Budget.&lt;/p&gt; 
&lt;h3&gt;Are you new to budgeting or want to start fresh?&lt;/h3&gt; 
&lt;p&gt;Check out the community's &lt;a href="https://actualbudget.org/docs/getting-started/starting-fresh"&gt;Starting Fresh&lt;/a&gt; guide so you can quickly get up and running!&lt;/p&gt; 
&lt;h3&gt;Are you migrating from other budgeting apps?&lt;/h3&gt; 
&lt;p&gt;Check out the community's &lt;a href="https://actualbudget.org/docs/migration/"&gt;Migration&lt;/a&gt; guide to start jumping on the Actual Budget train!&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;We have a wide range of documentation on how to use Actual, this is all available in our &lt;a href="https://actualbudget.org/docs"&gt;Community Documentation&lt;/a&gt;, this includes topics on Budgeting, Account Management, Tips &amp;amp; Tricks and some documentation for developers.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Actual is a community driven product. Learn more about &lt;a href="https://actualbudget.org/docs/contributing/"&gt;contributing to Actual&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Code structure&lt;/h3&gt; 
&lt;p&gt;The Actual app is split up into a few packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;loot-core - The core application that runs on any platform&lt;/li&gt; 
 &lt;li&gt;desktop-client - The desktop UI&lt;/li&gt; 
 &lt;li&gt;desktop-electron - The desktop app&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More information on the project structure is available in our &lt;a href="https://actualbudget.org/docs/contributing/project-details"&gt;community documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Feature Requests&lt;/h3&gt; 
&lt;p&gt;Current feature requests can be seen &lt;a href="https://github.com/actualbudget/actual/issues?q=is%3Aissue+label%3A%22needs+votes%22+sort%3Areactions-%2B1-desc"&gt;here&lt;/a&gt;. Vote for your favorite requests by reacting &lt;span&gt;👍&lt;/span&gt; to the top comment of the request.&lt;/p&gt; 
&lt;p&gt;To add new feature requests, open a new Issue of the "Feature Request" type.&lt;/p&gt; 
&lt;h3&gt;Translation&lt;/h3&gt; 
&lt;p&gt;Make Actual Budget accessible to more people by helping with the &lt;a href="https://actualbudget.org/docs/contributing/i18n/"&gt;Internationalization&lt;/a&gt; of Actual. We are using a crowd sourcing tool to manage the translations, see our &lt;a href="https://hosted.weblate.org/projects/actualbudget/"&gt;Weblate Project&lt;/a&gt;. Weblate proudly supports open-source software projects through their &lt;a href="https://weblate.org/en/hosting/#libre"&gt;Libre plan&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/actualbudget/"&gt; &lt;img src="https://hosted.weblate.org/widget/actualbudget/actual/287x66-grey.png" alt="Translation status"&gt; &lt;/a&gt; 
&lt;h2&gt;Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e20537dd8b74956f86736726ccfbc6f0565bec22.svg?sanitize=true" alt="Alt" title="Repobeats analytics image"&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Thanks to our wonderful sponsors who make Actual Budget possible!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.netlify.com"&gt; &lt;img src="https://www.netlify.com/v3/img/components/netlify-color-accent.svg?sanitize=true" alt="Deploys by Netlify"&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MaaAssistantArknights/MaaAssistantArknights</title>
      <link>https://github.com/MaaAssistantArknights/MaaAssistantArknights</link>
      <description>&lt;p&gt;《明日方舟》小助手，全日常一键长草！| A one-click tool for the daily tasks of Arknights, supporting all clients.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img alt="LOGO" src="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/docs/.vuepress/public/images/maa-logo_512x512.png" width="256" height="256"&gt; 
 &lt;h1&gt;MaaAssistantArknights&lt;/h1&gt; 
 &lt;br&gt; 
 &lt;div&gt; 
  &lt;img alt="C++" src="https://img.shields.io/badge/C++-20-%2300599C?logo=cplusplus"&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img alt="platform" src="https://img.shields.io/badge/platform-Windows%20%7C%20Linux%20%7C%20macOS-blueviolet"&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img alt="license" src="https://img.shields.io/github/license/MaaAssistantArknights/MaaAssistantArknights"&gt; 
  &lt;img alt="commit" src="https://img.shields.io/github/commit-activity/m/MaaAssistantArknights/MaaAssistantArknights?color=%23ff69b4"&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;img alt="stars" src="https://img.shields.io/github/stars/MaaAssistantArknights/MaaAssistantArknights?style=social"&gt; 
  &lt;img alt="GitHub all releases" src="https://img.shields.io/github/downloads/MaaAssistantArknights/MaaAssistantArknights/total?style=social"&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;!-- markdownlint-restore --&gt; 
 &lt;p&gt;&lt;a href="https://maa.plus/docs/zh-cn/"&gt;简体中文&lt;/a&gt; | &lt;a href="https://maa.plus/docs/zh-tw/"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://maa.plus/docs/en-us/"&gt;English&lt;/a&gt; | &lt;a href="https://maa.plus/docs/ja-jp/"&gt;日本語&lt;/a&gt; | &lt;a href="https://maa.plus/docs/ko-kr/"&gt;한국어&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;MAA 的意思是 MAA Assistant Arknights&lt;/p&gt; 
 &lt;p&gt;一款明日方舟游戏小助手&lt;/p&gt; 
 &lt;p&gt;基于图像识别技术，一键完成全部日常任务！&lt;/p&gt; 
 &lt;p&gt;绝赞更新中 ✿✿ヽ(°▽°)ノ✿&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;下载与安装&lt;/h2&gt; 
&lt;p&gt;请阅读 &lt;a href="https://maa.plus/docs/zh-cn/manual/newbie.html"&gt;文档&lt;/a&gt; 后前往 &lt;a href="https://maa.plus"&gt;官网&lt;/a&gt; 或 &lt;a href="https://github.com/MaaAssistantArknights/MaaAssistantArknights/releases"&gt;Releases&lt;/a&gt; 下载，并参考 &lt;a href="https://maa.plus/docs/zh-cn/manual/newbie.html"&gt;新手上路&lt;/a&gt; 进行安装。&lt;/p&gt; 
&lt;h2&gt;亮点功能&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;刷理智，掉落识别及上传 &lt;a href="https://penguin-stats.cn/"&gt;企鹅物流&lt;/a&gt;，&lt;a href="https://ark.yituliu.cn/"&gt;一图流&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;智能基建换班，自动计算干员效率，单设施内最优解；同时也支持 &lt;a href="https://maa.plus/docs/zh-cn/protocol/base-scheduling-schema.html"&gt;自定义排班&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;自动公招，可选使用加急许可，一次全部刷完！公招数据自动上传 &lt;a href="https://penguin-stats.cn/result/stage/recruit/recruit"&gt;企鹅物流&lt;/a&gt;，&lt;a href="https://ark.yituliu.cn/survey/maarecruitdata"&gt;一图流&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;支持手动识别公招界面，方便对高星公招做出选择 &lt;del&gt;（你的这个高资回费出的是推王呢还是推王呢）&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;支持识别干员列表，统计已有和未有干员及潜能，并在公招识别显示&lt;/li&gt; 
 &lt;li&gt;支持识别养成材料，并导出至 &lt;a href="https://penguin-stats.cn/planner"&gt;企鹅物流刷图规划&lt;/a&gt;、&lt;a href="https://arkntools.app/#/material"&gt;明日方舟工具箱&lt;/a&gt;、&lt;a href="https://ark-nights.com/settings"&gt;ARK-NIGHTS 干员培养表&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;访问好友、收取信用及购物、领取日常奖励等，一键全日常自动长草&lt;/li&gt; 
 &lt;li&gt;肉鸽全自动刷源石锭和等级，自动烧水和凹直升，智能识别干员及练度&lt;/li&gt; 
 &lt;li&gt;选择作业 JSON 文件，自动抄作业， &lt;a href="https://www.bilibili.com/video/BV1H841177Fk/"&gt;视频演示&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;支持 C, Python, Java, Rust, Golang, Java HTTP, Rust HTTP 等多种接口，方便集成调用，自定义你的 MAA！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;details&gt;
 &lt;summary&gt;话不多说，看图！&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/.vuepress/public/images/zh-cn/readme/1-dark.png"&gt; 
  &lt;img alt="zh1" src="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/docs/.vuepress/public/images/zh-cn/readme/1-light.png"&gt; 
 &lt;/picture&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/.vuepress/public/images/zh-cn/readme/2-dark.png"&gt; 
  &lt;img alt="zh2" src="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/docs/.vuepress/public/images/zh-cn/readme/2-light.png"&gt; 
 &lt;/picture&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/.vuepress/public/images/zh-cn/readme/3-dark.png"&gt; 
  &lt;img alt="zh3" src="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/docs/.vuepress/public/images/zh-cn/readme/3-light.png"&gt; 
 &lt;/picture&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/.vuepress/public/images/zh-cn/readme/4-dark.png"&gt; 
  &lt;img alt="zh4" src="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/docs/.vuepress/public/images/zh-cn/readme/4-light.png"&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;h2&gt;使用说明&lt;/h2&gt; 
&lt;h3&gt;功能介绍&lt;/h3&gt; 
&lt;p&gt;请参阅 &lt;a href="https://maa.plus/docs/zh-cn/manual/"&gt;用户手册&lt;/a&gt;。&lt;/p&gt; 
&lt;h3&gt;外服支持&lt;/h3&gt; 
&lt;p&gt;目前国际服（美服）、日服、韩服、繁中服的绝大部分功能均已支持。但由于外服用户较少及项目人手不足，很多功能并没有进行全面的测试，所以请自行体验。&lt;br&gt; 若您遇到了 Bug，或对某个功能有强需求，欢迎在 &lt;a href="https://github.com/MaaAssistantArknights/MaaAssistantArknights/issues"&gt;Issues&lt;/a&gt; 和 &lt;a href="https://github.com/MaaAssistantArknights/MaaAssistantArknights/discussions"&gt;讨论区&lt;/a&gt; 催更；或加入我们一起建设 MAA！请参阅 &lt;a href="https://maa.plus/docs/zh-cn/develop/overseas-client-adaptation.html"&gt;外服适配教程&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;CLI 支持&lt;/h3&gt; 
&lt;p&gt;MAA 支持命令行界面（CLI）操作，支持 Linux，macOS 和 Windows，可用于自动化脚本或在无图形界面的服务器上使用。请参阅 &lt;a href="https://maa.plus/docs/zh-cn/manual/cli/"&gt;CLI 使用指南&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;加入我们&lt;/h2&gt; 
&lt;h3&gt;主要关联项目&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;目前项目组非常缺前端大佬，若您有相关经验，欢迎加入我们！&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;全新框架：&lt;a href="https://github.com/MaaXYZ/MaaFramework"&gt;MaaFramework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://prts.plus"&gt;作业站&lt;/a&gt; 前端：&lt;a href="https://github.com/MaaAssistantArknights/maa-copilot-frontend"&gt;maa-copilot-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://prts.plus"&gt;作业站&lt;/a&gt; 后端：&lt;a href="https://github.com/MaaAssistantArknights/MaaBackendCenter"&gt;MaaBackendCenter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://maa.plus"&gt;官网&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/website"&gt;前端&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;深度学习：&lt;a href="https://github.com/MaaAssistantArknights/MaaAI"&gt;MaaAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;多语言 (i18n)&lt;/h3&gt; 
&lt;p&gt;MAA 支持多国语言，并使用 Weblate 进行本地化管理。如果您通晓多门语言，欢迎前往 &lt;a href="https://weblate.maa-org.net"&gt;MAA Weblate&lt;/a&gt; 帮助我们进行翻译。&lt;/p&gt; 
&lt;p&gt;MAA 以中文（简体）为第一语言，翻译词条均以中文（简体）为准。&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://weblate.maa-org.net/engage/maa/"&gt;&lt;img src="https://weblate.maa-org.net/widget/maa/wpf-gui/multi-auto.svg?sanitize=true" alt="Weblate"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;参与开发&lt;/h3&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;p&gt;请参阅 &lt;a href="https://maa.plus/docs/zh-cn/develop/development.html"&gt;开始开发&lt;/a&gt;。&lt;/p&gt; 
&lt;h4&gt;Linux | macOS&lt;/h4&gt; 
&lt;p&gt;请参阅 &lt;a href="https://maa.plus/docs/zh-cn/develop/linux-tutorial.html"&gt;Linux 编译教程&lt;/a&gt;。&lt;/p&gt; 
&lt;h4&gt;API&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/include/AsstCaller.h"&gt;C 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Cpp/main.cpp"&gt;集成示例&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Python/asst/asst.py"&gt;Python 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Python/sample.py"&gt;集成示例&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Golang"&gt;Golang 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Golang/maa/maa.go"&gt;集成示例&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Dart"&gt;Dart 接口&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Java/src/main/java/com/iguigui/maaj/easySample/MaaCore.java"&gt;Java 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Java/src/main/java/com/iguigui/maaj/easySample/MaaJavaSample.java"&gt;集成示例&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Java/Readme.md"&gt;Java HTTP 接口&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Rust/src/maa_sys"&gt;Rust 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Rust"&gt;HTTP 接口&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MaaAssistantArknights/MaaX/tree/main/packages/main/coreLoader"&gt;TypeScript 接口&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Woolang/maa.wo"&gt;Woolang 接口&lt;/a&gt;：&lt;a href="https://raw.githubusercontent.com/MaaAssistantArknights/MaaAssistantArknights/dev/src/Woolang/demo.wo"&gt;集成示例&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://maa.plus/docs/zh-cn/protocol/integration.html"&gt;集成文档&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://maa.plus/docs/zh-cn/protocol/callback-schema.html"&gt;回调消息协议&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://maa.plus/docs/zh-cn/protocol/task-schema.html"&gt;任务流程协议&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://maa.plus/docs/zh-cn/protocol/copilot-schema.html"&gt;自动抄作业协议&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;外服适配&lt;/h4&gt; 
&lt;p&gt;请参阅 &lt;a href="https://maa.plus/docs/zh-cn/develop/overseas-client-adaptation.html"&gt;外服适配教程&lt;/a&gt;，对于国服已支持的功能，绝大部分的外服适配工作仅需要截图 + 简单的 JSON 修改即可。&lt;/p&gt; 
&lt;h4&gt;想参与开发，但不太会用 GitHub?&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://maa.plus/docs/zh-cn/develop/development.html#github-pull-request-%E6%B5%81%E7%A8%8B%E7%AE%80%E8%BF%B0"&gt;GitHub Pull Request 流程简述&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Issue bot&lt;/h4&gt; 
&lt;p&gt;请参阅 &lt;a href="https://maa.plus/docs/zh-cn/develop/issue-bot-usage.html"&gt;Issue Bot 使用方法&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;致谢&lt;/h2&gt; 
&lt;h3&gt;开源库&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;图像识别库：&lt;a href="https://github.com/opencv/opencv.git"&gt;opencv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;文字识别库：&lt;a href="https://github.com/DayBreak-u/chineseocr_lite.git"&gt;chineseocr_lite&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;文字识别库：&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;PaddleOCR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;深度学习部署库：&lt;a href="https://github.com/PaddlePaddle/FastDeploy"&gt;FastDeploy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;机器学习加速器：&lt;a href="https://github.com/microsoft/onnxruntime"&gt;onnxruntime&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;关卡掉落识别：&lt;a href="https://github.com/penguin-statistics/recognizer"&gt;企鹅物流识别&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;地图格子识别：&lt;a href="https://github.com/yuanyan3060/Arknights-Tile-Pos"&gt;Arknights-Tile-Pos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C++ JSON 库：&lt;a href="https://github.com/MistEO/meojson.git"&gt;meojson&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C++ 运算符解析器：&lt;a href="https://github.com/kimwalisch/calculator"&gt;calculator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;C++ base64 编解码：&lt;a href="https://github.com/ReneNyffenegger/cpp-base64"&gt;cpp-base64&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;C++ 解压压缩库：&lt;a href="https://github.com/madler/zlib"&gt;zlib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C++ Gzip 封装：&lt;a href="https://github.com/mapbox/gzip-hpp"&gt;gzip-hpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;安卓触控事件器：&lt;a href="https://github.com/DeviceFarmer/minitouch"&gt;Minitouch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;安卓触控事件器：&lt;a href="https://github.com/MaaAssistantArknights/MaaTouch"&gt;MaaTouch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WPF MVVM 框架：&lt;a href="https://github.com/canton7/Stylet"&gt;Stylet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WPF 控件库：&lt;a href="https://github.com/HandyOrg/HandyControl"&gt;HandyControl&lt;/a&gt; -&amp;gt; &lt;a href="https://github.com/ghost1372/HandyControls"&gt;HandyControls&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C# 日志：&lt;a href="https://github.com/serilog/serilog"&gt;Serilog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C# JSON 库：&lt;a href="https://github.com/JamesNK/Newtonsoft.Json"&gt;Newtonsoft.Json&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dotnet/runtime"&gt;System.Text.Json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;下载器：&lt;a href="https://github.com/aria2/aria2"&gt;aria2&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;数据源&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;del&gt;公开招募数据：&lt;a href="https://www.bigfun.cn/tools/aktools/hr"&gt;明日方舟工具箱&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;干员及基建数据：&lt;a href="http://prts.wiki/"&gt;PRTS Wiki&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;关卡数据：&lt;a href="https://penguin-stats.cn/"&gt;企鹅物流数据统计&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;游戏数据及资源：&lt;a href="https://github.com/yuanyan3060/ArknightsGameResource"&gt;明日方舟客户端素材&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;游戏数据：&lt;a href="https://github.com/ArknightsAssets/ArknightsGamedata"&gt;《明日方舟》Yostar游戏数据&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;贡献/参与者&lt;/h3&gt; 
&lt;p&gt;感谢所有参与到开发/测试中的朋友们，是大家的帮助让 MAA 越来越好！ (*´▽｀)ノノ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/MaaAssistantArknights/MaaAssistantArknights/graphs/contributors"&gt;&lt;img src="https://contributors-img.web.app/image?repo=MaaAssistantArknights/MaaAssistantArknights&amp;amp;max=105&amp;amp;columns=15" alt="Contributors"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;声明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;本软件使用 &lt;a href="https://spdx.org/licenses/AGPL-3.0-only.html"&gt;GNU Affero General Public License v3.0 only&lt;/a&gt; 开源，并附带额外 &lt;a href="https://github.com/MaaAssistantArknights/MaaAssistantArknights/raw/dev/terms-of-service.md"&gt;用户协议&lt;/a&gt;。&lt;/li&gt; 
 &lt;li&gt;本软件 logo 并非使用 AGPL 3.0 协议开源，&lt;a href="https://weibo.com/u/3251357314"&gt;耗毛&lt;/a&gt;、vie 两位画师及软件全体开发者保留所有权利。不得以 AGPL 3.0 协议已授权为由在未经授权的情况下使用本软件 logo，不得在未经授权的情况下将本软件 logo 用于任何商业用途。&lt;/li&gt; 
 &lt;li&gt;本软件开源、免费，仅供学习交流使用。若您遇到商家使用本软件进行代练并收费，可能是设备与时间等费用，产生的问题及后果与本软件无关。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DirectML 支持说明&lt;/h3&gt; 
&lt;p&gt;本软件支持 GPU 加速功能，其在 Windows 平台上依赖于 Microsoft 提供的独立组件 &lt;a href="https://learn.microsoft.com/en-us/windows/ai/directml/"&gt;DirectML&lt;/a&gt;。DirectML 并非本项目的开源部分，也不受 AGPL 3.0 的约束。为方便用户，我们随安装包附带了一个未经修改的 DirectML.dll 文件。如果您无需 GPU 加速功能，可安全删除该 DLL 文件，软件的核心功能仍可正常运行。&lt;/p&gt; 
&lt;h2&gt;广告&lt;/h2&gt; 
&lt;p&gt;用户交流 QQ 群：&lt;a href="https://api.maa.plus/MaaAssistantArknights/api/qqgroup/index.html"&gt;MAA 使用 &amp;amp; 粥游交流 QQ 群&lt;/a&gt;&lt;br&gt; Discord 服务器: &lt;a href="https://discord.gg/23DfZ9uA4V"&gt;邀请链接&lt;/a&gt;&lt;br&gt; 用户交流 TG 群：&lt;a href="https://t.me/+Mgc2Zngr-hs3ZjU1"&gt;Telegram 群&lt;/a&gt;&lt;br&gt; 自动战斗 JSON 作业分享：&lt;a href="https://prts.plus"&gt;prts.plus&lt;/a&gt;&lt;br&gt; Bilibili 直播间：&lt;a href="https://live.bilibili.com/2808861"&gt;MrEO 直播间&lt;/a&gt; 直播敲代码 &amp;amp; &lt;a href="https://live.bilibili.com/27548877"&gt;MAA-Official 直播间&lt;/a&gt; 游戏/杂谈&lt;/p&gt; 
&lt;p&gt;技术群（舟无关、禁水）：&lt;a href="https://jq.qq.com/?_wv=1027&amp;amp;k=ypbzXcA2"&gt;内卷地狱！(QQ 群)&lt;/a&gt;&lt;br&gt; 开发者群：&lt;a href="https://jq.qq.com/?_wv=1027&amp;amp;k=JM9oCk3C"&gt;QQ 群&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果觉得软件对你有帮助，帮忙点个 Star 吧！~（网页最上方右上角的小星星），这就是对我们最大的支持了！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>souzatharsis/podcastfy</title>
      <link>https://github.com/souzatharsis/podcastfy</link>
      <description>&lt;p&gt;An Open Source Python alternative to NotebookLM's podcast feature: Transforming Multimodal Content into Captivating Multilingual Audio Conversations with GenAI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12965" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12965" alt="Podcastfy.ai | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Podcastfy.ai 🎙️🤖&lt;/h1&gt; 
 &lt;p&gt;An Open Source API alternative to NotebookLM's podcast feature: Transforming Multimodal Content into Captivating Multilingual Audio Conversations with GenAI&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5d42c106-aabe-44c1-8498-e9c53545ba40"&gt;https://github.com/user-attachments/assets/5d42c106-aabe-44c1-8498-e9c53545ba40&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/souzatharsis/podcastfy/raw/main/paper/paper.pdf"&gt;Paper&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/raw/59563ee105a0d1dbb46744e0ff084471670dd725/podcastfy.ipynb"&gt;Python Package&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/raw/59563ee105a0d1dbb46744e0ff084471670dd725/usage/cli.md"&gt;CLI&lt;/a&gt; | &lt;a href="https://openpod.fly.dev/"&gt;Web App&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/issues"&gt;Feedback&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/souzatharsis/podcastfy/blob/main/podcastfy.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/podcastfy/"&gt;&lt;img src="https://img.shields.io/pypi/v/podcastfy" alt="PyPi Status"&gt;&lt;/a&gt; &lt;img src="https://static.pepy.tech/badge/podcastfy" alt="PyPI Downloads"&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/issues"&gt;&lt;img src="https://img.shields.io/github/issues-raw/souzatharsis/podcastfy" alt="Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/actions/workflows/python-app.yml"&gt;&lt;img src="https://github.com/souzatharsis/podcastfy/actions/workflows/python-app.yml/badge.svg?sanitize=true" alt="Pytest"&gt;&lt;/a&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/actions/workflows/docker-publish.yml"&gt;&lt;img src="https://github.com/souzatharsis/podcastfy/actions/workflows/docker-publish.yml/badge.svg?sanitize=true" alt="Docker"&gt;&lt;/a&gt; &lt;a href="https://podcastfy.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/podcastfy/badge/?version=latest" alt="Documentation Status"&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/souzatharsis/podcastfy" alt="GitHub Repo stars"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Podcastfy is an open-source Python package that transforms multi-modal content (text, images) into engaging, multi-lingual audio conversations using GenAI. Input content includes websites, PDFs, images, YouTube videos, as well as user provided topics.&lt;/p&gt; 
&lt;p&gt;Unlike closed-source UI-based tools focused primarily on research synthesis (e.g. NotebookLM ❤️), Podcastfy focuses on open source, programmatic and bespoke generation of engaging, conversational content from a multitude of multi-modal sources, enabling customization and scale.&lt;/p&gt; 
&lt;h2&gt;Testimonials 💬&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Love that you casually built an open source version of the most popular product Google built in the last decade"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Loving this initiative and the best I have seen so far especially for a 'non-techie' user."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Your library was very straightforward to work with. You did Amazing work brother 🙏"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"I think it's awesome that you were inspired/recognize how hard it is to beat NotebookLM's quality, but you did an &lt;em&gt;incredible&lt;/em&gt; job with this! It sounds incredible, and it's open-source! Thank you for being amazing!"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=souzatharsis/podcastfy&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=souzatharsis/podcastfy&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Audio Examples 🔊&lt;/h2&gt; 
&lt;p&gt;This sample collection was generated using this &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/examples.ipynb"&gt;Python Notebook&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;Sample 1: Senecio, 1922 (Paul Klee) and Connection of Civilizations (2017) by Gheorghe Virtosu&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/Senecio.jpeg" alt="Senecio, 1922 (Paul Klee)" width="20%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/connection.jpg" alt="Connection of Civilizations (2017) by Gheorghe Virtosu " width="21.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/a4134a0d-138c-4ab4-bc70-0f53b3507e6b"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Sample 2: The Great Wave off Kanagawa, 1831 (Hokusai) and Takiyasha the Witch and the Skeleton Spectre, c. 1844 (Kuniyoshi)&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/japan_1.jpg" alt="The Great Wave off Kanagawa, 1831 (Hokusai)" width="20%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/japan2.jpg" alt="Takiyasha the Witch and the Skeleton Spectre, c. 1844 (Kuniyoshi)" width="21.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/f6aaaeeb-39d2-4dde-afaf-e2cd212e9fed"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Sample 3: Pop culture icon Taylor Swift and Mona Lisa, 1503 (Leonardo da Vinci)&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/taylor.png" alt="Taylor Swift" width="28%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/monalisa.jpeg" alt="Mona Lisa" width="10.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/3b6f7075-159b-4540-946f-3f3907dffbca"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h3&gt;Text&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Audio&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;video src="https://github.com/user-attachments/assets/ef41a207-a204-4b60-a11e-06d66a0fbf06"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td&gt;Personal Website&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.souzatharsis.com"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://soundcloud.com/high-lander123/amodei?in=high-lander123/sets/podcastfy-sample-audio-longform&amp;amp;si=b8dfaf4e3ddc4651835e277500384156"&gt;Audio&lt;/a&gt; (&lt;code&gt;longform=True&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;Lex Fridman Podcast: 5h interview with Dario Amodei Anthropic's CEO&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=ugvHCXCOmm4"&gt;Youtube&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://soundcloud.com/high-lander123/benjamin?in=high-lander123/sets/podcastfy-sample-audio-longform&amp;amp;si=dca7e2eec1c94252be18b8794499959a&amp;amp;utm_source=clipboard&amp;amp;utm_medium=text&amp;amp;utm_campaign=social_sharing"&gt;Audio&lt;/a&gt; (&lt;code&gt;longform=True&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;Benjamin Franklin's Autobiography&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gutenberg.org/cache/epub/148/pg148.txt"&gt;Book&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Multi-Lingual Text&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Content Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Audio&lt;/th&gt; 
   &lt;th&gt;Source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French&lt;/td&gt; 
   &lt;td&gt;Website&lt;/td&gt; 
   &lt;td&gt;Agroclimate research information&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://audio.com/thatupiso/audio/podcast-fr-agro"&gt;Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://agroclim.inrae.fr/"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese-BR&lt;/td&gt; 
   &lt;td&gt;News Article&lt;/td&gt; 
   &lt;td&gt;Election polls in São Paulo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://audio.com/thatupiso/audio/podcast-thatupiso-br"&gt;Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://noticias.uol.com.br/eleicoes/2024/10/03/nova-pesquisa-datafolha-quem-subiu-e-quem-caiu-na-disputa-de-sp-03-10.htm"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart 💻&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$ pip install ffmpeg&lt;/code&gt; (for audio processing)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install from PyPI &lt;code&gt;$ pip install podcastfy&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set up your &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/config.md"&gt;API keys&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from podcastfy.client import generate_podcast

audio_file = generate_podcast(urls=["&amp;lt;url1&amp;gt;", "&amp;lt;url2&amp;gt;"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;python -m podcastfy.client --url &amp;lt;url1&amp;gt; --url &amp;lt;url2&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fastapi (Beta for urls)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Containerize podcastify and launch the api
Dockerfile_api

Make requests to the api look at the notebook for a clear example
fetch_audio(request_data, ENDPOINT, BASE_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage 💻&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/podcastfy.ipynb"&gt;Python Package Quickstart&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/how-to.md"&gt;How to&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://podcastfy.readthedocs.io/en/latest/podcastfy.html"&gt;Python Package Reference Manual&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/cli.md"&gt;CLI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Customization 🔧&lt;/h2&gt; 
&lt;p&gt;Podcastfy offers a range of customization options to tailor your AI-generated podcasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Customize podcast &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/conversation_custom.md"&gt;conversation&lt;/a&gt; (e.g. format, style, voices)&lt;/li&gt; 
 &lt;li&gt;Choose to run &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/local_llm.md"&gt;Local LLMs&lt;/a&gt; (156+ HuggingFace models)&lt;/li&gt; 
 &lt;li&gt;Set other &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/config.md"&gt;Configuration Settings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features ✨&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate conversational content from multiple sources and formats (images, text, websites, YouTube, and PDFs).&lt;/li&gt; 
 &lt;li&gt;Generate shorts (2-5 minutes) or longform (30+ minutes) podcasts.&lt;/li&gt; 
 &lt;li&gt;Customize transcript and audio generation (e.g., style, language, structure).&lt;/li&gt; 
 &lt;li&gt;Generate transcripts using 100+ LLM models (OpenAI, Anthropic, Google etc).&lt;/li&gt; 
 &lt;li&gt;Leverage local LLMs for transcript generation for increased privacy and control.&lt;/li&gt; 
 &lt;li&gt;Integrate with advanced text-to-speech models (OpenAI, Google, ElevenLabs, and Microsoft Edge).&lt;/li&gt; 
 &lt;li&gt;Provide multi-language support for global content creation.&lt;/li&gt; 
 &lt;li&gt;Integrate seamlessly with CLI and Python packages for automated workflows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built with Podcastfy 🚀&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.open-notebook.ai/"&gt;OpenNotebook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.surfsense.net/"&gt;SurfSense&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openpod.fly.dev/"&gt;OpenPod&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evandempsey/podcast-llm"&gt;Podcast-llm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/thatupiso/Podcastfy.ai_demo"&gt;Podcastfy-HuggingFace App&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Updates 🚀🚀&lt;/h2&gt; 
&lt;h3&gt;v0.4.0+ release&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Released new Multi-Speaker TTS model (is it the one NotebookLM uses?!?)&lt;/li&gt; 
 &lt;li&gt;Generate short or longform podcasts&lt;/li&gt; 
 &lt;li&gt;Generate podcasts from input topic using grounded real-time web search&lt;/li&gt; 
 &lt;li&gt;Integrate with 100+ LLM models (OpenAI, Anthropic, Google etc) for transcript generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This software is licensed under &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/LICENSE"&gt;Apache 2.0&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/license-guide.md"&gt;instructions&lt;/a&gt; if you would like to use podcastfy in your software.&lt;/p&gt; 
&lt;h2&gt;Contributing 🤝&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/GUIDELINES.md"&gt;Guidelines&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Example Use Cases 🎧🎶&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Content Creators&lt;/strong&gt; can use &lt;code&gt;Podcastfy&lt;/code&gt; to convert blog posts, articles, or multimedia content into podcast-style audio, enabling them to reach broader audiences. By transforming content into an audio format, creators can cater to users who prefer listening over reading.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Educators&lt;/strong&gt; can transform lecture notes, presentations, and visual materials into audio conversations, making educational content more accessible to students with different learning preferences. This is particularly beneficial for students with visual impairments or those who have difficulty processing written information.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Researchers&lt;/strong&gt; can convert research papers, visual data, and technical content into conversational audio. This makes it easier for a wider audience, including those with disabilities, to consume and understand complex scientific information. Researchers can also create audio summaries of their work to enhance accessibility.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accessibility Advocates&lt;/strong&gt; can use &lt;code&gt;Podcastfy&lt;/code&gt; to promote digital accessibility by providing a tool that converts multimodal content into auditory formats. This helps individuals with visual impairments, dyslexia, or other disabilities that make it challenging to consume written or visual content.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/souzatharsis/podcastfy/graphs/contributors"&gt; &lt;img alt="contributors" src="https://contrib.rocks/image?repo=souzatharsis/podcastfy"&gt; &lt;/a&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; ↑ Back to Top ↑ &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jellyfin/jellyfin</title>
      <link>https://github.com/jellyfin/jellyfin</link>
      <description>&lt;p&gt;The Free Software Media System - Server Backend &amp; API&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Jellyfin&lt;/h1&gt; 
&lt;h3 align="center"&gt;The Free Software Media System&lt;/h3&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; &lt;img alt="Logo Banner" src="https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true"&gt; &lt;br&gt; &lt;br&gt; &lt;a href="https://github.com/jellyfin/jellyfin"&gt; &lt;img alt="GPL 2.0 License" src="https://img.shields.io/github/license/jellyfin/jellyfin.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/releases"&gt; &lt;img alt="Current Release" src="https://img.shields.io/github/release/jellyfin/jellyfin.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://translate.jellyfin.org/projects/jellyfin/jellyfin-core/?utm_source=widget"&gt; &lt;img alt="Translation Status" src="https://translate.jellyfin.org/widgets/jellyfin/-/jellyfin-core/svg-badge.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/jellyfin/jellyfin"&gt; &lt;img alt="Docker Pull Count" src="https://img.shields.io/docker/pulls/jellyfin/jellyfin.svg?sanitize=true"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://opencollective.com/jellyfin"&gt; &lt;img alt="Donate" src="https://img.shields.io/opencollective/all/jellyfin.svg?label=backers"&gt; &lt;/a&gt; &lt;a href="https://features.jellyfin.org"&gt; &lt;img alt="Submit Feature Requests" src="https://img.shields.io/badge/fider-vote%20on%20features-success.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://matrix.to/#/%23jellyfinorg:matrix.org"&gt; &lt;img alt="Chat on Matrix" src="https://img.shields.io/matrix/jellyfinorg:matrix.org.svg?logo=matrix"&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/releases.atom"&gt; &lt;img alt="Release RSS Feed" src="https://img.shields.io/badge/rss-releases-ffa500?logo=rss"&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/commits/master.atom"&gt; &lt;img alt="Master Commits RSS Feed" src="https://img.shields.io/badge/rss-commits-ffa500?logo=rss"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it. We welcome anyone who is interested in joining us in our quest!&lt;/p&gt; 
&lt;p&gt;For further details, please see &lt;a href="https://jellyfin.org/docs/"&gt;our documentation page&lt;/a&gt;. To receive the latest updates, get help with Jellyfin, and join the community, please visit &lt;a href="https://jellyfin.org/docs/general/getting-help"&gt;one of our communication channels&lt;/a&gt;. For more information about the project, please see our &lt;a href="https://jellyfin.org/docs/general/about"&gt;about page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to get started?&lt;/strong&gt;&lt;br&gt; Check out our &lt;a href="https://jellyfin.org/downloads"&gt;downloads page&lt;/a&gt; or our &lt;a href="https://jellyfin.org/docs/general/installation/"&gt;installation guide&lt;/a&gt;, then see our &lt;a href="https://jellyfin.org/docs/general/quick-start"&gt;quick start guide&lt;/a&gt;. You can also &lt;a href="https://jellyfin.org/docs/general/installation/source"&gt;build from source&lt;/a&gt;.&lt;br&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Something not working right?&lt;/strong&gt;&lt;br&gt; Open an &lt;a href="https://jellyfin.org/docs/general/contributing/issues"&gt;Issue&lt;/a&gt; on GitHub.&lt;br&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to contribute?&lt;/strong&gt;&lt;br&gt; Check out our &lt;a href="https://jellyfin.org/contribute"&gt;contributing choose-your-own-adventure&lt;/a&gt; to see where you can help, then see our &lt;a href="https://jellyfin.org/docs/general/contributing/"&gt;contributing guide&lt;/a&gt; and our &lt;a href="https://jellyfin.org/docs/general/community-standards"&gt;community standards&lt;/a&gt;.&lt;br&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;New idea or improvement?&lt;/strong&gt;&lt;br&gt; Check out our &lt;a href="https://features.jellyfin.org/?view=most-wanted"&gt;feature request hub&lt;/a&gt;.&lt;br&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't see Jellyfin in your language?&lt;/strong&gt;&lt;br&gt; Check out our &lt;a href="https://translate.jellyfin.org"&gt;Weblate instance&lt;/a&gt; to help translate Jellyfin and its subprojects.&lt;br&gt;&lt;/p&gt; 
&lt;a href="https://translate.jellyfin.org/engage/jellyfin/?utm_source=widget"&gt; &lt;img src="https://translate.jellyfin.org/widgets/jellyfin/-/jellyfin-web/multi-auto.svg?sanitize=true" alt="Detailed Translation Status"&gt; &lt;/a&gt; 
&lt;hr&gt; 
&lt;h2&gt;Jellyfin Server&lt;/h2&gt; 
&lt;p&gt;This repository contains the code for Jellyfin's backend server. Note that this is only one of many projects under the Jellyfin GitHub &lt;a href="https://github.com/jellyfin/"&gt;organization&lt;/a&gt; on GitHub. If you want to contribute, you can start by checking out our &lt;a href="https://jellyfin.org/docs/general/contributing/index.html"&gt;documentation&lt;/a&gt; to see what to work on.&lt;/p&gt; 
&lt;h2&gt;Server Development&lt;/h2&gt; 
&lt;p&gt;These instructions will help you get set up with a local development environment in order to contribute to this repository. Before you start, please be sure to completely read our &lt;a href="https://jellyfin.org/docs/general/contributing/development.html"&gt;guidelines on development contributions&lt;/a&gt;. Note that this project is supported on all major operating systems except FreeBSD, which is still incompatible.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Before the project can be built, you must first install the &lt;a href="https://dotnet.microsoft.com/download/dotnet"&gt;.NET 9.0 SDK&lt;/a&gt; on your system.&lt;/p&gt; 
&lt;p&gt;Instructions to run this project from the command line are included here, but you will also need to install an IDE if you want to debug the server while it is running. Any IDE that supports .NET 6 development will work, but two options are recent versions of &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio&lt;/a&gt; (at least 2022) and &lt;a href="https://code.visualstudio.com/Download"&gt;Visual Studio Code&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jellyfin/jellyfin-ffmpeg"&gt;ffmpeg&lt;/a&gt; will also need to be installed.&lt;/p&gt; 
&lt;h3&gt;Cloning the Repository&lt;/h3&gt; 
&lt;p&gt;After dependencies have been installed you will need to clone a local copy of this repository. If you just want to run the server from source you can clone this repository directly, but if you are intending to contribute code changes to the project, you should &lt;a href="https://jellyfin.org/docs/general/contributing/development.html#set-up-your-copy-of-the-repo"&gt;set up your own fork&lt;/a&gt; of the repository. The following example shows how you can clone the repository directly over HTTPS.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jellyfin/jellyfin.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing the Web Client&lt;/h3&gt; 
&lt;p&gt;The server is configured to host the static files required for the &lt;a href="https://github.com/jellyfin/jellyfin-web"&gt;web client&lt;/a&gt; in addition to serving the backend by default. Before you can run the server, you will need to get a copy of the web client since they are not included in this repository directly.&lt;/p&gt; 
&lt;p&gt;Note that it is also possible to &lt;a href="https://raw.githubusercontent.com/jellyfin/jellyfin/master/#hosting-the-web-client-separately"&gt;host the web client separately&lt;/a&gt; from the web server with some additional configuration, in which case you can skip this step.&lt;/p&gt; 
&lt;p&gt;There are three options to get the files for the web client.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download one of the finished builds from the &lt;a href="https://dev.azure.com/jellyfin-project/jellyfin/_build?definitionId=27"&gt;Azure DevOps pipeline&lt;/a&gt;. You can download the build for a specific release by looking at the &lt;a href="https://dev.azure.com/jellyfin-project/jellyfin/_build?definitionId=27&amp;amp;_a=summary&amp;amp;repositoryFilter=6&amp;amp;view=branches"&gt;branches tab&lt;/a&gt; of the pipelines page.&lt;/li&gt; 
 &lt;li&gt;Build them from source following the instructions on the &lt;a href="https://github.com/jellyfin/jellyfin-web"&gt;jellyfin-web repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Get the pre-built files from an existing installation of the server. For example, with a Windows server installation the client files are located at &lt;code&gt;C:\Program Files\Jellyfin\Server\jellyfin-web&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Running The Server&lt;/h3&gt; 
&lt;p&gt;The following instructions will help you get the project up and running via the command line, or your preferred IDE.&lt;/p&gt; 
&lt;h4&gt;Running With Visual Studio&lt;/h4&gt; 
&lt;p&gt;To run the project with Visual Studio you can open the Solution (&lt;code&gt;.sln&lt;/code&gt;) file and then press &lt;code&gt;F5&lt;/code&gt; to run the server.&lt;/p&gt; 
&lt;h4&gt;Running With Visual Studio Code&lt;/h4&gt; 
&lt;p&gt;To run the project with Visual Studio Code you will first need to open the repository directory with Visual Studio Code using the &lt;code&gt;Open Folder...&lt;/code&gt; option.&lt;/p&gt; 
&lt;p&gt;Second, you need to &lt;a href="https://code.visualstudio.com/docs/editor/extension-gallery#_recommended-extensions"&gt;install the recommended extensions for the workspace&lt;/a&gt;. Note that extension recommendations are classified as either "Workspace Recommendations" or "Other Recommendations", but only the "Workspace Recommendations" are required.&lt;/p&gt; 
&lt;p&gt;After the required extensions are installed, you can run the server by pressing &lt;code&gt;F5&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Running From the Command Line&lt;/h4&gt; 
&lt;p&gt;To run the server from the command line you can use the &lt;code&gt;dotnet run&lt;/code&gt; command. The example below shows how to do this if you have cloned the repository into a directory named &lt;code&gt;jellyfin&lt;/code&gt; (the default directory name) and should work on all operating systems.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd jellyfin                          # Move into the repository directory
dotnet run --project Jellyfin.Server --webdir /absolute/path/to/jellyfin-web/dist # Run the server startup project
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A second option is to build the project and then run the resulting executable file directly. When running the executable directly you can easily add command line options. Add the &lt;code&gt;--help&lt;/code&gt; flag to list details on all the supported command line options.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dotnet build                       # Build the project
cd Jellyfin.Server/bin/Debug/net9.0 # Change into the build output directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Execute the build output. On Linux, Mac, etc. use &lt;code&gt;./jellyfin&lt;/code&gt; and on Windows use &lt;code&gt;jellyfin.exe&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Accessing the Hosted Web Client&lt;/h4&gt; 
&lt;p&gt;If the Server is configured to host the Web Client, and the Server is running, the Web Client can be accessed at &lt;code&gt;http://localhost:8096&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;API documentation can be viewed at &lt;code&gt;http://localhost:8096/api-docs/swagger/index.html&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Running from GitHub Codespaces&lt;/h3&gt; 
&lt;p&gt;As Jellyfin will run on a container on a GitHub hosted server, JF needs to handle some things differently.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Depending on the selected configuration (if you just click 'create codespace' it will create a default configuration one) it might take 20-30 seconds to load all extensions and prepare the environment while VS Code is already open. Just give it some time and wait until you see &lt;code&gt;Downloading .NET version(s) 7.0.15~x64 ...... Done!&lt;/code&gt; in the output tab.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you want to access the JF instance from outside, like with a WebClient on another PC, remember to set the "ports" in the lower VS Code window to public.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; When first opening the server instance with any WebUI, you will be sent to the login instead of the setup page. Refresh the login page once and you should be redirected to the Setup.&lt;/p&gt; 
&lt;p&gt;There are two configurations for you to choose from.&lt;/p&gt; 
&lt;h4&gt;Default - Development Jellyfin Server&lt;/h4&gt; 
&lt;p&gt;This creates a container that has everything to run and debug the Jellyfin Media server but does not setup anything else. Each time you create a new container you have to run through the whole setup again. There is also no ffmpeg, webclient or media preloaded. Use the &lt;code&gt;.NET Launch (nowebclient)&lt;/code&gt; launch config to start the server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Keep in mind that as this has no web client you have to connect to it via an external client. This can be just another codespace container running the WebUI. vuejs does not work from the get-go as it does not support the setup steps.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Development Jellyfin Server ffmpeg&lt;/h4&gt; 
&lt;p&gt;this extends the default server with a default installation of ffmpeg6 though the means described here: &lt;a href="https://jellyfin.org/docs/general/installation/linux#repository-manual"&gt;https://jellyfin.org/docs/general/installation/linux#repository-manual&lt;/a&gt; If you want to install a specific ffmpeg version, follow the comments embedded in the &lt;code&gt;.devcontainer/Dev - Server Ffmpeg/install.ffmpeg.sh&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;Use the &lt;code&gt;ghcs .NET Launch (nowebclient, ffmpeg)&lt;/code&gt; launch config to run with the jellyfin-ffmpeg enabled.&lt;/p&gt; 
&lt;h3&gt;Running The Tests&lt;/h3&gt; 
&lt;p&gt;This repository also includes unit tests that are used to validate functionality as part of a CI pipeline on Azure. There are several ways to run these tests.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run tests from the command line using &lt;code&gt;dotnet test&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run tests in Visual Studio using the &lt;a href="https://docs.microsoft.com/en-us/visualstudio/test/run-unit-tests-with-test-explorer"&gt;Test Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run individual tests in Visual Studio Code using the associated &lt;a href="https://github.com/OmniSharp/omnisharp-vscode/wiki/How-to-run-and-debug-unit-tests"&gt;CodeLens annotation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;The following sections describe some more advanced scenarios for running the server from source that build upon the standard instructions above.&lt;/p&gt; 
&lt;h4&gt;Hosting The Web Client Separately&lt;/h4&gt; 
&lt;p&gt;It is not necessary to host the frontend web client as part of the backend server. Hosting these two components separately may be useful for frontend developers who would prefer to host the client in a separate webpack development server for a tighter development loop. See the &lt;a href="https://github.com/jellyfin/jellyfin-web#getting-started"&gt;jellyfin-web&lt;/a&gt; repo for instructions on how to do this.&lt;/p&gt; 
&lt;p&gt;To instruct the server not to host the web content, there is a &lt;code&gt;nowebclient&lt;/code&gt; configuration flag that must be set. This can be specified using the command line switch &lt;code&gt;--nowebclient&lt;/code&gt; or the environment variable &lt;code&gt;JELLYFIN_NOWEBCONTENT=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Since this is a common scenario, there is also a separate launch profile defined for Visual Studio called &lt;code&gt;Jellyfin.Server (nowebcontent)&lt;/code&gt; that can be selected from the 'Start Debugging' dropdown in the main toolbar.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The setup wizard cannot be run if the web client is hosted separately.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; This project is supported by: &lt;br&gt; &lt;br&gt; &lt;a href="https://www.digitalocean.com"&gt;&lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg?sanitize=true" height="50px" alt="DigitalOcean"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.jetbrains.com"&gt;&lt;img src="https://gist.githubusercontent.com/anthonylavado/e8b2403deee9581e0b4cb8cd675af7db/raw/fa104b7d73f759d7262794b94569f1b89df41c0b/jetbrains.svg?sanitize=true" height="50px" alt="JetBrains logo"&gt;&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dyad-sh/dyad</title>
      <link>https://github.com/dyad-sh/dyad</link>
      <description>&lt;p&gt;Free, local, open-source AI app builder | v0 / lovable / Bolt alternative | 🌟 Star if you like it!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dyad&lt;/h1&gt; 
&lt;p&gt;Dyad is a local, open-source AI app builder. It's fast, private and fully under your control — like Lovable, v0, or Bolt, but running right on your machine.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/f6c83dfc-6ffd-4d32-93dd-4b9c46d17790" alt="Image"&gt;&lt;/p&gt; 
&lt;p&gt;More info at: &lt;a href="http://dyad.sh/"&gt;http://dyad.sh/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡️ &lt;strong&gt;Local&lt;/strong&gt;: Fast, private and no lock-in.&lt;/li&gt; 
 &lt;li&gt;🛠 &lt;strong&gt;Bring your own keys&lt;/strong&gt;: Use your own AI API keys with no vendor lock-in.&lt;/li&gt; 
 &lt;li&gt;🖥️ &lt;strong&gt;Cross-platform&lt;/strong&gt;: Easy to run on Mac or Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📦 Download&lt;/h2&gt; 
&lt;p&gt;No sign-up required. Just download and go.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.dyad.sh/#download"&gt;👉 Download for your platform&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;dyad&lt;/strong&gt; is open source (Apache 2.0-licensed).&lt;/p&gt; 
&lt;p&gt;If you're interested in contributing to dyad, please read our &lt;a href="https://raw.githubusercontent.com/dyad-sh/dyad/main/CONTRIBUTING.md"&gt;contributing&lt;/a&gt; doc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rasbt/LLMs-from-scratch</title>
      <link>https://github.com/rasbt/LLMs-from-scratch</link>
      <description>&lt;p&gt;Implement a ChatGPT-like LLM in PyTorch from scratch, step by step&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Build a Large Language Model (From Scratch)&lt;/h1&gt; 
&lt;p&gt;This repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book &lt;a href="https://amzn.to/4fqvn0D"&gt;Build a Large Language Model (From Scratch)&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://amzn.to/4fqvn0D"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123" width="250px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;In &lt;a href="http://mng.bz/orYv"&gt;&lt;em&gt;Build a Large Language Model (From Scratch)&lt;/em&gt;&lt;/a&gt;, you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.&lt;/p&gt; 
&lt;p&gt;The method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Link to the official &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;source code repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mng.bz/orYv"&gt;Link to the book at Manning (the publisher's website)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/1633437167"&gt;Link to the book page on Amazon.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ISBN 9781633437166&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="http://mng.bz/orYv#reviews"&gt;&lt;img src="https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png" width="220px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;To download a copy of this repository, click on the &lt;a href="https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip"&gt;Download ZIP&lt;/a&gt; button or execute the following command in your terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;br&gt; 
&lt;p&gt;(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; for the latest updates.)&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;p&gt;Please note that this &lt;code&gt;README.md&lt;/code&gt; file is a Markdown (&lt;code&gt;.md&lt;/code&gt;) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, &lt;a href="https://ghostwriter.kde.org"&gt;Ghostwriter&lt;/a&gt; is a good free option.&lt;/p&gt; 
&lt;p&gt;You can alternatively view this and other files on GitHub at &lt;a href="https://github.com/rasbt/LLMs-from-scratch"&gt;https://github.com/rasbt/LLMs-from-scratch&lt;/a&gt; in your browser, which renders Markdown automatically.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip:&lt;/strong&gt; If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md"&gt;README.md&lt;/a&gt; file located in the &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup"&gt;setup&lt;/a&gt; directory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg?sanitize=true" alt="Code tests Linux"&gt;&lt;/a&gt; &lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg?sanitize=true" alt="Code tests Windows"&gt;&lt;/a&gt; &lt;a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml"&gt;&lt;img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg?sanitize=true" alt="Code tests macOS"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chapter Title&lt;/th&gt; 
   &lt;th&gt;Main Code (for Quick Access)&lt;/th&gt; 
   &lt;th&gt;All Code + Supplementary&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup"&gt;Setup recommendations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 1: Understanding Large Language Models&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 2: Working with Text Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/ch02.ipynb"&gt;ch02.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/dataloader.ipynb"&gt;dataloader.ipynb&lt;/a&gt; (summary)&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02"&gt;./ch02&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 3: Coding Attention Mechanisms&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/ch03.ipynb"&gt;ch03.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/multihead-attention.ipynb"&gt;multihead-attention.ipynb&lt;/a&gt; (summary) &lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03"&gt;./ch03&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 4: Implementing a GPT Model from Scratch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/ch04.ipynb"&gt;ch04.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/gpt.py"&gt;gpt.py&lt;/a&gt; (summary)&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04"&gt;./ch04&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 5: Pretraining on Unlabeled Data&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/ch05.ipynb"&gt;ch05.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_train.py"&gt;gpt_train.py&lt;/a&gt; (summary) &lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_generate.py"&gt;gpt_generate.py&lt;/a&gt; (summary) &lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05"&gt;./ch05&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 6: Finetuning for Text Classification&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/ch06.ipynb"&gt;ch06.ipynb&lt;/a&gt; &lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/gpt_class_finetune.py"&gt;gpt_class_finetune.py&lt;/a&gt; &lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06"&gt;./ch06&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ch 7: Finetuning to Follow Instructions&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ch07.ipynb"&gt;ch07.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py"&gt;gpt_instruction_finetuning.py&lt;/a&gt; (summary)&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ollama_evaluate.py"&gt;ollama_evaluate.py&lt;/a&gt; (summary)&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07"&gt;./ch07&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix A: Introduction to PyTorch&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part1.ipynb"&gt;code-part1.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part2.ipynb"&gt;code-part2.ipynb&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/DDP-script.py"&gt;DDP-script.py&lt;/a&gt;&lt;br&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/exercise-solutions.ipynb"&gt;exercise-solutions.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A"&gt;./appendix-A&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix B: References and Further Reading&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix C: Exercise Solutions&lt;/td&gt; 
   &lt;td&gt;No code&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix D: Adding Bells and Whistles to the Training Loop&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D/01_main-chapter-code/appendix-D.ipynb"&gt;appendix-D.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D"&gt;./appendix-D&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Appendix E: Parameter-efficient Finetuning with LoRA&lt;/td&gt; 
   &lt;td&gt;- &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E/01_main-chapter-code/appendix-E.ipynb"&gt;appendix-E.ipynb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E"&gt;./appendix-E&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br&gt; &amp;nbsp; 
&lt;p&gt;The mental model below summarizes the contents covered in this book.&lt;/p&gt; 
&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg" width="650px"&gt; 
&lt;br&gt; &amp;nbsp; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;The most important prerequisite is a strong foundation in Python programming. With this knowledge, you will be well prepared to explore the fascinating world of LLMs and understand the concepts and code examples presented in this book.&lt;/p&gt; 
&lt;p&gt;If you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.&lt;/p&gt; 
&lt;p&gt;This book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, &lt;a href="https://sebastianraschka.com/teaching/pytorch-1h/"&gt;PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs&lt;/a&gt;, helpful for learning about the essentials.&lt;/p&gt; 
&lt;br&gt; &amp;nbsp; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;p&gt;The code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the &lt;a href="https://github.com/rasbt/LLMs-from-scratch/raw/main/setup/README.md"&gt;setup&lt;/a&gt; doc for additional recommendations.)&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Video Course&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/livevideo/master-and-build-large-language-models"&gt;A 17-hour and 15-minute companion video course&lt;/a&gt; where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/livevideo/master-and-build-large-language-models"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123" width="350px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Exercises&lt;/h2&gt; 
&lt;p&gt;Each chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example, &lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb"&gt;./ch02/01_main-chapter-code/exercise-solutions.ipynb&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to the code exercises, you can download a free 170-page PDF titled &lt;a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"&gt;Test Yourself On Build a Large Language Model (From Scratch)&lt;/a&gt; from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"&gt;&lt;img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123" width="150px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Bonus Material&lt;/h2&gt; 
&lt;p&gt;Several folders contain optional materials as a bonus for interested readers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Setup&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/01_optional-python-setup-preferences"&gt;Python Setup Tips&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/02_installing-python-libraries"&gt;Installing Python Packages and Libraries Used In This Book&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/03_optional-docker-environment"&gt;Docker Environment Setup Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 2: Working with text data&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb"&gt;Byte Pair Encoding (BPE) Tokenizer From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/02_bonus_bytepair-encoder"&gt;Comparing Various Byte Pair Encoding (BPE) Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/03_bonus_embedding-vs-matmul"&gt;Understanding the Difference Between Embedding Layers and Linear Layers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/04_bonus_dataloader-intuition"&gt;Dataloader Intuition with Simple Numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 3: Coding attention mechanisms&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb"&gt;Comparing Efficient Multi-Head Attention Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/03_understanding-buffers/understanding-buffers.ipynb"&gt;Understanding PyTorch Buffers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 4: Implementing a GPT model from scratch&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/02_performance-analysis/flops-analysis.ipynb"&gt;FLOPS Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/03_kv-cache"&gt;KV Cache&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 5: Pretraining on unlabeled data:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/02_alternative_weight_loading/"&gt;Alternative Weight Loading Methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/03_bonus_pretraining_on_gutenberg"&gt;Pretraining GPT on the Project Gutenberg Dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/04_learning_rate_schedulers"&gt;Adding Bells and Whistles to the Training Loop&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/05_bonus_hparam_tuning"&gt;Optimizing Hyperparameters for Pretraining&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/06_user_interface"&gt;Building a User Interface to Interact With the Pretrained LLM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama"&gt;Converting GPT to Llama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama/standalone-llama32.ipynb"&gt;Llama 3.2 From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/11_qwen3/"&gt;Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb"&gt;Memory-efficient Model Weight Loading&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/09_extending-tokenizers/extend-tiktoken.ipynb"&gt;Extending the Tiktoken BPE Tokenizer with New Tokens&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/10_llm-training-speed"&gt;PyTorch Performance Tips for Faster LLM Training&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 6: Finetuning for classification&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/02_bonus_additional-experiments"&gt;Additional experiments finetuning different layers and using larger models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/03_bonus_imdb-classification"&gt;Finetuning different models on 50k IMDB movie review dataset&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/04_user_interface"&gt;Building a User Interface to Interact With the GPT-based Spam Classifier&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chapter 7: Finetuning to follow instructions&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/02_dataset-utilities"&gt;Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/03_model-evaluation"&gt;Evaluating Instruction Responses Using the OpenAI API and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/llama3-ollama.ipynb"&gt;Generating a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/reflection-gpt4.ipynb"&gt;Improving a Dataset for Instruction Finetuning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb"&gt;Generating a Preference Dataset with Llama 3.1 70B and Ollama&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb"&gt;Direct Preference Optimization (DPO) for LLM Alignment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/06_user_interface"&gt;Building a User Interface to Interact With the Instruction Finetuned GPT Model&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; &amp;nbsp; 
&lt;h2&gt;Questions, Feedback, and Contributing to This Repository&lt;/h2&gt; 
&lt;p&gt;I welcome all sorts of feedback, best shared via the &lt;a href="https://livebook.manning.com/forum?product=raschka&amp;amp;page=1"&gt;Manning Forum&lt;/a&gt; or &lt;a href="https://github.com/rasbt/LLMs-from-scratch/discussions"&gt;GitHub Discussions&lt;/a&gt;. Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.&lt;/p&gt; 
&lt;p&gt;Please note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this book or code useful for your research, please consider citing it.&lt;/p&gt; 
&lt;p&gt;Chicago-style citation:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Raschka, Sebastian. &lt;em&gt;Build A Large Language Model (From Scratch)&lt;/em&gt;. Manning, 2024. ISBN: 978-1633437166.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;BibTeX entry:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>MotiaDev/motia</title>
      <link>https://github.com/MotiaDev/motia</link>
      <description>&lt;p&gt;Modern Backend Framework that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system with built-in observability and state management.&lt;/p&gt;&lt;hr&gt;&lt;a href="https://motia.dev"&gt; &lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/packages/docs/public/github-readme-banner.png" alt="Motia Banner" width="100%"&gt; &lt;/a&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14032"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/14032" alt="Motia" style="width: 250px; height: 55px;" width="250" height="55"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;🔥 A Modern Unified Backend Framework for APIs, background jobs, workflows, and Agents 🔥&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/motia"&gt; &lt;img src="https://img.shields.io/npm/v/motia?style=flat&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;color=CB3837&amp;amp;labelColor=000000" alt="npm version"&gt; &lt;/a&gt; &lt;a href="https://github.com/MotiaDev/motia/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-MIT-green?style=flat&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white&amp;amp;labelColor=000000" alt="license"&gt; &lt;/a&gt; &lt;a href="https://github.com/MotiaDev/motia"&gt; &lt;img src="https://img.shields.io/github/stars/MotiaDev/motia?style=flat&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;color=yellow&amp;amp;labelColor=000000" alt="GitHub stars"&gt; &lt;/a&gt; &lt;a href="https://twitter.com/motiadev" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Follow-@motiadev-1DA1F2?style=flat&amp;amp;logo=twitter&amp;amp;logoColor=white&amp;amp;labelColor=000000" alt="Twitter Follow"&gt; &lt;/a&gt; &lt;a href="https://discord.com/invite/nJFfsH5d6v" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1322278831184281721?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=5865F2&amp;amp;label=Discord&amp;amp;labelColor=000000" alt="Discord"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.motia.dev/manifesto"&gt;💡 Motia Manifesto&lt;/a&gt; • &lt;a href="https://www.motia.dev/docs/getting-started/quick-start"&gt;🚀 Quick Start&lt;/a&gt; • &lt;a href="https://www.motia.dev/docs/concepts/steps/defining-steps"&gt;📋 Defining Steps&lt;/a&gt; • &lt;a href="https://motia.dev/docs"&gt;📚 Docs&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;🎯 What is Motia?&lt;/h2&gt; 
&lt;p&gt;Motia is a &lt;strong&gt;modern backend framework&lt;/strong&gt; that unifies APIs, background jobs, workflows, and AI agents into a single cohesive system. Eliminate runtime complexity and build unified backends where &lt;strong&gt;JavaScript, TypeScript, Python, etc&lt;/strong&gt;, work together in event-driven workflows, with built-in state management, observability, and one-click deployments.&lt;/p&gt; 
&lt;p&gt;Motia brings cohesion to the fragmented backend world with our core primitive: the &lt;strong&gt;Step&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://motia.dev"&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/Motia_Github_Repository_GIF.gif" alt="Motia combines APIs, background queues, and AI agents into one system"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Quickstart&lt;/h2&gt; 
&lt;p&gt;Get Motia project up and running in &lt;strong&gt;under 60 seconds&lt;/strong&gt;:&lt;/p&gt; 
&lt;h3&gt;1. Bootstrap a New Motia Project&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx motia@latest create -i   # runs the interactive terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the prompts to pick a template, project name, and language.&lt;/p&gt; 
&lt;h3&gt;2. Start the Workbench&lt;/h3&gt; 
&lt;p&gt;Inside your new project folder, launch the dev server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx motia dev # ➜ http://localhost:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This spins up the Motia Workbench – a local UI for building, testing &amp;amp; observing your backend in real-time.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/motia-terminal.gif" alt="motia-terminal"&gt;&lt;/p&gt; 
&lt;h3&gt;3. Hit Your First Endpoint&lt;/h3&gt; 
&lt;p&gt;Open a new terminal tab and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl http://localhost:3000/default
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see the JSON response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{ "message": "Hello World from Motia!" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Explore the Workbench UI&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/new-workbench.png" alt="new-workbench"&gt; The Workbench is your command centre:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🌊 Flows&lt;/strong&gt; – Visualise how your Steps connect.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔌 Endpoints&lt;/strong&gt; – Test APIs with one click and stream results live.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;👁️ Traces&lt;/strong&gt; – Inspect end-to-end traces of every execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📊 Logs&lt;/strong&gt; – View structured logs grouped by trace.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🏪 State&lt;/strong&gt; – Inspect the key-value store across Steps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;p&gt;🎉 &lt;strong&gt;That's it!&lt;/strong&gt; You now have a fully-featured Motia project with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;code&gt;/default&lt;/code&gt; API endpoint&lt;/li&gt; 
 &lt;li&gt;✅ Visual debugger &amp;amp; flow inspector&lt;/li&gt; 
 &lt;li&gt;✅ Built-in observability&lt;/li&gt; 
 &lt;li&gt;✅ Hot-reload for instant feedback&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;🧱 The Step Philosophy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 Your Logic, Your Step&lt;/strong&gt;: A Step holds your business logic. It can be a simple function, a call to a database, or a complex AI agent. This is where your application's real work gets done.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌍 Any Language, One Workflow&lt;/strong&gt;: Write Steps in TypeScript, Python, and other languages to come. all in the same project. Use Python for your AI agents and TypeScript for your API, and Motia makes them work together effortlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Full Power, No Boilerplate&lt;/strong&gt;: Inside a Step's &lt;code&gt;handler&lt;/code&gt;, you have the full power of the Node.js or Python ecosystem. Install any package, call any API, connect to any database. No restrictions, just your code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;👁️ Zero-Config Observability&lt;/strong&gt;: Get full end-to-end tracing and logging for every Step execution, automatically. No setup required. See exactly what happened, when, and why.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌊 Simple &amp;amp; Powerful Workflows&lt;/strong&gt;: Connect Steps together by emitting and subscribing to events. Build complex, multi-stage processes with simple, declarative code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🏪 Unified State&lt;/strong&gt;: Share data between Steps effortlessly. Motia provides built-in state management that is automatically traced, giving you a complete picture of your data's lifecycle through a workflow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚧 The Problem&lt;/h2&gt; 
&lt;p&gt;Backend teams juggle &lt;strong&gt;fragmented runtimes&lt;/strong&gt; across APIs, background queues, and AI agents. This creates deployment complexity, debugging gaps, and cognitive overhead from context-switching between frameworks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This fragmentation demands a unified system.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;✅ The Unified System&lt;/h2&gt; 
&lt;p&gt;Motia unifies your entire backend into a &lt;strong&gt;unified state&lt;/strong&gt;. APIs, background jobs, and AI agents become interconnected Steps with shared state and integrated observability.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Before&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;After (Motia)&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multiple deployment targets&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Single unified deployment&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fragmented observability&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;End-to-end tracing&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language dependent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;JavaScript, TypeScript, Python, etc&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Context-switching overhead&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Single intuitive model&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Complex error handling&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Automatic retries &amp;amp; fault tolerance&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;🔧 Supported Step Types&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Trigger&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;api&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HTTP Request&lt;/td&gt; 
   &lt;td&gt;Expose REST endpoints&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;event&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Emitted Topics&lt;/td&gt; 
   &lt;td&gt;React to internal or external events&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;cron&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Scheduled Time (cron)&lt;/td&gt; 
   &lt;td&gt;Automate recurring jobs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;noop&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
   &lt;td&gt;Placeholder for manual/external tasks&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h3&gt;🤔 How it Works&lt;/h3&gt; 
&lt;p&gt;Motia's architecture is built around a single, powerful primitive: the &lt;strong&gt;Step&lt;/strong&gt;. A Step is not just a trigger; it's a powerful container for your business logic. You can write anything from a simple database query to a complex AI agent interaction inside a single step. Instead of managing separate services for APIs, background workers, and scheduled tasks, you simply define how your steps are triggered.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need a public API?&lt;/strong&gt; Create an &lt;code&gt;api&lt;/code&gt; step. This defines a route and handler for HTTP requests. You can build a complete REST or GraphQL API just with these steps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need a background job or queue?&lt;/strong&gt; Have your &lt;code&gt;api&lt;/code&gt; step &lt;code&gt;emit&lt;/code&gt; an event. An &lt;code&gt;event&lt;/code&gt; step subscribed to that event's topic will pick up the job and process it asynchronously. This is how you handle anything that shouldn't block the main request thread, from sending emails to complex data processing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need to run a task on a schedule?&lt;/strong&gt; Use a &lt;code&gt;cron&lt;/code&gt; step. It will trigger automatically based on the schedule you define.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This model means you no longer need to glue together separate frameworks and tools. A single Motia application can replace a stack that might otherwise include &lt;strong&gt;Nest.js&lt;/strong&gt; (for APIs), &lt;strong&gt;Temporal&lt;/strong&gt; (for workflows), and &lt;strong&gt;Celery/BullMQ&lt;/strong&gt; (for background jobs). It's all just steps and events.&lt;/p&gt; 
&lt;h2&gt;⚡ Core Concepts&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;Step&lt;/strong&gt; is Motia's core primitive. The following concepts are deeply integrated with Steps to help you build powerful, complex, and scalable backends:&lt;/p&gt; 
&lt;h3&gt;🔑 Steps &amp;amp; Step Types&lt;/h3&gt; 
&lt;p&gt;Understand the three ways Steps are triggered:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP (&lt;code&gt;api&lt;/code&gt;)&lt;/strong&gt; – Build REST/GraphQL endpoints with zero boilerplate.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Events (&lt;code&gt;event&lt;/code&gt;)&lt;/strong&gt; – React to internal or external events emitted by other steps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cron (&lt;code&gt;cron&lt;/code&gt;)&lt;/strong&gt; – Schedule recurring jobs with a familiar cron syntax.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📣 Emit &amp;amp; Subscribe (Event-Driven Workflows)&lt;/h3&gt; 
&lt;p&gt;Steps talk to each other by &lt;strong&gt;emitting&lt;/strong&gt; and &lt;strong&gt;subscribing&lt;/strong&gt; to topics. This decouples producers from consumers and lets you compose complex workflows with simple, declarative code.&lt;/p&gt; 
&lt;h3&gt;🏪 State Management&lt;/h3&gt; 
&lt;p&gt;All steps share a unified key-value state store. Every &lt;code&gt;get&lt;/code&gt;, &lt;code&gt;set&lt;/code&gt;, and &lt;code&gt;delete&lt;/code&gt; is automatically traced so you always know when and where your data changed.&lt;/p&gt; 
&lt;h3&gt;📊 Structured Logging&lt;/h3&gt; 
&lt;p&gt;Motia provides structured, JSON logs correlated with trace IDs and step names. Search and filter your logs without regex hassle.&lt;/p&gt; 
&lt;h3&gt;📡 Streams: Real-time Messaging&lt;/h3&gt; 
&lt;p&gt;Push live updates from long-running or asynchronous workflows to clients without polling. Perfect for dashboards, progress indicators, and interactive AI agents.&lt;/p&gt; 
&lt;h3&gt;👁️ End-to-End Observability with Traces&lt;/h3&gt; 
&lt;p&gt;Every execution generates a full trace, capturing step timelines, state operations, emits, stream calls, and logs. Visualise everything in the Workbench's Traces UI and debug faster.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;🗂 Examples&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent"&gt;Finance Agent&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow"&gt;GitHub Agent&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-workflow"&gt;Gmail Manager&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/finance-agent.png" alt="Finance"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/github-pr-management.png" alt="GitHub"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/gmail-flow.png" alt="Gmail"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow"&gt;Trello Automation&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag_example"&gt;RAG Agent&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/MotiaDev/motia-examples/tree/main/examples/vision-example"&gt;AI Image Gen&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/trello-manager.png" alt="Trello"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/parse-embed-rag.png" alt="RAG"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/MotiaDev/motia/main/assets/examples/generate-image.png" alt="AI Image"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;🌐 Language Support&lt;/h2&gt; 
&lt;p&gt;Write steps in your preferred language:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Stable&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.js&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TypeScript&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Stable&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.ts&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Stable&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.py&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ruby&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;🚧 Beta&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.rb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Go&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;🔄 Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.go&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Rust&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;🔄 Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;handler.step.rs&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h3&gt;💬 &lt;strong&gt;Get Help&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;📋 Questions&lt;/strong&gt;: Use our &lt;a href="https://discord.gg/7rXsekMK"&gt;Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🐛 Bug Reports&lt;/strong&gt;: &lt;a href="https://github.com/MotiaDev/motia/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📖 Documentation&lt;/strong&gt;: &lt;a href="https://motia.dev/docs"&gt;Official Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎥 Blog&lt;/strong&gt;: &lt;a href="https://dev.to/motiadev"&gt;Motia Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🤝 &lt;strong&gt;Contributing&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! Whether it's:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 Bug fixes and improvements&lt;/li&gt; 
 &lt;li&gt;✨ New features and step types&lt;/li&gt; 
 &lt;li&gt;📚 Documentation and examples&lt;/li&gt; 
 &lt;li&gt;🌍 Language support additions&lt;/li&gt; 
 &lt;li&gt;🎨 Workbench UI enhancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our &lt;a href="https://github.com/MotiaDev/motia/raw/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;🌟 Ready to unify your backend?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://motia.dev"&gt;🚀 &lt;strong&gt;Get Started Now&lt;/strong&gt;&lt;/a&gt; • &lt;a href="https://motia.dev/docs"&gt;📖 &lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt; • &lt;a href="https://discord.com/invite/nJFfsH5d6v"&gt;💬 &lt;strong&gt;Join Discord&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#motiadev/motia&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=motiadev/motia&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;sub&gt;Built with ❤️ by the Motia team • &lt;strong&gt;Star us if you find &lt;a href="https://github.com/orgs/MotiaDev/motia"&gt;Motia&lt;/a&gt; useful!&lt;/strong&gt; ⭐&lt;/sub&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;🚧 Roadmap&lt;/h3&gt; 
&lt;p&gt;We have a public roadmap for Motia, you can view it &lt;a href="https://github.com/orgs/MotiaDev/projects/2/views/4"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Feel free to add comments to the issues, or create a new issue if you have a feature request.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python Types&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/485"&gt;#485&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Python types&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Streams: RBAC&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/495"&gt;#495&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for RBAC&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Streams: Workbench UI&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/497"&gt;#497&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Workbench UI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Queue Strategies&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/476"&gt;#476&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Queue Strategies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Reactive Steps&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/477"&gt;#477&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Reactive Steps&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Allow cloud configuration&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/478"&gt;#478&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for cloud configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Bring your own Cloud: AWS&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/479"&gt;#479&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for AWS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Point in time triggers&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/480"&gt;#480&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Point in time triggers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Workbench plugins&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/481"&gt;#481&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Workbench plugins&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rewrite our Core in either Go or Rust&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/482"&gt;#482&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Rewrite our Core in either Go or Rust&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Decrease deployment time&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/483"&gt;#483&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Decrease deployment time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Built-in database support&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/484"&gt;#484&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for built-in database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Google Cloud Platform&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/486"&gt;#486&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Google Cloud Platform&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Microsoft Azure&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/487"&gt;#487&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Microsoft Azure&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Vercel&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/488"&gt;#488&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Vercel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Cloudflare&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/489"&gt;#489&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Cloudflare&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New languages: Go&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/490"&gt;#490&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Go&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New languages: Rust&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/491"&gt;#491&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Rust&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New languages: Java&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/492"&gt;#492&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Java&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New languages: Ruby&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/493"&gt;#493&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Ruby&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New languages: C#&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/494"&gt;#494&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for C#&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BYOC: Kubernetes&lt;/td&gt; 
   &lt;td&gt;Planned&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/MotiaDev/motia/issues/496"&gt;#496&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add support for Kubernetes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>reflex-dev/reflex</title>
      <link>https://github.com/reflex-dev/reflex</link>
      <description>&lt;p&gt;🕸️ Web apps in pure Python 🐍&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex.svg?sanitize=true" alt="Reflex Logo" width="300px"&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;&lt;strong&gt;✨ Performant, customizable web apps in pure Python. Deploy in seconds. ✨&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/reflex"&gt;&lt;img src="https://badge.fury.io/py/reflex.svg?sanitize=true" alt="PyPI version"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/reflex.svg?sanitize=true" alt="versions"&gt; &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;&lt;img src="https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/reflex"&gt;&lt;img src="https://static.pepy.tech/badge/reflex" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;&lt;img src="https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/reflex-dev/reflex/raw/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_cn/README.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_tw/README.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/tr/README.md"&gt;Türkçe&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/in/README.md"&gt;हिंदी&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pt/pt_br/README.md"&gt;Português (Brasil)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/it/README.md"&gt;Italiano&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/es/README.md"&gt;Español&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/kr/README.md"&gt;한국어&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/ja/README.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/de/README.md"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pe/README.md"&gt;Persian (پارسی)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/vi/README.md"&gt;Tiếng Việt&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 🚀 &lt;strong&gt;Try &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt;&lt;/strong&gt; – our AI-powered app builder that generates full-stack Reflex applications in seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;Reflex is a library to build full-stack web apps in pure Python.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pure Python&lt;/strong&gt; - Write your app's frontend and backend all in Python, no need to learn Javascript.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Flexibility&lt;/strong&gt; - Reflex is easy to get started with, but can also scale to complex apps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy Instantly&lt;/strong&gt; - After building, deploy your app with a &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start/"&gt;single command&lt;/a&gt; or host it on your own server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture"&gt;architecture page&lt;/a&gt; to learn how Reflex works under the hood.&lt;/p&gt; 
&lt;h2&gt;⚙️ Installation&lt;/h2&gt; 
&lt;p&gt;Open a terminal and run (Requires Python 3.10+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install reflex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🥳 Create your first app&lt;/h2&gt; 
&lt;p&gt;Installing &lt;code&gt;reflex&lt;/code&gt; also installs the &lt;code&gt;reflex&lt;/code&gt; command line tool.&lt;/p&gt; 
&lt;p&gt;Test that the install was successful by creating a new project. (Replace &lt;code&gt;my_app_name&lt;/code&gt; with your project name):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir my_app_name
cd my_app_name
reflex init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command initializes a template app in your new directory.&lt;/p&gt; 
&lt;p&gt;You can run this app in development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;reflex run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see your app running at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Reflex has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; 
&lt;h2&gt;🫧 Example App&lt;/h2&gt; 
&lt;p&gt;Let's go over an example: creating an image generation UI around &lt;a href="https://platform.openai.com/docs/guides/images/image-generation?context=node"&gt;DALL·E&lt;/a&gt;. For simplicity, we just call the &lt;a href="https://platform.openai.com/docs/api-reference/authentication"&gt;OpenAI API&lt;/a&gt;, but you could replace this with an ML model run locally.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif" alt="A frontend wrapper for DALL·E, shown in the process of generating an image." width="550"&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    """The app state."""

    prompt = ""
    image_url = ""
    processing = False
    complete = False

    def get_image(self):
        """Get the image from the prompt."""
        if self.prompt == "":
            return rx.window_alert("Prompt Empty")

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size="1024x1024"
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading("DALL-E", font_size="1.5em"),
            rx.input(
                placeholder="Enter a prompt..",
                on_blur=State.set_prompt,
                width="25em",
            ),
            rx.button(
                "Generate Image",
                on_click=State.get_image,
                width="25em",
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width="20em"),
            ),
            align="center",
        ),
        width="100%",
        height="100vh",
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title="Reflex:DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Let's break this down.&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png" alt="Explaining the differences between backend and frontend parts of the DALL-E app." width="900"&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;Reflex UI&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Let's start with the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def index():
    return rx.center(
        ...
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; 
&lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; 
&lt;p&gt;Reflex comes with &lt;a href="https://reflex.dev/docs/library"&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, and it's easy to &lt;a href="https://reflex.dev/docs/wrapping-react/overview/"&gt;create your own components&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Reflex represents your UI as a function of your state.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class State(rx.State):
    """The app state."""
    prompt = ""
    image_url = ""
    processing = False
    complete = False

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them.&lt;/p&gt; 
&lt;p&gt;Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;processing&lt;/code&gt; and &lt;code&gt;complete&lt;/code&gt; to indicate when to disable the button (during image generation) and when to show the resulting image.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_image(self):
    """Get the image from the prompt."""
    if self.prompt == "":
        return rx.window_alert("Prompt Empty")

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size="1024x1024"
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; 
&lt;p&gt;Our DALL·E app has an event handler, &lt;code&gt;get_image&lt;/code&gt; which gets this image from the OpenAI API. Using &lt;code&gt;yield&lt;/code&gt; in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Finally, we define our app.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app = rx.App()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app.add_page(index, title="DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create a multi-page app by adding more pages.&lt;/p&gt; 
&lt;h2&gt;📑 Resources&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;📑 &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; 🗞️ &lt;a href="https://reflex.dev/blog"&gt;Blog&lt;/a&gt; &amp;nbsp; | &amp;nbsp; 📱 &lt;a href="https://reflex.dev/docs/library"&gt;Component Library&lt;/a&gt; &amp;nbsp; | &amp;nbsp; 🖼️ &lt;a href="https://reflex.dev/templates/"&gt;Templates&lt;/a&gt; &amp;nbsp; | &amp;nbsp; 🛸 &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start"&gt;Deployment&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;✅ Status&lt;/h2&gt; 
&lt;p&gt;Reflex launched in December 2022 with the name Pynecone.&lt;/p&gt; 
&lt;p&gt;🚀 Introducing &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt; — Our AI-Powered Builder Reflex Build uses AI to generate complete full-stack Python applications. It helps you quickly create, customize, and refine your Reflex apps — from frontend components to backend logic — so you can focus on your ideas instead of boilerplate code. Whether you’re prototyping or scaling, Reflex Build accelerates development by intelligently scaffolding and optimizing your app’s entire stack.&lt;/p&gt; 
&lt;p&gt;Alongside this, &lt;a href="https://cloud.reflex.dev"&gt;Reflex Cloud&lt;/a&gt; launched in 2025 to offer the best hosting experience for your Reflex apps. We’re continuously improving the platform with new features and capabilities.&lt;/p&gt; 
&lt;p&gt;Reflex has new releases and features coming every week! Make sure to &lt;span&gt;⭐&lt;/span&gt; star and &lt;span&gt;👀&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Reflex community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;Discord&lt;/a&gt; is the best place to get help on your Reflex project and to discuss how you can contribute.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/reflex-dev/reflex/issues"&gt;Issues&lt;/a&gt; are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are actively looking for contributors, no matter your skill level or experience. To contribute check out &lt;a href="https://github.com/reflex-dev/reflex/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;All Thanks To Our Contributors:&lt;/h2&gt; 
&lt;a href="https://github.com/reflex-dev/reflex/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=reflex-dev/reflex"&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Reflex is open-source and licensed under the &lt;a href="https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wg-easy/wg-easy</title>
      <link>https://github.com/wg-easy/wg-easy</link>
      <description>&lt;p&gt;The easiest way to run WireGuard VPN + Web-based Admin UI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WireGuard Easy&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/wg-easy/wg-easy/actions/workflows/deploy.yml"&gt;&lt;img src="https://github.com/wg-easy/wg-easy/actions/workflows/deploy.yml/badge.svg?branch=production" alt="Build &amp;amp; Publish latest Image"&gt;&lt;/a&gt; &lt;a href="https://github.com/wg-easy/wg-easy/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/wg-easy/wg-easy/actions/workflows/lint.yml/badge.svg?branch=master" alt="Lint"&gt;&lt;/a&gt; &lt;a href="https://github.com/wg-easy/wg-easy/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/wg-easy/wg-easy" alt="GitHub Stars"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/wg-easy/wg-easy/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/wg-easy/wg-easy" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/wg-easy/wg-easy/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/wg-easy/wg-easy" alt="GitHub Release"&gt;&lt;/a&gt; &lt;a href="https://github.com/wg-easy/wg-easy/pkgs/container/wg-easy"&gt;&lt;img src="https://img.shields.io/badge/image_pulls-12M+-blue" alt="Image Pulls"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You have found the easiest way to install &amp;amp; manage WireGuard on any Linux host!&lt;/p&gt; 
&lt;!-- TOOD: update screenshot --&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/wg-easy/wg-easy/master/assets/screenshot.png" width="802" alt="wg-easy Screenshot"&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;All-in-one: WireGuard + Web UI.&lt;/li&gt; 
 &lt;li&gt;Easy installation, simple to use.&lt;/li&gt; 
 &lt;li&gt;List, create, edit, delete, enable &amp;amp; disable clients.&lt;/li&gt; 
 &lt;li&gt;Show a client's QR code.&lt;/li&gt; 
 &lt;li&gt;Download a client's configuration file.&lt;/li&gt; 
 &lt;li&gt;Statistics for which clients are connected.&lt;/li&gt; 
 &lt;li&gt;Tx/Rx charts for each connected client.&lt;/li&gt; 
 &lt;li&gt;Gravatar support.&lt;/li&gt; 
 &lt;li&gt;Automatic Light / Dark Mode&lt;/li&gt; 
 &lt;li&gt;Multilanguage Support&lt;/li&gt; 
 &lt;li&gt;One Time Links&lt;/li&gt; 
 &lt;li&gt;Client Expiration&lt;/li&gt; 
 &lt;li&gt;Prometheus metrics support&lt;/li&gt; 
 &lt;li&gt;IPv6 support&lt;/li&gt; 
 &lt;li&gt;CIDR support&lt;/li&gt; 
 &lt;li&gt;2FA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To better manage documentation for this project, it has its own site here: &lt;a href="https://wg-easy.github.io/wg-easy/latest"&gt;https://wg-easy.github.io/wg-easy/latest&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/getting-started/"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/basic-installation/"&gt;Basic Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/caddy/"&gt;Caddy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/traefik/"&gt;Traefik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/podman-nft/"&gt;Podman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/adguard/"&gt;AdGuard Home&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you want to migrate from the old version to the new version, you can find the migration guide here: &lt;a href="https://wg-easy.github.io/wg-easy/latest/advanced/migrate/"&gt;Migration Guide&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;This is a quick start guide to get you up and running with WireGuard Easy.&lt;/p&gt; 
&lt;p&gt;For a more detailed installation guide, please refer to the &lt;a href="https://wg-easy.github.io/wg-easy/latest/getting-started/"&gt;Getting Started&lt;/a&gt; page.&lt;/p&gt; 
&lt;h3&gt;1. Install Docker&lt;/h3&gt; 
&lt;p&gt;If you haven't installed Docker yet, install it by running as root:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -sSL https://get.docker.com | sh
exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And log in again.&lt;/p&gt; 
&lt;h3&gt;2. Run WireGuard Easy&lt;/h3&gt; 
&lt;p&gt;The easiest way to run WireGuard Easy is with Docker Compose.&lt;/p&gt; 
&lt;p&gt;Just follow &lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/basic-installation/"&gt;these steps&lt;/a&gt; in the detailed documentation.&lt;/p&gt; 
&lt;p&gt;You can also install WireGuard Easy with the &lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/docker-run/"&gt;docker run command&lt;/a&gt; or via &lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/podman-nft/"&gt;podman&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now &lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/basic-installation/#setup-reverse-proxy"&gt;setup a reverse proxy&lt;/a&gt; to be able to access the Web UI securely from the internet. This step is optional, just make sure to follow the guide &lt;a href="https://wg-easy.github.io/wg-easy/latest/examples/tutorials/reverse-proxyless/"&gt;here&lt;/a&gt; if you decide not to do it.&lt;/p&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;Are you enjoying this project? Consider donating.&lt;/p&gt; 
&lt;p&gt;Founder: &lt;a href="https://github.com/sponsors/WeeJeWel"&gt;Buy Emile a beer!&lt;/a&gt; 🍻&lt;/p&gt; 
&lt;p&gt;Maintainer: &lt;a href="https://github.com/sponsors/kaaax0815"&gt;Buy kaaax0815 a coffee!&lt;/a&gt; ☕&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker&lt;/li&gt; 
 &lt;li&gt;Node LTS &amp;amp; corepack enabled&lt;/li&gt; 
 &lt;li&gt;Visual Studio Code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dev Server&lt;/h3&gt; 
&lt;p&gt;This starts the development server with docker&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Update Auto Imports&lt;/h3&gt; 
&lt;p&gt;If you add something that should be auto-importable and VSCode complains, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd src
pnpm install
cd ..
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Test Cli&lt;/h3&gt; 
&lt;p&gt;This starts the cli with docker&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm cli:dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the AGPL-3.0-only License - see the &lt;a href="https://raw.githubusercontent.com/wg-easy/wg-easy/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details&lt;/p&gt; 
&lt;p&gt;This project is not affiliated, associated, authorized, endorsed by, or in any way officially connected with Jason A. Donenfeld, ZX2C4 or Edge Security&lt;/p&gt; 
&lt;p&gt;"WireGuard" and the "WireGuard" logo are registered trademarks of Jason A. Donenfeld&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>