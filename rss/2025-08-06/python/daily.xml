<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 05 Aug 2025 01:35:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>rougier/numpy-100</title>
      <link>https://github.com/rougier/numpy-100</link>
      <description>&lt;p&gt;100 numpy exercises (with solutions)&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;100 numpy exercises&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://mybinder.org/repo/rougier/numpy-100/notebooks/100%20Numpy%20exercises.ipynb"&gt;&lt;img src="http://mybinder.org/badge.svg?sanitize=true" alt="Binder"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This is a collection of numpy exercises from numpy mailing list, stack overflow, and numpy documentation. I've also created some problems myself to reach the 100 limit. The goal of this collection is to offer a quick reference for both old and new users but also to provide a set of exercises for those who teach. For extended exercises, make sure to read &lt;a href="http://www.labri.fr/perso/nrougier/from-python-to-numpy/"&gt;From Python to NumPy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;‚Üí &lt;a href="http://mybinder.org/repo/rougier/numpy-100/notebooks/100_Numpy_exercises.ipynb"&gt;Test them on Binder&lt;/a&gt;&lt;br&gt; ‚Üí &lt;a href="https://raw.githubusercontent.com/rougier/numpy-100/master/100_Numpy_exercises.md"&gt;Read them on GitHub&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Note: markdown and ipython notebook are created programmatically from the source data in &lt;code&gt;source/exercises.ktx&lt;/code&gt;. To modify the content of these files, please change the text in the source and run the &lt;code&gt;generators.py&lt;/code&gt; module with a python interpreter with the libraries under &lt;code&gt;requirements.txt&lt;/code&gt; installed.&lt;/p&gt; 
&lt;p&gt;The keyed text format (&lt;code&gt;ktx&lt;/code&gt;) is a minimal human readable key-values to store text (markdown or others) indexed by keys.&lt;/p&gt; 
&lt;p&gt;This work is licensed under the MIT license.&lt;br&gt; &lt;a href="https://zenodo.org/badge/latestdoi/10173/rougier/numpy-100"&gt;&lt;img src="https://zenodo.org/badge/10173/rougier/numpy-100.svg?sanitize=true" alt="DOI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Variants in Other Languages&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Julia&lt;/strong&gt;: &lt;a href="https://github.com/RoyiAvital/Julia100Exercises"&gt;100 Julia Exercises&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/adk-samples</title>
      <link>https://github.com/google/adk-samples</link>
      <description>&lt;p&gt;A collection of sample agents built with Agent Development (ADK)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK) Samples&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://github.com/google/adk-docs/raw/main/docs/assets/agent-development-kit.png" alt="Agent Development Kit Logo" width="150"&gt; 
&lt;p&gt;Welcome to the ADK Sample Agents repository! This collection provides ready-to-use agents built on top of the &lt;a href="https://google.github.io/adk-docs/"&gt;Agent Development Kit&lt;/a&gt;, designed to accelerate your development process. These agents cover a range of common use cases and complexities, from simple conversational bots to complex multi-agent workflows.&lt;/p&gt; 
&lt;h2&gt;‚ú® Getting Started&lt;/h2&gt; 
&lt;p&gt;This repo contains ADK sample agents for both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;Java.&lt;/strong&gt; Navigate to the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/python/"&gt;Python&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/java/"&gt;Java&lt;/a&gt;&lt;/strong&gt; subfolders to see language-specific setup instructions, and learn more about the available sample agents.&lt;/p&gt; 
&lt;p&gt;To learn more, check out the &lt;a href="https://google.github.io/adk-docs/"&gt;ADK Documentation&lt;/a&gt;, and the GitHub repositories for &lt;a href="https://github.com/google/adk-python"&gt;ADK Python&lt;/a&gt; and &lt;a href="https://github.com/google/adk-java"&gt;ADK Java&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üå≥ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚îú‚îÄ‚îÄ java
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ agents
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ software-bug-assistant
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ time-series-forecasting
‚îÇ&amp;nbsp;&amp;nbsp; ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ python
‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ agents
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ academic-research
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ brand-search-optimization
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ camel
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ customer-service
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ data-science
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ financial-advisor
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ fomc-research
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini-fullstack
‚îÇ&amp;nbsp;&amp;nbsp; ‚îÇ&amp;nbsp;&amp;nbsp; ‚îú‚îÄ‚îÄ image-scoring
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm-auditor
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ machine-learning-engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketing-agency
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ personalized-shopping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RAG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ software-bug-assistant  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ travel-concierge
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ÑπÔ∏è Getting help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or if you found any problems with this repository, please report through &lt;a href="https://github.com/google/adk-samples/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our &lt;a href="https://github.com/google/adk-samples/raw/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guidelines&lt;/strong&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://github.com/google/adk-samples/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product. This project is not eligible for the &lt;a href="https://bughunters.google.com/open-source-security"&gt;Google Open Source Software Vulnerability Rewards Program&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is intended for demonstration purposes only. It is not intended for use in a production environment.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spotDL/spotify-downloader</title>
      <link>https://github.com/spotDL/spotify-downloader</link>
      <description>&lt;p&gt;Download your Spotify playlists and songs along with album art and metadata (from YouTube if a match is found).&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;spotDL v4&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;spotDL&lt;/strong&gt; finds songs from Spotify playlists on YouTube and downloads them - along with album art, lyrics and metadata.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/spotDL/spotify-downloader/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/spotdl/spotify-downloader?color=44CC11&amp;amp;style=flat-square" alt="MIT License"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/spotdl/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/spotDL?color=%2344CC11&amp;amp;style=flat-square" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/spotdl/"&gt;&lt;img src="https://img.shields.io/pypi/dw/spotDL?label=downloads@pypi&amp;amp;color=344CC11&amp;amp;style=flat-square" alt="PyPi downloads"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/contributors/spotDL/spotify-downloader?style=flat-square" alt="Contributors"&gt; &lt;a href="https://discord.gg/xCa23pwJWY"&gt;&lt;img src="https://img.shields.io/discord/771628785447337985?label=discord&amp;amp;logo=discord&amp;amp;style=flat-square" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;spotDL: The fastest, easiest and most accurate command-line music downloader.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://spotdl.readthedocs.io"&gt;Read the documentation on ReadTheDocs!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://spotdl.readthedocs.io/en/latest/installation.html"&gt;Installation Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Python (Recommended Method)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;spotDL&lt;/em&gt; can be installed by running &lt;code&gt;pip install spotdl&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To update spotDL run &lt;code&gt;pip install --upgrade spotdl&lt;/code&gt;&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;On some systems you might have to change &lt;code&gt;pip&lt;/code&gt; to &lt;code&gt;pip3&lt;/code&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary style="font-size:1.25em"&gt;&lt;strong&gt;Other options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Prebuilt executable 
   &lt;ul&gt; 
    &lt;li&gt;You can download the latest version from the &lt;a href="https://github.com/spotDL/spotify-downloader/releases"&gt;Releases Tab&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;On Termux 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;curl -L https://raw.githubusercontent.com/spotDL/spotify-downloader/master/scripts/termux.sh | sh&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Arch 
   &lt;ul&gt; 
    &lt;li&gt;There is an &lt;a href="https://aur.archlinux.org/packages/spotdl/"&gt;Arch User Repository (AUR) package&lt;/a&gt; for spotDL.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Docker 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;Build image:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t spotdl .
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Launch container with spotDL parameters (see section below). You need to create mapped volume to access song files&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -v $(pwd):/music spotdl download [trackUrl]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Build from source&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/spotDL/spotify-downloader &amp;amp;&amp;amp; cd spotify-downloader
pip install uv
uv sync
uv run scripts/build.py
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An executable is created in &lt;code&gt;spotify-downloader/dist/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Installing FFmpeg&lt;/h3&gt; 
&lt;p&gt;FFmpeg is required for spotDL. If using FFmpeg only for spotDL, you can simply install FFmpeg to your spotDL installation directory: &lt;code&gt;spotdl --download-ffmpeg&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;We recommend the above option, but if you want to install FFmpeg system-wide, follow these instructions&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://windowsloop.com/install-ffmpeg-windows-10/"&gt;Windows Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OSX - &lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Linux - &lt;code&gt;sudo apt install ffmpeg&lt;/code&gt; or use your distro's package manager&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Using SpotDL without options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;spotdl [urls]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run &lt;em&gt;spotDL&lt;/em&gt; as a package if running it as a script doesn't work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python -m spotdl [urls]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;General usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;spotdl [operation] [options] QUERY
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are different &lt;strong&gt;operations&lt;/strong&gt; spotDL can perform. The &lt;em&gt;default&lt;/em&gt; is &lt;code&gt;download&lt;/code&gt;, which simply downloads the songs from YouTube and embeds metadata.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;query&lt;/strong&gt; for spotDL is usually a list of Spotify URLs, but for some operations like &lt;strong&gt;sync&lt;/strong&gt;, only a single link or file is required. For a list of all &lt;strong&gt;options&lt;/strong&gt; use &lt;code&gt;spotdl -h&lt;/code&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary style="font-size:1em"&gt;&lt;strong&gt;Supported operations&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;save&lt;/code&gt;: Saves only the metadata from Spotify without downloading anything.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Usage: &lt;code&gt;spotdl save [query] --save-file {filename}.spotdl&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;web&lt;/code&gt;: Starts a web interface instead of using the command line. However, it has limited features and only supports downloading single songs.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;url&lt;/code&gt;: Get direct download link for each song from the query.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Usage: &lt;code&gt;spotdl url [query]&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;sync&lt;/code&gt;: Updates directories. Compares the directory with the current state of the playlist. Newly added songs will be downloaded and removed songs will be deleted. No other songs will be downloaded and no other files will be deleted.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;Usage: &lt;code&gt;spotdl sync [query] --save-file {filename}.spotdl&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This create a new &lt;strong&gt;sync&lt;/strong&gt; file, to update the directory in the future, use:&lt;/p&gt; &lt;p&gt;&lt;code&gt;spotdl sync {filename}.spotdl&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;code&gt;meta&lt;/code&gt;: Updates metadata for the provided song files.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Music Sourcing and Audio Quality&lt;/h2&gt; 
&lt;p&gt;spotDL uses YouTube as a source for music downloads. This method is used to avoid any issues related to downloading music from Spotify.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; Users are responsible for their actions and potential legal consequences. We do not support unauthorized downloading of copyrighted material and take no responsibility for user actions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Audio Quality&lt;/h3&gt; 
&lt;p&gt;spotDL downloads music from YouTube and is designed to always download the highest possible bitrate; which is 128 kbps for regular users and 256 kbps for YouTube Music premium users.&lt;/p&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/usage.md#audio-formats-and-quality"&gt;Audio Formats&lt;/a&gt; page for more info.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Check out our &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to find resources around contributing along with a guide on how to set up a development environment.&lt;/p&gt; 
&lt;h3&gt;Join our amazing community as a code contributor&lt;/h3&gt; 
&lt;a href="https://github.com/spotDL/spotify-downloader/graphs/contributors"&gt; &lt;img class="dark-light" src="https://contrib.rocks/image?repo=spotDL/spotify-downloader&amp;amp;anon=0&amp;amp;columns=25&amp;amp;max=100&amp;amp;r=true"&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is Licensed under the &lt;a href="https://raw.githubusercontent.com/spotDL/spotify-downloader/master/LICENSE"&gt;MIT&lt;/a&gt; License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>reflex-dev/reflex</title>
      <link>https://github.com/reflex-dev/reflex</link>
      <description>&lt;p&gt;üï∏Ô∏è Web apps in pure Python üêç&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex.svg?sanitize=true" alt="Reflex Logo" width="300px"&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;&lt;strong&gt;‚ú® Performant, customizable web apps in pure Python. Deploy in seconds. ‚ú®&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/reflex"&gt;&lt;img src="https://badge.fury.io/py/reflex.svg?sanitize=true" alt="PyPI version"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/reflex.svg?sanitize=true" alt="versions"&gt; &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;&lt;img src="https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/reflex"&gt;&lt;img src="https://static.pepy.tech/badge/reflex" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;&lt;img src="https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/reflex-dev/reflex/raw/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_cn/README.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_tw/README.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/tr/README.md"&gt;T√ºrk√ße&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/in/README.md"&gt;‡§π‡§ø‡§Ç‡§¶‡•Ä&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pt/pt_br/README.md"&gt;Portugu√™s (Brasil)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/it/README.md"&gt;Italiano&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/es/README.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/kr/README.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/ja/README.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/de/README.md"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pe/README.md"&gt;Persian (Ÿæÿßÿ±ÿ≥€å)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/vi/README.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] üöÄ &lt;strong&gt;Try &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt;&lt;/strong&gt; ‚Äì our AI-powered app builder that generates full-stack Reflex applications in seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;Reflex is a library to build full-stack web apps in pure Python.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pure Python&lt;/strong&gt; - Write your app's frontend and backend all in Python, no need to learn Javascript.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Flexibility&lt;/strong&gt; - Reflex is easy to get started with, but can also scale to complex apps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy Instantly&lt;/strong&gt; - After building, deploy your app with a &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start/"&gt;single command&lt;/a&gt; or host it on your own server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture"&gt;architecture page&lt;/a&gt; to learn how Reflex works under the hood.&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è Installation&lt;/h2&gt; 
&lt;p&gt;Open a terminal and run (Requires Python 3.10+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install reflex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü•≥ Create your first app&lt;/h2&gt; 
&lt;p&gt;Installing &lt;code&gt;reflex&lt;/code&gt; also installs the &lt;code&gt;reflex&lt;/code&gt; command line tool.&lt;/p&gt; 
&lt;p&gt;Test that the install was successful by creating a new project. (Replace &lt;code&gt;my_app_name&lt;/code&gt; with your project name):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir my_app_name
cd my_app_name
reflex init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command initializes a template app in your new directory.&lt;/p&gt; 
&lt;p&gt;You can run this app in development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;reflex run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see your app running at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Reflex has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; 
&lt;h2&gt;ü´ß Example App&lt;/h2&gt; 
&lt;p&gt;Let's go over an example: creating an image generation UI around &lt;a href="https://platform.openai.com/docs/guides/images/image-generation?context=node"&gt;DALL¬∑E&lt;/a&gt;. For simplicity, we just call the &lt;a href="https://platform.openai.com/docs/api-reference/authentication"&gt;OpenAI API&lt;/a&gt;, but you could replace this with an ML model run locally.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif" alt="A frontend wrapper for DALL¬∑E, shown in the process of generating an image." width="550"&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    """The app state."""

    prompt = ""
    image_url = ""
    processing = False
    complete = False

    def get_image(self):
        """Get the image from the prompt."""
        if self.prompt == "":
            return rx.window_alert("Prompt Empty")

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size="1024x1024"
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading("DALL-E", font_size="1.5em"),
            rx.input(
                placeholder="Enter a prompt..",
                on_blur=State.set_prompt,
                width="25em",
            ),
            rx.button(
                "Generate Image",
                on_click=State.get_image,
                width="25em",
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width="20em"),
            ),
            align="center",
        ),
        width="100%",
        height="100vh",
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title="Reflex:DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Let's break this down.&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png" alt="Explaining the differences between backend and frontend parts of the DALL-E app." width="900"&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;Reflex UI&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Let's start with the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def index():
    return rx.center(
        ...
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; 
&lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; 
&lt;p&gt;Reflex comes with &lt;a href="https://reflex.dev/docs/library"&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, and it's easy to &lt;a href="https://reflex.dev/docs/wrapping-react/overview/"&gt;create your own components&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Reflex represents your UI as a function of your state.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class State(rx.State):
    """The app state."""
    prompt = ""
    image_url = ""
    processing = False
    complete = False

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them.&lt;/p&gt; 
&lt;p&gt;Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;processing&lt;/code&gt; and &lt;code&gt;complete&lt;/code&gt; to indicate when to disable the button (during image generation) and when to show the resulting image.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_image(self):
    """Get the image from the prompt."""
    if self.prompt == "":
        return rx.window_alert("Prompt Empty")

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size="1024x1024"
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; 
&lt;p&gt;Our DALL¬∑E app has an event handler, &lt;code&gt;get_image&lt;/code&gt; which gets this image from the OpenAI API. Using &lt;code&gt;yield&lt;/code&gt; in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Finally, we define our app.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app = rx.App()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app.add_page(index, title="DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create a multi-page app by adding more pages.&lt;/p&gt; 
&lt;h2&gt;üìë Resources&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;üìë &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üóûÔ∏è &lt;a href="https://reflex.dev/blog"&gt;Blog&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üì± &lt;a href="https://reflex.dev/docs/library"&gt;Component Library&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üñºÔ∏è &lt;a href="https://reflex.dev/templates/"&gt;Templates&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üõ∏ &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start"&gt;Deployment&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚úÖ Status&lt;/h2&gt; 
&lt;p&gt;Reflex launched in December 2022 with the name Pynecone.&lt;/p&gt; 
&lt;p&gt;üöÄ Introducing &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt; ‚Äî Our AI-Powered Builder Reflex Build uses AI to generate complete full-stack Python applications. It helps you quickly create, customize, and refine your Reflex apps ‚Äî from frontend components to backend logic ‚Äî so you can focus on your ideas instead of boilerplate code. Whether you‚Äôre prototyping or scaling, Reflex Build accelerates development by intelligently scaffolding and optimizing your app‚Äôs entire stack.&lt;/p&gt; 
&lt;p&gt;Alongside this, &lt;a href="https://cloud.reflex.dev"&gt;Reflex Cloud&lt;/a&gt; launched in 2025 to offer the best hosting experience for your Reflex apps. We‚Äôre continuously improving the platform with new features and capabilities.&lt;/p&gt; 
&lt;p&gt;Reflex has new releases and features coming every week! Make sure to &lt;span&gt;‚≠ê&lt;/span&gt; star and &lt;span&gt;üëÄ&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Reflex community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;Discord&lt;/a&gt; is the best place to get help on your Reflex project and to discuss how you can contribute.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/reflex-dev/reflex/issues"&gt;Issues&lt;/a&gt; are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are actively looking for contributors, no matter your skill level or experience. To contribute check out &lt;a href="https://github.com/reflex-dev/reflex/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;All Thanks To Our Contributors:&lt;/h2&gt; 
&lt;a href="https://github.com/reflex-dev/reflex/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=reflex-dev/reflex"&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Reflex is open-source and licensed under the &lt;a href="https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AUTOMATIC1111/stable-diffusion-webui</title>
      <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
      <description>&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; 
&lt;p&gt;A web interface for Stable Diffusion, implemented using Gradio library.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/screenshot.png" alt=""&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features"&gt;Detailed feature showcase with images&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original txt2img and img2img modes&lt;/li&gt; 
 &lt;li&gt;One click install and run script (but you still must install python and git)&lt;/li&gt; 
 &lt;li&gt;Outpainting&lt;/li&gt; 
 &lt;li&gt;Inpainting&lt;/li&gt; 
 &lt;li&gt;Color Sketch&lt;/li&gt; 
 &lt;li&gt;Prompt Matrix&lt;/li&gt; 
 &lt;li&gt;Stable Diffusion Upscale&lt;/li&gt; 
 &lt;li&gt;Attention, specify parts of text that the model should pay more attention to 
  &lt;ul&gt; 
   &lt;li&gt;a man in a &lt;code&gt;((tuxedo))&lt;/code&gt; - will pay more attention to tuxedo&lt;/li&gt; 
   &lt;li&gt;a man in a &lt;code&gt;(tuxedo:1.21)&lt;/code&gt; - alternative syntax&lt;/li&gt; 
   &lt;li&gt;select text and press &lt;code&gt;Ctrl+Up&lt;/code&gt; or &lt;code&gt;Ctrl+Down&lt;/code&gt; (or &lt;code&gt;Command+Up&lt;/code&gt; or &lt;code&gt;Command+Down&lt;/code&gt; if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Loopback, run img2img processing multiple times&lt;/li&gt; 
 &lt;li&gt;X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters&lt;/li&gt; 
 &lt;li&gt;Textual Inversion 
  &lt;ul&gt; 
   &lt;li&gt;have as many embeddings as you want and use any names you like for them&lt;/li&gt; 
   &lt;li&gt;use multiple embeddings with different numbers of vectors per token&lt;/li&gt; 
   &lt;li&gt;works with half precision floating point numbers&lt;/li&gt; 
   &lt;li&gt;train embeddings on 8GB (also reports of 6GB working)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Extras tab with: 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN, neural network that fixes faces&lt;/li&gt; 
   &lt;li&gt;CodeFormer, face restoration tool as an alternative to GFPGAN&lt;/li&gt; 
   &lt;li&gt;RealESRGAN, neural network upscaler&lt;/li&gt; 
   &lt;li&gt;ESRGAN, neural network upscaler with a lot of third party models&lt;/li&gt; 
   &lt;li&gt;SwinIR and Swin2SR (&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092"&gt;see here&lt;/a&gt;), neural network upscalers&lt;/li&gt; 
   &lt;li&gt;LDSR, Latent diffusion super resolution upscaling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Resizing aspect ratio options&lt;/li&gt; 
 &lt;li&gt;Sampling method selection 
  &lt;ul&gt; 
   &lt;li&gt;Adjust sampler eta values (noise multiplier)&lt;/li&gt; 
   &lt;li&gt;More advanced noise setting options&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Interrupt processing at any time&lt;/li&gt; 
 &lt;li&gt;4GB video card support (also reports of 2GB working)&lt;/li&gt; 
 &lt;li&gt;Correct seeds for batches&lt;/li&gt; 
 &lt;li&gt;Live prompt token length validation&lt;/li&gt; 
 &lt;li&gt;Generation parameters 
  &lt;ul&gt; 
   &lt;li&gt;parameters you used to generate images are saved with that image&lt;/li&gt; 
   &lt;li&gt;in PNG chunks for PNG, in EXIF for JPEG&lt;/li&gt; 
   &lt;li&gt;can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI&lt;/li&gt; 
   &lt;li&gt;can be disabled in settings&lt;/li&gt; 
   &lt;li&gt;drag and drop an image/text-parameters to promptbox&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Read Generation Parameters Button, loads parameters in promptbox to UI&lt;/li&gt; 
 &lt;li&gt;Settings page&lt;/li&gt; 
 &lt;li&gt;Running arbitrary python code from UI (must run with &lt;code&gt;--allow-code&lt;/code&gt; to enable)&lt;/li&gt; 
 &lt;li&gt;Mouseover hints for most UI elements&lt;/li&gt; 
 &lt;li&gt;Possible to change defaults/mix/max/step values for UI elements via text config&lt;/li&gt; 
 &lt;li&gt;Tiling support, a checkbox to create images that can be tiled like textures&lt;/li&gt; 
 &lt;li&gt;Progress bar and live image generation preview 
  &lt;ul&gt; 
   &lt;li&gt;Can use a separate neural network to produce previews with almost none VRAM or compute requirement&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Negative prompt, an extra text field that allows you to list what you don't want to see in generated image&lt;/li&gt; 
 &lt;li&gt;Styles, a way to save part of prompt and easily apply them via dropdown later&lt;/li&gt; 
 &lt;li&gt;Variations, a way to generate same image but with tiny differences&lt;/li&gt; 
 &lt;li&gt;Seed resizing, a way to generate same image but at slightly different resolution&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator, a button that tries to guess prompt from an image&lt;/li&gt; 
 &lt;li&gt;Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway&lt;/li&gt; 
 &lt;li&gt;Batch Processing, process a group of files using img2img&lt;/li&gt; 
 &lt;li&gt;Img2img Alternative, reverse Euler method of cross attention control&lt;/li&gt; 
 &lt;li&gt;Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions&lt;/li&gt; 
 &lt;li&gt;Reloading checkpoints on the fly&lt;/li&gt; 
 &lt;li&gt;Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts"&gt;Custom scripts&lt;/a&gt; with many extensions from community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"&gt;Composable-Diffusion&lt;/a&gt;, a way to use multiple prompts at once 
  &lt;ul&gt; 
   &lt;li&gt;separate prompts using uppercase &lt;code&gt;AND&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;also supports weights for prompts: &lt;code&gt;a cat :1.2 AND a dog AND a penguin :2.2&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;No token limit for prompts (original stable diffusion lets you use up to 75 tokens)&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru integration, creates danbooru style tags for anime prompts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers"&gt;xformers&lt;/a&gt;, major speed increase for select cards: (add &lt;code&gt;--xformers&lt;/code&gt; to commandline args)&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser"&gt;History tab&lt;/a&gt;: view, direct and delete images conveniently within the UI&lt;/li&gt; 
 &lt;li&gt;Generate forever option&lt;/li&gt; 
 &lt;li&gt;Training tab 
  &lt;ul&gt; 
   &lt;li&gt;hypernetworks and embeddings options&lt;/li&gt; 
   &lt;li&gt;Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Clip skip&lt;/li&gt; 
 &lt;li&gt;Hypernetworks&lt;/li&gt; 
 &lt;li&gt;Loras (same as Hypernetworks but more pretty)&lt;/li&gt; 
 &lt;li&gt;A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt&lt;/li&gt; 
 &lt;li&gt;Can select to load a different VAE from settings screen&lt;/li&gt; 
 &lt;li&gt;Estimated completion time in progress bar&lt;/li&gt; 
 &lt;li&gt;API&lt;/li&gt; 
 &lt;li&gt;Support for dedicated &lt;a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion"&gt;inpainting model&lt;/a&gt; by RunwayML&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients"&gt;Aesthetic Gradients&lt;/a&gt;, a way to generate images with a specific aesthetic by using clip images embeds (implementation of &lt;a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients"&gt;https://github.com/vicgalle/stable-diffusion-aesthetic-gradients&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;Stable Diffusion 2.0&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2211.06679"&gt;Alt-Diffusion&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;Now without any bad letters!&lt;/li&gt; 
 &lt;li&gt;Load checkpoints in safetensors format&lt;/li&gt; 
 &lt;li&gt;Eased resolution restriction: generated image's dimensions must be a multiple of 8 rather than 64&lt;/li&gt; 
 &lt;li&gt;Now with a license!&lt;/li&gt; 
 &lt;li&gt;Reorder elements in the UI from settings screen&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/segmind/SSD-1B"&gt;Segmind Stable Diffusion&lt;/a&gt; support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation and Running&lt;/h2&gt; 
&lt;p&gt;Make sure the required &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies"&gt;dependencies&lt;/a&gt; are met and follow the instructions available for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;NVidia&lt;/a&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs"&gt;AMD&lt;/a&gt; GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon"&gt;Intel CPUs, Intel GPUs (both integrated and discrete)&lt;/a&gt; (external wiki page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs"&gt;Ascend NPUs&lt;/a&gt; (external wiki page)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, use online services (like Google Colab):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services"&gt;List of Online Services&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation on Windows 10/11 with NVidia-GPUs using release package&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download &lt;code&gt;sd.webui.zip&lt;/code&gt; from &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre"&gt;v1.0.0-pre&lt;/a&gt; and extract its contents.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;update.bat&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;run.bat&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For more details see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;Install-and-Run-on-NVidia-GPUs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Automatic Installation on Windows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;a href="https://www.python.org/downloads/release/python-3106/"&gt;Python 3.10.6&lt;/a&gt; (Newer version of Python does not support torch), checking "Add Python to PATH".&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://git-scm.com/download/win"&gt;git&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the stable-diffusion-webui repository, for example by running &lt;code&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;webui-user.bat&lt;/code&gt; from Windows Explorer as normal, non-administrator, user.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Automatic Installation on Linux&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your system is very new, you need to install python3.11 or python3.10:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd="python3.11"
# or in webui-user.sh
python_cmd="python3.11"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to the directory you would like the webui to be installed and execute the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or just clone the repo wherever you want:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Run &lt;code&gt;webui.sh&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Check &lt;code&gt;webui-user.sh&lt;/code&gt; for options.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Installation on Apple Silicon&lt;/h3&gt; 
&lt;p&gt;Find the instructions &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Here's how to add code to this repo: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation was moved from this README over to the project's &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) &lt;a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;crawlable wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Licenses for borrowed code can be found in &lt;code&gt;Settings -&amp;gt; Licenses&lt;/code&gt; screen, and also in &lt;code&gt;html/licenses.html&lt;/code&gt; file.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable Diffusion - &lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;https://github.com/Stability-AI/stablediffusion&lt;/a&gt;, &lt;a href="https://github.com/CompVis/taming-transformers"&gt;https://github.com/CompVis/taming-transformers&lt;/a&gt;, &lt;a href="https://github.com/mcmonkey4eva/sd3-ref"&gt;https://github.com/mcmonkey4eva/sd3-ref&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;k-diffusion - &lt;a href="https://github.com/crowsonkb/k-diffusion.git"&gt;https://github.com/crowsonkb/k-diffusion.git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spandrel - &lt;a href="https://github.com/chaiNNer-org/spandrel"&gt;https://github.com/chaiNNer-org/spandrel&lt;/a&gt; implementing 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN - &lt;a href="https://github.com/TencentARC/GFPGAN.git"&gt;https://github.com/TencentARC/GFPGAN.git&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;CodeFormer - &lt;a href="https://github.com/sczhou/CodeFormer"&gt;https://github.com/sczhou/CodeFormer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;ESRGAN - &lt;a href="https://github.com/xinntao/ESRGAN"&gt;https://github.com/xinntao/ESRGAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;SwinIR - &lt;a href="https://github.com/JingyunLiang/SwinIR"&gt;https://github.com/JingyunLiang/SwinIR&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Swin2SR - &lt;a href="https://github.com/mv-lab/swin2sr"&gt;https://github.com/mv-lab/swin2sr&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;LDSR - &lt;a href="https://github.com/Hafiidz/latent-diffusion"&gt;https://github.com/Hafiidz/latent-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MiDaS - &lt;a href="https://github.com/isl-org/MiDaS"&gt;https://github.com/isl-org/MiDaS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ideas for optimizations - &lt;a href="https://github.com/basujindal/stable-diffusion"&gt;https://github.com/basujindal/stable-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - Doggettx - &lt;a href="https://github.com/Doggettx/stable-diffusion"&gt;https://github.com/Doggettx/stable-diffusion&lt;/a&gt;, original idea for prompt editing.&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - InvokeAI, lstein - &lt;a href="https://github.com/invoke-ai/InvokeAI"&gt;https://github.com/invoke-ai/InvokeAI&lt;/a&gt; (originally &lt;a href="http://github.com/lstein/stable-diffusion"&gt;http://github.com/lstein/stable-diffusion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Sub-quadratic Cross Attention layer optimization - Alex Birch (&lt;a href="https://github.com/Birch-san/diffusers/pull/1"&gt;https://github.com/Birch-san/diffusers/pull/1&lt;/a&gt;), Amin Rezaei (&lt;a href="https://github.com/AminRezaei0x443/memory-efficient-attention"&gt;https://github.com/AminRezaei0x443/memory-efficient-attention&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Textual Inversion - Rinon Gal - &lt;a href="https://github.com/rinongal/textual_inversion"&gt;https://github.com/rinongal/textual_inversion&lt;/a&gt; (we're not using his code, but we are using his ideas).&lt;/li&gt; 
 &lt;li&gt;Idea for SD upscale - &lt;a href="https://github.com/jquesnelle/txt2imghd"&gt;https://github.com/jquesnelle/txt2imghd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Noise generation for outpainting mk2 - &lt;a href="https://github.com/parlance-zz/g-diffuser-bot"&gt;https://github.com/parlance-zz/g-diffuser-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator idea and borrowing some code - &lt;a href="https://github.com/pharmapsychotic/clip-interrogator"&gt;https://github.com/pharmapsychotic/clip-interrogator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Idea for Composable Diffusion - &lt;a href="https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch"&gt;https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;xformers - &lt;a href="https://github.com/facebookresearch/xformers"&gt;https://github.com/facebookresearch/xformers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru - interrogator for anime diffusers &lt;a href="https://github.com/KichangKim/DeepDanbooru"&gt;https://github.com/KichangKim/DeepDanbooru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (&lt;a href="https://github.com/Birch-san/diffusers-play/tree/92feee6"&gt;https://github.com/Birch-san/diffusers-play/tree/92feee6&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - &lt;a href="https://github.com/timothybrooks/instruct-pix2pix"&gt;https://github.com/timothybrooks/instruct-pix2pix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Security advice - RyotaK&lt;/li&gt; 
 &lt;li&gt;UniPC sampler - Wenliang Zhao - &lt;a href="https://github.com/wl-zhao/UniPC"&gt;https://github.com/wl-zhao/UniPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TAESD - Ollin Boer Bohan - &lt;a href="https://github.com/madebyollin/taesd"&gt;https://github.com/madebyollin/taesd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LyCORIS - KohakuBlueleaf&lt;/li&gt; 
 &lt;li&gt;Restart sampling - lambertae - &lt;a href="https://github.com/Newbeeer/diffusion_restart_sampling"&gt;https://github.com/Newbeeer/diffusion_restart_sampling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hypertile - tfernd - &lt;a href="https://github.com/tfernd/HyperTile"&gt;https://github.com/tfernd/HyperTile&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.&lt;/li&gt; 
 &lt;li&gt;(You)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;img width="1200" alt="cb-big2" src="https://github.com/user-attachments/assets/bd8c5f03-e91d-4ee5-b680-57355da204d1"&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text"&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with ‚ô•Ô∏è by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We're excited to introduce Chatterbox, &lt;a href="https://resemble.ai"&gt;Resemble AI's&lt;/a&gt; first production-grade open source TTS model. Licensed under MIT, Chatterbox has been benchmarked against leading closed-source systems like ElevenLabs, and is consistently preferred in side-by-side evaluations.&lt;/p&gt; 
&lt;p&gt;Whether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. It's also the first open source TTS model to support &lt;strong&gt;emotion exaggeration control&lt;/strong&gt;, a powerful feature that makes your voices stand out. Try it now on our &lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Hugging Face Gradio app.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;h1&gt;Key Details&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;SoTA zeroshot TTS&lt;/li&gt; 
 &lt;li&gt;0.5B Llama backbone&lt;/li&gt; 
 &lt;li&gt;Unique exaggeration/intensity control&lt;/li&gt; 
 &lt;li&gt;Ultra-stable with alignment-informed inference&lt;/li&gt; 
 &lt;li&gt;Trained on 0.5M hours of cleaned data&lt;/li&gt; 
 &lt;li&gt;Watermarked outputs&lt;/li&gt; 
 &lt;li&gt;Easy voice conversion script&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podonos.com/resembleai/chatterbox"&gt;Outperforms ElevenLabs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Tips&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debain 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
from chatterbox.tts import ChatterboxTTS

model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-1.wav", wav, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h1&gt;Supported Lanugage&lt;/h1&gt; 
&lt;p&gt;Currenlty only English.&lt;/p&gt; 
&lt;h1&gt;Acknowledgements&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h1&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Official Discord&lt;/h1&gt; 
&lt;p&gt;üëã Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h1&gt;Citation&lt;/h1&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/mcp-for-beginners</title>
      <link>https://github.com/microsoft/mcp-for-beginners</link>
      <description>&lt;p&gt;This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in .NET, Java, TypeScript, JavaScript, and Python. Designed for developers, it focuses on practical techniques for building modular, scalable, and secure AI workflows from session setup to service orchestration.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/images/mcp-beginners.png" alt="MCP-for-beginners"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/issues"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub pull-requests"&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/mcp-for-beginners?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt="Microsoft Azure AI Foundry Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Follow these steps to get started using these resources:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;: Click &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;: &lt;code&gt;git clone https://github.com/microsoft/mcp-for-beginners.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;strong&gt;Join The Azure AI Foundry Discord and meet experts and fellow developers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üåê Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;üöÄ Model Context Protocol (MCP) Curriculum for Beginners&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;Learn MCP with Hands-on Code Examples in C#, Java, JavaScript, Python, and TypeScript&lt;/strong&gt;&lt;/h2&gt; 
&lt;h2&gt;üß† Overview of the Model Context Protocol Curriculum&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; is a cutting-edge framework designed to standardize interactions between AI models and client applications. This open-source curriculum offers a structured learning path, complete with practical coding examples and real-world use cases, across popular programming languages including C#, Java, JavaScript, TypeScript, and Python.&lt;/p&gt; 
&lt;p&gt;Whether you're an AI developer, system architect, or software engineer, this guide is your comprehensive resource for mastering MCP fundamentals and implementation strategies.&lt;/p&gt; 
&lt;h2&gt;üîó Official MCP Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://modelcontextprotocol.io/"&gt;MCP Documentation&lt;/a&gt; ‚Äì Detailed tutorials and user guides&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://modelcontextprotocol.io/docs/"&gt;MCP Specification&lt;/a&gt; ‚Äì Protocol architecture and technical references&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://spec.modelcontextprotocol.io/"&gt;Original MCP Specification&lt;/a&gt; ‚Äì Legacy technical references (may contain additional details)&lt;/li&gt; 
 &lt;li&gt;üßë‚Äçüíª &lt;a href="https://github.com/modelcontextprotocol"&gt;MCP GitHub Repository&lt;/a&gt; ‚Äì Open-source SDKs, tools, and code samples&lt;/li&gt; 
 &lt;li&gt;üåê &lt;a href="https://github.com/orgs/modelcontextprotocol/discussions"&gt;MCP Community&lt;/a&gt; ‚Äì Join discussions and contribute to the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join us for MCP Dev Days 29-30th July 2025&lt;/h2&gt; 
&lt;p&gt;Get ready for two days of deep technical insight, community connection, and hands-on learning at MCP Dev Days, a virtual event dedicated to the Model Context Protocol (MCP) ‚Äî the emerging standard that bridges AI models and the tools they rely on.&lt;/p&gt; 
&lt;p&gt;‚û°Ô∏è &lt;a href="https://developer.microsoft.com/en-us/reactor/series/S-1563/"&gt;Register for MCP Dev Days&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can watch MCP Dev Days by registering on our event page: &lt;a href="https://aka.ms/mcpdevdays"&gt;https://aka.ms/mcpdevdays&lt;/a&gt;. From there, you‚Äôll be able to join a live stream on YouTube or Twitch. All of the content is recorded and will be available afterwards on the Microsoft Developer YouTube channel. Source code for the demos will be available on GitHub too.&lt;/p&gt; 
&lt;h3&gt;Event Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dates: July 29 (Day 1) &amp;amp; July 30 (Day 2)&lt;/li&gt; 
 &lt;li&gt;Time: 9:00 AM PST daily&lt;/li&gt; 
 &lt;li&gt;Where: Online ‚Äì join from anywhere!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Day 1: MCP Productivity, DevTools, &amp;amp; Community:&lt;/h4&gt; 
&lt;p&gt;Is all about empowering developers to use MCP in their developer workflow and celebrating the amazing MCP community. We‚Äôll be joined with community members and partners such as Arcade, Block, Okta, and Neon to see how they are collaborating with Microsoft to shape an open, extensible MCP ecosystem. Real-world demos across VS Code, Visual Studio, GitHub Copilot, and popular community tools Practical, context-driven dev workflows Community-led sessions and insights Whether you‚Äôre just getting started with MCP or already building with it, Day 1 will set the stage with inspiration and actionable takeaways.&lt;/p&gt; 
&lt;h4&gt;Day 2: Build MCP Servers with Confidence&lt;/h4&gt; 
&lt;p&gt;Is for MCP builders. We‚Äôll go deep into implementation strategies and best practices for creating MCP servers and integrating MCP into your AI workflows.&lt;/p&gt; 
&lt;h3&gt;Topics include:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building MCP Servers and integrating them into agent experiences&lt;/li&gt; 
 &lt;li&gt;Prompt-driven development&lt;/li&gt; 
 &lt;li&gt;Security best practices&lt;/li&gt; 
 &lt;li&gt;Using building blocks like Functions, ACA, and API Management&lt;/li&gt; 
 &lt;li&gt;Registry alignment and tooling (1P + 3P)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you‚Äôre a developer, tool builder, or AI product strategist, this day is packed with the insights you need to build scalable, secure, and future-ready MCP solutions.&lt;/p&gt; 
&lt;h2&gt;üß≠ MCP Curriculum Overview&lt;/h2&gt; 
&lt;h3&gt;üìö Complete Curriculum Structure&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 1-3: Fundamentals&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;Introduction to MCP&lt;/td&gt; 
   &lt;td&gt;Overview of the Model Context Protocol and its significance in AI pipelines&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/00-Introduction/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;Core Concepts Explained&lt;/td&gt; 
   &lt;td&gt;In-depth exploration of core MCP concepts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/01-CoreConcepts/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;Security in MCP&lt;/td&gt; 
   &lt;td&gt;Security threats and best practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/02-Security/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;Getting Started with MCP&lt;/td&gt; 
   &lt;td&gt;Environment setup, basic servers/clients, integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 3: Building Your First Server &amp;amp; Client&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.1&lt;/td&gt; 
   &lt;td&gt;First Server&lt;/td&gt; 
   &lt;td&gt;Create your first MCP server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/01-first-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;First Client&lt;/td&gt; 
   &lt;td&gt;Develop a basic MCP client&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/02-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.3&lt;/td&gt; 
   &lt;td&gt;Client with LLM&lt;/td&gt; 
   &lt;td&gt;Integrate large language models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/03-llm-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;VS Code Integration&lt;/td&gt; 
   &lt;td&gt;Consume MCP servers in VS Code&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/04-vscode/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.5&lt;/td&gt; 
   &lt;td&gt;SSE Server&lt;/td&gt; 
   &lt;td&gt;Create servers using Server-Sent Events&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/05-sse-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.6&lt;/td&gt; 
   &lt;td&gt;HTTP Streaming&lt;/td&gt; 
   &lt;td&gt;Implement HTTP streaming in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/06-http-streaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.7&lt;/td&gt; 
   &lt;td&gt;AI Toolkit&lt;/td&gt; 
   &lt;td&gt;Use AI Toolkit with MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/07-aitk/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.8&lt;/td&gt; 
   &lt;td&gt;Testing&lt;/td&gt; 
   &lt;td&gt;Test your MCP server implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/08-testing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;Deployment&lt;/td&gt; 
   &lt;td&gt;Deploy MCP servers to production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/09-deployment/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 4-5: Practical &amp;amp; Advanced&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;Practical Implementation&lt;/td&gt; 
   &lt;td&gt;SDKs, debugging, testing, reusable prompt templates&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;Advanced Topics in MCP&lt;/td&gt; 
   &lt;td&gt;Multi-modal AI, scaling, enterprise use&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Azure Integration&lt;/td&gt; 
   &lt;td&gt;MCP Integration with Azure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;Multi-modality&lt;/td&gt; 
   &lt;td&gt;Working with multiple modalities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-multi-modality/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;OAuth2 Demo&lt;/td&gt; 
   &lt;td&gt;Implement OAuth2 authentication&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-oauth2-demo/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.4&lt;/td&gt; 
   &lt;td&gt;Root Contexts&lt;/td&gt; 
   &lt;td&gt;Understand and implement root contexts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-root-contexts/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.5&lt;/td&gt; 
   &lt;td&gt;Routing&lt;/td&gt; 
   &lt;td&gt;MCP routing strategies&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-routing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;Sampling&lt;/td&gt; 
   &lt;td&gt;Sampling techniques in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-sampling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.7&lt;/td&gt; 
   &lt;td&gt;Scaling&lt;/td&gt; 
   &lt;td&gt;Scale MCP implementations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-scaling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.8&lt;/td&gt; 
   &lt;td&gt;Security&lt;/td&gt; 
   &lt;td&gt;Advanced security considerations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.9&lt;/td&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;Implement web search capabilities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/web-search-mcp/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.10&lt;/td&gt; 
   &lt;td&gt;Realtime Streaming&lt;/td&gt; 
   &lt;td&gt;Build realtime streaming functionality&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimestreaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.11&lt;/td&gt; 
   &lt;td&gt;Realtime Search&lt;/td&gt; 
   &lt;td&gt;Implement realtime search&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimesearch/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.12&lt;/td&gt; 
   &lt;td&gt;Entra ID Auth&lt;/td&gt; 
   &lt;td&gt;Authentication with Microsoft Entra ID&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security-entra/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.13&lt;/td&gt; 
   &lt;td&gt;Foundry Integration&lt;/td&gt; 
   &lt;td&gt;Integrate with Azure AI Foundry&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-foundry-agent-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.14&lt;/td&gt; 
   &lt;td&gt;Context Engineering&lt;/td&gt; 
   &lt;td&gt;Techniques for effective context engineering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-contextengineering/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 6-10: Community &amp;amp; Best Practices&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;Community Contributions&lt;/td&gt; 
   &lt;td&gt;How to contribute to the MCP ecosystem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/06-CommunityContributions/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;Insights from Early Adoption&lt;/td&gt; 
   &lt;td&gt;Real-world implementation stories&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/07-LessonsFromEarlyAdoption/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;Best Practices for MCP&lt;/td&gt; 
   &lt;td&gt;Performance, fault-tolerance, resilience&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/08-BestPractices/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;MCP Case Studies&lt;/td&gt; 
   &lt;td&gt;Practical implementation examples&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/09-CaseStudy/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;Hands-on Workshop&lt;/td&gt; 
   &lt;td&gt;Building an MCP Server with AI Toolkit&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/10-StreamliningAIWorkflowsBuildingAnMCPServerWithAIToolkit/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üíª Sample Code Projects&lt;/h3&gt; 
&lt;h4&gt;Basic MCP Calculator Samples&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;MCP Server Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;MCP Calculator&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/java/calculator/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;MCP Demo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;MCP Server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/python/mcp_calculator_server.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;MCP Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Advanced MCP Implementations&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;Container App Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/java/containerapp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Complex Implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/python/mcp_sample.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;Container Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üéØ Prerequisites for Learning MCP&lt;/h2&gt; 
&lt;p&gt;To get the most out of this curriculum, you should have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of programming in at least one of the following languages: C#, Java, JavaScript, Python, or TypeScript&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Understanding of client-server model and APIs&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Familiarity with REST and HTTP concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Background in AI/ML concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Joining our community discussions for support&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö Study Guide &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;This repository includes several resources to help you navigate and learn effectively:&lt;/p&gt; 
&lt;h3&gt;Study Guide&lt;/h3&gt; 
&lt;p&gt;A comprehensive &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/study_guide.md"&gt;Study Guide&lt;/a&gt; is available to help you navigate this repository effectively. The guide includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A visual curriculum map showing all topics covered&lt;/li&gt; 
 &lt;li&gt;Detailed breakdown of each repository section&lt;/li&gt; 
 &lt;li&gt;Guidance on how to use sample projects&lt;/li&gt; 
 &lt;li&gt;Recommended learning paths for different skill levels&lt;/li&gt; 
 &lt;li&gt;Additional resources to complement your learning journey&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Changelog&lt;/h3&gt; 
&lt;p&gt;We maintain a detailed &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/changelog.md"&gt;Changelog&lt;/a&gt; that tracks all significant updates to the curriculum materials, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;New content additions&lt;/li&gt; 
 &lt;li&gt;Structural changes&lt;/li&gt; 
 &lt;li&gt;Feature improvements&lt;/li&gt; 
 &lt;li&gt;Documentation updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è How to Use This Curriculum Effectively&lt;/h2&gt; 
&lt;p&gt;Each lesson in this guide includes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clear explanations of MCP concepts&lt;/li&gt; 
 &lt;li&gt;Live code examples in multiple languages&lt;/li&gt; 
 &lt;li&gt;Exercises to build real MCP applications&lt;/li&gt; 
 &lt;li&gt;Extra resources for advanced learners&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üåü Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to Microsoft Valued Professional &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples.&lt;/p&gt; 
&lt;h2&gt;üìú License Information&lt;/h2&gt; 
&lt;p&gt;This content is licensed under the &lt;strong&gt;MIT License&lt;/strong&gt;. For terms and conditions, see the &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contribution Guidelines&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;üìÇ Repository Structure&lt;/h2&gt; 
&lt;p&gt;The repository is organized as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Curriculum (00-10)&lt;/strong&gt;: The main content organized in ten sequential modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;images/&lt;/strong&gt;: Diagrams and illustrations used throughout the curriculum&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translations/&lt;/strong&gt;: Multi-language support with automated translations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translated_images/&lt;/strong&gt;: Localized versions of diagrams and illustrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;study_guide.md&lt;/strong&gt;: Comprehensive guide to navigating the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;changelog.md&lt;/strong&gt;: Record of all significant changes to the curriculum materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mcp.json&lt;/strong&gt;: Configuration file for MCP specification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CODE_OF_CONDUCT.md, LICENSE, SECURITY.md, SUPPORT.md&lt;/strong&gt;: Project governance documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéí Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚Ñ¢Ô∏è Trademark Notice&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stanford-cs336/spring2025-lectures</title>
      <link>https://github.com/stanford-cs336/spring2025-lectures</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Spring 2025 CS336 lectures&lt;/h1&gt; 
&lt;p&gt;This repo contains the lecture materials for "Stanford CS336: Language modeling from scratch".&lt;/p&gt; 
&lt;h2&gt;Non-executable (ppt/pdf) lectures&lt;/h2&gt; 
&lt;p&gt;Located in &lt;code&gt;nonexecutable/&lt;/code&gt;as PDFs&lt;/p&gt; 
&lt;h2&gt;Executable lectures&lt;/h2&gt; 
&lt;p&gt;Located as &lt;code&gt;lecture_*.py&lt;/code&gt; in the root directory&lt;/p&gt; 
&lt;p&gt;You can compile a lecture by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    python execute.py -m lecture_01
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;which generates a &lt;code&gt;var/traces/lecture_01.json&lt;/code&gt; and caches any images as appropriate.&lt;/p&gt; 
&lt;p&gt;However, if you want to run it on the cluster, you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    ./remote_execute.sh lecture_01
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;which copies the files to our slurm cluster, runs it there, and copies the results back. You have to setup the appropriate environment and tweak some configs to make this work (these instructions are not complete).&lt;/p&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;p&gt;If you need to tweak the Javascript:&lt;/p&gt; 
&lt;p&gt;Install (one-time):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    npm create vite@latest trace-viewer -- --template react
    cd trace-viewer
    npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Load a local server to view at &lt;code&gt;http://localhost:5173?trace=var/traces/sample.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Deploy to the main website:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    cd trace-viewer
    npm run build
    git add dist/assets
    # then commit to the repo and it should show up on the website
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>souzatharsis/podcastfy</title>
      <link>https://github.com/souzatharsis/podcastfy</link>
      <description>&lt;p&gt;An Open Source Python alternative to NotebookLM's podcast feature: Transforming Multimodal Content into Captivating Multilingual Audio Conversations with GenAI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12965" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12965" alt="Podcastfy.ai | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Podcastfy.ai üéôÔ∏èü§ñ&lt;/h1&gt; 
 &lt;p&gt;An Open Source API alternative to NotebookLM's podcast feature: Transforming Multimodal Content into Captivating Multilingual Audio Conversations with GenAI&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5d42c106-aabe-44c1-8498-e9c53545ba40"&gt;https://github.com/user-attachments/assets/5d42c106-aabe-44c1-8498-e9c53545ba40&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/souzatharsis/podcastfy/raw/main/paper/paper.pdf"&gt;Paper&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/raw/59563ee105a0d1dbb46744e0ff084471670dd725/podcastfy.ipynb"&gt;Python Package&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/raw/59563ee105a0d1dbb46744e0ff084471670dd725/usage/cli.md"&gt;CLI&lt;/a&gt; | &lt;a href="https://openpod.fly.dev/"&gt;Web App&lt;/a&gt; | &lt;a href="https://github.com/souzatharsis/podcastfy/issues"&gt;Feedback&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/souzatharsis/podcastfy/blob/main/podcastfy.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/podcastfy/"&gt;&lt;img src="https://img.shields.io/pypi/v/podcastfy" alt="PyPi Status"&gt;&lt;/a&gt; &lt;img src="https://static.pepy.tech/badge/podcastfy" alt="PyPI Downloads"&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/issues"&gt;&lt;img src="https://img.shields.io/github/issues-raw/souzatharsis/podcastfy" alt="Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/actions/workflows/python-app.yml"&gt;&lt;img src="https://github.com/souzatharsis/podcastfy/actions/workflows/python-app.yml/badge.svg?sanitize=true" alt="Pytest"&gt;&lt;/a&gt; &lt;a href="https://github.com/souzatharsis/podcastfy/actions/workflows/docker-publish.yml"&gt;&lt;img src="https://github.com/souzatharsis/podcastfy/actions/workflows/docker-publish.yml/badge.svg?sanitize=true" alt="Docker"&gt;&lt;/a&gt; &lt;a href="https://podcastfy.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/podcastfy/badge/?version=latest" alt="Documentation Status"&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/souzatharsis/podcastfy" alt="GitHub Repo stars"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Podcastfy is an open-source Python package that transforms multi-modal content (text, images) into engaging, multi-lingual audio conversations using GenAI. Input content includes websites, PDFs, images, YouTube videos, as well as user provided topics.&lt;/p&gt; 
&lt;p&gt;Unlike closed-source UI-based tools focused primarily on research synthesis (e.g. NotebookLM ‚ù§Ô∏è), Podcastfy focuses on open source, programmatic and bespoke generation of engaging, conversational content from a multitude of multi-modal sources, enabling customization and scale.&lt;/p&gt; 
&lt;h2&gt;Testimonials üí¨&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Love that you casually built an open source version of the most popular product Google built in the last decade"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Loving this initiative and the best I have seen so far especially for a 'non-techie' user."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Your library was very straightforward to work with. You did Amazing work brother üôè"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"I think it's awesome that you were inspired/recognize how hard it is to beat NotebookLM's quality, but you did an &lt;em&gt;incredible&lt;/em&gt; job with this! It sounds incredible, and it's open-source! Thank you for being amazing!"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=souzatharsis/podcastfy&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=souzatharsis/podcastfy&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Audio Examples üîä&lt;/h2&gt; 
&lt;p&gt;This sample collection was generated using this &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/examples.ipynb"&gt;Python Notebook&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;Sample 1: Senecio, 1922 (Paul Klee) and Connection of Civilizations (2017) by Gheorghe Virtosu&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/Senecio.jpeg" alt="Senecio, 1922 (Paul Klee)" width="20%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/connection.jpg" alt="Connection of Civilizations (2017) by Gheorghe Virtosu " width="21.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/a4134a0d-138c-4ab4-bc70-0f53b3507e6b"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Sample 2: The Great Wave off Kanagawa, 1831 (Hokusai) and Takiyasha the Witch and the Skeleton Spectre, c. 1844 (Kuniyoshi)&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/japan_1.jpg" alt="The Great Wave off Kanagawa, 1831 (Hokusai)" width="20%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/japan2.jpg" alt="Takiyasha the Witch and the Skeleton Spectre, c. 1844 (Kuniyoshi)" width="21.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/f6aaaeeb-39d2-4dde-afaf-e2cd212e9fed"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;Sample 3: Pop culture icon Taylor Swift and Mona Lisa, 1503 (Leonardo da Vinci)&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/taylor.png" alt="Taylor Swift" width="28%" height="auto"&gt; &lt;img src="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/data/images/monalisa.jpeg" alt="Mona Lisa" width="10.5%" height="auto"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/3b6f7075-159b-4540-946f-3f3907dffbca"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h3&gt;Text&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Audio&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;video src="https://github.com/user-attachments/assets/ef41a207-a204-4b60-a11e-06d66a0fbf06"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td&gt;Personal Website&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.souzatharsis.com"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://soundcloud.com/high-lander123/amodei?in=high-lander123/sets/podcastfy-sample-audio-longform&amp;amp;si=b8dfaf4e3ddc4651835e277500384156"&gt;Audio&lt;/a&gt; (&lt;code&gt;longform=True&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;Lex Fridman Podcast: 5h interview with Dario Amodei Anthropic's CEO&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=ugvHCXCOmm4"&gt;Youtube&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://soundcloud.com/high-lander123/benjamin?in=high-lander123/sets/podcastfy-sample-audio-longform&amp;amp;si=dca7e2eec1c94252be18b8794499959a&amp;amp;utm_source=clipboard&amp;amp;utm_medium=text&amp;amp;utm_campaign=social_sharing"&gt;Audio&lt;/a&gt; (&lt;code&gt;longform=True&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;Benjamin Franklin's Autobiography&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gutenberg.org/cache/epub/148/pg148.txt"&gt;Book&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Multi-Lingual Text&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Content Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Audio&lt;/th&gt; 
   &lt;th&gt;Source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French&lt;/td&gt; 
   &lt;td&gt;Website&lt;/td&gt; 
   &lt;td&gt;Agroclimate research information&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://audio.com/thatupiso/audio/podcast-fr-agro"&gt;Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://agroclim.inrae.fr/"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese-BR&lt;/td&gt; 
   &lt;td&gt;News Article&lt;/td&gt; 
   &lt;td&gt;Election polls in S√£o Paulo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://audio.com/thatupiso/audio/podcast-thatupiso-br"&gt;Audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://noticias.uol.com.br/eleicoes/2024/10/03/nova-pesquisa-datafolha-quem-subiu-e-quem-caiu-na-disputa-de-sp-03-10.htm"&gt;Website&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart üíª&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$ pip install ffmpeg&lt;/code&gt; (for audio processing)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install from PyPI &lt;code&gt;$ pip install podcastfy&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set up your &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/config.md"&gt;API keys&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from podcastfy.client import generate_podcast

audio_file = generate_podcast(urls=["&amp;lt;url1&amp;gt;", "&amp;lt;url2&amp;gt;"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;python -m podcastfy.client --url &amp;lt;url1&amp;gt; --url &amp;lt;url2&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fastapi (Beta for urls)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Containerize podcastify and launch the api
Dockerfile_api

Make requests to the api look at the notebook for a clear example
fetch_audio(request_data, ENDPOINT, BASE_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage üíª&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/podcastfy.ipynb"&gt;Python Package Quickstart&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/how-to.md"&gt;How to&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://podcastfy.readthedocs.io/en/latest/podcastfy.html"&gt;Python Package Reference Manual&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/cli.md"&gt;CLI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Customization üîß&lt;/h2&gt; 
&lt;p&gt;Podcastfy offers a range of customization options to tailor your AI-generated podcasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Customize podcast &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/conversation_custom.md"&gt;conversation&lt;/a&gt; (e.g. format, style, voices)&lt;/li&gt; 
 &lt;li&gt;Choose to run &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/local_llm.md"&gt;Local LLMs&lt;/a&gt; (156+ HuggingFace models)&lt;/li&gt; 
 &lt;li&gt;Set other &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/config.md"&gt;Configuration Settings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features ‚ú®&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate conversational content from multiple sources and formats (images, text, websites, YouTube, and PDFs).&lt;/li&gt; 
 &lt;li&gt;Generate shorts (2-5 minutes) or longform (30+ minutes) podcasts.&lt;/li&gt; 
 &lt;li&gt;Customize transcript and audio generation (e.g., style, language, structure).&lt;/li&gt; 
 &lt;li&gt;Generate transcripts using 100+ LLM models (OpenAI, Anthropic, Google etc).&lt;/li&gt; 
 &lt;li&gt;Leverage local LLMs for transcript generation for increased privacy and control.&lt;/li&gt; 
 &lt;li&gt;Integrate with advanced text-to-speech models (OpenAI, Google, ElevenLabs, and Microsoft Edge).&lt;/li&gt; 
 &lt;li&gt;Provide multi-language support for global content creation.&lt;/li&gt; 
 &lt;li&gt;Integrate seamlessly with CLI and Python packages for automated workflows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built with Podcastfy üöÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.open-notebook.ai/"&gt;OpenNotebook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.surfsense.net/"&gt;SurfSense&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openpod.fly.dev/"&gt;OpenPod&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evandempsey/podcast-llm"&gt;Podcast-llm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/thatupiso/Podcastfy.ai_demo"&gt;Podcastfy-HuggingFace App&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Updates üöÄüöÄ&lt;/h2&gt; 
&lt;h3&gt;v0.4.0+ release&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Released new Multi-Speaker TTS model (is it the one NotebookLM uses?!?)&lt;/li&gt; 
 &lt;li&gt;Generate short or longform podcasts&lt;/li&gt; 
 &lt;li&gt;Generate podcasts from input topic using grounded real-time web search&lt;/li&gt; 
 &lt;li&gt;Integrate with 100+ LLM models (OpenAI, Anthropic, Google etc) for transcript generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This software is licensed under &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/LICENSE"&gt;Apache 2.0&lt;/a&gt;. See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/usage/license-guide.md"&gt;instructions&lt;/a&gt; if you would like to use podcastfy in your software.&lt;/p&gt; 
&lt;h2&gt;Contributing ü§ù&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/GUIDELINES.md"&gt;Guidelines&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Example Use Cases üéßüé∂&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Content Creators&lt;/strong&gt; can use &lt;code&gt;Podcastfy&lt;/code&gt; to convert blog posts, articles, or multimedia content into podcast-style audio, enabling them to reach broader audiences. By transforming content into an audio format, creators can cater to users who prefer listening over reading.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Educators&lt;/strong&gt; can transform lecture notes, presentations, and visual materials into audio conversations, making educational content more accessible to students with different learning preferences. This is particularly beneficial for students with visual impairments or those who have difficulty processing written information.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Researchers&lt;/strong&gt; can convert research papers, visual data, and technical content into conversational audio. This makes it easier for a wider audience, including those with disabilities, to consume and understand complex scientific information. Researchers can also create audio summaries of their work to enhance accessibility.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accessibility Advocates&lt;/strong&gt; can use &lt;code&gt;Podcastfy&lt;/code&gt; to promote digital accessibility by providing a tool that converts multimodal content into auditory formats. This helps individuals with visual impairments, dyslexia, or other disabilities that make it challenging to consume written or visual content.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/souzatharsis/podcastfy/graphs/contributors"&gt; &lt;img alt="contributors" src="https://contrib.rocks/image?repo=souzatharsis/podcastfy"&gt; &lt;/a&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/souzatharsis/podcastfy/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; ‚Üë Back to Top ‚Üë &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tautulli/Tautulli</title>
      <link>https://github.com/Tautulli/Tautulli</link>
      <description>&lt;p&gt;A Python based monitoring and tracking tool for Plex Media Server.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tautulli&lt;/h1&gt; 
&lt;p&gt;A python based web application for monitoring, analytics and notifications for &lt;a href="https://plex.tv"&gt;Plex Media Server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is based on code from &lt;a href="https://github.com/rembo10/headphones"&gt;Headphones&lt;/a&gt; and &lt;a href="https://github.com/ecleese/plexWatchWeb"&gt;PlexWatchWeb&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Responsive web design viewable on desktop, tablet and mobile web browsers.&lt;/li&gt; 
 &lt;li&gt;Themed to complement Plex/Web.&lt;/li&gt; 
 &lt;li&gt;Easy configuration setup (no separate web server required).&lt;/li&gt; 
 &lt;li&gt;Monitor current Plex Media Server activity.&lt;/li&gt; 
 &lt;li&gt;Fully customizable notifications for stream activity and recently added media.&lt;/li&gt; 
 &lt;li&gt;Top statistics on home page with configurable duration and measurement metric.&lt;/li&gt; 
 &lt;li&gt;Global watching history with search/filtering &amp;amp; dynamic column sorting.&lt;/li&gt; 
 &lt;li&gt;Full user list with general information and comparison stats.&lt;/li&gt; 
 &lt;li&gt;Individual user information including devices IP addresses.&lt;/li&gt; 
 &lt;li&gt;Complete library statistics and media file information.&lt;/li&gt; 
 &lt;li&gt;Rich analytics presented using Highcharts graphing.&lt;/li&gt; 
 &lt;li&gt;Beautiful content information pages.&lt;/li&gt; 
 &lt;li&gt;Full sync list data on all users syncing items from your library.&lt;/li&gt; 
 &lt;li&gt;And many more!!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://tautulli.com"&gt;Full preview gallery available on our website&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://tautulli.com/images/screenshots/activity-compressed.jpg?v=2" alt="Tautulli Homepage"&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://python.org/downloads"&gt;&lt;img src="https://img.shields.io/badge/python-%3E=3.9-blue?style=flat-square" alt="Python"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tautulli/tautulli"&gt;&lt;img src="https://img.shields.io/docker/pulls/tautulli/tautulli?style=flat-square" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tautulli/tautulli"&gt;&lt;img src="https://img.shields.io/docker/stars/tautulli/tautulli?style=flat-square" alt="Docker Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/Tautulli/Tautulli/releases/latest"&gt;&lt;img src="https://img.shields.io/github/downloads/Tautulli/Tautulli/total?style=flat-square" alt="Downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Branch: &lt;code&gt;master&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Branch: &lt;code&gt;beta&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Branch: &lt;code&gt;nightly&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Release&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?style=flat-square" alt="Release@master"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release-date/Tautulli/Tautulli?style=flat-square&amp;amp;color=blue" alt="Release Date@master"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?include_prereleases&amp;amp;style=flat-square" alt="Release@beta"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/commits/beta"&gt;&lt;img src="https://img.shields.io/github/commits-since/Tautulli/Tautulli/latest/beta?style=flat-square&amp;amp;color=blue" alt="Commits@beta"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/commits/nightly"&gt;&lt;img src="https://img.shields.io/github/last-commit/Tautulli/Tautulli/nightly?style=flat-square&amp;amp;color=blue" alt="Last Commits@nightly"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/commits/nightly"&gt;&lt;img src="https://img.shields.io/github/commits-since/Tautulli/Tautulli/latest/nightly?style=flat-square&amp;amp;color=blue" alt="Commits@nightly"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docker&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hub.docker.com/r/tautulli/tautulli"&gt;&lt;img src="https://img.shields.io/badge/docker-latest-blue?style=flat-square" alt="Docker@master"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Docker%22+branch%3Amaster"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-docker.yml?style=flat-square&amp;amp;branch=master" alt="Docker Build@master"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hub.docker.com/r/tautulli/tautulli"&gt;&lt;img src="https://img.shields.io/badge/docker-beta-blue?style=flat-square" alt="Docker@beta"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Docker%22+branch%3Abeta"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-docker.yml?style=flat-square&amp;amp;branch=beta" alt="Docker Build@beta"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hub.docker.com/r/tautulli/tautulli"&gt;&lt;img src="https://img.shields.io/badge/docker-nightly-blue?style=flat-square" alt="Docker@nightly"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Docker%22+branch%3Anightly"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-docker.yml?style=flat-square&amp;amp;branch=nightly" alt="Docker Build@nightly"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Snap&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://snapcraft.io/tautulli"&gt;&lt;img src="https://img.shields.io/badge/snap-stable-blue?style=flat-square" alt="Snap@master"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Snap%22+branch%3Amaster"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-snap.yml?style=flat-square&amp;amp;branch=master" alt="Snap Build@master"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://snapcraft.io/tautulli"&gt;&lt;img src="https://img.shields.io/badge/snap-beta-blue?style=flat-square" alt="Snap@beta"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Snap%22+branch%3Abeta"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-snap.yml?style=flat-square&amp;amp;branch=beta" alt="Snap Build@beta"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://snapcraft.io/tautulli"&gt;&lt;img src="https://img.shields.io/badge/snap-edge-blue?style=flat-square" alt="Snap@nightly"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Snap%22+branch%3Anightly"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-snap.yml?style=flat-square&amp;amp;branch=nightly" alt="Snap Build@nightly"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Installer&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?label=windows&amp;amp;style=flat-square" alt="Windows@master"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?label=macos&amp;amp;style=flat-square" alt="MacOS@master"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Installers%22+branch%3Amaster"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-installers.yml?style=flat-square&amp;amp;branch=master" alt="Installer Build@master"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?label=windows&amp;amp;include_prereleases&amp;amp;style=flat-square" alt="Windows@beta"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/Tautulli/Tautulli?label=macos&amp;amp;include_prereleases&amp;amp;style=flat-square" alt="MacOS@beta"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Installers%22+branch%3Abeta"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-installers.yml?style=flat-square&amp;amp;branch=beta" alt="Installer Build@beta"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Tautulli/Tautulli/actions?query=workflow%3A%22Publish+Installers%22+branch%3Anightly"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/Tautulli/Tautulli/.github/workflows/publish-installers.yml?style=flat-square&amp;amp;branch=nightly" alt="Installer Build@nightly"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Read the &lt;a href="https://github.com/Tautulli/Tautulli/wiki/Installation"&gt;Installation Guides&lt;/a&gt; for instructions on how to install Tautulli.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tautulli/Tautulli/wiki"&gt;&lt;img src="https://img.shields.io/badge/github-wiki-black?style=flat-square" alt="Wiki"&gt;&lt;/a&gt; &lt;a href="https://tautulli.com/discord"&gt;&lt;img src="https://img.shields.io/discord/183396325142822912?label=discord&amp;amp;style=flat-square&amp;amp;color=7289DA" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://reddit.com/r/Tautulli"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/tautulli?label=reddit&amp;amp;style=flat-square&amp;amp;color=FF5700" alt="Reddit"&gt;&lt;/a&gt; &lt;a href="https://forums.plex.tv/t/tautulli-monitor-your-plex-media-server/225242"&gt;&lt;img src="https://img.shields.io/badge/plex%20forums-discussion-E5A00D?style=flat-square" alt="Plex Forums"&gt;&lt;/a&gt; &lt;a href="https://github.com/Tautulli/Tautulli/issues"&gt;&lt;img src="https://img.shields.io/badge/github-issues-black?style=flat-square" alt="Issues"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you think you've found a bug in Tautulli make sure you have read the &lt;a href="https://github.com/Tautulli/Tautulli/wiki/Frequently-Asked-Questions"&gt;FAQ&lt;/a&gt; first to make sure it hasn't been covered by one of the questions there. If your problem isn't answered in the FAQ try the following first:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Update to the latest version of Tautulli.&lt;/li&gt; 
 &lt;li&gt;Turning your device off and on again.&lt;/li&gt; 
 &lt;li&gt;Analyzing your logs, you just might find the solution yourself!&lt;/li&gt; 
 &lt;li&gt;Using the &lt;strong&gt;search&lt;/strong&gt; function to see if this issue has already been reported/solved.&lt;/li&gt; 
 &lt;li&gt;Checking the &lt;a href="https://github.com/Tautulli/Tautulli/wiki"&gt;Wiki&lt;/a&gt; for &lt;a href="https://github.com/Tautulli/Tautulli/wiki/Installation"&gt;Installation&lt;/a&gt; instructions and reading the &lt;a href="https://github.com/Tautulli/Tautulli/wiki/Frequently-Asked-Questions"&gt;FAQs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For basic questions try asking on &lt;a href="https://tautulli.com/discord"&gt;Discord&lt;/a&gt;, &lt;a href="https://reddit.com/r/Tautulli"&gt;Reddit&lt;/a&gt;, or the &lt;a href="https://forums.plex.tv/t/tautulli-monitor-your-plex-media-server/225242"&gt;Plex Forums&lt;/a&gt; first before opening an issue.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;If nothing has worked:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Please check the &lt;a href="https://github.com/Tautulli/Tautulli/issues"&gt;issues tracker&lt;/a&gt; to see if someone else has already reported the bug.&lt;/li&gt; 
 &lt;li&gt;If this is a new bug, open a &lt;a href="https://github.com/Tautulli/Tautulli/issues/new/choose"&gt;bug report&lt;/a&gt; on the issues tracker.&lt;/li&gt; 
 &lt;li&gt;Provide a clear title to easily help identify your problem.&lt;/li&gt; 
 &lt;li&gt;Use proper &lt;a href="https://help.github.com/articles/github-flavored-markdown"&gt;Markdown syntax&lt;/a&gt; to structure your post (i.e. code/log in code blocks).&lt;/li&gt; 
 &lt;li&gt;Make sure to fill out the required information on the issue template.&lt;/li&gt; 
 &lt;li&gt;Close your issue when it's solved! If you found the solution yourself please comment so that others benefit from it.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pleases check the &lt;a href="https://github.com/Tautulli/Tautulli/issues"&gt;issues tracker&lt;/a&gt; to see if someone else has already requested the feature. If a similar idea has already been requested, &lt;em&gt;give it a thumbs up&lt;/em&gt;. &lt;strong&gt;Do not comment with &lt;code&gt;+1&lt;/code&gt; or something similar as it creates unnecessary spam.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;If this is a new feature request, open a &lt;a href="https://github.com/Tautulli/Tautulli/issues/new/choose"&gt;feature request&lt;/a&gt; on the issues tracker.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tautulli/Tautulli/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/Tautulli/Tautulli?style=flat-square" alt="License"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This is free software under the GPL v3 open source license. Feel free to do with it what you wish, but any modification must be open sourced. A copy of the license is included.&lt;/p&gt; 
&lt;p&gt;This software includes Highsoft software libraries which you may freely distribute for non-commercial use. Commercial users must licence this software, for more information visit &lt;a href="https://shop.highsoft.com/faq/non-commercial#non-commercial-redistribution"&gt;https://shop.highsoft.com/faq/non-commercial#non-commercial-redistribution&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>