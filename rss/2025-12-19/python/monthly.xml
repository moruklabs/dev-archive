<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Thu, 18 Dec 2025 01:52:38 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;ğŸ“š ã€Šä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ã€‹â€”â€”ä»é›¶å¼€å§‹çš„æ™ºèƒ½ä½“åŸç†ä¸å®è·µæ•™ç¨‹&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ä¸­æ–‡ 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ğŸ¤– ã€Šä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ã€‹&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/15520" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15520" alt="datawhalechina%2Fhello-agents | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;em&gt;ä»åŸºç¡€ç†è®ºåˆ°å®é™…åº”ç”¨ï¼Œå…¨é¢æŒæ¡æ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/åœ¨çº¿é˜…è¯»-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¯ é¡¹ç›®ä»‹ç»&lt;/h2&gt; 
&lt;p&gt;â€ƒâ€ƒå¦‚æœè¯´ 2024 å¹´æ˜¯"ç™¾æ¨¡å¤§æˆ˜"çš„å…ƒå¹´ï¼Œé‚£ä¹ˆ 2025 å¹´æ— ç–‘å¼€å¯äº†"Agent å…ƒå¹´"ã€‚æŠ€æœ¯çš„ç„¦ç‚¹æ­£ä»è®­ç»ƒæ›´å¤§çš„åŸºç¡€æ¨¡å‹ï¼Œè½¬å‘æ„å»ºæ›´èªæ˜çš„æ™ºèƒ½ä½“åº”ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰ç³»ç»Ÿæ€§ã€é‡å®è·µçš„æ•™ç¨‹å´æåº¦åŒ®ä¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘èµ·äº† Hello-Agents é¡¹ç›®ï¼Œå¸Œæœ›èƒ½ä¸ºç¤¾åŒºæä¾›ä¸€æœ¬ä»é›¶å¼€å§‹ã€ç†è®ºä¸å®æˆ˜å¹¶é‡çš„æ™ºèƒ½ä½“ç³»ç»Ÿæ„å»ºæŒ‡å—ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒHello-Agents æ˜¯ Datawhale ç¤¾åŒºçš„&lt;strong&gt;ç³»ç»Ÿæ€§æ™ºèƒ½ä½“å­¦ä¹ æ•™ç¨‹&lt;/strong&gt;ã€‚å¦‚ä»Š Agent æ„å»ºä¸»è¦åˆ†ä¸ºä¸¤æ´¾ï¼Œä¸€æ´¾æ˜¯ Difyï¼ŒCozeï¼Œn8n è¿™ç±»è½¯ä»¶å·¥ç¨‹ç±» Agentï¼Œå…¶æœ¬è´¨æ˜¯æµç¨‹é©±åŠ¨çš„è½¯ä»¶å¼€å‘ï¼ŒLLM ä½œä¸ºæ•°æ®å¤„ç†çš„åç«¯ï¼›å¦ä¸€æ´¾åˆ™æ˜¯ AI åŸç”Ÿçš„ Agentï¼Œå³çœŸæ­£ä»¥ AI é©±åŠ¨çš„ Agentã€‚æœ¬æ•™ç¨‹æ—¨åœ¨å¸¦é¢†å¤§å®¶æ·±å…¥ç†è§£å¹¶æ„å»ºåè€…â€”â€”çœŸæ­£çš„ AI Native Agentã€‚æ•™ç¨‹å°†å¸¦é¢†ä½ ç©¿é€æ¡†æ¶è¡¨è±¡ï¼Œä»æ™ºèƒ½ä½“çš„æ ¸å¿ƒåŸç†å‡ºå‘ï¼Œæ·±å…¥å…¶æ ¸å¿ƒæ¶æ„ï¼Œç†è§£å…¶ç»å…¸èŒƒå¼ï¼Œå¹¶æœ€ç»ˆäº²æ‰‹æ„å»ºèµ·å±äºè‡ªå·±çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ€å¥½çš„å­¦ä¹ æ–¹å¼å°±æ˜¯åŠ¨æ‰‹å®è·µã€‚å¸Œæœ›è¿™æœ¬æ•™ç¨‹èƒ½æˆä¸ºä½ æ¢ç´¢æ™ºèƒ½ä½“ä¸–ç•Œçš„èµ·ç‚¹ï¼Œèƒ½å¤Ÿä»ä¸€åå¤§è¯­è¨€æ¨¡å‹çš„"ä½¿ç”¨è€…"ï¼Œèœ•å˜ä¸ºä¸€åæ™ºèƒ½ä½“ç³»ç»Ÿçš„"æ„å»ºè€…"ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ“š å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;h3&gt;åœ¨çº¿é˜…è¯»&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;ğŸŒ ç‚¹å‡»è¿™é‡Œå¼€å§‹åœ¨çº¿é˜…è¯»&lt;/a&gt;&lt;/strong&gt; - æ— éœ€ä¸‹è½½ï¼Œéšæ—¶éšåœ°å­¦ä¹ &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;ğŸ“– Cookbook(æµ‹è¯•ç‰ˆ)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;æœ¬åœ°é˜…è¯»&lt;/h3&gt; 
&lt;p&gt;å¦‚æœæ‚¨å¸Œæœ›åœ¨æœ¬åœ°é˜…è¯»æˆ–è´¡çŒ®å†…å®¹ï¼Œè¯·å‚è€ƒä¸‹æ–¹çš„å­¦ä¹ æŒ‡å—ã€‚&lt;/p&gt; 
&lt;h3&gt;âœ¨ ä½ å°†æ”¶è·ä»€ä¹ˆï¼Ÿ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Datawhale å¼€æºå…è´¹&lt;/strong&gt; å®Œå…¨å…è´¹å­¦ä¹ æœ¬é¡¹ç›®æ‰€æœ‰å†…å®¹ï¼Œä¸ç¤¾åŒºå…±åŒæˆé•¿&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;ç†è§£æ ¸å¿ƒåŸç†&lt;/strong&gt; æ·±å…¥ç†è§£æ™ºèƒ½ä½“çš„æ¦‚å¿µã€å†å²ä¸ç»å…¸èŒƒå¼&lt;/li&gt; 
 &lt;li&gt;ğŸ—ï¸ &lt;strong&gt;äº²æ‰‹å®ç°&lt;/strong&gt; æŒæ¡çƒ­é—¨ä½ä»£ç å¹³å°å’Œæ™ºèƒ½ä½“ä»£ç æ¡†æ¶çš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ &lt;strong&gt;è‡ªç ”æ¡†æ¶&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; åŸºäº Openai åŸç”Ÿ API ä»é›¶æ„å»ºä¸€ä¸ªè‡ªå·±çš„æ™ºèƒ½ä½“æ¡†æ¶&lt;/li&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;æŒæ¡é«˜çº§æŠ€èƒ½&lt;/strong&gt; ä¸€æ­¥æ­¥å®ç°ä¸Šä¸‹æ–‡å·¥ç¨‹ã€Memoryã€åè®®ã€è¯„ä¼°ç­‰ç³»ç»Ÿæ€§æŠ€æœ¯&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ &lt;strong&gt;æ¨¡å‹è®­ç»ƒ&lt;/strong&gt; æŒæ¡ Agentic RLï¼Œä» SFT åˆ° GRPO çš„å…¨æµç¨‹å®æˆ˜è®­ç»ƒ LLM&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;é©±åŠ¨çœŸå®æ¡ˆä¾‹&lt;/strong&gt; å®æˆ˜å¼€å‘æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€èµ›åšå°é•‡ç­‰ç»¼åˆé¡¹ç›®&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;æ±‚èŒé¢è¯•&lt;/strong&gt; å­¦ä¹ æ™ºèƒ½ä½“æ±‚èŒç›¸å…³é¢è¯•é—®é¢˜&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“– å†…å®¹å¯¼èˆª&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç« èŠ‚&lt;/th&gt; 
   &lt;th&gt;å…³é”®å†…å®¹&lt;/th&gt; 
   &lt;th&gt;çŠ¶æ€&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;å‰è¨€&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;é¡¹ç›®çš„ç¼˜èµ·ã€èƒŒæ™¯åŠè¯»è€…å»ºè®®&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬ä¸€éƒ¨åˆ†ï¼šæ™ºèƒ½ä½“ä¸è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;ç¬¬ä¸€ç«  åˆè¯†æ™ºèƒ½ä½“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ™ºèƒ½ä½“å®šä¹‰ã€ç±»å‹ã€èŒƒå¼ä¸åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;ç¬¬äºŒç«  æ™ºèƒ½ä½“å‘å±•å²&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä»ç¬¦å·ä¸»ä¹‰åˆ° LLM é©±åŠ¨çš„æ™ºèƒ½ä½“æ¼”è¿›&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;ç¬¬ä¸‰ç«  å¤§è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformerã€æç¤ºã€ä¸»æµ LLM åŠå…¶å±€é™&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºä½ çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;ç¬¬å››ç«  æ™ºèƒ½ä½“ç»å…¸èŒƒå¼æ„å»º&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ‰‹æŠŠæ‰‹å®ç° ReActã€Plan-and-Solveã€Reflection&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;ç¬¬äº”ç«  åŸºäºä½ä»£ç å¹³å°çš„æ™ºèƒ½ä½“æ­å»º&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;äº†è§£ Cozeã€Difyã€n8n ç­‰ä½ä»£ç æ™ºèƒ½ä½“å¹³å°ä½¿ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;ç¬¬å…­ç«  æ¡†æ¶å¼€å‘å®è·µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGenã€AgentScopeã€LangGraph ç­‰ä¸»æµæ¡†æ¶åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;ç¬¬ä¸ƒç«  æ„å»ºä½ çš„Agentæ¡†æ¶&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä» 0 å¼€å§‹æ„å»ºæ™ºèƒ½ä½“æ¡†æ¶&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§çŸ¥è¯†æ‰©å±•&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;ç¬¬å…«ç«  è®°å¿†ä¸æ£€ç´¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;è®°å¿†ç³»ç»Ÿï¼ŒRAGï¼Œå­˜å‚¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;ç¬¬ä¹ç«  ä¸Šä¸‹æ–‡å·¥ç¨‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æŒç»­äº¤äº’çš„"æƒ…å¢ƒç†è§£"&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;ç¬¬åç«  æ™ºèƒ½ä½“é€šä¿¡åè®®&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCPã€A2Aã€ANP ç­‰åè®®è§£æ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;ç¬¬åä¸€ç«  Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä» SFT åˆ° GRPO çš„ LLM è®­ç»ƒå®æˆ˜&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;ç¬¬åäºŒç«  æ™ºèƒ½ä½“æ€§èƒ½è¯„ä¼°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ ¸å¿ƒæŒ‡æ ‡ã€åŸºå‡†æµ‹è¯•ä¸è¯„ä¼°æ¡†æ¶&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬å››éƒ¨åˆ†ï¼šç»¼åˆæ¡ˆä¾‹è¿›é˜¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;ç¬¬åä¸‰ç«  æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ä¸å¤šæ™ºèƒ½ä½“åä½œçš„çœŸå®ä¸–ç•Œåº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;ç¬¬åå››ç«  è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent å¤ç°ä¸è§£æ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;ç¬¬åäº”ç«  æ„å»ºèµ›åšå°é•‡&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ä¸æ¸¸æˆçš„ç»“åˆï¼Œæ¨¡æ‹Ÿç¤¾ä¼šåŠ¨æ€&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬äº”éƒ¨åˆ†ï¼šæ¯•ä¸šè®¾è®¡åŠæœªæ¥å±•æœ›&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;ç¬¬åå…­ç«  æ¯•ä¸šè®¾è®¡&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ„å»ºå±äºä½ çš„å®Œæ•´å¤šæ™ºèƒ½ä½“åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ç¤¾åŒºè´¡çŒ®ç²¾é€‰ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;â€ƒâ€ƒæ¬¢è¿å¤§å®¶å°†åœ¨å­¦ä¹  Hello-Agents æˆ– Agent ç›¸å…³æŠ€æœ¯ä¸­çš„ç‹¬åˆ°è§è§£ã€å®è·µæ€»ç»“ï¼Œä»¥ PR çš„å½¢å¼è´¡çŒ®åˆ°ç¤¾åŒºç²¾é€‰ã€‚å¦‚æœæ˜¯ç‹¬ç«‹äºæ­£æ–‡çš„å†…å®¹ï¼Œä¹Ÿå¯ä»¥æŠ•ç¨¿è‡³ Extra-Chapterï¼&lt;strong&gt;æœŸå¾…ä½ çš„ç¬¬ä¸€æ¬¡è´¡çŒ®ï¼&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç¤¾åŒºç²¾é€‰&lt;/th&gt; 
   &lt;th&gt;å†…å®¹æ€»ç»“&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-Agenté¢è¯•é¢˜æ€»ç»“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent å²—ä½ç›¸å…³é¢è¯•é—®é¢˜&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-Agenté¢è¯•é¢˜ç­”æ¡ˆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ç›¸å…³é¢è¯•é—®é¢˜ç­”æ¡ˆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-ä¸Šä¸‹æ–‡å·¥ç¨‹å†…å®¹è¡¥å……&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä¸Šä¸‹æ–‡å·¥ç¨‹å†…å®¹æ‰©å±•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-Difyæ™ºèƒ½ä½“åˆ›å»ºä¿å§†çº§æ•™ç¨‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Difyæ™ºèƒ½ä½“åˆ›å»ºä¿å§†çº§æ•™ç¨‹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsè¯¾ç¨‹å¸¸è§é—®é¢˜&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Datawhaleè¯¾ç¨‹å¸¸è§é—®é¢˜&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ç‰ˆæœ¬ä¸‹è½½&lt;/h3&gt; 
&lt;p&gt;â€ƒâ€ƒ&lt;em&gt;&lt;strong&gt;æœ¬ Hello-Agents PDF æ•™ç¨‹å®Œå…¨å¼€æºå…è´¹ã€‚ä¸ºé˜²æ­¢å„ç±»è¥é”€å·åŠ æ°´å°åè´©å–ç»™å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆå­¦è€…ï¼Œæˆ‘ä»¬ç‰¹åœ°åœ¨ PDF æ–‡ä»¶ä¸­é¢„å…ˆæ·»åŠ äº†ä¸å½±å“é˜…è¯»çš„ Datawhale å¼€æºæ ‡å¿—æ°´å°ï¼Œæ•¬è¯·è°…è§£ï½&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF å›½å†…ä¸‹è½½åœ°å€ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ’¡ å¦‚ä½•å­¦ä¹ &lt;/h2&gt; 
&lt;p&gt;â€ƒâ€ƒæ¬¢è¿ä½ ï¼Œæœªæ¥çš„æ™ºèƒ½ç³»ç»Ÿæ„å»ºè€…ï¼åœ¨å¼€å¯è¿™æ®µæ¿€åŠ¨äººå¿ƒçš„æ—…ç¨‹ä¹‹å‰ï¼Œè¯·å…è®¸æˆ‘ä»¬ç»™ä½ ä¸€äº›æ¸…æ™°çš„æŒ‡å¼•ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒæœ¬é¡¹ç›®å†…å®¹å…¼é¡¾ç†è®ºä¸å®æˆ˜ï¼Œæ—¨åœ¨å¸®åŠ©ä½ ç³»ç»Ÿæ€§åœ°æŒæ¡ä»å•ä¸ªæ™ºèƒ½ä½“åˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡ä¸å¼€å‘å…¨æµç¨‹ã€‚å› æ­¤ï¼Œå°¤å…¶é€‚åˆæœ‰ä¸€å®šç¼–ç¨‹åŸºç¡€çš„ &lt;strong&gt;AI å¼€å‘è€…ã€è½¯ä»¶å·¥ç¨‹å¸ˆã€åœ¨æ ¡å­¦ç”Ÿ&lt;/strong&gt; ä»¥åŠå¯¹å‰æ²¿ AI æŠ€æœ¯æŠ±æœ‰æµ“åšå…´è¶£çš„ &lt;strong&gt;è‡ªå­¦è€…&lt;/strong&gt;ã€‚åœ¨å­¦ä¹ æœ¬é¡¹ç›®ä¹‹å‰ï¼Œæˆ‘ä»¬å¸Œæœ›ä½ å…·å¤‡åŸºç¡€çš„ Python ç¼–ç¨‹èƒ½åŠ›ï¼Œå¹¶å¯¹å¤§è¯­è¨€æ¨¡å‹æœ‰åŸºæœ¬çš„æ¦‚å¿µæ€§äº†è§£ï¼ˆä¾‹å¦‚ï¼ŒçŸ¥é“å¦‚ä½•é€šè¿‡ API è°ƒç”¨ä¸€ä¸ª LLMï¼‰ã€‚é¡¹ç›®çš„é‡ç‚¹æ˜¯åº”ç”¨ä¸æ„å»ºï¼Œå› æ­¤ä½ æ— éœ€å…·å¤‡æ·±åšçš„ç®—æ³•æˆ–æ¨¡å‹è®­ç»ƒèƒŒæ™¯ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒé¡¹ç›®åˆ†ä¸ºäº”å¤§éƒ¨åˆ†ï¼Œæ¯ä¸€éƒ¨åˆ†éƒ½æ˜¯é€šå¾€ä¸‹ä¸€é˜¶æ®µçš„åšå®é˜¶æ¢¯ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬ä¸€éƒ¨åˆ†ï¼šæ™ºèƒ½ä½“ä¸è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/strong&gt;ï¼ˆç¬¬ä¸€ç« ï½ç¬¬ä¸‰ç« ï¼‰ï¼Œæˆ‘ä»¬å°†ä»æ™ºèƒ½ä½“çš„å®šä¹‰ã€ç±»å‹ä¸å‘å±•å†å²è®²èµ·ï¼Œä¸ºä½ æ¢³ç†"æ™ºèƒ½ä½“"è¿™ä¸€æ¦‚å¿µçš„æ¥é¾™å»è„‰ã€‚éšåï¼Œæˆ‘ä»¬ä¼šå¿«é€Ÿå·©å›ºå¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œä¸ºä½ çš„å®è·µä¹‹æ—…æ‰“ä¸‹åšå®çš„ç†è®ºåœ°åŸºã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºä½ çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“&lt;/strong&gt;ï¼ˆç¬¬å››ç« ï½ç¬¬ä¸ƒç« ï¼‰ï¼Œè¿™æ˜¯ä½ åŠ¨æ‰‹å®è·µçš„èµ·ç‚¹ã€‚ä½ å°†äº²æ‰‹å®ç° ReAct ç­‰ç»å…¸èŒƒå¼ï¼Œä½“éªŒ Coze ç­‰ä½ä»£ç å¹³å°çš„ä¾¿æ·ï¼Œå¹¶æŒæ¡ Langgraph ç­‰ä¸»æµæ¡†æ¶çš„åº”ç”¨ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬è¿˜ä¼šå¸¦ä½ ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå±äºè‡ªå·±çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œè®©ä½ å…¼å…·â€œç”¨è½®å­â€ä¸â€œé€ è½®å­â€çš„èƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§çŸ¥è¯†æ‰©å±•&lt;/strong&gt;ï¼ˆç¬¬å…«ç« ï½ç¬¬åäºŒç« ï¼‰ï¼Œåœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œä½ çš„æ™ºèƒ½ä½“å°†â€œå­¦ä¼šâ€æ€è€ƒä¸åä½œã€‚æˆ‘ä»¬å°†ä½¿ç”¨ç¬¬äºŒéƒ¨åˆ†çš„è‡ªç ”æ¡†æ¶ï¼Œæ·±å…¥æ¢ç´¢è®°å¿†ä¸æ£€ç´¢ã€ä¸Šä¸‹æ–‡å·¥ç¨‹ã€Agent è®­ç»ƒç­‰æ ¸å¿ƒæŠ€æœ¯ï¼Œå¹¶å­¦ä¹ å¤šæ™ºèƒ½ä½“é—´çš„é€šä¿¡åè®®ã€‚æœ€ç»ˆï¼Œä½ å°†æŒæ¡è¯„ä¼°æ™ºèƒ½ä½“ç³»ç»Ÿæ€§èƒ½çš„ä¸“ä¸šæ–¹æ³•ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬å››éƒ¨åˆ†ï¼šç»¼åˆæ¡ˆä¾‹è¿›é˜¶&lt;/strong&gt;ï¼ˆç¬¬åä¸‰ç« ï½ç¬¬åäº”ç« ï¼‰ï¼Œè¿™é‡Œæ˜¯ç†è®ºä¸å®è·µçš„äº¤æ±‡ç‚¹ã€‚ä½ å°†æŠŠæ‰€å­¦èä¼šè´¯é€šï¼Œäº²æ‰‹æ‰“é€ æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼Œä¹ƒè‡³ä¸€ä¸ªæ¨¡æ‹Ÿç¤¾ä¼šåŠ¨æ€çš„èµ›åšå°é•‡ï¼Œåœ¨çœŸå®æœ‰è¶£çš„é¡¹ç›®ä¸­æ·¬ç‚¼ä½ çš„æ„å»ºèƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬äº”éƒ¨åˆ†ï¼šæ¯•ä¸šè®¾è®¡åŠæœªæ¥å±•æœ›&lt;/strong&gt;ï¼ˆç¬¬åå…­ç« ï¼‰ï¼Œåœ¨æ—…ç¨‹çš„ç»ˆç‚¹ï¼Œä½ å°†è¿æ¥ä¸€ä¸ªæ¯•ä¸šè®¾è®¡ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„ã€å±äºä½ è‡ªå·±çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ï¼Œå…¨é¢æ£€éªŒä½ çš„å­¦ä¹ æˆæœã€‚æˆ‘ä»¬è¿˜å°†ä¸ä½ ä¸€åŒå±•æœ›æ™ºèƒ½ä½“çš„æœªæ¥ï¼Œæ¢ç´¢æ¿€åŠ¨äººå¿ƒçš„å‰æ²¿æ–¹å‘ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;â€ƒâ€ƒæ™ºèƒ½ä½“æ˜¯ä¸€ä¸ªé£é€Ÿå‘å±•ä¸”æåº¦ä¾èµ–å®è·µçš„é¢†åŸŸã€‚ä¸ºäº†è·å¾—æœ€ä½³çš„å­¦ä¹ æ•ˆæœï¼Œæˆ‘ä»¬åœ¨é¡¹ç›®çš„&lt;code&gt;code&lt;/code&gt;æ–‡ä»¶å¤¹å†…æä¾›äº†é…å¥—çš„å…¨éƒ¨ä»£ç ï¼Œå¼ºçƒˆå»ºè®®ä½ &lt;strong&gt;å°†ç†è®ºä¸å®è·µç›¸ç»“åˆ&lt;/strong&gt;ã€‚è¯·åŠ¡å¿…äº²æ‰‹è¿è¡Œã€è°ƒè¯•ç”šè‡³ä¿®æ”¹é¡¹ç›®é‡Œæä¾›çš„æ¯ä¸€ä»½ä»£ç ã€‚æ¬¢è¿ä½ éšæ—¶å…³æ³¨ Datawhale ä»¥åŠå…¶ä»– Agent ç›¸å…³ç¤¾åŒºï¼Œå½“é‡åˆ°é—®é¢˜æ—¶ï¼Œä½ å¯ä»¥éšæ—¶åœ¨æœ¬é¡¹ç›®çš„ issue åŒºæé—®ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒç°åœ¨ï¼Œå‡†å¤‡å¥½è¿›å…¥æ™ºèƒ½ä½“çš„å¥‡å¦™ä¸–ç•Œäº†å—ï¼Ÿè®©æˆ‘ä»¬å³åˆ»å¯ç¨‹ï¼&lt;/p&gt; 
&lt;h2&gt;ä¸‹ä¸€æ­¥è§„åˆ’&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[]è‹±æ–‡ç‰ˆæ•™ç¨‹&lt;/li&gt; 
 &lt;li&gt;[]åŒè¯­è§†é¢‘è¯¾ç¨‹[è‹±æ–‡+ä¸­æ–‡]ï¼ˆå°†ä¼šæ›´åŠ ç»†è‡´ï¼Œå®è·µè¯¾å¸¦é¢†å¤§å®¶ä»è®¾è®¡æ€è·¯åˆ°å®æ–½ï¼Œæˆäººä»¥é±¼ä¹Ÿæˆäººä»¥æ¸”ï¼‰&lt;/li&gt; 
 &lt;li&gt;[]å…±åˆ›ç¬¬16ç« ï¼ˆæ‰“é€ å„ç±»Agentåº”ç”¨,æ›´æ‰“é€ Agentç”Ÿæ€ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤ å¦‚ä½•è´¡çŒ®&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ˜¯ä¸€ä¸ªå¼€æ”¾çš„å¼€æºç¤¾åŒºï¼Œæ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;æŠ¥å‘Š Bug&lt;/strong&gt; - å‘ç°å†…å®¹æˆ–ä»£ç é—®é¢˜ï¼Œè¯·æäº¤ Issue&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;strong&gt;æå‡ºå»ºè®®&lt;/strong&gt; - å¯¹é¡¹ç›®æœ‰å¥½æƒ³æ³•ï¼Œæ¬¢è¿å‘èµ·è®¨è®º&lt;/li&gt; 
 &lt;li&gt;ğŸ“ &lt;strong&gt;å®Œå–„å†…å®¹&lt;/strong&gt; - å¸®åŠ©æ”¹è¿›æ•™ç¨‹ï¼Œæäº¤ä½ çš„ Pull Request&lt;/li&gt; 
 &lt;li&gt;âœï¸ &lt;strong&gt;åˆ†äº«å®è·µ&lt;/strong&gt; - åœ¨"ç¤¾åŒºè´¡çŒ®ç²¾é€‰"ä¸­åˆ†äº«ä½ çš„å­¦ä¹ ç¬”è®°å’Œé¡¹ç›®&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™ è‡´è°¢&lt;/h2&gt; 
&lt;h3&gt;æ ¸å¿ƒè´¡çŒ®è€…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;é™ˆæ€å·-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt; (Datawhale æˆå‘˜, å…¨æ–‡å†™ä½œå’Œæ ¡å¯¹)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;å­™éŸ¬-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt; (Datawhale æˆå‘˜, ç¬¬ä¹ç« å†…å®¹å’Œæ ¡å¯¹)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;å§œèˆ’å‡¡-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt;ï¼ˆDatawhale æˆå‘˜, ç« èŠ‚ä¹ é¢˜è®¾è®¡å’Œæ ¡å¯¹ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;é»„ä½©æ—-Datawhaleæ„å‘æˆå‘˜&lt;/a&gt; (Agent å¼€å‘å·¥ç¨‹å¸ˆ, ç¬¬äº”ç« å†…å®¹è´¡çŒ®è€…)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;æ›¾é‘«æ°‘-Agentå·¥ç¨‹å¸ˆ&lt;/a&gt; (ç‰›å®¢ç§‘æŠ€, ç¬¬åå››ç« æ¡ˆä¾‹å¼€å‘)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;æœ±ä¿¡å¿ -æŒ‡å¯¼ä¸“å®¶&lt;/a&gt; (Datawhaleé¦–å¸­ç§‘å­¦å®¶-æµ™æ±Ÿå¸ˆèŒƒå¤§å­¦æ­å·äººå·¥æ™ºèƒ½ç ”ç©¶é™¢æ•™æˆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter è´¡çŒ®è€…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (å†…å®¹è´¡çŒ®è€…)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;å‘¨å¥¥æ°-DWè´¡çŒ®è€…å›¢é˜Ÿ&lt;/a&gt; (è¥¿å®‰äº¤é€šå¤§å­¦, Extra02 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;å¼ å®¸æ—­-ä¸ªäººå¼€å‘è€…&lt;/a&gt;(å¸å›½ç†å·¥å­¦é™¢, Extra03 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;é»„å®æ™—-DWè´¡çŒ®è€…å›¢é˜Ÿ&lt;/a&gt; (æ·±åœ³å¤§å­¦, Extra04 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ç‰¹åˆ«æ„Ÿè°¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; å¯¹æœ¬é¡¹ç›®çš„å¸®åŠ©ä¸æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ä»¬ â¤ï¸&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-20251217.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;å…³äº Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;æ‰«æäºŒç»´ç å…³æ³¨ Datawhale å…¬ä¼—å·ï¼Œè·å–æ›´å¤šä¼˜è´¨å¼€æºå†…å®¹&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“œ å¼€æºåè®®&lt;/h2&gt; 
&lt;p&gt;æœ¬ä½œå“é‡‡ç”¨&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®&lt;/a&gt;è¿›è¡Œè®¸å¯ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apurvsinghgautam/robin</title>
      <link>https://github.com/apurvsinghgautam/robin</link>
      <description>&lt;p&gt;AI-Powered Dark Web OSINT Tool&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/.github/assets/logo.png" alt="Logo" width="300" /&gt; 
 &lt;br /&gt;
 &lt;a href="https://github.com/apurvsinghgautam/robin/actions/workflows/binary.yml"&gt;&lt;img alt="Build" src="https://github.com/apurvsinghgautam/robin/actions/workflows/binary.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/apurvsinghgautam/robin/releases"&gt;&lt;img alt="GitHub Release" src="https://img.shields.io/github/v/release/apurvsinghgautam/robin" /&gt;&lt;/a&gt; 
 &lt;a href="https://hub.docker.com/r/apurvsg/robin"&gt;&lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/apurvsg/robin" /&gt;&lt;/a&gt; 
 &lt;h1&gt;Robin: AI-Powered Dark Web OSINT Tool&lt;/h1&gt; 
 &lt;p&gt;Robin is an AI-powered tool for conducting dark web OSINT investigations. It leverages LLMs to refine queries, filter search results from dark web search engines, and provide an investigation summary.&lt;/p&gt; 
 &lt;a href="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/#installation"&gt;Installation&lt;/a&gt; â€¢ 
 &lt;a href="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/#usage"&gt;Usage&lt;/a&gt; â€¢ 
 &lt;a href="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/#contributing"&gt;Contributing&lt;/a&gt; â€¢ 
 &lt;a href="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/.github/assets/screen.png" alt="Demo" /&gt; &lt;img src="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/.github/assets/screen-ui.png" alt="Demo" /&gt; &lt;img src="https://raw.githubusercontent.com/apurvsinghgautam/robin/main/.github/assets/robin-workflow.png" alt="Workflow" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;Modular Architecture&lt;/strong&gt; â€“ Clean separation between search, scrape, and LLM workflows.&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Multi-Model Support&lt;/strong&gt; â€“ Easily switch between OpenAI, Claude, Gemini or local models like Ollama.&lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;strong&gt;CLI-First Design&lt;/strong&gt; â€“ Built for terminal warriors and automation ninjas.&lt;/li&gt; 
 &lt;li&gt;ğŸ³ &lt;strong&gt;Docker-Ready&lt;/strong&gt; â€“ Optional Docker deployment for clean, isolated usage.&lt;/li&gt; 
 &lt;li&gt;ğŸ“ &lt;strong&gt;Custom Reporting&lt;/strong&gt; â€“ Save investigation output to file for reporting or further analysis.&lt;/li&gt; 
 &lt;li&gt;ğŸ§© &lt;strong&gt;Extensible&lt;/strong&gt; â€“ Easy to plug in new search engines, models, or output formats.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;âš ï¸ Disclaimer&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This tool is intended for educational and lawful investigative purposes only. Accessing or interacting with certain dark web content may be illegal depending on your jurisdiction. The author is not responsible for any misuse of this tool or the data gathered using it.&lt;/p&gt; 
 &lt;p&gt;Use responsibly and at your own risk. Ensure you comply with all relevant laws and institutional policies before conducting OSINT investigations.&lt;/p&gt; 
 &lt;p&gt;Additionally, Robin leverages third-party APIs (including LLMs). Be cautious when sending potentially sensitive queries, and review the terms of service for any API or model provider you use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The tool needs Tor to do the searches. You can install Tor using &lt;code&gt;apt install tor&lt;/code&gt; on Linux/Windows(WSL) or &lt;code&gt;brew install tor&lt;/code&gt; on Mac. Once installed, confirm if Tor is running in the background.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can provide OpenAI or Anthropic or Google API key by either creating .env file (refer to sample env file in the repo) or by setting env variables in PATH.&lt;/p&gt; 
 &lt;p&gt;For Ollama, provide &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt; as &lt;code&gt;OLLAMA_BASE_URL&lt;/code&gt; in your env if running using docker method or &lt;code&gt;http://127.0.0.1:11434&lt;/code&gt; for other methods. You might need to serve Ollama on 0.0.0.0 depending on your OS. You can do by running &lt;code&gt;OLLAMA_HOST=0.0.0.0 ollama serve &amp;amp;&lt;/code&gt; in your terminal.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Docker (Web UI Mode) [Recommended]&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pull the latest Robin docker image&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull apurvsg/robin:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the docker image as:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm \
   -v "$(pwd)/.env:/app/.env" \
   --add-host=host.docker.internal:host-gateway \
   -p 8501:8501 \
   apurvsg/robin:latest ui --ui-port 8501 --ui-host 0.0.0.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Release Binary (CLI Mode)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the appropriate binary for your system from the &lt;a href="https://github.com/apurvsinghgautam/robin/releases/latest"&gt;latest release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Unzip the file, make it executable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chmod +x robin
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the binary as:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;robin cli --model gpt-4.1 --query "ransomware payments"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Python (Development Version)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;With &lt;code&gt;Python 3.10+&lt;/code&gt; installed, run the following:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
python main.py cli -m gpt-4.1 -q "ransomware payments" -t 12
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;Robin: AI-Powered Dark Web OSINT Tool

options:
  -h, --help            show this help message and exit
  --model {gpt4o,gpt-4.1,claude-3-5-sonnet-latest,llama3.1,gemini-2.5-flash}, -m {gpt4o,gpt-4.1,claude-3-5-sonnet-latest,llama3.1,gemini-2.5-flash}
                        Select LLM model (e.g., gpt4o, claude sonnet 3.5, ollama models, gemini 2.5 flash)
  --query QUERY, -q QUERY
                        Dark web search query
  --threads THREADS, -t THREADS
                        Number of threads to use for scraping (Default: 5)
  --output OUTPUT, -o OUTPUT
                        Filename to save the final intelligence summary. If not provided, a filename based on the
                        current date and time is used.

Example commands:
 - robin -m gpt4.1 -q "ransomware payments" -t 12
 - robin --model gpt4.1 --query "sensitive credentials exposure" --threads 8 --output filename
 - robin -m llama3.1 -q "zero days"
 - robin -m gemini-2.5-flash -q "zero days"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request if you have major feature updates.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch (git checkout -b feature/amazing-feature)&lt;/li&gt; 
 &lt;li&gt;Commit your changes (git commit -m 'Add some amazing feature')&lt;/li&gt; 
 &lt;li&gt;Push to the branch (git push origin feature/amazing-feature)&lt;/li&gt; 
 &lt;li&gt;Open a Pull Request&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open an Issue for any of these situations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you spot a bug or bad code&lt;/li&gt; 
 &lt;li&gt;If you have a feature request idea&lt;/li&gt; 
 &lt;li&gt;If you have questions or doubts about usage&lt;/li&gt; 
 &lt;li&gt;If you have minor code changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Idea inspiration from &lt;a href="https://x.com/fr0gger_"&gt;Thomas Roccia&lt;/a&gt; and his demo of &lt;a href="https://x.com/fr0gger_/status/1908051083068645558"&gt;Perplexity of the Dark Web&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Tools inspiration from my &lt;a href="https://github.com/apurvsinghgautam/dark-web-osint-tools"&gt;OSINT Tools for the Dark Web&lt;/a&gt; repository.&lt;/li&gt; 
 &lt;li&gt;LLM Prompt inspiration from &lt;a href="https://github.com/AXRoux/OSINT-Assistant"&gt;OSINT-Assistant&lt;/a&gt; repository.&lt;/li&gt; 
 &lt;li&gt;Logo Design by my friend &lt;a href="https://github.com/Tanq16/"&gt;Tanishq Rupaal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Workflow Design by &lt;a href="https://www.linkedin.com/in/chintangurjar"&gt;Chintan Gurjar&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/magentic-ui</title>
      <link>https://github.com/microsoft/magentic-ui</link>
      <description>&lt;p&gt;A research prototype of a human-centered web agent&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/microsoft/magentic-ui/main/docs/img/magui-readme-logo.svg?sanitize=true" alt="Magentic-UI Logo" /&gt; 
 &lt;p&gt;&lt;em&gt;Automate your web tasks while you stay in control&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pypi.python.org/pypi/magentic_ui"&gt;&lt;img src="https://img.shields.io/pypi/v/magentic_ui.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/magentic_ui"&gt;&lt;img src="https://img.shields.io/pypi/l/magentic_ui.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue" alt="Python Versions" /&gt; &lt;a href="https://arxiv.org/abs/2507.22358"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2507.22358-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Magentic-UI is a &lt;strong&gt;research prototype&lt;/strong&gt; human-centered AI agent that solves complex web and coding tasks that may require monitoring. Unlike other black-box agents, the system reveals its plan before executions, lets you guide its actions, and requests approval for sensitive operations while browsing websites, executing code, and analyzing files. &lt;em&gt;Check out the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#demos"&gt;demo section&lt;/a&gt; for inspiration on what tasks you can accomplish.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ What's New&lt;/h2&gt; 
&lt;p&gt;Microsoft latest agentic model &lt;a href="https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/"&gt;Fara-7B&lt;/a&gt; is now integrated in Magentic-UI, read how to launch in &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#fara-7b"&gt; Fara-7B guide&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Tell me When"&lt;/strong&gt;: Automate monitoring tasks and repeatable workflows that require web or API access that span minutes to days. &lt;em&gt;Learn more &lt;a href="https://www.microsoft.com/en-us/research/blog/tell-me-when-building-agents-that-can-wait-monitor-and-act/"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Upload Support&lt;/strong&gt;: Upload any file through the UI for analysis or modification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Agents&lt;/strong&gt;: Extend capabilities with your favorite MCP servers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easier Installation&lt;/strong&gt;: We have uploaded our docker containers to GHCR so you no longer need to build any containers! Installation time now is much quicker.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;Here's how you can get started with Magentic-UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Setup environment
python3 -m venv .venv
source .venv/bin/activate
pip install magentic-ui --upgrade

# 2. Set your API key
export OPENAI_API_KEY="your-api-key-here"

# 3. Launch Magentic-UI
magentic-ui --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open &lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt; in your browser to interact with Magentic-UI!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: Requires Docker and Python 3.10+. Windows users should use WSL2. See &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#%EF%B8%8F-installation"&gt;detailed installation&lt;/a&gt; for more info.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Alternative Usage Options&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Without Docker&lt;/strong&gt; (limited functionality: no code execution):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --run-without-docker --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Command Line Interface&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-cli --work-dir PATH/TO/STORE/DATA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Custom LLM Clients&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Azure
pip install magentic-ui[azure]

# Ollama (local models)
pip install magentic-ui[ollama]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then pass a config file to the &lt;code&gt;magentic-ui&lt;/code&gt; command (&lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#model-client-configuration"&gt; client config&lt;/a&gt;) or change the model client inside the UI settings.&lt;/p&gt; 
&lt;p&gt;For further details on installation please read the &lt;a href="#ï¸-installation"&gt;ğŸ› ï¸ Installation&lt;/a&gt; section. For common installation issues and their solutions, please refer to the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/TROUBLESHOOTING.md"&gt;troubleshooting document&lt;/a&gt;. See advanced usage instructions with the command &lt;code&gt;magentic-ui --help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Navigation:&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#demos"&gt;ğŸ¬ Demos&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#how-it-works"&gt;ğŸŸª How it Works&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#installation"&gt;ğŸ› ï¸ Installation&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#troubleshooting"&gt;âš ï¸ Troubleshooting&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#contributing"&gt;ğŸ¤ Contributing&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#license"&gt;ğŸ“„ License&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;p&gt;&lt;strong&gt;ğŸ• Pizza Ordering&lt;/strong&gt;&lt;br /&gt; &lt;em&gt;Web automation with human-in-the-loop&lt;/em&gt;&lt;/p&gt; 
    &lt;video src="https://github.com/user-attachments/assets/dc95cf5f-c4b4-4fe0-b708-158ff071e5a9" width="100%" style="max-height: 300px;"&gt; 
    &lt;/video&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;p&gt;&lt;strong&gt;ğŸ  Airbnb Price Analysis&lt;/strong&gt;&lt;br /&gt; &lt;em&gt;MCP agent integration&lt;/em&gt;&lt;/p&gt; 
    &lt;video src="https://github.com/user-attachments/assets/c19ed8c2-e06f-43b7-bee3-5e2ffc4c5e02" width="100%" style="max-height: 300px;"&gt; 
    &lt;/video&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;p&gt;&lt;strong&gt;â­ Star Monitoring&lt;/strong&gt;&lt;br /&gt; &lt;em&gt;Long-running monitoring task&lt;/em&gt;&lt;/p&gt; 
    &lt;video src="https://github.com/user-attachments/assets/d2a463ca-7a94-4414-932d-a69f30fff63b" width="100%" style="max-height: 300px;"&gt; 
    &lt;/video&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;How it Works&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/magentic-ui/main/docs/img/magenticui_running.png" alt="Magentic-UI" height="400" /&gt; &lt;/p&gt; 
&lt;p&gt;Magentic-UI is especially useful for web tasks that require actions on the web (e.g., filling a form, customizing a food order), deep navigation through websites not indexed by search engines (e.g., filtering flights, finding a link from a personal site) or tasks that need web navigation and code execution (e.g., generate a chart from online data).&lt;/p&gt; 
&lt;p&gt;What differentiates Magentic-UI from other browser use offerings is its transparent and controllable interface that allows for efficient human-in-the-loop involvement. Magentic-UI is built using &lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt; and provides a platform to study human-agent interaction and experiment with web agents. Key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ§‘â€ğŸ¤â€ğŸ§‘ &lt;strong&gt;Co-Planning&lt;/strong&gt;: Collaboratively create and approve step-by-step plans using chat and the plan editor.&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ &lt;strong&gt;Co-Tasking&lt;/strong&gt;: Interrupt and guide the task execution using the web browser directly or through chat. Magentic-UI can also ask for clarifications and help when needed.&lt;/li&gt; 
 &lt;li&gt;ğŸ›¡ï¸ &lt;strong&gt;Action Guards&lt;/strong&gt;: Sensitive actions are only executed with explicit user approvals.&lt;/li&gt; 
 &lt;li&gt;ğŸ§  &lt;strong&gt;Plan Learning and Retrieval&lt;/strong&gt;: Learn from previous runs to improve future task automation and save them in a plan gallery. Automatically or manually retrieve saved plans in future tasks.&lt;/li&gt; 
 &lt;li&gt;ğŸ”€ &lt;strong&gt;Parallel Task Execution&lt;/strong&gt;: You can run multiple tasks in parallel and session status indicators will let you know when Magentic-UI needs your input or has completed the task.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=wOs-5SR8xOc" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/wOs-5SR8xOc/maxresdefault.jpg" alt="Watch the demo video" width="600" /&gt; &lt;/a&gt; 
 &lt;br /&gt; â–¶ï¸ 
 &lt;em&gt; Click to watch a video and learn more about Magentic-UI &lt;/em&gt; 
&lt;/div&gt; 
&lt;h3&gt;Autonomous Evaluation&lt;/h3&gt; 
&lt;p&gt;To evaluate its autonomous capabilities, Magentic-UI has been tested against several benchmarks when running with o4-mini: &lt;a href="https://huggingface.co/datasets/gaia-benchmark/GAIA"&gt;GAIA&lt;/a&gt; test set (42.52%), which assesses general AI assistants across reasoning, tool use, and web interaction tasks ; &lt;a href="https://huggingface.co/AssistantBench"&gt;AssistantBench&lt;/a&gt; test set (27.60%), focusing on realistic, time-consuming web tasks; &lt;a href="https://github.com/MinorJerry/WebVoyager"&gt;WebVoyager&lt;/a&gt; (82.2%), measuring end-to-end web navigation in real-world scenarios; and &lt;a href="https://webgames.convergence.ai/"&gt;WebGames&lt;/a&gt; (45.5%), evaluating general-purpose web-browsing agents through interactive challenges. To reproduce these experimental results, please see the following &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/experiments/eval/README.md"&gt;instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're interested in reading more checkout our &lt;a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/magentic-ui-report.pdf"&gt;technical report&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/"&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Pre-Requisites&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you're using Windows, we highly recommend using &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/install"&gt;WSL2&lt;/a&gt; (Windows Subsystem for Linux).&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;If running on &lt;strong&gt;Windows&lt;/strong&gt; or &lt;strong&gt;Mac&lt;/strong&gt; you should use &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; or if inside WSL2 you can install Docker directly inside WSL &lt;a href="https://gist.github.com/dehsilvadeveloper/c3bdf0f4cdcc5c177e2fe9be671820c7"&gt;docker in WSL2 guide&lt;/a&gt;. If running on &lt;strong&gt;Linux&lt;/strong&gt;, you should use &lt;a href="https://docs.docker.com/engine/install/"&gt;Docker Engine&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If using Docker Desktop, make sure it is set up to use WSL2: - Go to Settings &amp;gt; Resources &amp;gt; WSL Integration - Enable integration with your development distro You can find more detailed instructions about this step &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/tutorials/wsl-containers"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;During the Installation step, you will need to set up your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;. To use other models, review the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#model-client-configuration"&gt;Model Client Configuration&lt;/a&gt; section below.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You need at least &lt;a href="https://www.python.org/downloads/"&gt;Python 3.10&lt;/a&gt; installed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you are on Windows, we recommend to run Magentic-UI inside &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/install"&gt;WSL2&lt;/a&gt; (Windows Subsystem for Linux) for correct Docker and file path compatibility.&lt;/p&gt; 
&lt;h3&gt;PyPI Installation&lt;/h3&gt; 
&lt;p&gt;Magentic-UI is available on PyPI. We recommend using a virtual environment to avoid conflicts with other packages.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m venv .venv
source .venv/bin/activate
pip install magentic-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; for dependency management, you can install Magentic-UI with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
. .venv/bin/activate
uv pip install magentic-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Magentic-UI&lt;/h3&gt; 
&lt;p&gt;To run Magentic-UI, make sure that Docker is running, then run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Running this command for the first time will pull two docker images required for the Magentic-UI agents. If you encounter problems, you can build them directly with the following command:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd docker
sh build-all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you face issues with Docker, please refer to the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/TROUBLESHOOTING.md"&gt;TROUBLESHOOTING.md&lt;/a&gt; document.&lt;/p&gt; 
&lt;p&gt;Once the server is running, you can access the UI at &lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Fara-7B&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;First install magentic-ui with the fara extras:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m venv .venv
source .venv/bin/activate
pip install magentic-ui[fara]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;In a seperate process, serve the Fara-7B model using vLLM:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve "microsoft/Fara-7B" --port 5000 --dtype auto 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;First create a &lt;code&gt;fara_config.yaml&lt;/code&gt; file with the following content:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;model_config_local_surfer: &amp;amp;client_surfer
  provider: OpenAIChatCompletionClient
  config:
    model: "microsoft/Fara-7B"
    base_url: http://localhost:5000/v1
    api_key: not-needed
    model_info:
      vision: true
      function_calling: true
      json_output: false
      family: "unknown" 
      structured_output: false
      multiple_system_messages: false

orchestrator_client: *client_surfer
coder_client: *client_surfer
web_surfer_client: *client_surfer
file_surfer_client: *client_surfer
action_guard_client: *client_surfer
model_client: *client_surfer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: if you are hosting vLLM on a different port or host, change the &lt;code&gt;base_url&lt;/code&gt; accordingly.&lt;/p&gt; 
&lt;p&gt;Then launch Magentic-UI with the fara agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --fara --port 8081 --config fara_config.yaml 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, navigate to &lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt; to access the interface!&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;h4&gt;Model Client Configuration&lt;/h4&gt; 
&lt;p&gt;If you want to use a different OpenAI key, or if you want to configure use with Azure OpenAI or Ollama, you can do so inside the UI by navigating to settings (top right icon) and changing model configuration. Another option is to pass a yaml config file when you start Magentic-UI which will override any settings in the UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --port 8081 --config config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Where the &lt;code&gt;config.yaml&lt;/code&gt; should look as follows with an AutoGen model client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;gpt4o_client: &amp;amp;gpt4o_client
    provider: OpenAIChatCompletionClient
    config:
      model: gpt-4o-2024-08-06
      api_key: null
      base_url: null
      max_retries: 5

orchestrator_client: *gpt4o_client
coder_client: *gpt4o_client
web_surfer_client: *gpt4o_client
file_surfer_client: *gpt4o_client
action_guard_client: *gpt4o_client
plan_learning_client: *gpt4o_client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can change the client for each of the agents using the config file and use AzureOpenAI (&lt;code&gt;AzureOpenAIChatCompletionClient&lt;/code&gt;), Ollama and other clients.&lt;/p&gt; 
&lt;h4&gt;MCP Server Configuration&lt;/h4&gt; 
&lt;p&gt;You can also extend Magentic-UI's capabilities by adding custom "McpAgents" to the multi-agent team. Each McpAgent can have access to one or more MCP Servers. You can specify these agents via the &lt;code&gt;mcp_agent_configs&lt;/code&gt; parameter in your &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, here's an agent called "airbnb_surfer" that has access to the OpenBnb MCP Server running locally via Stdio.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp_agent_configs:
  - name: airbnb_surfer
    description: "The airbnb_surfer has direct access to AirBnB."
    model_client: 
      provider: OpenAIChatCompletionClient
      config:
        model: gpt-4.1-2025-04-14
      max_retries: 10
    system_message: |-
      You are AirBnb Surfer, a helpful digital assistant that can help users acces AirBnB.

      You have access to a suite of tools provided by the AirBnB API. Use those tools to satisfy the users requests.
    reflect_on_tool_use: false
    mcp_servers:
      - server_name: AirBnB
        server_params:
          type: StdioServerParams
          command: npx
          args:
            - -y
            - "@openbnb/mcp-server-airbnb"
            - --ignore-robots-txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Under the hood, each &lt;code&gt;McpAgent&lt;/code&gt; is just a &lt;code&gt;autogen_agentchat.agents.AssistantAgent&lt;/code&gt; with the set of MCP Servers exposed as an &lt;code&gt;AggregateMcpWorkbench&lt;/code&gt; which is simply a named collection of &lt;code&gt;autogen_ext.tools.mcp.McpWorkbench&lt;/code&gt; objects (one per MCP Server).&lt;/p&gt; 
&lt;p&gt;Currently the supported MCP Server types are &lt;code&gt;autogen_ext.tools.mcp.StdioServerParams&lt;/code&gt; and &lt;code&gt;autogen_ext.tools.mcp.SseServerParams&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Building Magentic-UI from source&lt;/h3&gt; 
&lt;p&gt;This step is primarily for users seeking to make modifications to the code, are having trouble with the pypi installation or want the latest code before a pypi version release.&lt;/p&gt; 
&lt;h4&gt;1. Make sure the above prerequisites are installed, and that Docker is running.&lt;/h4&gt; 
&lt;h4&gt;2. Clone the repository to your local machine:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/microsoft/magentic-ui.git
cd magentic-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Install Magentic-UI's dependencies with uv or your favorite package manager:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install uv through https://docs.astral.sh/uv/getting-started/installation/
uv venv --python=3.12 .venv
uv sync --all-extras
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Build the frontend:&lt;/h4&gt; 
&lt;p&gt;First make sure to install node:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# install nvm to install node
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash
nvm install node
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install the frontend:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
npm install -g gatsby-cli
npm install --global yarn
yarn install
yarn build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Run Magentic-UI, as usual.&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Running the UI from source&lt;/h4&gt; 
&lt;p&gt;If you are making changes to the source code of the UI, you can run the frontend in development mode so that it will automatically update when you make changes for faster development.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open a separate terminal and change directory to the frontend&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Create a &lt;code&gt;.env.development&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.default .env.development
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Launch frontend server&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run start
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Then run the UI:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;magentic-ui --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The frontend from source will be available at &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;, and the compiled frontend will be available at &lt;a href="http://localhost:8081"&gt;http://localhost:8081&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If you were unable to get Magentic-UI running, do not worry! The first step is to make sure you have followed the steps outlined above, particularly with the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/#pre-requisites"&gt;pre-requisites&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For common issues and their solutions, please refer to the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/TROUBLESHOOTING.md"&gt;TROUBLESHOOTING.md&lt;/a&gt; file in this repository. If you do not see your problem there, please open a &lt;code&gt;GitHub Issue&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. For information about contributing to Magentic-UI, please see our &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; guide, which includes current issues to be resolved and other forms of contributing.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information, see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite our paper if you use our work in your research:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{mozannar2025magentic,
  title={Magentic-UI: Towards Human-in-the-loop Agentic Systems},
  author={Mozannar, Hussein and Bansal, Gagan and Tan, Cheng and Fourney, Adam and Dibia, Victor and Chen, Jingya and Gerrits, Jack and Payne, Tyler and Maldaner, Matheus Kunzler and Grunde-McLaughlin, Madeleine and others},
  journal={arXiv preprint arXiv:2507.22358},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Microsoft, and any contributors, grant you a license to any code in the repository under the &lt;a href="https://opensource.org/licenses/MIT"&gt;MIT License&lt;/a&gt;. See the &lt;a href="https://raw.githubusercontent.com/microsoft/magentic-ui/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;Microsoft, Windows, Microsoft Azure, and/or other Microsoft products and services referenced in the documentation may be either trademarks or registered trademarks of Microsoft in the United States and/or other countries. The licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks. Microsoft's general trademark guidelines can be found at &lt;a href="http://go.microsoft.com/fwlink/?LinkID=254653"&gt;http://go.microsoft.com/fwlink/?LinkID=254653&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;p&gt;Privacy information can be found at &lt;a href="https://go.microsoft.com/fwlink/?LinkId=521839"&gt;https://go.microsoft.com/fwlink/?LinkId=521839&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Microsoft and any contributors reserve all other rights, whether under their respective copyrights, patents, or trademarks, whether by implication, estoppel, or otherwise.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-quickstarts</title>
      <link>https://github.com/anthropics/claude-quickstarts</link>
      <description>&lt;p&gt;A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Quickstarts&lt;/h1&gt; 
&lt;p&gt;Claude Quickstarts is a collection of projects designed to help developers quickly get started with building applications using the Claude API. Each quickstart provides a foundation that you can easily build upon and customize for your specific needs.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To use these quickstarts, you'll need an Claude API key. If you don't have one yet, you can sign up for free at &lt;a href="https://console.anthropic.com"&gt;console.anthropic.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Available Quickstarts&lt;/h2&gt; 
&lt;h3&gt;Customer Support Agent&lt;/h3&gt; 
&lt;p&gt;A customer support agent powered by Claude. This project demonstrates how to leverage Claude's natural language understanding and generation capabilities to create an AI-assisted customer support system with access to a knowledge base.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/customer-support-agent"&gt;Go to Customer Support Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Financial Data Analyst&lt;/h3&gt; 
&lt;p&gt;A financial data analyst powered by Claude. This project demonstrates how to leverage Claude's capabilities with interactive data visualization to analyze financial data via chat.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/financial-data-analyst"&gt;Go to Financial Data Analyst Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Computer Use Demo&lt;/h3&gt; 
&lt;p&gt;An environment and tools that Claude can use to control a desktop computer. This project demonstrates how to leverage the computer use capabilities of Claude, including support for the latest &lt;code&gt;computer_use_20251124&lt;/code&gt; tool version with zoom actions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/computer-use-demo"&gt;Go to Computer Use Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Autonomous Coding Agent&lt;/h3&gt; 
&lt;p&gt;An autonomous coding agent powered by the Claude Agent SDK. This project demonstrates a two-agent pattern (initializer + coding agent) that can build complete applications over multiple sessions, with progress persisted via git and a feature list that the agent works through incrementally.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/autonomous-coding"&gt;Go to Autonomous Coding Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;General Usage&lt;/h2&gt; 
&lt;p&gt;Each quickstart project comes with its own README and setup instructions. Generally, you'll follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository&lt;/li&gt; 
 &lt;li&gt;Navigate to the specific quickstart directory&lt;/li&gt; 
 &lt;li&gt;Install the required dependencies&lt;/li&gt; 
 &lt;li&gt;Set up your Claude API key as an environment variable&lt;/li&gt; 
 &lt;li&gt;Run the quickstart application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;p&gt;To deepen your understanding of working with Claude and the Claude API, check out these resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com"&gt;Claude API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-cookbooks"&gt;Claude Cookbooks&lt;/a&gt; - A collection of code snippets and guides for common tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals"&gt;Claude API Fundamentals Course&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Claude Quickstarts repository! If you have ideas for new quickstart projects or improvements to existing ones, please open an issue or submit a pull request.&lt;/p&gt; 
&lt;h2&gt;Community and Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://www.anthropic.com/discord"&gt;Anthropic Discord community&lt;/a&gt; for discussions and support&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://support.anthropic.com"&gt;Anthropic support documentation&lt;/a&gt; for additional help&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;Open-source AI agents for penetration testing&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Strix&lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://deepwiki.com/usestrix/strix"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¦‰ Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Capabilities:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ &lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;strong&gt;Developerâ€‘first&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;Autoâ€‘fix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¯ Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Application Security Testing&lt;/strong&gt; - Detect and validate critical vulnerabilities in your applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rapid Penetration Testing&lt;/strong&gt; - Get penetration tests done in hours, not weeks, with compliance reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Bounty Automation&lt;/strong&gt; - Automate bug bounty research and generate PoCs for faster reporting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD Integration&lt;/strong&gt; - Run tests in CI/CD to block vulnerabilities before reaching production&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (e.g. &lt;a href="https://platform.openai.com/api-keys"&gt;get OpenAI API key&lt;/a&gt; or use a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation &amp;amp; First Scan&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Strix
curl -sSL https://strix.ai/install | bash

# Or via pipx
pipx install strix-agent

# Configure your AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run your first security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] First run automatically pulls the sandbox Docker image. Results are saved to &lt;code&gt;strix_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;â˜ï¸ Run Strix in Cloud&lt;/h2&gt; 
&lt;p&gt;Want to skip the local setup, API keys, and unpredictable LLM costs? Run the hosted cloud version of Strix at &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;app.usestrix.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Launch a scan in just a few minutesâ€”no setup or configuration requiredâ€”and youâ€™ll get:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A full pentest report&lt;/strong&gt; with validated findings and clear remediation steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shareable dashboards&lt;/strong&gt; your team can use to track fixes over time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD and GitHub integrations&lt;/strong&gt; to block risky changes before production&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Continuous monitoring&lt;/strong&gt; so new vulnerabilities are caught quickly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Run your first pentest now â†’&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ› ï¸ Agentic Security Tools&lt;/h3&gt; 
&lt;p&gt;Strix agents come equipped with a comprehensive security testing toolkit:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¯ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;p&gt;Strix can identify and validate a wide range of security vulnerabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ•¸ï¸ Graph of Agents&lt;/h3&gt; 
&lt;p&gt;Advanced multi-agent orchestration for comprehensive security testing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’» Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Scan a local codebase
strix --target ./app-directory

# Security review of a GitHub repository
strix --target https://github.com/org/repo

# Black-box web application assessment
strix --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Testing Scenarios&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Grey-box authenticated testing
strix --target https://your-app.com --instruction "Perform authenticated testing using credentials: user:pass"

# Multi-target testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with custom instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"

# Provide detailed instructions through file (e.g., rules of engagement, scope, exclusions)
strix --target api.your-app.com --instruction-file ./instruction.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ¤– Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flagâ€”perfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”„ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install Strix
        run: curl -sSL https://strix.ai/install | bash

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./ --scan-mode quick
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;âš™ï¸ Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://openai.com/api/"&gt;OpenAI's GPT-5&lt;/a&gt; (&lt;code&gt;openai/gpt-5&lt;/code&gt;) and &lt;a href="https://claude.com/platform/api"&gt;Anthropic's Claude Sonnet 4.5&lt;/a&gt; (&lt;code&gt;anthropic/claude-sonnet-4-5&lt;/code&gt;) are the recommended models for best results with Strix. We also support many &lt;a href="https://docs.litellm.ai/docs/providers"&gt;other options&lt;/a&gt;, including cloud and local models, though their performance and reliability may vary.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of code, docs, and new prompt modules - check out our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started or open a &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull request&lt;/a&gt;/&lt;a href="https://github.com/usestrix/strix/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ‘¥ Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a â­ on GitHub!&lt;/p&gt; 
&lt;h2&gt;ğŸ™ Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Strix builds on the incredible work of open-source projects like &lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;, &lt;a href="https://github.com/caido/caido"&gt;Caido&lt;/a&gt;, &lt;a href="https://github.com/projectdiscovery"&gt;ProjectDiscovery&lt;/a&gt;, &lt;a href="https://github.com/microsoft/playwright"&gt;Playwright&lt;/a&gt;, and &lt;a href="https://github.com/Textualize/textual"&gt;Textual&lt;/a&gt;. Huge thanks to their maintainers!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test apps you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>ModelTC/LightX2V</title>
      <link>https://github.com/ModelTC/LightX2V</link>
      <description>&lt;p&gt;Light Video Generation Inference Framework&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="font-family: charter;"&gt; 
 &lt;h1&gt;âš¡ï¸ LightX2V:&lt;br /&gt; Light Video Generation Inference Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;img alt="logo" src="https://raw.githubusercontent.com/ModelTC/LightX2V/main/assets/img_lightx2v.png" width="75%" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ModelTC/lightx2v"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://lightx2v-en.readthedocs.io/en/latest"&gt;&lt;img src="https://img.shields.io/badge/docs-English-99cc2" alt="Doc" /&gt;&lt;/a&gt; &lt;a href="https://lightx2v-zhcn.readthedocs.io/zh-cn/latest"&gt;&lt;img src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E4%B8%AD%E6%96%87-99cc2" alt="Doc" /&gt;&lt;/a&gt; &lt;a href="https://lightx2v-papers-zhcn.readthedocs.io/zh-cn/latest"&gt;&lt;img src="https://img.shields.io/badge/%E8%AE%BA%E6%96%87%E9%9B%86-%E4%B8%AD%E6%96%87-99cc2" alt="Papers" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lightx2v/lightx2v/tags"&gt;&lt;img src="https://img.shields.io/badge/Docker-2496ED?style=flat&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;[ English | &lt;a href="https://raw.githubusercontent.com/ModelTC/LightX2V/main/README_zh.md"&gt;ä¸­æ–‡&lt;/a&gt; ]&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;LightX2V&lt;/strong&gt; is an advanced lightweight video generation inference framework engineered to deliver efficient, high-performance video synthesis solutions. This unified platform integrates multiple state-of-the-art video generation techniques, supporting diverse generation tasks including text-to-video (T2V) and image-to-video (I2V). &lt;strong&gt;X2V represents the transformation of different input modalities (X, such as text or images) into video output (V)&lt;/strong&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸŒ &lt;strong&gt;Try it online now!&lt;/strong&gt; Experience LightX2V without installation: &lt;strong&gt;&lt;a href="https://x2v.light-ai.top/login"&gt;LightX2V Online Service&lt;/a&gt;&lt;/strong&gt; - Free, lightweight, and fast AI digital human video generation platform.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”¥&lt;/span&gt; Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;December 15, 2025:&lt;/strong&gt; ğŸš€ Supported deployment on Hygon DCU.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;December 4, 2025:&lt;/strong&gt; ğŸš€ Supported GGUF format model inference &amp;amp; deployment on Cambricon MLU590/MetaX C500.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;November 24, 2025:&lt;/strong&gt; ğŸš€ We released 4-step distilled models for HunyuanVideo-1.5! These models enable &lt;strong&gt;ultra-fast 4-step inference&lt;/strong&gt; without CFG requirements, achieving approximately &lt;strong&gt;25x speedup&lt;/strong&gt; compared to standard 50-step inference. Both base and FP8 quantized versions are now available: &lt;a href="https://huggingface.co/lightx2v/Hy1.5-Distill-Models"&gt;Hy1.5-Distill-Models&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;November 21, 2025:&lt;/strong&gt; ğŸš€ We support the &lt;a href="https://huggingface.co/tencent/HunyuanVideo-1.5"&gt;HunyuanVideo-1.5&lt;/a&gt; video generation model since Day 0. With the same number of GPUs, LightX2V can achieve a speed improvement of over 2 times and supports deployment on GPUs with lower memory (such as the 24GB RTX 4090). It also supports CFG/Ulysses parallelism, efficient offloading, TeaCache/MagCache technologies, and more. We will soon update more models on our &lt;a href="https://huggingface.co/lightx2v"&gt;HuggingFace page&lt;/a&gt;, including step distillation, VAE distillation, and other related models. Quantized models and lightweight VAE models are now available: &lt;a href="https://huggingface.co/lightx2v/Hy1.5-Quantized-Models"&gt;Hy1.5-Quantized-Models&lt;/a&gt; for quantized inference, and &lt;a href="https://huggingface.co/lightx2v/Autoencoders/blob/main/lighttaehy1_5.safetensors"&gt;LightTAE for HunyuanVideo-1.5&lt;/a&gt; for fast VAE decoding. Refer to &lt;a href="https://github.com/ModelTC/LightX2V/tree/main/scripts/hunyuan_video_15"&gt;this&lt;/a&gt; for usage tutorials, or check out the &lt;a href="https://github.com/ModelTC/LightX2V/tree/main/examples"&gt;examples directory&lt;/a&gt; for code examples.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ† Performance Benchmarks (Updated on 2025.12.01)&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š Cross-Framework Performance Comparison (H100)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Framework&lt;/th&gt; 
   &lt;th&gt;GPUs&lt;/th&gt; 
   &lt;th&gt;Step Time&lt;/th&gt; 
   &lt;th&gt;Speedup&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Diffusers&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;9.77s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xDiT&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;8.93s/it&lt;/td&gt; 
   &lt;td&gt;1.1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FastVideo&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;7.35s/it&lt;/td&gt; 
   &lt;td&gt;1.3x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SGL-Diffusion&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;6.13s/it&lt;/td&gt; 
   &lt;td&gt;1.6x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;5.18s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.9x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FastVideo&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;2.94s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xDiT&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;2.70s/it&lt;/td&gt; 
   &lt;td&gt;1.1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SGL-Diffusion&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1.19s/it&lt;/td&gt; 
   &lt;td&gt;2.5x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.75s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.9x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸ“Š Cross-Framework Performance Comparison (RTX 4090D)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Framework&lt;/th&gt; 
   &lt;th&gt;GPUs&lt;/th&gt; 
   &lt;th&gt;Step Time&lt;/th&gt; 
   &lt;th&gt;Speedup&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Diffusers&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;30.50s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FastVideo&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;22.66s/it&lt;/td&gt; 
   &lt;td&gt;1.3x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xDiT&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SGL-Diffusion&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;20.26s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.5x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FastVideo&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;15.48s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xDiT&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SGL-Diffusion&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;4.75s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.3x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸ“Š LightX2V Performance Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Framework&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Configuration&lt;/th&gt; 
   &lt;th&gt;Step Time&lt;/th&gt; 
   &lt;th&gt;Speedup&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;H100&lt;/td&gt; 
   &lt;td&gt;8 GPUs + cfg&lt;/td&gt; 
   &lt;td&gt;0.75s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;H100&lt;/td&gt; 
   &lt;td&gt;8 GPUs + no cfg&lt;/td&gt; 
   &lt;td&gt;0.39s/it&lt;/td&gt; 
   &lt;td&gt;1.9x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;H100&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;8 GPUs + no cfg + fp8&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.35s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.1x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;4090D&lt;/td&gt; 
   &lt;td&gt;8 GPUs + cfg&lt;/td&gt; 
   &lt;td&gt;4.75s/it&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;4090D&lt;/td&gt; 
   &lt;td&gt;8 GPUs + no cfg&lt;/td&gt; 
   &lt;td&gt;3.13s/it&lt;/td&gt; 
   &lt;td&gt;1.5x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LightX2V&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;4090D&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;8 GPUs + no cfg + fp8&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.35s/it&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.0x&lt;/strong&gt; ğŸš€&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: All the above performance data were tested on Wan2.1-I2V-14B-480P(40 steps, 81 frames). In addition, we also provide 4-step distilled models on the &lt;a href="https://huggingface.co/lightx2v"&gt;HuggingFace page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ’¡ Quick Start&lt;/h2&gt; 
&lt;p&gt;For comprehensive usage instructions, please refer to our documentation: &lt;strong&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/"&gt;English Docs&lt;/a&gt; | &lt;a href="https://lightx2v-zhcn.readthedocs.io/zh-cn/latest/"&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We highly recommend using the Docker environment, as it is the simplest and fastest way to set up the environment. For details, please refer to the Quick Start section in the documentation.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Installation from Git&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -v git+https://github.com/ModelTC/LightX2V.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ModelTC/LightX2V.git
cd LightX2V
uv pip install -v . # pip install -v .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;(Optional) Install Attention/Quantize Operators&lt;/h3&gt; 
&lt;p&gt;For attention operators installation, please refer to our documentation: &lt;strong&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/getting_started/quickstart.html#step-4-install-attention-operators"&gt;English Docs&lt;/a&gt; | &lt;a href="https://lightx2v-zhcn.readthedocs.io/zh-cn/latest/getting_started/quickstart.html#id9"&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Usage Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# examples/wan/wan_i2v.py
"""
Wan2.2 image-to-video generation example.
This example demonstrates how to use LightX2V with Wan2.2 model for I2V generation.
"""

from lightx2v import LightX2VPipeline

# Initialize pipeline for Wan2.2 I2V task
# For wan2.1, use model_cls="wan2.1"
pipe = LightX2VPipeline(
    model_path="/path/to/Wan2.2-I2V-A14B",
    model_cls="wan2.2_moe",
    task="i2v",
)

# Alternative: create generator from config JSON file
# pipe.create_generator(
#     config_json="configs/wan22/wan_moe_i2v.json"
# )

# Enable offloading to significantly reduce VRAM usage with minimal speed impact
# Suitable for RTX 30/40/50 consumer GPUs
pipe.enable_offload(
    cpu_offload=True,
    offload_granularity="block",  # For Wan models, supports both "block" and "phase"
    text_encoder_offload=True,
    image_encoder_offload=False,
    vae_offload=False,
)

# Create generator manually with specified parameters
pipe.create_generator(
    attn_mode="sage_attn2",
    infer_steps=40,
    height=480,  # Can be set to 720 for higher resolution
    width=832,  # Can be set to 1280 for higher resolution
    num_frames=81,
    guidance_scale=[3.5, 3.5],  # For wan2.1, guidance_scale is a scalar (e.g., 5.0)
    sample_shift=5.0,
)

# Generation parameters
seed = 42
prompt = "Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard. The fluffy-furred feline gazes directly at the camera with a relaxed expression. Blurred beach scenery forms the background featuring crystal-clear waters, distant green hills, and a blue sky dotted with white clouds. The cat assumes a naturally relaxed posture, as if savoring the sea breeze and warm sunlight. A close-up shot highlights the feline's intricate details and the refreshing atmosphere of the seaside."
negative_prompt = "é•œå¤´æ™ƒåŠ¨ï¼Œè‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°"
image_path="/path/to/img_0.jpg"
save_result_path = "/path/to/save_results/output.mp4"

# Generate video
pipe.generate(
    seed=seed,
    image_path=image_path,
    prompt=prompt,
    negative_prompt=negative_prompt,
    save_result_path=save_result_path,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ &lt;strong&gt;More Examples&lt;/strong&gt;: For more usage examples including quantization, offloading, caching, and other advanced configurations, please refer to the &lt;a href="https://github.com/ModelTC/LightX2V/tree/main/examples"&gt;examples directory&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ¤– Supported Model Ecosystem&lt;/h2&gt; 
&lt;h3&gt;Official Open-Source Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/tencent/HunyuanVideo-1.5"&gt;HunyuanVideo-1.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/Wan-AI/"&gt;Wan2.1 &amp;amp; Wan2.2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/Qwen/Qwen-Image"&gt;Qwen-Image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/spaces/Qwen/Qwen-Image-Edit"&gt;Qwen-Image-Edit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/Qwen/Qwen-Image-Edit-2509"&gt;Qwen-Image-Edit-2509&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quantized and Distilled Models/LoRAs (&lt;strong&gt;ğŸš€ Recommended: 4-step inference&lt;/strong&gt;)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Wan2.1-Distill-Models"&gt;Wan2.1-Distill-Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Wan2.2-Distill-Models"&gt;Wan2.2-Distill-Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Wan2.1-Distill-Loras"&gt;Wan2.1-Distill-Loras&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Wan2.2-Distill-Loras"&gt;Wan2.2-Distill-Loras&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Lightweight Autoencoder Models (&lt;strong&gt;ğŸš€ Recommended: fast inference &amp;amp; low memory usage&lt;/strong&gt;)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Autoencoders"&gt;Autoencoders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Autoregressive Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/lightx2v/Wan2.1-T2V-14B-CausVid"&gt;Wan2.1-T2V-CausVid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://github.com/guandeh17/Self-Forcing"&gt;Self-Forcing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;a href="https://huggingface.co/Skywork/Matrix-Game-2.0"&gt;Matrix-Game-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ”” Follow our &lt;a href="https://huggingface.co/lightx2v"&gt;HuggingFace page&lt;/a&gt; for the latest model releases from our team.&lt;/p&gt; 
&lt;p&gt;ğŸ’¡ Refer to the &lt;a href="https://lightx2v-en.readthedocs.io/en/latest/getting_started/model_structure.html"&gt;Model Structure Documentation&lt;/a&gt; to quickly get started with LightX2V&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Frontend Interfaces&lt;/h2&gt; 
&lt;p&gt;We provide multiple frontend interface deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Gradio Interface&lt;/strong&gt;: Clean and user-friendly web interface, perfect for quick experience and prototyping 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ“– &lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/deploy_gradio.html"&gt;Gradio Deployment Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ ComfyUI Interface&lt;/strong&gt;: Powerful node-based workflow interface, supporting complex video generation tasks 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ“– &lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/deploy_comfyui.html"&gt;ComfyUI Deployment Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸš€ Windows One-Click Deployment&lt;/strong&gt;: Convenient deployment solution designed for Windows users, featuring automatic environment configuration and intelligent parameter optimization 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ“– &lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/deploy_local_windows.html"&gt;Windows One-Click Deployment Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ’¡ Recommended Solutions&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;First-time Users&lt;/strong&gt;: We recommend the Windows one-click deployment solution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Users&lt;/strong&gt;: We recommend the ComfyUI interface for more customization options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick Experience&lt;/strong&gt;: The Gradio interface provides the most intuitive operation experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Core Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Ultimate Performance Optimization&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”¥ SOTA Inference Speed&lt;/strong&gt;: Achieve &lt;strong&gt;~20x&lt;/strong&gt; acceleration via step distillation and system optimization (single GPU)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ï¸ Revolutionary 4-Step Distillation&lt;/strong&gt;: Compress original 40-50 step inference to just 4 steps without CFG requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› ï¸ Advanced Operator Support&lt;/strong&gt;: Integrated with cutting-edge operators including &lt;a href="https://github.com/thu-ml/SageAttention"&gt;Sage Attention&lt;/a&gt;, &lt;a href="https://github.com/Dao-AILab/flash-attention"&gt;Flash Attention&lt;/a&gt;, &lt;a href="https://github.com/mit-han-lab/radial-attention"&gt;Radial Attention&lt;/a&gt;, &lt;a href="https://github.com/KONAKONA666/q8_kernels"&gt;q8-kernel&lt;/a&gt;, &lt;a href="https://github.com/sgl-project/sglang/tree/main/sgl-kernel"&gt;sgl-kernel&lt;/a&gt;, &lt;a href="https://github.com/vllm-project/vllm"&gt;vllm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ’¾ &lt;strong&gt;Resource-Efficient Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¡ Breaking Hardware Barriers&lt;/strong&gt;: Run 14B models for 480P/720P video generation with only &lt;strong&gt;8GB VRAM + 16GB RAM&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Intelligent Parameter Offloading&lt;/strong&gt;: Advanced disk-CPU-GPU three-tier offloading architecture with phase/block-level granular management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš™ï¸ Comprehensive Quantization&lt;/strong&gt;: Support for &lt;code&gt;w8a8-int8&lt;/code&gt;, &lt;code&gt;w8a8-fp8&lt;/code&gt;, &lt;code&gt;w4a4-nvfp4&lt;/code&gt; and other quantization strategies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¨ &lt;strong&gt;Rich Feature Ecosystem&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ˆ Smart Feature Caching&lt;/strong&gt;: Intelligent caching mechanisms to eliminate redundant computations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”„ Parallel Inference&lt;/strong&gt;: Multi-GPU parallel processing for enhanced performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“± Flexible Deployment Options&lt;/strong&gt;: Support for Gradio, service deployment, ComfyUI and other deployment methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›ï¸ Dynamic Resolution Inference&lt;/strong&gt;: Adaptive resolution adjustment for optimal generation quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸï¸ Video Frame Interpolation&lt;/strong&gt;: RIFE-based frame interpolation for smooth frame rate enhancement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“š Technical Documentation&lt;/h2&gt; 
&lt;h3&gt;ğŸ“– &lt;strong&gt;Method Tutorials&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/quantization.html"&gt;Model Quantization&lt;/a&gt; - Comprehensive guide to quantization strategies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/cache.html"&gt;Feature Caching&lt;/a&gt; - Intelligent caching mechanisms&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/attention.html"&gt;Attention Mechanisms&lt;/a&gt; - State-of-the-art attention operators&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/offload.html"&gt;Parameter Offloading&lt;/a&gt; - Three-tier storage architecture&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/parallel.html"&gt;Parallel Inference&lt;/a&gt; - Multi-GPU acceleration strategies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/changing_resolution.html"&gt;Changing Resolution Inference&lt;/a&gt; - U-shaped resolution strategy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/step_distill.html"&gt;Step Distillation&lt;/a&gt; - 4-step inference technology&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/method_tutorials/video_frame_interpolation.html"&gt;Video Frame Interpolation&lt;/a&gt; - Base on the RIFE technology&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ› ï¸ &lt;strong&gt;Deployment Guides&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/for_low_resource.html"&gt;Low-Resource Deployment&lt;/a&gt; - Optimized 8GB VRAM solutions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/for_low_latency.html"&gt;Low-Latency Deployment&lt;/a&gt; - Ultra-fast inference optimization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/deploy_gradio.html"&gt;Gradio Deployment&lt;/a&gt; - Web interface setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/deploy_service.html"&gt;Service Deployment&lt;/a&gt; - Production API service deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightx2v-en.readthedocs.io/en/latest/deploy_guides/lora_deploy.html"&gt;Lora Model Deployment&lt;/a&gt; - Flexible Lora deployment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ§¾ Contributing Guidelines&lt;/h2&gt; 
&lt;p&gt;We maintain code quality through automated pre-commit hooks to ensure consistent formatting across the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;Setup Instructions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install required dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install ruff pre-commit
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Run before committing:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pre-commit run --all-files
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We appreciate your contributions to making LightX2V better!&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We extend our gratitude to all the model repositories and research communities that inspired and contributed to the development of LightX2V. This framework builds upon the collective efforts of the open-source community.&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#ModelTC/lightx2v&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=ModelTC/lightx2v&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœï¸ Citation&lt;/h2&gt; 
&lt;p&gt;If you find LightX2V useful in your research, please consider citing our work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{lightx2v,
 author = {LightX2V Contributors},
 title = {LightX2V: Light Video Generation Inference Framework},
 year = {2025},
 publisher = {GitHub},
 journal = {GitHub repository},
 howpublished = {\url{https://github.com/ModelTC/lightx2v}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“ Contact &amp;amp; Support&lt;/h2&gt; 
&lt;p&gt;For questions, suggestions, or support, please feel free to reach out through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;a href="https://github.com/ModelTC/lightx2v/issues"&gt;GitHub Issues&lt;/a&gt; - Bug reports and feature requests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt;
  Built with â¤ï¸ by the LightX2V team 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;ğŸ¯ å‘Šåˆ«ä¿¡æ¯è¿‡è½½ï¼ŒAI åŠ©ä½ çœ‹æ‡‚æ–°é—»èµ„è®¯çƒ­ç‚¹ï¼Œç®€å•çš„èˆ†æƒ…ç›‘æ§åˆ†æ - å¤šå¹³å°çƒ­ç‚¹èšåˆ+åŸºäº MCP çš„AIåˆ†æå·¥å…·ã€‚ç›‘æ§35ä¸ªå¹³å°ï¼ˆæŠ–éŸ³ã€çŸ¥ä¹ã€Bç«™ã€åå°”è¡—è§é—»ã€è´¢è”ç¤¾ç­‰ï¼‰ï¼Œæ™ºèƒ½ç­›é€‰+è‡ªåŠ¨æ¨é€+AIå¯¹è¯åˆ†æï¼ˆç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»ï¼šè¶‹åŠ¿è¿½è¸ªã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ£€ç´¢ç­‰13ç§å·¥å…·ï¼‰ã€‚æ”¯æŒä¼ä¸šå¾®ä¿¡/ä¸ªäººå¾®ä¿¡/é£ä¹¦/é’‰é’‰/Telegram/é‚®ä»¶/ntfy/bark/slack æ¨é€ï¼Œ1åˆ†é’Ÿæ‰‹æœºé€šçŸ¥ï¼Œæ— éœ€ç¼–ç¨‹ã€‚æ”¯æŒDockeréƒ¨ç½²ï¼Œæ”¯æŒæ•°æ®è¿œç¨‹äº‘å­˜å‚¨â­ è®©ç®—æ³•ä¸ºä½ æœåŠ¡ï¼Œç”¨AIç†è§£çƒ­ç‚¹&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="trendradar"&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;ğŸ“¢ å…¬å‘Šï¼š&lt;/strong&gt; &lt;strong&gt;v4.0.0&lt;/strong&gt; ç‰ˆæœ¬å·²å‘å¸ƒï¼åŒ…å«å­˜å‚¨æ¶æ„é‡æ„ã€æ•°æ®åº“ä¼˜åŒ–ã€æ¨¡å—åŒ–æ”¹è¿›ç­‰é‡å¤§æ›´æ–°&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;a href="https://github.com/sansan0/TrendRadar" title="TrendRadar"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner.webp" alt="TrendRadar Banner" width="80%" /&gt; &lt;/a&gt; 
 &lt;p&gt;ğŸš€ æœ€å¿«&lt;strong&gt;30ç§’&lt;/strong&gt;éƒ¨ç½²çš„çƒ­ç‚¹åŠ©æ‰‹ â€”â€” å‘Šåˆ«æ— æ•ˆåˆ·å±ï¼Œåªçœ‹çœŸæ­£å…³å¿ƒçš„æ–°é—»èµ„è®¯&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14726" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14726" alt="sansan0%2FTrendRadar | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://shandianshuo.cn" target="_blank" title="AI è¯­éŸ³è¾“å…¥ï¼Œæ¯”æ‰“å­—å¿« 4 å€ âš¡"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/shandianshuo.png" alt="é—ªç”µè¯´ logo" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=yellow" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/version-v4.0.0-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/MCP-v1.1.0-green.svg?sanitize=true" alt="MCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://work.weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ä¼ä¸šå¾®ä¿¡é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%B8%AA%E4%BA%BA%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ä¸ªäººå¾®ä¿¡é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://telegram.org/"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="Telegramé€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/%E9%92%89%E9%92%89-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="dingtalké€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://www.feishu.cn/"&gt;&lt;img src="https://img.shields.io/badge/%E9%A3%9E%E4%B9%A6-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é£ä¹¦é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/Email-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é‚®ä»¶é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://github.com/binwiederhier/ntfy"&gt;&lt;img src="https://img.shields.io/badge/ntfy-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ntfyé€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Finb/Bark"&gt;&lt;img src="https://img.shields.io/badge/Bark-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="Barké€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://slack.com/"&gt;&lt;img src="https://img.shields.io/badge/Slack-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="Slacké€šçŸ¥" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Actions-%E8%87%AA%E5%8A%A8%E5%8C%96-2088FF?style=flat-square&amp;amp;logo=github-actions&amp;amp;logoColor=white" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://sansan0.github.io/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Pages-%E9%83%A8%E7%BD%B2-4285F4?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Pages" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/wantcat/trendradar"&gt;&lt;img src="https://img.shields.io/badge/Docker-%E9%83%A8%E7%BD%B2-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io/"&gt;&lt;img src="https://img.shields.io/badge/MCP-AI%E5%88%86%E6%9E%90%E6%94%AF%E6%8C%81-FF6B6B?style=flat-square&amp;amp;logo=ai&amp;amp;logoColor=white" alt="MCP Support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;ä¸­æ–‡&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-EN.md"&gt;English&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä»¥è½»é‡ï¼Œæ˜“éƒ¨ç½²ä¸ºç›®æ ‡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸš¨ &lt;strong&gt;ã€å¿…è¯»ã€‘é‡è¦å…¬å‘Šï¼šv4.0.0 éƒ¨ç½²æ–¹å¼ä¸å­˜å‚¨æ¶æ„å˜æ›´&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ› ï¸ è¯·é€‰æ‹©é€‚åˆä½ çš„éƒ¨ç½²æ–¹å¼&lt;/h3&gt; 
 &lt;h4&gt;ğŸ…°ï¸ æ–¹æ¡ˆä¸€ï¼šDocker éƒ¨ç½²ï¼ˆæ¨è ğŸ”¥ï¼‰&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šæœ€ç¨³å®šã€æœ€ç®€å•ï¼Œæ•°æ®å­˜å‚¨åœ¨ &lt;strong&gt;æœ¬åœ° SQLite&lt;/strong&gt;ï¼Œå®Œå…¨è‡ªä¸»å¯æ§ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€‚ç”¨&lt;/strong&gt;ï¼šæœ‰è‡ªå·±çš„æœåŠ¡å™¨ã€NAS æˆ–é•¿æœŸè¿è¡Œçš„ç”µè„‘ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ğŸ‘‰ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;è·³è½¬åˆ° Docker éƒ¨ç½²æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;ğŸ…±ï¸ æ–¹æ¡ˆäºŒï¼šGitHub Actions éƒ¨ç½²ï¼ˆå·²æ¢å¤ âœ…ï¼‰&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šæ•°æ®ä¸å†ç›´æ¥å†™å…¥ä»“åº“ï¼ˆGit Commitï¼‰ï¼Œè€Œæ˜¯å­˜å‚¨åœ¨ &lt;strong&gt;è¿œç¨‹äº‘å­˜å‚¨&lt;/strong&gt;ï¼ˆæ”¯æŒ S3 å…¼å®¹åè®®ï¼šCloudflare R2ã€é˜¿é‡Œäº‘ OSSã€è…¾è®¯äº‘ COS ç­‰ï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é—¨æ§›&lt;/strong&gt;ï¼š&lt;strong&gt;å¿…é¡»&lt;/strong&gt;é…ç½®ä¸€ä¸ª S3 å…¼å®¹çš„å¯¹è±¡å­˜å‚¨æœåŠ¡ï¼ˆæ¨èå…è´¹çš„ Cloudflare R2ï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;âš ï¸ æ³¨æ„&lt;/strong&gt;ï¼šé€‰æ‹©æ­¤æ–¹æ¡ˆï¼Œè¯·åŠ¡å¿…æ‰§è¡Œä»¥ä¸‹ä¸¤æ­¥é…ç½®ï¼š&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;1. ğŸš€ æ¨èçš„å¼€å§‹æ–¹å¼ï¼šUse this template&lt;/h4&gt; 
 &lt;p&gt;ä¸ºäº†ä¿æŒä»“åº“æ•´æ´ï¼Œé¿å…ç»§æ‰¿å†—ä½™çš„å†å²è®°å½•ï¼Œæˆ‘&lt;strong&gt;å»ºè®®&lt;/strong&gt;ä½ ä½¿ç”¨ Template æ¨¡å¼ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç‚¹å‡»&lt;/strong&gt;åŸä»“åº“é¡µé¢å³ä¸Šè§’çš„ç»¿è‰² &lt;strong&gt;[Use this template]&lt;/strong&gt; æŒ‰é’®ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€‰æ‹©&lt;/strong&gt; "Create a new repository"ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;ğŸ’¡ ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿ&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Use this template&lt;/strong&gt;ï¼šåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ã€å¹²å‡€çš„ä»“åº“ï¼Œæ²¡æœ‰å†å²åŒ…è¢±ã€‚&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Fork&lt;/strong&gt;ï¼šä¼šä¿ç•™å®Œæ•´çš„æäº¤å†å²å’Œå…³è”å…³ç³»ï¼Œå ç”¨ GitHub æ›´å¤šèµ„æºã€‚&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;2. â˜ï¸ å…³äº GitHub Actions å¿…é…çš„è¿œç¨‹å­˜å‚¨&lt;/h4&gt; 
 &lt;p&gt;å¦‚æœä½ é€‰æ‹© &lt;strong&gt;æ–¹æ¡ˆäºŒ (GitHub Actions)&lt;/strong&gt;ï¼Œåˆ™å¿…é¡»é…ç½®ä¸€ä¸ª S3 å…¼å®¹çš„å¯¹è±¡å­˜å‚¨æœåŠ¡ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;æ”¯æŒçš„å­˜å‚¨æœåŠ¡ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Cloudflare R2&lt;/strong&gt;ï¼ˆæ¨èï¼Œå…è´¹é¢åº¦å……è¶³ï¼‰&lt;/li&gt; 
  &lt;li&gt;å…¶ä»– S3 å…¼å®¹æœåŠ¡&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ ä»¥ Cloudflare R2 ä¸ºä¾‹çš„é…ç½®å‰ç½®æ¡ä»¶ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;æ ¹æ® Cloudflare å¹³å°è§„åˆ™ï¼Œå¼€é€š R2 éœ€ç»‘å®šæ”¯ä»˜æ–¹å¼ã€‚&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç›®çš„&lt;/strong&gt;ï¼šä»…ä½œèº«ä»½éªŒè¯ï¼ˆVerify Onlyï¼‰ï¼Œ&lt;strong&gt;ä¸äº§ç”Ÿæ‰£è´¹&lt;/strong&gt;ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ”¯ä»˜&lt;/strong&gt;ï¼šæ”¯æŒåŒå¸ä¿¡ç”¨å¡æˆ–å›½åŒº PayPalã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç”¨é‡&lt;/strong&gt;ï¼šR2 çš„å…è´¹é¢åº¦ï¼ˆ10GBå­˜å‚¨/æœˆï¼‰è¶³ä»¥è¦†ç›–æœ¬é¡¹ç›®æ—¥å¸¸è¿è¡Œï¼Œæ— éœ€æ‹…å¿ƒä»˜è´¹ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ğŸ‘‰ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†é…ç½®æ•™ç¨‹&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“‘ å¿«é€Ÿå¯¼èˆª&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90"&gt;ğŸ¤– AI æ™ºèƒ½åˆ†æ&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3"&gt;âš™ï¸ é…ç½®è¯¦è§£&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E%E4%BA%A4%E6%B5%81"&gt;â“ ç­”ç–‘ä¸äº¤æµ&lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Dockeréƒ¨ç½²&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-mcp-%E5%AE%A2%E6%88%B7%E7%AB%AF"&gt;ğŸ”Œ MCPå®¢æˆ·ç«¯&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3"&gt;ğŸ“š é¡¹ç›®ç›¸å…³&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E8%B5%9E%E5%8A%A9%E5%95%86"&gt;ğŸª„ èµåŠ©å•†&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;è€å¿ƒåé¦ˆ bug&lt;/strong&gt; çš„è´¡çŒ®è€…ï¼Œä½ ä»¬çš„æ¯ä¸€æ¡åé¦ˆè®©é¡¹ç›®æ›´åŠ å®Œå–„ğŸ˜‰;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;ä¸ºé¡¹ç›®ç‚¹ star&lt;/strong&gt; çš„è§‚ä¼—ä»¬ï¼Œ&lt;strong&gt;fork&lt;/strong&gt; ä½ æ‰€æ¬²ä¹Ÿï¼Œ&lt;strong&gt;star&lt;/strong&gt; æˆ‘æ‰€æ¬²ä¹Ÿï¼Œä¸¤è€…å¾—å…¼ğŸ˜æ˜¯å¯¹å¼€æºç²¾ç¥æœ€å¥½çš„æ”¯æŒ;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;å…³æ³¨&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E%E4%BA%A4%E6%B5%81"&gt;å…¬ä¼—å·&lt;/a&gt;&lt;/strong&gt; çš„è¯»è€…ä»¬ï¼Œä½ ä»¬çš„ç•™è¨€ã€ç‚¹èµã€åˆ†äº«å’Œæ¨èç­‰ç§¯æäº’åŠ¨è®©å†…å®¹æ›´æœ‰æ¸©åº¦ğŸ˜ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt; (å½“å‰ &lt;strong&gt;ğŸ”¥73ğŸ”¥&lt;/strong&gt; ä½)&lt;/summary&gt; 
 &lt;h3&gt;åŸºç¡€è®¾æ–½æ”¯æŒ&lt;/h3&gt; 
 &lt;p&gt;æ„Ÿè°¢ &lt;strong&gt;GitHub&lt;/strong&gt; å…è´¹æä¾›çš„åŸºç¡€è®¾æ–½ï¼Œè¿™æ˜¯æœ¬é¡¹ç›®å¾—ä»¥&lt;strong&gt;ä¸€é”® fork&lt;/strong&gt;ä¾¿æ·è¿è¡Œçš„æœ€å¤§å‰æã€‚&lt;/p&gt; 
 &lt;h3&gt;æ•°æ®æ”¯æŒ&lt;/h3&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä½¿ç”¨ &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; é¡¹ç›®çš„ API è·å–å¤šå¹³å°æ•°æ®ï¼Œç‰¹åˆ«æ„Ÿè°¢ä½œè€…æä¾›çš„æœåŠ¡ã€‚&lt;/p&gt; 
 &lt;p&gt;ç»è”ç³»ï¼Œä½œè€…è¡¨ç¤ºæ— éœ€æ‹…å¿ƒæœåŠ¡å™¨å‹åŠ›ï¼Œä½†è¿™æ˜¯åŸºäºä»–çš„å–„æ„å’Œä¿¡ä»»ã€‚è¯·å¤§å®¶ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;å‰å¾€ &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow é¡¹ç›®&lt;/a&gt; ç‚¹ star æ”¯æŒ&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Docker éƒ¨ç½²æ—¶ï¼Œè¯·åˆç†æ§åˆ¶æ¨é€é¢‘ç‡ï¼Œå‹¿ç«­æ³½è€Œæ¸”&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;æ¨å¹¿åŠ©åŠ›&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹å¹³å°å’Œä¸ªäººçš„æ¨è(æŒ‰æ—¶é—´æ’åˆ—)&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA"&gt;å°ä¼—è½¯ä»¶&lt;/a&gt; - å¼€æºè½¯ä»¶æ¨èå¹³å°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://linux.do/"&gt;LinuxDo ç¤¾åŒº&lt;/a&gt; - æŠ€æœ¯çˆ±å¥½è€…çš„èšé›†åœ°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ruanyf/weekly"&gt;é˜®ä¸€å³°å‘¨åˆŠ&lt;/a&gt; - æŠ€æœ¯åœˆæœ‰å½±å“åŠ›çš„å‘¨åˆŠ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;è§‚ä¼—æ”¯æŒ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢&lt;strong&gt;ç»™äºˆèµ„é‡‘æ”¯æŒ&lt;/strong&gt;çš„æœ‹å‹ä»¬ï¼Œä½ ä»¬çš„æ…·æ…¨å·²åŒ–èº«ä¸ºé”®ç›˜æ—çš„é›¶é£Ÿé¥®æ–™ï¼Œé™ªä¼´ç€é¡¹ç›®çš„æ¯ä¸€æ¬¡è¿­ä»£ã€‚&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;"ä¸€å…ƒç‚¹èµ"å·²æš‚åœ&lt;/strong&gt;ï¼Œå¦‚ä»æƒ³æ”¯æŒä½œè€…ï¼Œå¯å‰å¾€&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E%E4%BA%A4%E6%B5%81"&gt;å…¬ä¼—å·&lt;/a&gt;æ–‡ç« åº•éƒ¨ç‚¹å‡»"å–œæ¬¢ä½œè€…"ã€‚&lt;/p&gt; 
  &lt;p&gt;ä¸€ä½å¯çˆ±çŒ«å¤´åƒçš„æœ‹å‹ï¼Œä¸çŸ¥ä½ ä»å“ªä¸ªè§’è½ç¿»åˆ°äº†æˆ‘çš„æ”¶æ¬¾ç ï¼Œä¸‰è¿äº† 1.8ï¼Œå¿ƒæ„å·²æ”¶åˆ°ï¼Œæ„Ÿè°¢åšçˆ±&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;ç‚¹èµäºº&lt;/th&gt; 
    &lt;th align="center"&gt;é‡‘é¢&lt;/th&gt; 
    &lt;th align="center"&gt;æ—¥æœŸ&lt;/th&gt; 
    &lt;th align="center"&gt;å¤‡æ³¨&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;D*5&lt;/td&gt; 
    &lt;td align="center"&gt;1.8 * 3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.24&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é¬¼&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è¶…&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;R*w&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.17&lt;/td&gt; 
    &lt;td align="center"&gt;è¿™ agent åšçš„ç‰›é€¼å•Š,å…„å¼Ÿ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.17&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æº,ç¥å¤§ä½¬äº‹ä¸šæœ‰æˆ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ™¨&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.16&lt;/td&gt; 
    &lt;td align="center"&gt;é¡¹ç›®ä¸é”™,ç ”ç©¶å­¦ä¹ ä¸­&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æµ·&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¾·&lt;/td&gt; 
    &lt;td align="center"&gt;1.99&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ç–&lt;/td&gt; 
    &lt;td align="center"&gt;8.8&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.14&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºï¼Œé¡¹ç›®å¾ˆæ£’ï¼Œæ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*e&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.14&lt;/td&gt; 
    &lt;td align="center"&gt;å¼€æºä¸æ˜“ï¼Œå¤§ä½¬è¾›è‹¦äº†&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æŸ¯&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*äº‘&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;å¥½é¡¹ç›®ï¼Œæ„Ÿè°¢å¼€æº&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*W&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å‡¯&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;å¯¹*.&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;Thanks for your TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;s*y&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**ç¿”&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;å¥½é¡¹ç›®ï¼Œç›¸è§æ¨æ™šï¼Œæ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*éŸ¦&lt;/td&gt; 
    &lt;td align="center"&gt;9.9&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadarè¶…èµï¼Œè¯·è€å¸ˆå–å’–å•¡~&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;h*p&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸­å›½å¼€æºåŠ›é‡ï¼ŒåŠ æ²¹ï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;c*r&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;a*n&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;ã€‚*c&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºåˆ†äº«&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.11&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸»&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*äº†&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.09&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.08&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ç‚¹&lt;/td&gt; 
    &lt;td align="center"&gt;8.80&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;å¼€å‘ä¸æ˜“ï¼Œæ”¯æŒä¸€ä¸‹ã€‚&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Q*Q&lt;/td&gt; 
    &lt;td align="center"&gt;6.66&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;C*e&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.05&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Peter Fan&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.29&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.27&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æº&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®¸&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.23&lt;/td&gt; 
    &lt;td align="center"&gt;è€å¸ˆ å°ç™½ä¸€æšï¼Œæ‘¸äº†å‡ å¤©äº†è¿˜æ²¡æ•´èµ·æ¥ï¼Œæ±‚æ•™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Eason&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.22&lt;/td&gt; 
    &lt;td align="center"&gt;è¿˜æ²¡æ•´æ˜ç™½ï¼Œä½†ä½ åœ¨åšå¥½äº‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¾&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.18&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¿—&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ˜€&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ°&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å•¸&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*çºª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*d&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;è°¢è°¢ä½ çš„å·¥å…·ï¼Œå¾ˆå¥½ç©...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*H&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;é‚£*O&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*åœ†&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*g&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Ocean&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.12&lt;/td&gt; 
    &lt;td align="center"&gt;...çœŸçš„å¤ªæ£’äº†ï¼ï¼ï¼å°ç™½çº§åˆ«ä¹Ÿèƒ½ç›´æ¥ç”¨...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**åŸ¹&lt;/td&gt; 
    &lt;td align="center"&gt;5.2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.2&lt;/td&gt; 
    &lt;td align="center"&gt;github-yzyf1312:å¼€æºä¸‡å²&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¤¿&lt;/td&gt; 
    &lt;td align="center"&gt;3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.23&lt;/td&gt; 
    &lt;td align="center"&gt;åŠ æ²¹ï¼Œå¾ˆä¸é”™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.21&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;E*f&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;z*u&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ˜Š&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å·&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;T*T&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å®¶&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*X&lt;/td&gt; 
    &lt;td align="center"&gt;1.11&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.3&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é£™&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.31&lt;/td&gt; 
    &lt;td align="center"&gt;æ¥è‡ªè€ç«¥è°¢è°¢&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸‹&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸‹åˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸Šåˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;S*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.05&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¾ &lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.04&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;x*x&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.03&lt;/td&gt; 
    &lt;td align="center"&gt;trendRadar å¥½é¡¹ç›® ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è¿œ&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é‚ª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¢¦&lt;/td&gt; 
    &lt;td align="center"&gt;0.1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**é¾™&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.29&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;âœ¨ æ ¸å¿ƒåŠŸèƒ½&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;å…¨ç½‘çƒ­ç‚¹èšåˆ&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;çŸ¥ä¹&lt;/li&gt; 
 &lt;li&gt;æŠ–éŸ³&lt;/li&gt; 
 &lt;li&gt;bilibili çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;åå°”è¡—è§é—»&lt;/li&gt; 
 &lt;li&gt;è´´å§&lt;/li&gt; 
 &lt;li&gt;ç™¾åº¦çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;è´¢è”ç¤¾çƒ­é—¨&lt;/li&gt; 
 &lt;li&gt;æ¾æ¹ƒæ–°é—»&lt;/li&gt; 
 &lt;li&gt;å‡¤å‡°ç½‘&lt;/li&gt; 
 &lt;li&gt;ä»Šæ—¥å¤´æ¡&lt;/li&gt; 
 &lt;li&gt;å¾®åš&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;é»˜è®¤ç›‘æ§ 11 ä¸ªä¸»æµå¹³å°ï¼Œä¹Ÿå¯è‡ªè¡Œå¢åŠ é¢å¤–çš„å¹³å°&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ è¯¦ç»†é…ç½®æ•™ç¨‹è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#1-%E5%B9%B3%E5%8F%B0%E9%85%8D%E7%BD%AE"&gt;é…ç½®è¯¦è§£ - å¹³å°é…ç½®&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;æ™ºèƒ½æ¨é€ç­–ç•¥&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ä¸‰ç§æ¨é€æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ¨¡å¼&lt;/th&gt; 
   &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;th&gt;æ¨é€ç‰¹ç‚¹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“æ—¥æ±‡æ€»&lt;/strong&gt; (daily)&lt;/td&gt; 
   &lt;td&gt;ä¼ä¸šç®¡ç†è€…/æ™®é€šç”¨æˆ·&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€å½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—»ï¼ˆä¼šåŒ…å«ä¹‹å‰æ¨é€è¿‡çš„ï¼‰&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“å‰æ¦œå•&lt;/strong&gt; (current)&lt;/td&gt; 
   &lt;td&gt;è‡ªåª’ä½“äºº/å†…å®¹åˆ›ä½œè€…&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€å½“å‰æ¦œå•åŒ¹é…æ–°é—»ï¼ˆæŒç»­åœ¨æ¦œçš„æ¯æ¬¡éƒ½å‡ºç°ï¼‰&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å¢é‡ç›‘æ§&lt;/strong&gt; (incremental)&lt;/td&gt; 
   &lt;td&gt;æŠ•èµ„è€…/äº¤æ˜“å‘˜&lt;/td&gt; 
   &lt;td&gt;ä»…æ¨é€æ–°å¢å†…å®¹ï¼Œé›¶é‡å¤&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ &lt;strong&gt;å¿«é€Ÿé€‰æ‹©æŒ‡å—ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ”„ ä¸æƒ³çœ‹åˆ°é‡å¤æ–°é—» â†’ ç”¨ &lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰&lt;/li&gt; 
  &lt;li&gt;ğŸ“Š æƒ³çœ‹å®Œæ•´æ¦œå•è¶‹åŠ¿ â†’ ç”¨ &lt;code&gt;current&lt;/code&gt;ï¼ˆå½“å‰æ¦œå•ï¼‰&lt;/li&gt; 
  &lt;li&gt;ğŸ“ éœ€è¦æ¯æ—¥æ±‡æ€»æŠ¥å‘Š â†’ ç”¨ &lt;code&gt;daily&lt;/code&gt;ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;è¯¦ç»†å¯¹æ¯”å’Œé…ç½®æ•™ç¨‹è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#3-%E6%8E%A8%E9%80%81%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3"&gt;é…ç½®è¯¦è§£ - æ¨é€æ¨¡å¼è¯¦è§£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;é™„åŠ åŠŸèƒ½&lt;/strong&gt;ï¼ˆå¯é€‰ï¼‰ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;åŠŸèƒ½&lt;/th&gt; 
   &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;th&gt;é»˜è®¤&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼ˆå¦‚ 09:00-18:00ï¼‰ï¼Œé¿å…éå·¥ä½œæ—¶é—´æ‰“æ‰°&lt;/td&gt; 
   &lt;td&gt;å…³é—­&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å†…å®¹é¡ºåºé…ç½®&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;è°ƒæ•´"çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡"å’Œ"æ–°å¢çƒ­ç‚¹æ–°é—»"çš„æ˜¾ç¤ºé¡ºåºï¼ˆv3.5.0 æ–°å¢ï¼‰&lt;/td&gt; 
   &lt;td&gt;ç»Ÿè®¡åœ¨å‰&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ è¯¦ç»†é…ç½®æ•™ç¨‹è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#7-%E6%8A%A5%E5%91%8A%E9%85%8D%E7%BD%AE"&gt;é…ç½®è¯¦è§£ - æŠ¥å‘Šé…ç½®&lt;/a&gt; å’Œ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#8-%E6%8E%A8%E9%80%81%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3%E9%85%8D%E7%BD%AE"&gt;é…ç½®è¯¦è§£ - æ¨é€æ—¶é—´çª—å£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;ç²¾å‡†å†…å®¹ç­›é€‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;è®¾ç½®ä¸ªäººå…³é”®è¯ï¼ˆå¦‚ï¼šAIã€æ¯”äºšè¿ªã€æ•™è‚²æ”¿ç­–ï¼‰ï¼Œåªæ¨é€ç›¸å…³çƒ­ç‚¹ï¼Œè¿‡æ»¤æ— å…³ä¿¡æ¯&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;åŸºç¡€è¯­æ³•&lt;/strong&gt;ï¼ˆ5ç§ï¼‰ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ™®é€šè¯ï¼šåŸºç¡€åŒ¹é…&lt;/li&gt; 
 &lt;li&gt;å¿…é¡»è¯ &lt;code&gt;+&lt;/code&gt;ï¼šé™å®šèŒƒå›´&lt;/li&gt; 
 &lt;li&gt;è¿‡æ»¤è¯ &lt;code&gt;!&lt;/code&gt;ï¼šæ’é™¤å¹²æ‰°&lt;/li&gt; 
 &lt;li&gt;æ•°é‡é™åˆ¶ &lt;code&gt;@&lt;/code&gt;ï¼šæ§åˆ¶æ˜¾ç¤ºæ•°é‡ï¼ˆv3.2.0 æ–°å¢ï¼‰&lt;/li&gt; 
 &lt;li&gt;å…¨å±€è¿‡æ»¤ &lt;code&gt;[GLOBAL_FILTER]&lt;/code&gt;ï¼šå…¨å±€æ’é™¤æŒ‡å®šå†…å®¹ï¼ˆv3.5.0 æ–°å¢ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;é«˜çº§åŠŸèƒ½&lt;/strong&gt;ï¼ˆv3.2.0 æ–°å¢ï¼‰ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”¢ &lt;strong&gt;å…³é”®è¯æ’åºæ§åˆ¶&lt;/strong&gt;ï¼šæŒ‰çƒ­åº¦ä¼˜å…ˆ or é…ç½®é¡ºåºä¼˜å…ˆ&lt;/li&gt; 
 &lt;li&gt;ğŸ“Š &lt;strong&gt;æ˜¾ç¤ºæ•°é‡ç²¾å‡†é™åˆ¶&lt;/strong&gt;ï¼šå…¨å±€é…ç½® + å•ç‹¬é…ç½®ï¼Œçµæ´»æ§åˆ¶æ¨é€é•¿åº¦&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;è¯ç»„åŒ–ç®¡ç†&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç©ºè¡Œåˆ†éš”ï¼Œç‹¬ç«‹ç»Ÿè®¡ä¸åŒä¸»é¢˜çƒ­ç‚¹&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ &lt;strong&gt;åŸºç¡€é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E5%85%B3%E9%94%AE%E8%AF%8D%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95"&gt;å…³é”®è¯é…ç½® - åŸºç¡€è¯­æ³•&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;ğŸ’¡ &lt;strong&gt;é«˜çº§é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E5%85%B3%E9%94%AE%E8%AF%8D%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE"&gt;å…³é”®è¯é…ç½® - é«˜çº§é…ç½®&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;ğŸ’¡ ä¹Ÿå¯ä»¥ä¸åšç­›é€‰ï¼Œå®Œæ•´æ¨é€æ‰€æœ‰çƒ­ç‚¹ï¼ˆå°† frequency_words.txt ç•™ç©ºï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;çƒ­ç‚¹è¶‹åŠ¿åˆ†æ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;å®æ—¶è¿½è¸ªæ–°é—»çƒ­åº¦å˜åŒ–ï¼Œè®©ä½ ä¸ä»…çŸ¥é“"ä»€ä¹ˆåœ¨çƒ­æœ"ï¼Œæ›´äº†è§£"çƒ­ç‚¹å¦‚ä½•æ¼”å˜"&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´è½´è¿½è¸ª&lt;/strong&gt;ï¼šè®°å½•æ¯æ¡æ–°é—»ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„å®Œæ•´æ—¶é—´è·¨åº¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;çƒ­åº¦å˜åŒ–&lt;/strong&gt;ï¼šç»Ÿè®¡æ–°é—»åœ¨ä¸åŒæ—¶é—´æ®µçš„æ’åå˜åŒ–å’Œå‡ºç°é¢‘æ¬¡&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–°å¢æ£€æµ‹&lt;/strong&gt;ï¼šå®æ—¶è¯†åˆ«æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜ï¼Œç”¨ğŸ†•æ ‡è®°ç¬¬ä¸€æ—¶é—´æé†’&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŒç»­æ€§åˆ†æ&lt;/strong&gt;ï¼šåŒºåˆ†ä¸€æ¬¡æ€§çƒ­ç‚¹è¯é¢˜å’ŒæŒç»­å‘é…µçš„æ·±åº¦æ–°é—»&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è·¨å¹³å°å¯¹æ¯”&lt;/strong&gt;ï¼šåŒä¸€æ–°é—»åœ¨ä¸åŒå¹³å°çš„æ’åè¡¨ç°ï¼Œçœ‹å‡ºåª’ä½“å…³æ³¨åº¦å·®å¼‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ æ¨é€æ ¼å¼è¯´æ˜è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#5-%E6%8E%A8%E9%80%81%E6%A0%BC%E5%BC%8F%E5%8F%82%E8%80%83"&gt;é…ç½®è¯¦è§£ - æ¨é€æ ¼å¼å‚è€ƒ&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;ä¸ªæ€§åŒ–çƒ­ç‚¹ç®—æ³•&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä¸å†è¢«å„ä¸ªå¹³å°çš„ç®—æ³•ç‰µç€èµ°ï¼ŒTrendRadar ä¼šé‡æ–°æ•´ç†å…¨ç½‘çƒ­æœï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;çœ‹é‡æ’åé«˜çš„æ–°é—»&lt;/strong&gt;ï¼ˆå 60%ï¼‰ï¼šå„å¹³å°å‰å‡ åçš„æ–°é—»ä¼˜å…ˆæ˜¾ç¤º&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…³æ³¨æŒç»­å‡ºç°çš„è¯é¢˜&lt;/strong&gt;ï¼ˆå 30%ï¼‰ï¼šåå¤å‡ºç°çš„æ–°é—»æ›´é‡è¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è€ƒè™‘æ’åè´¨é‡&lt;/strong&gt;ï¼ˆå 10%ï¼‰ï¼šä¸ä»…å¤šæ¬¡å‡ºç°ï¼Œè¿˜ç»å¸¸æ’åœ¨å‰åˆ—&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ è¿™ä¸‰ä¸ªæ¯”ä¾‹å¯ä»¥è°ƒæ•´ï¼Œè¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#4-%E7%83%AD%E7%82%B9%E6%9D%83%E9%87%8D%E8%B0%83%E6%95%B4"&gt;é…ç½®è¯¦è§£ - çƒ­ç‚¹æƒé‡è°ƒæ•´&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šæ¸ é“å®æ—¶æ¨é€&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒ&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;(+ å¾®ä¿¡æ¨é€æ–¹æ¡ˆ)ã€&lt;strong&gt;é£ä¹¦&lt;/strong&gt;ã€&lt;strong&gt;é’‰é’‰&lt;/strong&gt;ã€&lt;strong&gt;Telegram&lt;/strong&gt;ã€&lt;strong&gt;é‚®ä»¶&lt;/strong&gt;ã€&lt;strong&gt;ntfy&lt;/strong&gt;ã€&lt;strong&gt;Bark&lt;/strong&gt;ã€&lt;strong&gt;Slack&lt;/strong&gt;ï¼Œæ¶ˆæ¯ç›´è¾¾æ‰‹æœºå’Œé‚®ç®±&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ“Œ å¤šè´¦å·æ¨é€è¯´æ˜ï¼ˆv3.5.0 æ–°å¢ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;æ”¯æŒå¤šè´¦å·é…ç½®&lt;/strong&gt;ï¼šæ‰€æœ‰æ¨é€æ¸ é“ï¼ˆé£ä¹¦ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ã€Telegramã€ntfyã€Barkã€Slackï¼‰å‡æ”¯æŒé…ç½®å¤šä¸ªè´¦å·&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;é…ç½®æ–¹å¼&lt;/strong&gt;ï¼šä½¿ç”¨è‹±æ–‡åˆ†å· &lt;code&gt;;&lt;/code&gt; åˆ†éš”å¤šä¸ªè´¦å·å€¼&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt; çš„ Secret å€¼å¡«å†™ &lt;code&gt;https://webhook1;https://webhook2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;âš ï¸ &lt;strong&gt;é…å¯¹é…ç½®&lt;/strong&gt;ï¼šTelegram å’Œ ntfy éœ€è¦ä¿è¯é…å¯¹å‚æ•°æ•°é‡ä¸€è‡´ï¼ˆå¦‚ token å’Œ chat_id éƒ½æ˜¯ 2 ä¸ªï¼‰&lt;/li&gt; 
 &lt;li&gt;âš ï¸ &lt;strong&gt;æ•°é‡é™åˆ¶&lt;/strong&gt;ï¼šé»˜è®¤æ¯ä¸ªæ¸ é“æœ€å¤š 3 ä¸ªè´¦å·ï¼Œè¶…å‡ºä¼šè¢«æˆªæ–­&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;çµæ´»å­˜å‚¨æ¶æ„&lt;/strong&gt;ï¼ˆv4.0.0 é‡å¤§æ›´æ–°ï¼‰&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;å¤šå­˜å‚¨åç«¯æ”¯æŒ&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;â˜ï¸ &lt;strong&gt;è¿œç¨‹äº‘å­˜å‚¨&lt;/strong&gt;ï¼šGitHub Actions ç¯å¢ƒé»˜è®¤ï¼Œæ”¯æŒ S3 å…¼å®¹åè®®ï¼ˆR2/OSS/COS ç­‰ï¼‰ï¼Œæ•°æ®å­˜å‚¨åœ¨äº‘ç«¯ï¼Œä¸æ±¡æŸ“ä»“åº“&lt;/li&gt; 
 &lt;li&gt;ğŸ’¾ &lt;strong&gt;æœ¬åœ° SQLite æ•°æ®åº“&lt;/strong&gt;ï¼šDocker/æœ¬åœ°ç¯å¢ƒé»˜è®¤ï¼Œæ•°æ®å®Œå…¨å¯æ§&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;è‡ªåŠ¨åç«¯é€‰æ‹©&lt;/strong&gt;ï¼šæ ¹æ®è¿è¡Œç¯å¢ƒæ™ºèƒ½åˆ‡æ¢å­˜å‚¨æ–¹å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;æ•°æ®æ ¼å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ ¼å¼&lt;/th&gt; 
   &lt;th&gt;ç”¨é€”&lt;/th&gt; 
   &lt;th&gt;è¯´æ˜&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SQLite&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ä¸»å­˜å‚¨&lt;/td&gt; 
   &lt;td&gt;å•æ–‡ä»¶æ•°æ®åº“ï¼ŒæŸ¥è¯¢å¿«é€Ÿï¼Œæ”¯æŒ MCP AI åˆ†æ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TXT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;å¯é€‰å¿«ç…§&lt;/td&gt; 
   &lt;td&gt;å¯è¯»æ–‡æœ¬æ ¼å¼ï¼Œæ–¹ä¾¿ç›´æ¥æŸ¥çœ‹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;HTML&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;æŠ¥å‘Šå±•ç¤º&lt;/td&gt; 
   &lt;td&gt;ç²¾ç¾å¯è§†åŒ–é¡µé¢ï¼ŒPC/ç§»åŠ¨ç«¯é€‚é…&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;æ•°æ®ç®¡ç†&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… è‡ªåŠ¨æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆå¯é…ç½®ä¿ç•™å¤©æ•°ï¼‰&lt;/li&gt; 
 &lt;li&gt;âœ… æ—¶åŒºé…ç½®æ”¯æŒï¼ˆå…¨çƒæ—¶åŒºï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ è¯¦ç»†è¯´æ˜è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#9-%E5%AD%98%E5%82%A8%E9%85%8D%E7%BD%AE"&gt;é…ç½®è¯¦è§£ - å­˜å‚¨é…ç½®&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šç«¯éƒ¨ç½²&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Actions&lt;/strong&gt;ï¼šå®šæ—¶è‡ªåŠ¨çˆ¬å– + è¿œç¨‹äº‘å­˜å‚¨ï¼ˆéœ€ç­¾åˆ°ç»­æœŸï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker éƒ¨ç½²&lt;/strong&gt;ï¼šæ”¯æŒå¤šæ¶æ„å®¹å™¨åŒ–è¿è¡Œï¼Œæ•°æ®æœ¬åœ°å­˜å‚¨&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æœ¬åœ°è¿è¡Œ&lt;/strong&gt;ï¼šWindows/Mac/Linux ç›´æ¥è¿è¡Œ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;AI æ™ºèƒ½åˆ†æï¼ˆv3.0.0 æ–°å¢ï¼‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åŸºäº MCP (Model Context Protocol) åè®®çš„ AI å¯¹è¯åˆ†æç³»ç»Ÿï¼Œè®©ä½ ç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»æ•°æ®&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å¯¹è¯å¼æŸ¥è¯¢&lt;/strong&gt;ï¼šç”¨è‡ªç„¶è¯­è¨€æé—®ï¼Œå¦‚"æŸ¥è¯¢æ˜¨å¤©çŸ¥ä¹çš„çƒ­ç‚¹"ã€"åˆ†ææ¯”ç‰¹å¸æœ€è¿‘çš„çƒ­åº¦è¶‹åŠ¿"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;13 ç§åˆ†æå·¥å…·&lt;/strong&gt;ï¼šæ¶µç›–åŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€è¶‹åŠ¿åˆ†æã€æ•°æ®æ´å¯Ÿã€æƒ…æ„Ÿåˆ†æç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒ&lt;/strong&gt;ï¼šCherry Studioï¼ˆGUI é…ç½®ï¼‰ã€Claude Desktopã€Cursorã€Cline ç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ·±åº¦åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;è¯é¢˜è¶‹åŠ¿è¿½è¸ªï¼ˆçƒ­åº¦å˜åŒ–ã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
   &lt;li&gt;è·¨å¹³å°æ•°æ®å¯¹æ¯”ï¼ˆæ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
   &lt;li&gt;æ™ºèƒ½æ‘˜è¦ç”Ÿæˆã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€å†å²å…³è”æ£€ç´¢&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ ä½¿ç”¨æç¤º&lt;/strong&gt;ï¼šAI åŠŸèƒ½éœ€è¦æœ¬åœ°æ–°é—»æ•°æ®æ”¯æŒ&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é¡¹ç›®è‡ªå¸¦ &lt;strong&gt;11æœˆ1-15æ—¥&lt;/strong&gt; æµ‹è¯•æ•°æ®ï¼Œå¯ç«‹å³ä½“éªŒ&lt;/li&gt; 
  &lt;li&gt;å»ºè®®è‡ªè¡Œéƒ¨ç½²è¿è¡Œé¡¹ç›®ï¼Œè·å–æ›´å®æ—¶çš„æ•°æ®&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;è¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90"&gt;AI æ™ºèƒ½åˆ†æ&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;é›¶æŠ€æœ¯é—¨æ§›éƒ¨ç½²&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GitHub ä¸€é”® Fork å³å¯ä½¿ç”¨ï¼Œæ— éœ€ç¼–ç¨‹åŸºç¡€ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;30ç§’éƒ¨ç½²ï¼š GitHub Pagesï¼ˆç½‘é¡µæµè§ˆï¼‰æ”¯æŒä¸€é”®ä¿å­˜æˆå›¾ç‰‡ï¼Œéšæ—¶åˆ†äº«ç»™ä»–äºº&lt;/p&gt; 
 &lt;p&gt;1åˆ†é’Ÿéƒ¨ç½²ï¼š ä¼ä¸šå¾®ä¿¡ï¼ˆæ‰‹æœºé€šçŸ¥ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æç¤ºï¼š&lt;/strong&gt; æƒ³è¦&lt;strong&gt;å®æ—¶æ›´æ–°&lt;/strong&gt;çš„ç½‘é¡µç‰ˆï¼Ÿfork åï¼Œè¿›å…¥ä½ çš„ä»“åº“ Settings â†’ Pagesï¼Œå¯ç”¨ GitHub Pagesã€‚&lt;a href="https://sansan0.github.io/TrendRadar/"&gt;æ•ˆæœé¢„è§ˆ&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;å‡å°‘ APP ä¾èµ–&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä»"è¢«ç®—æ³•æ¨èç»‘æ¶"å˜æˆ"ä¸»åŠ¨è·å–è‡ªå·±æƒ³è¦çš„ä¿¡æ¯"&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤ï¼š&lt;/strong&gt; æŠ•èµ„è€…ã€è‡ªåª’ä½“äººã€ä¼ä¸šå…¬å…³ã€å…³å¿ƒæ—¶äº‹çš„æ™®é€šç”¨æˆ·&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å…¸å‹åœºæ™¯ï¼š&lt;/strong&gt; è‚¡å¸‚æŠ•èµ„ç›‘æ§ã€å“ç‰Œèˆ†æƒ…è¿½è¸ªã€è¡Œä¸šåŠ¨æ€å…³æ³¨ã€ç”Ÿæ´»èµ„è®¯è·å–&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Github Pages æ•ˆæœ(æ‰‹æœºç«¯é€‚é…ã€é‚®ç®±æ¨é€æ•ˆæœ)&lt;/th&gt; 
   &lt;th align="center"&gt;é£ä¹¦æ¨é€æ•ˆæœ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/github-pages.png" alt="Github Pagesæ•ˆæœ" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/feishu.jpg" alt="é£ä¹¦æ¨é€æ•ˆæœ" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Œ æŸ¥çœ‹æœ€æ–°æ›´æ–°&lt;/strong&gt;ï¼š&lt;strong&gt;&lt;a href="https://github.com/sansan0/TrendRadar?tab=readme-ov-file#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;åŸä»“åº“æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šä¸è¦é€šè¿‡ &lt;strong&gt;Sync fork&lt;/strong&gt; æ›´æ–°æœ¬é¡¹ç›®ï¼Œå»ºè®®æŸ¥çœ‹ã€å†å²æ›´æ–°ã€‘ï¼Œæ˜ç¡®å…·ä½“çš„ã€å‡çº§æ–¹å¼ã€‘å’Œã€åŠŸèƒ½å†…å®¹ã€‘&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§ç‰ˆæœ¬å‡çº§&lt;/strong&gt;ï¼šä» v1.x å‡çº§åˆ° v2.yï¼Œå»ºè®®åˆ é™¤ç°æœ‰ fork åé‡æ–° forkï¼Œè¿™æ ·æ›´çœåŠ›ä¸”é¿å…é…ç½®å†²çª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/12/17 - v4.0.1&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;StorageManager æ·»åŠ æ¨é€è®°å½•ä»£ç†æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;S3 å®¢æˆ·ç«¯åˆ‡æ¢è‡³ virtual-hosted style ä»¥æå‡å…¼å®¹æ€§ï¼ˆæ”¯æŒè…¾è®¯äº‘ COS ç­‰æ›´å¤šæœåŠ¡ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/12/13 - mcp-v1.1.0&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;é€‚é… v4.0.0ï¼ŒåŒæ—¶ä¹Ÿå…¼å®¹ v3.x çš„æ•°æ®&lt;/li&gt; 
 &lt;li&gt;æ–°å¢å­˜å‚¨åŒæ­¥å·¥å…·ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sync_from_remote&lt;/code&gt;: ä»è¿œç¨‹å­˜å‚¨æ‹‰å–æ•°æ®åˆ°æœ¬åœ°&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;get_storage_status&lt;/code&gt;: è·å–å­˜å‚¨é…ç½®å’ŒçŠ¶æ€&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;list_available_dates&lt;/code&gt;: åˆ—å‡ºæœ¬åœ°/è¿œç¨‹å¯ç”¨æ—¥æœŸèŒƒå›´&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;å†å²æ›´æ–°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;2025/12/13 - v4.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ‰ é‡å¤§æ›´æ–°ï¼šå…¨é¢é‡æ„å­˜å‚¨å’Œæ ¸å¿ƒæ¶æ„&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;å¤šå­˜å‚¨åç«¯æ”¯æŒ&lt;/strong&gt;ï¼šå¼•å…¥å…¨æ–°çš„å­˜å‚¨æ¨¡å—ï¼Œæ”¯æŒæœ¬åœ° SQLite å’Œè¿œç¨‹äº‘å­˜å‚¨ï¼ˆS3 å…¼å®¹åè®®ï¼Œæ¨èå…è´¹çš„ Cloudflare R2ï¼‰ï¼Œé€‚åº” GitHub Actionsã€Docker å’Œæœ¬åœ°ç¯å¢ƒã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ•°æ®åº“ç»“æ„ä¼˜åŒ–&lt;/strong&gt;ï¼šé‡æ„ SQLite æ•°æ®åº“è¡¨ç»“æ„ï¼Œæå‡æ•°æ®æ•ˆç‡å’ŒæŸ¥è¯¢èƒ½åŠ›ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ ¸å¿ƒä»£ç æ¨¡å—åŒ–&lt;/strong&gt;ï¼šå°†ä¸»ç¨‹åºé€»è¾‘æ‹†åˆ†ä¸º trendradar åŒ…çš„å¤šä¸ªæ¨¡å—ï¼Œæ˜¾è‘—æå‡ä»£ç å¯ç»´æŠ¤æ€§ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å¢å¼ºåŠŸèƒ½&lt;/strong&gt;ï¼šå®ç°æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–ã€æ•°æ®ä¿ç•™ç­–ç•¥ã€æ—¶åŒºé…ç½®æ”¯æŒã€æ—¶é—´æ˜¾ç¤ºä¼˜åŒ–ï¼Œå¹¶ä¿®å¤è¿œç¨‹å­˜å‚¨æ•°æ®æŒä¹…åŒ–é—®é¢˜ï¼Œç¡®ä¿æ•°æ®åˆå¹¶çš„å‡†ç¡®æ€§ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ¸…ç†å’Œå…¼å®¹&lt;/strong&gt;ï¼šç§»é™¤äº†å¤§éƒ¨åˆ†å†å²å…¼å®¹ä»£ç ï¼Œç»Ÿä¸€äº†æ•°æ®å­˜å‚¨å’Œè¯»å–æ–¹å¼ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/12/03 - v3.5.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ‰ æ ¸å¿ƒåŠŸèƒ½å¢å¼º&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¤šè´¦å·æ¨é€æ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ‰€æœ‰æ¨é€æ¸ é“ï¼ˆé£ä¹¦ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ã€Telegramã€ntfyã€Barkã€Slackï¼‰æ”¯æŒå¤šè´¦å·é…ç½®&lt;/li&gt; 
    &lt;li&gt;ä½¿ç”¨åˆ†å· &lt;code&gt;;&lt;/code&gt; åˆ†éš”å¤šä¸ªè´¦å·ï¼Œä¾‹å¦‚ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL=url1;url2&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;è‡ªåŠ¨éªŒè¯é…å¯¹é…ç½®ï¼ˆå¦‚ Telegram çš„ token å’Œ chat_idï¼‰æ•°é‡ä¸€è‡´æ€§&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ¨é€å†…å®¹é¡ºåºå¯é…ç½®&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ–°å¢ &lt;code&gt;reverse_content_order&lt;/code&gt; é…ç½®é¡¹&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒè‡ªå®šä¹‰çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡ä¸æ–°å¢çƒ­ç‚¹æ–°é—»çš„æ˜¾ç¤ºé¡ºåº&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å…¨å±€è¿‡æ»¤å…³é”®è¯&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ–°å¢ &lt;code&gt;[GLOBAL_FILTER]&lt;/code&gt; åŒºåŸŸæ ‡è®°ï¼Œæ”¯æŒå…¨å±€è¿‡æ»¤ä¸æƒ³çœ‹åˆ°çš„å†…å®¹&lt;/li&gt; 
    &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šè¿‡æ»¤å¹¿å‘Šã€è¥é”€ã€ä½è´¨å†…å®¹ç­‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ³ Docker åŒè·¯å¾„ HTML ç”Ÿæˆä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;é—®é¢˜ä¿®å¤&lt;/strong&gt;ï¼šè§£å†³ Docker ç¯å¢ƒä¸‹ &lt;code&gt;index.html&lt;/code&gt; æ— æ³•åŒæ­¥åˆ°å®¿ä¸»æœºçš„é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;åŒè·¯å¾„ç”Ÿæˆ&lt;/strong&gt;ï¼šå½“æ—¥æ±‡æ€» HTML åŒæ—¶ç”Ÿæˆåˆ°ä¸¤ä¸ªä½ç½® 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;index.html&lt;/code&gt;ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰ï¼šä¾› GitHub Pages è®¿é—®&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;output/index.html&lt;/code&gt;ï¼šé€šè¿‡ Docker Volume æŒ‚è½½ï¼Œå®¿ä¸»æœºå¯ç›´æ¥è®¿é—®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å…¼å®¹æ€§&lt;/strong&gt;ï¼šç¡®ä¿ Dockerã€GitHub Actionsã€æœ¬åœ°è¿è¡Œç¯å¢ƒå‡èƒ½æ­£å¸¸è®¿é—®ç½‘é¡µç‰ˆæŠ¥å‘Š&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ³ Docker MCP é•œåƒæ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢ç‹¬ç«‹çš„ MCP æœåŠ¡é•œåƒ &lt;code&gt;wantcat/trendradar-mcp&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒ Docker éƒ¨ç½² AI åˆ†æåŠŸèƒ½ï¼Œé€šè¿‡ HTTP æ¥å£ï¼ˆç«¯å£ 3333ï¼‰æä¾›æœåŠ¡&lt;/li&gt; 
  &lt;li&gt;åŒå®¹å™¨æ¶æ„ï¼šæ–°é—»æ¨é€æœåŠ¡ä¸ MCP æœåŠ¡ç‹¬ç«‹è¿è¡Œï¼Œå¯åˆ†åˆ«æ‰©å±•å’Œé‡å¯&lt;/li&gt; 
  &lt;li&gt;è¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;Docker éƒ¨ç½² - MCP æœåŠ¡&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸŒ Web æœåŠ¡å™¨æ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢å†…ç½® Web æœåŠ¡å™¨ï¼Œæ”¯æŒé€šè¿‡æµè§ˆå™¨è®¿é—®ç”Ÿæˆçš„æŠ¥å‘Š&lt;/li&gt; 
  &lt;li&gt;é€šè¿‡ &lt;code&gt;manage.py&lt;/code&gt; å‘½ä»¤æ§åˆ¶å¯åŠ¨/åœæ­¢ï¼š&lt;code&gt;docker exec -it trend-radar python manage.py start_webserver&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;è®¿é—®åœ°å€ï¼š&lt;code&gt;http://localhost:8080&lt;/code&gt;ï¼ˆç«¯å£å¯é…ç½®ï¼‰&lt;/li&gt; 
  &lt;li&gt;å®‰å…¨ç‰¹æ€§ï¼šé™æ€æ–‡ä»¶æœåŠ¡ã€ç›®å½•é™åˆ¶ã€æœ¬åœ°è®¿é—®&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒè‡ªåŠ¨å¯åŠ¨å’Œæ‰‹åŠ¨æ§åˆ¶ä¸¤ç§æ¨¡å¼&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“– æ–‡æ¡£ä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#7-%E6%8A%A5%E5%91%8A%E9%85%8D%E7%BD%AE"&gt;æŠ¥å‘Šé…ç½®&lt;/a&gt; ç« èŠ‚ï¼šreport ç›¸å…³å‚æ•°è¯¦è§£&lt;/li&gt; 
  &lt;li&gt;æ–°å¢ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#8-%E6%8E%A8%E9%80%81%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3%E9%85%8D%E7%BD%AE"&gt;æ¨é€æ—¶é—´çª—å£é…ç½®&lt;/a&gt; ç« èŠ‚ï¼špush_window é…ç½®æ•™ç¨‹&lt;/li&gt; 
  &lt;li&gt;æ–°å¢ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#9-%E6%89%A7%E8%A1%8C%E9%A2%91%E7%8E%87%E9%85%8D%E7%BD%AE"&gt;æ‰§è¡Œé¢‘ç‡é…ç½®&lt;/a&gt; ç« èŠ‚ï¼šCron è¡¨è¾¾å¼è¯´æ˜å’Œå¸¸ç”¨ç¤ºä¾‹&lt;/li&gt; 
  &lt;li&gt;æ–°å¢ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#10-%E5%A4%9A%E8%B4%A6%E5%8F%B7%E6%8E%A8%E9%80%81%E9%85%8D%E7%BD%AE"&gt;å¤šè´¦å·æ¨é€é…ç½®&lt;/a&gt; ç« èŠ‚ï¼šå¤šè´¦å·æ¨é€é…ç½®è¯¦è§£&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ–å„é…ç½®ç« èŠ‚ï¼šç»Ÿä¸€æ·»åŠ "é…ç½®ä½ç½®"è¯´æ˜&lt;/li&gt; 
  &lt;li&gt;ç®€åŒ–å¿«é€Ÿå¼€å§‹é…ç½®è¯´æ˜ï¼šä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶ä¸€ç›®äº†ç„¶&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ– &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;Docker éƒ¨ç½²&lt;/a&gt; ç« èŠ‚ï¼šæ–°å¢é•œåƒè¯´æ˜ã€æ¨è git clone éƒ¨ç½²ã€é‡ç»„éƒ¨ç½²æ–¹å¼&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·&lt;/strong&gt;ï¼šæ›´æ–° &lt;code&gt;main.py&lt;/code&gt;ã€&lt;code&gt;config/config.yaml&lt;/code&gt;ï¼ˆæ–°å¢å¤šè´¦å·æ¨é€æ”¯æŒï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰é…ç½®ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å¤šè´¦å·æ¨é€&lt;/strong&gt;ï¼šæ–°åŠŸèƒ½ï¼Œé»˜è®¤ä¸å¯ç”¨ï¼Œç°æœ‰å•è´¦å·é…ç½®ä¸å—å½±å“&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/26 - mcp-v1.0.3&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢æ—¥æœŸè§£æå·¥å…· resolve_date_range,è§£å†³ AI æ¨¡å‹è®¡ç®—æ—¥æœŸä¸ä¸€è‡´çš„é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒè‡ªç„¶è¯­è¨€æ—¥æœŸè¡¨è¾¾å¼è§£æ(æœ¬å‘¨ã€æœ€è¿‘7å¤©ã€ä¸Šæœˆç­‰)&lt;/li&gt; 
  &lt;li&gt;å·¥å…·æ€»æ•°ä» 13 ä¸ªå¢åŠ åˆ° 14 ä¸ª&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/28 - v3.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ æ ¼å¼ä¼˜åŒ–&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bark æ¨é€å¢å¼º&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Bark ç°æ”¯æŒ Markdown æ¸²æŸ“&lt;/li&gt; 
    &lt;li&gt;å¯ç”¨åŸç”Ÿ Markdown æ ¼å¼ï¼šç²—ä½“ã€é“¾æ¥ã€åˆ—è¡¨ã€ä»£ç å—ç­‰&lt;/li&gt; 
    &lt;li&gt;ç§»é™¤çº¯æ–‡æœ¬è½¬æ¢ï¼Œå……åˆ†åˆ©ç”¨ Bark åŸç”Ÿæ¸²æŸ“èƒ½åŠ›&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Slack æ ¼å¼ç²¾å‡†åŒ–&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä½¿ç”¨ä¸“ç”¨ mrkdwn æ ¼å¼å¤„ç†åˆ†æ‰¹å†…å®¹&lt;/li&gt; 
    &lt;li&gt;æå‡å­—èŠ‚å¤§å°ä¼°ç®—å‡†ç¡®æ€§ï¼ˆé¿å…æ¶ˆæ¯è¶…é™ï¼‰&lt;/li&gt; 
    &lt;li&gt;ä¼˜åŒ–é“¾æ¥æ ¼å¼ï¼š&lt;code&gt;&amp;lt;url|text&amp;gt;&lt;/code&gt; å’ŒåŠ ç²—è¯­æ³•ï¼š&lt;code&gt;*text*&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ€§èƒ½æå‡&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ ¼å¼è½¬æ¢åœ¨åˆ†æ‰¹è¿‡ç¨‹ä¸­å®Œæˆï¼Œé¿å…äºŒæ¬¡å¤„ç†&lt;/li&gt; 
    &lt;li&gt;å‡†ç¡®ä¼°ç®—æ¶ˆæ¯å¤§å°ï¼Œå‡å°‘å‘é€å¤±è´¥ç‡&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·&lt;/strong&gt;ï¼šæ›´æ–° &lt;code&gt;main.py&lt;/code&gt;ï¼Œ&lt;code&gt;config.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/25 - v3.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ‰ æ–°å¢ Slack æ¨é€æ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å›¢é˜Ÿåä½œæ¨é€æ¸ é“&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒ Slack Incoming Webhooksï¼ˆå…¨çƒæµè¡Œçš„å›¢é˜Ÿåä½œå·¥å…·ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ¶ˆæ¯é›†ä¸­ç®¡ç†ï¼Œé€‚åˆå›¢é˜Ÿå…±äº«çƒ­ç‚¹èµ„è®¯&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒ mrkdwn æ ¼å¼ï¼ˆç²—ä½“ã€é“¾æ¥ç­‰ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¤šç§éƒ¨ç½²æ–¹å¼&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;GitHub Actionsï¼šé…ç½® &lt;code&gt;SLACK_WEBHOOK_URL&lt;/code&gt; Secret&lt;/li&gt; 
    &lt;li&gt;Dockerï¼šç¯å¢ƒå˜é‡ &lt;code&gt;SLACK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æœ¬åœ°è¿è¡Œï¼š&lt;code&gt;config/config.yaml&lt;/code&gt; é…ç½®æ–‡ä»¶&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ“– &lt;strong&gt;è¯¦ç»†é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;å¿«é€Ÿå¼€å§‹ - Slack æ¨é€&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¼˜åŒ– setup-windows.bat å’Œ setup-windows-en.bat ä¸€é”®å®‰è£… MCP çš„ä½“éªŒ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·&lt;/strong&gt;ï¼šæ›´æ–° &lt;code&gt;main.py&lt;/code&gt;ã€&lt;code&gt;config/config.yaml&lt;/code&gt;ã€&lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/24 - v3.3.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ‰ æ–°å¢ Bark æ¨é€æ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;iOS ä¸“å±æ¨é€æ¸ é“&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒ Bark æ¨é€ï¼ˆåŸºäº APNsï¼ŒiOS å¹³å°ï¼‰&lt;/li&gt; 
    &lt;li&gt;å…è´¹å¼€æºï¼Œç®€æ´é«˜æ•ˆï¼Œæ— å¹¿å‘Šå¹²æ‰°&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒå®˜æ–¹æœåŠ¡å™¨å’Œè‡ªå»ºæœåŠ¡å™¨ä¸¤ç§æ–¹å¼&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¤šç§éƒ¨ç½²æ–¹å¼&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;GitHub Actionsï¼šé…ç½® &lt;code&gt;BARK_URL&lt;/code&gt; Secret&lt;/li&gt; 
    &lt;li&gt;Dockerï¼šç¯å¢ƒå˜é‡ &lt;code&gt;BARK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æœ¬åœ°è¿è¡Œï¼š&lt;code&gt;config/config.yaml&lt;/code&gt; é…ç½®æ–‡ä»¶&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ“– &lt;strong&gt;è¯¦ç»†é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;å¿«é€Ÿå¼€å§‹ - Bark æ¨é€&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ› Bug ä¿®å¤&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤ &lt;code&gt;config.yaml&lt;/code&gt; ä¸­ &lt;code&gt;ntfy_server_url&lt;/code&gt; é…ç½®ä¸ç”Ÿæ•ˆçš„é—®é¢˜ (&lt;a href="https://github.com/sansan0/TrendRadar/issues/345"&gt;#345&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·&lt;/strong&gt;ï¼šæ›´æ–° &lt;code&gt;main.py&lt;/code&gt;ã€&lt;code&gt;config/config.yaml&lt;/code&gt;ã€&lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/23 - v3.2.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ¯ æ–°å¢é«˜çº§å®šåˆ¶åŠŸèƒ½&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å…³é”®è¯æ’åºä¼˜å…ˆçº§é…ç½®&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒä¸¤ç§æ’åºç­–ç•¥ï¼šçƒ­åº¦ä¼˜å…ˆ vs é…ç½®é¡ºåºä¼˜å…ˆ&lt;/li&gt; 
    &lt;li&gt;æ»¡è¶³ä¸åŒä½¿ç”¨åœºæ™¯ï¼šçƒ­ç‚¹è¿½è¸ª or ä¸ªæ€§åŒ–å…³æ³¨&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ˜¾ç¤ºæ•°é‡ç²¾å‡†æ§åˆ¶&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å…¨å±€é…ç½®ï¼šç»Ÿä¸€é™åˆ¶æ‰€æœ‰å…³é”®è¯æ˜¾ç¤ºæ•°é‡&lt;/li&gt; 
    &lt;li&gt;å•ç‹¬é…ç½®ï¼šä½¿ç”¨ &lt;code&gt;@æ•°å­—&lt;/code&gt; è¯­æ³•ä¸ºç‰¹å®šå…³é”®è¯è®¾ç½®é™åˆ¶&lt;/li&gt; 
    &lt;li&gt;æœ‰æ•ˆæ§åˆ¶æ¨é€é•¿åº¦ï¼Œçªå‡ºé‡ç‚¹å†…å®¹&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ“– &lt;strong&gt;è¯¦ç»†é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E5%85%B3%E9%94%AE%E8%AF%8D%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE"&gt;å…³é”®è¯é…ç½® - é«˜çº§é…ç½®&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ”§ å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·&lt;/strong&gt;ï¼šæ›´æ–° &lt;code&gt;main.py&lt;/code&gt;ã€&lt;code&gt;config/config.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/18 - mcp-v1.0.2&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¼˜åŒ–æŸ¥è¯¢ä»Šæ—¥æ–°é—»å´å¯èƒ½é”™è¯¯è¿”å›è¿‡å»æ—¥æœŸçš„æƒ…å†µ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/22 - v3.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ä¿®å¤æ•°æ®å¼‚å¸¸å¯¼è‡´çš„å´©æºƒé—®é¢˜&lt;/strong&gt;ï¼šè§£å†³éƒ¨åˆ†ç”¨æˆ·åœ¨ GitHub Actions ç¯å¢ƒä¸­é‡åˆ°çš„ &lt;code&gt;'float' object has no attribute 'lower'&lt;/code&gt; é”™è¯¯&lt;/li&gt; 
  &lt;li&gt;æ–°å¢åŒé‡é˜²æŠ¤æœºåˆ¶ï¼šåœ¨æ•°æ®è·å–é˜¶æ®µè¿‡æ»¤æ— æ•ˆæ ‡é¢˜ï¼ˆNoneã€floatã€ç©ºå­—ç¬¦ä¸²ï¼‰ï¼ŒåŒæ—¶åœ¨å‡½æ•°è°ƒç”¨å¤„æ·»åŠ ç±»å‹æ£€æŸ¥&lt;/li&gt; 
  &lt;li&gt;æå‡ç³»ç»Ÿç¨³å®šæ€§ï¼Œç¡®ä¿åœ¨æ•°æ®æºè¿”å›å¼‚å¸¸æ ¼å¼æ—¶ä»èƒ½æ­£å¸¸è¿è¡Œ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;å‡çº§è¯´æ˜&lt;/strong&gt;ï¼ˆGitHub Fork ç”¨æˆ·ï¼‰ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å¿…é¡»æ›´æ–°ï¼š&lt;code&gt;main.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;å»ºè®®ä½¿ç”¨å°ç‰ˆæœ¬å‡çº§æ–¹å¼ï¼šå¤åˆ¶æ›¿æ¢ä¸Šè¿°æ–‡ä»¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/20 - v3.1.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ–°å¢ä¸ªäººå¾®ä¿¡æ¨é€æ”¯æŒ&lt;/strong&gt;ï¼šä¼ä¸šå¾®ä¿¡åº”ç”¨å¯æ¨é€åˆ°ä¸ªäººå¾®ä¿¡ï¼Œæ— éœ€å®‰è£…ä¼ä¸šå¾®ä¿¡ APP&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒä¸¤ç§æ¶ˆæ¯æ ¼å¼ï¼š&lt;code&gt;markdown&lt;/code&gt;ï¼ˆä¼ä¸šå¾®ä¿¡ç¾¤æœºå™¨äººï¼‰å’Œ &lt;code&gt;text&lt;/code&gt;ï¼ˆä¸ªäººå¾®ä¿¡åº”ç”¨ï¼‰&lt;/li&gt; 
  &lt;li&gt;æ–°å¢ &lt;code&gt;WEWORK_MSG_TYPE&lt;/code&gt; ç¯å¢ƒå˜é‡é…ç½®ï¼Œæ”¯æŒ GitHub Actionsã€Dockerã€docker compose ç­‰å¤šç§éƒ¨ç½²æ–¹å¼&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;text&lt;/code&gt; æ¨¡å¼è‡ªåŠ¨æ¸…é™¤ Markdown è¯­æ³•ï¼Œæä¾›çº¯æ–‡æœ¬æ¨é€æ•ˆæœ&lt;/li&gt; 
  &lt;li&gt;è¯¦è§å¿«é€Ÿå¼€å§‹ä¸­çš„ã€Œä¸ªäººå¾®ä¿¡æ¨é€ã€é…ç½®è¯´æ˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;å‡çº§è¯´æ˜&lt;/strong&gt;ï¼ˆGitHub Fork ç”¨æˆ·ï¼‰ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å¿…é¡»æ›´æ–°ï¼š&lt;code&gt;main.py&lt;/code&gt;ã€&lt;code&gt;config/config.yaml&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;å¯é€‰æ›´æ–°ï¼š&lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt;ï¼ˆå¦‚ä½¿ç”¨ GitHub Actions éƒ¨ç½²ï¼‰&lt;/li&gt; 
  &lt;li&gt;å»ºè®®ä½¿ç”¨å°ç‰ˆæœ¬å‡çº§æ–¹å¼ï¼šå¤åˆ¶æ›¿æ¢ä¸Šè¿°æ–‡ä»¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/11/12 - v3.0.5&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤é‚®ä»¶å‘é€ SSL/TLS ç«¯å£é…ç½®é€»è¾‘é”™è¯¯&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ–é‚®ç®±æœåŠ¡å•†ï¼ˆQQ/163/126ï¼‰é»˜è®¤ä½¿ç”¨ 465 ç«¯å£ï¼ˆSSLï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ–°å¢ Docker ç¯å¢ƒå˜é‡æ”¯æŒ&lt;/strong&gt;ï¼šæ ¸å¿ƒé…ç½®é¡¹ï¼ˆ&lt;code&gt;enable_crawler&lt;/code&gt;ã€&lt;code&gt;report_mode&lt;/code&gt;ã€&lt;code&gt;push_window&lt;/code&gt; ç­‰ï¼‰æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œè§£å†³ NAS ç”¨æˆ·ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸ç”Ÿæ•ˆçš„é—®é¢˜ï¼ˆè¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Docker éƒ¨ç½²&lt;/a&gt; ç« èŠ‚ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/26 - mcp-v1.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤æ—¥æœŸæŸ¥è¯¢å‚æ•°ä¼ é€’é”™è¯¯&lt;/li&gt; 
  &lt;li&gt;ç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„æ—¶é—´å‚æ•°æ ¼å¼&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/31 - v3.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é£ä¹¦å› æ¨é€å†…å®¹è¿‡é•¿è€Œäº§ç”Ÿçš„é”™è¯¯ï¼Œå®ç°äº†åˆ†æ‰¹æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/23 - v3.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ‰©å¤§ ntfy é”™è¯¯ä¿¡æ¯æ˜¾ç¤ºèŒƒå›´&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/21 - v3.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/20 - v3.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§æ›´æ–° - AI åˆ†æåŠŸèƒ½ä¸Šçº¿&lt;/strong&gt; ğŸ¤–&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ–°å¢åŸºäº MCP (Model Context Protocol) çš„ AI åˆ†ææœåŠ¡å™¨&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒ13ç§æ™ºèƒ½åˆ†æå·¥å…·ï¼šåŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€é«˜çº§åˆ†æã€ç³»ç»Ÿç®¡ç†&lt;/li&gt; 
    &lt;li&gt;è‡ªç„¶è¯­è¨€äº¤äº’ï¼šé€šè¿‡å¯¹è¯æ–¹å¼æŸ¥è¯¢å’Œåˆ†ææ–°é—»æ•°æ®&lt;/li&gt; 
    &lt;li&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒï¼šClaude Desktopã€Cherry Studioã€Cursorã€Cline ç­‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¯é¢˜è¶‹åŠ¿åˆ†æï¼ˆçƒ­åº¦è¿½è¸ªã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ•°æ®æ´å¯Ÿï¼ˆå¹³å°å¯¹æ¯”ã€æ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
    &lt;li&gt;æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ&lt;/li&gt; 
    &lt;li&gt;å†å²ç›¸å…³æ–°é—»æ£€ç´¢ã€å¤šæ¨¡å¼æœç´¢&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™æ˜¯ç‹¬ç«‹çš„ AI åˆ†æåŠŸèƒ½ï¼Œä¸å½±å“ç°æœ‰çš„æ¨é€åŠŸèƒ½&lt;/li&gt; 
    &lt;li&gt;å¯é€‰æ‹©æ€§ä½¿ç”¨ï¼Œæ— éœ€å‡çº§ç°æœ‰éƒ¨ç½²&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/15 - v2.4.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜ + 1&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤æ¨é€æ—¶é—´çª—å£åˆ¤æ–­é—®é¢˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ã€å°ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/10 - v2.4.3&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ &lt;a href="https://github.com/sansan0/TrendRadar/issues/98"&gt;nidaye996&lt;/a&gt; å‘ç°çš„ä½“éªŒé—®é¢˜&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡æ„"é™é»˜æ¨é€æ¨¡å¼"å‘½åä¸º"æ¨é€æ—¶é—´çª—å£æ§åˆ¶"ï¼Œæå‡åŠŸèƒ½ç†è§£åº¦&lt;/li&gt; 
    &lt;li&gt;æ˜ç¡®æ¨é€æ—¶é—´çª—å£ä½œä¸ºå¯é€‰é™„åŠ åŠŸèƒ½ï¼Œå¯ä¸ä¸‰ç§æ¨é€æ¨¡å¼æ­é…ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;æ”¹è¿›æ³¨é‡Šå’Œæ–‡æ¡£æè¿°ï¼Œä½¿åŠŸèƒ½å®šä½æ›´åŠ æ¸…æ™°&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™ä¸ªä»…ä»…æ˜¯é‡æ„ï¼Œå¯ä»¥ä¸ç”¨å‡çº§&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/8 - v2.4.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤é…ç½®æ–‡ä»¶ç¼ºå¤±é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¼˜åŒ– ntfy æ¨é€æ•ˆæœ&lt;/li&gt; 
    &lt;li&gt;å¢åŠ  github page å›¾ç‰‡åˆ†æ®µå¯¼å‡ºåŠŸèƒ½&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/2 - v2.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ–°å¢ ntfy æ¨é€é€šçŸ¥&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒ ntfy.sh å…¬å…±æœåŠ¡å’Œè‡ªæ‰˜ç®¡æœåŠ¡å™¨&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é€‚åˆè¿½æ±‚éšç§çš„ç”¨æˆ·ï¼ˆæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/li&gt; 
    &lt;li&gt;è·¨å¹³å°æ¨é€ï¼ˆiOSã€Androidã€Desktopã€Webï¼‰&lt;/li&gt; 
    &lt;li&gt;æ— éœ€æ³¨å†Œè´¦å·ï¼ˆå…¬å…±æœåŠ¡å™¨ï¼‰&lt;/li&gt; 
    &lt;li&gt;å¼€æºå…è´¹ï¼ˆMIT åè®®ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/26 - v2.3.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®æ­£äº†é‚®ä»¶é€šçŸ¥é…ç½®æ£€æŸ¥è¢«é—æ¼çš„é—®é¢˜ï¼ˆ&lt;a href="https://github.com/sansan0/TrendRadar/issues/88"&gt;#88&lt;/a&gt;ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³äº†å³ä½¿æ­£ç¡®é…ç½®é‚®ä»¶é€šçŸ¥ï¼Œç³»ç»Ÿä»æç¤º"æœªé…ç½®ä»»ä½•webhook"çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/22 - v2.3.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ–°å¢é‚®ä»¶æ¨é€åŠŸèƒ½&lt;/strong&gt;ï¼Œæ”¯æŒå°†çƒ­ç‚¹æ–°é—»æŠ¥å‘Šå‘é€åˆ°é‚®ç®±&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ™ºèƒ½ SMTP è¯†åˆ«&lt;/strong&gt;ï¼šè‡ªåŠ¨è¯†åˆ« Gmailã€QQé‚®ç®±ã€Outlookã€ç½‘æ˜“é‚®ç®±ç­‰ 10+ ç§é‚®ç®±æœåŠ¡å•†é…ç½®&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HTML ç²¾ç¾æ ¼å¼&lt;/strong&gt;ï¼šé‚®ä»¶å†…å®¹é‡‡ç”¨ä¸ç½‘é¡µç‰ˆç›¸åŒçš„ HTML æ ¼å¼ï¼Œæ’ç‰ˆç²¾ç¾ï¼Œç§»åŠ¨ç«¯é€‚é…&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ‰¹é‡å‘é€æ”¯æŒ&lt;/strong&gt;ï¼šæ”¯æŒå¤šä¸ªæ”¶ä»¶äººï¼Œç”¨é€—å·åˆ†éš”å³å¯åŒæ—¶å‘é€ç»™å¤šäºº&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰ SMTP&lt;/strong&gt;ï¼šå¯è‡ªå®šä¹‰ SMTP æœåŠ¡å™¨å’Œç«¯å£&lt;/li&gt; 
  &lt;li&gt;ä¿®å¤Dockeræ„å»ºç½‘ç»œè¿æ¥é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šé€‚åˆéœ€è¦é‚®ä»¶å½’æ¡£ã€å›¢é˜Ÿåˆ†äº«ã€å®šæ—¶æŠ¥å‘Šçš„ç”¨æˆ·&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒé‚®ç®±ï¼šGmailã€QQé‚®ç®±ã€Outlook/Hotmailã€163/126é‚®ç®±ã€æ–°æµªé‚®ç®±ã€æœç‹é‚®ç®±ç­‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ­¤æ¬¡æ›´æ–°çš„å†…å®¹æ¯”è¾ƒå¤šï¼Œå¦‚æœæƒ³å‡çº§ï¼Œå»ºè®®é‡‡ç”¨ã€å¤§ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/17 - v2.2.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢ä¸€é”®ä¿å­˜æ–°é—»å›¾ç‰‡åŠŸèƒ½ï¼Œè®©ä½ è½»æ¾åˆ†äº«å…³æ³¨çš„çƒ­ç‚¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šå½“ä½ æŒ‰ç…§æ•™ç¨‹å¼€å¯äº†ç½‘é¡µç‰ˆåŠŸèƒ½å(GitHub Pages)&lt;/li&gt; 
  &lt;li&gt;ä½¿ç”¨æ–¹æ³•ï¼šç”¨æ‰‹æœºæˆ–ç”µè„‘æ‰“å¼€è¯¥ç½‘é¡µé“¾æ¥ï¼Œç‚¹å‡»é¡µé¢é¡¶éƒ¨çš„"ä¿å­˜ä¸ºå›¾ç‰‡"æŒ‰é’®&lt;/li&gt; 
  &lt;li&gt;å®é™…æ•ˆæœï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å°†å½“å‰çš„æ–°é—»æŠ¥å‘Šåˆ¶ä½œæˆä¸€å¼ ç²¾ç¾å›¾ç‰‡ï¼Œä¿å­˜åˆ°ä½ çš„æ‰‹æœºç›¸å†Œæˆ–ç”µè„‘æ¡Œé¢&lt;/li&gt; 
  &lt;li&gt;åˆ†äº«ä¾¿åˆ©ï¼šä½ å¯ä»¥ç›´æ¥æŠŠè¿™å¼ å›¾ç‰‡å‘ç»™æœ‹å‹ã€å‘åˆ°æœ‹å‹åœˆï¼Œæˆ–åˆ†äº«åˆ°å·¥ä½œç¾¤ï¼Œè®©åˆ«äººä¹Ÿèƒ½çœ‹åˆ°ä½ å‘ç°çš„é‡è¦èµ„è®¯&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/13 - v2.1.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é’‰é’‰çš„æ¨é€å®¹é‡é™åˆ¶å¯¼è‡´çš„æ–°é—»æ¨é€å¤±è´¥é—®é¢˜(é‡‡ç”¨åˆ†æ‰¹æ¨é€)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/04 - v2.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤dockeråœ¨æŸäº›æ¶æ„ä¸­æ— æ³•æ­£å¸¸è¿è¡Œçš„é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;æ­£å¼å‘å¸ƒå®˜æ–¹ Docker é•œåƒ wantcat/trendradarï¼Œæ”¯æŒå¤šæ¶æ„&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ– Docker éƒ¨ç½²æµç¨‹ï¼Œæ— éœ€æœ¬åœ°æ„å»ºå³å¯å¿«é€Ÿä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/30 - v2.1.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒæ”¹è¿›&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é€»è¾‘ä¼˜åŒ–&lt;/strong&gt;ï¼šä»"æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€"æ”¹ä¸º"æ—¶é—´çª—å£å†…å¯æ§æ¨é€"&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;ï¼šå¯è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼Œé¿å…éå·¥ä½œæ—¶é—´æ‰“æ‰°&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡å¯é€‰&lt;/strong&gt;ï¼šæ—¶é—´æ®µå†…æ”¯æŒå•æ¬¡æ¨é€æˆ–å¤šæ¬¡æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬åŠŸèƒ½é»˜è®¤å…³é—­ï¼Œéœ€æ‰‹åŠ¨åœ¨ config.yaml ä¸­å¼€å¯æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/li&gt; 
  &lt;li&gt;å‡çº§éœ€åŒæ—¶æ›´æ–° main.py å’Œ config.yaml ä¸¤ä¸ªæ–‡ä»¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/27 - v2.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬æ¬¡ç‰ˆæœ¬ä¸æ˜¯åŠŸèƒ½ä¿®å¤ï¼Œè€Œæ˜¯é‡è¦æé†’&lt;/li&gt; 
  &lt;li&gt;è¯·åŠ¡å¿…å¦¥å–„ä¿ç®¡å¥½ webhooksï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ ä»¥ fork çš„æ–¹å¼å°†æœ¬é¡¹ç›®éƒ¨ç½²åœ¨ GitHub ä¸Šï¼Œè¯·å°† webhooks å¡«å…¥ GitHub Secretï¼Œè€Œé config.yaml&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ å·²ç»æš´éœ²äº† webhooks æˆ–å°†å…¶å¡«å…¥äº† config.yamlï¼Œå»ºè®®åˆ é™¤åé‡æ–°ç”Ÿæˆ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/06 - v2.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¼˜åŒ– github page çš„ç½‘é¡µç‰ˆæ•ˆæœï¼Œæ–¹ä¾¿ç§»åŠ¨ç«¯ä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/28 - v2.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é‡æ„ä»£ç &lt;/li&gt; 
  &lt;li&gt;è§£å†³ç‰ˆæœ¬å·å®¹æ˜“è¢«é—æ¼ä¿®æ”¹çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/27 - v2.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;docker çš„ shell è„šæœ¬çš„æ¢è¡Œç¬¦ä¸º CRLF å¯¼è‡´çš„æ‰§è¡Œå¼‚å¸¸é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå¯¼è‡´æ–°é—»å‘é€ä¹Ÿä¸ºç©ºçš„é€»è¾‘é—®é¢˜&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤åï¼Œå½“ä½ é€‰æ‹© frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå°†&lt;strong&gt;æ¨é€æ‰€æœ‰æ–°é—»&lt;/strong&gt;ï¼Œä½†å—é™äºæ¶ˆæ¯æ¨é€å¤§å°é™åˆ¶ï¼Œè¯·åšå¦‚ä¸‹è°ƒæ•´ 
   &lt;ul&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸€ï¼šå…³é—­æ‰‹æœºæ¨é€ï¼Œåªé€‰æ‹© Github Pages å¸ƒç½®(è¿™æ˜¯èƒ½è·å¾—æœ€å®Œæ•´ä¿¡æ¯çš„æ–¹æ¡ˆï¼Œå°†æŠŠæ‰€æœ‰å¹³å°çš„çƒ­ç‚¹æŒ‰ç…§ä½ &lt;strong&gt;è‡ªå®šä¹‰çš„çƒ­æœç®—æ³•&lt;/strong&gt;è¿›è¡Œé‡æ–°æ’åº)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆäºŒï¼šå‡å°‘æ¨é€å¹³å°ï¼Œä¼˜å…ˆé€‰æ‹©&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;æˆ–&lt;strong&gt;Telegram&lt;/strong&gt;ï¼Œè¿™ä¸¤ä¸ªæ¨é€æˆ‘åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½(å› ä¸ºåˆ†æ‰¹æ¨é€å½±å“æ¨é€ä½“éªŒï¼Œä¸”åªæœ‰è¿™ä¸¤ä¸ªå¹³å°åªç»™ä¸€ç‚¹ç‚¹æ¨é€å®¹é‡ï¼Œæ‰€ä»¥æ‰ä¸å¾—å·²åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½ï¼Œä½†è‡³å°‘èƒ½ä¿è¯è·å¾—çš„ä¿¡æ¯å®Œæ•´)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸‰ï¼šå¯ä¸æ–¹æ¡ˆäºŒç»“åˆï¼Œæ¨¡å¼é€‰æ‹© current æˆ– incremental å¯æœ‰æ•ˆå‡å°‘ä¸€æ¬¡æ€§æ¨é€çš„å†…å®¹&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/17 - v2.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§é‡æ„&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é…ç½®ç®¡ç†é‡æ„ï¼šæ‰€æœ‰é…ç½®ç°åœ¨é€šè¿‡ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ç®¡ç†ï¼ˆmain.py æˆ‘ä¾æ—§æ²¡æ‹†åˆ†ï¼Œæ–¹ä¾¿ä½ ä»¬å¤åˆ¶å‡çº§ï¼‰&lt;/li&gt; 
  &lt;li&gt;è¿è¡Œæ¨¡å¼å‡çº§ï¼šæ”¯æŒä¸‰ç§æ¨¡å¼ - &lt;code&gt;daily&lt;/code&gt;ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰ã€&lt;code&gt;current&lt;/code&gt;ï¼ˆå½“å‰æ¦œå•ï¼‰ã€&lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰&lt;/li&gt; 
  &lt;li&gt;Docker æ”¯æŒï¼šå®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒå®¹å™¨åŒ–è¿è¡Œ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - ä¸»é…ç½®æ–‡ä»¶ï¼ˆåº”ç”¨è®¾ç½®ã€çˆ¬è™«é…ç½®ã€é€šçŸ¥é…ç½®ã€å¹³å°é…ç½®ç­‰ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆç›‘æ§è¯æ±‡è®¾ç½®ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/09 - v1.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;åŠŸèƒ½æ–°å¢&lt;/strong&gt;ï¼šå¢åŠ å¢é‡æ¨é€(åœ¨ main.py å¤´éƒ¨é…ç½® FOCUS_NEW_ONLY)ï¼Œè¯¥å¼€å…³åªå…³å¿ƒæ–°è¯é¢˜è€ŒéæŒç»­çƒ­åº¦ï¼Œåªåœ¨æœ‰æ–°å†…å®¹æ—¶æ‰å‘é€šçŸ¥ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;: æŸäº›æƒ…å†µä¸‹ï¼Œç”±äºæ–°é—»æœ¬èº«å«æœ‰ç‰¹æ®Šç¬¦å·å¯¼è‡´çš„å¶å‘æ€§æ’ç‰ˆå¼‚å¸¸ã€‚&lt;/p&gt; 
 &lt;h3&gt;2025/06/23 - v1.3.0&lt;/h3&gt; 
 &lt;p&gt;ä¼ä¸šå¾®ä¿¡ å’Œ Telegram çš„æ¨é€æ¶ˆæ¯æœ‰é•¿åº¦é™åˆ¶ï¼Œå¯¹æ­¤æˆ‘é‡‡ç”¨å°†æ¶ˆæ¯æ‹†åˆ†æ¨é€çš„æ–¹å¼ã€‚å¼€å‘æ–‡æ¡£è¯¦è§&lt;a href="https://developer.work.weixin.qq.com/document/path/91770"&gt;ä¼ä¸šå¾®ä¿¡&lt;/a&gt; å’Œ &lt;a href="https://core.telegram.org/bots/api"&gt;Telegram&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/21 - v1.2.1&lt;/h3&gt; 
 &lt;p&gt;åœ¨æœ¬ç‰ˆæœ¬ä¹‹å‰çš„æ—§ç‰ˆæœ¬ï¼Œä¸ä»… main.py éœ€è¦å¤åˆ¶æ›¿æ¢ï¼Œ crawler.yml ä¹Ÿéœ€è¦ä½ å¤åˆ¶æ›¿æ¢ &lt;a href="https://github.com/sansan0/TrendRadar/raw/master/.github/workflows/crawler.yml"&gt;https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/19 - v1.2.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ claude research æ•´ç†çš„å„å¹³å° api ,è®©æˆ‘å¿«é€Ÿå®Œæˆå„å¹³å°é€‚é…ï¼ˆè™½ç„¶ä»£ç æ›´å¤šå†—ä½™äº†~&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ”¯æŒ telegram ï¼Œä¼ä¸šå¾®ä¿¡ï¼Œé’‰é’‰æ¨é€æ¸ é“, æ”¯æŒå¤šæ¸ é“é…ç½®å’ŒåŒæ—¶æ¨é€&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/18 - v1.1.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;200 starâ­&lt;/strong&gt; äº†, ç»§ç»­ç»™å¤§ä¼™å„¿åŠ©å…´~è¿‘æœŸï¼Œåœ¨æˆ‘çš„"æ€‚æ¿"ä¸‹ï¼ŒæŒºå¤šäººåœ¨æˆ‘å…¬ä¼—å·ç‚¹èµåˆ†äº«æ¨èåŠ©åŠ›äº†æˆ‘ï¼Œæˆ‘éƒ½åœ¨åå°çœ‹è§äº†å…·ä½“è´¦å·çš„é¼“åŠ±æ•°æ®ï¼Œå¾ˆå¤šéƒ½æˆäº†å¤©ä½¿è½®è€ç²‰ï¼ˆæˆ‘ç©å…¬ä¼—å·æ‰ä¸€ä¸ªå¤šæœˆï¼Œè™½ç„¶æ³¨å†Œæ˜¯ä¸ƒå…«å¹´å‰çš„äº‹äº†å“ˆå“ˆï¼Œå±äºä¸Šè½¦æ—©ï¼Œå‘è½¦æ™šï¼‰ï¼Œä½†å› ä¸ºä½ ä»¬æ²¡æœ‰ç•™è¨€æˆ–ç§ä¿¡æˆ‘ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæ— æ³•ä¸€ä¸€å›åº”å¹¶æ„Ÿè°¢æ”¯æŒï¼Œåœ¨æ­¤ä¸€å¹¶è°¢è°¢ï¼&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é‡è¦çš„æ›´æ–°ï¼ŒåŠ äº†æƒé‡ï¼Œä½ ç°åœ¨çœ‹åˆ°çš„æ–°é—»éƒ½æ˜¯æœ€çƒ­ç‚¹æœ€æœ‰å…³æ³¨åº¦çš„å‡ºç°åœ¨æœ€ä¸Šé¢&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°æ–‡æ¡£ä½¿ç”¨ï¼Œå› ä¸ºè¿‘æœŸæ›´æ–°äº†å¾ˆå¤šåŠŸèƒ½ï¼Œè€Œä¸”ä¹‹å‰çš„ä½¿ç”¨æ–‡æ¡£æˆ‘å·æ‡’å†™çš„ç®€å•ï¼ˆè§ä¸‹é¢çš„ âš™ï¸ frequency_words.txt é…ç½®å®Œæ•´æ•™ç¨‹ï¼‰&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/16 - v1.0.0&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¢åŠ äº†ä¸€ä¸ªé¡¹ç›®æ–°ç‰ˆæœ¬æ›´æ–°æç¤ºï¼Œé»˜è®¤æ‰“å¼€ï¼Œå¦‚è¦å…³æ‰ï¼Œå¯ä»¥åœ¨ main.py ä¸­æŠŠ "FEISHU_SHOW_VERSION_UPDATE": True ä¸­çš„ True æ”¹æˆ False å³å¯&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/13+14&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å»æ‰äº†å…¼å®¹ä»£ç ï¼Œä¹‹å‰ fork çš„åŒå­¦ï¼Œç›´æ¥å¤åˆ¶ä»£ç ä¼šåœ¨å½“å¤©æ˜¾ç¤ºå¼‚å¸¸ï¼ˆç¬¬äºŒå¤©ä¼šæ¢å¤æ­£å¸¸ï¼‰&lt;/li&gt; 
  &lt;li&gt;feishu å’Œ html åº•éƒ¨å¢åŠ ä¸€ä¸ªæ–°å¢æ–°é—»æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/09&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;100 starâ­&lt;/strong&gt; äº†ï¼Œå†™ä¸ªå°åŠŸèƒ½ç»™å¤§ä¼™å„¿åŠ©åŠ©å…´ frequency_words.txt æ–‡ä»¶å¢åŠ äº†ä¸€ä¸ªã€å¿…é¡»è¯ã€‘åŠŸèƒ½ï¼Œä½¿ç”¨ + å·&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¿…é¡»è¯è¯­æ³•å¦‚ä¸‹ï¼š&lt;br /&gt; å”åƒ§æˆ–è€…çŒªå…«æˆ’å¿…é¡»åœ¨æ ‡é¢˜é‡ŒåŒæ—¶å‡ºç°ï¼Œæ‰ä¼šæ”¶å½•åˆ°æ¨é€æ–°é—»ä¸­&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
+çŒªå…«æˆ’
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;è¿‡æ»¤è¯çš„ä¼˜å…ˆçº§æ›´é«˜ï¼š&lt;br /&gt; å¦‚æœæ ‡é¢˜ä¸­è¿‡æ»¤è¯åŒ¹é…åˆ°å”åƒ§å¿µç»ï¼Œé‚£ä¹ˆå³ä½¿å¿…é¡»è¯é‡Œæœ‰å”åƒ§ï¼Œä¹Ÿä¸æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
!å”åƒ§å¿µç»
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;2025/06/02&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ç½‘é¡µ&lt;/strong&gt;å’Œ&lt;strong&gt;é£ä¹¦æ¶ˆæ¯&lt;/strong&gt;æ”¯æŒæ‰‹æœºç›´æ¥è·³è½¬è¯¦æƒ…æ–°é—»&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ–æ˜¾ç¤ºæ•ˆæœ + 1&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/05/26&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é£ä¹¦æ¶ˆæ¯æ˜¾ç¤ºæ•ˆæœä¼˜åŒ–&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å‰&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/before.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å‰" width="400" /&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/after.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å" width="400" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“– æé†’&lt;/strong&gt;ï¼šFork ç”¨æˆ·å»ºè®®å…ˆ &lt;strong&gt;&lt;a href="https://github.com/sansan0/TrendRadar?tab=readme-ov-file"&gt;æŸ¥çœ‹æœ€æ–°å®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/strong&gt;ï¼Œç¡®ä¿é…ç½®æ­¥éª¤æ˜¯æœ€æ–°çš„ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš ï¸ GitHub Actions ä½¿ç”¨è¯´æ˜&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;v4.0.0 é‡è¦å˜æ›´&lt;/strong&gt;ï¼šå¼•å…¥ã€Œæ´»è·ƒåº¦æ£€æµ‹ã€æœºåˆ¶ï¼ŒGitHub Actions éœ€å®šæœŸç­¾åˆ°ä»¥ç»´æŒè¿è¡Œã€‚&lt;/p&gt; 
&lt;h4&gt;ğŸ”„ ç­¾åˆ°ç»­æœŸæœºåˆ¶&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;è¿è¡Œå‘¨æœŸ&lt;/strong&gt;ï¼šæœ‰æ•ˆæœŸä¸º &lt;strong&gt;7 å¤©&lt;/strong&gt;ï¼Œå€’è®¡æ—¶ç»“æŸåæœåŠ¡å°†è‡ªåŠ¨æŒ‚èµ·ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ç»­æœŸæ–¹å¼&lt;/strong&gt;ï¼šåœ¨ Actions é¡µé¢æ‰‹åŠ¨è§¦å‘ "Check In" workflowï¼Œå³å¯é‡ç½® 7 å¤©æœ‰æ•ˆæœŸã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ“ä½œè·¯å¾„&lt;/strong&gt;ï¼š&lt;code&gt;Actions&lt;/code&gt; â†’ &lt;code&gt;Check In&lt;/code&gt; â†’ &lt;code&gt;Run workflow&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è®¾è®¡ç†å¿µ&lt;/strong&gt;ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;å¦‚æœ 7 å¤©éƒ½å¿˜äº†ç­¾åˆ°ï¼Œæˆ–è®¸è¿™äº›èµ„è®¯å¯¹ä½ æ¥è¯´å¹¶éåˆšéœ€ã€‚é€‚æ—¶çš„æš‚åœï¼Œèƒ½å¸®ä½ ä»ä¿¡æ¯æµä¸­æŠ½ç¦»ï¼Œç»™å¤§è„‘ç•™å‡ºå–˜æ¯çš„ç©ºé—´ã€‚&lt;/li&gt; 
   &lt;li&gt;GitHub Actions æ˜¯å®è´µçš„å…¬å…±è®¡ç®—èµ„æºã€‚å¼•å…¥ç­¾åˆ°æœºåˆ¶æ—¨åœ¨é¿å…ç®—åŠ›çš„æ— æ•ˆç©ºè½¬ï¼Œç¡®ä¿èµ„æºèƒ½åˆ†é…ç»™çœŸæ­£æ´»è·ƒä¸”éœ€è¦çš„ç”¨æˆ·ã€‚æ„Ÿè°¢ä½ çš„ç†è§£ä¸æ”¯æŒã€‚&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“¦ æ•°æ®å­˜å‚¨ï¼ˆå¿…éœ€é…ç½®ï¼‰&lt;/h4&gt; 
&lt;p&gt;GitHub Actions ç¯å¢ƒä¸‹ï¼Œæ•°æ®å­˜å‚¨åœ¨ &lt;strong&gt;è¿œç¨‹äº‘å­˜å‚¨&lt;/strong&gt;ï¼ˆæ”¯æŒ S3 å…¼å®¹åè®®ï¼Œæ¨èå…è´¹çš„ Cloudflare R2ï¼‰ï¼Œä¸ä¼šæ±¡æŸ“ä»“åº“ï¼ˆè§ä¸‹æ–¹ &lt;strong&gt;å¿…éœ€é…ç½®ï¼šè¿œç¨‹äº‘å­˜å‚¨&lt;/strong&gt;ï¼‰&lt;/p&gt; 
&lt;h4&gt;ğŸš€ æ¨èï¼šDocker éƒ¨ç½²&lt;/h4&gt; 
&lt;p&gt;å¦‚éœ€é•¿æœŸç¨³å®šè¿è¡Œï¼Œå»ºè®®ä½¿ç”¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;Docker éƒ¨ç½²&lt;/a&gt;ï¼Œæ•°æ®å­˜å‚¨åœ¨æœ¬åœ°ï¼Œæ— éœ€ç­¾åˆ°ï¼Œä¸è¿‡éœ€è¦é¢å¤–ä»˜è´¹è´­ä¹°äº‘æœåŠ¡å™¨ã€‚&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fork æœ¬é¡¹ç›®&lt;/strong&gt;åˆ°ä½ çš„ GitHub è´¦æˆ·&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ç‚¹å‡»æœ¬é¡µé¢å³ä¸Šè§’çš„"Fork"æŒ‰é’®&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¾ç½® GitHub Secretsï¼ˆå¿…éœ€ + å¯é€‰å¹³å°ï¼‰&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;åœ¨ä½  Fork åçš„ä»“åº“ä¸­ï¼Œè¿›å…¥ &lt;code&gt;Settings&lt;/code&gt; &amp;gt; &lt;code&gt;Secrets and variables&lt;/code&gt; &amp;gt; &lt;code&gt;Actions&lt;/code&gt; &amp;gt; &lt;code&gt;New repository secret&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ğŸ“Œ é‡è¦è¯´æ˜ï¼ˆè¯·åŠ¡å¿…ä»”ç»†é˜…è¯»ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;ä¸€ä¸ª Name å¯¹åº”ä¸€ä¸ª Secret&lt;/strong&gt;ï¼šæ¯æ·»åŠ ä¸€ä¸ªé…ç½®é¡¹ï¼Œç‚¹å‡»ä¸€æ¬¡"New repository secret"æŒ‰é’®ï¼Œå¡«å†™ä¸€å¯¹"Name"å’Œ"Secret"&lt;/li&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;ä¿å­˜åçœ‹ä¸åˆ°å€¼æ˜¯æ­£å¸¸çš„&lt;/strong&gt;ï¼šå‡ºäºå®‰å…¨è€ƒè™‘ï¼Œä¿å­˜åé‡æ–°ç¼–è¾‘æ—¶ï¼Œåªèƒ½çœ‹åˆ° Nameï¼ˆåç§°ï¼‰ï¼Œçœ‹ä¸åˆ° Secretï¼ˆå€¼ï¼‰çš„å†…å®¹&lt;/li&gt; 
   &lt;li&gt;âš ï¸ &lt;strong&gt;ä¸¥ç¦è‡ªåˆ›åç§°&lt;/strong&gt;ï¼šSecret çš„ Nameï¼ˆåç§°ï¼‰å¿…é¡»&lt;strong&gt;ä¸¥æ ¼ä½¿ç”¨&lt;/strong&gt;ä¸‹æ–¹åˆ—å‡ºçš„åç§°ï¼ˆå¦‚ &lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;ã€&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt; ç­‰ï¼‰ï¼Œä¸èƒ½è‡ªå·±éšæ„ä¿®æ”¹æˆ–åˆ›é€ æ–°åç§°ï¼Œå¦åˆ™ç³»ç»Ÿæ— æ³•è¯†åˆ«&lt;/li&gt; 
   &lt;li&gt;ğŸ’¡ &lt;strong&gt;å¯ä»¥åŒæ—¶é…ç½®å¤šä¸ªå¹³å°&lt;/strong&gt;ï¼šç³»ç»Ÿä¼šå‘æ‰€æœ‰é…ç½®çš„å¹³å°å‘é€é€šçŸ¥&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;ğŸ“Œ å¤šè´¦å·æ¨é€è¯´æ˜ï¼ˆv3.5.0 æ–°å¢ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;æ”¯æŒå¤šè´¦å·é…ç½®&lt;/strong&gt;ï¼šæ‰€æœ‰æ¨é€æ¸ é“ï¼ˆé£ä¹¦ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ã€Telegramã€ntfyã€Barkã€Slackï¼‰å‡æ”¯æŒé…ç½®å¤šä¸ªè´¦å·&lt;/li&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;é…ç½®æ–¹å¼&lt;/strong&gt;ï¼šä½¿ç”¨è‹±æ–‡åˆ†å· &lt;code&gt;;&lt;/code&gt; åˆ†éš”å¤šä¸ªè´¦å·å€¼&lt;/li&gt; 
   &lt;li&gt;âœ… &lt;strong&gt;ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt; çš„ Secret å€¼å¡«å†™ &lt;code&gt;https://webhook1;https://webhook2&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;âš ï¸ &lt;strong&gt;é…å¯¹é…ç½®&lt;/strong&gt;ï¼šTelegram å’Œ ntfy éœ€è¦ä¿è¯é…å¯¹å‚æ•°æ•°é‡ä¸€è‡´ï¼ˆå¦‚ token å’Œ chat_id éƒ½æ˜¯ 2 ä¸ªï¼‰&lt;/li&gt; 
   &lt;li&gt;âš ï¸ &lt;strong&gt;æ•°é‡é™åˆ¶&lt;/strong&gt;ï¼šé»˜è®¤æ¯ä¸ªæ¸ é“æœ€å¤š 3 ä¸ªè´¦å·ï¼Œè¶…å‡ºéƒ¨åˆ†è¢«æˆªæ–­&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;å¤šè´¦å·é…ç½®ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;Nameï¼ˆåç§°ï¼‰&lt;/th&gt; 
     &lt;th&gt;Secretï¼ˆå€¼ï¼‰ç¤ºä¾‹&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;https://webhook1;https://webhook2;https://webhook3&lt;/code&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;token1;token2&lt;/code&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;chatid1;chatid2&lt;/code&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;NTFY_TOPIC&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;topic1;topic2&lt;/code&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;NTFY_TOKEN&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;;token2&lt;/code&gt;ï¼ˆç¬¬ä¸€ä¸ªæ—  token æ—¶ç•™ç©ºå ä½ï¼‰&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;p&gt;&lt;strong&gt;é…ç½®ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/secrets.png" alt="GitHub Secrets é…ç½®ç¤ºä¾‹" /&gt; &lt;p&gt;å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªé…ç½®é¡¹ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼šå¿…é¡»ä½¿ç”¨ä¸‹æ–¹å±•å¼€å†…å®¹ä¸­åˆ—å‡ºçš„å›ºå®šåç§°ï¼ˆå¦‚ &lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šå¡«å†™ä½ ä»å¯¹åº”å¹³å°è·å–çš„å®é™…å†…å®¹ï¼ˆå¦‚ Webhook åœ°å€ã€Token ç­‰ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;br /&gt; 
  &lt;details&gt; 
   &lt;summary&gt;âš ï¸ &lt;strong&gt;å¿…éœ€é…ç½®ï¼šè¿œç¨‹äº‘å­˜å‚¨&lt;/strong&gt;ï¼ˆGitHub Actions ç¯å¢ƒå¿…éœ€ï¼Œæ¨è Cloudflare R2ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ ä»¥ä¸‹ 4 ä¸ªé…ç½®é¡¹éƒ½æ˜¯å¿…éœ€çš„ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;Nameï¼ˆåç§°ï¼‰&lt;/th&gt; 
      &lt;th&gt;Secretï¼ˆå€¼ï¼‰è¯´æ˜&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;S3_BUCKET_NAME&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;å­˜å‚¨æ¡¶åç§°ï¼ˆå¦‚ &lt;code&gt;trendradar-data&lt;/code&gt;ï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;S3_ACCESS_KEY_ID&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;è®¿é—®å¯†é’¥ IDï¼ˆAccess Key IDï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;S3_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;è®¿é—®å¯†é’¥ï¼ˆSecret Access Keyï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;S3_ENDPOINT_URL&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;S3 API ç«¯ç‚¹ï¼ˆå¦‚ R2ï¼š&lt;code&gt;https://&amp;lt;account-id&amp;gt;.r2.cloudflarestorage.com&lt;/code&gt;ï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;å¦‚ä½•è·å–å‡­æ®ï¼ˆä»¥ Cloudflare R2 ä¸ºä¾‹ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;&lt;strong&gt;è¿›å…¥ R2 æ¦‚è§ˆ&lt;/strong&gt;ï¼š&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç™»å½• &lt;a href="https://dash.cloudflare.com/"&gt;Cloudflare Dashboard&lt;/a&gt;ã€‚&lt;/li&gt; 
    &lt;li&gt;åœ¨å·¦ä¾§ä¾§è¾¹æ æ‰¾åˆ°å¹¶ç‚¹å‡» &lt;code&gt;R2å¯¹è±¡å­˜å‚¨&lt;/code&gt;ã€‚&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;ol start="2"&gt; 
    &lt;li&gt;&lt;strong&gt;åˆ›å»ºå­˜å‚¨æ¡¶&lt;/strong&gt;ï¼š&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç‚¹å‡»&lt;code&gt;æ¦‚è¿°&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»å³ä¸Šè§’çš„ &lt;code&gt;åˆ›å»ºå­˜å‚¨æ¡¶&lt;/code&gt; (Create bucket)ã€‚&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥åç§°ï¼ˆä¾‹å¦‚ &lt;code&gt;trendradar-data&lt;/code&gt;ï¼‰ï¼Œç‚¹å‡» &lt;code&gt;åˆ›å»ºå­˜å‚¨æ¡¶&lt;/code&gt;ã€‚&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;ol start="3"&gt; 
    &lt;li&gt;&lt;strong&gt;åˆ›å»º API ä»¤ç‰Œ&lt;/strong&gt;ï¼š&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å›åˆ° &lt;strong&gt;æ¦‚è¿°&lt;/strong&gt;é¡µé¢ã€‚&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»&lt;strong&gt;å³ä¸‹è§’&lt;/strong&gt; &lt;code&gt;Account Details &lt;/code&gt;æ‰¾åˆ°å¹¶ç‚¹å‡» &lt;code&gt;Manage&lt;/code&gt; (Manage R2 API Tokens)ã€‚&lt;/li&gt; 
    &lt;li&gt;åŒæ—¶ä½ ä¼šçœ‹åˆ° &lt;code&gt;S3 API&lt;/code&gt;ï¼š&lt;code&gt;https://&amp;lt;account-id&amp;gt;.r2.cloudflarestorage.com&lt;/code&gt;(è¿™å°±æ˜¯ S3_ENDPOINT_URL)&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡» &lt;code&gt;åˆ›å»º Account APl ä»¤ç‰Œ&lt;/code&gt; ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;âš ï¸ å…³é”®è®¾ç½®&lt;/strong&gt;ï¼š 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;ä»¤ç‰Œåç§°&lt;/strong&gt;ï¼šéšæ„å¡«å†™ï¼ˆå¦‚ &lt;code&gt;github-action-write&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;æƒé™&lt;/strong&gt;ï¼šé€‰æ‹© &lt;code&gt;ç®¡ç†å‘˜è¯»å’Œå†™&lt;/code&gt; ã€‚&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;æŒ‡å®šå­˜å‚¨æ¡¶&lt;/strong&gt;ï¼šä¸ºäº†å®‰å…¨ï¼Œå»ºè®®é€‰æ‹© &lt;code&gt;ä»…é€‚ç”¨äºæŒ‡å®šå­˜å‚¨æ¡¶&lt;/code&gt; å¹¶é€‰ä¸­ä½ çš„æ¡¶ï¼ˆå¦‚ &lt;code&gt;trendradar-data&lt;/code&gt;ï¼‰ã€‚&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡» &lt;code&gt;åˆ›å»º API ä»¤ç‰Œ&lt;/code&gt;ï¼Œ&lt;strong&gt;ç«‹å³å¤åˆ¶&lt;/strong&gt; æ˜¾ç¤ºçš„ &lt;code&gt;Access Key ID&lt;/code&gt; å’Œ &lt;code&gt;Secret Access Key&lt;/code&gt;ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼ï¼‰ã€‚&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;R2 å…è´¹é¢åº¦&lt;/strong&gt;ï¼šæ¯æœˆ 10GB å­˜å‚¨ + 100ä¸‡æ¬¡è¯»å–ï¼Œå¯¹æœ¬é¡¹ç›®æ¥è¯´éå¸¸å……è¶³ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ”¯ä»˜éªŒè¯&lt;/strong&gt;ï¼šå¼€é€š R2 å³ä½¿æ˜¯å…è´¹é¢åº¦ï¼ŒCloudflare ä¹Ÿè¦æ±‚ç»‘å®š PayPal æˆ–ä¿¡ç”¨å¡è¿›è¡Œèº«ä»½éªŒè¯ï¼ˆä¸ä¼šå®é™…æ‰£è´¹ï¼Œé™¤éè¶…è¿‡é¢åº¦ï¼‰ã€‚&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;ä¼ä¸šå¾®ä¿¡æœºå™¨äºº&lt;/strong&gt;ï¼ˆé…ç½®æœ€ç®€å•æœ€è¿…é€Ÿï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼Œé¿å…æ‰“é”™ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ä¼ä¸šå¾®ä¿¡æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;æ‰‹æœºç«¯è®¾ç½®ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;æ‰“å¼€ä¼ä¸šå¾®ä¿¡ App â†’ è¿›å…¥ç›®æ ‡å†…éƒ¨ç¾¤èŠ&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»å³ä¸Šè§’"â€¦"æŒ‰é’® â†’ é€‰æ‹©"æ¶ˆæ¯æ¨é€"&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»"æ·»åŠ " â†’ åç§°è¾“å…¥"TrendRadar"&lt;/li&gt; 
    &lt;li&gt;å¤åˆ¶ Webhook åœ°å€ï¼Œç‚¹å‡»ä¿å­˜ï¼Œå¤åˆ¶çš„å†…å®¹é…ç½®åˆ°ä¸Šæ–¹çš„ GitHub Secret ä¸­&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;PC ç«¯è®¾ç½®æµç¨‹ç±»ä¼¼&lt;/h4&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;ä¸ªäººå¾®ä¿¡æ¨é€&lt;/strong&gt;ï¼ˆåŸºäºä¼ä¸šå¾®ä¿¡åº”ç”¨ï¼Œæ¨é€åˆ°ä¸ªäººå¾®ä¿¡ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;ç”±äºè¯¥æ–¹æ¡ˆæ˜¯åŸºäºä¼ä¸šå¾®ä¿¡çš„æ’ä»¶æœºåˆ¶ï¼Œæ¨é€æ ·å¼ä¸ºçº¯æ–‡æœ¬ï¼ˆæ—  markdown æ ¼å¼ï¼‰ï¼Œä½†å¯ä»¥ç›´æ¥æ¨é€åˆ°ä¸ªäººå¾®ä¿¡ï¼Œæ— éœ€å®‰è£…ä¼ä¸šå¾®ä¿¡ Appã€‚&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ä¼ä¸šå¾®ä¿¡åº”ç”¨ Webhook åœ°å€&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;WEWORK_MSG_TYPE&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;text&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;è®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;å®Œæˆä¸Šæ–¹çš„ä¼ä¸šå¾®ä¿¡æœºå™¨äºº Webhook è®¾ç½®&lt;/li&gt; 
    &lt;li&gt;æ·»åŠ  &lt;code&gt;WEWORK_MSG_TYPE&lt;/code&gt; Secretï¼Œå€¼è®¾ä¸º &lt;code&gt;text&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æŒ‰ç…§ä¸‹é¢å›¾ç‰‡æ“ä½œï¼Œå…³è”ä¸ªäººå¾®ä¿¡&lt;/li&gt; 
    &lt;li&gt;é…ç½®å¥½åï¼Œæ‰‹æœºä¸Šçš„ä¼ä¸šå¾®ä¿¡ App å¯ä»¥åˆ é™¤&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/wework.png" title="ä¸ªäººå¾®ä¿¡æ¨é€é…ç½®" /&gt; 
   &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¸ä¼ä¸šå¾®ä¿¡æœºå™¨äººä½¿ç”¨ç›¸åŒçš„ Webhook åœ°å€&lt;/li&gt; 
    &lt;li&gt;åŒºåˆ«åœ¨äºæ¶ˆæ¯æ ¼å¼ï¼š&lt;code&gt;text&lt;/code&gt; ä¸ºçº¯æ–‡æœ¬ï¼Œ&lt;code&gt;markdown&lt;/code&gt; ä¸ºå¯Œæ–‡æœ¬ï¼ˆé»˜è®¤ï¼‰&lt;/li&gt; 
    &lt;li&gt;çº¯æ–‡æœ¬æ ¼å¼ä¼šè‡ªåŠ¨å»é™¤æ‰€æœ‰ markdown è¯­æ³•ï¼ˆç²—ä½“ã€é“¾æ¥ç­‰ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;é£ä¹¦æœºå™¨äºº&lt;/strong&gt;ï¼ˆæ¶ˆæ¯æ˜¾ç¤ºæœ€å‹å¥½ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„é£ä¹¦æœºå™¨äºº Webhook åœ°å€ï¼ˆè¯¥é“¾æ¥å¼€å¤´ç±»ä¼¼ &lt;a href="https://www.feishu.cn/flow/api/trigger-webhook/********%EF%BC%89"&gt;https://www.feishu.cn/flow/api/trigger-webhook/********ï¼‰&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;æœ‰ä¸¤ä¸ªæ–¹æ¡ˆï¼Œ&lt;strong&gt;æ–¹æ¡ˆä¸€&lt;/strong&gt;é…ç½®ç®€å•ï¼Œ&lt;strong&gt;æ–¹æ¡ˆäºŒ&lt;/strong&gt;é…ç½®å¤æ‚(ä½†æ˜¯ç¨³å®šæ¨é€)&lt;/p&gt; 
   &lt;p&gt;å…¶ä¸­æ–¹æ¡ˆä¸€ï¼Œç”± &lt;strong&gt;ziventian&lt;/strong&gt;å‘ç°å¹¶æä¾›å»ºè®®ï¼Œåœ¨è¿™é‡Œæ„Ÿè°¢ä»–ï¼Œé»˜è®¤æ˜¯ä¸ªäººæ¨é€ï¼Œä¹Ÿå¯ä»¥é…ç½®ç¾¤ç»„æ¨é€æ“ä½œ&lt;a href="https://github.com/sansan0/TrendRadar/issues/97"&gt;#97&lt;/a&gt; ï¼Œ&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆä¸€ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;å¯¹éƒ¨åˆ†äººå­˜åœ¨é¢å¤–æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥"ç³»ç»Ÿé”™è¯¯"ã€‚éœ€è¦æ‰‹æœºç«¯æœç´¢ä¸‹æœºå™¨äººï¼Œç„¶åå¼€å¯é£ä¹¦æœºå™¨äººåº”ç”¨(è¯¥å»ºè®®æ¥è‡ªäºç½‘å‹ï¼Œå¯å‚è€ƒ)&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-command"&gt;https://botbuilder.feishu.cn/home/my-command&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººæŒ‡ä»¤"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©è§¦å‘å™¨"ï¼Œå¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="6"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "é€šè¿‡å®˜æ–¹æœºå™¨äººå‘æ¶ˆæ¯"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="9"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 4 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆäºŒï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-app"&gt;https://botbuilder.feishu.cn/home/my-app&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººåº”ç”¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;è¿›å…¥åˆ›å»ºçš„åº”ç”¨åï¼Œç‚¹å‡»"æµç¨‹æ¶‰åŠ" &amp;gt; "åˆ›å»ºæµç¨‹" &amp;gt; "é€‰æ‹©è§¦å‘å™¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;å¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="7"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "å‘é€é£ä¹¦æ¶ˆæ¯"ï¼Œå‹¾é€‰ "ç¾¤æ¶ˆæ¯"ï¼Œç„¶åç‚¹å‡»ä¸‹é¢çš„è¾“å…¥æ¡†ï¼Œç‚¹å‡»"æˆ‘ç®¡ç†çš„ç¾¤ç»„"ï¼ˆå¦‚æœæ²¡æœ‰ç¾¤ç»„ï¼Œä½ å¯ä»¥åœ¨é£ä¹¦ app ä¸Šåˆ›å»ºç¾¤ç»„ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="10"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 5 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;é’‰é’‰æœºå™¨äºº&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„é’‰é’‰æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äººï¼ˆä»… PC ç«¯æ”¯æŒï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰“å¼€é’‰é’‰ PC å®¢æˆ·ç«¯ï¼Œè¿›å…¥ç›®æ ‡ç¾¤èŠ&lt;/li&gt; 
      &lt;li&gt;ç‚¹å‡»ç¾¤è®¾ç½®å›¾æ ‡ï¼ˆâš™ï¸ï¼‰â†’ å¾€ä¸‹ç¿»æ‰¾åˆ°"æœºå™¨äºº"ç‚¹å¼€&lt;/li&gt; 
      &lt;li&gt;é€‰æ‹©"æ·»åŠ æœºå™¨äºº" â†’ "è‡ªå®šä¹‰"&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å®‰å…¨è®¾ç½®&lt;/strong&gt;ï¼š 
       &lt;ul&gt; 
        &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰å…³é”®è¯&lt;/strong&gt;ï¼šè®¾ç½® "çƒ­ç‚¹"&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å®Œæˆè®¾ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å‹¾é€‰æœåŠ¡æ¡æ¬¾åè®® â†’ ç‚¹å‡»"å®Œæˆ"&lt;/li&gt; 
      &lt;li&gt;å¤åˆ¶è·å¾—çš„ Webhook URL&lt;/li&gt; 
      &lt;li&gt;å°† URL é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šç§»åŠ¨ç«¯åªèƒ½æ¥æ”¶æ¶ˆæ¯ï¼Œæ— æ³•åˆ›å»ºæ–°æœºå™¨äººã€‚&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;Telegram Bot&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ Telegram Bot Token&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ Telegram Chat ID&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šTelegram éœ€è¦é…ç½®&lt;strong&gt;ä¸¤ä¸ª&lt;/strong&gt; Secretï¼Œè¯·åˆ†åˆ«ç‚¹å‡»ä¸¤æ¬¡"New repository secret"æŒ‰é’®æ·»åŠ &lt;/p&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;åœ¨ Telegram ä¸­æœç´¢ &lt;code&gt;@BotFather&lt;/code&gt;ï¼ˆå¤§å°å†™æ³¨æ„ï¼Œæœ‰è“è‰²å¾½ç« å‹¾å‹¾ï¼Œæœ‰ç±»ä¼¼ 37849827 monthly usersï¼Œè¿™ä¸ªæ‰æ˜¯å®˜æ–¹çš„ï¼Œæœ‰ä¸€äº›ä»¿å®˜æ–¹çš„è´¦å·æ³¨æ„è¾¨åˆ«ï¼‰&lt;/li&gt; 
      &lt;li&gt;å‘é€ &lt;code&gt;/newbot&lt;/code&gt; å‘½ä»¤åˆ›å»ºæ–°æœºå™¨äºº&lt;/li&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°ï¼ˆå¿…é¡»ä»¥"bot"ç»“å°¾ï¼Œå¾ˆå®¹æ˜“é‡åˆ°é‡å¤åå­—ï¼Œæ‰€ä»¥ä½ è¦ç»å°½è„‘æ±æƒ³ä¸åŒçš„åå­—ï¼‰&lt;/li&gt; 
      &lt;li&gt;è·å– Bot Tokenï¼ˆæ ¼å¼å¦‚ï¼š&lt;code&gt;123456789:AAHfiqksKZ8WmR2zSjiQ7_v4TMAKdiHm9T0&lt;/code&gt;ï¼‰&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è·å– Chat ID&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•ä¸€ï¼šé€šè¿‡å®˜æ–¹ API è·å–&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å…ˆå‘ä½ çš„æœºå™¨äººå‘é€ä¸€æ¡æ¶ˆæ¯&lt;/li&gt; 
      &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;https://api.telegram.org/bot&amp;lt;ä½ çš„Bot Token&amp;gt;/getUpdates&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;åœ¨è¿”å›çš„ JSON ä¸­æ‰¾åˆ° &lt;code&gt;"chat":{"id":æ•°å­—}&lt;/code&gt; ä¸­çš„æ•°å­—&lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•äºŒï¼šä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æœç´¢ &lt;code&gt;@userinfobot&lt;/code&gt; å¹¶å‘é€ &lt;code&gt;/start&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;è·å–ä½ çš„ç”¨æˆ· ID ä½œä¸º Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®åˆ° GitHub&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 1 æ­¥è·å¾—çš„ Bot Token&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 2 æ­¥è·å¾—çš„ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;é‚®ä»¶æ¨é€&lt;/strong&gt;ï¼ˆæ”¯æŒæ‰€æœ‰ä¸»æµé‚®ç®±ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ³¨æ„äº‹é¡¹ï¼šä¸ºé˜²æ­¢é‚®ä»¶ç¾¤å‘åŠŸèƒ½è¢«&lt;strong&gt;æ»¥ç”¨&lt;/strong&gt;ï¼Œå½“å‰çš„ç¾¤å‘æ˜¯æ‰€æœ‰æ”¶ä»¶äººéƒ½èƒ½çœ‹åˆ°å½¼æ­¤çš„é‚®ç®±åœ°å€ã€‚&lt;/li&gt; 
    &lt;li&gt;å¦‚æœä½ æ²¡æœ‰è¿‡é…ç½®ä¸‹é¢è¿™ç§é‚®ç®±å‘é€çš„ç»å†ï¼Œä¸å»ºè®®å°è¯•&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;âš ï¸ &lt;strong&gt;é‡è¦é…ç½®ä¾èµ–&lt;/strong&gt;ï¼šé‚®ä»¶æ¨é€éœ€è¦ HTML æŠ¥å‘Šæ–‡ä»¶ã€‚è¯·ç¡®ä¿ &lt;code&gt;config/config.yaml&lt;/code&gt; ä¸­çš„ &lt;code&gt;formats.html&lt;/code&gt; è®¾ç½®ä¸º &lt;code&gt;true&lt;/code&gt;ï¼š&lt;/p&gt; 
    &lt;pre&gt;&lt;code class="language-yaml"&gt;formats:
  sqlite: true
  txt: false
  html: true   # å¿…é¡»å¯ç”¨ï¼Œå¦åˆ™é‚®ä»¶æ¨é€ä¼šå¤±è´¥
&lt;/code&gt;&lt;/pre&gt; 
    &lt;p&gt;å¦‚æœè®¾ç½®ä¸º &lt;code&gt;false&lt;/code&gt;ï¼Œé‚®ä»¶æ¨é€æ—¶ä¼šæŠ¥é”™ï¼š&lt;code&gt;é”™è¯¯ï¼šHTMLæ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæä¾›: None&lt;/code&gt;&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;EMAIL_FROM&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šå‘ä»¶äººé‚®ç®±åœ°å€&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šé‚®ç®±å¯†ç æˆ–æˆæƒç &lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;EMAIL_TO&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šæ”¶ä»¶äººé‚®ç®±åœ°å€ï¼ˆå¤šä¸ªæ”¶ä»¶äººç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œä¹Ÿå¯ä»¥å’Œ EMAIL_FROM ä¸€æ ·ï¼Œè‡ªå·±å‘é€ç»™è‡ªå·±ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ï¼ˆå¯é€‰é…ç½®ï¼Œè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šSMTPæœåŠ¡å™¨åœ°å€ï¼ˆå¯ç•™ç©ºï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ï¼ˆå¯é€‰é…ç½®ï¼Œè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šSMTPç«¯å£ï¼ˆå¯ç•™ç©ºï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šé‚®ä»¶æ¨é€éœ€è¦é…ç½®è‡³å°‘&lt;strong&gt;3ä¸ªå¿…éœ€&lt;/strong&gt; Secretï¼ˆEMAIL_FROMã€EMAIL_PASSWORDã€EMAIL_TOï¼‰ï¼Œåä¸¤ä¸ªä¸ºå¯é€‰é…ç½®&lt;/p&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æ”¯æŒçš„é‚®ç®±æœåŠ¡å•†&lt;/strong&gt;ï¼ˆè‡ªåŠ¨è¯†åˆ« SMTP é…ç½®ï¼‰ï¼š&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;é‚®ç®±æœåŠ¡å•†&lt;/th&gt; 
      &lt;th&gt;åŸŸå&lt;/th&gt; 
      &lt;th&gt;SMTP æœåŠ¡å™¨&lt;/th&gt; 
      &lt;th&gt;ç«¯å£&lt;/th&gt; 
      &lt;th&gt;åŠ å¯†æ–¹å¼&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;Gmail&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;gmail.com&lt;/td&gt; 
      &lt;td&gt;smtp.gmail.com&lt;/td&gt; 
      &lt;td&gt;587&lt;/td&gt; 
      &lt;td&gt;TLS&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;QQé‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;qq.com&lt;/td&gt; 
      &lt;td&gt;smtp.qq.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;Outlook&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;outlook.com&lt;/td&gt; 
      &lt;td&gt;smtp-mail.outlook.com&lt;/td&gt; 
      &lt;td&gt;587&lt;/td&gt; 
      &lt;td&gt;TLS&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;Hotmail&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;hotmail.com&lt;/td&gt; 
      &lt;td&gt;smtp-mail.outlook.com&lt;/td&gt; 
      &lt;td&gt;587&lt;/td&gt; 
      &lt;td&gt;TLS&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;Live&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;live.com&lt;/td&gt; 
      &lt;td&gt;smtp-mail.outlook.com&lt;/td&gt; 
      &lt;td&gt;587&lt;/td&gt; 
      &lt;td&gt;TLS&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;163é‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;163.com&lt;/td&gt; 
      &lt;td&gt;smtp.163.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;126é‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;126.com&lt;/td&gt; 
      &lt;td&gt;smtp.126.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;æ–°æµªé‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;sina.com&lt;/td&gt; 
      &lt;td&gt;smtp.sina.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;æœç‹é‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;sohu.com&lt;/td&gt; 
      &lt;td&gt;smtp.sohu.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;å¤©ç¿¼é‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;189.cn&lt;/td&gt; 
      &lt;td&gt;smtp.189.cn&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;SSL&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;strong&gt;é˜¿é‡Œäº‘é‚®ç®±&lt;/strong&gt;&lt;/td&gt; 
      &lt;td&gt;aliyun.com&lt;/td&gt; 
      &lt;td&gt;smtp.aliyun.com&lt;/td&gt; 
      &lt;td&gt;465&lt;/td&gt; 
      &lt;td&gt;TLS&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;&lt;strong&gt;è‡ªåŠ¨è¯†åˆ«&lt;/strong&gt;ï¼šä½¿ç”¨ä»¥ä¸Šé‚®ç®±æ—¶ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½® &lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt; å’Œ &lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ã€‚&lt;/p&gt; 
    &lt;p&gt;&lt;strong&gt;åé¦ˆè¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;å¦‚æœä½ ä½¿ç”¨&lt;strong&gt;å…¶ä»–é‚®ç®±&lt;/strong&gt;æµ‹è¯•æˆåŠŸï¼Œæ¬¢è¿å¼€ &lt;a href="https://github.com/sansan0/TrendRadar/issues"&gt;Issues&lt;/a&gt; å‘ŠçŸ¥ï¼Œæˆ‘ä¼šæ·»åŠ åˆ°æ”¯æŒåˆ—è¡¨&lt;/li&gt; 
     &lt;li&gt;å¦‚æœä¸Šè¿°é‚®ç®±é…ç½®æœ‰è¯¯æˆ–æ— æ³•ä½¿ç”¨ï¼Œä¹Ÿè¯·å¼€ &lt;a href="https://github.com/sansan0/TrendRadar/issues"&gt;Issues&lt;/a&gt; åé¦ˆï¼Œå¸®åŠ©æ”¹è¿›é¡¹ç›®&lt;/li&gt; 
    &lt;/ul&gt; 
    &lt;p&gt;&lt;strong&gt;ç‰¹åˆ«æ„Ÿè°¢&lt;/strong&gt;ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;æ„Ÿè°¢ &lt;a href="https://github.com/DYZYD"&gt;@DYZYD&lt;/a&gt; è´¡çŒ®å¤©ç¿¼é‚®ç®±ï¼ˆ189.cnï¼‰é…ç½®å¹¶å®Œæˆè‡ªå‘è‡ªæ”¶æµ‹è¯• (&lt;a href="https://github.com/sansan0/TrendRadar/issues/291"&gt;#291&lt;/a&gt;)&lt;/li&gt; 
     &lt;li&gt;æ„Ÿè°¢ &lt;a href="https://github.com/longzhenren"&gt;@longzhenren&lt;/a&gt; è´¡çŒ®é˜¿é‡Œäº‘é‚®ç®±ï¼ˆaliyun.comï¼‰é…ç½®å¹¶å®Œæˆæµ‹è¯• (&lt;a href="https://github.com/sansan0/TrendRadar/issues/344"&gt;#344&lt;/a&gt;)&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é‚®ç®±è®¾ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;QQé‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½• QQé‚®ç®±ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ è´¦æˆ·&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ POP3/SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆæˆæƒç ï¼ˆ16ä½å­—æ¯ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç ï¼Œè€Œé QQ å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;Gmailï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;å¼€å¯ä¸¤æ­¥éªŒè¯&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆåº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™åº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;163/126é‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½•ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ POP3/SMTP/IMAP&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;è®¾ç½®å®¢æˆ·ç«¯æˆæƒç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;é«˜çº§é…ç½®&lt;/strong&gt;ï¼š å¦‚æœè‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼Œå¯æ‰‹åŠ¨é…ç½® SMTPï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ï¼šå¦‚ smtp.gmail.com&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ï¼šå¦‚ 587ï¼ˆTLSï¼‰æˆ– 465ï¼ˆSSLï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;å¦‚æœæœ‰å¤šä¸ªæ”¶ä»¶äºº(æ³¨æ„æ˜¯è‹±æ–‡é€—å·åˆ†éš”)&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;EMAIL_TO="&lt;a href="mailto:user1@example.com"&gt;user1@example.com&lt;/a&gt;,&lt;a href="mailto:user2@example.com"&gt;user2@example.com&lt;/a&gt;,&lt;a href="mailto:user3@example.com"&gt;user3@example.com&lt;/a&gt;"&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;ntfy æ¨é€&lt;/strong&gt;ï¼ˆå¼€æºå…è´¹ï¼Œæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;æ–¹å¼ä¸€ï¼šå…è´¹ä½¿ç”¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰ ğŸ†“&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… æ— éœ€æ³¨å†Œè´¦å·ï¼Œç«‹å³ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;âœ… æ¯å¤© 250 æ¡æ¶ˆæ¯ï¼ˆè¶³å¤Ÿ 90% ç”¨æˆ·ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… Topic åç§°å³"å¯†ç "ï¼ˆéœ€é€‰æ‹©ä¸æ˜“çŒœæµ‹çš„åç§°ï¼‰&lt;/li&gt; 
    &lt;li&gt;âš ï¸ æ¶ˆæ¯æœªåŠ å¯†ï¼Œä¸é€‚åˆæ•æ„Ÿä¿¡æ¯, ä½†é€‚åˆæˆ‘ä»¬è¿™ä¸ªé¡¹ç›®çš„ä¸æ•æ„Ÿä¿¡æ¯&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;å¿«é€Ÿå¼€å§‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä¸‹è½½ ntfy åº”ç”¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Androidï¼š&lt;a href="https://play.google.com/store/apps/details?id=io.heckel.ntfy"&gt;Google Play&lt;/a&gt; / &lt;a href="https://f-droid.org/en/packages/io.heckel.ntfy/"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;iOSï¼š&lt;a href="https://apps.apple.com/us/app/ntfy/id1625396347"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;æ¡Œé¢ï¼šè®¿é—® &lt;a href="https://ntfy.sh"&gt;ntfy.sh&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¢é˜…ä¸»é¢˜&lt;/strong&gt;ï¼ˆé€‰æ‹©ä¸€ä¸ªéš¾çŒœçš„åç§°ï¼‰ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code&gt;å»ºè®®æ ¼å¼ï¼štrendradar-{ä½ çš„åå­—ç¼©å†™}-{éšæœºæ•°å­—}

ä¸èƒ½ä½¿ç”¨ä¸­æ–‡

âœ… å¥½ä¾‹å­ï¼štrendradar-zs-8492
âŒ åä¾‹å­ï¼šnewsã€alertsï¼ˆå¤ªå®¹æ˜“è¢«çŒœåˆ°ï¼‰
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® GitHub Secretï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;NTFY_TOPIC&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šå¡«å†™ä½ åˆšæ‰è®¢é˜…çš„ä¸»é¢˜åç§°&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;NTFY_SERVER_URL&lt;/code&gt;ï¼ˆå¯é€‰é…ç½®ï¼Œè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼‰&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šç•™ç©ºï¼ˆé»˜è®¤ä½¿ç”¨ ntfy.shï¼‰&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;NTFY_TOKEN&lt;/code&gt;ï¼ˆå¯é€‰é…ç½®ï¼Œè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼‰&lt;/p&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šç•™ç©º&lt;/p&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šntfy è‡³å°‘éœ€è¦é…ç½® 1 ä¸ªå¿…éœ€ Secret (NTFY_TOPIC)ï¼Œåä¸¤ä¸ªä¸ºå¯é€‰é…ç½®&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æµ‹è¯•&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -d "æµ‹è¯•æ¶ˆæ¯" ntfy.sh/ä½ çš„ä¸»é¢˜åç§°
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;h3&gt;æ–¹å¼äºŒï¼šè‡ªæ‰˜ç®¡ï¼ˆå®Œå…¨éšç§æ§åˆ¶ï¼‰ ğŸ”’&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤&lt;/strong&gt;ï¼šæœ‰æœåŠ¡å™¨ã€è¿½æ±‚å®Œå…¨éšç§ã€æŠ€æœ¯èƒ½åŠ›å¼º&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… å®Œå…¨å¼€æºï¼ˆApache 2.0 + GPLv2ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… æ•°æ®å®Œå…¨è‡ªä¸»æ§åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… æ— ä»»ä½•é™åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… é›¶è´¹ç”¨&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ä¸€é”®éƒ¨ç½²&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name ntfy \
  -p 80:80 \
  -v /var/cache/ntfy:/var/cache/ntfy \
  binwiederhier/ntfy \
  serve --cache-file /var/cache/ntfy/cache.db
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;é…ç½® TrendRadar&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;NTFY_SERVER_URL: https://ntfy.yourdomain.com
NTFY_TOPIC: trendradar-alerts  # è‡ªæ‰˜ç®¡å¯ç”¨ç®€å•åç§°
NTFY_TOKEN: tk_your_token  # å¯é€‰ï¼šå¯ç”¨è®¿é—®æ§åˆ¶
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;åœ¨åº”ç”¨ä¸­è®¢é˜…&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç‚¹å‡»"Use another server"&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä½ çš„æœåŠ¡å™¨åœ°å€&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä¸»é¢˜åç§°&lt;/li&gt; 
    &lt;li&gt;ï¼ˆå¯é€‰ï¼‰è¾“å…¥ç™»å½•å‡­æ®&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é—®é¢˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q1: å…è´¹ç‰ˆå¤Ÿç”¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;æ¯å¤© 250 æ¡æ¶ˆæ¯å¯¹å¤§å¤šæ•°ç”¨æˆ·è¶³å¤Ÿã€‚æŒ‰ 30 åˆ†é’ŸæŠ“å–ä¸€æ¬¡è®¡ç®—ï¼Œæ¯å¤©çº¦ 48 æ¬¡æ¨é€ï¼Œå®Œå…¨å¤Ÿç”¨ã€‚&lt;/p&gt; 
   &lt;/details&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q2: Topic åç§°çœŸçš„å®‰å…¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;å¦‚æœä½ é€‰æ‹©éšæœºçš„ã€è¶³å¤Ÿé•¿çš„åç§°ï¼ˆå¦‚ &lt;code&gt;trendradar-zs-8492-news&lt;/code&gt;ï¼‰ï¼Œæš´åŠ›ç ´è§£å‡ ä¹ä¸å¯èƒ½ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ntfy æœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶ï¼ˆ1 ç§’ 1 æ¬¡è¯·æ±‚ï¼‰&lt;/li&gt; 
     &lt;li&gt;64 ä¸ªå­—ç¬¦é€‰æ‹©ï¼ˆA-Z, a-z, 0-9, _, -ï¼‰&lt;/li&gt; 
     &lt;li&gt;10 ä½éšæœºå­—ç¬¦ä¸²æœ‰ 64^10 ç§å¯èƒ½æ€§ï¼ˆéœ€è¦æ•°å¹´æ‰èƒ½ç ´è§£ï¼‰&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/details&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;æ¨èé€‰æ‹©ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;ç”¨æˆ·ç±»å‹&lt;/th&gt; 
      &lt;th&gt;æ¨èæ–¹æ¡ˆ&lt;/th&gt; 
      &lt;th&gt;ç†ç”±&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æ™®é€šç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸€ï¼ˆå…è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;ç®€å•å¿«é€Ÿï¼Œå¤Ÿç”¨&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æŠ€æœ¯ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼äºŒï¼ˆè‡ªæ‰˜ç®¡ï¼‰&lt;/td&gt; 
      &lt;td&gt;å®Œå…¨æ§åˆ¶ï¼Œæ— é™åˆ¶&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;é«˜é¢‘ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸‰ï¼ˆä»˜è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;è¿™ä¸ªè‡ªå·±å»å®˜ç½‘çœ‹å§&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;p&gt;&lt;strong&gt;ç›¸å…³é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/"&gt;ntfy å®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/install/"&gt;è‡ªæ‰˜ç®¡æ•™ç¨‹&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/binwiederhier/ntfy"&gt;GitHub ä»“åº“&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;Bark æ¨é€&lt;/strong&gt;ï¼ˆiOS ä¸“å±ï¼Œç®€æ´é«˜æ•ˆï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;BARK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ Bark æ¨é€ URL&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;Bark ç®€ä»‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;Bark æ˜¯ä¸€æ¬¾ iOS å¹³å°çš„å…è´¹å¼€æºæ¨é€å·¥å…·ï¼Œç‰¹ç‚¹æ˜¯ç®€å•ã€å¿«é€Ÿã€æ— å¹¿å‘Šã€‚&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ–¹å¼ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;æ–¹å¼ä¸€ï¼šä½¿ç”¨å®˜æ–¹æœåŠ¡å™¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰ ğŸ†“&lt;/h3&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä¸‹è½½ Bark App&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;iOSï¼š&lt;a href="https://apps.apple.com/cn/app/bark-%E7%BB%99%E4%BD%A0%E7%9A%84%E6%89%8B%E6%9C%BA%E5%8F%91%E6%8E%A8%E9%80%81/id1403753865"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è·å–æ¨é€ URL&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰“å¼€ Bark App&lt;/li&gt; 
      &lt;li&gt;å¤åˆ¶é¦–é¡µæ˜¾ç¤ºçš„æ¨é€ URLï¼ˆæ ¼å¼å¦‚ï¼š&lt;code&gt;https://api.day.app/your_device_key&lt;/code&gt;ï¼‰&lt;/li&gt; 
      &lt;li&gt;å°† URL é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;BARK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h3&gt;æ–¹å¼äºŒï¼šè‡ªå»ºæœåŠ¡å™¨ï¼ˆå®Œå…¨éšç§æ§åˆ¶ï¼‰ ğŸ”’&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤&lt;/strong&gt;ï¼šæœ‰æœåŠ¡å™¨ã€è¿½æ±‚å®Œå…¨éšç§ã€æŠ€æœ¯èƒ½åŠ›å¼º&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ä¸€é”®éƒ¨ç½²&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name bark-server \
  -p 8080:8080 \
  finab/bark-server
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;é…ç½® TrendRadar&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;BARK_URL: http://your-server-ip:8080/your_device_key
&lt;/code&gt;&lt;/pre&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… Bark ä½¿ç”¨ APNs æ¨é€ï¼Œå•æ¡æ¶ˆæ¯æœ€å¤§ 4KB&lt;/li&gt; 
    &lt;li&gt;âœ… æ”¯æŒè‡ªåŠ¨åˆ†æ‰¹æ¨é€ï¼Œæ— éœ€æ‹…å¿ƒæ¶ˆæ¯è¿‡é•¿&lt;/li&gt; 
    &lt;li&gt;âœ… æ¨é€æ ¼å¼ä¸ºçº¯æ–‡æœ¬ï¼ˆè‡ªåŠ¨å»é™¤ Markdown è¯­æ³•ï¼‰&lt;/li&gt; 
    &lt;li&gt;âš ï¸ ä»…æ”¯æŒ iOS å¹³å°&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;ç›¸å…³é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://bark.day.app/"&gt;Bark å®˜æ–¹ç½‘ç«™&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/Finb/Bark"&gt;Bark GitHub ä»“åº“&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/Finb/bark-server"&gt;Bark Server è‡ªå»ºæ•™ç¨‹&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;Slack æ¨é€&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼ˆâš ï¸ Name åç§°å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼‰ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Nameï¼ˆåç§°ï¼‰&lt;/strong&gt;ï¼š&lt;code&gt;SLACK_WEBHOOK_URL&lt;/code&gt;ï¼ˆè¯·å¤åˆ¶ç²˜è´´æ­¤åç§°ï¼Œä¸è¦æ‰‹æ‰“ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Secretï¼ˆå€¼ï¼‰&lt;/strong&gt;ï¼šä½ çš„ Slack Incoming Webhook URL&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;Slack ç®€ä»‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;p&gt;Slack æ˜¯å›¢é˜Ÿåä½œå·¥å…·ï¼ŒIncoming Webhooks å¯ä»¥å°†æ¶ˆæ¯æ¨é€åˆ° Slack é¢‘é“ã€‚&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;è®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;æ­¥éª¤ 1ï¼šåˆ›å»º Slack App&lt;/h3&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¿é—® Slack API é¡µé¢&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰“å¼€ &lt;a href="https://api.slack.com/apps?new_app=1"&gt;https://api.slack.com/apps?new_app=1&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;å¦‚æœæœªç™»å½•ï¼Œå…ˆç™»å½•ä½ çš„ Slack å·¥ä½œç©ºé—´&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€‰æ‹©åˆ›å»ºæ–¹å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ç‚¹å‡» &lt;strong&gt;"From scratch"&lt;/strong&gt;ï¼ˆä»å¤´å¼€å§‹åˆ›å»ºï¼‰&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¡«å†™ App ä¿¡æ¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;App Name&lt;/strong&gt;ï¼šå¡«å†™åº”ç”¨åç§°ï¼ˆå¦‚ &lt;code&gt;TrendRadar&lt;/code&gt; æˆ– &lt;code&gt;çƒ­ç‚¹æ–°é—»ç›‘æ§&lt;/code&gt;ï¼‰&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;Workspace&lt;/strong&gt;ï¼šä»ä¸‹æ‹‰åˆ—è¡¨é€‰æ‹©ä½ çš„å·¥ä½œç©ºé—´&lt;/li&gt; 
      &lt;li&gt;ç‚¹å‡» &lt;strong&gt;"Create App"&lt;/strong&gt; æŒ‰é’®&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h3&gt;æ­¥éª¤ 2ï¼šå¯ç”¨ Incoming Webhooks&lt;/h3&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯¼èˆªåˆ° Incoming Webhooks&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;åœ¨å·¦ä¾§èœå•ä¸­æ‰¾åˆ°å¹¶ç‚¹å‡» &lt;strong&gt;"Incoming Webhooks"&lt;/strong&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯ç”¨åŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰¾åˆ° &lt;strong&gt;"Activate Incoming Webhooks"&lt;/strong&gt; å¼€å…³&lt;/li&gt; 
      &lt;li&gt;å°†å¼€å…³ä» &lt;code&gt;OFF&lt;/code&gt; åˆ‡æ¢åˆ° &lt;code&gt;ON&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;é¡µé¢ä¼šè‡ªåŠ¨åˆ·æ–°æ˜¾ç¤ºæ–°çš„é…ç½®é€‰é¡¹&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h3&gt;æ­¥éª¤ 3ï¼šç”Ÿæˆ Webhook URL&lt;/h3&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ·»åŠ æ–°çš„ Webhook&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨&lt;/li&gt; 
      &lt;li&gt;ç‚¹å‡» &lt;strong&gt;"Add New Webhook to Workspace"&lt;/strong&gt; æŒ‰é’®&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€‰æ‹©ç›®æ ‡é¢‘é“&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ç³»ç»Ÿä¼šå¼¹å‡ºæˆæƒé¡µé¢&lt;/li&gt; 
      &lt;li&gt;ä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©è¦æ¥æ”¶æ¶ˆæ¯çš„é¢‘é“ï¼ˆå¦‚ &lt;code&gt;#çƒ­ç‚¹æ–°é—»&lt;/code&gt;ï¼‰&lt;/li&gt; 
      &lt;li&gt;âš ï¸ å¦‚æœè¦é€‰æ‹©ç§æœ‰é¢‘é“ï¼Œå¿…é¡»å…ˆåŠ å…¥è¯¥é¢‘é“&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æˆæƒåº”ç”¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ç‚¹å‡» &lt;strong&gt;"Allow"&lt;/strong&gt; æŒ‰é’®å®Œæˆæˆæƒ&lt;/li&gt; 
      &lt;li&gt;ç³»ç»Ÿä¼šè‡ªåŠ¨è·³è½¬å›é…ç½®é¡µé¢&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h3&gt;æ­¥éª¤ 4ï¼šå¤åˆ¶å¹¶ä¿å­˜ Webhook URL&lt;/h3&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŸ¥çœ‹ç”Ÿæˆçš„ URL&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;åœ¨ "Webhook URLs for Your Workspace" åŒºåŸŸ&lt;/li&gt; 
      &lt;li&gt;ä¼šçœ‹åˆ°åˆšåˆšç”Ÿæˆçš„ Webhook URL&lt;/li&gt; 
      &lt;li&gt;æ ¼å¼å¦‚ï¼š&lt;code&gt;https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¤åˆ¶ URL&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ç‚¹å‡» URL å³ä¾§çš„ &lt;strong&gt;"Copy"&lt;/strong&gt; æŒ‰é’®&lt;/li&gt; 
      &lt;li&gt;æˆ–æ‰‹åŠ¨é€‰ä¸­ URL å¹¶å¤åˆ¶&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®åˆ° TrendRadar&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;GitHub Actions&lt;/strong&gt;ï¼šå°† URL æ·»åŠ åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;SLACK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;æœ¬åœ°æµ‹è¯•&lt;/strong&gt;ï¼šå°† URL å¡«å…¥ &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;slack_webhook_url&lt;/code&gt; å­—æ®µ&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;Docker éƒ¨ç½²&lt;/strong&gt;ï¼šå°† URL æ·»åŠ åˆ° &lt;code&gt;docker/.env&lt;/code&gt; æ–‡ä»¶çš„ &lt;code&gt;SLACK_WEBHOOK_URL&lt;/code&gt; å˜é‡&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… æ”¯æŒ Markdown æ ¼å¼ï¼ˆè‡ªåŠ¨è½¬æ¢ä¸º Slack mrkdwnï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… æ”¯æŒè‡ªåŠ¨åˆ†æ‰¹æ¨é€ï¼ˆæ¯æ‰¹ 4KBï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… é€‚åˆå›¢é˜Ÿåä½œï¼Œæ¶ˆæ¯é›†ä¸­ç®¡ç†&lt;/li&gt; 
    &lt;li&gt;âš ï¸ Webhook URL åŒ…å«å¯†é’¥ï¼Œåˆ‡å‹¿å…¬å¼€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æ¶ˆæ¯æ ¼å¼é¢„è§ˆï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;pre&gt;&lt;code&gt;*[ç¬¬ 1/2 æ‰¹æ¬¡]*

ğŸ“Š *çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡*

ğŸ”¥ *[1/3] AI ChatGPT* : 2 æ¡

  1. [ç™¾åº¦çƒ­æœ] ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ *[1]* - 09æ—¶15åˆ† (1æ¬¡)

  2. [ä»Šæ—¥å¤´æ¡] AIèŠ¯ç‰‡æ¦‚å¿µè‚¡æš´æ¶¨ *[3]* - [08æ—¶30åˆ† ~ 10æ—¶45åˆ†] (3æ¬¡)
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;ç›¸å…³é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://api.slack.com/messaging/webhooks"&gt;Slack Incoming Webhooks å®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://api.slack.com/apps"&gt;Slack API åº”ç”¨ç®¡ç†&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ‰‹åŠ¨æµ‹è¯•æ–°é—»æ¨é€&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;ğŸ’¡ &lt;strong&gt;å®Œæˆç¬¬1-2æ­¥åï¼Œè¯·ç«‹å³æµ‹è¯•ï¼&lt;/strong&gt; æµ‹è¯•æˆåŠŸåå†æ ¹æ®éœ€è¦è°ƒæ•´é…ç½®ï¼ˆç¬¬4æ­¥ï¼‰ã€‚&lt;/p&gt; 
   &lt;p&gt;âš ï¸ &lt;strong&gt;é‡è¦æé†’ï¼šè¯·è¿›å…¥ä½ è‡ªå·± fork çš„é¡¹ç›®ï¼Œä¸æ˜¯æœ¬é¡¹ç›®ï¼&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;strong&gt;å¦‚ä½•æ‰¾åˆ°ä½ çš„ Actions é¡µé¢&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;æ–¹æ³•ä¸€&lt;/strong&gt;ï¼šæ‰“å¼€ä½  fork çš„é¡¹ç›®ä¸»é¡µï¼Œç‚¹å‡»é¡¶éƒ¨çš„ &lt;strong&gt;Actions&lt;/strong&gt; æ ‡ç­¾&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;æ–¹æ³•äºŒ&lt;/strong&gt;ï¼šç›´æ¥è®¿é—® &lt;code&gt;https://github.com/ä½ çš„ç”¨æˆ·å/TrendRadar/actions&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;ç¤ºä¾‹å¯¹æ¯”&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;âŒ ä½œè€…çš„é¡¹ç›®ï¼š&lt;code&gt;https://github.com/sansan0/TrendRadar/actions&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;âœ… ä½ çš„é¡¹ç›®ï¼š&lt;code&gt;https://github.com/ä½ çš„ç”¨æˆ·å/TrendRadar/actions&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æµ‹è¯•æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;è¿›å…¥ä½ é¡¹ç›®çš„ Actions é¡µé¢&lt;/li&gt; 
   &lt;li&gt;æ‰¾åˆ° &lt;strong&gt;"Get Hot News"&lt;/strong&gt;(å¿…é¡»å¾—æ˜¯è¿™ä¸ªå­—)ç‚¹è¿›å»ï¼Œç‚¹å‡»å³ä¾§çš„ &lt;strong&gt;"Run workflow"&lt;/strong&gt; æŒ‰é’®è¿è¡Œ 
    &lt;ul&gt; 
     &lt;li&gt;å¦‚æœçœ‹ä¸åˆ°è¯¥å­—æ ·ï¼Œå‚ç…§ &lt;a href="https://github.com/sansan0/TrendRadar/issues/109"&gt;#109&lt;/a&gt; è§£å†³&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;3 åˆ†é’Ÿå·¦å³ï¼Œæ¶ˆæ¯ä¼šæ¨é€åˆ°ä½ é…ç½®çš„å¹³å°&lt;/li&gt; 
  &lt;/ol&gt; &lt;br /&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;â±ï¸ &lt;strong&gt;æµ‹è¯•æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ‰‹åŠ¨æµ‹è¯•ä¸è¦å¤ªé¢‘ç¹ï¼Œé¿å…è§¦å‘ GitHub Actions é™åˆ¶&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡» Run workflow åéœ€è¦&lt;strong&gt;åˆ·æ–°æµè§ˆå™¨é¡µé¢&lt;/strong&gt;æ‰èƒ½çœ‹åˆ°æ–°çš„è¿è¡Œè®°å½•&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®è¯´æ˜ï¼ˆå¯é€‰ï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;ğŸ’¡ &lt;strong&gt;é»˜è®¤é…ç½®å·²å¯æ­£å¸¸ä½¿ç”¨&lt;/strong&gt;ï¼Œå¦‚éœ€ä¸ªæ€§åŒ–è°ƒæ•´ï¼Œäº†è§£ä»¥ä¸‹ä¸‰ä¸ªæ–‡ä»¶å³å¯&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;æ–‡ä»¶&lt;/th&gt; 
     &lt;th&gt;ä½œç”¨&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;config/config.yaml&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;ä¸»é…ç½®æ–‡ä»¶ï¼šæ¨é€æ¨¡å¼ã€æ—¶é—´çª—å£ã€å¹³å°åˆ—è¡¨ã€çƒ­ç‚¹æƒé‡ç­‰&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;å…³é”®è¯æ–‡ä»¶ï¼šè®¾ç½®ä½ å…³å¿ƒçš„è¯æ±‡ï¼Œç­›é€‰æ¨é€å†…å®¹&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ‰§è¡Œé¢‘ç‡ï¼šæ§åˆ¶å¤šä¹…è¿è¡Œä¸€æ¬¡ï¼ˆâš ï¸ è°¨æ…ä¿®æ”¹ï¼‰&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;p&gt;ğŸ‘‰ &lt;strong&gt;è¯¦ç»†é…ç½®æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3"&gt;é…ç½®è¯¦è§£&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ‰ éƒ¨ç½²æˆåŠŸï¼åˆ†äº«ä½ çš„ä½¿ç”¨ä½“éªŒ&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;æ­å–œä½ å®Œæˆäº† TrendRadar çš„é…ç½®ï¼ç°åœ¨ä½ å¯ä»¥å¼€å§‹è¿½è¸ªçƒ­ç‚¹èµ„è®¯äº†ã€‚&lt;/p&gt; &lt;p&gt;ğŸ’¬ &lt;strong&gt;æœ‰æ›´å¤šå°ä¼™ä¼´åœ¨å…¬ä¼—å·äº¤æµä½¿ç”¨å¿ƒå¾—ï¼ŒæœŸå¾…ä½ çš„åˆ†äº«~&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æƒ³äº†è§£æ›´å¤šç©æ³•å’Œé«˜çº§æŠ€å·§ï¼Ÿ&lt;/li&gt; 
   &lt;li&gt;é‡åˆ°é—®é¢˜éœ€è¦å¿«é€Ÿè§£ç­”ï¼Ÿ&lt;/li&gt; 
   &lt;li&gt;æœ‰å¥½çš„æƒ³æ³•æƒ³è¦äº¤æµï¼Ÿ&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;ğŸ‘‰ &lt;strong&gt;æ¬¢è¿å…³æ³¨å…¬ä¼—å·ã€Œç¡…åŸºèŒ¶æ°´é—´ã€&lt;/strong&gt;ï¼Œä½ çš„ç‚¹èµå’Œç•™è¨€éƒ½æ˜¯é¡¹ç›®æŒç»­æ›´æ–°çš„åŠ¨åŠ›ã€‚&lt;/p&gt; &lt;p&gt;è¯¦ç»†çš„äº¤æµæ–¹å¼ï¼Œè¯·æŸ¥çœ‹ â†’ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E%E4%BA%A4%E6%B5%81"&gt;é—®é¢˜ç­”ç–‘ä¸äº¤æµ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æƒ³è¦æ›´æ™ºèƒ½çš„åˆ†æï¼Ÿè¯•è¯• AI å¢å¼ºåŠŸèƒ½&lt;/strong&gt;ï¼ˆå¯é€‰ï¼‰&lt;/p&gt; &lt;p&gt;åŸºç¡€é…ç½®å·²ç»èƒ½æ»¡è¶³æ—¥å¸¸ä½¿ç”¨ï¼Œä½†å¦‚æœä½ æƒ³è¦ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ“Š è®© AI è‡ªåŠ¨åˆ†æçƒ­ç‚¹è¶‹åŠ¿å’Œæ•°æ®æ´å¯Ÿ&lt;/li&gt; 
   &lt;li&gt;ğŸ” é€šè¿‡è‡ªç„¶è¯­è¨€æœç´¢å’ŒæŸ¥è¯¢æ–°é—»&lt;/li&gt; 
   &lt;li&gt;ğŸ’¡ è·å¾—æƒ…æ„Ÿåˆ†æã€è¯é¢˜é¢„æµ‹ç­‰æ·±åº¦åˆ†æ&lt;/li&gt; 
   &lt;li&gt;âš¡ åœ¨ Claudeã€Cursor ç­‰ AI å·¥å…·ä¸­ç›´æ¥è°ƒç”¨æ•°æ®&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;ğŸ‘‰ &lt;strong&gt;äº†è§£æ›´å¤š&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90"&gt;AI æ™ºèƒ½åˆ†æ&lt;/a&gt; â€” è§£é”é¡¹ç›®çš„éšè—èƒ½åŠ›ï¼Œè®©çƒ­ç‚¹è¿½è¸ªæ›´é«˜æ•ˆï¼&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a name="é…ç½®è¯¦è§£"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âš™ï¸ é…ç½®è¯¦è§£&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“– æé†’&lt;/strong&gt;ï¼šæœ¬ç« èŠ‚æä¾›è¯¦ç»†çš„é…ç½®è¯´æ˜ï¼Œå»ºè®®å…ˆå®Œæˆ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;å¿«é€Ÿå¼€å§‹&lt;/a&gt; çš„åŸºç¡€é…ç½®ï¼Œå†æ ¹æ®éœ€è¦å›æ¥æŸ¥çœ‹è¯¦ç»†é€‰é¡¹ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;1. å¹³å°é…ç½®&lt;/h3&gt; 
&lt;details id="è‡ªå®šä¹‰ç›‘æ§å¹³å°"&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;è‡ªå®šä¹‰ç›‘æ§å¹³å°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;platforms&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®çš„èµ„è®¯æ•°æ®æ¥æºäº &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; ï¼Œä½ å¯ä»¥ç‚¹å‡»&lt;a href="https://newsnow.busiyi.world/"&gt;ç½‘ç«™&lt;/a&gt;ï¼Œç‚¹å‡»[æ›´å¤š]ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰ä½ æƒ³è¦çš„å¹³å°ã€‚&lt;/p&gt; 
 &lt;p&gt;å…·ä½“æ·»åŠ å¯è®¿é—® &lt;a href="https://github.com/ourongxing/newsnow/tree/main/server/sources"&gt;é¡¹ç›®æºä»£ç &lt;/a&gt;ï¼Œæ ¹æ®é‡Œé¢çš„æ–‡ä»¶åï¼Œåœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ä¸­ä¿®æ”¹ &lt;code&gt;platforms&lt;/code&gt; é…ç½®ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;platforms:
  - id: "toutiao"
    name: "ä»Šæ—¥å¤´æ¡"
  - id: "baidu"
    name: "ç™¾åº¦çƒ­æœ"
  - id: "wallstreetcn-hot"
    name: "åå°”è¡—è§é—»"
  # æ·»åŠ æ›´å¤šå¹³å°...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;å¿«æ·æ–¹å¼&lt;/strong&gt;ï¼šå¦‚æœä¸ä¼šçœ‹æºä»£ç ï¼Œå¯ä»¥å¤åˆ¶ä»–äººæ•´ç†å¥½çš„ &lt;a href="https://github.com/sansan0/TrendRadar/issues/95"&gt;å¹³å°é…ç½®æ±‡æ€»&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;âš ï¸ &lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šå¹³å°ä¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼Œå»ºè®®é€‰æ‹© 10-15 ä¸ªæ ¸å¿ƒå¹³å°ã€‚è¿‡å¤šå¹³å°ä¼šå¯¼è‡´ä¿¡æ¯è¿‡è½½ï¼Œåè€Œé™ä½ä½¿ç”¨ä½“éªŒã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;h3&gt;2. å…³é”®è¯é…ç½®&lt;/h3&gt; 
&lt;p&gt;åœ¨ &lt;code&gt;frequency_words.txt&lt;/code&gt; æ–‡ä»¶ä¸­é…ç½®ç›‘æ§çš„å…³é”®è¯ï¼Œæ”¯æŒäº”ç§è¯­æ³•ã€åŒºåŸŸæ ‡è®°å’Œè¯ç»„åŠŸèƒ½ã€‚&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;è¯­æ³•ç±»å‹&lt;/th&gt; 
   &lt;th&gt;ç¬¦å·&lt;/th&gt; 
   &lt;th&gt;ä½œç”¨&lt;/th&gt; 
   &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
   &lt;th&gt;åŒ¹é…é€»è¾‘&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;æ™®é€šè¯&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;æ— &lt;/td&gt; 
   &lt;td&gt;åŸºç¡€åŒ¹é…&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;åä¸º&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;åŒ…å«ä»»æ„ä¸€ä¸ªå³å¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;é™å®šèŒƒå›´&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;+æ‰‹æœº&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;å¿…é¡»åŒæ—¶åŒ…å«&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;!&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;æ’é™¤å¹²æ‰°&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;!å¹¿å‘Š&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;åŒ…å«åˆ™ç›´æ¥æ’é™¤&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;æ•°é‡é™åˆ¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;@&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;æ§åˆ¶æ˜¾ç¤ºæ•°é‡&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;@10&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;æœ€å¤šæ˜¾ç¤º10æ¡æ–°é—»ï¼ˆv3.2.0æ–°å¢ï¼‰&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å…¨å±€è¿‡æ»¤&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;[GLOBAL_FILTER]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;å…¨å±€æ’é™¤æŒ‡å®šå†…å®¹&lt;/td&gt; 
   &lt;td&gt;è§ä¸‹æ–¹ç¤ºä¾‹&lt;/td&gt; 
   &lt;td&gt;ä»»ä½•æƒ…å†µä¸‹éƒ½è¿‡æ»¤ï¼ˆv3.5.0æ–°å¢ï¼‰&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;2.1 åŸºç¡€è¯­æ³•&lt;/h4&gt; 
&lt;p&gt;&lt;a name="å…³é”®è¯åŸºç¡€è¯­æ³•"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;åŸºç¡€è¯­æ³•æ•™ç¨‹&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/frequency_words.txt&lt;/code&gt;&lt;/p&gt; 
 &lt;h5&gt;1. &lt;strong&gt;æ™®é€šå…³é”®è¯&lt;/strong&gt; - åŸºç¡€åŒ¹é…&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; æ–°é—»æ ‡é¢˜åŒ…å«å…¶ä¸­&lt;strong&gt;ä»»æ„ä¸€ä¸ªè¯&lt;/strong&gt;å°±ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h5&gt;2. &lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt; &lt;code&gt;+è¯æ±‡&lt;/code&gt; - é™å®šèŒƒå›´&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ‰‹æœº
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; å¿…é¡»åŒæ—¶åŒ…å«æ™®é€šè¯&lt;strong&gt;å’Œ&lt;/strong&gt;å¿…é¡»è¯æ‰ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h5&gt;3. &lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt; &lt;code&gt;!è¯æ±‡&lt;/code&gt; - æ’é™¤å¹²æ‰°&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;è‹¹æœ
åä¸º
!æ°´æœ
!ä»·æ ¼
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; åŒ…å«è¿‡æ»¤è¯çš„æ–°é—»ä¼šè¢«&lt;strong&gt;ç›´æ¥æ’é™¤&lt;/strong&gt;ï¼Œå³ä½¿åŒ…å«å…³é”®è¯&lt;/p&gt; 
 &lt;h5&gt;4. &lt;strong&gt;æ•°é‡é™åˆ¶&lt;/strong&gt; &lt;code&gt;@æ•°å­—&lt;/code&gt; - æ§åˆ¶æ˜¾ç¤ºæ•°é‡ï¼ˆv3.2.0 æ–°å¢ï¼‰&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;ç‰¹æ–¯æ‹‰
é©¬æ–¯å…‹
@5
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; é™åˆ¶è¯¥å…³é”®è¯ç»„æœ€å¤šæ˜¾ç¤ºçš„æ–°é—»æ¡æ•°&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä¼˜å…ˆçº§ï¼š&lt;/strong&gt; &lt;code&gt;@æ•°å­—&lt;/code&gt; &amp;gt; å…¨å±€é…ç½® &amp;gt; ä¸é™åˆ¶&lt;/p&gt; 
 &lt;h5&gt;5. &lt;strong&gt;å…¨å±€è¿‡æ»¤&lt;/strong&gt; &lt;code&gt;[GLOBAL_FILTER]&lt;/code&gt; - å…¨å±€æ’é™¤æŒ‡å®šå†…å®¹ï¼ˆv3.5.0 æ–°å¢ï¼‰&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;[GLOBAL_FILTER]
å¹¿å‘Š
æ¨å¹¿
è¥é”€
éœ‡æƒŠ
æ ‡é¢˜å…š

[WORD_GROUPS]
ç§‘æŠ€
AI

åä¸º
é¸¿è’™
!è½¦
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; åœ¨ä»»ä½•æƒ…å†µä¸‹è¿‡æ»¤åŒ…å«æŒ‡å®šè¯çš„æ–°é—»ï¼Œ&lt;strong&gt;ä¼˜å…ˆçº§æœ€é«˜&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è¿‡æ»¤ä½è´¨å†…å®¹ï¼šéœ‡æƒŠã€æ ‡é¢˜å…šã€çˆ†æ–™ç­‰&lt;/li&gt; 
  &lt;li&gt;è¿‡æ»¤è¥é”€å†…å®¹ï¼šå¹¿å‘Šã€æ¨å¹¿ã€èµåŠ©ç­‰&lt;/li&gt; 
  &lt;li&gt;è¿‡æ»¤ç‰¹å®šä¸»é¢˜ï¼šå¨±ä¹ã€å…«å¦ï¼ˆæ ¹æ®éœ€æ±‚ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;è¿‡æ»¤ä¼˜å…ˆçº§ï¼š&lt;/strong&gt; å…¨å±€è¿‡æ»¤ &amp;gt; è¯ç»„å†…è¿‡æ»¤(&lt;code&gt;!&lt;/code&gt;) &amp;gt; è¯ç»„åŒ¹é…&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŒºåŸŸè¯´æ˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;[GLOBAL_FILTER]&lt;/code&gt;ï¼šå…¨å±€è¿‡æ»¤åŒºï¼ŒåŒ…å«çš„è¯åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½ä¼šè¢«è¿‡æ»¤&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;[WORD_GROUPS]&lt;/code&gt;ï¼šè¯ç»„åŒºï¼Œä¿æŒç°æœ‰è¯­æ³•ï¼ˆ&lt;code&gt;!&lt;/code&gt;ã€&lt;code&gt;+&lt;/code&gt;ã€&lt;code&gt;@&lt;/code&gt;ï¼‰&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä¸ä½¿ç”¨åŒºåŸŸæ ‡è®°ï¼Œé»˜è®¤å…¨éƒ¨ä½œä¸ºè¯ç»„å¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;[GLOBAL_FILTER]
å¹¿å‘Š

[WORD_GROUPS]
ç§‘æŠ€
AI
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âŒ "å¹¿å‘Šï¼šæœ€æ–°ç§‘æŠ€äº§å“å‘å¸ƒ" â† åŒ…å«å…¨å±€è¿‡æ»¤è¯"å¹¿å‘Š"ï¼Œç›´æ¥æ‹’ç»&lt;/li&gt; 
  &lt;li&gt;âœ… "ç§‘æŠ€å…¬å¸å‘å¸ƒAIæ–°äº§å“" â† ä¸åŒ…å«å…¨å±€è¿‡æ»¤è¯ï¼ŒåŒ¹é…"ç§‘æŠ€"è¯ç»„&lt;/li&gt; 
  &lt;li&gt;âœ… "AIæŠ€æœ¯çªç ´å¼•å‘å…³æ³¨" â† ä¸åŒ…å«å…¨å±€è¿‡æ»¤è¯ï¼ŒåŒ¹é…"ç§‘æŠ€"è¯ç»„ä¸­çš„"AI"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…¨å±€è¿‡æ»¤è¯åº”è°¨æ…ä½¿ç”¨ï¼Œé¿å…è¿‡åº¦è¿‡æ»¤å¯¼è‡´é—æ¼æœ‰ä»·å€¼å†…å®¹&lt;/li&gt; 
  &lt;li&gt;å»ºè®®å…¨å±€è¿‡æ»¤è¯æ§åˆ¶åœ¨ 5-15 ä¸ªä»¥å†…&lt;/li&gt; 
  &lt;li&gt;å¯¹äºç‰¹å®šè¯ç»„çš„è¿‡æ»¤ï¼Œä¼˜å…ˆä½¿ç”¨è¯ç»„å†…è¿‡æ»¤è¯ï¼ˆ&lt;code&gt;!&lt;/code&gt; å‰ç¼€ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;ğŸ”— è¯ç»„åŠŸèƒ½ - ç©ºè¡Œåˆ†éš”çš„é‡è¦ä½œç”¨&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒè§„åˆ™ï¼š&lt;/strong&gt; ç”¨&lt;strong&gt;ç©ºè¡Œ&lt;/strong&gt;åˆ†éš”ä¸åŒçš„è¯ç»„ï¼Œæ¯ä¸ªè¯ç»„ç‹¬ç«‹ç»Ÿè®¡&lt;/p&gt; 
 &lt;h5&gt;ç¤ºä¾‹é…ç½®ï¼š&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;iPhone
åä¸º
OPPO
+å‘å¸ƒ

Aè‚¡
ä¸Šè¯
æ·±è¯
+æ¶¨è·Œ
!é¢„æµ‹

ä¸–ç•Œæ¯
æ¬§æ´²æ¯
äºšæ´²æ¯
+æ¯”èµ›
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;è¯ç»„è§£é‡ŠåŠåŒ¹é…æ•ˆæœï¼š&lt;/h5&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬1ç»„ - æ‰‹æœºæ–°å“ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šiPhoneã€åä¸ºã€OPPO&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šå‘å¸ƒ&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå¿…é¡»åŒ…å«æ‰‹æœºå“ç‰Œåï¼ŒåŒæ—¶åŒ…å«"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "iPhone 15æ­£å¼å‘å¸ƒå”®ä»·å…¬å¸ƒ" â† æœ‰"iPhone"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "åä¸ºMate60ç³»åˆ—å‘å¸ƒä¼šç›´æ’­" â† æœ‰"åä¸º"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "OPPO Find X7å‘å¸ƒæ—¶é—´ç¡®å®š" â† æœ‰"OPPO"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âŒ "iPhoneé”€é‡åˆ›æ–°é«˜" â† æœ‰"iPhone"ä½†ç¼ºå°‘"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬2ç»„ - è‚¡å¸‚è¡Œæƒ…ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šAè‚¡ã€ä¸Šè¯ã€æ·±è¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¶¨è·Œ&lt;/li&gt; 
  &lt;li&gt;è¿‡æ»¤è¯ï¼šé¢„æµ‹&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå…³æ³¨è‚¡å¸‚æ¶¨è·Œå®å†µï¼Œæ’é™¤é¢„æµ‹ç±»å†…å®¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "Aè‚¡ä»Šæ—¥å¤§å¹…æ¶¨è·Œåˆ†æ" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âœ… "ä¸Šè¯æŒ‡æ•°æ¶¨è·Œå¹…åˆ›æ–°é«˜" â† æœ‰"ä¸Šè¯"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âŒ "ä¸“å®¶é¢„æµ‹Aè‚¡æ¶¨è·Œè¶‹åŠ¿" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"ä½†åŒ…å«"é¢„æµ‹"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬3ç»„ - è¶³çƒèµ›äº‹ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šä¸–ç•Œæ¯ã€æ¬§æ´²æ¯ã€äºšæ´²æ¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¯”èµ›&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šåªå…³æ³¨æ¯”èµ›ç›¸å…³æ–°é—»&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;ğŸ“ é…ç½®æŠ€å·§&lt;/h4&gt; 
 &lt;h5&gt;1. &lt;strong&gt;ä»å®½åˆ°ä¸¥&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# ç¬¬ä¸€æ­¥ï¼šå…ˆç”¨å®½æ³›å…³é”®è¯æµ‹è¯•
äººå·¥æ™ºèƒ½
AI
ChatGPT

# ç¬¬äºŒæ­¥ï¼šå‘ç°è¯¯åŒ¹é…åï¼ŒåŠ å…¥å¿…é¡»è¯é™å®š
äººå·¥æ™ºèƒ½
AI
ChatGPT
+æŠ€æœ¯

# ç¬¬ä¸‰æ­¥ï¼šå‘ç°å¹²æ‰°å†…å®¹åï¼ŒåŠ å…¥è¿‡æ»¤è¯
äººå·¥æ™ºèƒ½
AI
ChatGPT
+æŠ€æœ¯
!å¹¿å‘Š
!åŸ¹è®­
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;2. &lt;strong&gt;é¿å…è¿‡åº¦å¤æ‚&lt;/strong&gt;&lt;/h5&gt; 
 &lt;p&gt;âŒ &lt;strong&gt;ä¸æ¨èï¼š&lt;/strong&gt; ä¸€ä¸ªè¯ç»„åŒ…å«å¤ªå¤šè¯æ±‡&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
ä¸‰æ˜Ÿ
vivo
ä¸€åŠ 
é­…æ—
+æ‰‹æœº
+å‘å¸ƒ
+é”€é‡
!å‡è´§
!ç»´ä¿®
!äºŒæ‰‹
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;âœ… &lt;strong&gt;æ¨èï¼š&lt;/strong&gt; æ‹†åˆ†æˆå¤šä¸ªç²¾ç¡®çš„è¯ç»„&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ–°å“

è‹¹æœ
ä¸‰æ˜Ÿ
+å‘å¸ƒ

æ‰‹æœº
é”€é‡
+å¸‚åœº
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;2.2 é«˜çº§é…ç½®ï¼ˆv3.2.0 æ–°å¢ï¼‰&lt;/h4&gt; 
&lt;p&gt;&lt;a name="å…³é”®è¯é«˜çº§é…ç½®"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;é«˜çº§é…ç½®æ•™ç¨‹&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;h5&gt;å…³é”®è¯æ’åºä¼˜å…ˆçº§&lt;/h5&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;report:
  sort_by_position_first: false  # æ’åºä¼˜å…ˆçº§é…ç½®
&lt;/code&gt;&lt;/pre&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é…ç½®å€¼&lt;/th&gt; 
    &lt;th&gt;æ’åºè§„åˆ™&lt;/th&gt; 
    &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;ï¼ˆé»˜è®¤ï¼‰&lt;/td&gt; 
    &lt;td&gt;çƒ­ç‚¹æ¡æ•° â†“ â†’ é…ç½®ä½ç½® â†‘&lt;/td&gt; 
    &lt;td&gt;å…³æ³¨çƒ­åº¦è¶‹åŠ¿&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;é…ç½®ä½ç½® â†‘ â†’ çƒ­ç‚¹æ¡æ•° â†“&lt;/td&gt; 
    &lt;td&gt;å…³æ³¨ä¸ªäººä¼˜å…ˆçº§&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;ç¤ºä¾‹ï¼š&lt;/strong&gt; é…ç½®é¡ºåº Aã€Bã€Cï¼Œçƒ­ç‚¹æ•° A(3æ¡)ã€B(10æ¡)ã€C(5æ¡)&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;false&lt;/code&gt;ï¼šB(10æ¡) â†’ C(5æ¡) â†’ A(3æ¡)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;true&lt;/code&gt;ï¼šA(3æ¡) â†’ B(10æ¡) â†’ C(5æ¡)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h5&gt;å…¨å±€æ˜¾ç¤ºæ•°é‡é™åˆ¶&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;report:
  max_news_per_keyword: 10  # æ¯ä¸ªå…³é”®è¯æœ€å¤šæ˜¾ç¤º10æ¡ï¼ˆ0=ä¸é™åˆ¶ï¼‰
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Docker ç¯å¢ƒå˜é‡ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;SORT_BY_POSITION_FIRST=true
MAX_NEWS_PER_KEYWORD=10
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ç»¼åˆç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
report:
  sort_by_position_first: true   # æŒ‰é…ç½®é¡ºåºä¼˜å…ˆ
  max_news_per_keyword: 10       # å…¨å±€é»˜è®¤æ¯ä¸ªå…³é”®è¯æœ€å¤š10æ¡
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# frequency_words.txt
ç‰¹æ–¯æ‹‰
é©¬æ–¯å…‹
@20              # é‡ç‚¹å…³æ³¨ï¼Œæ˜¾ç¤º20æ¡ï¼ˆè¦†ç›–å…¨å±€é…ç½®ï¼‰

åä¸º            # ä½¿ç”¨å…¨å±€é…ç½®ï¼Œæ˜¾ç¤º10æ¡

æ¯”äºšè¿ª
@5               # é™åˆ¶5æ¡
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æœ€ç»ˆæ•ˆæœï¼š&lt;/strong&gt; æŒ‰é…ç½®é¡ºåºæ˜¾ç¤º ç‰¹æ–¯æ‹‰(20æ¡) â†’ åä¸º(10æ¡) â†’ æ¯”äºšè¿ª(5æ¡)&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3. æ¨é€æ¨¡å¼è¯¦è§£&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;ä¸‰ç§æ¨é€æ¨¡å¼è¯¦ç»†å¯¹æ¯”&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;report.mode&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;report:
  mode: "daily"  # å¯é€‰: "daily" | "incremental" | "current"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Docker ç¯å¢ƒå˜é‡ï¼š&lt;/strong&gt; &lt;code&gt;REPORT_MODE=incremental&lt;/code&gt;&lt;/p&gt; 
 &lt;h4&gt;è¯¦ç»†å¯¹æ¯”è¡¨æ ¼&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ¨¡å¼&lt;/th&gt; 
    &lt;th&gt;é€‚ç”¨äººç¾¤&lt;/th&gt; 
    &lt;th&gt;æ¨é€æ—¶æœº&lt;/th&gt; 
    &lt;th&gt;æ˜¾ç¤ºå†…å®¹&lt;/th&gt; 
    &lt;th&gt;å…¸å‹ä½¿ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å½“æ—¥æ±‡æ€»&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ“‹ ä¼ä¸šç®¡ç†è€…/æ™®é€šç”¨æˆ·&lt;/td&gt; 
    &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
    &lt;td&gt;å½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;æ¡ˆä¾‹&lt;/strong&gt;ï¼šæ¯å¤©ä¸‹åˆ6ç‚¹æŸ¥çœ‹ä»Šå¤©æ‰€æœ‰é‡è¦æ–°é—»&lt;br /&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šçœ‹å…¨å¤©å®Œæ•´è¶‹åŠ¿ï¼Œä¸æ¼æ‰ä»»ä½•çƒ­ç‚¹&lt;br /&gt;&lt;strong&gt;æé†’&lt;/strong&gt;ï¼šä¼šåŒ…å«ä¹‹å‰æ¨é€è¿‡çš„æ–°é—»&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å½“å‰æ¦œå•&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ“° è‡ªåª’ä½“äºº/å†…å®¹åˆ›ä½œè€…&lt;/td&gt; 
    &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
    &lt;td&gt;å½“å‰æ¦œå•åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;æ¡ˆä¾‹&lt;/strong&gt;ï¼šæ¯å°æ—¶è¿½è¸ª"å“ªäº›è¯é¢˜ç°åœ¨æœ€ç«"&lt;br /&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šå®æ—¶äº†è§£å½“å‰çƒ­åº¦æ’åå˜åŒ–&lt;br /&gt;&lt;strong&gt;æé†’&lt;/strong&gt;ï¼šæŒç»­åœ¨æ¦œçš„æ–°é—»æ¯æ¬¡éƒ½ä¼šå‡ºç°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å¢é‡ç›‘æ§&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;incremental&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ“ˆ æŠ•èµ„è€…/äº¤æ˜“å‘˜&lt;/td&gt; 
    &lt;td&gt;æœ‰æ–°å¢æ‰æ¨é€&lt;/td&gt; 
    &lt;td&gt;æ–°å‡ºç°çš„åŒ¹é…é¢‘ç‡è¯æ–°é—»&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;æ¡ˆä¾‹&lt;/strong&gt;ï¼šç›‘æ§"ç‰¹æ–¯æ‹‰"ï¼Œåªåœ¨æœ‰æ–°æ¶ˆæ¯æ—¶é€šçŸ¥&lt;br /&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼šé›¶é‡å¤ï¼Œåªçœ‹é¦–æ¬¡å‡ºç°çš„æ–°é—»&lt;br /&gt;&lt;strong&gt;é€‚åˆ&lt;/strong&gt;ï¼šé«˜é¢‘ç›‘æ§ã€é¿å…ä¿¡æ¯æ‰“æ‰°&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;å®é™…æ¨é€æ•ˆæœä¸¾ä¾‹&lt;/h4&gt; 
 &lt;p&gt;å‡è®¾ä½ ç›‘æ§"è‹¹æœ"å…³é”®è¯ï¼Œæ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ—¶é—´&lt;/th&gt; 
    &lt;th&gt;daily æ¨¡å¼æ¨é€&lt;/th&gt; 
    &lt;th&gt;current æ¨¡å¼æ¨é€&lt;/th&gt; 
    &lt;th&gt;incremental æ¨¡å¼æ¨é€&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;10:00&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Aã€æ–°é—»B&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Aã€æ–°é—»B&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Aã€æ–°é—»B&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;11:00&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Aã€æ–°é—»Bã€æ–°é—»C&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Bã€æ–°é—»Cã€æ–°é—»D&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;ä»…&lt;/strong&gt;æ–°é—»C&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;12:00&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Aã€æ–°é—»Bã€æ–°é—»C&lt;/td&gt; 
    &lt;td&gt;æ–°é—»Cã€æ–°é—»Dã€æ–°é—»E&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;ä»…&lt;/strong&gt;æ–°é—»Dã€æ–°é—»E&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;daily&lt;/code&gt;ï¼šç´¯ç§¯å±•ç¤ºå½“å¤©æ‰€æœ‰æ–°é—»ï¼ˆAã€Bã€C éƒ½ä¿ç•™ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;current&lt;/code&gt;ï¼šå±•ç¤ºå½“å‰æ¦œå•çš„æ–°é—»ï¼ˆæ’åå˜åŒ–ï¼Œæ–°é—»Dä¸Šæ¦œï¼Œæ–°é—»Aæ‰æ¦œï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;incremental&lt;/code&gt;ï¼š&lt;strong&gt;åªæ¨é€æ–°å‡ºç°çš„æ–°é—»&lt;/strong&gt;ï¼ˆé¿å…é‡å¤å¹²æ‰°ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;å¸¸è§é—®é¢˜&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;ğŸ’¡ é‡åˆ°è¿™ä¸ªé—®é¢˜ï¼Ÿ&lt;/strong&gt; ğŸ‘‰ "æ¯ä¸ªå°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œç¬¬ä¸€æ¬¡æ‰§è¡Œå®Œè¾“å‡ºçš„æ–°é—»ï¼Œåœ¨ä¸‹ä¸€ä¸ªå°æ—¶æ‰§è¡Œæ—¶è¿˜ä¼šå‡ºç°"&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;åŸå› &lt;/strong&gt;ï¼šä½ å¯èƒ½é€‰æ‹©äº† &lt;code&gt;daily&lt;/code&gt;ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰æˆ– &lt;code&gt;current&lt;/code&gt;ï¼ˆå½“å‰æ¦œå•ï¼‰æ¨¡å¼&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;è§£å†³&lt;/strong&gt;ï¼šæ”¹ç”¨ &lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰æ¨¡å¼ï¼Œåªæ¨é€æ–°å¢å†…å®¹&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;âš ï¸ å¢é‡æ¨¡å¼é‡è¦æç¤º&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;é€‰æ‹©äº† &lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰æ¨¡å¼çš„ç”¨æˆ·è¯·æ³¨æ„ï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;p&gt;ğŸ“Œ &lt;strong&gt;å¢é‡æ¨¡å¼åªåœ¨æœ‰æ–°å¢åŒ¹é…æ–°é—»æ—¶æ‰ä¼šæ¨é€&lt;/strong&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;å¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ”¶åˆ°æ¨é€ï¼Œå¯èƒ½æ˜¯å› ä¸ºï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;å½“å‰æ—¶æ®µæ²¡æœ‰ç¬¦åˆä½ å…³é”®è¯çš„æ–°çƒ­ç‚¹å‡ºç°&lt;/li&gt; 
   &lt;li&gt;å…³é”®è¯é…ç½®è¿‡äºä¸¥æ ¼æˆ–è¿‡äºå®½æ³›&lt;/li&gt; 
   &lt;li&gt;ç›‘æ§å¹³å°æ•°é‡è¾ƒå°‘&lt;/li&gt; 
  &lt;/ol&gt; 
  &lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æ–¹æ¡ˆ1ï¼šğŸ‘‰ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#2-%E5%85%B3%E9%94%AE%E8%AF%8D%E9%85%8D%E7%BD%AE"&gt;ä¼˜åŒ–å…³é”®è¯é…ç½®&lt;/a&gt; - è°ƒæ•´å…³é”®è¯çš„ç²¾å‡†åº¦ï¼Œå¢åŠ æˆ–ä¿®æ”¹ç›‘æ§è¯æ±‡&lt;/li&gt; 
   &lt;li&gt;æ–¹æ¡ˆ2ï¼šåˆ‡æ¢æ¨é€æ¨¡å¼ - æ”¹ç”¨ &lt;code&gt;current&lt;/code&gt; æˆ– &lt;code&gt;daily&lt;/code&gt; æ¨¡å¼ï¼Œå¯ä»¥å®šæ—¶æ¥æ”¶æ¨é€&lt;/li&gt; 
   &lt;li&gt;æ–¹æ¡ˆ3ï¼šğŸ‘‰ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#1-%E5%B9%B3%E5%8F%B0%E9%85%8D%E7%BD%AE"&gt;å¢åŠ ç›‘æ§å¹³å°&lt;/a&gt; - æ·»åŠ æ›´å¤šæ–°é—»å¹³å°ï¼Œæ‰©å¤§ä¿¡æ¯æ¥æº&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;h3&gt;4. çƒ­ç‚¹æƒé‡è°ƒæ•´&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;çƒ­ç‚¹æƒé‡è°ƒæ•´&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;weight&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.6       # æ’åæƒé‡
  frequency_weight: 0.3  # é¢‘æ¬¡æƒé‡
  hotness_weight: 0.1    # çƒ­åº¦æƒé‡
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å½“å‰é»˜è®¤çš„é…ç½®æ˜¯å¹³è¡¡æ€§é…ç½®&lt;/p&gt; 
 &lt;h4&gt;ä¸¤ä¸ªæ ¸å¿ƒåœºæ™¯&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½å®æ—¶çƒ­ç‚¹å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.8    # ä¸»è¦çœ‹æ’å
  frequency_weight: 0.1  # ä¸å¤ªåœ¨ä¹æŒç»­æ€§
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šè‡ªåª’ä½“åšä¸»ã€è¥é”€äººå‘˜ã€æƒ³å¿«é€Ÿäº†è§£å½“ä¸‹æœ€ç«è¯é¢˜çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½æ·±åº¦è¯é¢˜å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.4    # é€‚åº¦çœ‹æ’å
  frequency_weight: 0.5  # é‡è§†å½“å¤©å†…çš„æŒç»­çƒ­åº¦
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šæŠ•èµ„è€…ã€ç ”ç©¶äººå‘˜ã€æ–°é—»å·¥ä½œè€…ã€éœ€è¦æ·±åº¦åˆ†æè¶‹åŠ¿çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;h4&gt;è°ƒæ•´çš„æ–¹æ³•&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ä¸‰ä¸ªæ•°å­—åŠ èµ·æ¥å¿…é¡»ç­‰äº 1.0&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å“ªä¸ªé‡è¦å°±è°ƒå¤§å“ªä¸ª&lt;/strong&gt;ï¼šåœ¨ä¹æ’åå°±è°ƒå¤§ rank_weightï¼Œåœ¨ä¹æŒç»­æ€§å°±è°ƒå¤§ frequency_weight&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å»ºè®®æ¯æ¬¡åªè°ƒ 0.1-0.2&lt;/strong&gt;ï¼Œè§‚å¯Ÿæ•ˆæœ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ ¸å¿ƒæ€è·¯ï¼šè¿½æ±‚é€Ÿåº¦å’Œæ—¶æ•ˆæ€§çš„ç”¨æˆ·æé«˜æ’åæƒé‡ï¼Œè¿½æ±‚æ·±åº¦å’Œç¨³å®šæ€§çš„ç”¨æˆ·æé«˜é¢‘æ¬¡æƒé‡ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. æ¨é€æ ¼å¼å‚è€ƒ&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;æ¨é€æ ¼å¼è¯´æ˜&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;h4&gt;æ¨é€ç¤ºä¾‹&lt;/h4&gt; 
 &lt;p&gt;ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡&lt;/p&gt; 
 &lt;p&gt;ğŸ”¥ [1/3] AI ChatGPT : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ç™¾åº¦çƒ­æœ] ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;] - 09æ—¶15åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[ä»Šæ—¥å¤´æ¡] AIèŠ¯ç‰‡æ¦‚å¿µè‚¡æš´æ¶¨ [&lt;strong&gt;3&lt;/strong&gt;] - [08æ—¶30åˆ† ~ 10æ—¶45åˆ†] (3æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“ˆ [2/3] æ¯”äºšè¿ª ç‰¹æ–¯æ‹‰ : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[å¾®åš] ğŸ†• æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;] - 10æ—¶20åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[æŠ–éŸ³] ç‰¹æ–¯æ‹‰é™ä»·ä¿ƒé”€ [&lt;strong&gt;4&lt;/strong&gt;] - [07æ—¶45åˆ† ~ 09æ—¶15åˆ†] (2æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“Œ [3/3] Aè‚¡ è‚¡å¸‚ : 1 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;[åå°”è¡—è§é—»] Aè‚¡åˆç›˜ç‚¹è¯„åˆ†æ [&lt;strong&gt;5&lt;/strong&gt;] - [11æ—¶30åˆ† ~ 12æ—¶00åˆ†] (2æ¬¡)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± 2 æ¡)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ç™¾åº¦çƒ­æœ&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;å¾®åš&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ›´æ–°æ—¶é—´ï¼š2025-01-15 12:30:15&lt;/p&gt; 
 &lt;h4&gt;æ¶ˆæ¯æ ¼å¼è¯´æ˜&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ ¼å¼å…ƒç´ &lt;/th&gt; 
    &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
    &lt;th&gt;å«ä¹‰&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ”¥ğŸ“ˆğŸ“Œ&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥ [1/3] AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;çƒ­åº¦ç­‰çº§&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥é«˜çƒ­åº¦(â‰¥10æ¡) ğŸ“ˆä¸­çƒ­åº¦(5-9æ¡) ğŸ“Œæ™®é€šçƒ­åº¦(&amp;lt;5æ¡)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[åºå·/æ€»æ•°]&lt;/td&gt; 
    &lt;td&gt;[1/3]&lt;/td&gt; 
    &lt;td&gt;æ’åºä½ç½®&lt;/td&gt; 
    &lt;td&gt;å½“å‰è¯ç»„åœ¨æ‰€æœ‰åŒ¹é…è¯ç»„ä¸­çš„æ’å&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;é¢‘ç‡è¯ç»„&lt;/td&gt; 
    &lt;td&gt;AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;å…³é”®è¯ç»„&lt;/td&gt; 
    &lt;td&gt;é…ç½®æ–‡ä»¶ä¸­çš„è¯ç»„ï¼Œæ ‡é¢˜å¿…é¡»åŒ…å«å…¶ä¸­è¯æ±‡&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;: N æ¡&lt;/td&gt; 
    &lt;td&gt;: 2 æ¡&lt;/td&gt; 
    &lt;td&gt;åŒ¹é…æ•°é‡&lt;/td&gt; 
    &lt;td&gt;è¯¥è¯ç»„åŒ¹é…çš„æ–°é—»æ€»æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[å¹³å°å]&lt;/td&gt; 
    &lt;td&gt;[ç™¾åº¦çƒ­æœ]&lt;/td&gt; 
    &lt;td&gt;æ¥æºå¹³å°&lt;/td&gt; 
    &lt;td&gt;æ–°é—»æ‰€å±çš„å¹³å°åç§°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ†•&lt;/td&gt; 
    &lt;td&gt;ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ&lt;/td&gt; 
    &lt;td&gt;æ–°å¢æ ‡è®°&lt;/td&gt; 
    &lt;td&gt;æœ¬è½®æŠ“å–ä¸­é¦–æ¬¡å‡ºç°çš„çƒ­ç‚¹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[&lt;strong&gt;æ•°å­—&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;[&lt;strong&gt;1&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;é«˜æ’å&lt;/td&gt; 
    &lt;td&gt;æ’åâ‰¤é˜ˆå€¼çš„çƒ­æœï¼Œçº¢è‰²åŠ ç²—æ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ•°å­—]&lt;/td&gt; 
    &lt;td&gt;[7]&lt;/td&gt; 
    &lt;td&gt;æ™®é€šæ’å&lt;/td&gt; 
    &lt;td&gt;æ’å&amp;gt;é˜ˆå€¼çš„çƒ­æœï¼Œæ™®é€šæ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;- æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;- 09æ—¶15åˆ†&lt;/td&gt; 
    &lt;td&gt;é¦–æ¬¡æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;è¯¥æ–°é—»é¦–æ¬¡è¢«å‘ç°çš„æ—¶é—´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ—¶é—´~æ—¶é—´]&lt;/td&gt; 
    &lt;td&gt;[08æ—¶30åˆ† ~ 10æ—¶45åˆ†]&lt;/td&gt; 
    &lt;td&gt;æŒç»­æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„æ—¶é—´èŒƒå›´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;(Næ¬¡)&lt;/td&gt; 
    &lt;td&gt;(3æ¬¡)&lt;/td&gt; 
    &lt;td&gt;å‡ºç°é¢‘ç‡&lt;/td&gt; 
    &lt;td&gt;åœ¨ç›‘æ§æœŸé—´å‡ºç°çš„æ€»æ¬¡æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ–°å¢åŒºåŸŸ&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ†• &lt;strong&gt;æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;æ–°è¯é¢˜æ±‡æ€»&lt;/td&gt; 
    &lt;td&gt;å•ç‹¬å±•ç¤ºæœ¬è½®æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;6. Docker éƒ¨ç½²&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;Docker éƒ¨ç½²å®Œæ•´æŒ‡å—&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é•œåƒè¯´æ˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TrendRadar æä¾›ä¸¤ä¸ªç‹¬ç«‹çš„ Docker é•œåƒï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©éƒ¨ç½²ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é•œåƒåç§°&lt;/th&gt; 
    &lt;th&gt;ç”¨é€”&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;wantcat/trendradar&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ–°é—»æ¨é€æœåŠ¡&lt;/td&gt; 
    &lt;td&gt;å®šæ—¶æŠ“å–æ–°é—»ã€æ¨é€é€šçŸ¥ï¼ˆå¿…é€‰ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;wantcat/trendradar-mcp&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;AI åˆ†ææœåŠ¡&lt;/td&gt; 
    &lt;td&gt;MCP åè®®æ”¯æŒã€AI å¯¹è¯åˆ†æï¼ˆå¯é€‰ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;å»ºè®®&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;åªéœ€è¦æ¨é€åŠŸèƒ½ï¼šä»…éƒ¨ç½² &lt;code&gt;wantcat/trendradar&lt;/code&gt; é•œåƒ&lt;/li&gt; 
   &lt;li&gt;éœ€è¦ AI åˆ†æåŠŸèƒ½ï¼šåŒæ—¶éƒ¨ç½²ä¸¤ä¸ªé•œåƒ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;æ–¹å¼ä¸€ï¼šä½¿ç”¨ docker composeï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºé¡¹ç›®ç›®å½•å’Œé…ç½®&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;æ–¹å¼ 1-Aï¼šä½¿ç”¨ git cloneï¼ˆæ¨èï¼Œæœ€ç®€å•ï¼‰&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# å…‹éš†é¡¹ç›®åˆ°æœ¬åœ°
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;æ–¹å¼ 1-Bï¼šä½¿ç”¨ wget ä¸‹è½½é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p trendradar/{config,docker}
cd trendradar

# ä¸‹è½½é…ç½®æ–‡ä»¶æ¨¡æ¿
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/

# ä¸‹è½½ docker compose é…ç½®
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/.env  -P docker/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/docker-compose.yml  -P docker/
&lt;/code&gt;&lt;/pre&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;ğŸ’¡ &lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼šDocker éƒ¨ç½²éœ€è¦çš„å…³é”®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š&lt;/p&gt; 
   &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;å½“å‰ç›®å½•/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ frequency_words.txt
â””â”€â”€ docker/
    â”œâ”€â”€ .env
    â””â”€â”€ docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - åº”ç”¨ä¸»é…ç½®ï¼ˆæŠ¥å‘Šæ¨¡å¼ã€æ¨é€è®¾ç½®ç­‰ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆè®¾ç½®ä½ å…³å¿ƒçš„çƒ­ç‚¹è¯æ±‡ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - ç¯å¢ƒå˜é‡é…ç½®ï¼ˆwebhook URLs å’Œå®šæ—¶ä»»åŠ¡ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;âš™ï¸ ç¯å¢ƒå˜é‡è¦†ç›–æœºåˆ¶ï¼ˆv3.0.5+ï¼‰&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;å¦‚æœä½ åœ¨ NAS æˆ–å…¶ä»– Docker ç¯å¢ƒä¸­é‡åˆ°&lt;strong&gt;ä¿®æ”¹ &lt;code&gt;config.yaml&lt;/code&gt; åé…ç½®ä¸ç”Ÿæ•ˆ&lt;/strong&gt;çš„é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ç›´æ¥è¦†ç›–é…ç½®ï¼š&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;ç¯å¢ƒå˜é‡&lt;/th&gt; 
      &lt;th&gt;å¯¹åº”é…ç½®&lt;/th&gt; 
      &lt;th&gt;ç¤ºä¾‹å€¼&lt;/th&gt; 
      &lt;th&gt;è¯´æ˜&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;ENABLE_CRAWLER&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;crawler.enable_crawler&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ˜¯å¦å¯ç”¨çˆ¬è™«&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;ENABLE_NOTIFICATION&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.enable_notification&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ˜¯å¦å¯ç”¨é€šçŸ¥&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;REPORT_MODE&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;report.mode&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;daily&lt;/code&gt; / &lt;code&gt;incremental&lt;/code&gt; / &lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æŠ¥å‘Šæ¨¡å¼&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;MAX_ACCOUNTS_PER_CHANNEL&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.max_accounts_per_channel&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ¯ä¸ªæ¸ é“æœ€å¤§è´¦å·æ•°&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;PUSH_WINDOW_ENABLED&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.push_window.enabled&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ¨é€æ—¶é—´çª—å£å¼€å…³&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;PUSH_WINDOW_START&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.push_window.time_range.start&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;08:00&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ¨é€å¼€å§‹æ—¶é—´&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;PUSH_WINDOW_END&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.push_window.time_range.end&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;22:00&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ¨é€ç»“æŸæ—¶é—´&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;ENABLE_WEBSERVER&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;-&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;æ˜¯å¦è‡ªåŠ¨å¯åŠ¨ Web æœåŠ¡å™¨&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;WEBSERVER_PORT&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;-&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;8080&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;Web æœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤ 8080ï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;notification.webhooks.feishu_url&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;&lt;code&gt;https://...&lt;/code&gt;&lt;/td&gt; 
      &lt;td&gt;é£ä¹¦ Webhookï¼ˆæ”¯æŒå¤šè´¦å·ï¼Œç”¨ &lt;code&gt;;&lt;/code&gt; åˆ†éš”ï¼‰&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; &lt;p&gt;&lt;strong&gt;é…ç½®ä¼˜å…ˆçº§&lt;/strong&gt;ï¼šç¯å¢ƒå˜é‡ &amp;gt; config.yaml&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ–¹æ³•&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®æ”¹ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶å¡«å†™éœ€è¦çš„é…ç½®&lt;/li&gt; 
    &lt;li&gt;æˆ–åœ¨ NAS/ç¾¤æ™– Docker ç®¡ç†ç•Œé¢çš„"ç¯å¢ƒå˜é‡"ä¸­ç›´æ¥æ·»åŠ &lt;/li&gt; 
    &lt;li&gt;é‡å¯å®¹å™¨åç”Ÿæ•ˆï¼š&lt;code&gt;docker compose up -d&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨æœåŠ¡&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;é€‰é¡¹ Aï¼šå¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆæ¨é€ + AI åˆ†æï¼‰&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æ‹‰å–æœ€æ–°é•œåƒ
docker compose pull

# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆtrend-radar + trend-radar-mcpï¼‰
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;é€‰é¡¹ Bï¼šä»…å¯åŠ¨æ–°é—»æ¨é€æœåŠ¡&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# åªå¯åŠ¨ trend-radarï¼ˆå®šæ—¶æŠ“å–å’Œæ¨é€ï¼‰
docker compose pull trend-radar
docker compose up -d trend-radar
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;é€‰é¡¹ Cï¼šä»…å¯åŠ¨ MCP AI åˆ†ææœåŠ¡&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# åªå¯åŠ¨ trend-radar-mcpï¼ˆæä¾› AI åˆ†ææ¥å£ï¼‰
docker compose pull trend-radar-mcp
docker compose up -d trend-radar-mcp
&lt;/code&gt;&lt;/pre&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;ğŸ’¡ &lt;strong&gt;æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;å¤§å¤šæ•°ç”¨æˆ·åªéœ€å¯åŠ¨ &lt;code&gt;trend-radar&lt;/code&gt; å³å¯å®ç°æ–°é—»æ¨é€åŠŸèƒ½&lt;/li&gt; 
     &lt;li&gt;åªæœ‰éœ€è¦ä½¿ç”¨ Claude/ChatGPT è¿›è¡Œ AI å¯¹è¯åˆ†ææ—¶ï¼Œæ‰éœ€å¯åŠ¨ &lt;code&gt;trend-radar-mcp&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;ä¸¤ä¸ªæœåŠ¡ç›¸äº’ç‹¬ç«‹ï¼Œå¯æ ¹æ®éœ€æ±‚çµæ´»ç»„åˆ&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/blockquote&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŸ¥çœ‹è¿è¡ŒçŠ¶æ€&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹æ–°é—»æ¨é€æœåŠ¡æ—¥å¿—
docker logs -f trend-radar

# æŸ¥çœ‹ MCP AI åˆ†ææœåŠ¡æ—¥å¿—
docker logs -f trend-radar-mcp

# æŸ¥çœ‹æ‰€æœ‰å®¹å™¨çŠ¶æ€
docker ps | grep trend-radar

# åœæ­¢ç‰¹å®šæœåŠ¡
docker compose stop trend-radar      # åœæ­¢æ¨é€æœåŠ¡
docker compose stop trend-radar-mcp  # åœæ­¢ MCP æœåŠ¡
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;æ–¹å¼äºŒï¼šæœ¬åœ°æ„å»ºï¼ˆå¼€å‘è€…é€‰é¡¹ï¼‰&lt;/h4&gt; 
 &lt;p&gt;å¦‚æœéœ€è¦è‡ªå®šä¹‰ä¿®æ”¹ä»£ç æˆ–æ„å»ºè‡ªå·±çš„é•œåƒï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# å…‹éš†é¡¹ç›®
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar

# ä¿®æ”¹é…ç½®æ–‡ä»¶
vim config/config.yaml
vim config/frequency_words.txt

# ä½¿ç”¨æ„å»ºç‰ˆæœ¬çš„ docker compose
cd docker
cp docker-compose-build.yml docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ„å»ºå¹¶å¯åŠ¨æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# é€‰é¡¹ Aï¼šæ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose build
docker compose up -d

# é€‰é¡¹ Bï¼šä»…æ„å»ºå¹¶å¯åŠ¨æ–°é—»æ¨é€æœåŠ¡
docker compose build trend-radar
docker compose up -d trend-radar

# é€‰é¡¹ Cï¼šä»…æ„å»ºå¹¶å¯åŠ¨ MCP AI åˆ†ææœåŠ¡
docker compose build trend-radar-mcp
docker compose up -d trend-radar-mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;æ¶æ„å‚æ•°è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é»˜è®¤æ„å»º &lt;code&gt;amd64&lt;/code&gt; æ¶æ„é•œåƒï¼ˆé€‚ç”¨äºå¤§å¤šæ•° x86_64 æœåŠ¡å™¨ï¼‰&lt;/li&gt; 
   &lt;li&gt;å¦‚éœ€æ„å»º &lt;code&gt;arm64&lt;/code&gt; æ¶æ„ï¼ˆApple Siliconã€æ ‘è“æ´¾ç­‰ï¼‰ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼š &lt;pre&gt;&lt;code class="language-bash"&gt;export DOCKER_ARCH=arm64
docker compose build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;é•œåƒæ›´æ–°&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æ–¹å¼ä¸€ï¼šæ‰‹åŠ¨æ›´æ–°ï¼ˆçˆ¬è™« + MCP é•œåƒï¼‰
docker pull wantcat/trendradar:latest
docker pull wantcat/trendradar-mcp:latest
docker compose down
docker compose up -d

# æ–¹å¼äºŒï¼šä½¿ç”¨ docker compose æ›´æ–°
docker compose pull
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;å¯ç”¨é•œåƒ&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é•œåƒåç§°&lt;/th&gt; 
    &lt;th&gt;ç”¨é€”&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;wantcat/trendradar&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ–°é—»æ¨é€æœåŠ¡&lt;/td&gt; 
    &lt;td&gt;å®šæ—¶æŠ“å–æ–°é—»ã€æ¨é€é€šçŸ¥&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;wantcat/trendradar-mcp&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;MCP æœåŠ¡&lt;/td&gt; 
    &lt;td&gt;AI åˆ†æåŠŸèƒ½ï¼ˆå¯é€‰ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;æœåŠ¡ç®¡ç†å‘½ä»¤&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
docker exec -it trend-radar python manage.py status

# æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡çˆ¬è™«
docker exec -it trend-radar python manage.py run

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker exec -it trend-radar python manage.py logs

# æ˜¾ç¤ºå½“å‰é…ç½®
docker exec -it trend-radar python manage.py config

# æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
docker exec -it trend-radar python manage.py files

# Web æœåŠ¡å™¨ç®¡ç†ï¼ˆç”¨äºæµè§ˆå™¨è®¿é—®ç”Ÿæˆçš„æŠ¥å‘Šï¼‰
docker exec -it trend-radar python manage.py start_webserver   # å¯åŠ¨ Web æœåŠ¡å™¨
docker exec -it trend-radar python manage.py stop_webserver    # åœæ­¢ Web æœåŠ¡å™¨
docker exec -it trend-radar python manage.py webserver_status  # æŸ¥çœ‹ Web æœåŠ¡å™¨çŠ¶æ€

# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
docker exec -it trend-radar python manage.py help

# é‡å¯å®¹å™¨
docker restart trend-radar

# åœæ­¢å®¹å™¨
docker stop trend-radar

# åˆ é™¤å®¹å™¨ï¼ˆä¿ç•™æ•°æ®ï¼‰
docker rm trend-radar
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;Web æœåŠ¡å™¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;å¯åŠ¨åå¯é€šè¿‡æµè§ˆå™¨è®¿é—® &lt;code&gt;http://localhost:8080&lt;/code&gt; æŸ¥çœ‹æœ€æ–°æŠ¥å‘Š&lt;/li&gt; 
   &lt;li&gt;é€šè¿‡ç›®å½•å¯¼èˆªè®¿é—®å†å²æŠ¥å‘Šï¼ˆå¦‚ï¼š&lt;code&gt;http://localhost:8080/2025-xx-xx/&lt;/code&gt;ï¼‰&lt;/li&gt; 
   &lt;li&gt;ç«¯å£å¯åœ¨ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ä¸­é…ç½® &lt;code&gt;WEBSERVER_PORT&lt;/code&gt; å‚æ•°&lt;/li&gt; 
   &lt;li&gt;è‡ªåŠ¨å¯åŠ¨ï¼šåœ¨ &lt;code&gt;.env&lt;/code&gt; ä¸­è®¾ç½® &lt;code&gt;ENABLE_WEBSERVER=true&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;å®‰å…¨æç¤ºï¼šä»…æä¾›é™æ€æ–‡ä»¶è®¿é—®ï¼Œé™åˆ¶åœ¨ output ç›®å½•ï¼Œåªç»‘å®šæœ¬åœ°è®¿é—®&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;æ•°æ®æŒä¹…åŒ–&lt;/h4&gt; 
 &lt;p&gt;ç”Ÿæˆçš„æŠ¥å‘Šå’Œæ•°æ®é»˜è®¤ä¿å­˜åœ¨ &lt;code&gt;./output&lt;/code&gt; ç›®å½•ä¸‹ï¼Œå³ä½¿å®¹å™¨é‡å¯æˆ–åˆ é™¤ï¼Œæ•°æ®ä¹Ÿä¼šä¿ç•™ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“Š ç½‘é¡µç‰ˆæŠ¥å‘Šè®¿é—®è·¯å¾„&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;p&gt;TrendRadar ç”Ÿæˆçš„å½“æ—¥æ±‡æ€» HTML æŠ¥å‘Šä¼šåŒæ—¶ä¿å­˜åˆ°ä¸¤ä¸ªä½ç½®ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ–‡ä»¶ä½ç½®&lt;/th&gt; 
    &lt;th&gt;è®¿é—®æ–¹å¼&lt;/th&gt; 
    &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;output/index.html&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å®¿ä¸»æœºç›´æ¥è®¿é—®&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;Docker éƒ¨ç½²&lt;/strong&gt;ï¼ˆé€šè¿‡ Volume æŒ‚è½½ï¼Œå®¿ä¸»æœºå¯è§ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;index.html&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ ¹ç›®å½•è®¿é—®&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;ï¼ˆä»“åº“æ ¹ç›®å½•ï¼ŒPages è‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;output/YYYY-MM-DD/html/å½“æ—¥æ±‡æ€».html&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å†å²æŠ¥å‘Šè®¿é—®&lt;/td&gt; 
    &lt;td&gt;æ‰€æœ‰ç¯å¢ƒï¼ˆæŒ‰æ—¥æœŸå½’æ¡£ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;æœ¬åœ°è®¿é—®ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æ–¹å¼ 1ï¼šé€šè¿‡ Web æœåŠ¡å™¨è®¿é—®ï¼ˆæ¨èï¼ŒDocker ç¯å¢ƒï¼‰
# 1. å¯åŠ¨ Web æœåŠ¡å™¨
docker exec -it trend-radar python manage.py start_webserver
# 2. åœ¨æµè§ˆå™¨è®¿é—®
http://localhost:8080                           # è®¿é—®æœ€æ–°æŠ¥å‘Šï¼ˆé»˜è®¤ index.htmlï¼‰
http://localhost:8080/2025-xx-xx/               # è®¿é—®æŒ‡å®šæ—¥æœŸçš„æŠ¥å‘Š
http://localhost:8080/2025-xx-xx/html/          # æµè§ˆè¯¥æ—¥æœŸä¸‹çš„æ‰€æœ‰ HTML æ–‡ä»¶

# æ–¹å¼ 2ï¼šç›´æ¥æ‰“å¼€æ–‡ä»¶ï¼ˆæœ¬åœ°ç¯å¢ƒï¼‰
open ./output/index.html             # macOS
start ./output/index.html            # Windows
xdg-open ./output/index.html         # Linux

# æ–¹å¼ 3ï¼šè®¿é—®å†å²å½’æ¡£
open ./output/2025-xx-xx/html/å½“æ—¥æ±‡æ€».html
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä¸ºä»€ä¹ˆæœ‰ä¸¤ä¸ª index.htmlï¼Ÿ&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;output/index.html&lt;/code&gt;ï¼šDocker Volume æŒ‚è½½åˆ°å®¿ä¸»æœºï¼Œæœ¬åœ°å¯ç›´æ¥æ‰“å¼€&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;index.html&lt;/code&gt;ï¼šGitHub Actions æ¨é€åˆ°ä»“åº“ï¼ŒGitHub Pages è‡ªåŠ¨éƒ¨ç½²&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šä¸¤ä¸ªæ–‡ä»¶å†…å®¹å®Œå…¨ç›¸åŒï¼Œé€‰æ‹©ä»»æ„ä¸€ä¸ªè®¿é—®å³å¯ã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;æ•…éšœæ’æŸ¥&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker inspect trend-radar

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs --tail 100 trend-radar

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker exec -it trend-radar /bin/bash

# éªŒè¯é…ç½®æ–‡ä»¶
docker exec -it trend-radar ls -la /app/config/
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;MCP æœåŠ¡éƒ¨ç½²ï¼ˆAI åˆ†æåŠŸèƒ½ï¼‰&lt;/h4&gt; 
 &lt;p&gt;å¦‚æœéœ€è¦ä½¿ç”¨ AI åˆ†æåŠŸèƒ½ï¼Œå¯ä»¥éƒ¨ç½²ç‹¬ç«‹çš„ MCP æœåŠ¡å®¹å™¨ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;æ¶æ„è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    subgraph trend-radar["trend-radar"]
        A1[å®šæ—¶æŠ“å–æ–°é—»]
        A2[æ¨é€é€šçŸ¥]
    end
    
    subgraph trend-radar-mcp["trend-radar-mcp"]
        B1[127.0.0.1:3333]
        B2[AI åˆ†ææ¥å£]
    end
    
    subgraph shared["å…±äº«å·"]
        C1["config/ (ro)"]
        C2["output/ (ro)"]
    end
    
    trend-radar --&amp;gt; shared
    trend-radar-mcp --&amp;gt; shared
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;å¿«é€Ÿå¯åŠ¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;p&gt;å¦‚æœå·²æŒ‰ç…§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E6%96%B9%E5%BC%8F%E4%B8%80%E4%BD%BF%E7%94%A8-docker-compose%E6%8E%A8%E8%8D%90"&gt;æ–¹å¼ä¸€ï¼šä½¿ç”¨ docker compose&lt;/a&gt; å®Œæˆéƒ¨ç½²ï¼Œåªéœ€å¯åŠ¨ MCP æœåŠ¡ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd TrendRadar/docker
docker compose up -d trend-radar-mcp

# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
docker ps | grep trend-radar-mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;å•ç‹¬å¯åŠ¨ MCP æœåŠ¡&lt;/strong&gt;ï¼ˆä¸ä½¿ç”¨ docker composeï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Linux/Mac
docker run -d --name trend-radar-mcp \
  -p 127.0.0.1:3333:3333 \
  -v $(pwd)/config:/app/config:ro \
  -v $(pwd)/output:/app/output:ro \
  -e TZ=Asia/Shanghai \
  wantcat/trendradar-mcp:latest

# Windows PowerShell
docker run -d --name trend-radar-mcp `
  -p 127.0.0.1:3333:3333 `
  -v ${PWD}/config:/app/config:ro `
  -v ${PWD}/output:/app/output:ro `
  -e TZ=Asia/Shanghai `
  wantcat/trendradar-mcp:latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;âš ï¸ &lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šå•ç‹¬è¿è¡Œæ—¶ï¼Œç¡®ä¿å½“å‰ç›®å½•ä¸‹æœ‰ &lt;code&gt;config/&lt;/code&gt; å’Œ &lt;code&gt;output/&lt;/code&gt; æ–‡ä»¶å¤¹ï¼Œä¸”åŒ…å«é…ç½®æ–‡ä»¶å’Œæ–°é—»æ•°æ®ã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;éªŒè¯æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æ£€æŸ¥ MCP æœåŠ¡å¥åº·çŠ¶æ€
curl http://127.0.0.1:3333/mcp

# æŸ¥çœ‹ MCP æœåŠ¡æ—¥å¿—
docker logs -f trend-radar-mcp
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;åœ¨ AI å®¢æˆ·ç«¯ä¸­é…ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;p&gt;MCP æœåŠ¡å¯åŠ¨åï¼Œæ ¹æ®ä¸åŒå®¢æˆ·ç«¯è¿›è¡Œé…ç½®ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Cherry Studio&lt;/strong&gt;ï¼ˆæ¨èï¼ŒGUI é…ç½®ï¼‰ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è®¾ç½® â†’ MCP æœåŠ¡å™¨ â†’ æ·»åŠ &lt;/li&gt; 
  &lt;li&gt;ç±»å‹ï¼š&lt;code&gt;streamableHttp&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;URLï¼š&lt;code&gt;http://127.0.0.1:3333/mcp&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Claude Desktop / Cline&lt;/strong&gt;ï¼ˆJSON é…ç½®ï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://127.0.0.1:3333/mcp",
      "type": "streamableHttp"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šMCP æœåŠ¡ä»…ç›‘å¬æœ¬åœ°ç«¯å£ï¼ˆ127.0.0.1ï¼‰ï¼Œç¡®ä¿å®‰å…¨æ€§ã€‚å¦‚éœ€è¿œç¨‹è®¿é—®ï¼Œè¯·è‡ªè¡Œé…ç½®åå‘ä»£ç†å’Œè®¤è¯ã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;h3&gt;7. æŠ¥å‘Šé…ç½®&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;æŠ¥å‘Šç›¸å…³å‚æ•°é…ç½®&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;report&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;report:
  mode: "daily"                    # æ¨é€æ¨¡å¼
  rank_threshold: 5                # æ’åé«˜äº®é˜ˆå€¼
  sort_by_position_first: false    # æ’åºä¼˜å…ˆçº§
  max_news_per_keyword: 0          # æ¯ä¸ªå…³é”®è¯æœ€å¤§æ˜¾ç¤ºæ•°é‡
  reverse_content_order: false     # å†…å®¹é¡ºåºé…ç½®
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;é…ç½®é¡¹è¯¦è§£&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é…ç½®é¡¹&lt;/th&gt; 
    &lt;th&gt;ç±»å‹&lt;/th&gt; 
    &lt;th&gt;é»˜è®¤å€¼&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;mode&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¨é€æ¨¡å¼ï¼Œå¯é€‰ &lt;code&gt;daily&lt;/code&gt;/&lt;code&gt;incremental&lt;/code&gt;/&lt;code&gt;current&lt;/code&gt;ï¼Œè¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#3-%E6%8E%A8%E9%80%81%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3"&gt;æ¨é€æ¨¡å¼è¯¦è§£&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;rank_threshold&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ’åé«˜äº®é˜ˆå€¼ï¼Œæ’å â‰¤ è¯¥å€¼çš„æ–°é—»ä¼šåŠ ç²—æ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;sort_by_position_first&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ’åºä¼˜å…ˆçº§ï¼š&lt;code&gt;false&lt;/code&gt;=æŒ‰çƒ­ç‚¹æ¡æ•°æ’åºï¼Œ&lt;code&gt;true&lt;/code&gt;=æŒ‰é…ç½®ä½ç½®æ’åº&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;max_news_per_keyword&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;int&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¯ä¸ªå…³é”®è¯æœ€å¤§æ˜¾ç¤ºæ•°é‡ï¼Œ&lt;code&gt;0&lt;/code&gt;=ä¸é™åˆ¶&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;reverse_content_order&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å†…å®¹é¡ºåºï¼š&lt;code&gt;false&lt;/code&gt;=çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡åœ¨å‰ï¼Œ&lt;code&gt;true&lt;/code&gt;=æ–°å¢çƒ­ç‚¹æ–°é—»åœ¨å‰&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;å†…å®¹é¡ºåºé…ç½®ï¼ˆv3.5.0 æ–°å¢ï¼‰&lt;/h4&gt; 
 &lt;p&gt;æ§åˆ¶æ¨é€æ¶ˆæ¯å’Œ HTML æŠ¥å‘Šä¸­ä¸¤éƒ¨åˆ†å†…å®¹çš„æ˜¾ç¤ºé¡ºåºï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é…ç½®å€¼&lt;/th&gt; 
    &lt;th&gt;æ˜¾ç¤ºé¡ºåº&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;ï¼ˆé»˜è®¤ï¼‰&lt;/td&gt; 
    &lt;td&gt;â‘  çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡ â†’ â‘¡ æ–°å¢çƒ­ç‚¹æ–°é—»&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;â‘  æ–°å¢çƒ­ç‚¹æ–°é—» â†’ â‘¡ çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨åœºæ™¯ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;false&lt;/code&gt;ï¼ˆé»˜è®¤ï¼‰ï¼šé€‚åˆå…³æ³¨å…³é”®è¯åŒ¹é…ç»“æœçš„ç”¨æˆ·ï¼Œå…ˆçœ‹åˆ†ç±»ç»Ÿè®¡&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;true&lt;/code&gt;ï¼šé€‚åˆå…³æ³¨æœ€æ–°åŠ¨æ€çš„ç”¨æˆ·ï¼Œä¼˜å…ˆæŸ¥çœ‹æ–°å¢çƒ­ç‚¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Docker ç¯å¢ƒå˜é‡ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;REVERSE_CONTENT_ORDER=true
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;æ’åºä¼˜å…ˆçº§é…ç½®&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ç¤ºä¾‹åœºæ™¯ï¼š&lt;/strong&gt; é…ç½®é¡ºåº Aã€Bã€Cï¼Œçƒ­ç‚¹æ•° A(3æ¡)ã€B(10æ¡)ã€C(5æ¡)&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é…ç½®å€¼&lt;/th&gt; 
    &lt;th&gt;æ˜¾ç¤ºé¡ºåº&lt;/th&gt; 
    &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;ï¼ˆé»˜è®¤ï¼‰&lt;/td&gt; 
    &lt;td&gt;B(10æ¡) â†’ C(5æ¡) â†’ A(3æ¡)&lt;/td&gt; 
    &lt;td&gt;å…³æ³¨çƒ­åº¦è¶‹åŠ¿&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;A(3æ¡) â†’ B(10æ¡) â†’ C(5æ¡)&lt;/td&gt; 
    &lt;td&gt;å…³æ³¨ä¸ªäººä¼˜å…ˆçº§&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Docker ç¯å¢ƒå˜é‡ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;SORT_BY_POSITION_FIRST=true
MAX_NEWS_PER_KEYWORD=10
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;8. æ¨é€æ—¶é—´çª—å£é…ç½®&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;æ¨é€æ—¶é—´çª—å£æ§åˆ¶è¯¦è§£&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;notification.push_window&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;notification:
  push_window:
    enabled: false                    # æ˜¯å¦å¯ç”¨
    time_range:
      start: "20:00"                  # å¼€å§‹æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
      end: "22:00"                    # ç»“æŸæ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
    once_per_day: true                # æ¯å¤©åªæ¨é€ä¸€æ¬¡
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;é…ç½®é¡¹è¯¦è§£&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;é…ç½®é¡¹&lt;/th&gt; 
    &lt;th&gt;ç±»å‹&lt;/th&gt; 
    &lt;th&gt;é»˜è®¤å€¼&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;enabled&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ˜¯å¦å¯ç”¨æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;time_range.start&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"20:00"&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¨é€æ—¶é—´çª—å£å¼€å§‹æ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼ŒHH:MM æ ¼å¼ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;time_range.end&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;string&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"22:00"&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¨é€æ—¶é—´çª—å£ç»“æŸæ—¶é—´ï¼ˆåŒ—äº¬æ—¶é—´ï¼ŒHH:MM æ ¼å¼ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;once_per_day&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;bool&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;=æ¯å¤©åœ¨çª—å£å†…åªæ¨é€ä¸€æ¬¡ï¼Œ&lt;code&gt;false&lt;/code&gt;=çª—å£å†…æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;ä½¿ç”¨åœºæ™¯&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;åœºæ™¯&lt;/th&gt; 
    &lt;th&gt;é…ç½®ç¤ºä¾‹&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å·¥ä½œæ—¶é—´æ¨é€&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;start: "09:00"&lt;/code&gt;, &lt;code&gt;end: "18:00"&lt;/code&gt;, &lt;code&gt;once_per_day: false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ™šé—´æ±‡æ€»æ¨é€&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;start: "20:00"&lt;/code&gt;, &lt;code&gt;end: "22:00"&lt;/code&gt;, &lt;code&gt;once_per_day: true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;åˆä¼‘æ—¶é—´æ¨é€&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;start: "12:00"&lt;/code&gt;, &lt;code&gt;end: "13:00"&lt;/code&gt;, &lt;code&gt;once_per_day: true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;é‡è¦æç¤º&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;âš ï¸ &lt;strong&gt;GitHub Actions ç”¨æˆ·æ³¨æ„ï¼š&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;GitHub Actions æ‰§è¡Œæ—¶é—´ä¸ç¨³å®šï¼Œå¯èƒ½æœ‰ Â±15 åˆ†é’Ÿçš„åå·®&lt;/li&gt; 
   &lt;li&gt;æ—¶é—´èŒƒå›´å»ºè®®è‡³å°‘ç•™è¶³ &lt;strong&gt;2 å°æ—¶&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;å¦‚æœæƒ³è¦ç²¾å‡†çš„å®šæ—¶æ¨é€ï¼Œå»ºè®®ä½¿ç”¨ &lt;strong&gt;Docker éƒ¨ç½²&lt;/strong&gt;åœ¨ä¸ªäººæœåŠ¡å™¨ä¸Š&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;Docker ç¯å¢ƒå˜é‡&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;PUSH_WINDOW_ENABLED=true
PUSH_WINDOW_START=09:00
PUSH_WINDOW_END=18:00
PUSH_WINDOW_ONCE_PER_DAY=false
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;å®Œæ•´é…ç½®ç¤ºä¾‹&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;åœºæ™¯ï¼šæ¯å¤©æ™šä¸Š 8-10 ç‚¹åªæ¨é€ä¸€æ¬¡æ±‡æ€»&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;notification:
  push_window:
    enabled: true
    time_range:
      start: "20:00"
      end: "22:00"
    once_per_day: true
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;åœºæ™¯ï¼šå·¥ä½œæ—¶é—´å†…æ¯å°æ—¶æ¨é€&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;notification:
  push_window:
    enabled: true
    time_range:
      start: "09:00"
      end: "18:00"
    once_per_day: false
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;9. æ‰§è¡Œé¢‘ç‡é…ç½®&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;è‡ªåŠ¨è¿è¡Œé¢‘ç‡è®¾ç½®&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®ï¼š&lt;/strong&gt; &lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt; çš„ &lt;code&gt;schedule&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;on:
  schedule:
    - cron: "0 * * * *"  # æ¯å°æ—¶è¿è¡Œä¸€æ¬¡
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ä»€ä¹ˆæ˜¯ Cron è¡¨è¾¾å¼ï¼Ÿ&lt;/h4&gt; 
 &lt;p&gt;Cron æ˜¯ä¸€ç§å®šæ—¶ä»»åŠ¡æ ¼å¼ï¼Œç”± 5 ä¸ªéƒ¨åˆ†ç»„æˆï¼š&lt;code&gt;åˆ† æ—¶ æ—¥ æœˆ å‘¨&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆ†é’Ÿ (0-59)
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å°æ—¶ (0-23)
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ—¥æœŸ (1-31)
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æœˆä»½ (1-12)
â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ˜ŸæœŸ (0-6ï¼Œ0=å‘¨æ—¥)
â”‚ â”‚ â”‚ â”‚ â”‚
* * * * *
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;å¸¸ç”¨é…ç½®ç¤ºä¾‹&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æƒ³è¦çš„æ•ˆæœ&lt;/th&gt; 
    &lt;th&gt;Cron è¡¨è¾¾å¼&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;æ¯å°æ—¶è¿è¡Œ&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0 * * * *&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¯å°æ—¶çš„ç¬¬ 0 åˆ†é’Ÿè¿è¡Œï¼ˆé»˜è®¤ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;æ¯ 30 åˆ†é’Ÿè¿è¡Œ&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;*/30 * * * *&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ¯éš” 30 åˆ†é’Ÿè¿è¡Œä¸€æ¬¡&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;æ¯å¤©æ—© 8 ç‚¹è¿è¡Œ&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0 0 * * *&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;UTC 0:00 = åŒ—äº¬æ—¶é—´ 8:00&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;å·¥ä½œæ—¶é—´è¿è¡Œ&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;*/30 0-14 * * *&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ—äº¬ 8:00-22:00ï¼Œæ¯ 30 åˆ†é’Ÿ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;æ¯å¤© 3 æ¬¡&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0 0,6,12 * * *&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ—äº¬ 8:00ã€14:00ã€20:00&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;é‡è¦æç¤º&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;âš ï¸ &lt;strong&gt;æ—¶åŒºæ³¨æ„&lt;/strong&gt;ï¼šGitHub Actions ä½¿ç”¨ &lt;strong&gt;UTC æ—¶é—´&lt;/strong&gt;ï¼ŒåŒ—äº¬æ—¶é—´éœ€è¦ &lt;strong&gt;å‡ 8 å°æ—¶&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æƒ³è¦åŒ—äº¬æ—¶é—´ 8:00 è¿è¡Œ â†’ è®¾ç½® UTC 0:00&lt;/li&gt; 
   &lt;li&gt;æƒ³è¦åŒ—äº¬æ—¶é—´ 20:00 è¿è¡Œ â†’ è®¾ç½® UTC 12:00&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;âš ï¸ &lt;strong&gt;é¢‘ç‡é™åˆ¶&lt;/strong&gt;ï¼šGitHub å¯¹æ¯ä¸ªè´¦å·çš„ Actions è¿è¡Œæ¬¡æ•°æœ‰é™é¢&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;å»ºè®®&lt;/strong&gt;ï¼šä¸è¦è®¾ç½®æ¯” 30 åˆ†é’Ÿæ›´çŸ­çš„é—´éš”&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;åŸå› &lt;/strong&gt;ï¼šè¿‡äºé¢‘ç¹å¯èƒ½è¢«åˆ¤å®šä¸ºæ»¥ç”¨ï¼Œé¢ä¸´å°å·é£é™©&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;å®é™…æƒ…å†µ&lt;/strong&gt;ï¼šGitHub Actions æ‰§è¡Œæ—¶é—´æœ¬èº«å°±æœ‰åå·®ï¼Œè®¾ç½®å¤ªç²¾ç¡®æ„ä¹‰ä¸å¤§&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;ä¿®æ”¹æ–¹æ³•&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ‰“å¼€ä½  fork çš„ä»“åº“&lt;/li&gt; 
  &lt;li&gt;æ‰¾åˆ° &lt;code&gt;.github/workflows/crawler.yml&lt;/code&gt; æ–‡ä»¶&lt;/li&gt; 
  &lt;li&gt;ç‚¹å‡»ç¼–è¾‘ï¼ˆé“…ç¬”å›¾æ ‡ï¼‰&lt;/li&gt; 
  &lt;li&gt;ä¿®æ”¹ &lt;code&gt;cron: "0 * * * *"&lt;/code&gt; ä¸­çš„è¡¨è¾¾å¼&lt;/li&gt; 
  &lt;li&gt;ç‚¹å‡» "Commit changes" ä¿å­˜&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;10. å¤šè´¦å·æ¨é€é…ç½®&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;å¤šè´¦å·æ¨é€é…ç½®è¯¦è§£&lt;/strong&gt;&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;h3&gt;âš ï¸ &lt;strong&gt;å®‰å…¨è­¦å‘Š&lt;/strong&gt;&lt;/h3&gt; 
  &lt;p&gt;&lt;strong&gt;GitHub Fork ç”¨æˆ·è¯·å‹¿åœ¨ &lt;code&gt;config.yaml&lt;/code&gt; ä¸­é…ç½®æ¨é€ä¿¡æ¯ï¼&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;é£é™©è¯´æ˜&lt;/strong&gt;ï¼š&lt;code&gt;config.yaml&lt;/code&gt; ä¼šè¢«æäº¤åˆ°å…¬å¼€çš„ Git ä»“åº“ï¼Œé…ç½®æ¨é€ä¿¡æ¯ï¼ˆWebhook URLã€Token ç­‰ï¼‰ä¼šæ³„éœ²æ•æ„Ÿæ•°æ®&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;æ¨èæ–¹å¼&lt;/strong&gt;ï¼š 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;GitHub Actions ç”¨æˆ·&lt;/strong&gt; â†’ ä½¿ç”¨ GitHub Secrets ç¯å¢ƒå˜é‡&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Docker ç”¨æˆ·&lt;/strong&gt; â†’ ä½¿ç”¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#6-docker-%E9%83%A8%E7%BD%B2"&gt;&lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶é…ç½®&lt;/a&gt;ï¼ˆ&lt;code&gt;.env&lt;/code&gt; å·²åœ¨ &lt;code&gt;.gitignore&lt;/code&gt; ä¸­ï¼Œä¸ä¼šè¢«æäº¤ï¼‰&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;æœ¬åœ°å¼€å‘ç”¨æˆ·&lt;/strong&gt;ï¼šå¯ä»¥åœ¨ &lt;code&gt;config.yaml&lt;/code&gt; ä¸­é…ç½®ï¼ˆç¡®ä¿ä¸ä¼š push åˆ°å…¬å¼€ä»“åº“ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;h4&gt;æ”¯æŒçš„æ¸ é“&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ¸ é“&lt;/th&gt; 
    &lt;th&gt;é…ç½®é¡¹&lt;/th&gt; 
    &lt;th&gt;æ˜¯å¦éœ€è¦é…å¯¹&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;é£ä¹¦&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;feishu_url&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¦&lt;/td&gt; 
    &lt;td&gt;å¤šä¸ª webhook URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;é’‰é’‰&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dingtalk_url&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¦&lt;/td&gt; 
    &lt;td&gt;å¤šä¸ª webhook URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;wework_url&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¦&lt;/td&gt; 
    &lt;td&gt;å¤šä¸ª webhook URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Telegram&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;telegram_bot_token&lt;/code&gt; + &lt;code&gt;telegram_chat_id&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;âœ… æ˜¯&lt;/td&gt; 
    &lt;td&gt;token å’Œ chat_id æ•°é‡å¿…é¡»ä¸€è‡´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ntfy&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ntfy_topic&lt;/code&gt; + &lt;code&gt;ntfy_token&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;âœ… æ˜¯&lt;/td&gt; 
    &lt;td&gt;topic å’Œ token æ•°é‡å¿…é¡»ä¸€è‡´ï¼ˆtoken å¯é€‰ï¼‰&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Bark&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;bark_url&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¦&lt;/td&gt; 
    &lt;td&gt;å¤šä¸ªæ¨é€ URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Slack&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;slack_webhook_url&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¦&lt;/td&gt; 
    &lt;td&gt;å¤šä¸ª webhook URL&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;é‚®ä»¶&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;email_to&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;å·²æ”¯æŒå¤šæ”¶ä»¶äººï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œæ— éœ€ä¿®æ”¹&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;æ¨èé…ç½®æ–¹å¼ 1ï¼šGitHub Actions ç¯å¢ƒå˜é‡&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®&lt;/strong&gt;ï¼šGitHub Repo â†’ Settings â†’ Secrets and variables â†’ Actions â†’ Repository secrets&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºç¡€é…ç½®ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# å¤šè´¦å·æ•°é‡é™åˆ¶
MAX_ACCOUNTS_PER_CHANNEL=3

# é£ä¹¦å¤šè´¦å·ï¼ˆ3ä¸ªç¾¤ç»„ï¼‰
FEISHU_WEBHOOK_URL=https://hook1.feishu.cn/xxx;https://hook2.feishu.cn/yyy;https://hook3.feishu.cn/zzz

# é’‰é’‰å¤šè´¦å·ï¼ˆ2ä¸ªç¾¤ç»„ï¼‰
DINGTALK_WEBHOOK_URL=https://oapi.dingtalk.com/xxx;https://oapi.dingtalk.com/yyy

# ä¼ä¸šå¾®ä¿¡å¤šè´¦å·ï¼ˆ2ä¸ªç¾¤ç»„ï¼‰
WEWORK_WEBHOOK_URL=https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=xxx;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=yyy

# Barkå¤šè´¦å·ï¼ˆ2ä¸ªè®¾å¤‡ï¼‰
BARK_URL=https://api.day.app/key1;https://api.day.app/key2

# Slackå¤šè´¦å·ï¼ˆ2ä¸ªé¢‘é“ï¼‰
SLACK_WEBHOOK_URL=https://hooks.slack.com/xxx;https://hooks.slack.com/yyy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é…å¯¹é…ç½®ç¤ºä¾‹ï¼ˆTelegram å’Œ ntfyï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;Telegram é…å¯¹é…ç½®&lt;/strong&gt;&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# âœ… æ­£ç¡®é…ç½®ï¼š2ä¸ªtokenå¯¹åº”2ä¸ªchat_id
TELEGRAM_BOT_TOKEN=123456:AAA-BBB;789012:CCC-DDD
TELEGRAM_CHAT_ID=-100111;-100222

# âŒ é”™è¯¯é…ç½®ï¼šæ•°é‡ä¸ä¸€è‡´ï¼Œå°†è·³è¿‡æ¨é€
TELEGRAM_BOT_TOKEN=token1;token2;token3
TELEGRAM_CHAT_ID=id1;id2
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;code&gt;token&lt;/code&gt; å’Œ &lt;code&gt;chat_id&lt;/code&gt; çš„æ•°é‡å¿…é¡»å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™è¯¥æ¸ é“æ¨é€ä¼šè¢«è·³è¿‡ã€‚&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;ntfy é…å¯¹é…ç½®&lt;/strong&gt;&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# âœ… æ­£ç¡®é…ç½®ï¼š3ä¸ªtopicï¼Œåªæœ‰ç¬¬2ä¸ªéœ€è¦token
NTFY_TOPIC=topic1;topic2;topic3
NTFY_TOKEN=;token_for_topic2;

# âœ… æ­£ç¡®é…ç½®ï¼š2ä¸ªtopicéƒ½éœ€è¦token
NTFY_TOPIC=topic1;topic2
NTFY_TOKEN=token1;token2

# âŒ é”™è¯¯é…ç½®ï¼štopicå’Œtokenæ•°é‡ä¸åŒ¹é…
NTFY_TOPIC=topic1;topic2
NTFY_TOKEN=token1;token2;token3
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;å¦‚æœæŸä¸ª topic ä¸éœ€è¦ tokenï¼Œåœ¨å¯¹åº”ä½ç½®ç•™ç©ºï¼ˆä¸¤ä¸ªåˆ†å·ä¹‹é—´ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;topic&lt;/code&gt; å’Œ &lt;code&gt;token&lt;/code&gt; çš„æ•°é‡å¿…é¡»ä¸€è‡´&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;æ¨èé…ç½®æ–¹å¼ 2ï¼šDocker ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®&lt;/strong&gt;ï¼šé¡¹ç›®æ ¹ç›®å½• &lt;code&gt;docker/.env&lt;/code&gt; æ–‡ä»¶&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºç¡€é…ç½®ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# å¤šè´¦å·æ•°é‡é™åˆ¶
MAX_ACCOUNTS_PER_CHANNEL=3

# é£ä¹¦å¤šè´¦å·ï¼ˆ3ä¸ªç¾¤ç»„ï¼‰
FEISHU_WEBHOOK_URL=https://hook1.feishu.cn/xxx;https://hook2.feishu.cn/yyy;https://hook3.feishu.cn/zzz

# é’‰é’‰å¤šè´¦å·ï¼ˆ2ä¸ªç¾¤ç»„ï¼‰
DINGTALK_WEBHOOK_URL=https://oapi.dingtalk.com/xxx;https://oapi.dingtalk.com/yyy

# ä¼ä¸šå¾®ä¿¡å¤šè´¦å·ï¼ˆ2ä¸ªç¾¤ç»„ï¼‰
WEWORK_WEBHOOK_URL=https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=xxx;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=yyy

# Barkå¤šè´¦å·ï¼ˆ2ä¸ªè®¾å¤‡ï¼‰
BARK_URL=https://api.day.app/key1;https://api.day.app/key2

# Slackå¤šè´¦å·ï¼ˆ2ä¸ªé¢‘é“ï¼‰
SLACK_WEBHOOK_URL=https://hooks.slack.com/xxx;https://hooks.slack.com/yyy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é…å¯¹é…ç½®ç¤ºä¾‹ï¼ˆTelegram å’Œ ntfyï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;Telegram é…å¯¹é…ç½®&lt;/strong&gt;&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# âœ… æ­£ç¡®é…ç½®ï¼š2ä¸ªtokenå¯¹åº”2ä¸ªchat_id
TELEGRAM_BOT_TOKEN=123456:AAA-BBB;789012:CCC-DDD
TELEGRAM_CHAT_ID=-100111;-100222

# âŒ é”™è¯¯é…ç½®ï¼šæ•°é‡ä¸ä¸€è‡´ï¼Œå°†è·³è¿‡æ¨é€
TELEGRAM_BOT_TOKEN=token1;token2;token3
TELEGRAM_CHAT_ID=id1;id2
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;code&gt;token&lt;/code&gt; å’Œ &lt;code&gt;chat_id&lt;/code&gt; çš„æ•°é‡å¿…é¡»å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™è¯¥æ¸ é“æ¨é€ä¼šè¢«è·³è¿‡ã€‚&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;ntfy é…å¯¹é…ç½®&lt;/strong&gt;&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-bash"&gt;# âœ… æ­£ç¡®é…ç½®ï¼š3ä¸ªtopicï¼Œåªæœ‰ç¬¬2ä¸ªéœ€è¦token
NTFY_TOPIC=topic1;topic2;topic3
NTFY_TOKEN=;token_for_topic2;

# âœ… æ­£ç¡®é…ç½®ï¼š2ä¸ªtopicéƒ½éœ€è¦token
NTFY_TOPIC=topic1;topic2
NTFY_TOKEN=token1;token2

# âŒ é”™è¯¯é…ç½®ï¼štopicå’Œtokenæ•°é‡ä¸åŒ¹é…
NTFY_TOPIC=topic1;topic2
NTFY_TOKEN=token1;token2;token3
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;&lt;strong&gt;è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;å¦‚æœæŸä¸ª topic ä¸éœ€è¦ tokenï¼Œåœ¨å¯¹åº”ä½ç½®ç•™ç©ºï¼ˆä¸¤ä¸ªåˆ†å·ä¹‹é—´ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;topic&lt;/code&gt; å’Œ &lt;code&gt;token&lt;/code&gt; çš„æ•°é‡å¿…é¡»ä¸€è‡´&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;æ¨é€è¡Œä¸ºè¯´æ˜&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ç‹¬ç«‹æ¨é€&lt;/strong&gt;ï¼šæ¯ä¸ªè´¦å·ç‹¬ç«‹å‘é€ï¼Œä¸€ä¸ªå¤±è´¥ä¸å½±å“å…¶ä»–è´¦å·&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;éƒ¨åˆ†æˆåŠŸåˆ¤å®š&lt;/strong&gt;ï¼šåªè¦æœ‰ä¸€ä¸ªè´¦å·å‘é€æˆåŠŸï¼Œæ•´ä½“è§†ä¸ºæˆåŠŸ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ—¥å¿—åŒºåˆ†&lt;/strong&gt;ï¼šå¤šè´¦å·æ—¶æ—¥å¿—ä¼šæ˜¾ç¤º"è´¦å·1"ã€"è´¦å·2"ç­‰æ ‡ç­¾&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ‰¹æ¬¡é—´éš”&lt;/strong&gt;ï¼šå¤šè´¦å·ä¼šå¢åŠ æ€»å‘é€æ—¶é—´ï¼ˆæ¯ä¸ªè´¦å·ç‹¬ç«‹è®¡ç®—æ‰¹æ¬¡é—´éš”ï¼‰&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr /&gt; 
 &lt;h4&gt;å¸¸è§é—®é¢˜&lt;/h4&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;Q1: è¶…è¿‡ 3 ä¸ªè´¦å·ä¼šæ€æ ·ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;ç³»ç»Ÿä¼šè‡ªåŠ¨æˆªæ–­åˆ°é…ç½®çš„æœ€å¤§æ•°é‡ï¼Œå¹¶è¾“å‡ºè­¦å‘Šæ—¥å¿—ã€‚å¯é€šè¿‡ &lt;code&gt;max_accounts_per_channel&lt;/code&gt; è°ƒæ•´é™åˆ¶ã€‚&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;âš ï¸ GitHub Actions ç”¨æˆ·ç‰¹åˆ«æ³¨æ„&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;ä¸å»ºè®®é…ç½®è¿‡å¤šè´¦å·&lt;/strong&gt;ï¼ˆå»ºè®®ä¸è¶…è¿‡ 3 ä¸ªï¼‰ï¼Œå¯èƒ½å¯¼è‡´ï¼š 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;è§¦å‘ GitHub Actions é€Ÿç‡é™åˆ¶&lt;/strong&gt;ï¼šé¢‘ç¹çš„ç½‘ç»œè¯·æ±‚å¯èƒ½è¢«è¯†åˆ«ä¸ºå¼‚å¸¸è¡Œä¸º&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;æ½œåœ¨è´¦å·é£é™©&lt;/strong&gt;ï¼šè¿‡åº¦ä½¿ç”¨ GitHub Actions èµ„æºå¯èƒ½å½±å“è´¦å·çŠ¶æ€&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;Q2: å¤šè´¦å·ä¼šå½±å“æ¨é€é€Ÿåº¦å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;ä¼šã€‚æ¯ä¸ªè´¦å·ç‹¬ç«‹å‘é€ï¼Œæ€»æ—¶é—´ = è´¦å·æ•° Ã— å•è´¦å·å‘é€æ—¶é—´ã€‚å»ºè®®æ§åˆ¶è´¦å·æ•°é‡ã€‚&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;strong&gt;Q3: æœ¬åœ°å¼€å‘ç”¨æˆ·å¦‚ä½•åœ¨ config.yaml ä¸­é…ç½®ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;å¦‚æœä½ æ˜¯æœ¬åœ°å¼€å‘ä¸”&lt;strong&gt;ä¸ä¼šå°†ä»£ç æ¨é€åˆ°å…¬å¼€ä»“åº“&lt;/strong&gt;ï¼Œå¯ä»¥ç›´æ¥åœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; ä¸­é…ç½®ï¼š&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-yaml"&gt;notification:
  enable_notification: true
  max_accounts_per_channel: 3

  webhooks:
    feishu_url: "https://hook1.feishu.cn/xxx;https://hook2.feishu.cn/yyy"
    telegram_bot_token: "token1;token2"
    telegram_chat_id: "id1;id2"
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;&lt;strong&gt;âš ï¸ é‡è¦æé†’&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ç¡®ä¿ &lt;code&gt;config/config.yaml&lt;/code&gt; åœ¨ &lt;code&gt;.gitignore&lt;/code&gt; ä¸­ï¼ˆå¦‚æœä¼šæäº¤ä»£ç ï¼‰&lt;/li&gt; 
   &lt;li&gt;æˆ–è€…åªåœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä½¿ç”¨ï¼Œ&lt;strong&gt;ç»ä¸æäº¤åˆ°å…¬å¼€ä»“åº“&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;h3&gt;11. å­˜å‚¨é…ç½®&lt;/h3&gt; 
&lt;details id="storage-config"&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;å­˜å‚¨æ¶æ„é…ç½®è¯¦è§£&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;h4&gt;å­˜å‚¨åç«¯é€‰æ‹©&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®ä½ç½®&lt;/strong&gt;ï¼š&lt;code&gt;config/config.yaml&lt;/code&gt; çš„ &lt;code&gt;storage&lt;/code&gt; éƒ¨åˆ†&lt;/p&gt; 
 &lt;p&gt;v4.0.0 ç‰ˆæœ¬é‡æ„äº†å­˜å‚¨æ¶æ„ï¼Œæ”¯æŒå¤šç§å­˜å‚¨åç«¯ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;storage:
  backend: auto  # å­˜å‚¨åç«¯ï¼šautoï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰/ localï¼ˆæœ¬åœ°SQLiteï¼‰/ remoteï¼ˆè¿œç¨‹äº‘å­˜å‚¨ï¼‰

  formats:
    sqlite: true   # æ˜¯å¦å¯ç”¨SQLiteå­˜å‚¨
    txt: true      # æ˜¯å¦ç”ŸæˆTXTå¿«ç…§
    html: true     # æ˜¯å¦ç”ŸæˆHTMLæŠ¥å‘Š

  local:
    data_dir: "output"    # æœ¬åœ°å­˜å‚¨ç›®å½•
    retention_days: 0     # æœ¬åœ°æ•°æ®ä¿ç•™å¤©æ•°ï¼Œ0è¡¨ç¤ºæ°¸ä¹…ä¿ç•™

  remote:
    endpoint_url: ""      # S3 API ç«¯ç‚¹
    bucket_name: ""       # å­˜å‚¨æ¡¶åç§°
    access_key_id: ""     # è®¿é—®å¯†é’¥ID
    secret_access_key: "" # è®¿é—®å¯†é’¥
    region: ""            # åŒºåŸŸï¼ˆå¯é€‰ï¼‰
    retention_days: 0     # è¿œç¨‹æ•°æ®ä¿ç•™å¤©æ•°ï¼Œ0è¡¨ç¤ºæ°¸ä¹…ä¿ç•™

  pull:
    enabled: false        # æ˜¯å¦å¯ç”¨å¯åŠ¨æ—¶ä»è¿œç¨‹æ‹‰å–æ•°æ®
    days: 7               # æ‹‰å–æœ€è¿‘Nå¤©çš„æ•°æ®
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;åç«¯é€‰æ‹©ç­–ç•¥&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;backend å€¼&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
    &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;auto&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;è‡ªåŠ¨é€‰æ‹©&lt;/strong&gt;ï¼ˆæ¨èï¼‰&lt;/td&gt; 
    &lt;td&gt;æ ¹æ®è¿è¡Œç¯å¢ƒæ™ºèƒ½é€‰æ‹©ï¼š&lt;br /&gt;â€¢ GitHub Actions â†’ Remote&lt;br /&gt;â€¢ Docker/æœ¬åœ° â†’ Local&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;local&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æœ¬åœ° SQLite æ•°æ®åº“&lt;/td&gt; 
    &lt;td&gt;Docker éƒ¨ç½²ã€æœ¬åœ°å¼€å‘&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;remote&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;è¿œç¨‹äº‘å­˜å‚¨ï¼ˆS3 å…¼å®¹ï¼Œå¦‚ Cloudflare R2ï¼‰&lt;/td&gt; 
    &lt;td&gt;GitHub Actionsã€å¤šæœºå™¨åŒæ­¥&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;è¿œç¨‹äº‘å­˜å‚¨é…ç½®&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ç¯å¢ƒå˜é‡&lt;/strong&gt;ï¼ˆæ¨èæ–¹å¼ï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# GitHub Actions / Docker ç¯å¢ƒå˜é‡
STORAGE_BACKEND=remote  # æˆ– auto

# æœ¬åœ°/è¿œç¨‹æ•°æ®ä¿ç•™å¤©æ•°ï¼ˆ0 è¡¨ç¤ºæ°¸ä¹…ä¿ç•™ï¼‰
LOCAL_RETENTION_DAYS=0
REMOTE_RETENTION_DAYS=0

# S3 å…¼å®¹å­˜å‚¨é…ç½®ï¼ˆä»¥ Cloudflare R2 ä¸ºä¾‹ï¼‰
S3_BUCKET_NAME=your-bucket-name
S3_ACCESS_KEY_ID=your-access-key-id
S3_SECRET_ACCESS_KEY=your-secret-access-key
S3_ENDPOINT_URL=https://&amp;lt;account-id&amp;gt;.r2.cloudflarestorage.com
S3_REGION=auto

# æ•°æ®æ‹‰å–é…ç½®ï¼ˆå¯é€‰ï¼Œä»è¿œç¨‹åŒæ­¥åˆ°æœ¬åœ°ï¼‰
PULL_ENABLED=false
PULL_DAYS=7
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;è·å–å‡­æ®&lt;/strong&gt;ï¼šå‚è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;å¿«é€Ÿå¼€å§‹ - è¿œç¨‹å­˜å‚¨é…ç½®&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;æ•°æ®æ¸…ç†ç­–ç•¥&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;è‡ªåŠ¨æ¸…ç†&lt;/strong&gt;ï¼šæ¯æ¬¡è¿è¡Œç»“æŸæ—¶æ£€æŸ¥å¹¶åˆ é™¤è¶…è¿‡ä¿ç•™å¤©æ•°çš„æ•°æ®ã€‚&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;storage:
  local:
    retention_days: 30  # æœ¬åœ°ä¿ç•™æœ€è¿‘30å¤©æ•°æ®
  remote:
    retention_days: 30  # è¿œç¨‹ä¿ç•™æœ€è¿‘30å¤©æ•°æ®
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ¸…ç†é€»è¾‘&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬åœ°å­˜å‚¨ï¼šåˆ é™¤è¿‡æœŸæ—¥æœŸçš„æ–‡ä»¶å¤¹ï¼ˆå¦‚ &lt;code&gt;output/2025-11-10/&lt;/code&gt;ï¼‰&lt;/li&gt; 
  &lt;li&gt;è¿œç¨‹å­˜å‚¨ï¼šæ‰¹é‡åˆ é™¤è¿‡æœŸçš„äº‘ç«¯å¯¹è±¡ï¼ˆå¦‚ &lt;code&gt;news/2025-11-10.db&lt;/code&gt;ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;æ—¶åŒºé…ç½®ï¼ˆv4.0.0 æ–°å¢ï¼‰&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;å…¨çƒæ—¶åŒºæ”¯æŒ&lt;/strong&gt;ï¼šè§£å†³éä¸­å›½ç”¨æˆ·æ¨é€æ—¶é—´çª—å£é—®é¢˜ã€‚&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;app:
  timezone: "Asia/Shanghai"  # é»˜è®¤ä¸­å›½æ—¶åŒº
  # å…¶ä»–ç¤ºä¾‹ï¼š
  # timezone: "America/Los_Angeles"  # ç¾è¥¿æ—¶é—´
  # timezone: "Europe/London"        # è‹±å›½æ—¶é—´
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ”¯æŒæ‰€æœ‰ IANA æ—¶åŒºåç§°&lt;/strong&gt;ï¼š&lt;a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones"&gt;æ—¶åŒºåˆ—è¡¨&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;ä¸å…¼å®¹å˜æ›´&lt;/h4&gt; 
 &lt;p&gt;âš ï¸ &lt;strong&gt;v4.0.0 ä¸å…¼å®¹ v3.x æ•°æ®&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ•°æ®åº“ç»“æ„å®Œå…¨é‡æ„ï¼Œæ— æ³•è¯»å–æ—§æ•°æ®&lt;/li&gt; 
  &lt;li&gt;æ–‡ä»¶è·¯å¾„æ ¼å¼å˜æ›´ï¼ˆISO æ ¼å¼ï¼‰&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;è¿ç§»å»ºè®®&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä» v4.0.0 å¼€å§‹é‡æ–°æ”¶é›†æ•°æ®&lt;/li&gt; 
  &lt;li&gt;æ—§æ•°æ®å¦‚éœ€ä¿ç•™ï¼Œè¯·æ‰‹åŠ¨é‡å‘½åç›®å½•æ ¼å¼ï¼ˆä¸æ¨èï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ¤– AI æ™ºèƒ½åˆ†æ&lt;/h2&gt; 
&lt;p&gt;TrendRadar v3.0.0 æ–°å¢äº†åŸºäº &lt;strong&gt;MCP (Model Context Protocol)&lt;/strong&gt; çš„ AI åˆ†æåŠŸèƒ½ï¼Œè®©ä½ å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€ä¸æ–°é—»æ•°æ®å¯¹è¯ï¼Œè¿›è¡Œæ·±åº¦åˆ†æã€‚&lt;/p&gt; 
&lt;h3&gt;âš ï¸ ä½¿ç”¨å‰å¿…è¯»&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;é‡è¦æç¤ºï¼šAI åŠŸèƒ½éœ€è¦æœ¬åœ°æ–°é—»æ•°æ®æ”¯æŒ&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;AI åˆ†æåŠŸèƒ½&lt;strong&gt;ä¸æ˜¯&lt;/strong&gt;ç›´æ¥æŸ¥è¯¢ç½‘ç»œå®æ—¶æ•°æ®ï¼Œè€Œæ˜¯åˆ†æä½ &lt;strong&gt;æœ¬åœ°å·²ç§¯ç´¯çš„æ–°é—»æ•°æ®&lt;/strong&gt;ï¼ˆå­˜å‚¨åœ¨ &lt;code&gt;output&lt;/code&gt; æ–‡ä»¶å¤¹ä¸­ï¼‰&lt;/p&gt; 
&lt;h4&gt;ä½¿ç”¨è¯´æ˜ï¼š&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é¡¹ç›®è‡ªå¸¦æµ‹è¯•æ•°æ®&lt;/strong&gt;ï¼š&lt;code&gt;output&lt;/code&gt; ç›®å½•é»˜è®¤åŒ…å« &lt;strong&gt;2025-11-01ï½2025-11-15&lt;/strong&gt; çš„æ–°é—»æ•°æ®ï¼Œå¯ç”¨äºå¿«é€Ÿä½“éªŒ AI åŠŸèƒ½&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŸ¥è¯¢é™åˆ¶&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;âœ… åªèƒ½æŸ¥è¯¢å·²æœ‰æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®ï¼ˆ11æœˆ1-15æ—¥ï¼‰&lt;/li&gt; 
   &lt;li&gt;âŒ æ— æ³•æŸ¥è¯¢å®æ—¶æ–°é—»æˆ–æœªæ¥æ—¥æœŸ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è·å–æœ€æ–°æ•°æ®&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æµ‹è¯•æ•°æ®ä»…ä¾›å¿«é€Ÿä½“éªŒï¼Œ&lt;strong&gt;å»ºè®®è‡ªè¡Œéƒ¨ç½²é¡¹ç›®&lt;/strong&gt;è·å–å®æ—¶æ•°æ®&lt;/li&gt; 
   &lt;li&gt;æŒ‰ç…§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;å¿«é€Ÿå¼€å§‹&lt;/a&gt; éƒ¨ç½²è¿è¡Œé¡¹ç›®&lt;/li&gt; 
   &lt;li&gt;ç­‰å¾…è‡³å°‘ 1 å¤©ç§¯ç´¯æ–°é—»æ•°æ®åï¼Œå³å¯æŸ¥è¯¢æœ€æ–°çƒ­ç‚¹&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;1. å¿«é€Ÿéƒ¨ç½²&lt;/h3&gt; 
&lt;p&gt;Cherry Studio æä¾› GUI é…ç½®ç•Œé¢ï¼Œ5 åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²ï¼Œå¤æ‚çš„éƒ¨åˆ†æ˜¯ä¸€é”®å®‰è£…çš„ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å›¾æ–‡éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼šç°å·²æ›´æ–°åˆ°æˆ‘çš„&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E%E4%BA%A4%E6%B5%81"&gt;å…¬ä¼—å·&lt;/a&gt;ï¼Œå›å¤ "mcp" å³å¯&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;éƒ¨ç½²æ¨¡å¼è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;STDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/strong&gt;ï¼šä¸€æ¬¡é…ç½®åç»­æ— éœ€é‡å¤é…ç½®ï¼Œ&lt;strong&gt;å›¾æ–‡éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ä¸­ä»…ä»¥æ­¤æ¨¡å¼çš„é…ç½®ä¸ºä¾‹ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP æ¨¡å¼ï¼ˆå¤‡é€‰ï¼‰&lt;/strong&gt;ï¼šå¦‚æœ STDIO æ¨¡å¼é…ç½®é‡åˆ°é—®é¢˜ï¼Œå¯ä½¿ç”¨ HTTP æ¨¡å¼ã€‚æ­¤æ¨¡å¼çš„é…ç½®æ–¹å¼ä¸ STDIO åŸºæœ¬ä¸€è‡´ï¼Œä½†å¤åˆ¶ç²˜è´´çš„å†…å®¹å°±ä¸€è¡Œï¼Œä¸æ˜“å‡ºé”™ã€‚å”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯æ¯æ¬¡ä½¿ç”¨å‰éƒ½éœ€è¦æ‰‹åŠ¨å¯åŠ¨ä¸€ä¸‹æœåŠ¡ã€‚è¯¦ç»†è¯·å‚è€ƒ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt; åº•éƒ¨çš„ HTTP æ¨¡å¼è¯´æ˜ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. å­¦ä¹ ä¸ AI å¯¹è¯çš„å§¿åŠ¿&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†å¯¹è¯æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-MCP-FAQ.md"&gt;README-MCP-FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;strong&gt;æŸ¥çœ‹ AI å¯¹è¯ç¤ºä¾‹å›¾&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ’¡ &lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šå®é™…ä¸å»ºè®®ä¸€æ¬¡æ€§é—®å¤šä¸ªé—®é¢˜ã€‚å¦‚æœä½ é€‰æ‹©çš„ AI æ¨¡å‹è¿ä¸‹å›¾çš„æŒ‰é¡ºåºè°ƒç”¨éƒ½æ— æ³•åšåˆ°ï¼Œå»ºè®®æ¢ä¸€ä¸ªã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/ai2.png" alt="mcp ä½¿ç”¨æ•ˆæœå›¾" width="600" /&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ”Œ MCP å®¢æˆ·ç«¯&lt;/h2&gt; 
&lt;p&gt;TrendRadar MCP æœåŠ¡æ”¯æŒæ ‡å‡†çš„ Model Context Protocol (MCP) åè®®ï¼Œå¯ä»¥æ¥å…¥å„ç§æ”¯æŒ MCP çš„ AI å®¢æˆ·ç«¯è¿›è¡Œæ™ºèƒ½åˆ†æã€‚&lt;/p&gt; 
&lt;h3&gt;æ”¯æŒçš„å®¢æˆ·ç«¯&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°† &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; æ›¿æ¢ä¸ºä½ çš„é¡¹ç›®å®é™…è·¯å¾„&lt;/li&gt; 
 &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åŒåæ–œæ ï¼š&lt;code&gt;C:\\Users\\YourName\\TrendRadar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ä¿å­˜åè®°å¾—é‡å¯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Claude Desktop&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;é…ç½®æ–‡ä»¶æ–¹å¼&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ Claude Desktop çš„ MCP é…ç½®æ–‡ä»¶ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;ï¼š &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Mac&lt;/strong&gt;ï¼š &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ],
      "env": {},
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Cursor&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;æ–¹å¼ä¸€ï¼šHTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® Cursor&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;é¡¹ç›®çº§é…ç½®&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://localhost:3333/mcp",
      "description": "TrendRadar æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;å…¨å±€é…ç½®&lt;/strong&gt;ï¼š åœ¨ç”¨æˆ·ç›®å½•åˆ›å»º &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;ï¼ˆåŒæ ·å†…å®¹ï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿å­˜é…ç½®æ–‡ä»¶åé‡å¯ Cursor&lt;/li&gt; 
    &lt;li&gt;åœ¨èŠå¤©ç•Œé¢çš„ "Available Tools" ä¸­æŸ¥çœ‹å·²è¿æ¥çš„å·¥å…·&lt;/li&gt; 
    &lt;li&gt;å¼€å§‹ä½¿ç”¨ï¼š&lt;code&gt;æœç´¢ä»Šå¤©çš„"AI"ç›¸å…³æ–°é—»&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;æ–¹å¼äºŒï¼šSTDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;VSCode (Cline/Continue)&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;Cline é…ç½®&lt;/h4&gt; 
 &lt;p&gt;åœ¨ Cline çš„ MCP è®¾ç½®ä¸­æ·»åŠ ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "url": "http://localhost:3333/mcp",
    "type": "streamableHttp",
    "autoApprove": [],
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "command": "uv",
    "args": [
      "--directory",
      "/path/to/TrendRadar",
      "run",
      "python",
      "-m",
      "mcp_server.server"
    ],
    "type": "stdio",
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Continue é…ç½®&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ &lt;code&gt;~/.continue/config.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "experimental": {
    "modelContextProtocolServers": [
      {
        "transport": {
          "type": "stdio",
          "command": "uv",
          "args": [
            "--directory",
            "/path/to/TrendRadar",
            "run",
            "python",
            "-m",
            "mcp_server.server"
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;åˆ†ææœ€è¿‘7å¤©"ç‰¹æ–¯æ‹‰"çš„çƒ­åº¦å˜åŒ–è¶‹åŠ¿
ç”Ÿæˆä»Šå¤©çš„çƒ­ç‚¹æ‘˜è¦æŠ¥å‘Š
æœç´¢"æ¯”ç‰¹å¸"ç›¸å…³æ–°é—»å¹¶åˆ†ææƒ…æ„Ÿå€¾å‘
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Claude Code CLI&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼é…ç½®&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. å¯åŠ¨ HTTP æœåŠ¡
# Windows: start-http.bat
# Mac/Linux: ./start-http.sh

# 2. æ·»åŠ  MCP æœåŠ¡å™¨
claude mcp add --transport http trendradar http://localhost:3333/mcp

# 3. éªŒè¯è¿æ¥ï¼ˆç¡®ä¿æœåŠ¡å·²å¯åŠ¨ï¼‰
claude mcp list
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥è¯¢æ–°é—»
claude "æœç´¢ä»Šå¤©çŸ¥ä¹çš„çƒ­ç‚¹æ–°é—»ï¼Œå‰10æ¡"

# è¶‹åŠ¿åˆ†æ
claude "åˆ†æ'äººå·¥æ™ºèƒ½'è¿™ä¸ªè¯é¢˜æœ€è¿‘ä¸€å‘¨çš„çƒ­åº¦è¶‹åŠ¿"

# æ•°æ®å¯¹æ¯”
claude "å¯¹æ¯”çŸ¥ä¹å’Œå¾®åšå¹³å°å¯¹'æ¯”ç‰¹å¸'çš„å…³æ³¨åº¦"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;MCP Inspector&lt;/b&gt;ï¼ˆè°ƒè¯•å·¥å…·ï¼‰&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;MCP Inspector æ˜¯å®˜æ–¹è°ƒè¯•å·¥å…·ï¼Œç”¨äºæµ‹è¯• MCP è¿æ¥ï¼š&lt;/p&gt; 
 &lt;h4&gt;ä½¿ç”¨æ­¥éª¤&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ TrendRadar HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ MCP Inspector&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åœ¨æµè§ˆå™¨ä¸­è¿æ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æµ‹è¯• "Ping Server" åŠŸèƒ½éªŒè¯è¿æ¥&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥ "List Tools" æ˜¯å¦è¿”å› 13 ä¸ªå·¥å…·ï¼š 
     &lt;ul&gt; 
      &lt;li&gt;åŸºç¡€æŸ¥è¯¢ï¼šget_latest_news, get_news_by_date, get_trending_topics&lt;/li&gt; 
      &lt;li&gt;æ™ºèƒ½æ£€ç´¢ï¼šsearch_news, search_related_news_history&lt;/li&gt; 
      &lt;li&gt;é«˜çº§åˆ†æï¼šanalyze_topic_trend, analyze_data_insights, analyze_sentiment, find_similar_news, generate_summary_report&lt;/li&gt; 
      &lt;li&gt;ç³»ç»Ÿç®¡ç†ï¼šget_current_config, get_system_status, trigger_crawl&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;å…¶ä»–æ”¯æŒ MCP çš„å®¢æˆ·ç«¯&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ä»»ä½•æ”¯æŒ Model Context Protocol çš„å®¢æˆ·ç«¯éƒ½å¯ä»¥è¿æ¥ TrendRadarï¼š&lt;/p&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;æœåŠ¡åœ°å€&lt;/strong&gt;ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "url": "http://localhost:3333/mcp",
  "type": "http",
  "description": "æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;STDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "command": "uv",
  "args": [
    "--directory",
    "/path/to/TrendRadar",
    "run",
    "python",
    "-m",
    "mcp_server.server"
  ],
  "type": "stdio"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›¿æ¢ &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ä¸ºå®é™…é¡¹ç›®è·¯å¾„&lt;/li&gt; 
  &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åæ–œæ è½¬ä¹‰ï¼š&lt;code&gt;C:\\Users\\...&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;ç¡®ä¿å·²å®Œæˆé¡¹ç›®ä¾èµ–å®‰è£…ï¼ˆè¿è¡Œè¿‡ setup è„šæœ¬ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;å¸¸è§é—®é¢˜&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Q1: HTTP æœåŠ¡æ— æ³•å¯åŠ¨ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;æ£€æŸ¥æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;ç¡®è®¤ç«¯å£ 3333 æœªè¢«å ç”¨ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
netstat -ano | findstr :3333

# Mac/Linux
lsof -i :3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æ£€æŸ¥é¡¹ç›®ä¾èµ–æ˜¯å¦å®‰è£…ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# é‡æ–°è¿è¡Œå®‰è£…è„šæœ¬
# Windows: setup-windows.bat æˆ–è€… setup-windows-en.bat
# Mac/Linux: ./setup-mac.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å°è¯•è‡ªå®šä¹‰ç«¯å£:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 33333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Q2: å®¢æˆ·ç«¯æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆ&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ UV è·¯å¾„æ­£ç¡®ï¼ˆè¿è¡Œ &lt;code&gt;which uv&lt;/code&gt; æˆ– &lt;code&gt;where uv&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤é¡¹ç›®è·¯å¾„æ­£ç¡®ä¸”æ— ä¸­æ–‡å­—ç¬¦&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å®¢æˆ·ç«¯é”™è¯¯æ—¥å¿—&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤æœåŠ¡å·²å¯åŠ¨ï¼ˆè®¿é—® &lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é˜²ç«å¢™è®¾ç½®&lt;/li&gt; 
    &lt;li&gt;å°è¯•ä½¿ç”¨ 127.0.0.1 æ›¿ä»£ localhost&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€šç”¨æ£€æŸ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡å¯å®¢æˆ·ç«¯åº”ç”¨&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ MCP æœåŠ¡æ—¥å¿—&lt;/li&gt; 
    &lt;li&gt;ä½¿ç”¨ MCP Inspector æµ‹è¯•è¿æ¥&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»å±•å¼€ï¼š&lt;b&gt;Q3: å·¥å…·è°ƒç”¨å¤±è´¥æˆ–è¿”å›é”™è¯¯ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;å¯èƒ½åŸå› &lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä¸å­˜åœ¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤å·²è¿è¡Œè¿‡çˆ¬è™«ï¼ˆæœ‰ output ç›®å½•æ•°æ®ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥æŸ¥è¯¢æ—¥æœŸèŒƒå›´æ˜¯å¦æœ‰æ•°æ®&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ output ç›®å½•çš„å¯ç”¨æ—¥æœŸ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å‚æ•°é”™è¯¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ£€æŸ¥æ—¥æœŸæ ¼å¼ï¼š&lt;code&gt;YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤å¹³å° ID æ­£ç¡®ï¼š&lt;code&gt;zhihu&lt;/code&gt;, &lt;code&gt;weibo&lt;/code&gt; ç­‰&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å·¥å…·æ–‡æ¡£ä¸­çš„å‚æ•°è¯´æ˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®é—®é¢˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/config.yaml&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/frequency_words.txt&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;â˜•é—®é¢˜ç­”ç–‘ä¸äº¤æµ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¦‚æœä½ æƒ³æ”¯æŒæœ¬é¡¹ç›®ï¼Œå¯é€šè¿‡å¾®ä¿¡æœç´¢&lt;strong&gt;è…¾è®¯å…¬ç›Š&lt;/strong&gt;ï¼Œå¯¹é‡Œé¢çš„&lt;strong&gt;åŠ©å­¦&lt;/strong&gt;ç›¸å…³çš„é¡¹ç›®éšå¿ƒæåŠ©&lt;/p&gt; 
 &lt;p&gt;æ„Ÿè°¢å‚ä¸è¿‡&lt;strong&gt;ä¸€å…ƒç‚¹èµ&lt;/strong&gt;çš„æœ‹å‹ï¼Œå·²æ”¶å½•è‡³é¡¶éƒ¨&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt;ï¼ä½ ä»¬çš„æ”¯æŒè®©å¼€æºç»´æŠ¤æ›´æœ‰åŠ¨åŠ›ï¼Œä¸ªäººæ‰“èµç ç°å·²ç§»é™¤ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;ï¼šé€‚åˆé’ˆå¯¹æ€§å¼ºçš„è§£ç­”ã€‚æé—®æ—¶è¯·æä¾›å®Œæ•´ä¿¡æ¯ï¼ˆæˆªå›¾ã€é”™è¯¯æ—¥å¿—ã€ç³»ç»Ÿç¯å¢ƒç­‰ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…¬ä¼—å·äº¤æµ&lt;/strong&gt;ï¼šé€‚åˆå¿«é€Ÿå’¨è¯¢ã€‚å»ºè®®ä¼˜å…ˆåœ¨ç›¸å…³æ–‡ç« ä¸‹çš„å…¬å…±ç•™è¨€åŒºäº¤æµï¼Œå¦‚ç§ä¿¡ï¼Œè¯·æ–‡æ˜ç¤¼è²Œç”¨è¯­ğŸ˜‰&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ éƒ¨ç½²æˆåŠŸäº†ï¼Ÿæ¥å…¬ä¼—å·è¯´è¯´æ„Ÿå—å§ï¼Œä½ çš„ç‚¹èµå’Œç•™è¨€éƒ½æ˜¯æˆ‘ç»§ç»­æ›´æ–°çš„åŠ¨åŠ›~&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;å…¬ä¼—å·å…³æ³¨&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/weixin.png" width="400" title="ç¡…åŸºèŒ¶æ°´é—´" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸª„ èµåŠ©å•†&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ¯å¤©è¿½è¸ªè¿™ä¹ˆå¤šçƒ­ç‚¹ï¼Œå†™æŠ¥å‘Šã€å›å¤æ¶ˆæ¯æ˜¯å¦è®©æ‰‹è…•ç–²æƒ«ï¼Ÿ&lt;br /&gt; è¯•è¯•ã€Œé—ªç”µè¯´ã€AI è¯­éŸ³è¾“å…¥æ³• â€”â€” ç”¨è¯´çš„ï¼Œæ¯”æ‰“å­—å¿« 4 å€ âš¡ ã€‚ä»çœ‹çƒ­ç‚¹åˆ°è¾“å‡ºå†…å®¹ï¼Œè®©æ•ˆç‡ç¿»å€ ğŸ‘‡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://shandianshuo.cn"&gt;&lt;img src="https://img.shields.io/badge/Mac-%E5%85%8D%E8%B4%B9%E4%B8%8B%E8%BD%BD-FF6B6B?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Macä¸‹è½½" /&gt;&lt;/a&gt; &lt;a href="https://shandianshuo.cn"&gt;&lt;img src="https://img.shields.io/badge/Windows-%E5%85%8D%E8%B4%B9%E4%B8%8B%E8%BD%BD-FF6B6B?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white" alt="Windowsä¸‹è½½" /&gt;&lt;/a&gt; &lt;a href="https://shandianshuo.cn" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner-shandianshuo.png" alt="é—ªç”µè¯´" width="700" /&gt; &lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“š é¡¹ç›®ç›¸å…³&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;4 ç¯‡æ–‡ç« &lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/KYEPfTPVzZNWFclZh4am_g"&gt;å¯åœ¨è¯¥æ–‡ç« ä¸‹æ–¹ç•™è¨€ï¼Œæ–¹ä¾¿é¡¹ç›®ä½œè€…ç”¨æ‰‹æœºç­”ç–‘&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/jzn0vLiQFX408opcfpPPxQ"&gt;2ä¸ªæœˆç ´ 1000 starï¼Œæˆ‘çš„GitHubé¡¹ç›®æ¨å¹¿å®æˆ˜ç»éªŒ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/C8evK-U7onG1sTTdwdW2zg"&gt;github fork è¿è¡Œæœ¬é¡¹ç›®çš„æ³¨æ„äº‹é¡¹ &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/8ghyfDAtQZjLrnWTQabYOQ"&gt;åŸºäºæœ¬é¡¹ç›®ï¼Œå¦‚ä½•å¼€å±•å…¬ä¼—å·æˆ–è€…æ–°é—»èµ„è®¯ç±»æ–‡ç« å†™ä½œ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;AI å¼€å‘&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;å¦‚æœä½ æœ‰å°ä¼—éœ€æ±‚ï¼Œå®Œå…¨å¯ä»¥åŸºäºæˆ‘çš„é¡¹ç›®è‡ªè¡Œå¼€å‘ï¼Œé›¶ç¼–ç¨‹åŸºç¡€çš„ä¹Ÿå¯ä»¥è¯•è¯•&lt;/li&gt; 
 &lt;li&gt;æˆ‘æ‰€æœ‰çš„å¼€æºé¡¹ç›®æˆ–å¤šæˆ–å°‘éƒ½ä½¿ç”¨äº†è‡ªå·±å†™çš„&lt;strong&gt;AIè¾…åŠ©è½¯ä»¶&lt;/strong&gt;æ¥æå‡å¼€å‘æ•ˆç‡ï¼Œè¿™æ¬¾å·¥å…·å·²å¼€æº&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼šè¿…é€Ÿç­›é€‰é¡¹ç›®ä»£ç å–‚ç»™AIï¼Œä½ åªéœ€è¦è¡¥å……ä¸ªäººéœ€æ±‚å³å¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®åœ°å€&lt;/strong&gt;ï¼š&lt;a href="https://github.com/sansan0/ai-code-context-helper"&gt;https://github.com/sansan0/ai-code-context-helper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å…¶ä½™é¡¹ç›®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ“ æ¯›ä¸»å¸­è¶³è¿¹åœ°å›¾ - äº¤äº’å¼åŠ¨æ€å±•ç¤º1893-1976å¹´å®Œæ•´è½¨è¿¹ã€‚æ¬¢è¿è¯¸ä½åŒå¿—è´¡çŒ®æ•°æ®&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/mao-map"&gt;https://github.com/sansan0/mao-map&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å“”å“©å“”å“©(bilibili)è¯„è®ºåŒºæ•°æ®å¯è§†åŒ–åˆ†æè½¯ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/bilibili-comment-analyzer"&gt;https://github.com/sansan0/bilibili-comment-analyzer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;æœ¬é¡¹ç›®æµç¨‹å›¾&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[ğŸ‘¤ ç”¨æˆ·å¼€å§‹] --&amp;gt; B{ğŸš€ é€‰æ‹©éƒ¨ç½²æ–¹å¼}
    
    B --&amp;gt;|äº‘ç«¯éƒ¨ç½²| C1[ğŸ´ Fork é¡¹ç›®åˆ° GitHub]
    B --&amp;gt;|æœ¬åœ°éƒ¨ç½²| C2[ğŸ³ Docker éƒ¨ç½²]
    
    C1 --&amp;gt; D[âš™ï¸ é…ç½®é€šçŸ¥æ¸ é“&amp;lt;br/&amp;gt;å¯åŒæ—¶é…ç½®å¤šä¸ª]
    C2 --&amp;gt; D
    
    D --&amp;gt; E[é€‰æ‹©é€šçŸ¥æ–¹å¼ï¼š&amp;lt;br/&amp;gt;ğŸ“±ä¼ä¸šå¾®ä¿¡ ğŸ’¬é£ä¹¦ ğŸ””é’‰é’‰&amp;lt;br/&amp;gt;ğŸ“ŸTelegram ğŸ“§é‚®ä»¶]
    
    E --&amp;gt; F[ğŸ”‘ å¡«å†™é€šçŸ¥å‚æ•°&amp;lt;br/&amp;gt;GitHub Secrets æˆ–ç¯å¢ƒå˜é‡]
    
    F --&amp;gt; G[ğŸ“ é…ç½®å…³é”®è¯&amp;lt;br/&amp;gt;config/frequency_words.txt&amp;lt;br/&amp;gt;æ™®é€šè¯/å¿…é¡»è¯+/è¿‡æ»¤è¯!]
    
    G --&amp;gt; H[ğŸ¯ é€‰æ‹©è¿è¡Œæ¨¡å¼&amp;lt;br/&amp;gt;config/config.yaml]
    
    H --&amp;gt; H1[ğŸ“‹ daily - å½“æ—¥æ±‡æ€»&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æ‰€æœ‰åŒ¹é…æ–°é—»]
    H --&amp;gt; H2[ğŸ“° current - å½“å‰æ¦œå•&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æœ€æ–°æ¦œå•]
    H --&amp;gt; H3[ğŸ“ˆ incremental - å¢é‡ç›‘æ§&amp;lt;br/&amp;gt;ä»…æ¨é€æ–°å¢å†…å®¹]
    
    H1 --&amp;gt; I[å¯é€‰ï¼šæ¨é€æ—¶é—´çª—å£æ§åˆ¶&amp;lt;br/&amp;gt;â° é™åˆ¶æ¨é€æ—¶é—´èŒƒå›´]
    H2 --&amp;gt; I
    H3 --&amp;gt; I
    
    I --&amp;gt; J[âœ… é…ç½®å®Œæˆ]
    
    J --&amp;gt; K[ğŸ¤– ç³»ç»Ÿè‡ªåŠ¨è¿è¡Œ]
    
    K --&amp;gt; L[ğŸ•·ï¸ çˆ¬å–11+å¹³å°çƒ­ç‚¹]
    L --&amp;gt; M[ğŸ” å…³é”®è¯ç­›é€‰]
    M --&amp;gt; N[âš–ï¸ æƒé‡ç®—æ³•æ’åº&amp;lt;br/&amp;gt;æ’å60% + é¢‘æ¬¡30% + çƒ­åº¦10%]
    N --&amp;gt; O[ğŸ“Š ç”ŸæˆæŠ¥å‘Š&amp;lt;br/&amp;gt;HTMLç½‘é¡µ + æ¨é€æ¶ˆæ¯]
    O --&amp;gt; P[ğŸ“± å¤šæ¸ é“æ¨é€é€šçŸ¥]
    
    P --&amp;gt; Q[ğŸ‰ æŒç»­æ¥æ”¶ç²¾å‡†æ¨é€&amp;lt;br/&amp;gt;å‘Šåˆ«ä¿¡æ¯è¿‡è½½]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style F fill:#fff9c4
    style G fill:#e8f5e9
    style H fill:#e0f2f1
    style I fill:#fce4ec
    style O fill:#e1bee7
    style Q fill:#c8e6c9
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#sansan0/TrendRadar&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sansan0/TrendRadar&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#trendradar"&gt;ğŸ” å›åˆ°é¡¶éƒ¨&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>MemoriLabs/Memori</title>
      <link>https://github.com/MemoriLabs/Memori</link>
      <description>&lt;p&gt;SQL Native Memory Layer for LLMs, AI Agents &amp; Multi-Agent Systems&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://memorilabs.ai/"&gt;&lt;img src="https://s3.us-east-1.amazonaws.com/images.memorilabs.ai/banner.png" alt="Memori Labs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;The memory fabric for enterprise AI&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Memori plugs into the software and infrastructure you already use. It is LLM, datastore and framework agnostic and seamlessly integrates into the architecture you've already designed.&lt;/i&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15418"&gt; &lt;img src="https://trendshift.io/_next/image?url=https%3A%2F%2Ftrendshift.io%2Fapi%2Fbadge%2Frepositories%2F15418&amp;amp;w=640&amp;amp;q=75" alt="Memori%2fLabs%2FMemori | Trendshif" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://badge.fury.io/py/memori"&gt; &lt;img src="https://badge.fury.io/py/memori.svg?sanitize=true" alt="PyPI version" /&gt; &lt;/a&gt; &lt;a href="https://pepy.tech/projects/memori"&gt; &lt;img src="https://static.pepy.tech/badge/memori" alt="Downloads" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/license/apache-2-0"&gt; &lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt; &lt;img src="https://img.shields.io/badge/python-3.8+-blue.svg?sanitize=true" alt="Python 3.8+" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/abD4eGym6v"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="Discord" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/MemoriLabs/Memori/stargazers"&gt; &lt;img src="https://img.shields.io/badge/â­%20Give%20a%20Star-Support%20the%20project-orange?style=for-the-badge" alt="Give a Star" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install Memori:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install memori
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What's New In v3?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Significant performance improvements using Advanced Augmentation.&lt;/li&gt; 
 &lt;li&gt;Threaded, zero latency replacement for the v2 extraction agent.&lt;/li&gt; 
 &lt;li&gt;LLM agnostic with support for all of the major foundational models.&lt;/li&gt; 
 &lt;li&gt;Datastore agnostic with support for all major databases and document stores.&lt;/li&gt; 
 &lt;li&gt;Adapter/driver architecture to make contributions easier.&lt;/li&gt; 
 &lt;li&gt;Vectorized memories and in-memory semantic search for more accurate context.&lt;/li&gt; 
 &lt;li&gt;Third normal form schema including storage of semantic triples for a knowledge graph.&lt;/li&gt; 
 &lt;li&gt;Reduced development overhead to a single line of code.&lt;/li&gt; 
 &lt;li&gt;Automatic schema migrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example with OpenAI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI
from memori import Memori

client = OpenAI(...)
mem = Memori().llm.register(client)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Attribution&lt;/h2&gt; 
&lt;p&gt;To get the most out of Memori, you want to attribute your LLM interactions to an entity (think person, place or thing; like a user) and a process (think your agent, LLM interaction or program).&lt;/p&gt; 
&lt;p&gt;If you do not provide any attribution, Memori cannot make memories for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;mem.attribution(entity_id="12345", process_id="my-ai-bot")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Session Management&lt;/h2&gt; 
&lt;p&gt;Memori uses sessions to group your LLM interactions together. For example, if you have an agent that executes multiple steps you want those to be recorded in a single session.&lt;/p&gt; 
&lt;p&gt;By default, Memori handles setting the session for you but you can start a new session or override the session by executing the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;mem.new_session()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;session_id = mem.config.session_id

# ...

mem.set_session(session_id)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Suggested Setup&lt;/h2&gt; 
&lt;p&gt;To make sure everything is installed in the most efficient manner, we suggest you execute the following once:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m memori setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This step is not necessary but will prep your environment for faster execution. If you do not perform this step, it will be executed the first time Memori is run which will cause the first execution (and only the first one) to be a little slower.&lt;/p&gt; 
&lt;h2&gt;Configure Your Database&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run this command once, via CI/CD or anytime you update Memori.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;Memori(conn=db_session_factory).config.storage.build()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Instantiate Memori with the connection factory.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI
from memori import Memori

client = OpenAI(...)
mem = Memori(conn=db_session_factory).llm.register(client)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Quickstart Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
import sqlite3

from memori import Memori
from openai import OpenAI


def get_sqlite_connection():
    return sqlite3.connect("memori.db")


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

memori = Memori(conn=get_sqlite_connection).llm.register(client)
memori.attribution(entity_id="123456", process_id="test-ai-agent")
memori.config.storage.build()

response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[
        {"role": "user", "content": "My favorite color is blue."}
    ]
)
print(response.choices[0].message.content + "\n")

# Advanced Augmentation runs asynchronously to efficiently
# create memories. For this example, a short lived command
# line program, we need to wait for it to finish.

memori.augmentation.wait()

# Memori stored that your favorite color is blue in SQLite.
# Now reset everything so there's no prior context.

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

memori = Memori(conn=get_sqlite_connection).llm.register(client)
memori.attribution(entity_id="123456", process_id="test-ai-agent")

response = client.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[
        {"role": "user", "content": "What's my favorite color?"}
    ]
)
print(response.choices[0].message.content + "\n")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported LLM&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Anthropic&lt;/li&gt; 
 &lt;li&gt;Bedrock&lt;/li&gt; 
 &lt;li&gt;Gemini&lt;/li&gt; 
 &lt;li&gt;Grok (xAI)&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;(unstreamed, streamed, synchronous and asynchronous)&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Supported Frameworks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Agno&lt;/li&gt; 
 &lt;li&gt;LangChain&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nebius AI Studio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Database Integrations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DB API 2.0&lt;/strong&gt; - Direct support for any Python database driver that implements the &lt;a href="https://peps.python.org/pep-0249/"&gt;PEP 249 Database API Specification v2.0&lt;/a&gt;. This includes drivers like &lt;code&gt;psycopg&lt;/code&gt;, &lt;code&gt;pymysql&lt;/code&gt;, &lt;code&gt;MySQLdb&lt;/code&gt;, &lt;code&gt;cx_Oracle&lt;/code&gt;, &lt;code&gt;oracledb&lt;/code&gt;, and &lt;code&gt;sqlite3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Django&lt;/strong&gt; - Native integration with Django's ORM and database layer&lt;/li&gt; 
 &lt;li&gt;SQLAlchemy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Datastores&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MemoriLabs/Memori/tree/main/examples/cockroachdb"&gt;CockroachDB&lt;/a&gt; - Full example with setup instructions&lt;/li&gt; 
 &lt;li&gt;MariaDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MemoriLabs/Memori/tree/main/examples/mongodb"&gt;MongoDB&lt;/a&gt; - Full example with setup instructions&lt;/li&gt; 
 &lt;li&gt;MySQL&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MemoriLabs/Memori/tree/main/examples/neon"&gt;Neon&lt;/a&gt; - Full example with setup instructions&lt;/li&gt; 
 &lt;li&gt;Oracle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MemoriLabs/Memori/tree/main/examples/postgres"&gt;PostgreSQL&lt;/a&gt; - Full example with setup instructions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MemoriLabs/Memori/tree/main/examples/sqlite"&gt;SQLite&lt;/a&gt; - Full example with setup instructions&lt;/li&gt; 
 &lt;li&gt;Supabase&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;For more examples and demos, check out the &lt;a href="https://github.com/MemoriLabs/memori-cookbook"&gt;Memori Cookbook&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Memori Advanced Augmentation&lt;/h2&gt; 
&lt;p&gt;Memories are tracked at several different levels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;entity: think person, place, or thing; like a user&lt;/li&gt; 
 &lt;li&gt;process: think your agent, LLM interaction or program&lt;/li&gt; 
 &lt;li&gt;session: the current interactions between the entity, process and the LLM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/MemoriLabs/Memori/raw/main/docs/advanced-augmentation.md"&gt;Memori's Advanced Augmentation&lt;/a&gt; enhances memories at each of these levels with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;attributes&lt;/li&gt; 
 &lt;li&gt;events&lt;/li&gt; 
 &lt;li&gt;facts&lt;/li&gt; 
 &lt;li&gt;people&lt;/li&gt; 
 &lt;li&gt;preferences&lt;/li&gt; 
 &lt;li&gt;relationships&lt;/li&gt; 
 &lt;li&gt;rules&lt;/li&gt; 
 &lt;li&gt;skills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Memori knows who your user is, what tasks your agent handles and creates unparalleled context between the two. Augmentation occurs in the background incurring no latency.&lt;/p&gt; 
&lt;p&gt;By default, Memori Advanced Augmentation is available without an account but rate limited. When you need increased limits, &lt;a href="https://app.memorilabs.ai/signup"&gt;sign up for Memori Advanced Augmentation&lt;/a&gt; or execute the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m memori sign-up &amp;lt;email_address&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Memori Advanced Augmentation is always free for developers!&lt;/p&gt; 
&lt;p&gt;Once you've obtained an API key, simply set the following environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export MEMORI_API_KEY=[api_key]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Managing Your Quota&lt;/h2&gt; 
&lt;p&gt;At any time, you can check your quota by executing the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m memori quota
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or by checking your account at &lt;a href="https://memorilabs.ai/"&gt;https://memorilabs.ai/&lt;/a&gt;. If you have reached your IP address quota, sign up and get an API key for increased limits.&lt;/p&gt; 
&lt;p&gt;If your API key exceeds its quota limits we will email you and let you know.&lt;/p&gt; 
&lt;h2&gt;Command Line Interface (CLI)&lt;/h2&gt; 
&lt;p&gt;To use the Memori CLI, execute the following from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m memori
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will display a menu of the available options. For more information about what you can do with the Memori CLI, please reference &lt;a href="https://github.com/MemoriLabs/Memori/raw/main/docs/cli.md"&gt;Command Line Interface&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Please see our &lt;a href="https://github.com/MemoriLabs/Memori/raw/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Code style and standards&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
 &lt;li&gt;Reporting issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://memorilabs.ai/docs"&gt;https://memorilabs.ai/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.gg/abD4eGym6v"&gt;https://discord.gg/abD4eGym6v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/MemoriLabs/Memori/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - see &lt;a href="https://github.com/MemoriLabs/Memori/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Star us on GitHub&lt;/strong&gt; to support the project&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#MemoriLabs/memori"&gt;&lt;img src="https://api.star-history.com/svg?repos=MemoriLabs/memori&amp;amp;type=date" alt="Star History" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trustedsec/social-engineer-toolkit</title>
      <link>https://github.com/trustedsec/social-engineer-toolkit</link>
      <description>&lt;p&gt;The Social-Engineer Toolkit (SET) repository from TrustedSec - All new versions of SET will be deployed here.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Social-Engineer Toolkit (SET)&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copyright &lt;span&gt;Â©&lt;/span&gt; 2020&lt;/li&gt; 
 &lt;li&gt;Written by: David Kennedy (ReL1K) @HackingDave&lt;/li&gt; 
 &lt;li&gt;Company: &lt;a href="https://www.trustedsec.com"&gt;TrustedSec&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Description&lt;/h2&gt; 
&lt;p&gt;The Social-Engineer Toolkit is an open-source penetration testing framework designed for social engineering. SET has a number of custom attack vectors that allow you to make a believable attack quickly. SET is a product of TrustedSec, LLC â€“ an information security consulting firm located in Cleveland, Ohio.&lt;/p&gt; 
&lt;p&gt;DISCLAIMER: This is &lt;em&gt;only&lt;/em&gt; for testing purposes and can only be used where strict consent has been given. Do not use this for illegal purposes, period. Please read the LICENSE under readme/LICENSE for the licensing of SET.&lt;/p&gt; 
&lt;h4&gt;Supported platforms:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Linux&lt;/li&gt; 
 &lt;li&gt;Mac OS X (experimental)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;h2&gt;Install via requirements.txt&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install -r requirements.txt
python3 setup.py 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Install SET&lt;/h2&gt; 
&lt;p&gt;=======&lt;/p&gt; 
&lt;h4&gt;Mac OS X&lt;/h4&gt; 
&lt;p&gt;You will need to use a virtual environment for the Python install if you are using an M2 Macbook with the following instructions in your CLI within the social-engineer-toolkit directory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;    # to install dependencies, run the following:
    python3 -m venv path/to/venv
    source path/to/venv/bin/activate
    python3 -m pip install -r requirements.txt

    # to install SET
    sudo python3 setup.py 
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h4&gt;Windows 10 WSL/WSL2 Kali Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install set -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Kali Linux on Windows 10 is a minimal installation so it doesn't have any tools installed. You can easily install Social Engineer Toolkit on WSL/WSL2 without needing pip using the above command.&lt;/p&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/trustedsec/social-engineer-toolkit/ setoolkit/
cd setoolkit
pip3 install -r requirements.txt
python setup.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h2&gt;SET Tutorial&lt;/h2&gt; 
&lt;p&gt;For a full document on how to use SET, &lt;a href="https://github.com/trustedsec/social-engineer-toolkit/raw/master/readme/User_Manual.pdf"&gt;visit the SET user manual&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Bugs and enhancements&lt;/h2&gt; 
&lt;p&gt;For bug reports or enhancements, please open an &lt;a href="https://github.com/trustedsec/social-engineer-toolkit/issues"&gt;issue&lt;/a&gt; here. &lt;br /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GoogleCloudPlatform/agent-starter-pack</title>
      <link>https://github.com/GoogleCloudPlatform/agent-starter-pack</link>
      <description>&lt;p&gt;Ship AI Agents to Google Cloud in minutes, not months. Production-ready templates with built-in CI/CD, evaluation, and observability.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸš€ Agent Starter Pack&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/pypi/v/agent-starter-pack?color=blue" alt="Version" /&gt; &lt;a href="https://youtu.be/jHt-ZVD660g"&gt;&lt;img src="https://img.shields.io/badge/1--Minute%20Overview-gray" alt="1-Minute Video Overview" /&gt;&lt;/a&gt; &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/"&gt;&lt;img src="https://img.shields.io/badge/Documentation-gray" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fagent_starter_pack%2Fresources%2Fidx"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://cdn.firebasestudio.dev/btn/try_light_20.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://cdn.firebasestudio.dev/btn/try_dark_20.svg" /&gt; 
   &lt;img height="20" alt="Try in Firebase Studio" src="https://cdn.firebasestudio.dev/btn/try_blue_20.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;a href="https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs"&gt;&lt;img src="https://img.shields.io/badge/Launch-in_Cloud_Shell-white" alt="Launch in Cloud Shell" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/GoogleCloudPlatform/agent-starter-pack?color=yellow" alt="Stars" /&gt;&lt;/p&gt; 
&lt;p&gt;A Python package that provides &lt;strong&gt;production-ready templates&lt;/strong&gt; for GenAI agents on Google Cloud.&lt;/p&gt; 
&lt;p&gt;Focus on your agent logicâ€”the starter pack provides everything else: infrastructure, CI/CD, observability, and security.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;âš¡ï¸ Launch&lt;/th&gt; 
   &lt;th&gt;ğŸ§ª Experiment&lt;/th&gt; 
   &lt;th&gt;âœ… Deploy&lt;/th&gt; 
   &lt;th&gt;ğŸ› ï¸ Customize&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/agent_starter_pack/agents/"&gt;Pre-built agent templates&lt;/a&gt; (ReAct, RAG, multi-agent, Live API).&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview"&gt;Vertex AI evaluation&lt;/a&gt; and an interactive playground.&lt;/td&gt; 
   &lt;td&gt;Production-ready infra with &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/observability"&gt;monitoring, observability&lt;/a&gt;, and &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment"&gt;CI/CD&lt;/a&gt; on &lt;a href="https://cloud.google.com/run"&gt;Cloud Run&lt;/a&gt; or &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview"&gt;Agent Engine&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Extend and customize templates according to your needs. ğŸ†• Now integrating with &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini CLI&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;âš¡ Get Started in 1 Minute&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;From zero to production-ready agent in 60 seconds using &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx agent-starter-pack create
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt; âœ¨ Alternative: Using pip&lt;/summary&gt; 
 &lt;p&gt;If you don't have &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; installed, you can use pip:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate a Python virtual environment
python -m venv .venv &amp;amp;&amp;amp; source .venv/bin/activate

# Install the agent starter pack
pip install --upgrade agent-starter-pack

# Create a new agent project
agent-starter-pack create
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; You now have a fully functional agent projectâ€”complete with backend, frontend, and deployment infrastructureâ€”ready for you to explore and customize.&lt;/p&gt; 
&lt;h3&gt;ğŸ”§ Enhance Existing Agents&lt;/h3&gt; 
&lt;p&gt;Already have an agent? Add production-ready deployment and infrastructure by running this command in your project's root folder:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx agent-starter-pack enhance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/installation"&gt;Installation Guide&lt;/a&gt; for more options, or try with zero setup in &lt;a href="https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx"&gt;Firebase Studio&lt;/a&gt; or &lt;a href="https://shell.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https%3A%2F%2Fgithub.com%2Feliasecchig%2Fasp-open-in-cloud-shell&amp;amp;cloudshell_print=open-in-cs"&gt;Cloud Shell&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¤– Agents&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A base ReAct agent implemented using Google's &lt;a href="https://github.com/google/adk-python"&gt;Agent Development Kit&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_a2a_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;An ADK agent with &lt;a href="https://a2a-protocol.org/"&gt;Agent2Agent (A2A) Protocol&lt;/a&gt; support for distributed agent communication and interoperability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;agentic_rag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG agent for document retrieval and Q&amp;amp;A. Supporting &lt;a href="https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction"&gt;Vertex AI Search&lt;/a&gt; and &lt;a href="https://cloud.google.com/vertex-ai/docs/vector-search/overview"&gt;Vector Search&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;langgraph_base&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A base ReAct agent implemented using LangChain's &lt;a href="https://github.com/langchain-ai/langgraph"&gt;LangGraph&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;adk_live&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A real-time multimodal RAG agent powered by Gemini, supporting audio/video/text chat&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;More agents are on the way!&lt;/strong&gt; We are continuously expanding our &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/agents/overview"&gt;agent library&lt;/a&gt;. Have a specific agent type in mind? &lt;a href="https://github.com/GoogleCloudPlatform/agent-starter-pack/issues/new?labels=enhancement"&gt;Raise an issue as a feature request!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ” ADK Samples&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Looking to explore more ADK examples? Check out the &lt;a href="https://github.com/google/adk-samples"&gt;ADK Samples Repository&lt;/a&gt; for additional examples and use cases demonstrating ADK's capabilities.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸŒŸ Community Showcase&lt;/h2&gt; 
&lt;p&gt;Explore amazing projects built with the Agent Starter Pack!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/community-showcase"&gt;View Community Showcase â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;agent-starter-pack&lt;/code&gt; offers key features to accelerate and simplify the development of your agent:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”„ &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/cli/setup_cicd"&gt;CI/CD Automation&lt;/a&gt;&lt;/strong&gt; - A single command to set up a complete CI/CD pipeline for all environments, supporting both &lt;strong&gt;Google Cloud Build&lt;/strong&gt; and &lt;strong&gt;GitHub Actions&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“¥ &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/data-ingestion"&gt;Data Pipeline for RAG with Terraform/CI-CD&lt;/a&gt;&lt;/strong&gt; - Seamlessly integrate a data pipeline to process embeddings for RAG into your agent system. Supporting &lt;a href="https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction"&gt;Vertex AI Search&lt;/a&gt; and &lt;a href="https://cloud.google.com/vertex-ai/docs/vector-search/overview"&gt;Vector Search&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/guide/remote-templating.md"&gt;Remote Templates&lt;/a&gt;&lt;/strong&gt;: Create and share your own agent starter packs templates from any Git repository.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Gemini CLI Integration&lt;/strong&gt; - Use the &lt;a href="https://github.com/google-gemini/gemini-cli"&gt;Gemini CLI&lt;/a&gt; and the included &lt;code&gt;GEMINI.md&lt;/code&gt; context file to ask questions about your template, agent architecture, and the path to production. Get instant guidance and code examples directly in your terminal.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;High-Level Architecture&lt;/h2&gt; 
&lt;p&gt;This starter pack covers all aspects of Agent development, from prototyping and evaluation to deployment and monitoring.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/docs/images/ags_high_level_architecture.png" alt="High Level Architecture" title="Architecture" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”§ Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/sdk/docs/install"&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.hashicorp.com/terraform/downloads"&gt;Terraform&lt;/a&gt; (for deployment)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.gnu.org/software/make/"&gt;Make&lt;/a&gt; (for development tasks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/"&gt;documentation site&lt;/a&gt; for comprehensive guides and references!&lt;/p&gt; 
&lt;p&gt;ğŸ” &lt;strong&gt;New to the codebase?&lt;/strong&gt; Explore the &lt;a href="https://codewiki.google/github.com/googlecloudplatform/agent-starter-pack"&gt;CodeWiki&lt;/a&gt; for AI-powered code understanding and navigation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/getting-started"&gt;Getting Started Guide&lt;/a&gt; - First steps with agent-starter-pack&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/installation"&gt;Installation Guide&lt;/a&gt; - Setting up your environment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/guide/deployment"&gt;Deployment Guide&lt;/a&gt; - Taking your agent to production&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/agents/overview"&gt;Agent Templates Overview&lt;/a&gt; - Explore available agent patterns&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://googlecloudplatform.github.io/agent-starter-pack/cli/"&gt;CLI Reference&lt;/a&gt; - Command-line tool documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Video Walkthrough:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=9zqwym-N3lg"&gt;Exploring the Agent Starter Pack&lt;/a&gt;&lt;/strong&gt;: A comprehensive tutorial demonstrating how to rapidly deploy AI Agents using the Agent Starter Pack, covering architecture, templates, and step-by-step deployment.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/live/eZ-8UQ_t4YM?feature=shared&amp;amp;t=2791"&gt;6-minute introduction&lt;/a&gt;&lt;/strong&gt; (April 2024): Explaining the Agent Starter Pack and demonstrating its key features. Part of the Kaggle GenAI intensive course.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Looking for more examples and resources for Generative AI on Google Cloud? Check out the &lt;a href="https://github.com/GoogleCloudPlatform/generative-ai"&gt;GoogleCloudPlatform/generative-ai&lt;/a&gt; repository for notebooks, code samples, and more!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! See the &lt;a href="https://raw.githubusercontent.com/GoogleCloudPlatform/agent-starter-pack/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We value your input! Your feedback helps us improve this starter pack and make it more useful for the community.&lt;/p&gt; 
&lt;h3&gt;Getting Help&lt;/h3&gt; 
&lt;p&gt;If you encounter any issues or have specific suggestions, please first consider &lt;a href="https://github.com/GoogleCloudPlatform/generative-ai/issues"&gt;raising an issue&lt;/a&gt; on our GitHub repository.&lt;/p&gt; 
&lt;h3&gt;Share Your Experience&lt;/h3&gt; 
&lt;p&gt;For other types of feedback, or if you'd like to share a positive experience or success story using this starter pack, we'd love to hear from you! You can reach out to us at &lt;a href="mailto:agent-starter-pack@google.com"&gt;&lt;/a&gt;&lt;a href="mailto:agent-starter-pack@google.com"&gt;agent-starter-pack@google.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thank you for your contributions!&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This repository is for demonstrative purposes only and is not an officially supported Google product.&lt;/p&gt; 
&lt;h2&gt;Terms of Service&lt;/h2&gt; 
&lt;p&gt;The agent-starter-pack templating CLI and the templates in this starter pack leverage Google Cloud APIs. When you use this starter pack, you'll be deploying resources in your own Google Cloud project and will be responsible for those resources. Please review the &lt;a href="https://cloud.google.com/terms/service-terms"&gt;Google Cloud Service Terms&lt;/a&gt; for details on the terms of service associated with these APIs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MetaCubeX/mihomo</title>
      <link>https://github.com/MetaCubeX/mihomo</link>
      <description>&lt;p&gt;A simple Python Pydantic model for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mihomo&lt;/h1&gt; 
&lt;p&gt;A simple python pydantic model (type hint and autocompletion support) for Honkai: Star Rail parsed data from the Mihomo API.&lt;/p&gt; 
&lt;p&gt;API url: &lt;a href="https://api.mihomo.me/sr_info_parsed/%7BUID%7D?lang=%7BLANG%7D"&gt;https://api.mihomo.me/sr_info_parsed/{UID}?lang={LANG}&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U git+https://github.com/KT-Yeh/mihomo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;p&gt;There are two parsed data formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;V1: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&amp;amp;version=v1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user_v1(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.v1.StarrailInfoParsedV1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models/v1&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;V2: 
  &lt;ul&gt; 
   &lt;li&gt;URL: &lt;a href="https://api.mihomo.me/sr_info_parsed/800333171?lang=en"&gt;https://api.mihomo.me/sr_info_parsed/800333171?lang=en&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Fetching: use &lt;code&gt;client.fetch_user(800333171)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Data model: &lt;code&gt;mihomo.models.StarrailInfoParsed&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;All models defined in &lt;code&gt;mihomo/models&lt;/code&gt; directory.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you don't want to use &lt;code&gt;client.get_icon_url&lt;/code&gt; to get the image url everytime, you can use &lt;code&gt;client.fetch_user(800333171, replace_icon_name_with_url=True)&lt;/code&gt; to get the parsed data with asset urls.&lt;/p&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import asyncio

from mihomo import Language, MihomoAPI
from mihomo.models import StarrailInfoParsed
from mihomo.models.v1 import StarrailInfoParsedV1

client = MihomoAPI(language=Language.EN)


async def v1():
    data: StarrailInfoParsedV1 = await client.fetch_user_v1(800333171)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Achievements: {data.player_details.achievements}")
    print(f"Characters count: {data.player_details.characters}")
    print(f"Profile picture url: {client.get_icon_url(data.player.icon)}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Level: {character.level}")
        print(f"Avatar url: {client.get_icon_url(character.icon)}")
        print(f"Preview url: {client.get_icon_url(character.preview)}")
        print(f"Portrait url: {client.get_icon_url(character.portrait)}")


async def v2():
    data: StarrailInfoParsed = await client.fetch_user(800333171, replace_icon_name_with_url=True)

    print(f"Name: {data.player.name}")
    print(f"Level: {data.player.level}")
    print(f"Signature: {data.player.signature}")
    print(f"Profile picture url: {data.player.avatar.icon}")
    for character in data.characters:
        print("-----------")
        print(f"Name: {character.name}")
        print(f"Rarity: {character.rarity}")
        print(f"Portrait url: {character.portrait}")

asyncio.run(v1())
asyncio.run(v2())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;from mihomo import tools&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Remove Duplicate Character&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    data = await client.fetch_user(800333171)
    data = tools.remove_duplicate_character(data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Merge Character Data&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;    old_data = await client.fetch_user(800333171)

    # Change characters in game and wait for the API to refresh
    # ...

    new_data = await client.fetch_user(800333171)
    data = tools.merge_character_data(new_data, old_data)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Data Persistence&lt;/h3&gt; 
&lt;p&gt;Take pickle and json as an example&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import pickle
import zlib
from mihomo import MihomoAPI, Language, StarrailInfoParsed

client = MihomoAPI(language=Language.EN)
data = await client.fetch_user(800333171)

# Save
pickle_data = zlib.compress(pickle.dumps(data))
print(len(pickle_data))
json_data = data.json(by_alias=True, ensure_ascii=False)
print(len(json_data))

# Load
data_from_pickle = pickle.loads(zlib.decompress(pickle_data))
data_from_json = StarrailInfoParsed.parse_raw(json_data)
print(type(data_from_pickle))
print(type(data_from_json))
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ostris/ai-toolkit</title>
      <link>https://github.com/ostris/ai-toolkit</link>
      <description>&lt;p&gt;The ultimate training toolkit for finetuning diffusion models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Toolkit by Ostris&lt;/h1&gt; 
&lt;p&gt;AI Toolkit is an all in one training suite for diffusion models. I try to support all the latest models on consumer grade hardware. Image and video models. It can be run as a GUI or CLI. It is designed to be easy to use but still have every feature imaginable.&lt;/p&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;If you enjoy my projects or use them commercially, please consider sponsoring me. Every bit helps! ğŸ’–&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/orgs/ostris"&gt;Sponsor on GitHub&lt;/a&gt; | &lt;a href="https://www.patreon.com/ostris"&gt;Support on Patreon&lt;/a&gt; | &lt;a href="https://www.paypal.com/donate/?hosted_button_id=9GEFUKC8T9R9W"&gt;Donate on PayPal&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Current Sponsors&lt;/h3&gt; 
&lt;p&gt;All of these people / organizations are the ones who selflessly make this project possible. Thank you!!&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Last updated: 2025-12-17 22:19 UTC&lt;/em&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1919488160125616128/QAZXTMEj_400x400.png" alt="a16z" width="280" height="280" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/replicate" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/60410876?v=4" alt="Replicate" width="280" height="280" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25720743?v=4" alt="Hugging Face" width="280" height="280" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.pixelcut.ai/" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1496882159658885133/11asz2Sc_400x400.jpg" alt="Pixelcut" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/weights-ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/185568492?v=4" alt="Weights" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/josephrocca" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1167575?u=92d92921b4cb5c8c7e225663fed53c4b41897736&amp;amp;v=4" alt="josephrocca" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/93304/J" alt="Joseph Rocca" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/161471720/dd330b4036d44a5985ed5985c12a5def/eyJ3IjoyMDB9/1.jpeg?token-hash=k1f4Vv7TevzYa9tqlzAjsogYmkZs8nrXQohPCDGJGkc%3D" alt="Vladimir Sotnikov" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/33158543/C" alt="clement Delangue" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/8654302/b0f5ebedc62a47c4b56222693e1254e9/eyJ3IjoyMDB9/2.jpeg?token-hash=suI7_QjKUgWpdPuJPaIkElkTrXfItHlL8ZHLPT-w_d4%3D" alt="Misch Strotz" width="200" height="200" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/120239481/49b1ce70d3d24704b8ec34de24ec8f55/eyJ3IjoyMDB9/1.jpeg?token-hash=o0y1JqSXqtGvVXnxb06HMXjQXs6OII9yMMx5WyyUqT4%3D" alt="nitish PNR" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/152118848/3b15a43d71714552b5ed1c9f84e66adf/eyJ3IjoyMDB9/1.png?token-hash=MKf3sWHz0MFPm_OAFjdsNvxoBfN5B5l54mn1ORdlRy8%3D" alt="Kristjan Retter" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2298192/1228b69bd7d7481baf3103315183250d/eyJ3IjoyMDB9/1.jpg?token-hash=opN1e4r4Nnvqbtr8R9HI8eyf9m5F50CiHDOdHzb4UcA%3D" alt="Mohamed Oumoumad" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/548524/S" alt="Steve Hanff" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/8449560/P" alt="Patron" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/169502989/220069e79ce745b29237e94c22a729df/eyJ3IjoyMDB9/1.png?token-hash=E8E2JOqx66k2zMtYUw8Gy57dw-gVqA6OPpdCmWFFSFw%3D" alt="Timothy Bielec" width="150" height="150" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/9547341/bb35d9a222fd460e862e960ba3eacbaf/eyJ3IjoyMDB9/1.jpeg?token-hash=Q2XGDvkCbiONeWNxBCTeTMOcuwTjOaJ8Z-CAf5xq3Hs%3D" alt="Travis Harrington" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/5021048/c6beacab0fdb4568bf9f0d549aa4bc44/eyJ3IjoyMDB9/1.jpeg?token-hash=JTEtFVzUeU7pQw4R3eSn6rGgqgi44uc2rDBAv6F6A4o%3D" alt="Infinite " width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://x.com/NuxZoe" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1916482710069014528/RDLnPRSg_400x400.jpg" alt="tungsten" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/E2GO" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1776669?u=bf52b2691fa7d1e421d6167b804a2c1cf3b229e7&amp;amp;v=4" alt="E2GO" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/7478272/T" alt="Totoro " width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://clwill.com/" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://images.squarespace-cdn.com/content/v1/63d444727a5d5f304f89eebe/c9def9ce-3824-404d-a8bb-96b6236338ca/favicon.ico?format=100w" alt="Christopher Williams" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="http://www.ir-ltd.net" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1602579392198283264/6Tm2GYus_400x400.jpg" alt="IR-Entertainment Ltd" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/27288932/6c35d2d961ee4e14a7a368c990791315/eyJ3IjoyMDB9/1.jpeg?token-hash=TGIto_PGEG2NEKNyqwzEnRStOkhrjb3QlMhHA3raKJY%3D" alt="David Garrido" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/33228112/J" alt="Jimmy Simmons" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://www.runcomfy.com/trainer/ai-toolkit/app" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/1747828425736273922/nlPQTDYO_400x400.jpg" alt="RunComfy" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/55206617/X" alt="xv" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/3712451/432e22a355494ec0a1ea1927ff8d452e/eyJ3IjoyMDB9/7.jpeg?token-hash=OpQ9SAfVQ4Un9dSYlGTHuApZo5GlJ797Mo0DtVtMOSc%3D" alt="David Shorey" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/80767260/1fa7b3119f9f4f40a68452e57de59bfe/eyJ3IjoyMDB9/1.jpeg?token-hash=H34Vxnd58NtbuJU1XFYPkQnraVXSynZHSL3SMMcdKbI%3D" alt="nuliajuk" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/40761075/R" alt="Randy McEntee" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/98811435/3a3632d1795b4c2b9f8f0270f2f6a650/eyJ3IjoyMDB9/1.jpeg?token-hash=657rzuJ0bZavMRZW3XZ-xQGqm3Vk6FkMZgFJVMCOPdk%3D" alt="EmmanuelMr18" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/93348210/5c650f32a0bc481d80900d2674528777/eyJ3IjoyMDB9/1.jpeg?token-hash=0jiknRw3jXqYWW6En8bNfuHgVDj4LI_rL7lSS4-_xlo%3D" alt="Armin Behjati" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/155963250/6f8fd7075c3b4247bfeb054ba49172d6/eyJ3IjoyMDB9/1.png?token-hash=z81EHmdU2cqSrwa9vJmZTV3h0LG-z9Qakhxq34FrYT4%3D" alt="Un Defined" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/squewel" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/97603184?v=4" alt="squewel" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/27791680/J" alt="Jean-Tristan Marin" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/570742/4ceb33453a5a4745b430a216aba9280f/eyJ3IjoyMDB9/1.jpg?token-hash=nPcJ2zj3sloND9jvbnbYnob2vMXRnXdRuujthqDLWlU%3D" alt="Al H" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/82763/f99cc484361d4b9d94fe4f0814ada303/eyJ3IjoyMDB9/1.jpeg?token-hash=A3JWlBNL0b24FFWb-FCRDAyhs-OAxg-zrhfBXP_axuU%3D" alt="Doron Adler" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/103077711/bb215761cc004e80bd9cec7d4bcd636d/eyJ3IjoyMDB9/2.jpeg?token-hash=3U8kdZSUpnmeYIDVK4zK9TTXFpnAud_zOwBRXx18018%3D" alt="John Dopamine" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/99036356/7ae9c4d80e604e739b68cca12ee2ed01/eyJ3IjoyMDB9/3.png?token-hash=ZhsBMoTOZjJ-Y6h5NOmU5MT-vDb2fjK46JDlpEehkVQ%3D" alt="njgnfhahfnhnwir" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/141098579/1a9f0a1249d447a7a0df718a57343912/eyJ3IjoyMDB9/2.png?token-hash=_n-AQmPgY0FP9zCGTIEsr5ka4Y7YuaMkt3qL26ZqGg8%3D" alt="The Local Lab" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://x.com/RalFingerLP" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://pbs.twimg.com/profile_images/919595465041162241/ZU7X3T5k_400x400.jpg" alt="RalFinger" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/53077895/M" alt="Marc" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/157407541/bb9d80cffdab4334ad78366060561520/eyJ3IjoyMDB9/2.png?token-hash=WYz-U_9zabhHstOT5UIa5jBaoFwrwwqyWxWEzIR2m_c%3D" alt="Tokio Studio srl IT10640050968" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/128354277/52c073d323924b02ada90c9eacc6b0a0/eyJ3IjoyMDB9/1.png?token-hash=Oc0mVzELN1s1r0lLQTEO_sfJ2lEMC3X-By2O2bG6h_Q%3D" alt="Alastair Green" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/134129880/680c7e14cd1a4d1a9face921fb010f88/eyJ3IjoyMDB9/1.png?token-hash=5fqqHE6DCTbt7gDQL7VRcWkV71jF7FvWcLhpYl5aMXA%3D" alt="Bharat Prabhakar" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/70218846/C" alt="Cosmosis" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/dylanzonix" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/167351340?v=4" alt="Dylan" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/30931983/54ab4e4ceab946e79a6418d205f9ed51/eyJ3IjoyMDB9/1.png?token-hash=j2phDrgd6IWuqKqNIDbq9fR2B3fMF-GUCQSdETS1w5Y%3D" alt="HestoySeghuro ." width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/4105384/J" alt="Jack Blakely" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/jakeblakeley" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2407659?u=be0bc786663527f2346b2e99ff608796bce19b26&amp;amp;v=4" alt="Jake Blakeley" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/47255859/7d68bf494f7645a382875fbaf901bf90/eyJ3IjoyMDB9/1.jpeg?token-hash=GUJtLcSZhj0sEvBWB1EiLXEw0hVQxr2Mf7YMUharte0%3D" alt="momen sree" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/Slartibart23" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/133593860?u=31217adb2522fb295805824ffa7e14e8f0fca6fa&amp;amp;v=4" alt="Slarti" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/97985240/3d1d0e6905d045aba713e8132cab4a30/eyJ3IjoyMDB9/1.png?token-hash=fRavvbO_yqWKA_OsJb5DzjfKZ1Yt-TG-ihMoeVBvlcM%3D" alt="×¢×•××¨ ××›×œ×•×£" width="100" height="100" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr style="width:100%;border:none;height:2px;background:#ddd;margin:30px 0;" /&gt; 
&lt;p align="center"&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/44568304/a9d83a0e786b41b4bdada150f7c9271c/eyJ3IjoyMDB9/1.jpeg?token-hash=FtxnwrSrknQUQKvDRv2rqPceX2EF23eLq4pNQYM_fmw%3D" alt="Albert Bukoski" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5048649/B" alt="Ben Ward" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/111904990/08b1cf65be6a4de091c9b73b693b3468/eyJ3IjoyMDB9/1.png?token-hash=_Odz6RD3CxtubEHbUxYujcjw6zAajbo3w8TRz249VBA%3D" alt="Brian Smith" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/494309/J" alt="Julian Tsependa" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/5602036/c7b6e02bab1241fc83ff5a0cedf19b43/eyJ3IjoyMDB9/1.jpeg?token-hash=nnd10QRNxqaHmhwr-zQh4EIlBDIFJEvt65YB3ebjhNw%3D" alt="Kelevra Quackenstien" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/358350/L" alt="L D" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/159203973/36c817f941ac4fa18103a4b8c0cb9cae/eyJ3IjoyMDB9/1.png?token-hash=zkt72HW3EoiIEAn3LSk9gJPBsXfuTVcc4rRBS3CeR8w%3D" alt="Marko jak" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/11198131/e696d9647feb4318bcf16243c2425805/eyJ3IjoyMDB9/1.jpeg?token-hash=c2c2p1SaiX86iXAigvGRvzm4jDHvIFCg298A49nIfUM%3D" alt="Nicholas Agranoff" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/785333/bdb9ede5765d42e5a2021a86eebf0d8f/eyJ3IjoyMDB9/2.jpg?token-hash=l_rajMhxTm6wFFPn7YdoKBxeUqhdRXKdy6_8SGCuNsE%3D" alt="Sapjes " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/76566911/6485eaf5ec6249a7b524ee0b979372f0/eyJ3IjoyMDB9/1.jpeg?token-hash=mwCSkTelDBaengG32NkN0lVl5mRjB-cwo6-a47wnOsU%3D" alt="the biitz" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/83034/W" alt="william tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/32633822/1ab5612efe80417cbebfe91e871fc052/eyJ3IjoyMDB9/1.png?token-hash=pOS_IU3b3RL5-iL96A3Xqoj2bQ-dDo4RUkBylcMED_s%3D" alt="Zack Abrams" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/25209707/36ae876d662d4d85aaf162b6d67d31e7/eyJ3IjoyMDB9/1.png?token-hash=Zows_A6uqlY5jClhfr4Y3QfMnDKVkS3mbxNHUDkVejo%3D" alt="fjioq8" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/46680573/ee3d99c04a674dd5a8e1ecfb926db6a2/eyJ3IjoyMDB9/1.jpeg?token-hash=cgD4EXyfZMPnXIrcqWQ5jGqzRUfqjPafb9yWfZUPB4Q%3D" alt="Neil Murray" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/julien-blanchon" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/11278197?v=4" alt="Blanchon" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Wallawalla47" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/46779408?v=4" alt="Ian R" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/63510241/A" alt="Andrew Park" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/Spikhalskiy" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/532108?u=2464983638afea8caf4cd9f0e4a7bc3e6a63bb0a&amp;amp;v=4" alt="Dmitry Spikhalsky" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/88567307/E" alt="el Chavo" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/117569999/55f75c57f95343e58402529cec852b26/eyJ3IjoyMDB9/1.jpeg?token-hash=squblHZH4-eMs3gI46Uqu1oTOK9sQ-0gcsFdZcB9xQg%3D" alt="James Thompson" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/28533016/e8f6044ccfa7483f87eeaa01c894a773/eyJ3IjoyMDB9/2.png?token-hash=ak-h3JWB50hyenCavcs32AAPw6nNhmH2nBFKpdk5hvM%3D" alt="William Tatum" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Gage Siuniak" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/11180426/J" alt="jarrett towe" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/zappazack" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/74406132?u=356e66c964f9ca4859b274ff6788aebd16e218d4&amp;amp;v=4" alt="zappazack" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/91298241/1b1e6d698cde4faaaae6fc4c2d95d257/eyJ3IjoyMDB9/1.jpeg?token-hash=GCo7gAF_UUdJqz3FsCq8p1pq3AEoRAoC6YIvy5xEeZk%3D" alt="Daniel Partzsch" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://www.youtube.com/@happyme7055" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://yt3.googleusercontent.com/ytc/AIdro_mFqhIRk99SoEWY2gvSvVp6u1SkCGMkRqYQ1OlBBeoOVp8=s160-c-k-c0x00ffffff-no-rj" alt="Marcus Rass" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/59408413/a0530a7770b6444bafdf0bc9f589eff0/eyJ3IjoyMDB9/1.jpg?token-hash=BlbxZsQpgchtqjByDuW9T8NoFWmCor5sWI0umhUKNlA%3D" alt="ByteC" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/55160464/42d4719ba0834e5d83aa989c04e762da/eyJ3IjoyMDB9/1.jpeg?token-hash=_twZUkW3NREIxGUOWskUdvuZQGEcRv9XMfu5NrnCe5M%3D" alt="Chris Canterbury" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/7208949/D" alt="D G" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/33866796/7fd2a214fd5c4062b0dd63a29f8de5bd/eyJ3IjoyMDB9/1.png?token-hash=8s-7yi8GawIlqr0FCTk5JWKy26acMiYlOD8LAk2HqqU%3D" alt="James" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/84891403/83682a2a2d3b49ba9d28e7221edd5752/eyJ3IjoyMDB9/1.jpeg?token-hash=LVB6lta4BonhfPwSUnZIDmSW3IU-eEO4sXD7NSK367g%3D" alt="Koray Birand" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/63232055/2300b4ab370341b5b476902c9b8218ee/eyJ3IjoyMDB9/1.png?token-hash=R9Nb4O0aLBRwxT1cGHUMThlvf6A2MD5SO88lpZBdH7M%3D" alt="Marek P" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/902918/5344727418634dc7b7fe7709d515a1d9/eyJ3IjoyMDB9/2.jpg?token-hash=myqV_oclkicVk9BDrvTO50jyjxJJGZ8i7oVJHwc05to%3D" alt="Michael Carychao" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/179944/P" alt="Paul Kroll" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/31613309/434500d03f714dc18049306ed3f0165c/eyJ3IjoyMDB9/1.jpg?token-hash=acILbq09wxUfJe-G2nMYUYkvHJ88ZxkzU4JebRPw2P0%3D" alt="Theta Graphics" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/10876902/T" alt="Tyssel" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/137975346/b0ac50eb2432471897ce59ddf1cb6b3d/eyJ3IjoyMDB9/1.png?token-hash=6iqhqukfgHK2IjlwTMsmBj3vratcfJ9pmxCmRkBu22s%3D" alt="GÃ¶ran Burlin" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/84873332/H" alt="Htango2" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Gary Joseph" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="keonmin lee" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="yvggeniy romanskiy" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/89623281/28d0cb75fc68439d9491f4343966f56e/eyJ3IjoyMDB9/1.jpeg?token-hash=Zt5UxtzvxDJGTPVh5Yr5rTY8JrcDsni0Mi89nZuYrp4%3D" alt="michele carlone" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/48109692/4237f732212343448ee87f5badc26e2c/eyJ3IjoyMDB9/1.jpeg?token-hash=gGqrOyctiITIyPZgjmF6YQKNf6cS9OeY4waIav3OAiU%3D" alt="Yves Poezevara" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/88656169/dd8943d7421d41bb9a8eb99f6d1279da/eyJ3IjoyMDB9/1.jpeg?token-hash=wT5j273p5pV10l81yR6kYdfYHR_yQ81xUzr3OfcSf7s%3D" alt="Ame Ame" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5155933/C" alt="Chris Dermody" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/63920575/D" alt="Dutchman5oh" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/27580949/97c7dd2456a34c71b6429612a9e20462/eyJ3IjoyMDB9/1.jpeg?token-hash=cASxwWk8joAXx4tUAHch5CvTiYBR2UOHMeJK6se5fl0%3D" alt="Gergely MadÃ¡csi" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/44200812/f84fd628abb243bbaded4203761aca29/eyJ3IjoyMDB9/1.png?token-hash=ArthznCCT4BqOSMj_9oP4ECWWHnrb8nYPUDZ6DqSvMU%3D" alt="kingroka" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/mertguvencli" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/29762151?u=16a906d90df96c8cff9ea131a575c4bc171b1523&amp;amp;v=4" alt="Mert Guvencli" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/174319926/f16dc35b5c4741bd9c79fac3a8c8044d/eyJ3IjoyMDB9/1.jpeg?token-hash=GvYgc-XaRGI8BPnoMOo_txDfW0BjVayFdcxkshPyrvg%3D" alt="Philip Ring" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/rickrender" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/121735855?u=a8187fe40cec7f3afdd7c4bb128e0cca500fc220&amp;amp;v=4" alt="renderartist" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/27667925/6dac043a087e4c498e842dfad193baae/eyJ3IjoyMDB9/1.jpeg?token-hash=0bSVQo7QMMdGxFazeM099gsR0wtf28_ZTXeLIHEbIVk%3D" alt="S.Hasan Rizvi" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/2986571/S" alt="stev " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2472633/fea4a2888ea74c029e282fcc7ba76dd0/eyJ3IjoyMDB9/1.jpeg?token-hash=9O0lv1GQqftKoo8my9NrWSrRzHu-3IT_6VpCjHYixL8%3D" alt="Teemu Berglund" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Joakim SÃ¤llstrÃ¶m" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2888571/65c717bd8a564e469c25aa5858f9821b/eyJ3IjoyMDB9/1.png?token-hash=zwMOgNEoC9hlr2KamiB7TG004gCfJ2exSRDO4dhxo5Q%3D" alt="Derrick Schultz" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5233761/N" alt="Newtown " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/7979776/P" alt="PizzaOrNot " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/82707622/3f0de2ffd6eb4074ba91e81381146e1c/eyJ3IjoyMDB9/1.jpeg?token-hash=wk6wjILO2dDHJla7gn3MH9mEKl08e7PuBDwZRUtEQAw%3D" alt="Russell Norris" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/lirexxx" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/94787562?u=ed7e681cbc200269a081c4151d6adfa6ef728f85&amp;amp;v=4" alt="Dimitar A." width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Heikki Rinkinen" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Josh Lindo" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="StrictLine e.U." width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="The Rope Dude" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Till Meyer" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Valarm, LLC" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Valarm, LLC" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Xavier Climent" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/94453070/S" alt="Speedy2023" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/151413472/1f97b80a64fd4aa69412c065246eb83d/eyJ3IjoyMDB9/1.jpeg?token-hash=nfsls-Qt-4JatAmeloyK6SRuJgXfpCf1nxBkTK7QiI0%3D" alt="Richard Spain" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/14029622/d81798dedfad4bff8b2c76e55c7b695f/eyJ3IjoyMDB9/1.png?token-hash=1qP6r5SXiAjLEly9PMFbWMo7Bl9lPahSisCSsMqYNOw%3D" alt="A1PHA " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/136770679/bfc06edc256e4e8c9d5e69669400ce80/eyJ3IjoyMDB9/1.png?token-hash=syeNGY9CgVD1D6v_EPNGafyTrzeXH_JMF3EAFyFJhvw%3D" alt="Ben May | sofsy" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/claygraffix" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1283083?v=4" alt="claygraffix" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c8.patreon.com/4/200/22711368/C" alt="CrypticWit" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="David Hooper" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/7436837/K" alt="Ken Finlayson" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/14767188/1f22bccbf86b45a2b32642c3f5a493b3/eyJ3IjoyMDB9/1.png?token-hash=cJhOEsMXSv_d5fcqCu8Q_idyYtqc4UocsOaTflsSmT8%3D" alt="Kukee" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/93681621/d638ff4a9e0a40a7bc2c24bae4d6f353/eyJ3IjoyMDB9/1.png?token-hash=AxFFly1YYJskPzdkaU_M5jgyb0kZijSxB1Yb2AbE9h0%3D" alt="Manuel2Santos" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/138787313/c809120005024afa959231fe8b253fd9/eyJ3IjoyMDB9/1.png?token-hash=O6x0kkR4uKBsg_OODFHjZqwAupVztiZEOiXYF_7yKxM%3D" alt="Metryman55" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Rudolf Goertz" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/40431966/190f07a0828d4f8190539c518c7d3115/eyJ3IjoyMDB9/1.png?token-hash=co9yehrBdxsPSKQGDB-sGQNB_g3HPfg4pckMXoCU4Ck%3D" alt="ShadowForge" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Tommy Falkowski" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Victor-Ray Valdez" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/caleboleary" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12816579?u=d7f6ec4b7caf3c4535385a5fa3d7c155057ef664&amp;amp;v=4" alt="Caleb O'Leary" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Florian Fiegl" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Karol StÄ™pieÅ„" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="manuel landron" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Paul Vu Nguyen" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/160878212/1c34e798b2a9420991bab7ccc0067463/eyJ3IjoyMDB9/1.jpeg?token-hash=V_omrlVIeWKw0vovf92DJHSft-fXiksP0Fqa-qbAUxM%3D" alt="Danwich Gaming" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/5752417/G" alt="Guillaume Roy" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/154134231/5d307160968b4c29922e2729bb555c99/eyJ3IjoyMDB9/1.jpeg?token-hash=dNP94e42G_A9CHO5zYfUunS2K80y3BPDHQ3NdzphNRY%3D" alt="Colin Boyd" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/122373805/d0d995f2a7d6483cbbe0e9b14391d1ed/eyJ3IjoyMDB9/1.png?token-hash=oQCZooskREZOB36TW0KNZASDeLc88yswNzF-PqcVQyw%3D" alt="DavidO" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/2697420/C" alt="Craig Penn" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/45804549/8117b86a8c4145348ed392d3ea8c9dde/eyJ3IjoyMDB9/2.png?token-hash=ej_ln6ecs0-Cija3vrXaWYFFyWEK2TWmItJE5ALWP4s%3D" alt="Jadev1311" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/194433979/a18cf671feef435c9a93080f11cc8cf3/eyJ3IjoyMDB9/1.png?token-hash=TN6zMy2-V1Wg5uSpZHstYAZAdb_DYk9Erk3XDjE8--M%3D" alt="Cyril Diagne" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/29010107/37b05d32281f460baa28b4a2d5f8dd52/eyJ3IjoyMDB9/3.jpg?token-hash=5FngEN5rK-hCAgHUM0EybhMTuHwRZI1gbbZyntuuH6g%3D" alt="Adel Gamal" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/15407925/B" alt="Brian M" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/17697321/C" alt="Chris Day" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/73708729/52866102958248c19e646b6b62c7c51a/eyJ3IjoyMDB9/1.png?token-hash=S_haqcc-5zBK1tefXbphLzvA-MGtmstPNlaHch3k4zo%3D" alt="Cora Nox" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/5103404/7dd6a7be5dd640038c426c61419a5aad/eyJ3IjoyMDB9/2.jpg?token-hash=7ref-eq7sSeODxCWYcfh-wrQkhnS8L4ujGIWjlV8HdE%3D" alt="Corey Corza" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/12844508/fd08528fbed74a359acb1f8d06181c0c/eyJ3IjoyMDB9/1.jpeg?token-hash=TNDGh5TSWmlteKxsvB6FLE9wwawPMyvNBaim2U2KRC4%3D" alt="Dave Talbott" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/49455/F" alt="freke70 " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/58082790/5f425b9f949047f78d9ae98e86faad35/eyJ3IjoyMDB9/1.png?token-hash=WYfg_M7cLsY-crrv71jcy6LLV77bB0_uD2_aw2f9nJ0%3D" alt="Greg Lemons" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/195837329/a136ba74b4d94df3a2b37e944beb6b9d/eyJ3IjoyMDB9/1.png?token-hash=oAIpcAmkts3GjjTjJVg2QrYs4UdcXgbW8q11p4kjVqQ%3D" alt="Greg Richards" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/100521338/J" alt="Jayson King" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/12128150/J" alt="Joshua Genke" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/75353/cff7a01bb97a45bba9023f1ff4a5f07a/eyJ3IjoyMDB9/1.jpeg?token-hash=3TxvQTWQSYWeqK4Elb6lX9y5ts21jh5jsWa1cXykcG8%3D" alt="Kenneth Loebenberg" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/31096978/f36222d290d2438cba8cfa3de63453c9/eyJ3IjoyMDB9/1.JPG?token-hash=0gwLI-GVquqxBj3FRR4XqJuRonvT5FsN5rdND2jApL0%3D" alt="Le_Fourbe " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/97609519/M" alt="Mollie" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/683426/N" alt="Noodles" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c8.patreon.com/4/200/4544036/O" alt="Osman Bayazit" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/106121692/060eb9f09ecc4dceb7fa0a6d3c330b85/eyJ3IjoyMDB9/1.jpeg?token-hash=K6vA5Foyh9tAy3yzCtuYKDRF9McrCbQaEUC61x2x1Ic%3D" alt="Pablo Fonseca" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/188726649/6db3706d63f14468a58535ae5fd1344c/eyJ3IjoyMDB9/1.png?token-hash=QzCqu543VaxIuxyXo_1qrYqBQAyOhprcfNfNSIN3TYk%3D" alt="Phil Ring" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/ProPatte" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/228614493?u=45908a4a76165a83ce0b20a474a4d7fd027d67af&amp;amp;v=4" alt="ProPatte" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/196027905/1d46e7eeaf7e45229bbbf0f64683f337/eyJ3IjoyMDB9/1.jpeg?token-hash=JkpA_7525wqMEeVAFU6Qb7AK4lrAnjtisI7i4U8NrwI%3D" alt="qassem benhayoun" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/25199293/e967e5c4ed884f07b705271e253fd584/eyJ3IjoyMDB9/1.png?token-hash=uupXPicJ3Glks9mm5WDriIb1PBUbRmoVgSR6vcMPjlY%3D" alt="Rob Stevens" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/2622685/bddc4b42c82c47d8b30b05c000b8127b/eyJ3IjoyMDB9/1.jpg?token-hash=4tEFL9DP2L5dpg7rxUcFBlw27qnHO2ceyG38RtI9_Hg%3D" alt="Saftle " width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/45125613/8a45d1081bfc43b0bf4cb523558cab65/eyJ3IjoyMDB9/3.jpeg?token-hash=iUZhvndnfAiT97FacklmB4XvnMxj0pvepaHsU7JBxLg%3D" alt="Tiny Tsuruta" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/7408850/e90af02547724fc59ca1f21565df93b1/eyJ3IjoyMDB9/1.png?token-hash=RnqIUjFVhT7ZpV79q8cgTxCULkVfyQxpWNy4yIQIhlk%3D" alt="Virtamouse" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/107652364/5cae258ff5cd4c9a8e104861e63d5180/eyJ3IjoyMDB9/1.png?token-hash=qkRK53prBXDFG4b_Opnb80wcvWj6q0FjgNqPoSz24yU%3D" alt="Yi Chen" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Boris HANSSEN" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Juan Franco" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;a href="https://github.com/marksverdhei" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://avatars.githubusercontent.com/u/46672778?u=d1ba8b17516e6ecf1cd55ca4db2b770f82285aad&amp;amp;v=4" alt="Markus / Mark" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt;&lt;/a&gt; &lt;img src="https://c10.patreonusercontent.com/4/patreon-media/p/user/134029856/d1c895bf165149f69ad81ac426e617e9/eyJ3IjoyMDB9/1.jpeg?token-hash=FPzyMI3pAjnZmRlH_nmy2baIRcGKtQrDnN6aMCOHVwo%3D" alt="v33ts" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;img src="https://ostris.com/wp-content/uploads/2025/08/supporter_default.jpg" alt="Fabrizio Pasqualicchio" width="60" height="60" style="border-radius:8px;margin:5px;display: inline-block;" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;python &amp;gt;3.10&lt;/li&gt; 
 &lt;li&gt;Nvidia GPU with enough ram to do what you need&lt;/li&gt; 
 &lt;li&gt;python venv&lt;/li&gt; 
 &lt;li&gt;git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python3 -m venv venv
source venv/bin/activate
# install torch first
pip3 install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows:&lt;/p&gt; 
&lt;p&gt;If you are having issues with Windows. I recommend using the easy install script at &lt;a href="https://github.com/Tavris1/AI-Toolkit-Easy-Install"&gt;https://github.com/Tavris1/AI-Toolkit-Easy-Install&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
python -m venv venv
.\venv\Scripts\activate
pip install --no-cache-dir torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;AI Toolkit UI&lt;/h1&gt; 
&lt;img src="https://ostris.com/wp-content/uploads/2025/02/toolkit-ui.jpg" alt="AI Toolkit UI" width="100%" /&gt; 
&lt;p&gt;The AI Toolkit UI is a web interface for the AI Toolkit. It allows you to easily start, stop, and monitor jobs. It also allows you to easily train models with a few clicks. It also allows you to set a token for the UI to prevent unauthorized access so it is mostly safe to run on an exposed server.&lt;/p&gt; 
&lt;h2&gt;Running the UI&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js &amp;gt; 18&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The UI does not need to be kept running for the jobs to run. It is only needed to start/stop/monitor jobs. The commands below will install / update the UI and it's dependencies and start the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ui
npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now access the UI at &lt;code&gt;http://localhost:8675&lt;/code&gt; or &lt;code&gt;http://&amp;lt;your-ip&amp;gt;:8675&lt;/code&gt; if you are running it on a server.&lt;/p&gt; 
&lt;h2&gt;Securing the UI&lt;/h2&gt; 
&lt;p&gt;If you are hosting the UI on a cloud provider or any network that is not secure, I highly recommend securing it with an auth token. You can do this by setting the environment variable &lt;code&gt;AI_TOOLKIT_AUTH&lt;/code&gt; to super secure password. This token will be required to access the UI. You can set this when starting the UI like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Linux
AI_TOOLKIT_AUTH=super_secure_password npm run build_and_start

# Windows
set AI_TOOLKIT_AUTH=super_secure_password &amp;amp;&amp;amp; npm run build_and_start

# Windows Powershell
$env:AI_TOOLKIT_AUTH="super_secure_password"; npm run build_and_start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FLUX.1 Training&lt;/h2&gt; 
&lt;h3&gt;Tutorial&lt;/h3&gt; 
&lt;p&gt;To get started quickly, check out &lt;a href="https://x.com/araminta_k"&gt;@araminta_k&lt;/a&gt; tutorial on &lt;a href="https://www.youtube.com/watch?v=HzGW_Kyermg"&gt;Finetuning Flux Dev on a 3090&lt;/a&gt; with 24GB VRAM.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;You currently need a GPU with &lt;strong&gt;at least 24GB of VRAM&lt;/strong&gt; to train FLUX.1. If you are using it as your GPU to control your monitors, you probably need to set the flag &lt;code&gt;low_vram: true&lt;/code&gt; in the config file under &lt;code&gt;model:&lt;/code&gt;. This will quantize the model on CPU and should allow it to train with monitors attached. Users have gotten it to work on Windows with WSL, but there are some reports of a bug when running on windows natively. I have only tested on linux for now. This is still extremely experimental and a lot of quantizing and tricks had to happen to get it to fit on 24GB at all.&lt;/p&gt; 
&lt;h3&gt;FLUX.1-dev&lt;/h3&gt; 
&lt;p&gt;FLUX.1-dev has a non-commercial license. Which means anything you train will inherit the non-commercial license. It is also a gated model, so you need to accept the license on HF before using it. Otherwise, this will fail. Here are the required steps to setup a license.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign into HF and accept the model access here &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;black-forest-labs/FLUX.1-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Make a file named &lt;code&gt;.env&lt;/code&gt; in the root on this folder&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/settings/tokens/new?"&gt;Get a READ key from huggingface&lt;/a&gt; and add it to the &lt;code&gt;.env&lt;/code&gt; file like so &lt;code&gt;HF_TOKEN=your_key_here&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;FLUX.1-schnell&lt;/h3&gt; 
&lt;p&gt;FLUX.1-schnell is Apache 2.0. Anything trained on it can be licensed however you want and it does not require a HF_TOKEN to train. However, it does require a special adapter to train with it, &lt;a href="https://huggingface.co/ostris/FLUX.1-schnell-training-adapter"&gt;ostris/FLUX.1-schnell-training-adapter&lt;/a&gt;. It is also highly experimental. For best overall quality, training on FLUX.1-dev is recommended.&lt;/p&gt; 
&lt;p&gt;To use it, You just need to add the assistant to the &lt;code&gt;model&lt;/code&gt; section of your config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      model:
        name_or_path: "black-forest-labs/FLUX.1-schnell"
        assistant_lora_path: "ostris/FLUX.1-schnell-training-adapter"
        is_flux: true
        quantize: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You also need to adjust your sample steps since schnell does not require as many&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      sample:
        guidance_scale: 1  # schnell does not do guidance
        sample_steps: 4  # 1 - 4 works well
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Training&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy the example config file located at &lt;code&gt;config/examples/train_lora_flux_24gb.yaml&lt;/code&gt; (&lt;code&gt;config/examples/train_lora_flux_schnell_24gb.yaml&lt;/code&gt; for schnell) to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Edit the file following the comments in the file&lt;/li&gt; 
 &lt;li&gt;Run the file like so &lt;code&gt;python run.py config/whatever_you_want.yml&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A folder with the name and the training folder from the config file will be created when you start. It will have all checkpoints and images in it. You can stop the training at any time using ctrl+c and when you resume, it will pick back up from the last checkpoint.&lt;/p&gt; 
&lt;p&gt;IMPORTANT. If you press crtl+c while it is saving, it will likely corrupt that checkpoint. So wait until it is done saving&lt;/p&gt; 
&lt;h3&gt;Need help?&lt;/h3&gt; 
&lt;p&gt;Please do not open a bug report unless it is a bug in the code. You are welcome to &lt;a href="https://discord.gg/VXmU2f5WEU"&gt;Join my Discord&lt;/a&gt; and ask for help there. However, please refrain from PMing me directly with general question or support. Ask in the discord and I will answer when I can.&lt;/p&gt; 
&lt;h2&gt;Gradio UI&lt;/h2&gt; 
&lt;p&gt;To get started training locally with a with a custom UI, once you followed the steps above and &lt;code&gt;ai-toolkit&lt;/code&gt; is installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai-toolkit #in case you are not yet in the ai-toolkit folder
huggingface-cli login #provide a `write` token to publish your LoRA at the end
python flux_train_ui.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will instantiate a UI that will let you upload your images, caption them, train and publish your LoRA &lt;img src="https://raw.githubusercontent.com/ostris/ai-toolkit/main/assets/lora_ease_ui.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Training in RunPod&lt;/h2&gt; 
&lt;p&gt;If you would like to use Runpod, but have not signed up yet, please consider using &lt;a href="https://runpod.io?ref=h0y9jyr2"&gt;my Runpod affiliate link&lt;/a&gt; to help support this project.&lt;/p&gt; 
&lt;p&gt;I maintain an official Runpod Pod template here which can be accessed &lt;a href="https://console.runpod.io/deploy?template=0fqzfjy6f3&amp;amp;ref=h0y9jyr2"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;I have also created a short video showing how to get started using AI Toolkit with Runpod &lt;a href="https://youtu.be/HBNeS-F6Zz8"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Training in Modal&lt;/h2&gt; 
&lt;h3&gt;1. Setup&lt;/h3&gt; 
&lt;h4&gt;ai-toolkit:&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/ostris/ai-toolkit.git
cd ai-toolkit
git submodule update --init --recursive
python -m venv venv
source venv/bin/activate
pip install torch
pip install -r requirements.txt
pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Modal:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run &lt;code&gt;pip install modal&lt;/code&gt; to install the modal Python package.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;modal setup&lt;/code&gt; to authenticate (if this doesnâ€™t work, try &lt;code&gt;python -m modal setup&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Hugging Face:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get a READ token from &lt;a href="https://huggingface.co/settings/tokens"&gt;here&lt;/a&gt; and request access to Flux.1-dev model from &lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;huggingface-cli login&lt;/code&gt; and paste your token.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. Upload your dataset&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Drag and drop your dataset folder containing the .jpg, .jpeg, or .png images and .txt files in &lt;code&gt;ai-toolkit&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. Configs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Copy an example config file located at &lt;code&gt;config/examples/modal&lt;/code&gt; to the &lt;code&gt;config&lt;/code&gt; folder and rename it to &lt;code&gt;whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Edit the config following the comments in the file, &lt;strong&gt;&lt;ins&gt;be careful and follow the example &lt;code&gt;/root/ai-toolkit&lt;/code&gt; paths&lt;/ins&gt;&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Edit run_modal.py&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Set your entire local &lt;code&gt;ai-toolkit&lt;/code&gt; path at &lt;code&gt;code_mount = modal.Mount.from_local_dir&lt;/code&gt; like:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;code_mount = modal.Mount.from_local_dir("/Users/username/ai-toolkit", remote_path="/root/ai-toolkit")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose a &lt;code&gt;GPU&lt;/code&gt; and &lt;code&gt;Timeout&lt;/code&gt; in &lt;code&gt;@app.function&lt;/code&gt; &lt;em&gt;(default is A100 40GB and 2 hour timeout)&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Training&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the config file in your terminal: &lt;code&gt;modal run run_modal.py --config-file-list-str=/root/ai-toolkit/config/whatever_you_want.yml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can monitor your training in your local terminal, or on &lt;a href="https://modal.com/"&gt;modal.com&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Models, samples and optimizer will be stored in &lt;code&gt;Storage &amp;gt; flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;6. Saving the model&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check contents of the volume by running &lt;code&gt;modal volume ls flux-lora-models&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the content by running &lt;code&gt;modal volume get flux-lora-models your-model-name&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Example: &lt;code&gt;modal volume get flux-lora-models my_first_flux_lora_v1&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Screenshot from Modal&lt;/h3&gt; 
&lt;img width="1728" alt="Modal Traning Screenshot" src="https://github.com/user-attachments/assets/7497eb38-0090-49d6-8ad9-9c8ea7b5388b" /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Dataset Preparation&lt;/h2&gt; 
&lt;p&gt;Datasets generally need to be a folder containing images and associated text files. Currently, the only supported formats are jpg, jpeg, and png. Webp currently has issues. The text files should be named the same as the images but with a &lt;code&gt;.txt&lt;/code&gt; extension. For example &lt;code&gt;image2.jpg&lt;/code&gt; and &lt;code&gt;image2.txt&lt;/code&gt;. The text file should contain only the caption. You can add the word &lt;code&gt;[trigger]&lt;/code&gt; in the caption file and if you have &lt;code&gt;trigger_word&lt;/code&gt; in your config, it will be automatically replaced.&lt;/p&gt; 
&lt;p&gt;Images are never upscaled but they are downscaled and placed in buckets for batching. &lt;strong&gt;You do not need to crop/resize your images&lt;/strong&gt;. The loader will automatically resize them and can handle varying aspect ratios.&lt;/p&gt; 
&lt;h2&gt;Training Specific Layers&lt;/h2&gt; 
&lt;p&gt;To train specific layers with LoRA, you can use the &lt;code&gt;only_if_contains&lt;/code&gt; network kwargs. For instance, if you want to train only the 2 layers used by The Last Ben, &lt;a href="https://x.com/__TheBen/status/1829554120270987740"&gt;mentioned in this post&lt;/a&gt;, you can adjust your network kwargs like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks.7.proj_out"
            - "transformer.single_transformer_blocks.20.proj_out"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The naming conventions of the layers are in diffusers format, so checking the state dict of a model will reveal the suffix of the name of the layers you want to train. You can also use this method to only train specific groups of weights. For instance to only train the &lt;code&gt;single_transformer&lt;/code&gt; for FLUX.1, you can use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          only_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also exclude layers by their names by using &lt;code&gt;ignore_if_contains&lt;/code&gt; network kwarg. So to exclude all the single transformer blocks,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lora"
        linear: 128
        linear_alpha: 128
        network_kwargs:
          ignore_if_contains:
            - "transformer.single_transformer_blocks."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;ignore_if_contains&lt;/code&gt; takes priority over &lt;code&gt;only_if_contains&lt;/code&gt;. So if a weight is covered by both, if will be ignored.&lt;/p&gt; 
&lt;h2&gt;LoKr Training&lt;/h2&gt; 
&lt;p&gt;To learn more about LoKr, read more about it at &lt;a href="https://github.com/KohakuBlueleaf/LyCORIS/raw/main/docs/Guidelines.md"&gt;KohakuBlueleaf/LyCORIS&lt;/a&gt;. To train a LoKr model, you can adjust the network type in the config file like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;      network:
        type: "lokr"
        lokr_full_rank: true
        lokr_factor: 8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Everything else should work the same including layer targeting.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Only larger updates are listed here. There are usually smaller daily updated that are omitted.&lt;/p&gt; 
&lt;h3&gt;Jul 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make it easy to add control images to the samples in the ui&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Jul 11, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added better video config settings to the UI for video models.&lt;/li&gt; 
 &lt;li&gt;Added Wan I2V training to the UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 29, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue where Kontext forced sizes on sampling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 26, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for FLUX.1 Kontext training&lt;/li&gt; 
 &lt;li&gt;added support for instruction dataset training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 25, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for OmniGen2 training&lt;/li&gt; 
 &lt;li&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 17, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Performance optimizations for batch preparation&lt;/li&gt; 
 &lt;li&gt;Added some docs via a popup for items in the simple ui explaining what settings do. Still a WIP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 16, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hide control images in the UI when viewing datasets&lt;/li&gt; 
 &lt;li&gt;WIP on mean flow loss&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 12, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed issue that resulted in blank captions in the dataloader&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;June 10, 2025&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Decided to keep track up updates in the readme&lt;/li&gt; 
 &lt;li&gt;Added support for SDXL in the UI&lt;/li&gt; 
 &lt;li&gt;Added support for SD 1.5 in the UI&lt;/li&gt; 
 &lt;li&gt;Fixed UI Wan 2.1 14b name bug&lt;/li&gt; 
 &lt;li&gt;Added support for for conv training in the UI for models that support it&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>TEN-framework/ten-framework</title>
      <link>https://github.com/TEN-framework/ten-framework</link>
      <description>&lt;p&gt;Open-source framework for conversational voice AI agents&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="readme-top"&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/799584b2-61ff-4255-bdd1-2548d0fdba52" alt="Image" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ten-framework/ten-framework?color=369eff&amp;amp;labelColor=gray&amp;amp;logo=github&amp;amp;style=flat-square" alt="TEN Releases" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/TEN-framework/ten-framework?branch=main"&gt;&lt;img src="https://coveralls.io/repos/github/TEN-framework/ten-framework/badge.svg?branch=main" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/ten-framework/ten-framework?labelColor=gray&amp;amp;style=flat-square" alt="Release Date" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/TEN-framework/ten-framework?labelColor=gray&amp;amp;color=pink" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/issues"&gt;&lt;img src="https://img.shields.io/github/issues-search?query=repo%3ATEN-framework%2Ften-framework%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=gray&amp;amp;color=green" alt="Issues closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ten-framework/ten-framework?color=c4f042&amp;amp;labelColor=gray&amp;amp;style=flat-square" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0_with_certain_conditions-blue.svg?labelColor=%20%23155EEF&amp;amp;color=%20%23528bff" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-lightgrey" alt="README in English" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-lightgrey" alt="ç®€ä½“ä¸­æ–‡æ“ä½œæŒ‡å—" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-JP.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-lightgrey" alt="æ—¥æœ¬èªã®README" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-lightgrey" alt="README in í•œêµ­ì–´" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-ES.md"&gt;&lt;img src="https://img.shields.io/badge/Espa%C3%B1ol-lightgrey" alt="README en EspaÃ±ol" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-FR.md"&gt;&lt;img src="https://img.shields.io/badge/Fran%C3%A7ais-lightgrey" alt="README en FranÃ§ais" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-IT.md"&gt;&lt;img src="https://img.shields.io/badge/Italiano-lightgrey" alt="README in Italiano" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11978"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11978" alt="TEN-framework%2Ften_framework | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://theten.ai"&gt;Official Site&lt;/a&gt; â€¢ &lt;a href="https://theten.ai/docs"&gt;Documentation&lt;/a&gt; â€¢ &lt;a href="https://theten.ai/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of Contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#welcome-to-ten"&gt;Welcome to TEN&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#agent-examples"&gt;Agent Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#quick-start-with-agent-examples"&gt;Quick Start with Agent Examples&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#localhost"&gt;Localhost&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#codespaces"&gt;Codespaces&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#agent-examples-self-hosting"&gt;Agent Examples Self-Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#deploying-with-docker"&gt;Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#deploying-with-other-cloud-services"&gt;Deploying with other cloud services&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#stay-tuned"&gt;Stay Tuned&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#ten-ecosystem"&gt;TEN Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#questions"&gt;Questions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#code-contributors"&gt;Code Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contribution-guidelines"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Welcome to TEN&lt;/h2&gt; 
&lt;p&gt;TEN is an open-source framework for real-time multimodal conversational AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#ten-ecosystem"&gt;TEN Ecosystem&lt;/a&gt; includes &lt;a href="https://github.com/ten-framework/ten-framework"&gt;TEN Framework&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/agents/examples"&gt;Agent Examples&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-vad"&gt;VAD&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;Turn Detection&lt;/a&gt; and &lt;a href="https://github.com/ten-framework/portal"&gt;Portal&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Community Channel&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=TenFramework"&gt;&lt;img src="https://img.shields.io/twitter/follow/TenFramework?logo=X&amp;amp;color=%20%23f5f5f5" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on X for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/VnPftUzAMJ"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20TEN%20Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord TEN Community" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Discord community to connect with developers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/company/ten-framework"&gt;&lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-TEN_Framework-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="Follow on LinkedIn" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on LinkedIn for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/TEN-framework"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-TEN%20Framework-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face Space" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Hugging Face community to explore our spaces and models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/discussions/170"&gt;&lt;img src="https://img.shields.io/badge/TEN_Framework-WeChat_Group-%2307C160?logo=wechat&amp;amp;labelColor=darkgreen&amp;amp;color=gray" alt="WeChat" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our WeChat group for Chinese community discussions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent Examples&lt;/h2&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/dce3db80-fb48-4e2a-8ac7-33f50bcffa32" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Multi-Purpose Voice Assistant&lt;/strong&gt; â€” This low-latency, high-quality real-time assistant supports both RTC and &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/websocket-example"&gt;WebSocket&lt;/a&gt; connections, and you can extend it with &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-memU"&gt;Memory&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-ten-vad"&gt;VAD&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-with-turn-detection"&gt;Turn Detection&lt;/a&gt;, and other extensions.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant"&gt;Example code&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/51ab1504-b67c-49d4-8a7a-5582d9b254da" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Lip Sync Avatars&lt;/strong&gt; â€” Works with multiple avatar vendors, the main character features Kei, an anime character with MotionSync-powered lip sync, and also supports realistic avatars from Trulience, HeyGen, and Tavus.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-live2d"&gt;Example code&lt;/a&gt; for different Live2D characters.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/f94b21b8-9dda-4efc-9274-b028cc01296a" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Speech Diarization&lt;/strong&gt; â€” Real-time diarization that detects and labels speakers, the Who Likes What game shows an interactive use case.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/speechmatics-diarization"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/6ed5b04d-945a-4a30-a1cc-f8014b602b38" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SIP Call&lt;/strong&gt; â€” SIP extension that enables phone calls powered by TEN.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/voice-assistant-sip-twilio"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/d793bc6c-c8de-4996-bd85-9ce88c69dd8d" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Transcription&lt;/strong&gt; â€” A transcription tool that transcribes audio to text.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/agents/examples/transcription"&gt;Example code&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3d60f1ff-0f82-4fe7-b5c2-ac03d284f60c" alt="Image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ESP32-S3 Korvo V3&lt;/strong&gt; â€” Runs TEN agent example on the Espressif ESP32-S3 Korvo V3 development board to integrate LLM-powered communication with hardware.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/ai_agents/esp32-client"&gt;integration guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Quick Start with Agent Examples&lt;/h2&gt; 
&lt;h3&gt;Localhost&lt;/h3&gt; 
&lt;h4&gt;Step â“µ - Prerequisites&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Keys&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ Agora &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App ID&lt;/a&gt; and &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App Certificate&lt;/a&gt;&lt;br /&gt;â€¢ &lt;a href="https://openai.com/index/openai-api/"&gt;OpenAI&lt;/a&gt; API key&lt;br /&gt;â€¢ &lt;a href="https://deepgram.com/"&gt;Deepgram&lt;/a&gt; ASR &lt;br /&gt;â€¢ &lt;a href="https://elevenlabs.io/"&gt;ElevenLabs&lt;/a&gt; TTS&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; / &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;br /&gt;â€¢ &lt;a href="https://nodejs.org/en"&gt;Node.js (LTS) v18&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Minimum System Requirements&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ CPU &amp;gt;= 2 cores&lt;br /&gt;â€¢ RAM &amp;gt;= 4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;!-- &gt; [!NOTE]
&gt; **macOS: Docker setting on Apple Silicon**
&gt;
&gt; Uncheck "Use Rosetta for x86/amd64 emulation" in Docker settings, it may result in slower build times on ARM, but performance will be normal when deployed to x64 servers. --&gt; 
&lt;h4&gt;Step â“¶ - Build agent examples in VM&lt;/h4&gt; 
&lt;h5&gt;1. Clone the repo, &lt;code&gt;cd&lt;/code&gt; into &lt;code&gt;ai_agents&lt;/code&gt;, and create a &lt;code&gt;.env&lt;/code&gt; file from &lt;code&gt;.env.example&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
cp ./.env.example ./.env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;2. Set up the Agora App ID and App Certificate in &lt;code&gt;.env&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AGORA_APP_ID=
AGORA_APP_CERTIFICATE=

# Deepgram (required for speech-to-text)
DEEPGRAM_API_KEY=

# OpenAI (required for language model)
OPENAI_API_KEY=

# ElevenLabs (required for text-to-speech)
ELEVENLABS_TTS_KEY=
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;3. Start agent development containers&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;4. Enter the container&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it ten_agent_dev bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;5. Build the agent with the default example (~5-8 min)&lt;/h5&gt; 
&lt;p&gt;Check the &lt;code&gt;agents/examples&lt;/code&gt; folder for additional samples. Start with one of these defaults:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# use the chained voice assistant
cd agents/examples/voice-assistant

# or use the speech-to-speech voice assistant in real time
cd agents/examples/voice-assistant-realtime
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;6. Start the web server&lt;/h5&gt; 
&lt;p&gt;Run &lt;code&gt;task build&lt;/code&gt; if you changed any local source code. This step is required for compiled languages (for example, TypeScript or Go) and not needed for Python.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;task install
task run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;7. Access the agent&lt;/h5&gt; 
&lt;p&gt;Once the agent example is running, you can access the following interfaces:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;localhost:49483&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;localhost:3000&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/191a7c0a-d8e6-48f9-866f-6a70c58f0118" alt="Screenshot 1" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/13e482b6-d907-4449-a779-9454bb24c0b1" alt="Screenshot 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;TMAN Designer: &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Agent Examples UI: &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h4&gt;Step â“· - Customize your agent example&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Right-click the STT, LLM, and TTS extensions.&lt;/li&gt; 
 &lt;li&gt;Open their properties and enter the corresponding API keys.&lt;/li&gt; 
 &lt;li&gt;Submit your changes, now you can see the updated Agent Example in &lt;a href="http://localhost:3000"&gt;localhost:3000&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;Run a transcriber app from TEN Manager without Docker (Beta)&lt;/h4&gt; 
&lt;p&gt;TEN also provides a transcriber app that you can run from TEN Manager without using Docker.&lt;/p&gt; 
&lt;p&gt;Check the &lt;a href="https://theten.ai/docs/ten_framework/getting-started/quick-start"&gt;quick start guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;Codespaces&lt;/h3&gt; 
&lt;p&gt;GitHub offers free Codespaces for each repository. You can run Agent Examples in Codespaces without using Docker. Codespaces typically start faster than local Docker environments.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/ten-framework/ten-agent"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/docs/ten_agent_examples/setup_development_env/setting_up_development_inside_codespace"&gt;this guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Agent Examples Self-Hosting&lt;/h2&gt; 
&lt;h3&gt;Deploying with Docker&lt;/h3&gt; 
&lt;p&gt;Once you have customized your agent (either by using the TMAN Designer or editing &lt;code&gt;property.json&lt;/code&gt; directly), you can deploy it by creating a release Docker image for your service.&lt;/p&gt; 
&lt;h5&gt;Release as Docker image&lt;/h5&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The following commands need to be executed outside of any Docker container.&lt;/p&gt; 
&lt;h6&gt;Build image&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
docker build -f agents/examples/&amp;lt;example-name&amp;gt;/Dockerfile -t example-app .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;Run&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it --env-file .env -p 3000:3000 example-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;Deploying with other cloud services&lt;/h3&gt; 
&lt;p&gt;You can split the deployment into two pieces when you want to host TEN on providers such as &lt;a href="https://vercel.com"&gt;Vercel&lt;/a&gt; or &lt;a href="https://www.netlify.com"&gt;Netlify&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the TEN backend on any container-friendly platform (a VM with Docker, Fly.io, Render, ECS, Cloud Run, or similar). Use the example Docker image without modifying it and expose port &lt;code&gt;8080&lt;/code&gt; from that service.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy only the frontend to Vercel or Netlify. Point the project root to &lt;code&gt;ai_agents/agents/examples/&amp;lt;example&amp;gt;/frontend&lt;/code&gt;, run &lt;code&gt;pnpm install&lt;/code&gt; (or &lt;code&gt;bun install&lt;/code&gt;) followed by &lt;code&gt;pnpm build&lt;/code&gt; (or &lt;code&gt;bun run build&lt;/code&gt;), and keep the default &lt;code&gt;.next&lt;/code&gt; output directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Configure environment variables in your hosting dashboard so that &lt;code&gt;AGENT_SERVER_URL&lt;/code&gt; points to the backend URL, and add any &lt;code&gt;NEXT_PUBLIC_*&lt;/code&gt; keys the UI needs (for example, Agora credentials you surface to the browser).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure your backend accepts requests from the frontend origin â€” via open CORS or by using the built-in proxy middleware.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;With this setup, the backend handles long-running worker processes, while the hosted frontend simply forwards API traffic to it.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Stay Tuned&lt;/h2&gt; 
&lt;p&gt;Get instant notifications for new releases and updates. Your support helps us grow and improve TEN!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/72c6cc46-a2a2-484d-82a9-f3079269c815" alt="Image" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;TEN Ecosystem&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Preview&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-framework"&gt;&lt;strong&gt;ï¸TEN Framework&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Open-source framework for conversational AI Agents.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-framework?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/799584b2-61ff-4255-bdd1-2548d0fdba52" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-vad"&gt;&lt;strong&gt;TEN VAD&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Low-latency, lightweight and high-performance streaming voice activity detector (VAD).&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-vad?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e504135e-67fd-4fa1-b0e4-d495358d8aa5" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;&lt;strong&gt;ï¸ TEN Turn Detection&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN Turn Detection enables full-duplex dialogue communication.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-turn-detection?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/c72d82cc-3667-496c-8bd6-3d194a91c452" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/agents/examples"&gt;&lt;strong&gt;TEN Agent Examples&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;Usecases powered by TEN.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7f735633-c7f6-4432-b6b4-d2a2977ca588" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/portal"&gt;&lt;strong&gt;TEN Portal&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;The official site of the TEN Framework with documentation and a blog.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/portal?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f56c75b9-722c-4156-902d-ae98ce2b3b5e" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Questions&lt;/h2&gt; 
&lt;p&gt;TEN Framework is available on these AI-powered Q&amp;amp;A platforms. They can help you find answers quickly and accurately in multiple languages, covering everything from basic setup to advanced implementation details.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepWiki&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ReadmeX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all forms of open-source collaboration! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas, your contributions help advance personalized AI tools. Check out our GitHub Issues and Projects to find ways to contribute and show your skills. Together, we can build something amazing!&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Welcome all kinds of contributions&lt;/strong&gt; ğŸ™&lt;/p&gt; 
 &lt;p&gt;Join us in building TEN better! Every contribution makes a difference, from code to documentation. Share your TEN Agent projects on social media to inspire others!&lt;/p&gt; 
 &lt;p&gt;Connect with one of the TEN maintainers &lt;a href="https://x.com/elliotchen200"&gt;@elliotchen200&lt;/a&gt; on ğ• or &lt;a href="https://github.com/cyfyifanchen"&gt;@cyfyifanchen&lt;/a&gt; on GitHub for project updates, discussions, and collaboration opportunities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;Code Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=TEN-framework/ten-framework" alt="TEN" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome! Please read the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/docs/code-of-conduct/contributing.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/aec54c94-ced9-4683-ae58-0a5a7ed803bd#gh-light-mode-only" alt="divider" /&gt; &lt;img src="https://github.com/user-attachments/assets/d57fad08-4f49-4a1c-bdfc-f659a5d86150#gh-dark-mode-only" alt="divider" /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The entire TEN framework (except for the folders explicitly listed below) is released under the Apache License, Version 2.0, with additional restrictions. For details, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/LICENSE"&gt;LICENSE&lt;/a&gt; file located in the root directory of the TEN framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The components within the &lt;code&gt;packages&lt;/code&gt; directory are released under the Apache License, Version 2.0. For details, please refer to the &lt;code&gt;LICENSE&lt;/code&gt; file located in each package's root directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The third-party libraries used by the TEN framework are listed and described in detail. For more information, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/third_party/"&gt;third_party&lt;/a&gt; folder.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- Navigation --&gt; 
&lt;!-- Header badges --&gt; 
&lt;!-- Localized READMEs --&gt; 
&lt;!-- Primary sites --&gt; 
&lt;!-- Welcome --&gt; 
&lt;!-- Community --&gt; 
&lt;!-- Agent examples --&gt; 
&lt;!-- Quick start --&gt; 
&lt;!-- Codespaces --&gt; 
&lt;!-- Deployment --&gt; 
&lt;!-- Stay tuned --&gt; 
&lt;!-- TEN ecosystem --&gt; 
&lt;!-- Contributing --&gt;</description>
    </item>
    
    <item>
      <title>microsoft/call-center-ai</title>
      <link>https://github.com/microsoft/call-center-ai</link>
      <description>&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Call Center AI&lt;/h1&gt; 
&lt;p&gt;AI-powered call center solution with Azure and OpenAI GPT.&lt;/p&gt; 
&lt;!-- github.com badges --&gt; 
&lt;p&gt;&lt;a href="https://github.com/clemlesne/call-center-ai/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/clemlesne/call-center-ai" alt="Last release date" /&gt;&lt;/a&gt; &lt;a href="https://github.com/clemlesne/call-center-ai/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/clemlesne/call-center-ai" alt="Project license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- GitHub Codespaces badge --&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt; 
&lt;p&gt;Insurance, IT support, customer service, and more. The bot can be customized in few hours (really) to fit your needs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ask the bot to call a phone number
data='{
  "bot_company": "Contoso",
  "bot_name": "AmÃ©lie",
  "phone_number": "+11234567890",
  "task": "Help the customer with their digital workplace. Assistant is working for the IT support department. The objective is to help the customer with their issue and gather information in the claim.",
  "agent_phone_number": "+33612345678",
  "claim": [
    {
      "name": "hardware_info",
      "type": "text"
    },
    {
      "name": "first_seen",
      "type": "datetime"
    },
    {
      "name": "building_location",
      "type": "text"
    }
  ]
}'

curl \
  --header 'Content-Type: application/json' \
  --request POST \
  --url https://xxx/call \
  --data $data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhanced communication and user experience&lt;/strong&gt;: Integrates inbound and outbound calls with a dedicated phone number, supports multiple languages and voice tones, and allows users to provide or receive information via SMS. Conversations are &lt;strong&gt;streamed in real-time&lt;/strong&gt; to avoid delays, can be &lt;strong&gt;resumed after disconnections&lt;/strong&gt;, and are &lt;strong&gt;stored for future reference&lt;/strong&gt;. This ensures an &lt;strong&gt;improved customer experience&lt;/strong&gt;, enabling 24/7 communication and handling of low to medium complexity calls, all in a more accessible and user-friendly manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced intelligence and data management&lt;/strong&gt;: Leverages &lt;strong&gt;gpt-4.1&lt;/strong&gt; and &lt;strong&gt;gpt-4.1-nano&lt;/strong&gt; (known for higher performance and a 10â€“15x cost premium) to achieve nuanced comprehension. It can discuss &lt;strong&gt;private and sensitive data&lt;/strong&gt;, including customer-specific information, while following &lt;strong&gt;retrieval-augmented generation (RAG)&lt;/strong&gt; best practices to ensure secure and compliant handling of internal documents. The system understands domain-specific terms, follows a structured claim schema, generates automated to-do lists, filters inappropriate content, and detects jailbreak attempts. Historical conversations and past interactions can also be used to &lt;strong&gt;fine-tune the LLM&lt;/strong&gt;, improving accuracy and personalization over time. Redis caching further enhances efficiency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Customization, oversight, and scalability&lt;/strong&gt;: Offers &lt;strong&gt;customizable prompts&lt;/strong&gt;, feature flags for controlled experimentation, human agent fallback, and call recording for quality assurance. Integrates Application Insights for monitoring and tracing, provides publicly accessible claim data, and plans future enhancements such as automated callbacks and IVR-like workflows. It also enables the creation of a &lt;strong&gt;brand-specific custom voice&lt;/strong&gt;, allowing the assistantâ€™s voice to reflect the companyâ€™s identity and improve brand consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud-native deployment and resource management&lt;/strong&gt;: Deployed on &lt;strong&gt;Azure&lt;/strong&gt; with a containerized, serverless architecture for low maintenance and elastic scaling. This approach optimizes costs based on usage, ensuring flexibility and affordability over time. Seamless integration with &lt;strong&gt;Azure Communication Services&lt;/strong&gt;, &lt;strong&gt;Cognitive Services&lt;/strong&gt;, and &lt;strong&gt;OpenAI resources&lt;/strong&gt; provides a secure environment suitable for rapid iteration, continuous improvement, and accommodating variable workloads in the call center.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Demo&lt;/h3&gt; 
&lt;p&gt;A French demo is avaialble on YouTube. Do not hesitate to watch the demo in x1.5 speed to get a quick overview of the project. Voice is hesitant on purpose to show the bot can handle it. All the infrastructure is deployed on Azure, mostly in serverless mode. Provisionning of the LLM resources can be done to reduce the latency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtube.com/watch?v=i_qhNdUUxSI"&gt;&lt;img src="https://img.youtube.com/vi/i_qhNdUUxSI/maxresdefault.jpg" alt="French demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Main interactions shown in the demo:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;User calls the call center&lt;/li&gt; 
 &lt;li&gt;The bot answers and the conversation starts&lt;/li&gt; 
 &lt;li&gt;The bot stores conversation, claim and todo list in the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Extract of the data stored during the call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "claim": {
    "incident_description": "Collision avec un autre vÃ©hicule, voiture dans le fossÃ©, pas de blessÃ©s",
    "incident_location": "Nationale 17",
    "involved_parties": "Dujardin, Madame LesnÃ©",
    "policy_number": "DEC1748"
  },
  "messages": [
    {
      "created_at": "2024-12-10T15:51:04.566727Z",
      "action": "talk",
      "content": "Non, je pense que c'est pas mal. Vous avez rÃ©pondu Ã  mes questions et lÃ  j'attends la dÃ©paneuse. Merci beaucoup.",
      "persona": "human",
      "style": "none",
      "tool_calls": []
    },
    {
      "created_at": "2024-12-10T15:51:06.040451Z",
      "action": "talk",
      "content": "Je suis ravi d'avoir pu vous aider! Si vous avez besoin de quoi que ce soit d'autre, n'hÃ©sitez pas Ã  nous contacter. Je vous souhaite une bonne journÃ©e et j'espÃ¨re que tout se passera bien avec la dÃ©panneuse. Au revoir!",
      "persona": "assistant",
      "style": "none",
      "tool_calls": []
    }
  ],
  "next": {
    "action": "case_closed",
    "justification": "The customer has provided all necessary information for the insurance claim, and a reminder has been set for a follow-up call. The customer is satisfied with the assistance provided and is waiting for the tow truck. The case can be closed for now."
  },
  "reminders": [
    {
      "created_at": "2024-12-10T15:50:09.507903Z",
      "description": "Rappeler le client pour faire le point sur l'accident et l'avancement du dossier.",
      "due_date_time": "2024-12-11T14:30:00",
      "owner": "assistant",
      "title": "Rappel client sur l'accident"
    }
  ],
  "synthesis": {
    "long": "During our call, you reported an accident involving your vehicle on the Nationale 17. You mentioned that there were no injuries, but both your car and the other vehicle ended up in a ditch. The other party involved is named Dujardin, and your vehicle is a 4x4 Ford. I have updated your claim with these details, including the license plates: yours is U837GE and the other vehicle's is GA837IA. A reminder has been set for a follow-up call tomorrow at 14:30 to discuss the progress of your claim. If you need further assistance, please feel free to reach out.",
    "satisfaction": "high",
    "short": "the accident on Nationale 17",
    "improvement_suggestions": "To improve the customer experience, it would be beneficial to ensure that the call connection is stable to avoid interruptions. Additionally, providing a clear step-by-step guide on what information is needed for the claim could help streamline the process and reduce any confusion for the customer."
  }
  ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;User report after the call&lt;/h3&gt; 
&lt;p&gt;A report is available at &lt;code&gt;https://[your_domain]/report/[phone_number]&lt;/code&gt; (like &lt;code&gt;http://localhost:8080/report/%2B133658471534&lt;/code&gt;). It shows the conversation history, claim data and reminders.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/call-center-ai/main/docs/user_report.png" alt="User report" /&gt;&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;High level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: System diagram (C4 model)
---
graph
  user(["User"])
  agent(["Agent"])

  app["Call Center AI"]

  app -- Transfer to --&amp;gt; agent
  app -. Send voice .-&amp;gt; user
  user -- Call --&amp;gt; app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Component level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: Claim AI component diagram (C4 model)
---
graph LR
  agent(["Agent"])
  user(["User"])

  subgraph "Claim AI"
    ada["Embedding&amp;lt;br&amp;gt;(ADA)"]
    app["App&amp;lt;br&amp;gt;(Container App)"]
    communication_services["Call &amp;amp; SMS gateway&amp;lt;br&amp;gt;(Communication Services)"]
    db[("Conversations and claims&amp;lt;br&amp;gt;(Cosmos DB)")]
    eventgrid["Broker&amp;lt;br&amp;gt;(Event Grid)"]
    gpt["LLM&amp;lt;br&amp;gt;(gpt-4.1, gpt-4.1-nano)"]
    queues[("Queues&amp;lt;br&amp;gt;(Azure Storage)")]
    redis[("Cache&amp;lt;br&amp;gt;(Redis)")]
    search[("RAG&amp;lt;br&amp;gt;(AI Search)")]
    sounds[("Sounds&amp;lt;br&amp;gt;(Azure Storage)")]
    sst["Speech-to-text&amp;lt;br&amp;gt;(Cognitive Services)"]
    translation["Translation&amp;lt;br&amp;gt;(Cognitive Services)"]
    tts["Text-to-speech&amp;lt;br&amp;gt;(Cognitive Services)"]
  end

  app -- Translate static TTS --&amp;gt; translation
  app -- Sezarch RAG data --&amp;gt; search
  app -- Generate completion --&amp;gt; gpt
  gpt -. Answer with completion .-&amp;gt; app
  app -- Generate voice --&amp;gt; tts
  tts -. Answer with voice .-&amp;gt; app
  app -- Get cached data --&amp;gt; redis
  app -- Save conversation --&amp;gt; db
  app -- Transform voice --&amp;gt; sst
  sst -. Answer with text .-&amp;gt; app
  app &amp;lt;-. Exchange audio .-&amp;gt; communication_services
  app -. Watch .-&amp;gt; queues

  communication_services -- Load sound --&amp;gt; sounds
  communication_services -- Notifies --&amp;gt; eventgrid
  communication_services -- Transfer to --&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; user

  eventgrid -- Push to --&amp;gt; queues

  search -- Generate embeddings --&amp;gt; ada

  user -- Call --&amp;gt; communication_services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This project is a proof of concept. It is not intended to be used in production. This demonstrates how can be combined Azure Communication Services, Azure Cognitive Services and Azure OpenAI to build an automated call center solution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;Prefer using GitHub Codespaces for a quick start.&lt;/a&gt; The environment will setup automatically with all the required tools.&lt;/p&gt; 
&lt;p&gt;In macOS, with &lt;a href="https://brew.sh"&gt;Homebrew&lt;/a&gt;, simply type &lt;code&gt;make brew&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For other systems, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli"&gt;Azure CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.twilio.com/docs/twilio-cli/getting-started/install"&gt;Twilio CLI&lt;/a&gt; (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mikefarah/yq?tab=readme-ov-file#install"&gt;yq&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Bash compatible shell, like &lt;code&gt;bash&lt;/code&gt; or &lt;code&gt;zsh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Make, &lt;code&gt;apt install make&lt;/code&gt; (Ubuntu), &lt;code&gt;yum install make&lt;/code&gt; (CentOS), &lt;code&gt;brew install make&lt;/code&gt; (macOS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, Azure resources are needed:&lt;/p&gt; 
&lt;h4&gt;1. &lt;a href="https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal"&gt;Create a new resource group&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prefer to use lowercase and no special characters other than dashes (e.g. &lt;code&gt;ccai-customer-a&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/create-communication-resource?tabs=linux&amp;amp;pivots=platform-azp"&gt;Create a Communication Services resource&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Same name as the resource group&lt;/li&gt; 
 &lt;li&gt;Enable system managed identity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/telephony/get-phone-number?tabs=linux&amp;amp;pivots=platform-azp-new"&gt;Buy a phone number&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;From the Communication Services resource&lt;/li&gt; 
 &lt;li&gt;Allow inbound and outbound communication&lt;/li&gt; 
 &lt;li&gt;Enable voice (required) and SMS (optional) capabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now that the prerequisites are configured (local + Azure), the deployment can be done.&lt;/p&gt; 
&lt;h3&gt;Remote (on Azure)&lt;/h3&gt; 
&lt;p&gt;A pre-built container image is available on GitHub Actions, it will be used to deploy the solution on Azure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Latest version from a branch: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Specific tag: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:0.1.0&lt;/code&gt; (recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Create the light config file&lt;/h4&gt; 
&lt;p&gt;Fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-remote-example.yaml"&gt;&lt;code&gt;config-remote-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;. It will be used by install scripts (incl. Makefile and Bicep) to configure the Azure resources.&lt;/p&gt; 
&lt;h4&gt;2. Connect to your Azure environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;az login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Run deployment automation&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Specify the release version under the &lt;code&gt;image_version&lt;/code&gt; parameter (default is &lt;code&gt;main&lt;/code&gt;). For example, &lt;code&gt;image_version=16.0.0&lt;/code&gt; or &lt;code&gt;image_version=sha-7ca2c0c&lt;/code&gt;. This will ensure any future project breaking changes won't affect your deployment.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the deployment to finish.&lt;/p&gt; 
&lt;h4&gt;4. Get the logs&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make logs name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local (on your machine)&lt;/h3&gt; 
&lt;h4&gt;1. Prerequisites&lt;/h4&gt; 
&lt;p&gt;If you skiped the &lt;code&gt;make brew&lt;/code&gt; command from the first install section, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rust-lang.org"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, run &lt;code&gt;make install&lt;/code&gt; to setup Python environment.&lt;/p&gt; 
&lt;h4&gt;2. Create the full config file&lt;/h4&gt; 
&lt;p&gt;If the application is already deployed on Azure, you can run &lt;code&gt;make name=my-rg-name sync-local-config&lt;/code&gt; to copy the configuration from remote to your local machine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] To use a Service Principal to authenticate to Azure, you can also add the following in a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;AZURE_CLIENT_ID=xxx
AZURE_CLIENT_SECRET=xxx
AZURE_TENANT_ID=xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If the solution is not running online, fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-local-example.yaml"&gt;&lt;code&gt;config-local-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;3. Run the deployment automation&lt;/h4&gt; 
&lt;p&gt;Execute if the solution is not yet deployed on Azure.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy-bicep deploy-post name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;This will deploy the Azure resources without the API server, allowing you to test the bot locally&lt;/li&gt; 
 &lt;li&gt;Wait for the deployment to finish&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. Connect to Azure Dev tunnels&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Tunnel requires to be run in a separate terminal, because it needs to be running all the time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;# Log in once
devtunnel login

# Start the tunnel
make tunnel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Iterate quickly with the code&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To override a specific configuration value, you can use environment variables. For example, to override the &lt;code&gt;llm.fast.endpoint&lt;/code&gt; value, you can use the &lt;code&gt;LLM__FAST__ENDPOINT&lt;/code&gt; variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;LLM__FAST__ENDPOINT=https://xxx.openai.azure.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Also, &lt;code&gt;local.py&lt;/code&gt; script is available to test the application without the need of a phone call (= without Communication Services). Run the script with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m tests.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Code is automatically reloaded on file changes, no need to restart the server&lt;/li&gt; 
 &lt;li&gt;The API server is available at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Advanced usage&lt;/h2&gt; 
&lt;h3&gt;Enable call recording&lt;/h3&gt; 
&lt;p&gt;Call recording is disabled by default. To enable it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a new container in the Azure Storage account (i.e. &lt;code&gt;recordings&lt;/code&gt;), it is already done if you deployed the solution on Azure&lt;/li&gt; 
 &lt;li&gt;Update the feature flag &lt;code&gt;recording_enabled&lt;/code&gt; in App Configuration to &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Add my custom training data with AI Search&lt;/h3&gt; 
&lt;p&gt;Training data is stored on AI Search to be retrieved by the bot, on demand.&lt;/p&gt; 
&lt;p&gt;Required index schema:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Field Name&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;Type&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Retrievable&lt;/th&gt; 
   &lt;th&gt;Searchable&lt;/th&gt; 
   &lt;th&gt;Dimensions&lt;/th&gt; 
   &lt;th&gt;Vectorizer&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;answer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;context&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;created_at&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;document_synthesis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;file_path&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;id&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;question&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vectors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Collection(Edm.Single)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;1536&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;OpenAI ADA&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Software to fill the index is included &lt;a href="https://github.com/clemlesne/rag-index"&gt;on Synthetic RAG Index&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h3&gt;Customize the languages&lt;/h3&gt; 
&lt;p&gt;The bot can be used in multiple languages. It can understand the language the user chose.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts#supported-languages"&gt;list of supported languages&lt;/a&gt; for the Text-to-Speech service.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: fr-FR-DeniseNeural
        - pronunciations_en: ["Chinese", "ZH", "China"]
          short_code: zh-CN
          voice: zh-CN-XiaoqiuNeural
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you built and deployed an &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-neural-voice"&gt;Azure Speech Custom Neural Voice (CNV)&lt;/a&gt;, add field &lt;code&gt;custom_voice_endpoint_id&lt;/code&gt; on the language configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: xxx
          custom_voice_endpoint_id: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the moderation levels&lt;/h3&gt; 
&lt;p&gt;Levels are defined for each category of Content Safety. The higher the score, the more strict the moderation is, from 0 to 7. Moderation is applied on all bot data, including the web page and the conversation. Configure them in Azure OpenAI Content Filters.&lt;/p&gt; 
&lt;h3&gt;Customize the claim data schema&lt;/h3&gt; 
&lt;p&gt;Customization of the data schema is fully supported. You can add or remove fields as needed, depending on the requirements.&lt;/p&gt; 
&lt;p&gt;By default, the schema of composed of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;caller_email&lt;/code&gt; (&lt;code&gt;email&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_name&lt;/code&gt; (&lt;code&gt;text&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_phone&lt;/code&gt; (&lt;code&gt;phone_number&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Values are validated to ensure the data format commit to your schema. They can be either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;datetime&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;email&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;phone_number&lt;/code&gt; (&lt;code&gt;E164&lt;/code&gt; format)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;text&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, an optional description can be provided. The description must be short and meaningful, it will be passed to the LLM.&lt;/p&gt; 
&lt;p&gt;Default schema, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  default_initiate:
    claim:
      - name: additional_notes
        type: text
        # description: xxx
      - name: device_info
        type: text
        # description: xxx
      - name: incident_datetime
        type: datetime
        # description: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Claim schema can be customized for each call, by adding the &lt;code&gt;claim&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the call objective&lt;/h3&gt; 
&lt;p&gt;The objective is a description of what the bot will do during the call. It is used to give a context to the LLM. It should be short, meaningful, and written in English.&lt;/p&gt; 
&lt;p&gt;This solution is priviledged instead of overriding the LLM prompt.&lt;/p&gt; 
&lt;p&gt;Default task, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    task: |
      Help the customer with their insurance claim. Assistant requires data from the customer to fill the claim. The latest claim data will be given. Assistant role is not over until all the relevant data is gathered.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Task can be customized for each call, by adding the &lt;code&gt;task&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the conversation&lt;/h3&gt; 
&lt;p&gt;Conversation options are represented as features. They can be configured from App Configuration, without the need to redeploy or restart the application. Once a feature is updated, a delay of 60 secs is needed to make the change effective.&lt;/p&gt; 
&lt;p&gt;By default, values are refreshed every 60 seconds. Refresh is not sync across all instances, so it can take up to 60 seconds to see the change on all users. Update this in the &lt;code&gt;app_configuration.ttl_sec&lt;/code&gt; field.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_hard_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before aborting the answer with an error message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_soft_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before sending a waiting message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;callback_timeout_hour&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for a callback in hours. Set 0 to disable.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;phone_silence_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amount of silence in secs to trigger a warning message from the assistant.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_retry_max&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TThe maximum number of retries for voice recognition. Minimum of 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_stt_complete_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for STT completion in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recording_enabled&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether call recording is enabled.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;slow_llm_for_chat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether to use the slow LLM for chat.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_cutoff_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The cutoff timeout for voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;250&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_silence_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Silence to trigger voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;500&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The threshold for voice activity detection. Between 0.1 and 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;float&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;0.5&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Use Twilio for SMS&lt;/h3&gt; 
&lt;p&gt;To use Twilio for SMS, you need to create an account and get the following information:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Account SID&lt;/li&gt; 
 &lt;li&gt;Auth Token&lt;/li&gt; 
 &lt;li&gt;Phone number&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, add the following in the &lt;code&gt;config.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
sms:
  mode: twilio
  twilio:
    account_sid: xxx
    auth_token: xxx
    phone_number: "+33612345678"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the prompts&lt;/h3&gt; 
&lt;p&gt;Note that prompt examples contains &lt;code&gt;{xxx}&lt;/code&gt; placeholders. These placeholders are replaced by the bot with the corresponding data. For example, &lt;code&gt;{bot_name}&lt;/code&gt; is internally replaced by the bot name. Be sure to write all the TTS prompts in English. This language is used as a pivot language for the conversation translation. All texts are referenced as lists, so user can have a different experience each time they call, thus making the conversation more engaging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
prompts:
  tts:
    hello_tpl:
      - : |
        Hello, I'm {bot_name}, from {bot_company}! I'm an IT support specialist.

        Here's how I work: when I'm working, you'll hear a little music; then, at the beep, it's your turn to speak. You can speak to me naturally, I'll understand.

        What's your problem?
      - : |
        Hi, I'm {bot_name} from {bot_company}. I'm here to help.

        You'll hear music, then a beep. Speak naturally, I'll understand.

        What's the issue?
  llm:
    default_system_tpl: |
      Assistant is called {bot_name} and is in a call center for the company {bot_company} as an expert with 20 years of experience in IT service.

      # Context
      Today is {date}. Customer is calling from {phone_number}. Call center number is {bot_phone_number}.
    chat_system_tpl: |
      # Objective
      Provide internal IT support to employees. Assistant requires data from the employee to provide IT support. The assistant's role is not over until the issue is resolved or the request is fulfilled.

      # Rules
      - Answers in {default_lang}, even if the customer speaks another language
      - Cannot talk about any topic other than IT support
      - Is polite, helpful, and professional
      - Rephrase the employee's questions as statements and answer them
      - Use additional context to enhance the conversation with useful details
      - When the employee says a word and then spells out letters, this means that the word is written in the way the employee spelled it (e.g. "I work in Paris PARIS", "My name is John JOHN", "My email is Clemence CLEMENCE at gmail GMAIL dot com COM")
      - You work for {bot_company}, not someone else

      # Required employee data to be gathered by the assistant
      - Department
      - Description of the IT issue or request
      - Employee name
      - Location

      # General process to follow
      1. Gather information to know the employee's identity (e.g. name, department)
      2. Gather details about the IT issue or request to understand the situation (e.g. description, location)
      3. Provide initial troubleshooting steps or solutions
      4. Gather additional information if needed (e.g. error messages, screenshots)
      5. Be proactive and create reminders for follow-up or further assistance

      # Support status
      {claim}

      # Reminders
      {reminders}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optimize response delay&lt;/h3&gt; 
&lt;p&gt;The delay mainly come from two things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Voice in and voice out are processed by Azure AI Speech, both are implemented in streaming mode but voice is not directly streamed to the LLM&lt;/li&gt; 
 &lt;li&gt;The LLM, more specifically the delay between API call and first sentence infered, can be long (as the sentences are sent one by one once they are made avalable), even longer if it hallucinate and returns empty answers (it happens regularly, and the applicatoipn retries the call)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;From now, the only impactful thing you can do is the LLM part. This can be acheieve by a PTU on Azure or using a less smart model like &lt;code&gt;gpt-4.1-nano&lt;/code&gt; (selected by default on the latest versions). With a PTU on Azure OpenAI, you can divide by 2 the latency in some case.&lt;/p&gt; 
&lt;p&gt;The application is natively connected to Azure Application Insights, so you can monitor the response time and see where the time is spent. This is a great start to identify the bottlenecks.&lt;/p&gt; 
&lt;p&gt;Feel free to raise an issue or propose a PR if you have any idea to optimize the response delay.&lt;/p&gt; 
&lt;h3&gt;Improving conversation quality through model fine-tuning&lt;/h3&gt; 
&lt;p&gt;Enhance the LLMâ€™s accuracy and domain adaptation by integrating historical data from human-run call centers. Before proceeding, ensure compliance with data privacy regulations, internal security standards, and &lt;a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2"&gt;Responsible AI principles&lt;/a&gt;. Consider the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aggregate authentic data sources: Collect voice recordings, call transcripts, and chat logs from previous human-managed interactions to provide the LLM with realistic training material.&lt;/li&gt; 
 &lt;li&gt;Preprocess and anonymize data: &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/overview"&gt;Remove sensitive information (AI Language Personally Identifiable Information detection)&lt;/a&gt;, including personal identifiers or confidential details, to preserve user privacy, meet compliance, and align with Responsible AI guidelines.&lt;/li&gt; 
 &lt;li&gt;Perform iterative fine-tuning: Continuously &lt;a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/fine-tuning-overview"&gt;refine the modelâ€™s using the curated dataset (AI Foundry Fine-tuning)&lt;/a&gt;, allowing it to learn industry-specific terminology, preferred conversation styles, and problem-resolution approaches.&lt;/li&gt; 
 &lt;li&gt;Validate improvements: Test the updated model against sample scenarios and measure key performance indicators (e.g. user satisfaction, call duration, resolution rate) to confirm that adjustments have led to meaningful enhancements.&lt;/li&gt; 
 &lt;li&gt;Monitor, iterate, and A/B test: Regularly reassess the modelâ€™s performance, integrate newly gathered data, and apply further fine-tuning as needed. Leverage &lt;a href="https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-experimentation"&gt;built-in feature configurations to A/B test (App Configuration Experimentation)&lt;/a&gt; different versions of the model, ensuring responsible, data-driven decisions and continuous optimization over time.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Monitoring the application&lt;/h3&gt; 
&lt;p&gt;Application send traces and metrics to Azure Application Insights. You can monitor the application from the Azure portal, or by using the API.&lt;/p&gt; 
&lt;p&gt;This includes application behavior, database queries, and external service calls. Plus, LLM metrics (latency, token usage, prompts content, raw response) from &lt;a href="https://github.com/traceloop/openllmetry"&gt;OpenLLMetry&lt;/a&gt;, following the &lt;a href="https://opentelemetry.io/docs/specs/semconv/gen-ai/openai/#openai-spans"&gt;semantic sonventions for OpenAI operations&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally custom metrics (viewable in Application Insights &amp;gt; Metrics) are published, notably:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.droped&lt;/code&gt;, number of times the echo cancellation dropped the voice completely.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.missed&lt;/code&gt;, number of times the echo cancellation failed to remove the echo in time.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.answer.latency&lt;/code&gt;, time between the end of the user voice and the start of the bot voice.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;h3&gt;What will this cost?&lt;/h3&gt; 
&lt;p&gt;For a monthly usage of 1000 calls of 10 minutes each. Costs are estimated for 2024-12-10, in USD. Prices are subject to change.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For production usage, it is recommended to upgrade to SKUs with vNET integration and private endpoints. This can increase notably the costs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This totalizes $720.07 /month, $0.12 /hour, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Audio Streaming&lt;/td&gt; 
   &lt;td&gt;$0.004 /minute&lt;/td&gt; 
   &lt;td&gt;$40&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.15 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$35.25&lt;/td&gt; 
   &lt;td&gt;8k tokens for conversation history, 3750 tokens for RAG, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.60 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$1.4&lt;/td&gt; 
   &lt;td&gt;400 tokens for each response incl tools, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$2.50 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;4k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$10 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;1k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$2.08&lt;/td&gt; 
   &lt;td&gt;1 search or 400 tokens for each message, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/"&gt;Azure Container Apps&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless vCPU&lt;/td&gt; 
   &lt;td&gt;$0.000024 /sec&lt;/td&gt; 
   &lt;td&gt;$128.56&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 1 vCPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless memory (average of 2 replicas)&lt;/td&gt; 
   &lt;td&gt;$0.000003 /sec&lt;/td&gt; 
   &lt;td&gt;$32.14&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 2GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/search/"&gt;Azure AI Search&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;$73.73 /month&lt;/td&gt; 
   &lt;td&gt;$73.73&lt;/td&gt; 
   &lt;td&gt;Has 15GB of storage /index, should be upgraded for big datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/"&gt;Azure AI Speech&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Speech-to-text real-time&lt;/td&gt; 
   &lt;td&gt;$1 /hour&lt;/td&gt; 
   &lt;td&gt;$83.33&lt;/td&gt; 
   &lt;td&gt;Each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Text-to-speech standard&lt;/td&gt; 
   &lt;td&gt;$15 /1M characters&lt;/td&gt; 
   &lt;td&gt;$69.23&lt;/td&gt; 
   &lt;td&gt;300 tokens for each response, 1.3 tokens /word in English, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cosmos-db/autoscale-provisioned/"&gt;Azure Cosmos DB&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Multi-region write RU/s /region&lt;/td&gt; 
   &lt;td&gt;$11.68 /100 RU/s&lt;/td&gt; 
   &lt;td&gt;$233.6&lt;/td&gt; 
   &lt;td&gt;Avg of 1k RU/s on 2 regions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Transactional storage&lt;/td&gt; 
   &lt;td&gt;$0.25 /GB&lt;/td&gt; 
   &lt;td&gt;$0.5&lt;/td&gt; 
   &lt;td&gt;2GB of storage, should be upgraded if more history is needed&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Not included upper:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Azure Monitor costs shouldn't be considered as optional as monitoring is a key part of maintaining a business-critical application and high-quality service for users.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional costs totalizing $343.02 /month, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Call recording&lt;/td&gt; 
   &lt;td&gt;$0.002 /minute&lt;/td&gt; 
   &lt;td&gt;$20&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$0.52&lt;/td&gt; 
   &lt;td&gt;10k PDF pages with 400 tokens each, for indexing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/monitor/"&gt;Azure Monitor&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic logs ingestion&lt;/td&gt; 
   &lt;td&gt;$0.645 /GB&lt;/td&gt; 
   &lt;td&gt;$322.5&lt;/td&gt; 
   &lt;td&gt;500GB of logs &lt;a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/opentelemetry-configuration?tabs=python#enable-sampling"&gt;with sampling enabled&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;What would it require to make it production ready?&lt;/h3&gt; 
&lt;p&gt;Quality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Unit and integration tests for persistence layer&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Complete unit and integration tests coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reliability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Reproductible builds&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Traces and telemetry&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Operation runbooks for common issues&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Proper dashboarding in Azure Application Insights (deployed with the IaC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Maintainability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automated and required static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Decouple assistant from the insights in a separate service&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Peer review to limit the bus factor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Resiliency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infrastructure as Code (IaC)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Multi-region deployment&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Reproductible performance tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Security:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CI builds attestations&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CodeQL static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GitOps for deployments&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Private networking&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Production SKUs allowing vNET integration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Red team exercises&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Responsible AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Harmful content detection&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Grounding detection with Content Safety&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Social impact assessment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why no LLM framework is used?&lt;/h3&gt; 
&lt;p&gt;At the time of development, no LLM framework was available to handle all of these features: streaming capability with multi-tools, backup models on availability issue, callbacks mechanisms in the triggered tools. So, OpenAI SDK is used directly and some algorithms are implemented to handle reliability.&lt;/p&gt; 
&lt;h2&gt;Related content&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For a simple sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, local deployment only, &lt;a href="https://github.com/Azure-Samples/aisearch-openai-rag-audio"&gt;see VoiceRAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For an easier-to-use sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, deployed on Azure, &lt;a href="https://github.com/Azure-Samples/realtime-call-center-accelerator"&gt;see Realtime Call Center Solution Accelerator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>numz/ComfyUI-SeedVR2_VideoUpscaler</title>
      <link>https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler</link>
      <description>&lt;p&gt;Official SeedVR2 Video Upscaler for ComfyUI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ComfyUI-SeedVR2_VideoUpscaler&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%82_View_Code-GitHub-181717?style=for-the-badge&amp;amp;logo=github" alt="View Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Official release of &lt;a href="https://github.com/ByteDance-Seed/SeedVR"&gt;SeedVR2&lt;/a&gt; for ComfyUI that enables high-quality video and image upscaling.&lt;/p&gt; 
&lt;p&gt;Can run as &lt;strong&gt;Multi-GPU standalone CLI&lt;/strong&gt; too, see &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-run-as-standalone-cli"&gt;ğŸ–¥ï¸ Run as Standalone&lt;/a&gt; section.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/MBtWYXq_r60"&gt;&lt;img src="https://img.youtube.com/vi/MBtWYXq_r60/maxresdefault.jpg" alt="SeedVR2 v2.5 Deep Dive Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/usage_01.png" alt="Usage Example" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/usage_02.png" alt="Usage Example" /&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“‹ Quick Access&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-future-work"&gt;ğŸ†™ Future Work&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-release-notes"&gt;ğŸš€ Release Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-features"&gt;ğŸ¯ Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-requirements"&gt;ğŸ”§ Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-installation"&gt;ğŸ“¦ Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-usage"&gt;ğŸ“– Usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#%EF%B8%8F-run-as-standalone-cli"&gt;ğŸ–¥ï¸ Run as Standalone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#%EF%B8%8F-limitations"&gt;âš ï¸ Limitations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-contributing"&gt;ğŸ¤ Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-credits"&gt;ğŸ™ Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-license"&gt;ğŸ“œ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ†™ Future Work&lt;/h2&gt; 
&lt;p&gt;We're actively working on improvements and new features. To stay informed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Œ Track Active Development&lt;/strong&gt;: Visit &lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/issues"&gt;Issues&lt;/a&gt; to see active development, report bugs, and request new features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¬ Join the Community&lt;/strong&gt;: Learn from others, share your workflows, and get help in the &lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”® Next Model Survey&lt;/strong&gt;: We're looking for community input on the next open-source super-powerful generic restoration model. Share your suggestions in &lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/issues/164"&gt;Issue #164&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Release Notes&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.13 - Version 2.5.22&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¬ CLI: FFmpeg video backend with 10-bit support&lt;/strong&gt; - New &lt;code&gt;--video_backend ffmpeg&lt;/code&gt; and &lt;code&gt;--10bit&lt;/code&gt; flags enable x265 encoding with 10-bit color depth, reducing banding artifacts in gradients compared to 8-bit OpenCV output &lt;em&gt;(based on PR by &lt;a href="https://github.com/thehhmdb"&gt;@thehhmdb&lt;/a&gt; - thank you!)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: MPS bicubic upscaling compatibility&lt;/strong&gt; - Added CPU fallback for bicubic+antialias interpolation on PyTorch versions before 2.8.0, resolving RGBA alpha upscaling errors on Apple Silicon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Fix: Cross-platform histogram matching&lt;/strong&gt; - Replaced scatter_ operation with argsort+index_select for improved reliability across CUDA, ROCm, and MPS backends&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§¹ MPS: Remove sync overhead&lt;/strong&gt; - Reverted unnecessary &lt;code&gt;torch.mps.synchronize()&lt;/code&gt; calls introduced in v2.5.21 for consistent behavior with CUDA pipeline&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.12 - Version 2.5.21&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› ï¸ Fix: GGUF dequantization error on MPS&lt;/strong&gt; - Resolved shape mismatch error introduced in 2.5.20 by skipping GGUF quantized buffers in precision conversion - these must remain in packed format for on-the-fly dequantization during inference&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ MPS: Eliminate CPU sync overhead&lt;/strong&gt; - Skip unnecessary CPU tensor offload on Apple Silicon unified memory architecture, preventing sync stalls that caused slowdowns. Input images and output video now stay on MPS device throughout the pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ MPS: Preload text embeddings&lt;/strong&gt; - Load text embeddings before Phase 1 encoding to avoid sync stall at Phase 2 start, improving timing accuracy and throughput&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§¹ MPS: Optimized model cleanup&lt;/strong&gt; - Skip redundant CPU movement before model deletion on unified memory&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.12 - Version 2.5.20&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Expanded attention backends&lt;/strong&gt; - Full support for Flash Attention 2 (Ampere+), Flash Attention 3 (Hopper+), SageAttention 2, and SageAttention 3 (Blackwell/RTX 50xx), with automatic fallback chains to PyTorch SDPA when unavailable &lt;em&gt;(based on PR by &lt;a href="https://github.com/naxci1"&gt;@naxci1&lt;/a&gt; - thank you!)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ macOS/Apple Silicon compatibility&lt;/strong&gt; - Replaced MPS autocast with explicit dtype conversion throughout VAE and DiT pipelines, resolving hangs and crashes on M-series Macs. BlockSwap now auto-disables with warning (unified memory makes it meaningless)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ Flash Attention graceful fallback&lt;/strong&gt; - Added compatibility shims for corrupted or partially installed flash_attn/xformers DLLs, preventing startup crashes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ AMD ROCm: bitsandbytes conflict fix&lt;/strong&gt; - Prevent kernel registration errors when diffusers attempts to re-import broken bitsandbytes installations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“¦ ComfyUI Manager: macOS classifier fix&lt;/strong&gt; - Removed NVIDIA CUDA classifier causing false "GPU not supported" warnings on macOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š Documentation updates&lt;/strong&gt; - Updated README with attention backend details, BlockSwap macOS notes, and clarified model caching descriptions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.10 - Version 2.5.19&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ New header logo design&lt;/strong&gt; - Refreshed ASCII art banner &lt;em&gt;(thanks &lt;a href="https://github.com/naxci1"&gt;@naxci1&lt;/a&gt;)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§¹ Remove dead flash attention wrapper&lt;/strong&gt; - Removed legacy code from FP8CompatibleDiT; FlashAttentionVarlen already handles backend switching via its &lt;code&gt;attention_mode&lt;/code&gt; attribute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ Fix graceful fallback from flash-attn&lt;/strong&gt; - Add compatibility shims for corrupted flash_attn/xformers DLLs, preventing startup crashes when CUDA extensions are broken&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Improved VRAM tracking&lt;/strong&gt; - Separate allocated vs reserved memory tracking, Windows-only overflow detection (WDDM paging behavior)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;â™»ï¸ Centralize backend detection&lt;/strong&gt; - Unified &lt;code&gt;is_mps_available()&lt;/code&gt;, &lt;code&gt;is_cuda_available()&lt;/code&gt;, &lt;code&gt;get_gpu_backend()&lt;/code&gt; helpers across codebase&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”„ Revert 2.5.14 VRAM limit enforcement&lt;/strong&gt; - Removed &lt;code&gt;set_per_process_memory_fraction&lt;/code&gt; call; Overflow detection and warnings remain.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.09 - Version 2.5.18&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸš€ CLI: Streaming mode for long videos&lt;/strong&gt; - New &lt;code&gt;--chunk_size&lt;/code&gt; flag processes videos in memory-bounded chunks, enabling arbitrarily long videos without RAM limits. Works with model caching (&lt;code&gt;--cache_dit&lt;/code&gt;/&lt;code&gt;--cache_vae&lt;/code&gt;) for chunk-to-chunk reuse &lt;em&gt;(inspired by &lt;a href="https://github.com/disk02"&gt;disk02&lt;/a&gt; PR contribution)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ CLI: Multi-GPU streaming&lt;/strong&gt; - Each GPU now streams its segment internally with independent model caching, improving memory efficiency and enabling &lt;code&gt;--temporal_overlap&lt;/code&gt; blending at GPU boundaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ CLI: Fix large video MemoryError&lt;/strong&gt; - Shared memory transfer replaces numpy pickling, preventing crashes on high-resolution/long video outputs &lt;em&gt;(inspired by &lt;a href="https://github.com/FurkanGozukara"&gt;FurkanGozukara&lt;/a&gt; PR contribution)&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.05 - Version 2.5.17&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: Older GPU compatibility (GTX 970, etc.)&lt;/strong&gt; - Runtime bf16 CUBLAS probe replaces compute capability heuristics, correctly detecting unsupported GPUs without affecting RTX 20XX&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.05 - Version 2.5.16&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: Older GPU compatibility (GTX 970, etc.)&lt;/strong&gt; - Automatic fallback for GPUs without bfloat16 support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› Fix: Quality regression&lt;/strong&gt; - Reverted bfloat16 detection that was causing artifact issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“‹ Debug: Environment info display&lt;/strong&gt; - Shows system info in debug mode to help with issue reporting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š Docs: Simplified contribution workflow&lt;/strong&gt; - Streamlined to main branch only&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.03 - Version 2.5.15&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: MPS compatibility&lt;/strong&gt; - Disable antialias for MPS tensors and fix bfloat16 arange issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Fix: Autocast device type&lt;/strong&gt; - Use proper device type attribute to prevent autocast errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Memory: Accurate VRAM tracking&lt;/strong&gt; - Use max_memory_reserved for more precise peak reporting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: Triton compatibility&lt;/strong&gt; - Add shim for bitsandbytes 0.45+ / triton 3.0+ (fixes PyTorch 2.7 installation errors)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.12.01 - Version 2.5.14&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: MPS device comparison&lt;/strong&gt; - Normalize device strings to prevent unnecessary tensor movements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Memory: VRAM swap detection&lt;/strong&gt; - Peak stats now show GPU+swap breakdown when overflow occurs, with warning when swap detected&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ›¡ï¸ Memory: Enforce physical VRAM limit&lt;/strong&gt; - PyTorch now OOMs instead of silently swapping to shared memory (prevents extreme slowdowns on Windows)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.30 - Version 2.5.13&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: PyTorch 2.7+ triton import error&lt;/strong&gt; - Resolved installation crash caused by triton.ops import chain on newer triton versions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¾ Fix: OOM on float32 conversion for long videos&lt;/strong&gt; - Graceful fallback to native dtype when insufficient memory for float32 conversion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: CLI watermark error on macOS&lt;/strong&gt; - Resolved MPS-related watermark processing crash on Apple Silicon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.28 - Version 2.5.12&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› Fix: Color artifacts regression&lt;/strong&gt; - Reverted in-place tensor operations in video transform pipeline that caused color artifacts on some images&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.28 - Version 2.5.11&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Feature: CUDNN attention backend&lt;/strong&gt; - Added support for PyTorch 2.3+ CUDNN_ATTENTION backend with automatic fallback for older versions (thanks @eadwu)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¾ Fix: Memory spike for long videos&lt;/strong&gt; - VAE decode now streams directly to pre-allocated tensor, eliminating OOM errors during long video processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Fix: LAB color correction artifacts&lt;/strong&gt; - Resolved tile boundary artifacts using wavelet reconstruction preprocessing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Fix: Color reference misalignment&lt;/strong&gt; - Fixed color correction frame alignment with temporal overlap&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: MPS detection reliability&lt;/strong&gt; - Switched to canonical &lt;code&gt;torch.backends.mps.is_available()&lt;/code&gt; API for consistent Apple Silicon detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Fix: Mac subprocess error&lt;/strong&gt; - CLI now uses direct processing on Mac to avoid MPS allocator failures in child processes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Fix: Multi-GPU device assignment&lt;/strong&gt; - CUDA_VISIBLE_DEVICES now set before spawn for proper worker inheritance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Fix: BlockSwap logging&lt;/strong&gt; - Now shows effective/total blocks (e.g., 32/32) instead of raw requested value&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Feature: Auto bfloat16 detection&lt;/strong&gt; - Automatically detects bfloat16 support to prevent CUBLAS errors on older GPUs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Feature: Peak RAM tracking&lt;/strong&gt; - Added RAM usage alongside VRAM in debug summary&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Performance: In-place tensor ops&lt;/strong&gt; - Reduced memory allocation overhead with in-place operations throughout pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“– Docs: Multi-GPU clarification&lt;/strong&gt; - Clarified frame-level parallelism behavior expectations for multi-GPU setups&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.13 - Version 2.5.10&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Fix: Deterministic generation&lt;/strong&gt; - Identical images with the same seed now produce identical results across different sessions and batch positions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: Model caching with BlockSwap&lt;/strong&gt; - Resolved issue where cached DiT models wouldn't properly reload when VAE caching state changed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¾ Fix: Runner caching optimization&lt;/strong&gt; - Runner templates now correctly cache whenever both DiT and VAE are cached, regardless of caching order&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ Fix: Case-insensitive model paths&lt;/strong&gt; - Extra model paths in YAML config now work regardless of case (seedvr2, SEEDVR2, SeedVR2, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› Fix: High resolution tile debug crash&lt;/strong&gt; - Fixed "NoneType has no attribute log" error when using maximum resolution with VAE tiling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Fix: Temporal overlap logging&lt;/strong&gt; - Corrected frame count reporting when temporal overlap is automatically adjusted&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Feature: Enhanced model path debugging&lt;/strong&gt; - Added detailed logging to help troubleshoot model loading issues (visible in debug mode)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.12 - Version 2.5.9&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› Fix: Tile debug visualization crash&lt;/strong&gt; - Fixed OpenCV error when using VAE tile debug mode on certain systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ Fix: macOS MPS loading error&lt;/strong&gt; - Added automatic CPU fallback for MPS allocator issues on certain PyTorch/macOS versions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Fix: Windows log buffering&lt;/strong&gt; - Added flush to print statements for real-time log visibility in ComfyUI on Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“¦ Fix: ComfyUI Registry logo&lt;/strong&gt; - Updated icon URL to display properly in ComfyUI node registry&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;â„¹ï¸ Feature: Version display&lt;/strong&gt; - Added version number to node name and CLI/ComfyUI header for better tracking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’ Feature: GitHub Sponsors&lt;/strong&gt; - Added sponsor button to support project development. Thank you everyone for your support!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“œ License: Apache 2.0&lt;/strong&gt; - Reverted License from MIT to Apache 2.0 to match ByteDance Seed project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.10 - Version 2.5.8&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ› Fix (CLI): Windows batch processing duplicate files&lt;/strong&gt; - Fixed CLI batch mode processing each file twice on Windows due to case-insensitive filesystem. Improved directory scanning performance by 2-3x&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ Fix(CLI): Output folder location&lt;/strong&gt; - Output files now created in sensible locations: batch mode creates &lt;code&gt;{folder_name}_upscaled/&lt;/code&gt; sibling folder with original filenames preserved; single file mode adds &lt;code&gt;_upscaled&lt;/code&gt; suffix in same directory. All logs now show absolute paths for clarity&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Fix(CLI): RGBA alpha channel support&lt;/strong&gt; - PNG images with transparency are now properly detected and preserved through the upscaling pipeline, matching ComfyUI behavior&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.10 - Version 2.5.7&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Fix: Conv3d workaround compatibility&lt;/strong&gt; - Enhanced platform detection and added graceful fallback to prevent errors on PyTorch dev builds and AMD ROCm systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.09 - Version 2.5.6&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ¨ &lt;strong&gt;Fix: Restored natural look for 7b model&lt;/strong&gt; - Corrected torch.compile optimization that was causing overly plastic/ high-specular appearance in upscaled videos with 7b model.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Memory: Fixed RAM leak for long videos&lt;/strong&gt; - On-demand reconstruction with lightweight batch indices instead of storing full transformed videos, fixed release_tensor_memory to handle CPU/CUDA/MPS consistently, and refactored batch processing helpers&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.08 - Version 2.5.4&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;Fix: AdaIN color correction&lt;/strong&gt; - Replace &lt;code&gt;.view()&lt;/code&gt; with &lt;code&gt;.reshape()&lt;/code&gt; to handle non-contiguous tensors after spatial padding, resolving "view size is not compatible with input tensor's size and stride" error&lt;/li&gt; 
 &lt;li&gt;ğŸ”´ &lt;strong&gt;Fix: AMD ROCm compatibility&lt;/strong&gt; - Add cuDNN availability check in Conv3d workaround to prevent "ATen not compiled with cuDNN support" error on ROCm systems (AMD GPUs on Windows/Linux)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.08 - Version 2.5.3&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ &lt;strong&gt;Fix: Apple Silicon MPS device handling&lt;/strong&gt; - Corrected MPS device enumeration to use &lt;code&gt;"mps"&lt;/code&gt; instead of &lt;code&gt;"mps:0"&lt;/code&gt;, resolving invalid device errors on M-series Macs&lt;/li&gt; 
 &lt;li&gt;ğŸªŸ &lt;strong&gt;Fix: torch.mps AttributeError on Windows&lt;/strong&gt; - Add defensive checks for &lt;code&gt;torch.mps.is_available()&lt;/code&gt; to handle PyTorch versions where the method doesn't exist on non-Mac platforms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.11.07 - Version 2.5.0&lt;/strong&gt; ğŸ‰&lt;/p&gt; 
&lt;p&gt;âš ï¸ &lt;strong&gt;BREAKING CHANGE&lt;/strong&gt;: This is a major update requiring workflow recreation. All nodes and CLI parameters have been redesigned for better usability and consistency. Watch the latest video from &lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX&lt;/a&gt; for a deep dive and check out the &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-usage"&gt;usage&lt;/a&gt; section.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ“¦ Official Release&lt;/strong&gt;: Now available on main branch with ComfyUI Manager support for easy installation and automatic version tracking. Updated dependencies and local imports prevent conflicts with other ComfyUI custom nodes.&lt;/p&gt; 
&lt;h3&gt;ğŸ¨ ComfyUI Improvements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Four-Node Modular Architecture&lt;/strong&gt;: Split into dedicated nodes for DiT model, VAE model, torch.compile settings, and main upscaler for granular control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global Model Cache&lt;/strong&gt;: Models now shared across multiple upscaler instances with automatic config updates - no more redundant loading&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ComfyUI V3 Migration&lt;/strong&gt;: Full compatibility with ComfyUI V3 stateless node design&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RGBA Support&lt;/strong&gt;: Native alpha channel processing with edge-guided upscaling for clean transparency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved Memory Management&lt;/strong&gt;: Streaming architecture prevents VRAM spikes regardless of video length&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Resolution Support&lt;/strong&gt;: Upscale to any resolution divisible by 2 with lossless padding approach (replaced restrictive cropping)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Parameters&lt;/strong&gt;: Added &lt;code&gt;uniform_batch_size&lt;/code&gt;, &lt;code&gt;temporal_overlap&lt;/code&gt;, &lt;code&gt;prepend_frames&lt;/code&gt;, and &lt;code&gt;max_resolution&lt;/code&gt; for better control&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ–¥ï¸ CLI Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Batch Directory Processing&lt;/strong&gt;: Process entire folders of videos/images with model caching for efficiency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Image Support&lt;/strong&gt;: Direct image upscaling without video conversion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Output Detection&lt;/strong&gt;: Auto-detects output format (MP4/PNG) based on input type&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Multi-GPU&lt;/strong&gt;: Improved workload distribution with temporal overlap blending&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Parameters&lt;/strong&gt;: CLI and ComfyUI now use identical parameter names for consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better UX&lt;/strong&gt;: Auto-display help, validation improvements, progress tracking, and cleaner output&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;âš¡ Performance &amp;amp; Optimization&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;torch.compile Support&lt;/strong&gt;: 20-40% DiT speedup and 15-25% VAE speedup with full graph compilation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized BlockSwap&lt;/strong&gt;: Adaptive memory clearing (5% threshold), separate I/O component handling, reduced overhead&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced VAE Tiling&lt;/strong&gt;: Tensor offload support for accumulation buffers, separate encode/decode configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native Dtype Pipeline&lt;/strong&gt;: Eliminated unnecessary conversions, maintains bfloat16 precision throughout for speed and quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized Tensor Operations&lt;/strong&gt;: Replaced einops rearrange with native PyTorch ops for 2-5x faster transforms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¯ Quality Improvements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LAB Color Correction&lt;/strong&gt;: New perceptual color transfer method with superior color accuracy (now default)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Additional Color Methods&lt;/strong&gt;: HSV saturation matching, wavelet adaptive, and hybrid approaches&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deterministic Generation&lt;/strong&gt;: Seed-based reproducibility with phase-specific seeding strategy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Temporal Consistency&lt;/strong&gt;: Hann window blending for smooth transitions between batches&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ’¾ Memory Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smarter Offloading&lt;/strong&gt;: Independent device configuration for DiT, VAE, and tensors (CPU/GPU/none)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Four-Phase Pipeline&lt;/strong&gt;: Completes each phase (encodeâ†’upscaleâ†’decodeâ†’postprocess) for all batches before moving to next, minimizing model swaps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Cleanup&lt;/strong&gt;: Phase-specific resource management with proper tensor memory release&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Peak VRAM Tracking&lt;/strong&gt;: Per-phase memory monitoring with summary display&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”§ Technical Improvements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GGUF Quantization Support&lt;/strong&gt;: Added full GGUF support for 4-bit/8-bit inference on low-VRAM systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improved GGUF Handling&lt;/strong&gt;: Fixed VRAM leaks, torch.compile compatibility, non-persistent buffers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apple Silicon Support&lt;/strong&gt;: Full MPS (Metal Performance Shaders) support for Apple Silicon Macs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMD ROCm Compatibility&lt;/strong&gt;: Conditional FSDP imports for PyTorch ROCm 7+ support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conv3d Memory Workaround&lt;/strong&gt;: Fixes PyTorch 2.9+ cuDNN memory bug (3x usage reduction)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flash Attention Optional&lt;/strong&gt;: Graceful fallback to SDPA when flash-attn unavailable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“š Code Quality&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Modular Architecture&lt;/strong&gt;: Split monolithic files into focused modules (generation_phases, model_configuration, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Documentation&lt;/strong&gt;: Extensive docstrings with type hints across all modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Error Handling&lt;/strong&gt;: Early validation, clear error messages, installation instructions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistent Logging&lt;/strong&gt;: Unified indentation, better categorization, concise messages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.08.07&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Unified Debug System&lt;/strong&gt;: New structured logging with categories, timers, and memory tracking. &lt;code&gt;enable_debug&lt;/code&gt; now available on main node&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Smart FP8 Optimization&lt;/strong&gt;: FP8 models now keep native FP8 storage, converting to BFloat16 only for arithmetic - faster and more memory efficient than FP16&lt;/li&gt; 
 &lt;li&gt;ğŸ“¦ &lt;strong&gt;Model Registry&lt;/strong&gt;: Multi-repo support (numz/ &amp;amp; AInVFX/), auto-discovery of user models, added mixed FP8 variants to fix 7B artifacts&lt;/li&gt; 
 &lt;li&gt;ğŸ’¾ &lt;strong&gt;Model Caching&lt;/strong&gt;: &lt;code&gt;cache_model&lt;/code&gt; moved to main node, fixed memory leaks with proper RoPE/wrapper cleanup&lt;/li&gt; 
 &lt;li&gt;ğŸ§¹ &lt;strong&gt;Code Cleanup&lt;/strong&gt;: New modular structure (&lt;code&gt;constants.py&lt;/code&gt;, &lt;code&gt;model_registry.py&lt;/code&gt;, &lt;code&gt;debug.py&lt;/code&gt;), removed legacy code&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Performance&lt;/strong&gt;: Better memory management with &lt;code&gt;torch.cuda.ipc_collect()&lt;/code&gt;, improved RoPE handling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.07.17&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› ï¸ Add 7B sharp Models: add 2 new 7B models with sharpen output&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.07.11&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¬ Complete tutorial released: Adrien from &lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX&lt;/a&gt; created an in-depth ComfyUI SeedVR2 guide covering everything from basic setup to advanced BlockSwap techniques for running on consumer GPUs. Perfect for understanding memory optimization and upscaling of image sequences with alpha channel! &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-usage"&gt;Watch the tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.09.07&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› ï¸ Blockswap Integration: Big thanks to &lt;a href="https://github.com/adrientoupet"&gt;Adrien Toupet&lt;/a&gt; from &lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX&lt;/a&gt; for this :), useful for low VRAM users (see &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-usage"&gt;usage&lt;/a&gt; section)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.07.03&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› ï¸ Can run as &lt;strong&gt;standalone mode&lt;/strong&gt; with &lt;strong&gt;Multi GPU&lt;/strong&gt; see &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#run-as-standalone-cli"&gt;ğŸ–¥ï¸ Run as Standalone&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.06.30&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ Speed Up the process and less VRAM used&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Fixed memory leak on 3B models&lt;/li&gt; 
 &lt;li&gt;âŒ Can now interrupt process if needed&lt;/li&gt; 
 &lt;li&gt;âœ… Refactored the code for better sharing with the community, feel free to propose pull requests&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Removed flash attention dependency (thanks to &lt;a href="https://github.com/Luke2642"&gt;luke2642&lt;/a&gt; !!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.06.24&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ Speed up the process until x4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.06.22&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’ª FP8 compatibility !&lt;/li&gt; 
 &lt;li&gt;ğŸš€ Speed Up all Process&lt;/li&gt; 
 &lt;li&gt;ğŸš€ less VRAM consumption (Stay high, batch_size=1 for RTX4090 max, I'm trying to fix that)&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ Better benchmark coming soon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2025.06.20&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› ï¸ Initial push&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¯ Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-Quality Diffusion-Based Upscaling&lt;/strong&gt;: One-step diffusion model for video and image enhancement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temporal Consistency&lt;/strong&gt;: Maintains coherence across video frames with configurable batch processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Format Support&lt;/strong&gt;: Handles RGB and RGBA (alpha channel) for both videos and images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Any Video Length&lt;/strong&gt;: Suitable for any video length&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Model Support&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Model Variants&lt;/strong&gt;: 3B and 7B parameter models with different precision options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FP16, FP8, and GGUF Quantization&lt;/strong&gt;: Choose between full precision (FP16), mixed precision (FP8), or heavily quantized GGUF models for different VRAM requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Model Downloads&lt;/strong&gt;: Models are automatically downloaded from HuggingFace on first use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Memory Optimization&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;BlockSwap Technology&lt;/strong&gt;: Dynamically swap transformer blocks between GPU and CPU memory to run large models on limited VRAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VAE Tiling&lt;/strong&gt;: Process large resolutions with tiled encoding/decoding to reduce VRAM usage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Offloading&lt;/strong&gt;: Offload models and intermediate tensors to CPU or secondary GPUs between processing phases&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GGUF Quantization Support&lt;/strong&gt;: Run models with 4-bit or 8-bit quantization for extreme VRAM savings&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;torch.compile Integration&lt;/strong&gt;: Optional 20-40% DiT speedup and 15-25% VAE speedup with PyTorch 2.0+ compilation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-GPU CLI&lt;/strong&gt;: Distribute workload across multiple GPUs with automatic temporal overlap blending&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Caching&lt;/strong&gt;: Keep models loaded between generations for single-GPU directory processing or multi-GPU streaming&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Attention Backends&lt;/strong&gt;: Choose between PyTorch SDPA (stable, always available), Flash Attention 2/3, or SageAttention 2/3 for faster computation on supported hardware&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quality Control&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Color Correction&lt;/strong&gt;: Five methods including LAB (recommended for highest fidelity), wavelet, wavelet adaptive, HSV, and AdaIN&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Noise Injection Controls&lt;/strong&gt;: Fine-tune input and latent noise scales for artifact reduction at high resolutions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Resolution Limits&lt;/strong&gt;: Set target and maximum resolutions with automatic aspect ratio preservation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Workflow Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ComfyUI Integration&lt;/strong&gt;: Four dedicated nodes for complete control over the upscaling pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone CLI&lt;/strong&gt;: Command-line interface for batch processing and automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debug Logging&lt;/strong&gt;: Comprehensive debug mode with memory tracking, timing information, and processing details&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progress Reporting&lt;/strong&gt;: Real-time progress updates during processing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”§ Requirements&lt;/h2&gt; 
&lt;h3&gt;Hardware&lt;/h3&gt; 
&lt;p&gt;With the current optimizations (tiling, BlockSwap, GGUF quantization), SeedVR2 can run on a wide range of hardware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal VRAM&lt;/strong&gt; (8GB or less): Use GGUF Q4_K_M models with BlockSwap and VAE tiling enabled&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Moderate VRAM&lt;/strong&gt; (12-16GB): Use FP8 models with BlockSwap or VAE tiling as needed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High VRAM&lt;/strong&gt; (24GB+): Use FP16 models for best quality and speed without memory optimizations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Software&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ComfyUI&lt;/strong&gt;: Latest version recommended&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+ (Python 3.12 and 3.13 tested and recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;: 2.0+ for torch.compile support (optional but recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Triton&lt;/strong&gt;: Required for torch.compile with inductor backend (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flash Attention / SageAttention&lt;/strong&gt;: Flash Attention 2 (Ampere+), Flash Attention 3 (Hopper+), SageAttention 2 or SageAttention 3 (Blackwell) provide faster attention computation on supported hardware (optional, falls back to PyTorch SDPA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Installation&lt;/h2&gt; 
&lt;h3&gt;Option 1: ComfyUI Manager (Recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open ComfyUI Manager in your ComfyUI interface&lt;/li&gt; 
 &lt;li&gt;Click "Custom Nodes Manager"&lt;/li&gt; 
 &lt;li&gt;Search for "ComfyUI-SeedVR2_VideoUpscaler"&lt;/li&gt; 
 &lt;li&gt;Click "Install" and restart ComfyUI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Registry Link&lt;/strong&gt;: &lt;a href="https://registry.comfy.org/nodes/seedvr2_videoupscaler"&gt;ComfyUI Registry - SeedVR2 Video Upscaler&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Option 2: Manual Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt; into your ComfyUI custom nodes directory:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ComfyUI
git clone https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler.git custom_nodes/seedvr2_videoupscaler
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Install dependencies using standalone Python&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install requirements (from same ComfyUI directory)
# Windows:
.venv\Scripts\python.exe -m pip install -r custom_nodes\seedvr2_videoupscaler\requirements.txt
# Linux/macOS:
.venv/bin/python -m pip install -r custom_nodes/seedvr2_videoupscaler/requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Restart ComfyUI&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Model Installation&lt;/h3&gt; 
&lt;p&gt;Models will be &lt;strong&gt;automatically downloaded&lt;/strong&gt; on first use and saved to &lt;code&gt;ComfyUI/models/SEEDVR2&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also manually download models from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Main models available at &lt;a href="https://huggingface.co/numz/SeedVR2_comfyUI/tree/main"&gt;numz/SeedVR2_comfyUI&lt;/a&gt; and &lt;a href="https://huggingface.co/AInVFX/SeedVR2_comfyUI/tree/main"&gt;AInVFX/SeedVR2_comfyUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Additional GGUF models available at &lt;a href="https://huggingface.co/cmeka/SeedVR2-GGUF/tree/main"&gt;cmeka/SeedVR2-GGUF&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“– Usage&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ Video Tutorials&lt;/h3&gt; 
&lt;h4&gt;Latest Version Deep Dive (Recommended)&lt;/h4&gt; 
&lt;p&gt;Complete walkthrough of version 2.5 by Adrien from &lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX&lt;/a&gt;, covering the new 4-node architecture, GGUF support, memory optimizations, and production workflows:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/MBtWYXq_r60"&gt;&lt;img src="https://img.youtube.com/vi/MBtWYXq_r60/maxresdefault.jpg" alt="SeedVR2 v2.5 Deep Dive Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This comprehensive tutorial covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installing v2.5 through ComfyUI Manager and troubleshooting conflicts&lt;/li&gt; 
 &lt;li&gt;Understanding the new 4-node modular architecture and why we rebuilt it&lt;/li&gt; 
 &lt;li&gt;Running 7B models on 8GB VRAM with GGUF quantization&lt;/li&gt; 
 &lt;li&gt;Configuring BlockSwap, VAE tiling, and torch.compile for your hardware&lt;/li&gt; 
 &lt;li&gt;Image and video upscaling workflows with alpha channel support&lt;/li&gt; 
 &lt;li&gt;CLI for batch processing and multi-GPU rendering&lt;/li&gt; 
 &lt;li&gt;Memory optimization strategies for different VRAM levels&lt;/li&gt; 
 &lt;li&gt;Real production tips and the critical batch_size formula (4n+1)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Previous Version Tutorial&lt;/h4&gt; 
&lt;p&gt;For reference, here's the original tutorial covering the initial release:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/I0sl45GMqNg"&gt;&lt;img src="https://img.youtube.com/vi/I0sl45GMqNg/maxresdefault.jpg" alt="SeedVR2 Deep Dive Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note: This tutorial covers the previous single-node architecture. While the UI has changed significantly in v2.5, the core concepts about BlockSwap and memory management remain valuable.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Node Setup&lt;/h3&gt; 
&lt;p&gt;SeedVR2 uses a modular node architecture with four specialized nodes:&lt;/p&gt; 
&lt;h4&gt;1. SeedVR2 (Down)Load DiT Model&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/dit_model_loader.png" alt="SeedVR2 (Down)Load DiT Model" /&gt;&lt;/p&gt; 
&lt;p&gt;Configure the DiT (Diffusion Transformer) model for video upscaling.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;model&lt;/strong&gt;: Choose your DiT model&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;3B Models&lt;/strong&gt;: Faster, lower VRAM requirements 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_3b_fp16.safetensors&lt;/code&gt;: FP16 (best quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_3b_fp8_e4m3fn.safetensors&lt;/code&gt;: FP8 8-bit (good quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_3b-Q4_K_M.gguf&lt;/code&gt;: GGUF 4-bit quantized (acceptable quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_3b-Q8_0.gguf&lt;/code&gt;: GGUF 8-bit quantized (good quality)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;7B Models&lt;/strong&gt;: Higher quality, higher VRAM requirements 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_7b_fp16.safetensors&lt;/code&gt;: FP16 (best quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_7b_fp8_e4m3fn_mixed_block35_fp16.safetensors&lt;/code&gt;: FP8 with last block in FP16 to reduce artifacts (good quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_7b-Q4_K_M.gguf&lt;/code&gt;: GGUF 4-bit quantized (acceptable quality)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;seedvr2_ema_7b_sharp_*&lt;/code&gt;: Sharp variants for enhanced detail&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;device&lt;/strong&gt;: GPU device for DiT inference (e.g., &lt;code&gt;cuda:0&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;offload_device&lt;/strong&gt;: Device to offload DiT model when not actively processing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: Keep model on inference device (fastest, highest VRAM)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cpu&lt;/code&gt;: Offload to system RAM (reduces VRAM)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cuda:X&lt;/code&gt;: Offload to another GPU (good balance if available)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;cache_model&lt;/strong&gt;: Keep DiT model loaded on offload_device between workflow runs&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Useful for batch processing to avoid repeated loading&lt;/li&gt; 
   &lt;li&gt;Requires offload_device to be set&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;blocks_to_swap&lt;/strong&gt;: BlockSwap memory optimization&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;0&lt;/code&gt;: Disabled (default)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;1-32&lt;/code&gt;: Number of transformer blocks to swap for 3B model&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;1-36&lt;/code&gt;: Number of transformer blocks to swap for 7B model&lt;/li&gt; 
   &lt;li&gt;Higher values = more VRAM savings but slower processing&lt;/li&gt; 
   &lt;li&gt;Requires offload_device to be set and different from device&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;swap_io_components&lt;/strong&gt;: Offload input/output embeddings and normalization layers&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Additional VRAM savings when combined with blocks_to_swap&lt;/li&gt; 
   &lt;li&gt;Requires offload_device to be set and different from device&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;attention_mode&lt;/strong&gt;: Attention computation backend&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sdpa&lt;/code&gt;: PyTorch scaled_dot_product_attention (default, always available)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;flash_attn_2&lt;/code&gt;: Flash Attention 2 (Ampere+, requires flash-attn package)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;flash_attn_3&lt;/code&gt;: Flash Attention 3 (Hopper+, requires flash-attn with FA3 support)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;sageattn_2&lt;/code&gt;: SageAttention 2 (requires sageattention package)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;sageattn_3&lt;/code&gt;: SageAttention 3 (Blackwell/RTX 50xx, requires sageattn3 package)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;torch_compile_args&lt;/strong&gt;: Connect to SeedVR2 Torch Compile Settings node for 20-40% speedup&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;BlockSwap Explained:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;BlockSwap enables running large models on GPUs with limited VRAM by dynamically swapping transformer blocks between GPU and CPU memory during inference.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; BlockSwap is not available on macOS. Apple Silicon Macs use unified memory architecture where GPU and CPU share the same memory pool, making BlockSwap meaningless. The option will be automatically disabled with a warning if requested on macOS.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Here's how it works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;What it does&lt;/strong&gt;: Keeps only the currently-needed transformer blocks on the GPU, while storing the rest on CPU or another device&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;When to use it&lt;/strong&gt;: When you get OOM (Out of Memory) errors during the upscaling phase&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;How to configure&lt;/strong&gt;: 
  &lt;ol&gt; 
   &lt;li&gt;Set &lt;code&gt;offload_device&lt;/code&gt; to &lt;code&gt;cpu&lt;/code&gt; or another GPU&lt;/li&gt; 
   &lt;li&gt;Start with &lt;code&gt;blocks_to_swap=16&lt;/code&gt; (half the blocks)&lt;/li&gt; 
   &lt;li&gt;If still getting OOM, increase to 24 or 32 (3B) / 36 (7B)&lt;/li&gt; 
   &lt;li&gt;Enable &lt;code&gt;swap_io_components&lt;/code&gt; for maximum VRAM savings&lt;/li&gt; 
   &lt;li&gt;If you have plenty of VRAM, decrease or set to 0 for faster processing&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Example Configuration for Low VRAM (8GB)&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;model: &lt;code&gt;seedvr2_ema_3b-Q8_0.gguf&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;device: &lt;code&gt;cuda:0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;offload_device: &lt;code&gt;cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;blocks_to_swap: &lt;code&gt;32&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;swap_io_components: &lt;code&gt;True&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. SeedVR2 (Down)Load VAE Model&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/vae_model_loader.png" alt="SeedVR2 (Down)Load VAE Model" /&gt;&lt;/p&gt; 
&lt;p&gt;Configure the VAE (Variational Autoencoder) model for encoding/decoding video frames.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;model&lt;/strong&gt;: VAE model selection&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ema_vae_fp16.safetensors&lt;/code&gt;: Default and recommended&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;device&lt;/strong&gt;: GPU device for VAE inference (e.g., &lt;code&gt;cuda:0&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;offload_device&lt;/strong&gt;: Device to offload VAE model when not actively processing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: Keep model on inference device (default, fastest)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cpu&lt;/code&gt;: Offload to system RAM (reduces VRAM)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cuda:X&lt;/code&gt;: Offload to another GPU (good balance if available)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;cache_model&lt;/strong&gt;: Keep VAE model loaded on offload_device between workflow runs&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires offload_device to be set&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;encode_tiled&lt;/strong&gt;: Enable tiled encoding to reduce VRAM usage during encoding phase&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Enable if you see OOM errors during the "Encoding" phase in debug logs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;encode_tile_size&lt;/strong&gt;: Encoding tile size in pixels (default: 1024)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Applied to both height and width&lt;/li&gt; 
   &lt;li&gt;Lower values reduce VRAM but may increase processing time&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;encode_tile_overlap&lt;/strong&gt;: Encoding tile overlap in pixels (default: 128)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Reduces visible seams between tiles&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;decode_tiled&lt;/strong&gt;: Enable tiled decoding to reduce VRAM usage during decoding phase&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Enable if you see OOM errors during the "Decoding" phase in debug logs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;decode_tile_size&lt;/strong&gt;: Decoding tile size in pixels (default: 1024)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;decode_tile_overlap&lt;/strong&gt;: Decoding tile overlap in pixels (default: 128)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;torch_compile_args&lt;/strong&gt;: Connect to SeedVR2 Torch Compile Settings node for 15-25% speedup&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;VAE Tiling Explained:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VAE tiling processes large resolutions in smaller tiles to reduce VRAM requirements. Here's how to use it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Run without tiling first&lt;/strong&gt; and monitor the debug logs (enable &lt;code&gt;enable_debug&lt;/code&gt; on main node)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;If OOM during "Encoding" phase&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Enable &lt;code&gt;encode_tiled&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If still OOM, reduce &lt;code&gt;encode_tile_size&lt;/code&gt; (try 768, 512, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;If OOM during "Decoding" phase&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Enable &lt;code&gt;decode_tiled&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If still OOM, reduce &lt;code&gt;decode_tile_size&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adjust overlap&lt;/strong&gt; (default 128) if you see visible seams in output (increase it) or processing times are too slow (decrease it).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example Configuration for High Resolution (4K)&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;encode_tiled: &lt;code&gt;True&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;encode_tile_size: &lt;code&gt;1024&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;encode_tile_overlap: &lt;code&gt;128&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;decode_tiled: &lt;code&gt;True&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;decode_tile_size: &lt;code&gt;1024&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;decode_tile_overlap: &lt;code&gt;128&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. SeedVR2 Torch Compile Settings (Optional)&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/torch_compile_settings.png" alt="SeedVR2 Torch Compile Settings" /&gt;&lt;/p&gt; 
&lt;p&gt;Configure torch.compile optimization for 20-40% DiT speedup and 15-25% VAE speedup.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PyTorch 2.0+&lt;/li&gt; 
 &lt;li&gt;Triton (for inductor backend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;backend&lt;/strong&gt;: Compilation backend&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;inductor&lt;/code&gt;: Full optimization with Triton kernel generation and fusion (recommended)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cudagraphs&lt;/code&gt;: Lightweight wrapper using CUDA graphs, no kernel optimization&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;mode&lt;/strong&gt;: Optimization level (compilation time vs runtime performance)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;default&lt;/code&gt;: Fast compilation with good speedup (recommended for development)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;reduce-overhead&lt;/code&gt;: Lower overhead, optimized for smaller models&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;max-autotune&lt;/code&gt;: Slowest compilation, best runtime performance (recommended for production)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;max-autotune-no-cudagraphs&lt;/code&gt;: Like max-autotune but without CUDA graphs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;fullgraph&lt;/strong&gt;: Compile entire model as single graph without breaks&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;False&lt;/code&gt;: Allow graph breaks for better compatibility (default, recommended)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;True&lt;/code&gt;: Enforce no breaks for maximum optimization (may fail with dynamic shapes)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;dynamic&lt;/strong&gt;: Handle varying input shapes without recompilation&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;False&lt;/code&gt;: Specialize for exact input shapes (default)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;True&lt;/code&gt;: Create dynamic kernels that adapt to shape variations (enable when processing different resolutions or batch sizes)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;dynamo_cache_size_limit&lt;/strong&gt;: Max cached compiled versions per function (default: 64)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Higher = more memory, lower = more recompilation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;dynamo_recompile_limit&lt;/strong&gt;: Max recompilation attempts before falling back to eager mode (default: 128)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Safety limit to prevent compilation loops&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add this node to your workflow&lt;/li&gt; 
 &lt;li&gt;Connect its output to the &lt;code&gt;torch_compile_args&lt;/code&gt; input of DiT and/or VAE loader nodes&lt;/li&gt; 
 &lt;li&gt;First run will be slow (compilation), subsequent runs will be much faster&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;When to use:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;torch.compile only makes sense when processing &lt;strong&gt;multiple batches, long videos, or many tiles&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;For single images or short clips, the compilation time outweighs the speed improvement&lt;/li&gt; 
 &lt;li&gt;Best suited for batch processing workflows or long videos&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Recommended Settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For development/testing: &lt;code&gt;mode=default&lt;/code&gt;, &lt;code&gt;backend=inductor&lt;/code&gt;, &lt;code&gt;fullgraph=False&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For production: &lt;code&gt;mode=max-autotune&lt;/code&gt;, &lt;code&gt;backend=inductor&lt;/code&gt;, &lt;code&gt;fullgraph=False&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. SeedVR2 Video Upscaler (Main Node)&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/docs/video_upscaler.png" alt="SeedVR2 Video Upscaler" /&gt;&lt;/p&gt; 
&lt;p&gt;Main upscaling node that processes video frames using DiT and VAE models.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Required Inputs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;: Input video frames as image batch (RGB or RGBA format)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dit&lt;/strong&gt;: DiT model configuration from SeedVR2 (Down)Load DiT Model node&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;vae&lt;/strong&gt;: VAE model configuration from SeedVR2 (Down)Load VAE Model node&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;seed&lt;/strong&gt;: Random seed for reproducible generation (default: 42)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Same seed with same inputs produces identical output&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;resolution&lt;/strong&gt;: Target resolution for shortest edge in pixels (default: 1080)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Maintains aspect ratio automatically&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;max_resolution&lt;/strong&gt;: Maximum resolution for any edge (default: 0 = no limit)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Automatically scales down if exceeded to prevent OOM&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;batch_size&lt;/strong&gt;: Frames per batch (default: 5)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;CRITICAL REQUIREMENT&lt;/strong&gt;: Must follow the &lt;strong&gt;4n+1 formula&lt;/strong&gt; (1, 5, 9, 13, 17, 21, 25, ...)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Why this matters&lt;/strong&gt;: The model uses these frames for temporal consistency calculations&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Minimum 5 for temporal consistency&lt;/strong&gt;: Use 1 only for single images or when temporal consistency isn't needed&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Match shot length ideally&lt;/strong&gt;: For best results, set batch_size to match your shot length (e.g., batch_size=21 for a 20-frame shot)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;VRAM impact&lt;/strong&gt;: Higher batch_size = better quality and speed but requires more VRAM&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;If you get OOM with batch_size=5&lt;/strong&gt;: Try optimization techniques first (model offloading, BlockSwap, GGUF models...) before reducing batch_size or input resolution, as these directly impact quality&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;uniform_batch_size&lt;/strong&gt; (default: False)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pads the final batch to match &lt;code&gt;batch_size&lt;/code&gt; for uniform processing&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prevents temporal artifacts when the last batch is significantly smaller than others&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Example: 45 frames with &lt;code&gt;batch_size=33&lt;/code&gt; creates [33, 33] instead of [33, 12]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Recommended when using large batch sizes and video length is not a multiple of &lt;code&gt;batch_size&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Increases VRAM usage slightly but ensures consistent temporal coherence across all batches&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;temporal_overlap&lt;/strong&gt;: Overlapping frames between batches (default: 0)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Used for blending between batches to reduce temporal artifacts&lt;/li&gt; 
   &lt;li&gt;Range: 0-16 frames&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;prepend_frames&lt;/strong&gt;: Frames to prepend (default: 0)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prepends reversed frames to reduce artifacts at video start&lt;/li&gt; 
   &lt;li&gt;Automatically removed after processing&lt;/li&gt; 
   &lt;li&gt;Range: 0-32 frames&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;color_correction&lt;/strong&gt;: Color correction method (default: "wavelet")&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;lab&lt;/code&gt;&lt;/strong&gt;: Full perceptual color matching with detail preservation (recommended for highest fidelity to original)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;wavelet&lt;/code&gt;&lt;/strong&gt;: Frequency-based natural colors, preserves details well&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;wavelet_adaptive&lt;/code&gt;&lt;/strong&gt;: Wavelet base + targeted saturation correction&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;hsv&lt;/code&gt;&lt;/strong&gt;: Hue-conditional saturation matching&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;adain&lt;/code&gt;&lt;/strong&gt;: Statistical style transfer&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;&lt;code&gt;none&lt;/code&gt;&lt;/strong&gt;: No color correction&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;input_noise_scale&lt;/strong&gt;: Input noise injection scale 0.0-1.0 (default: 0.0)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Adds noise to input frames to reduce artifacts at very high resolutions&lt;/li&gt; 
   &lt;li&gt;Try 0.1-0.3 if you see artifacts with high output resolutions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;latent_noise_scale&lt;/strong&gt;: Latent space noise scale 0.0-1.0 (default: 0.0)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Adds noise during diffusion process, can soften excessive detail&lt;/li&gt; 
   &lt;li&gt;Use if input_noise doesn't help, try 0.05-0.15&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;offload_device&lt;/strong&gt;: Device for storing intermediate tensors between processing phases (default: "cpu")&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: Keep all tensors on inference device (fastest but highest VRAM)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cpu&lt;/code&gt;: Offload to system RAM (recommended for long videos, slower transfers)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cuda:X&lt;/code&gt;: Offload to another GPU (good balance if available, faster than CPU)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;enable_debug&lt;/strong&gt;: Enable detailed debug logging (default: False)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Shows memory usage, timing information, and processing details&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Highly recommended&lt;/strong&gt; for troubleshooting OOM issues&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Upscaled video frames with color correction applied&lt;/li&gt; 
 &lt;li&gt;Format (RGB/RGBA) matches input&lt;/li&gt; 
 &lt;li&gt;Range [0, 1] normalized for ComfyUI compatibility&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Typical Workflow Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Basic Workflow (High VRAM - 24GB+)&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Load Video Frames
    â†“
SeedVR2 Load DiT Model
  â”œâ”€ model: seedvr2_ema_3b_fp16.safetensors
  â””â”€ device: cuda:0
    â†“
SeedVR2 Load VAE Model
  â”œâ”€ model: ema_vae_fp16.safetensors
  â””â”€ device: cuda:0
    â†“
SeedVR2 Video Upscaler
  â”œâ”€ batch_size: 21
  â””â”€ resolution: 1080
    â†“
Save Video/Frames
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Low VRAM Workflow (8-12GB)&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Load Video Frames
    â†“
SeedVR2 Load DiT Model
  â”œâ”€ model: seedvr2_ema_3b-Q8_0.gguf
  â”œâ”€ device: cuda:0
  â”œâ”€ offload_device: cpu
  â”œâ”€ blocks_to_swap: 32
  â””â”€ swap_io_components: True
    â†“
SeedVR2 Load VAE Model
  â”œâ”€ model: ema_vae_fp16.safetensors
  â”œâ”€ device: cuda:0
  â”œâ”€ encode_tiled: True
  â””â”€ decode_tiled: True
    â†“
SeedVR2 Video Upscaler
  â”œâ”€ batch_size: 5
  â””â”€ resolution: 720
    â†“
Save Video/Frames
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;High Performance Workflow (24GB+ with torch.compile)&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Load Video Frames
    â†“
SeedVR2 Torch Compile Settings
  â”œâ”€ mode: max-autotune
  â””â”€ backend: inductor
    â†“
SeedVR2 Load DiT Model
  â”œâ”€ model: seedvr2_ema_7b_sharp_fp16.safetensors
  â”œâ”€ device: cuda:0
  â””â”€ torch_compile_args: connected
    â†“
SeedVR2 Load VAE Model
  â”œâ”€ model: ema_vae_fp16.safetensors
  â”œâ”€ device: cuda:0
  â””â”€ torch_compile_args: connected
    â†“
SeedVR2 Video Upscaler
  â”œâ”€ batch_size: 81
  â””â”€ resolution: 1080
    â†“
Save Video/Frames
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ–¥ï¸ Run as Standalone (CLI)&lt;/h2&gt; 
&lt;p&gt;The standalone CLI provides powerful batch processing capabilities with multi-GPU support and sophisticated optimization options.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Choose the appropriate setup based on your installation:&lt;/p&gt; 
&lt;h4&gt;Option 1: Already Have ComfyUI with SeedVR2 Installed&lt;/h4&gt; 
&lt;p&gt;If you've already installed SeedVR2 as part of ComfyUI (via &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#-installation"&gt;ComfyUI installation&lt;/a&gt;), you can use the CLI directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to your ComfyUI directory
cd ComfyUI

# Run the CLI using standalone Python (display help message)
# Windows:
.venv\Scripts\python.exe custom_nodes\seedvr2_videoupscaler\inference_cli.py --help
# Linux/macOS:
.venv/bin/python custom_nodes/seedvr2_videoupscaler/inference_cli.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Skip to &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/#command-line-usage"&gt;Command Line Usage&lt;/a&gt; below.&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Option 2: Standalone Installation (Without ComfyUI)&lt;/h4&gt; 
&lt;p&gt;If you want to use the CLI without ComfyUI installation, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt;&lt;/strong&gt; (modern Python package manager):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS and Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler.git seedvr2_videoupscaler
cd seedvr2_videoupscaler
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Create virtual environment and install dependencies&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create virtual environment with Python 3.13
uv venv --python 3.13

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# Linux/macOS:
source .venv/bin/activate

# Install PyTorch with CUDA support
# Check command line based on your environment: https://pytorch.org/get-started/locally/
uv pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130

# Install SeedVR2 requirements
uv pip install -r requirements.txt

# Run the CLI (display help message)
# Windows:
.venv\Scripts\python.exe inference_cli.py --help
# Linux/macOS:
.venv/bin/python inference_cli.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command Line Usage&lt;/h3&gt; 
&lt;p&gt;The CLI provides comprehensive options for single-GPU, multi-GPU, and batch processing workflows.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic Usage Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic image upscaling
python inference_cli.py image.jpg

# Basic video upscaling with temporal consistency
python inference_cli.py video.mp4 --resolution 720 --batch_size 33

# Streaming mode for long videos (memory-efficient) with 10-bit video output (requires FFMPEG)
# Processes video in chunks of 330 frames to avoid loading entire video into RAM
# Use --temporal_overlap to ensure smooth transitions between chunks
python inference_cli.py long_video.mp4 \
    --resolution 1080 \
    --batch_size 33 \
    --chunk_size 330 \
    --temporal_overlap 3 \
    --video_backend ffmpeg \
    --10bit

# Multi-GPU processing with temporal overlap
python inference_cli.py video.mp4 \
    --cuda_device 0,1 \
    --resolution 1080 \
    --batch_size 81 \
    --uniform_batch_size \
    --temporal_overlap 3 \
    --prepend_frames 4

# Memory-optimized for low VRAM (8GB)
python inference_cli.py image.png \
    --dit_model seedvr2_ema_3b-Q8_0.gguf \
    --resolution 1080 \
    --blocks_to_swap 32 \
    --swap_io_components \
    --dit_offload_device cpu \
    --vae_offload_device cpu

# High resolution with VAE tiling
python inference_cli.py video.mp4 \
    --resolution 1440 \
    --batch_size 31 \
    --uniform_batch_size \
    --temporal_overlap 3 \
    --vae_encode_tiled \
    --vae_decode_tiled

# Batch directory processing with model caching
python inference_cli.py media_folder/ \
    --output processed/ \
    --cuda_device 0 \
    --cache_dit \
    --cache_vae \
    --dit_offload_device cpu \
    --vae_offload_device cpu \
    --resolution 1080 \
    --max_resolution 1920
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command Line Arguments&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Input/Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt;: Input file (.mp4, .avi, .png, .jpg, etc.) or directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output&lt;/code&gt;: Output path (default: auto-generated in 'output/' directory)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--output_format&lt;/code&gt;: Output format: 'mp4' (video) or 'png' (image sequence). Default: auto-detect from input type&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--video_backend&lt;/code&gt;: Video encoder backend: 'opencv' (default) or 'ffmpeg' (requires ffmpeg in PATH)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--10bit&lt;/code&gt;: Save 10-bit video with x265 codec and yuv420p10le pixel format (reduces banding in gradients). Without this flag, ffmpeg uses x264 (yuv420p) for maximum compatibility. Requires --video_backend ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--model_dir&lt;/code&gt;: Model directory (default: ./models/SEEDVR2)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Model Selection:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--dit_model&lt;/code&gt;: DiT model to use. Options: 3B/7B with fp16/fp8/GGUF variants (default: 3B FP8)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Processing Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--resolution&lt;/code&gt;: Target short-side resolution in pixels (default: 1080)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max_resolution&lt;/code&gt;: Maximum resolution for any edge. Scales down if exceeded. 0 = no limit (default: 0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--batch_size&lt;/code&gt;: Frames per batch (must follow 4n+1: 1, 5, 9, 13, 17, 21...). Ideally matches shot length for best temporal consistency (default: 5)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--seed&lt;/code&gt;: Random seed for reproducibility (default: 42)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--skip_first_frames&lt;/code&gt;: Skip N initial frames (default: 0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--load_cap&lt;/code&gt;: Maximum total frames to load from video. 0 = load all (default: 0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--chunk_size&lt;/code&gt;: Frames per chunk for streaming mode. When &amp;gt; 0, processes video in memory-bounded chunks of N frames, writing each chunk before loading the next. Essential for long videos that would otherwise exceed RAM. Use with &lt;code&gt;--temporal_overlap&lt;/code&gt; for seamless chunk transitions. 0 = load all frames at once (default: 0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--prepend_frames&lt;/code&gt;: Prepend N reversed frames to reduce start artifacts (auto-removed) (default: 0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--temporal_overlap&lt;/code&gt;: Frames to overlap between batches/GPUs for smooth blending (default: 0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quality Control:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--color_correction&lt;/code&gt;: Color correction method: 'lab' (perceptual, recommended), 'wavelet', 'wavelet_adaptive', 'hsv', 'adain', or 'none' (default: lab)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--input_noise_scale&lt;/code&gt;: Input noise injection scale (0.0-1.0). Reduces artifacts at high resolutions (default: 0.0)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--latent_noise_scale&lt;/code&gt;: Latent space noise scale (0.0-1.0). Softens details if needed (default: 0.0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Memory Management:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--dit_offload_device&lt;/code&gt;: Device to offload DiT model: 'none' (keep on GPU), 'cpu', or 'cuda:X' (default: none)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_offload_device&lt;/code&gt;: Device to offload VAE model: 'none', 'cpu', or 'cuda:X' (default: none)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--blocks_to_swap&lt;/code&gt;: Number of transformer blocks to swap (0=disabled, 3B: 0-32, 7B: 0-36). Requires dit_offload_device (default: 0). Not available on macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--swap_io_components&lt;/code&gt;: Offload I/O components for additional VRAM savings. Requires dit_offload_device. Not available on macOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;VAE Tiling:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--vae_encode_tiled&lt;/code&gt;: Enable VAE encode tiling to reduce VRAM during encoding&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_encode_tile_size&lt;/code&gt;: VAE encode tile size in pixels (default: 1024)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_encode_tile_overlap&lt;/code&gt;: VAE encode tile overlap in pixels (default: 128)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_decode_tiled&lt;/code&gt;: Enable VAE decode tiling to reduce VRAM during decoding&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_decode_tile_size&lt;/code&gt;: VAE decode tile size in pixels (default: 1024)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--vae_decode_tile_overlap&lt;/code&gt;: VAE decode tile overlap in pixels (default: 128)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tile_debug&lt;/code&gt;: Visualize tiles: 'false' (default), 'encode', or 'decode'&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Optimization:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--allow_vram_overflow&lt;/code&gt;: Allow VRAM overflow to system RAM. Prevents OOM but may cause severe slowdown&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--attention_mode&lt;/code&gt;: Attention backend: 'sdpa' (default), 'flash_attn_2' (Ampere+), 'flash_attn_3' (Hopper+), 'sageattn_2', or 'sageattn_3' (Blackwell)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_dit&lt;/code&gt;: Enable torch.compile for DiT model (20-40% speedup, requires PyTorch 2.0+ and Triton)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_vae&lt;/code&gt;: Enable torch.compile for VAE model (15-25% speedup, requires PyTorch 2.0+ and Triton)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_backend&lt;/code&gt;: Compilation backend: 'inductor' (full optimization) or 'cudagraphs' (lightweight) (default: inductor)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_mode&lt;/code&gt;: Optimization level: 'default', 'reduce-overhead', 'max-autotune', 'max-autotune-no-cudagraphs' (default: default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_fullgraph&lt;/code&gt;: Compile entire model as single graph (faster but less flexible) (default: False)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_dynamic&lt;/code&gt;: Handle varying input shapes without recompilation (default: False)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_dynamo_cache_size_limit&lt;/code&gt;: Max cached compiled versions per function (default: 64)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compile_dynamo_recompile_limit&lt;/code&gt;: Max recompilation attempts before fallback (default: 128)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Model Caching (batch processing):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cache_dit&lt;/code&gt;: Keep DiT model in memory between generations. Works with single-GPU directory processing or multi-GPU streaming (&lt;code&gt;--chunk_size&lt;/code&gt;). Requires &lt;code&gt;--dit_offload_device&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cache_vae&lt;/code&gt;: Keep VAE model in memory between generations. Works with single-GPU directory processing or multi-GPU streaming (&lt;code&gt;--chunk_size&lt;/code&gt;). Requires &lt;code&gt;--vae_offload_device&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Multi-GPU:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cuda_device&lt;/code&gt;: CUDA device id(s). Single id (e.g., '0') or comma-separated list '0,1' for multi-GPU&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debugging:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt;: Enable verbose debug logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multi-GPU Processing Explained&lt;/h3&gt; 
&lt;p&gt;The CLI's multi-GPU mode uses &lt;strong&gt;frame-level parallelism&lt;/strong&gt;: the video is split into chunks and each GPU processes its chunk independently through all 4 phases (encode â†’ upscale â†’ decode â†’ postprocess). This is ideal for long videos where you want to reduce total processing time by dividing the workload.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Video frames are split evenly across GPUs (e.g., 100 frames on 2 GPUs â†’ 50 frames each)&lt;/li&gt; 
 &lt;li&gt;Each GPU loads its own copy of the models and processes its chunk independently&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--temporal_overlap&lt;/code&gt; is set, chunks include overlapping frames for seamless blending&lt;/li&gt; 
 &lt;li&gt;Results are concatenated (and blended at overlap regions) into the final video&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example for 100 frames on 2 GPUs with temporal_overlap=4:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GPU 0: Frames 0-53 (50 base + 4 overlap at end, processed as independent video)
GPU 1: Frames 50-99 (50 frames, 4 overlap at start, processed as independent video)
Result: Frames 0-99 with smooth blending at the transition point
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important considerations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each GPU processes its chunk as a separate video with its own batch splitting&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt; controls batching &lt;em&gt;within&lt;/em&gt; each GPU's chunk, not across GPUs&lt;/li&gt; 
 &lt;li&gt;For short videos (&amp;lt; 100 frames), single GPU is often more efficient due to model loading overhead&lt;/li&gt; 
 &lt;li&gt;Multi-GPU doubles VRAM usage (each GPU loads full models) but roughly halves processing time&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;When to use multi-GPU:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Long videos (100+ frames) where splitting provides significant time savings&lt;/li&gt; 
 &lt;li&gt;When you have multiple GPUs with sufficient VRAM each&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;When to use single GPU:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Short videos where model loading overhead outweighs parallel gains&lt;/li&gt; 
 &lt;li&gt;When you want all frames processed together for maximum temporal coherence&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best practices:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set &lt;code&gt;--temporal_overlap&lt;/code&gt; to 2-4 frames for smooth blending between GPU chunks&lt;/li&gt; 
 &lt;li&gt;Higher overlap = smoother transitions but more redundant processing&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--prepend_frames&lt;/code&gt; to reduce artifacts at video start&lt;/li&gt; 
 &lt;li&gt;For optimal quality on short videos, use single GPU with &lt;code&gt;batch_size&lt;/code&gt; matching your shot length&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš ï¸ Limitations&lt;/h2&gt; 
&lt;h3&gt;Model Limitations&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Batch Size Constraint&lt;/strong&gt;: The model requires batch_size to follow the &lt;strong&gt;4n+1 formula&lt;/strong&gt; (1, 5, 9, 13, 17, 21, 25, ...) due to temporal consistency architecture. All frames in a batch are processed together for temporal coherence, then batches can be blended using temporal_overlap. Ideally, set batch_size to match your shot length for optimal quality.&lt;/p&gt; 
&lt;h3&gt;Performance Considerations&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;VAE Bottleneck&lt;/strong&gt;: Even with optimized DiT upscaling (BlockSwap, GGUF, torch.compile), the VAE encoding/decoding stages can be the bottleneck, especially for high resolutions. The VAE is slow. Use large batch_size to mitigate this.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;VRAM Usage&lt;/strong&gt;: While the integration now supports low VRAM systems (8GB or less with proper optimization), VRAM usage varies based on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Input/output resolution (larger = more VRAM)&lt;/li&gt; 
 &lt;li&gt;Batch size (higher = more VRAM but better temporal consistency and speed)&lt;/li&gt; 
 &lt;li&gt;Model choice (FP16 &amp;gt; FP8 &amp;gt; GGUF in VRAM usage)&lt;/li&gt; 
 &lt;li&gt;Optimization settings (BlockSwap, VAE tiling significantly reduce VRAM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Processing speed depends on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GPU capabilities (compute performance, VRAM bandwidth, and architecture generation)&lt;/li&gt; 
 &lt;li&gt;Model size (3B faster than 7B)&lt;/li&gt; 
 &lt;li&gt;Batch size (larger batch sizes are faster per frame due to better GPU utilization)&lt;/li&gt; 
 &lt;li&gt;Optimization settings (torch.compile provides significant speedup)&lt;/li&gt; 
 &lt;li&gt;Resolution (higher resolutions are slower)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start with debug enabled&lt;/strong&gt; to understand where VRAM is being used&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For OOM errors during encoding&lt;/strong&gt;: Enable VAE encode tiling and reduce tile size&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For OOM errors during upscaling&lt;/strong&gt;: Enable BlockSwap and increase blocks_to_swap&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For OOM errors during decoding&lt;/strong&gt;: Enable VAE decode tiling and reduce tile size 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;If still getting OOM after trying all above&lt;/strong&gt;: Reduce batch_size or resolution&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For best quality&lt;/strong&gt;: Use higher batch_size matching your shot length, FP16 models, and LAB color correction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For speed&lt;/strong&gt;: Use FP8/GGUF models, enable torch.compile, and use Flash Attention if available&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test settings with a short clip first&lt;/strong&gt; before processing long videos&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! We value community input and improvements.&lt;/p&gt; 
&lt;p&gt;For detailed contribution guidelines, see &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create your feature branch (&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Commit your changes (&lt;code&gt;git commit -m 'Add some AmazingFeature'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Open a Pull Request to the &lt;strong&gt;main&lt;/strong&gt; branch&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Get Help:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;YouTube: &lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX Channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub &lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/issues"&gt;Issues&lt;/a&gt;: For bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;GitHub &lt;a href="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/discussions"&gt;Discussions&lt;/a&gt;: For questions and community support&lt;/li&gt; 
 &lt;li&gt;Discord: adrientoupet &amp;amp; NumZ#7184&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™ Credits&lt;/h2&gt; 
&lt;p&gt;This ComfyUI implementation is a collaborative project by &lt;strong&gt;&lt;a href="https://github.com/numz"&gt;NumZ&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://www.youtube.com/@AInVFX"&gt;AInVFX&lt;/a&gt;&lt;/strong&gt; (Adrien Toupet), based on the original &lt;a href="https://github.com/ByteDance-Seed/SeedVR"&gt;SeedVR2&lt;/a&gt; by ByteDance Seed Team.&lt;/p&gt; 
&lt;p&gt;Special thanks to our community contributors including &lt;a href="https://github.com/naxci1"&gt;naxci1&lt;/a&gt;, &lt;a href="https://github.com/benjaminherb"&gt;benjaminherb&lt;/a&gt;, &lt;a href="https://github.com/cmeka"&gt;cmeka&lt;/a&gt;, &lt;a href="https://github.com/FurkanGozukara"&gt;FurkanGozukara&lt;/a&gt;, &lt;a href="https://github.com/JohnAlcatraz"&gt;JohnAlcatraz&lt;/a&gt;, &lt;a href="https://github.com/lihaoyun6"&gt;lihaoyun6&lt;/a&gt;, &lt;a href="https://github.com/Luchuanzhao"&gt;Luchuanzhao&lt;/a&gt;, &lt;a href="https://github.com/Luke2642"&gt;Luke2642&lt;/a&gt;, &lt;a href="https://github.com/proxyid"&gt;proxyid&lt;/a&gt;, &lt;a href="https://github.com/q5sys"&gt;q5sys&lt;/a&gt;, and many others for their improvements, bug fixes, and testing.&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ License&lt;/h2&gt; 
&lt;p&gt;The code in this repository is released under the Apache 2.0 license as found in the &lt;a href="https://raw.githubusercontent.com/numz/ComfyUI-SeedVR2_VideoUpscaler/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/LightRAG</title>
      <link>https://github.com/HKUDS/LightRAG</link>
      <description>&lt;p&gt;[EMNLP2025] "LightRAG: Simple and Fast Retrieval-Augmented Generation"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/assets/logo.png" width="120" height="120" alt="LightRAG Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;ğŸš€ LightRAG: Simple and Fast Retrieval-Augmented Generation&lt;/h1&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/13043" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13043" alt="HKUDS%2FLightRAG | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/ğŸ”¥Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/ğŸ“„arXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/LightRAG?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/lightrag-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/lightrag-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG/issues/285"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README-zh.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡¨ğŸ‡³ä¸­æ–‡ç‰ˆ-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡ºğŸ‡¸English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://pepy.tech/projects/lightrag-hku"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/lightrag-hku?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=BLACK&amp;amp;right_color=GREEN&amp;amp;left_text=downloads" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center" style="margin: 30px 0;"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="800" /&gt; 
&lt;/div&gt; 
&lt;div align="center" style="margin: 30px 0;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.assets/b2aaf634151b4706892693ffb43d9093.png" width="800" alt="LightRAG Diagram" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ‰ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025.11]ğŸ¯[New Feature]: Integrated &lt;strong&gt;RAGAS for Evaluation&lt;/strong&gt; and &lt;strong&gt;Langfuse for Tracing&lt;/strong&gt;. Updated the API to return retrieved contexts alongside query results to support context precision metrics.&lt;/li&gt; 
 &lt;li&gt;[2025.10]ğŸ¯[Scalability Enhancement]: Eliminated processing bottlenecks to support &lt;strong&gt;Large-Scale Datasets Efficiently&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025.09]ğŸ¯[New Feature] Enhances knowledge graph extraction accuracy for &lt;strong&gt;Open-Sourced LLMs&lt;/strong&gt; such as Qwen3-30B-A3B.&lt;/li&gt; 
 &lt;li&gt;[2025.08]ğŸ¯[New Feature] &lt;strong&gt;Reranker&lt;/strong&gt; is now supported, significantly boosting performance for mixed queries (set as default query mode).&lt;/li&gt; 
 &lt;li&gt;[2025.08]ğŸ¯[New Feature] Added &lt;strong&gt;Document Deletion&lt;/strong&gt; with automatic KG regeneration to ensure optimal query performance.&lt;/li&gt; 
 &lt;li&gt;[2025.06]ğŸ¯[New Release] Our team has released &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt; â€” an &lt;strong&gt;All-in-One Multimodal RAG&lt;/strong&gt; system for seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;[2025.06]ğŸ¯[New Feature] LightRAG now supports comprehensive multimodal data handling through &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt; integration, enabling seamless document parsing and RAG capabilities across diverse formats including PDFs, images, Office documents, tables, and formulas. Please refer to the new &lt;a href="https://github.com/HKUDS/LightRAG/?tab=readme-ov-file#multimodal-document-processing-rag-anything-integration"&gt;multimodal section&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;[2025.03]ğŸ¯[New Feature] LightRAG now supports citation functionality, enabling proper source attribution and enhanced document traceability.&lt;/li&gt; 
 &lt;li&gt;[2025.02]ğŸ¯[New Feature] You can now use MongoDB as an all-in-one storage solution for unified data management.&lt;/li&gt; 
 &lt;li&gt;[2025.02]ğŸ¯[New Release] Our team has released &lt;a href="https://github.com/HKUDS/VideoRAG"&gt;VideoRAG&lt;/a&gt;-a RAG system for understanding extremely long-context videos&lt;/li&gt; 
 &lt;li&gt;[2025.01]ğŸ¯[New Release] Our team has released &lt;a href="https://github.com/HKUDS/MiniRAG"&gt;MiniRAG&lt;/a&gt; making RAG simpler with small models.&lt;/li&gt; 
 &lt;li&gt;[2025.01]ğŸ¯You can now use PostgreSQL as an all-in-one storage solution for data management.&lt;/li&gt; 
 &lt;li&gt;[2024.11]ğŸ¯[New Resource] A comprehensive guide to LightRAG is now available on &lt;a href="https://learnopencv.com/lightrag"&gt;LearnOpenCV&lt;/a&gt;. â€” explore in-depth tutorials and best practices. Many thanks to the blog author for this excellent contribution!&lt;/li&gt; 
 &lt;li&gt;[2024.11]ğŸ¯[New Feature] Introducing the LightRAG WebUI â€” an interface that allows you to insert, query, and visualize LightRAG knowledge through an intuitive web-based dashboard.&lt;/li&gt; 
 &lt;li&gt;[2024.11]ğŸ¯[New Feature] You can now &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#using-neo4j-for-storage"&gt;use Neo4J for Storage&lt;/a&gt;-enabling graph database support.&lt;/li&gt; 
 &lt;li&gt;[2024.10]ğŸ¯[New Feature] We've added a link to a &lt;a href="https://youtu.be/oageL-1I0GE"&gt;LightRAG Introduction Video&lt;/a&gt;. â€” a walkthrough of LightRAG's capabilities. Thanks to the author for this excellent contribution!&lt;/li&gt; 
 &lt;li&gt;[2024.10]ğŸ¯[New Channel] We have created a &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;Discord channel&lt;/a&gt;!ğŸ’¬ Welcome to join our community for sharing, discussions, and collaboration! ğŸ‰ğŸ‰&lt;/li&gt; 
 &lt;li&gt;[2024.10]ğŸ¯[New Feature] LightRAG now supports &lt;a href="https://github.com/HKUDS/LightRAG?tab=readme-ov-file#quick-start"&gt;Ollama models&lt;/a&gt;!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary style="font-size: 1.4em; font-weight: bold; cursor: pointer; display: list-item;"&gt; Algorithm Flowchart &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-VectorDB-Json-KV-Store-Indexing-Flowchart-scaled.jpg" alt="LightRAG Indexing Flowchart" /&gt; &lt;em&gt;Figure 1: LightRAG Indexing Flowchart - Img Caption : &lt;a href="https://learnopencv.com/lightrag/"&gt;Source&lt;/a&gt;&lt;/em&gt; &lt;img src="https://learnopencv.com/wp-content/uploads/2024/11/LightRAG-Querying-Flowchart-Dual-Level-Retrieval-Generation-Knowledge-Graphs-scaled.jpg" alt="LightRAG Retrieval and Querying Flowchart" /&gt; &lt;em&gt;Figure 2: LightRAG Retrieval and Querying Flowchart - Img Caption : &lt;a href="https://learnopencv.com/lightrag/"&gt;Source&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Using uv for Package Management&lt;/strong&gt;: This project uses &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; for fast and reliable Python package management. Install uv first: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt; (Unix/macOS) or &lt;code&gt;powershell -c "irm https://astral.sh/uv/install.ps1 | iex"&lt;/code&gt; (Windows)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can also use pip if you prefer, but uv is recommended for better performance and more reliable dependency management.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“¦ Offline Deployment&lt;/strong&gt;: For offline or air-gapped environments, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/docs/OfflineDeployment.md"&gt;Offline Deployment Guide&lt;/a&gt; for instructions on pre-installing all dependencies and cache files.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install LightRAG Server&lt;/h3&gt; 
&lt;p&gt;The LightRAG Server is designed to provide Web UI and API support. The Web UI facilitates document indexing, knowledge graph exploration, and a simple RAG query interface. LightRAG Server also provide an Ollama compatible interfaces, aiming to emulate LightRAG as an Ollama chat model. This allows AI chat bot, such as Open WebUI, to access LightRAG easily.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from PyPI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using uv (recommended)
uv pip install "lightrag-hku[api]"
# Or using pip
# pip install "lightrag-hku[api]"

cp env.example .env  # Update the .env with your LLM and embedding configurations

lightrag-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation from Source&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG

# Using uv (recommended)
# Note: uv sync automatically creates a virtual environment in .venv/
uv sync --extra api
source .venv/bin/activate  # Activate the virtual environment (Linux/macOS)
# Or on Windows: .venv\Scripts\activate

# Or using pip with virtual environment
# python -m venv .venv
# source .venv/bin/activate  # Windows: .venv\Scripts\activate
# pip install -e ".[api]"

cp env.example .env  # Update the .env with your LLM and embedding configurations

# Build front-end artifacts
cd lightrag_webui
bun install --frozen-lockfile
bun run build
cd ..

lightrag-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launching the LightRAG Server with Docker Compose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
cp env.example .env  # Update the .env with your LLM and embedding configurations
# modify LLM and Embedding settings in .env
docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Historical versions of LightRAG docker images can be found here: &lt;a href="https://github.com/HKUDS/LightRAG/pkgs/container/lightrag"&gt;LightRAG Docker Images&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install LightRAG Core&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from source (Recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd LightRAG
# Note: uv sync automatically creates a virtual environment in .venv/
uv sync
source .venv/bin/activate  # Activate the virtual environment (Linux/macOS)
# Or on Windows: .venv\Scripts\activate

# Or: pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install from PyPI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install lightrag-hku
# Or: pip install lightrag-hku
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;LLM and Technology Stack Requirements for LightRAG&lt;/h3&gt; 
&lt;p&gt;LightRAG's demands on the capabilities of Large Language Models (LLMs) are significantly higher than those of traditional RAG, as it requires the LLM to perform entity-relationship extraction tasks from documents. Configuring appropriate Embedding and Reranker models is also crucial for improving query performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Selection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;It is recommended to use an LLM with at least 32 billion parameters.&lt;/li&gt; 
   &lt;li&gt;The context length should be at least 32KB, with 64KB being recommended.&lt;/li&gt; 
   &lt;li&gt;It is not recommended to choose reasoning models during the document indexing stage.&lt;/li&gt; 
   &lt;li&gt;During the query stage, it is recommended to choose models with stronger capabilities than those used in the indexing stage to achieve better query results.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embedding Model&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;A high-performance Embedding model is essential for RAG.&lt;/li&gt; 
   &lt;li&gt;We recommend using mainstream multilingual Embedding models, such as: &lt;code&gt;BAAI/bge-m3&lt;/code&gt; and &lt;code&gt;text-embedding-3-large&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Important Note&lt;/strong&gt;: The Embedding model must be determined before document indexing, and the same model must be used during the document query phase. For certain storage solutions (e.g., PostgreSQL), the vector dimension must be defined upon initial table creation. Therefore, when changing embedding models, it is necessary to delete the existing vector-related tables and allow LightRAG to recreate them with the new dimensions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reranker Model Configuration&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Configuring a Reranker model can significantly enhance LightRAG's retrieval performance.&lt;/li&gt; 
   &lt;li&gt;When a Reranker model is enabled, it is recommended to set the "mix mode" as the default query mode.&lt;/li&gt; 
   &lt;li&gt;We recommend using mainstream Reranker models, such as: &lt;code&gt;BAAI/bge-reranker-v2-m3&lt;/code&gt; or models provided by services like Jina.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start for LightRAG Server&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start for LightRAG core&lt;/h3&gt; 
&lt;p&gt;To get started with LightRAG core, refer to the sample codes available in the &lt;code&gt;examples&lt;/code&gt; folder. Additionally, a &lt;a href="https://www.youtube.com/watch?v=g21royNJ4fw"&gt;video demo&lt;/a&gt; demonstration is provided to guide you through the local setup process. If you already possess an OpenAI API key, you can run the demo right away:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;### you should run the demo code with project folder
cd LightRAG
### provide your API-KEY for OpenAI
export OPENAI_API_KEY="sk-...your_opeai_key..."
### download the demo document of "A Christmas Carol" by Charles Dickens
curl https://raw.githubusercontent.com/gusye1234/nano-graphrag/main/tests/mock_data.txt &amp;gt; ./book.txt
### run the demo code
python examples/lightrag_openai_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a streaming response implementation example, please see &lt;code&gt;examples/lightrag_openai_compatible_demo.py&lt;/code&gt;. Prior to execution, ensure you modify the sample code's LLM and embedding configurations accordingly.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note 1&lt;/strong&gt;: When running the demo program, please be aware that different test scripts may use different embedding models. If you switch to a different embedding model, you must clear the data directory (&lt;code&gt;./dickens&lt;/code&gt;); otherwise, the program may encounter errors. If you wish to retain the LLM cache, you can preserve the &lt;code&gt;kv_store_llm_response_cache.json&lt;/code&gt; file while clearing the data directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: Only &lt;code&gt;lightrag_openai_demo.py&lt;/code&gt; and &lt;code&gt;lightrag_openai_compatible_demo.py&lt;/code&gt; are officially supported sample codes. Other sample files are community contributions that haven't undergone full testing and optimization.&lt;/p&gt; 
&lt;h2&gt;Programming with LightRAG Core&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ &lt;strong&gt;If you would like to integrate LightRAG into your project, we recommend utilizing the REST API provided by the LightRAG Server&lt;/strong&gt;. LightRAG Core is typically intended for embedded applications or for researchers who wish to conduct studies and evaluations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš ï¸ Important: Initialization Requirements&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;LightRAG requires explicit initialization before use.&lt;/strong&gt; You must call &lt;code&gt;await rag.initialize_storages()&lt;/code&gt; after creating a LightRAG instance, otherwise you will encounter errors.&lt;/p&gt; 
&lt;h3&gt;A Simple Program&lt;/h3&gt; 
&lt;p&gt;Use the below Python snippet to initialize LightRAG, insert text to it, and perform queries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed
from lightrag.utils import setup_logger

setup_logger("lightrag", level="INFO")

WORKING_DIR = "./rag_storage"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
    )
    # IMPORTANT: Both initialization calls are required!
    await rag.initialize_storages()  # Initialize storage backends    return rag

async def main():
    try:
        # Initialize RAG instance
        rag = await initialize_rag()
        await rag.ainsert("Your text")

        # Perform hybrid search
        mode = "hybrid"
        print(
          await rag.aquery(
              "What are the top themes in this story?",
              param=QueryParam(mode=mode)
          )
        )

    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        if rag:
            await rag.finalize_storages()

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Important notes for the above snippet:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Export your OPENAI_API_KEY environment variable before running the script.&lt;/li&gt; 
 &lt;li&gt;This program uses the default storage settings for LightRAG, so all data will be persisted to WORKING_DIR/rag_storage.&lt;/li&gt; 
 &lt;li&gt;This program demonstrates only the simplest way to initialize a LightRAG object: Injecting the embedding and LLM functions, and initializing storage and pipeline status after creating the LightRAG object.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;LightRAG init parameters&lt;/h3&gt; 
&lt;p&gt;A full list of LightRAG init parameters:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Parameters &lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;Parameter&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Type&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Explanation&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Default&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;working_dir&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Directory where the cache will be stored&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lightrag_cache+timestamp&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;workspace&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;str&lt;/td&gt; 
    &lt;td&gt;Workspace name for data isolation between different LightRAG Instances&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;kv_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for documents and text chunks. Supported types: &lt;code&gt;JsonKVStorage&lt;/code&gt;,&lt;code&gt;PGKVStorage&lt;/code&gt;,&lt;code&gt;RedisKVStorage&lt;/code&gt;,&lt;code&gt;MongoKVStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;JsonKVStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vector_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for embedding vectors. Supported types: &lt;code&gt;NanoVectorDBStorage&lt;/code&gt;,&lt;code&gt;PGVectorStorage&lt;/code&gt;,&lt;code&gt;MilvusVectorDBStorage&lt;/code&gt;,&lt;code&gt;ChromaVectorDBStorage&lt;/code&gt;,&lt;code&gt;FaissVectorDBStorage&lt;/code&gt;,&lt;code&gt;MongoVectorDBStorage&lt;/code&gt;,&lt;code&gt;QdrantVectorDBStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;NanoVectorDBStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;graph_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for graph edges and nodes. Supported types: &lt;code&gt;NetworkXStorage&lt;/code&gt;,&lt;code&gt;Neo4JStorage&lt;/code&gt;,&lt;code&gt;PGGraphStorage&lt;/code&gt;,&lt;code&gt;AGEStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;NetworkXStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;doc_status_storage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Storage type for documents process status. Supported types: &lt;code&gt;JsonDocStatusStorage&lt;/code&gt;,&lt;code&gt;PGDocStatusStorage&lt;/code&gt;,&lt;code&gt;MongoDocStatusStorage&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;JsonDocStatusStorage&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;chunk_token_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum token size per chunk when splitting documents&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1200&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;chunk_overlap_token_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Overlap token size between two chunks when splitting documents&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;tokenizer&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Tokenizer&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The function used to convert text into tokens (numbers) and back using .encode() and .decode() functions following &lt;code&gt;TokenizerInterface&lt;/code&gt; protocol. If you don't specify one, it will use the default Tiktoken tokenizer.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TiktokenTokenizer&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;tiktoken_model_name&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If you're using the default Tiktoken tokenizer, this is the name of the specific Tiktoken model to use. This setting is ignored if you provide your own tokenizer.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;gpt-4o-mini&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;entity_extract_max_gleaning&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Number of loops in the entity extraction process, appending history messages&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;node_embedding_algorithm&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Algorithm for node embedding (currently not used)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;node2vec&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;node2vec_params&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Parameters for node embedding&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;{"dimensions": 1536,"num_walks": 10,"walk_length": 40,"window_size": 2,"iterations": 3,"random_seed": 3,}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_func&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;EmbeddingFunc&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Function to generate embedding vectors from text&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;openai_embed&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_batch_num&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum batch size for embedding processes (multiple texts sent per batch)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;32&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_func_max_async&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum number of concurrent asynchronous embedding processes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;16&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_func&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;callable&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Function for LLM generation&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;gpt_4o_mini_complete&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_name&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;str&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;LLM model name for generation&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;meta-llama/Llama-3.2-1B-Instruct&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;summary_context_size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum tokens send to LLM to generate summaries for entity relation merging&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10000&lt;/code&gt;ï¼ˆconfigured by env var SUMMARY_CONTEXT_SIZE)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;summary_max_tokens&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum token size for entity/relation description&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;500&lt;/code&gt;ï¼ˆconfigured by env var SUMMARY_MAX_TOKENS)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_max_async&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum number of concurrent asynchronous LLM processes&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;4&lt;/code&gt;ï¼ˆdefault value changed by env var MAX_ASYNC)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llm_model_kwargs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters for LLM generation&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vector_db_storage_cls_kwargs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters for vector database, like setting the threshold for nodes and relations retrieval&lt;/td&gt; 
    &lt;td&gt;cosine_better_than_threshold: 0.2ï¼ˆdefault value changed by env var COSINE_THRESHOLD)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;enable_llm_cache&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;TRUE&lt;/code&gt;, stores LLM results in cache; repeated prompts return cached responses&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TRUE&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;enable_llm_cache_for_entity_extract&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;TRUE&lt;/code&gt;, stores LLM results in cache for entity extraction; Good for beginners to debug your application&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;TRUE&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;addon_params&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Additional parameters, e.g., &lt;code&gt;{"language": "Simplified Chinese", "entity_types": ["organization", "person", "location", "event"]}&lt;/code&gt;: sets example limit, entity/relation extraction output language&lt;/td&gt; 
    &lt;td&gt;language: English`&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;embedding_cache_config&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dict&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Configuration for question-answer caching. Contains three parameters: &lt;code&gt;enabled&lt;/code&gt;: Boolean value to enable/disable cache lookup functionality. When enabled, the system will check cached responses before generating new answers. &lt;code&gt;similarity_threshold&lt;/code&gt;: Float value (0-1), similarity threshold. When a new question's similarity with a cached question exceeds this threshold, the cached answer will be returned directly without calling the LLM. &lt;code&gt;use_llm_check&lt;/code&gt;: Boolean value to enable/disable LLM similarity verification. When enabled, LLM will be used as a secondary check to verify the similarity between questions before returning cached answers.&lt;/td&gt; 
    &lt;td&gt;Default: &lt;code&gt;{"enabled": False, "similarity_threshold": 0.95, "use_llm_check": False}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Query Param&lt;/h3&gt; 
&lt;p&gt;Use QueryParam to control the behavior your query:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class QueryParam:
    """Configuration parameters for query execution in LightRAG."""

    mode: Literal["local", "global", "hybrid", "naive", "mix", "bypass"] = "global"
    """Specifies the retrieval mode:
    - "local": Focuses on context-dependent information.
    - "global": Utilizes global knowledge.
    - "hybrid": Combines local and global retrieval methods.
    - "naive": Performs a basic search without advanced techniques.
    - "mix": Integrates knowledge graph and vector retrieval.
    """

    only_need_context: bool = False
    """If True, only returns the retrieved context without generating a response."""

    only_need_prompt: bool = False
    """If True, only returns the generated prompt without producing a response."""

    response_type: str = "Multiple Paragraphs"
    """Defines the response format. Examples: 'Multiple Paragraphs', 'Single Paragraph', 'Bullet Points'."""

    stream: bool = False
    """If True, enables streaming output for real-time responses."""

    top_k: int = int(os.getenv("TOP_K", "60"))
    """Number of top items to retrieve. Represents entities in 'local' mode and relationships in 'global' mode."""

    chunk_top_k: int = int(os.getenv("CHUNK_TOP_K", "20"))
    """Number of text chunks to retrieve initially from vector search and keep after reranking.
    If None, defaults to top_k value.
    """

    max_entity_tokens: int = int(os.getenv("MAX_ENTITY_TOKENS", "6000"))
    """Maximum number of tokens allocated for entity context in unified token control system."""

    max_relation_tokens: int = int(os.getenv("MAX_RELATION_TOKENS", "8000"))
    """Maximum number of tokens allocated for relationship context in unified token control system."""

    max_total_tokens: int = int(os.getenv("MAX_TOTAL_TOKENS", "30000"))
    """Maximum total tokens budget for the entire query context (entities + relations + chunks + system prompt)."""

    # History messages are only sent to LLM for context, not used for retrieval
    conversation_history: list[dict[str, str]] = field(default_factory=list)
    """Stores past conversation history to maintain context.
    Format: [{"role": "user/assistant", "content": "message"}].
    """

    ids: list[str] | None = None
    """List of ids to filter the results."""

    model_func: Callable[..., object] | None = None
    """Optional override for the LLM model function to use for this specific query.
    If provided, this will be used instead of the global model function.
    This allows using different models for different query modes.
    """

    user_prompt: str | None = None
    """User-provided prompt for the query.
    Addition instructions for LLM. If provided, this will be inject into the prompt template.
    It's purpose is the let user customize the way LLM generate the response.
    """

    enable_rerank: bool = True
    """Enable reranking for retrieved text chunks. If True but no rerank model is configured, a warning will be issued.
    Default is True to enable reranking when rerank model is available.
    """
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;default value of Top_k can be change by environment variables TOP_K.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LLM and Embedding Injection&lt;/h3&gt; 
&lt;p&gt;LightRAG requires the utilization of LLM and Embedding models to accomplish document indexing and querying tasks. During the initialization phase, it is necessary to inject the invocation methods of the relevant models into LightRAGï¼š&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Open AI-like APIs&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LightRAG also supports Open AI-like chat/embeddings APIs:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.openai import openai_complete_if_cache, openai_embed

async def llm_model_func(
    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs
) -&amp;gt; str:
    return await openai_complete_if_cache(
        "solar-mini",
        prompt,
        system_prompt=system_prompt,
        history_messages=history_messages,
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar",
        **kwargs
    )

@wrap_embedding_func_with_attrs(embedding_dim=4096, max_token_size=8192)
async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    return await openai_embed.func(
        texts,
        model="solar-embedding-1-large-query",
        api_key=os.getenv("UPSTAGE_API_KEY"),
        base_url="https://api.upstage.ai/v1/solar"
    )

async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=llm_model_func,
        embedding_func=embedding_func  # Pass the decorated function directly
    )

    await rag.initialize_storages()
    return rag
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Important Note on Embedding Function Wrapping:&lt;/strong&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;code&gt;EmbeddingFunc&lt;/code&gt; cannot be nested. Functions that have been decorated with &lt;code&gt;@wrap_embedding_func_with_attrs&lt;/code&gt; (such as &lt;code&gt;openai_embed&lt;/code&gt;, &lt;code&gt;ollama_embed&lt;/code&gt;, etc.) cannot be wrapped again using &lt;code&gt;EmbeddingFunc()&lt;/code&gt;. This is why we call &lt;code&gt;xxx_embed.func&lt;/code&gt; (the underlying unwrapped function) instead of &lt;code&gt;xxx_embed&lt;/code&gt; directly when creating custom embedding functions.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Hugging Face Models&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you want to use Hugging Face models, you only need to set LightRAG as follows:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;See &lt;code&gt;lightrag_hf_demo.py&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Initialize LightRAG with Hugging Face model
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=hf_model_complete,  # Use Hugging Face model for text generation
    llm_model_name='meta-llama/Llama-3.1-8B-Instruct',  # Model name from Hugging Face
    # Use Hugging Face embedding function
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=lambda texts: hf_embed(
            texts,
            tokenizer=AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2"),
            embed_model=AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        )
    ),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Ollama Models&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;If you want to use Ollama models, you need to pull model you plan to use and embedding model, for example &lt;code&gt;nomic-embed-text&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;Then you only need to set LightRAG as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.ollama import ollama_model_complete, ollama_embed

@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=8192)
async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    return await ollama_embed.func(texts, embed_model="nomic-embed-text")

# Initialize LightRAG with Ollama model
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation
    llm_model_name='your_model_name', # Your model name
    embedding_func=embedding_func,  # Pass the decorated function directly
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Increasing context size&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In order for LightRAG to work context should be at least 32k tokens. By default Ollama models have context size of 8k. You can achieve this using one of two ways:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Increasing the &lt;code&gt;num_ctx&lt;/code&gt; parameter in Modelfile&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Pull the model:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama pull qwen2
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Display the model file:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama show --modelfile qwen2 &amp;gt; Modelfile
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Edit the Modelfile by adding the following line:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;PARAMETER num_ctx 32768
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="4"&gt; 
  &lt;li&gt;Create the modified model:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f Modelfile qwen2m
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Setup &lt;code&gt;num_ctx&lt;/code&gt; via Ollama API&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Tiy can use &lt;code&gt;llm_model_kwargs&lt;/code&gt; param to configure ollama:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np
from lightrag.utils import wrap_embedding_func_with_attrs
from lightrag.llm.ollama import ollama_model_complete, ollama_embed

@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=8192)
async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    return await ollama_embed.func(texts, embed_model="nomic-embed-text")

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,  # Use Ollama model for text generation
    llm_model_name='your_model_name', # Your model name
    llm_model_kwargs={"options": {"num_ctx": 32768}},
    embedding_func=embedding_func,  # Pass the decorated function directly
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Important Note on Embedding Function Wrapping:&lt;/strong&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;code&gt;EmbeddingFunc&lt;/code&gt; cannot be nested. Functions that have been decorated with &lt;code&gt;@wrap_embedding_func_with_attrs&lt;/code&gt; (such as &lt;code&gt;openai_embed&lt;/code&gt;, &lt;code&gt;ollama_embed&lt;/code&gt;, etc.) cannot be wrapped again using &lt;code&gt;EmbeddingFunc()&lt;/code&gt;. This is why we call &lt;code&gt;xxx_embed.func&lt;/code&gt; (the underlying unwrapped function) instead of &lt;code&gt;xxx_embed&lt;/code&gt; directly when creating custom embedding functions.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Low RAM GPUs&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In order to run this experiment on low RAM GPU you should select small model and tune context window (increasing context increase memory consumption). For example, running this ollama example on repurposed mining GPU with 6Gb of RAM required to set context size to 26k while using &lt;code&gt;gemma2:2b&lt;/code&gt;. It was able to find 197 entities and 19 relations on &lt;code&gt;book.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;LlamaIndex&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG supports integration with LlamaIndex (&lt;code&gt;llm/llama_index_impl.py&lt;/code&gt;):&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integrates with OpenAI and other providers through LlamaIndex&lt;/li&gt; 
  &lt;li&gt;See &lt;a href="https://developers.llamaindex.ai/python/framework/"&gt;LlamaIndex Documentation&lt;/a&gt; for detailed setup or the &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/unofficial-sample/"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Example Usage&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Using LlamaIndex with direct OpenAI access
import asyncio
from lightrag import LightRAG
from lightrag.llm.llama_index_impl import llama_index_complete_if_cache, llama_index_embed
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from lightrag.utils import setup_logger

# Setup log handler for LightRAG
setup_logger("lightrag", level="INFO")

async def initialize_rag():
    rag = LightRAG(
        working_dir="your/path",
        llm_model_func=llama_index_complete_if_cache,  # LlamaIndex-compatible completion function
        embedding_func=EmbeddingFunc(    # LlamaIndex-compatible embedding function
            embedding_dim=1536,
            func=lambda texts: llama_index_embed(texts, embed_model=embed_model)
        ),
    )

    await rag.initialize_storages()
    return rag

def main():
    # Initialize RAG instance
    rag = asyncio.run(initialize_rag())

    with open("./book.txt", "r", encoding="utf-8") as f:
        rag.insert(f.read())

    # Perform naive search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="naive"))
    )

    # Perform local search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="local"))
    )

    # Perform global search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="global"))
    )

    # Perform hybrid search
    print(
        rag.query("What are the top themes in this story?", param=QueryParam(mode="hybrid"))
    )

if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For detailed documentation and examples, see:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://developers.llamaindex.ai/python/framework/"&gt;LlamaIndex Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/unofficial-sample/lightrag_llamaindex_direct_demo.py"&gt;Direct OpenAI Example&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/unofficial-sample/lightrag_llamaindex_litellm_demo.py"&gt;LiteLLM Proxy Example&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/examples/unofficial-sample/lightrag_llamaindex_litellm_opik_demo.py"&gt;LiteLLM Proxy with Opik Example&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Rerank Function Injection&lt;/h3&gt; 
&lt;p&gt;To enhance retrieval quality, documents can be re-ranked based on a more effective relevance scoring model. The &lt;code&gt;rerank.py&lt;/code&gt; file provides three Reranker provider driver functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cohere / vLLM&lt;/strong&gt;: &lt;code&gt;cohere_rerank&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jina AI&lt;/strong&gt;: &lt;code&gt;jina_rerank&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aliyun&lt;/strong&gt;: &lt;code&gt;ali_rerank&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can inject one of these functions into the &lt;code&gt;rerank_model_func&lt;/code&gt; attribute of the LightRAG object. This will enable LightRAG's query function to re-order retrieved text blocks using the injected function. For detailed usage, please refer to the &lt;code&gt;examples/rerank_example.py&lt;/code&gt; file.&lt;/p&gt; 
&lt;h3&gt;User Prompt vs. Query&lt;/h3&gt; 
&lt;p&gt;When using LightRAG for content queries, avoid combining the search process with unrelated output processing, as this significantly impacts query effectiveness. The &lt;code&gt;user_prompt&lt;/code&gt; parameter in Query Param is specifically designed to address this issue â€” it does not participate in the RAG retrieval phase, but rather guides the LLM on how to process the retrieved results after the query is completed. Here's how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create query parameters
query_param = QueryParam(
    mode = "hybrid",  # Other modesï¼šlocal, global, hybrid, mix, naive
    user_prompt = "For diagrams, use mermaid format with English/Pinyin node names and Chinese display labels",
)

# Query and process
response_default = rag.query(
    "Please draw a character relationship diagram for Scrooge",
    param=query_param
)
print(response_default)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Insert&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Basic Insert &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic Insert
rag.insert("Text")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Batch Insert &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic Batch Insert: Insert multiple texts at once
rag.insert(["TEXT1", "TEXT2",...])

# Batch Insert with custom batch size configuration
rag = LightRAG(
    ...
    working_dir=WORKING_DIR,
    max_parallel_insert = 4
)

rag.insert(["TEXT1", "TEXT2", "TEXT3", ...])  # Documents will be processed in batches of 4
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;max_parallel_insert&lt;/code&gt; parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is &lt;strong&gt;2&lt;/strong&gt;. We recommend keeping this setting &lt;strong&gt;below 10&lt;/strong&gt;, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.The &lt;code&gt;max_parallel_insert&lt;/code&gt; parameter determines the number of documents processed concurrently in the document indexing pipeline. If unspecified, the default value is &lt;strong&gt;2&lt;/strong&gt;. We recommend keeping this setting &lt;strong&gt;below 10&lt;/strong&gt;, as the performance bottleneck typically lies with the LLM (Large Language Model) processing.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Insert with ID &lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;If you want to provide your own IDs for your documents, number of documents and number of IDs must be the same.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Insert single text, and provide ID for it
rag.insert("TEXT1", ids=["ID_FOR_TEXT1"])

# Insert multiple texts, and provide IDs for them
rag.insert(["TEXT1", "TEXT2",...], ids=["ID_FOR_TEXT1", "ID_FOR_TEXT2"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Insert using Pipeline&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;apipeline_enqueue_documents&lt;/code&gt; and &lt;code&gt;apipeline_process_enqueue_documents&lt;/code&gt; functions allow you to perform incremental insertion of documents into the graph.&lt;/p&gt; 
 &lt;p&gt;This is useful for scenarios where you want to process documents in the background while still allowing the main thread to continue executing.&lt;/p&gt; 
 &lt;p&gt;And using a routine to process new documents.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;rag = LightRAG(..)

await rag.apipeline_enqueue_documents(input)
# Your routine in loop
await rag.apipeline_process_enqueue_documents(input)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Insert Multi-file Type Support&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;The &lt;code&gt;textract&lt;/code&gt; supports reading file types such as TXT, DOCX, PPTX, CSV, and PDF.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import textract

file_path = 'TEXT.pdf'
text_content = textract.process(file_path)

rag.insert(text_content.decode('utf-8'))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Citation Functionality&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;By providing file paths, the system ensures that sources can be traced back to their original documents.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Define documents and their file paths
documents = ["Document content 1", "Document content 2"]
file_paths = ["path/to/doc1.txt", "path/to/doc2.txt"]

# Insert documents with file paths
rag.insert(documents, file_paths=file_paths)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Storage&lt;/h3&gt; 
&lt;p&gt;LightRAG uses 4 types of storage for different purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KV_STORAGE: llm response cache, text chunks, document information&lt;/li&gt; 
 &lt;li&gt;VECTOR_STORAGE: entities vectors, relation vectors, chunks vectors&lt;/li&gt; 
 &lt;li&gt;GRAPH_STORAGE: entity relation graph&lt;/li&gt; 
 &lt;li&gt;DOC_STATUS_STORAGE: document indexing status&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each storage type has several implementations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;KV_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;JsonKVStorage    JsonFile (default)
PGKVStorage      Postgres
RedisKVStorage   Redis
MongoKVStorage   MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;GRAPH_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;NetworkXStorage      NetworkX (default)
Neo4JStorage         Neo4J
PGGraphStorage       PostgreSQL with AGE plugin
MemgraphStorage.     Memgraph
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Testing has shown that Neo4J delivers superior performance in production environments compared to PostgreSQL with AGE plugin.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;VECTOR_STORAGE supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;NanoVectorDBStorage         NanoVector (default)
PGVectorStorage             Postgres
MilvusVectorDBStorage       Milvus
FaissVectorDBStorage        Faiss
QdrantVectorDBStorage       Qdrant
MongoVectorDBStorage        MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;DOC_STATUS_STORAGE: supported implementations:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;JsonDocStatusStorage        JsonFile (default)
PGDocStatusStorage          Postgres
MongoDocStatusStorage       MongoDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example connection configurations for each storage type can be found in the &lt;code&gt;env.example&lt;/code&gt; file. The database instance in the connection string needs to be created by you on the database server beforehand. LightRAG is only responsible for creating tables within the database instance, not for creating the database instance itself. If using Redis as storage, remember to configure automatic data persistence rules for Redis, otherwise data will be lost after the Redis service restarts. If using PostgreSQL, it is recommended to use version 16.6 or above.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Neo4J Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;For production level scenarios you will most likely want to leverage an enterprise solution&lt;/li&gt; 
  &lt;li&gt;for KG storage. Running Neo4J in Docker is recommended for seamless local testing.&lt;/li&gt; 
  &lt;li&gt;See: &lt;a href="https://hub.docker.com/_/neo4j"&gt;https://hub.docker.com/_/neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;export NEO4J_URI="neo4j://localhost:7687"
export NEO4J_USERNAME="neo4j"
export NEO4J_PASSWORD="password"

# Setup logger for LightRAG
setup_logger("lightrag", level="INFO")

# When you launch the project be sure to override the default KG: NetworkX
# by specifying kg="Neo4JStorage".

# Note: Default settings use NetworkX
# Initialize LightRAG with Neo4J implementation.
async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model
        graph_storage="Neo4JStorage", #&amp;lt;-----------override KG default
    )

    # Initialize database connections
    await rag.initialize_storages()
    # Initialize pipeline status for document processing
    return rag
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;see test_neo4j.py for a working example.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using PostgreSQL Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;For production level scenarios you will most likely want to leverage an enterprise solution. PostgreSQL can provide a one-stop solution for you as KV store, VectorDB (pgvector) and GraphDB (apache AGE). PostgreSQL version 16.6 or higher is supported.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;PostgreSQL is lightweight,the whole binary distribution including all necessary plugins can be zipped to 40MB: Ref to &lt;a href="https://github.com/ShanGor/apache-age-windows/releases/tag/PG17%2Fv1.5.0-rc0"&gt;Windows Release&lt;/a&gt; as it is easy to install for Linux/Mac.&lt;/li&gt; 
  &lt;li&gt;If you prefer docker, please start with this image if you are a beginner to avoid hiccups (Default user password:rag/rag): &lt;a href="https://hub.docker.com/r/gzdaniel/postgres-for-rag"&gt;https://hub.docker.com/r/gzdaniel/postgres-for-rag&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;How to start? Ref to: &lt;a href="https://github.com/HKUDS/LightRAG/raw/main/examples/lightrag_zhipu_postgres_demo.py"&gt;examples/lightrag_zhipu_postgres_demo.py&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;For high-performance graph database requirements, Neo4j is recommended as Apache AGE's performance is not as competitive.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Faiss Storage&lt;/b&gt; &lt;/summary&gt; Before using Faiss vector database, you must manually install `faiss-cpu` or `faiss-gpu`. 
 &lt;ul&gt; 
  &lt;li&gt;Install the required dependencies:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code&gt;pip install faiss-cpu
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can also install &lt;code&gt;faiss-gpu&lt;/code&gt; if you have GPU support.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Here we are using &lt;code&gt;sentence-transformers&lt;/code&gt; but you can also use &lt;code&gt;OpenAIEmbedding&lt;/code&gt; model with &lt;code&gt;3072&lt;/code&gt; dimensions.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;async def embedding_func(texts: list[str]) -&amp;gt; np.ndarray:
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(texts, convert_to_numpy=True)
    return embeddings

# Initialize LightRAG with the LLM model function and embedding function
rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=llm_model_func,
    embedding_func=EmbeddingFunc(
        embedding_dim=384,
        func=embedding_func,
    ),
    vector_storage="FaissVectorDBStorage",
    vector_db_storage_cls_kwargs={
        "cosine_better_than_threshold": 0.3  # Your desired threshold
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Memgraph for Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Memgraph is a high-performance, in-memory graph database compatible with the Neo4j Bolt protocol.&lt;/li&gt; 
  &lt;li&gt;You can run Memgraph locally using Docker for easy testing:&lt;/li&gt; 
  &lt;li&gt;See: &lt;a href="https://memgraph.com/download"&gt;https://memgraph.com/download&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;export MEMGRAPH_URI="bolt://localhost:7687"

# Setup logger for LightRAG
setup_logger("lightrag", level="INFO")

# When you launch the project, override the default KG: NetworkX
# by specifying kg="MemgraphStorage".

# Note: Default settings use NetworkX
# Initialize LightRAG with Memgraph implementation.
async def initialize_rag():
    rag = LightRAG(
        working_dir=WORKING_DIR,
        llm_model_func=gpt_4o_mini_complete,  # Use gpt_4o_mini_complete LLM model
        graph_storage="MemgraphStorage", #&amp;lt;-----------override KG default
    )

    # Initialize database connections
    await rag.initialize_storages()
    # Initialize pipeline status for document processing
    return rag
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using MongoDB Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;MongoDB provides a one-stop storage solution for LightRAG. MongoDB offers native KV storage and vector storage. LightRAG uses MongoDB collections to implement a simple graph storage. MongoDB's official vector search functionality (&lt;code&gt;$vectorSearch&lt;/code&gt;) currently requires their official cloud service MongoDB Atlas. This functionality cannot be used on self-hosted MongoDB Community/Enterprise versions.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Using Redis Storage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG supports using Redis as KV storage. When using Redis storage, attention should be paid to persistence configuration and memory usage configuration. The following is the recommended Redis configuration:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;save 900 1
save 300 10
save 60 1000
stop-writes-on-bgsave-error yes
maxmemory 4gb
maxmemory-policy noeviction
maxclients 500
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Isolation Between LightRAG Instances&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;workspace&lt;/code&gt; parameter ensures data isolation between different LightRAG instances. Once initialized, the &lt;code&gt;workspace&lt;/code&gt; is immutable and cannot be changed.Here is how workspaces are implemented for different types of storage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For local file-based databases, data isolation is achieved through workspace subdirectories:&lt;/strong&gt; &lt;code&gt;JsonKVStorage&lt;/code&gt;, &lt;code&gt;JsonDocStatusStorage&lt;/code&gt;, &lt;code&gt;NetworkXStorage&lt;/code&gt;, &lt;code&gt;NanoVectorDBStorage&lt;/code&gt;, &lt;code&gt;FaissVectorDBStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For databases that store data in collections, it's done by adding a workspace prefix to the collection name:&lt;/strong&gt; &lt;code&gt;RedisKVStorage&lt;/code&gt;, &lt;code&gt;RedisDocStatusStorage&lt;/code&gt;, &lt;code&gt;MilvusVectorDBStorage&lt;/code&gt;, &lt;code&gt;MongoKVStorage&lt;/code&gt;, &lt;code&gt;MongoDocStatusStorage&lt;/code&gt;, &lt;code&gt;MongoVectorDBStorage&lt;/code&gt;, &lt;code&gt;MongoGraphStorage&lt;/code&gt;, &lt;code&gt;PGGraphStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For Qdrant vector database, data isolation is achieved through payload-based partitioning (Qdrant's recommended multitenancy approach):&lt;/strong&gt; &lt;code&gt;QdrantVectorDBStorage&lt;/code&gt; uses shared collections with payload filtering for unlimited workspace scalability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For relational databases, data isolation is achieved by adding a &lt;code&gt;workspace&lt;/code&gt; field to the tables for logical data separation:&lt;/strong&gt; &lt;code&gt;PGKVStorage&lt;/code&gt;, &lt;code&gt;PGVectorStorage&lt;/code&gt;, &lt;code&gt;PGDocStatusStorage&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For the Neo4j graph database, logical data isolation is achieved through labels:&lt;/strong&gt; &lt;code&gt;Neo4JStorage&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To maintain compatibility with legacy data, the default workspace for PostgreSQL non-graph storage is &lt;code&gt;default&lt;/code&gt; and, for PostgreSQL AGE graph storage is null, for Neo4j graph storage is &lt;code&gt;base&lt;/code&gt; when no workspace is configured. For all external storages, the system provides dedicated workspace environment variables to override the common &lt;code&gt;WORKSPACE&lt;/code&gt; environment variable configuration. These storage-specific workspace environment variables are: &lt;code&gt;REDIS_WORKSPACE&lt;/code&gt;, &lt;code&gt;MILVUS_WORKSPACE&lt;/code&gt;, &lt;code&gt;QDRANT_WORKSPACE&lt;/code&gt;, &lt;code&gt;MONGODB_WORKSPACE&lt;/code&gt;, &lt;code&gt;POSTGRES_WORKSPACE&lt;/code&gt;, &lt;code&gt;NEO4J_WORKSPACE&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;AGENTS.md -- Guiding Coding Agents&lt;/h3&gt; 
&lt;p&gt;AGENTS.md is a simple, open format for guiding coding agents (&lt;a href="https://agents.md/"&gt;https://agents.md/&lt;/a&gt;). It is a dedicated, predictable place to provide the context and instructions to help AI coding agents work on LightRAG project. Different AI coders should not maintain separate guidance files individually. If any AI coder cannot automatically recognize AGENTS.md, symbolic links can be used as a solution. After establishing symbolic links, you can prevent them from being committed to the Git repository by configuring your local &lt;code&gt;.gitignore_global&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Edit Entities and Relations&lt;/h2&gt; 
&lt;p&gt;LightRAG now supports comprehensive knowledge graph management capabilities, allowing you to create, edit, and delete entities and relationships within your knowledge graph.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Create Entities and Relations &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Create new entity
entity = rag.create_entity("Google", {
    "description": "Google is a multinational technology company specializing in internet-related services and products.",
    "entity_type": "company"
})

# Create another entity
product = rag.create_entity("Gmail", {
    "description": "Gmail is an email service developed by Google.",
    "entity_type": "product"
})

# Create relation between entities
relation = rag.create_relation("Google", "Gmail", {
    "description": "Google develops and operates Gmail.",
    "keywords": "develops operates service",
    "weight": 2.0
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Edit Entities and Relations &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Edit an existing entity
updated_entity = rag.edit_entity("Google", {
    "description": "Google is a subsidiary of Alphabet Inc., founded in 1998.",
    "entity_type": "tech_company"
})

# Rename an entity (with all its relationships properly migrated)
renamed_entity = rag.edit_entity("Gmail", {
    "entity_name": "Google Mail",
    "description": "Google Mail (formerly Gmail) is an email service."
})

# Edit a relation between entities
updated_relation = rag.edit_relation("Google", "Google Mail", {
    "description": "Google created and maintains Google Mail service.",
    "keywords": "creates maintains email service",
    "weight": 3.0
})
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;All operations are available in both synchronous and asynchronous versions. The asynchronous versions have the prefix "a" (e.g., &lt;code&gt;acreate_entity&lt;/code&gt;, &lt;code&gt;aedit_relation&lt;/code&gt;).&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Insert Custom KG &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;custom_kg = {
        "chunks": [
            {
                "content": "Alice and Bob are collaborating on quantum computing research.",
                "source_id": "doc-1",
                "file_path": "test_file",
            }
        ],
        "entities": [
            {
                "entity_name": "Alice",
                "entity_type": "person",
                "description": "Alice is a researcher specializing in quantum physics.",
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "entity_name": "Bob",
                "entity_type": "person",
                "description": "Bob is a mathematician.",
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "entity_name": "Quantum Computing",
                "entity_type": "technology",
                "description": "Quantum computing utilizes quantum mechanical phenomena for computation.",
                "source_id": "doc-1",
                "file_path": "test_file"
            }
        ],
        "relationships": [
            {
                "src_id": "Alice",
                "tgt_id": "Bob",
                "description": "Alice and Bob are research partners.",
                "keywords": "collaboration research",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "src_id": "Alice",
                "tgt_id": "Quantum Computing",
                "description": "Alice conducts research on quantum computing.",
                "keywords": "research expertise",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            },
            {
                "src_id": "Bob",
                "tgt_id": "Quantum Computing",
                "description": "Bob researches quantum computing.",
                "keywords": "research application",
                "weight": 1.0,
                "source_id": "doc-1",
                "file_path": "test_file"
            }
        ]
    }

rag.insert_custom_kg(custom_kg)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Other Entity and Relation Operations&lt;/b&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_entity&lt;/strong&gt;: Creates a new entity with specified attributes&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;edit_entity&lt;/strong&gt;: Updates an existing entity's attributes or renames it&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_relation&lt;/strong&gt;: Creates a new relation between existing entities&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;edit_relation&lt;/strong&gt;: Updates an existing relation's attributes&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These operations maintain data consistency across both the graph database and vector database components, ensuring your knowledge graph remains coherent.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Delete Functions&lt;/h2&gt; 
&lt;p&gt;LightRAG provides comprehensive deletion capabilities, allowing you to delete documents, entities, and relationships.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete Entities&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete entities by their name along with all associated relationships:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete entity and all its relationships (synchronous version)
rag.delete_by_entity("Google")

# Asynchronous version
await rag.adelete_by_entity("Google")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When deleting an entity:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Removes the entity node from the knowledge graph&lt;/li&gt; 
  &lt;li&gt;Deletes all associated relationships&lt;/li&gt; 
  &lt;li&gt;Removes related embedding vectors from the vector database&lt;/li&gt; 
  &lt;li&gt;Maintains knowledge graph integrity&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete Relations&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete relationships between two specific entities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete relationship between two entities (synchronous version)
rag.delete_by_relation("Google", "Gmail")

# Asynchronous version
await rag.adelete_by_relation("Google", "Gmail")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When deleting a relationship:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Removes the specified relationship edge&lt;/li&gt; 
  &lt;li&gt;Deletes the relationship's embedding vector from the vector database&lt;/li&gt; 
  &lt;li&gt;Preserves both entity nodes and their other relationships&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Delete by Document ID&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can delete an entire document and all its related knowledge through document ID:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Delete by document ID (asynchronous version)
await rag.adelete_by_doc_id("doc-12345")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Optimized processing when deleting by document ID:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Smart Cleanup&lt;/strong&gt;: Automatically identifies and removes entities and relationships that belong only to this document&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Preserve Shared Knowledge&lt;/strong&gt;: If entities or relationships exist in other documents, they are preserved and their descriptions are rebuilt&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Cache Optimization&lt;/strong&gt;: Clears related LLM cache to reduce storage overhead&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Incremental Rebuilding&lt;/strong&gt;: Reconstructs affected entity and relationship descriptions from remaining documents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;The deletion process includes:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Delete all text chunks related to the document&lt;/li&gt; 
  &lt;li&gt;Identify and delete entities and relationships that belong only to this document&lt;/li&gt; 
  &lt;li&gt;Rebuild entities and relationships that still exist in other documents&lt;/li&gt; 
  &lt;li&gt;Update all related vector indexes&lt;/li&gt; 
  &lt;li&gt;Clean up document status records&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Note: Deletion by document ID is an asynchronous operation as it involves complex knowledge graph reconstruction processes.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;Important Reminders:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Irreversible Operations&lt;/strong&gt;: All deletion operations are irreversible, please use with caution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Considerations&lt;/strong&gt;: Deleting large amounts of data may take some time, especially deletion by document ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Consistency&lt;/strong&gt;: Deletion operations automatically maintain consistency between the knowledge graph and vector database&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backup Recommendations&lt;/strong&gt;: Consider backing up data before performing important deletion operations&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Batch Deletion Recommendations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For batch deletion operations, consider using asynchronous methods for better performance&lt;/li&gt; 
 &lt;li&gt;For large-scale deletions, consider processing in batches to avoid excessive system load&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Entity Merging&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Merge Entities and Their Relationships&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG now supports merging multiple entities into a single entity, automatically handling all relationships:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic entity merging
rag.merge_entities(
    source_entities=["Artificial Intelligence", "AI", "Machine Intelligence"],
    target_entity="AI Technology"
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;With custom merge strategy:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Define custom merge strategy for different fields
rag.merge_entities(
    source_entities=["John Smith", "Dr. Smith", "J. Smith"],
    target_entity="John Smith",
    merge_strategy={
        "description": "concatenate",  # Combine all descriptions
        "entity_type": "keep_first",   # Keep the entity type from the first entity
        "source_id": "join_unique"     # Combine all unique source IDs
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;With custom target entity data:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Specify exact values for the merged entity
rag.merge_entities(
    source_entities=["New York", "NYC", "Big Apple"],
    target_entity="New York City",
    target_entity_data={
        "entity_type": "LOCATION",
        "description": "New York City is the most populous city in the United States.",
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Advanced usage combining both approaches:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Merge company entities with both strategy and custom data
rag.merge_entities(
    source_entities=["Microsoft Corp", "Microsoft Corporation", "MSFT"],
    target_entity="Microsoft",
    merge_strategy={
        "description": "concatenate",  # Combine all descriptions
        "source_id": "join_unique"     # Combine source IDs
    },
    target_entity_data={
        "entity_type": "ORGANIZATION",
    }
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When merging entities:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;All relationships from source entities are redirected to the target entity&lt;/li&gt; 
  &lt;li&gt;Duplicate relationships are intelligently merged&lt;/li&gt; 
  &lt;li&gt;Self-relationships (loops) are prevented&lt;/li&gt; 
  &lt;li&gt;Source entities are removed after merging&lt;/li&gt; 
  &lt;li&gt;Relationship weights and attributes are preserved&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Multimodal Document Processing (RAG-Anything Integration)&lt;/h2&gt; 
&lt;p&gt;LightRAG now seamlessly integrates with &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything&lt;/a&gt;, a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built specifically for LightRAG. RAG-Anything enables advanced parsing and retrieval-augmented generation (RAG) capabilities, allowing you to handle multimodal documents seamlessly and extract structured contentâ€”including text, images, tables, and formulasâ€”from various document formats for integration into your RAG pipeline.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-End Multimodal Pipeline&lt;/strong&gt;: Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Universal Document Support&lt;/strong&gt;: Seamless processing of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and diverse file formats&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Content Analysis&lt;/strong&gt;: Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal Knowledge Graph&lt;/strong&gt;: Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Intelligent Retrieval&lt;/strong&gt;: Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install RAG-Anything:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install raganything
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Process multimodal documents:&lt;/p&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;b&gt; RAGAnything Usage Example &lt;/b&gt;&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-python"&gt;    import asyncio
    from raganything import RAGAnything
    from lightrag import LightRAG
    from lightrag.llm.openai import openai_complete_if_cache, openai_embed
    from lightrag.utils import EmbeddingFunc
    import os

    async def load_existing_lightrag():
        # First, create or load an existing LightRAG instance
        lightrag_working_dir = "./existing_lightrag_storage"

        # Check if previous LightRAG instance exists
        if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
            print("âœ… Found existing LightRAG instance, loading...")
        else:
            print("âŒ No existing LightRAG instance found, will create new one")

        # Create/Load LightRAG instance with your configurations
        lightrag_instance = LightRAG(
            working_dir=lightrag_working_dir,
            llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
                "gpt-4o-mini",
                prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key="your-api-key",
                **kwargs,
            ),
            embedding_func=EmbeddingFunc(
                embedding_dim=3072,
                func=lambda texts: openai_embed(
                    texts,
                    model="text-embedding-3-large",
                    api_key=api_key,
                    base_url=base_url,
                ),
            )
        )

        # Initialize storage (this will load existing data if available)
        await lightrag_instance.initialize_storages()

        # Now initialize RAGAnything with the existing LightRAG instance
        rag = RAGAnything(
            lightrag=lightrag_instance,  # Pass the existing LightRAG instance
            # Only need vision model for multimodal processing
            vision_model_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {"role": "user", "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                    ]} if image_data else {"role": "user", "content": prompt}
                ],
                api_key="your-api-key",
                **kwargs,
            ) if image_data else openai_complete_if_cache(
                "gpt-4o-mini",
                prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                api_key="your-api-key",
                **kwargs,
            )
            # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
        )

        # Query the existing knowledge base
        result = await rag.query_with_multimodal(
            "What data has been processed in this LightRAG instance?",
            mode="hybrid"
        )
        print("Query result:", result)

        # Add new multimodal documents to the existing LightRAG instance
        await rag.process_document_complete(
            file_path="path/to/new/multimodal_document.pdf",
            output_dir="./output"
        )

    if __name__ == "__main__":
        asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed documentation and advanced usage, please refer to the &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;RAG-Anything repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Token Usage Tracking&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Overview and Usage&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;LightRAG provides a TokenTracker tool to monitor and manage token consumption by large language models. This feature is particularly useful for controlling API costs and optimizing performance.&lt;/p&gt; 
 &lt;h3&gt;Usage&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from lightrag.utils import TokenTracker

# Create TokenTracker instance
token_tracker = TokenTracker()

# Method 1: Using context manager (Recommended)
# Suitable for scenarios requiring automatic token usage tracking
with token_tracker:
    result1 = await llm_model_func("your question 1")
    result2 = await llm_model_func("your question 2")

# Method 2: Manually adding token usage records
# Suitable for scenarios requiring more granular control over token statistics
token_tracker.reset()

rag.insert()

rag.query("your question 1", param=QueryParam(mode="naive"))
rag.query("your question 2", param=QueryParam(mode="mix"))

# Display total token usage (including insert and query operations)
print("Token usage:", token_tracker.get_usage())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Usage Tips&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use context managers for long sessions or batch operations to automatically track all token consumption&lt;/li&gt; 
  &lt;li&gt;For scenarios requiring segmented statistics, use manual mode and call reset() when appropriate&lt;/li&gt; 
  &lt;li&gt;Regular checking of token usage helps detect abnormal consumption early&lt;/li&gt; 
  &lt;li&gt;Actively use this feature during development and testing to optimize production costs&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Practical Examples&lt;/h3&gt; 
 &lt;p&gt;You can refer to these examples for implementing token tracking:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;examples/lightrag_gemini_track_token_demo.py&lt;/code&gt;: Token tracking example using Google Gemini model&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;examples/lightrag_siliconcloud_track_token_demo.py&lt;/code&gt;: Token tracking example using SiliconCloud model&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These examples demonstrate how to effectively use the TokenTracker feature with different models and scenarios.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Data Export Functions&lt;/h2&gt; 
&lt;h3&gt;Overview&lt;/h3&gt; 
&lt;p&gt;LightRAG allows you to export your knowledge graph data in various formats for analysis, sharing, and backup purposes. The system supports exporting entities, relations, and relationship data.&lt;/p&gt; 
&lt;h3&gt;Export Functions&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Basic Usage &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Basic CSV export (default format)
rag.export_data("knowledge_graph.csv")

# Specify any format
rag.export_data("output.xlsx", file_format="excel")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Different File Formats supported &lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;#Export data in CSV format
rag.export_data("graph_data.csv", file_format="csv")

# Export data in Excel sheet
rag.export_data("graph_data.xlsx", file_format="excel")

# Export data in markdown format
rag.export_data("graph_data.md", file_format="md")

# Export data in Text
rag.export_data("graph_data.txt", file_format="txt")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt; Additional Options &lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Include vector embeddings in the export (optional):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;rag.export_data("complete_data.csv", include_vector_data=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Data Included in Export&lt;/h3&gt; 
&lt;p&gt;All exports include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Entity information (names, IDs, metadata)&lt;/li&gt; 
 &lt;li&gt;Relation data (connections between entities)&lt;/li&gt; 
 &lt;li&gt;Relationship information from vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;b&gt;Clear Cache&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;You can clear the LLM response cache with different modes:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Clear all cache
await rag.aclear_cache()

# Clear local mode cache
await rag.aclear_cache(modes=["local"])

# Clear extraction cache
await rag.aclear_cache(modes=["default"])

# Clear multiple modes
await rag.aclear_cache(modes=["local", "global", "hybrid"])

# Synchronous version
rag.clear_cache(modes=["local"])
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Valid modes are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;"default"&lt;/code&gt;: Extraction cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"naive"&lt;/code&gt;: Naive search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"local"&lt;/code&gt;: Local search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"global"&lt;/code&gt;: Global search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"hybrid"&lt;/code&gt;: Hybrid search cache&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;"mix"&lt;/code&gt;: Mix search cache&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Initialization Errors&lt;/h3&gt; 
&lt;p&gt;If you encounter these errors when using LightRAG:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;AttributeError: __aenter__&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Storage backends not initialized&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Call &lt;code&gt;await rag.initialize_storages()&lt;/code&gt; after creating the LightRAG instance&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;KeyError: 'history_messages'&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Pipeline status not initialized&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Call `&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Both errors in sequence&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Cause&lt;/strong&gt;: Neither initialization method was called&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Always follow this pattern:&lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-python"&gt;rag = LightRAG(...)
await rag.initialize_storages()   ```

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Model Switching Issues&lt;/h3&gt; 
&lt;p&gt;When switching between different embedding models, you must clear the data directory to avoid errors. The only file you may want to preserve is &lt;code&gt;kv_store_llm_response_cache.json&lt;/code&gt; if you wish to retain the LLM cache.&lt;/p&gt; 
&lt;h2&gt;LightRAG API&lt;/h2&gt; 
&lt;p&gt;The LightRAG Server is designed to provide Web UI and API support. &lt;strong&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Graph Visualization&lt;/h2&gt; 
&lt;p&gt;The LightRAG Server offers a comprehensive knowledge graph visualization feature. It supports various gravity layouts, node queries, subgraph filtering, and more. &lt;strong&gt;For more information about LightRAG Server, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/api/README.md"&gt;LightRAG Server&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HKUDS/LightRAG/main/README.assets/iShot_2025-03-23_12.40.08.png" alt="iShot_2025-03-23_12.40.08" /&gt;&lt;/p&gt; 
&lt;h2&gt;Langfuse observability integration&lt;/h2&gt; 
&lt;p&gt;Langfuse provides a drop-in replacement for the OpenAI client that automatically tracks all LLM interactions, enabling developers to monitor, debug, and optimize their RAG systems without code changes.&lt;/p&gt; 
&lt;h3&gt;Installation with Langfuse option&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pip install lightrag-hku
pip install lightrag-hku[observability]

# Or install from source code with debug mode enabled
pip install -e .
pip install -e ".[observability]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Config Langfuse env vars&lt;/h3&gt; 
&lt;p&gt;modify .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;## Langfuse Observability (Optional)
# LLM observability and tracing platform
# Install with: pip install lightrag-hku[observability]
# Sign up at: https://cloud.langfuse.com or self-host
LANGFUSE_SECRET_KEY=""
LANGFUSE_PUBLIC_KEY=""
LANGFUSE_HOST="https://cloud.langfuse.com"  # or your self-hosted instance
LANGFUSE_ENABLE_TRACE=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Langfuse Usage&lt;/h3&gt; 
&lt;p&gt;Once installed and configured, Langfuse automatically traces all OpenAI LLM calls. Langfuse dashboard features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tracing&lt;/strong&gt;: View complete LLM call chains&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Analytics&lt;/strong&gt;: Token usage, latency, cost metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt;: Inspect prompts and responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: Compare model outputs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Real-time alerting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Important Notice&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: LightRAG currently only integrates OpenAI-compatible API calls with Langfuse. APIs such as Ollama, Azure, and AWS Bedrock are not yet supported for Langfuse observability.&lt;/p&gt; 
&lt;h2&gt;RAGAS-based Evaluation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;RAGAS&lt;/strong&gt; (Retrieval Augmented Generation Assessment) is a framework for reference-free evaluation of RAG systems using LLMs. There is an evaluation script based on RAGAS. For detailed information, please refer to &lt;a href="https://raw.githubusercontent.com/HKUDS/LightRAG/main/lightrag/evaluation/README_EVALUASTION_RAGAS.md"&gt;RAGAS-based Evaluation Framework&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Evaluation&lt;/h2&gt; 
&lt;h3&gt;Dataset&lt;/h3&gt; 
&lt;p&gt;The dataset used in LightRAG can be downloaded from &lt;a href="https://huggingface.co/datasets/TommyChien/UltraDomain"&gt;TommyChien/UltraDomain&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Generate Query&lt;/h3&gt; 
&lt;p&gt;LightRAG uses the following prompt to generate high-level queries, with the corresponding code in &lt;code&gt;examples/generate_query.py&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;Given the following description of a dataset:

{description}

Please identify 5 potential users who would engage with this dataset. For each user, list 5 tasks they would perform with this dataset. Then, for each (user, task) combination, generate 5 questions that require a high-level understanding of the entire dataset.

Output the results in the following structure:
- User 1: [user description]
    - Task 1: [task description]
        - Question 1:
        - Question 2:
        - Question 3:
        - Question 4:
        - Question 5:
    - Task 2: [task description]
        ...
    - Task 5: [task description]
- User 2: [user description]
    ...
- User 5: [user description]
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Batch Eval&lt;/h3&gt; 
&lt;p&gt;To evaluate the performance of two RAG systems on high-level queries, LightRAG uses the following prompt, with the specific code available in &lt;code&gt;reproduce/batch_eval.py&lt;/code&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Prompt &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;---Role---
You are an expert tasked with evaluating two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.
---Goal---
You will evaluate two answers to the same question based on three criteria: **Comprehensiveness**, **Diversity**, and **Empowerment**.

- **Comprehensiveness**: How much detail does the answer provide to cover all aspects and details of the question?
- **Diversity**: How varied and rich is the answer in providing different perspectives and insights on the question?
- **Empowerment**: How well does the answer help the reader understand and make informed judgments about the topic?

For each criterion, choose the better answer (either Answer 1 or Answer 2) and explain why. Then, select an overall winner based on these three categories.

Here is the question:
{query}

Here are the two answers:

**Answer 1:**
{answer1}

**Answer 2:**
{answer2}

Evaluate both answers using the three criteria listed above and provide detailed explanations for each criterion.

Output your evaluation in the following JSON format:

{{
    "Comprehensiveness": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Provide explanation here]"
    }},
    "Empowerment": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Provide explanation here]"
    }},
    "Overall Winner": {{
        "Winner": "[Answer 1 or Answer 2]",
        "Explanation": "[Summarize why this answer is the overall winner based on the three criteria]"
    }}
}}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Overall Performance Table&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Agriculture&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;CS&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Legal&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Mix&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;NaiveRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;23.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;62.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;13.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;86.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;83.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RQ-RAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;31.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;39.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.8%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;29.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;70.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;39.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;11.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;88.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;30.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;69.2%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;31.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;68.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;36.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;63.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;84.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;62.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;14.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;85.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;60.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HyDE&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;24.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;38.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;61.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;20.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;80.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;32.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;67.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;25.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;74.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;46.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;24.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;75.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;42.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;57.6%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GraphRAG&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;LightRAG&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Comprehensiveness&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;51.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;51.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.6%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;22.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;77.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;40.8%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;59.2%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;26.4%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;73.6%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;36.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;64.0%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Empowerment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;41.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;58.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;43.6%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;56.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.2%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;45.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;54.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;48.0%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;52.0%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;47.2%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;52.8%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;50.4%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;49.6%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Reproduce&lt;/h2&gt; 
&lt;p&gt;All the code can be found in the &lt;code&gt;./reproduce&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Step-0 Extract Unique Contexts&lt;/h3&gt; 
&lt;p&gt;First, we need to extract unique contexts in the datasets.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def extract_unique_contexts(input_directory, output_directory):

    os.makedirs(output_directory, exist_ok=True)

    jsonl_files = glob.glob(os.path.join(input_directory, '*.jsonl'))
    print(f"Found {len(jsonl_files)} JSONL files.")

    for file_path in jsonl_files:
        filename = os.path.basename(file_path)
        name, ext = os.path.splitext(filename)
        output_filename = f"{name}_unique_contexts.json"
        output_path = os.path.join(output_directory, output_filename)

        unique_contexts_dict = {}

        print(f"Processing file: {filename}")

        try:
            with open(file_path, 'r', encoding='utf-8') as infile:
                for line_number, line in enumerate(infile, start=1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        json_obj = json.loads(line)
                        context = json_obj.get('context')
                        if context and context not in unique_contexts_dict:
                            unique_contexts_dict[context] = None
                    except json.JSONDecodeError as e:
                        print(f"JSON decoding error in file {filename} at line {line_number}: {e}")
        except FileNotFoundError:
            print(f"File not found: {filename}")
            continue
        except Exception as e:
            print(f"An error occurred while processing file {filename}: {e}")
            continue

        unique_contexts_list = list(unique_contexts_dict.keys())
        print(f"There are {len(unique_contexts_list)} unique `context` entries in the file {filename}.")

        try:
            with open(output_path, 'w', encoding='utf-8') as outfile:
                json.dump(unique_contexts_list, outfile, ensure_ascii=False, indent=4)
            print(f"Unique `context` entries have been saved to: {output_filename}")
        except Exception as e:
            print(f"An error occurred while saving to the file {output_filename}: {e}")

    print("All files have been processed.")

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-1 Insert Contexts&lt;/h3&gt; 
&lt;p&gt;For the extracted contexts, we insert them into the LightRAG system.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def insert_text(rag, file_path):
    with open(file_path, mode='r') as f:
        unique_contexts = json.load(f)

    retries = 0
    max_retries = 3
    while retries &amp;lt; max_retries:
        try:
            rag.insert(unique_contexts)
            break
        except Exception as e:
            retries += 1
            print(f"Insertion failed, retrying ({retries}/{max_retries}), error: {e}")
            time.sleep(10)
    if retries == max_retries:
        print("Insertion failed after exceeding the maximum number of retries")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-2 Generate Queries&lt;/h3&gt; 
&lt;p&gt;We extract tokens from the first and the second half of each context in the dataset, then combine them as dataset descriptions to generate queries.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

def get_summary(context, tot_tokens=2000):
    tokens = tokenizer.tokenize(context)
    half_tokens = tot_tokens // 2

    start_tokens = tokens[1000:1000 + half_tokens]
    end_tokens = tokens[-(1000 + half_tokens):1000]

    summary_tokens = start_tokens + end_tokens
    summary = tokenizer.convert_tokens_to_string(summary_tokens)

    return summary
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step-3 Query&lt;/h3&gt; 
&lt;p&gt;For the queries generated in Step-2, we will extract them and query LightRAG.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; Code &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def extract_queries(file_path):
    with open(file_path, 'r') as f:
        data = f.read()

    data = data.replace('**', '')

    queries = re.findall(r'- Question \d+: (.+)', data)

    return queries
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ”— Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;ğŸ“¸&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;RAG-Anything&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Multimodal RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;ğŸ¥&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;âœ¨&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#HKUDS/LightRAG&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/LightRAG&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;ğŸ¤ Contribution&lt;/h2&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/LightRAG/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/LightRAG" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“– Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@article{guo2024lightrag,
title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
year={2024},
eprint={2410.05779},
archivePrefix={arXiv},
primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/â­%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ›%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/LightRAG/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ’¬%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting LightRAG!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>comfyanonymous/ComfyUI</title>
      <link>https://github.com/comfyanonymous/ComfyUI</link>
      <description>&lt;p&gt;The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;ComfyUI&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;The most powerful and modular visual AI engine and application.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.comfy.org/"&gt;&lt;img src="https://img.shields.io/badge/ComfyOrg-4285F4?style=flat" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://www.comfy.org/discord"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fcomfyorg%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=green&amp;amp;suffix=%20total" alt="Dynamic JSON Badge" /&gt;&lt;/a&gt; &lt;a href="https://x.com/ComfyUI"&gt;&lt;img src="https://img.shields.io/twitter/follow/ComfyUI" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org"&gt;&lt;img src="https://img.shields.io/badge/Matrix-000000?style=flat&amp;amp;logo=matrix&amp;amp;logoColor=white" alt="Matrix" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/comfyanonymous/ComfyUI?style=flat&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/comfyanonymous/ComfyUI?style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/total?style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/comfyanonymous/ComfyUI/latest/total?style=flat&amp;amp;label=downloads%40latest" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- Workaround to display total user from https://github.com/badges/shields/issues/4500#issuecomment-2060079995 --&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe" alt="ComfyUI Screenshot" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;ComfyUI lets you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. Available on Windows, Linux, and macOS.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h4&gt;&lt;a href="https://www.comfy.org/download"&gt;Desktop Application&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;The easiest way to get started.&lt;/li&gt; 
 &lt;li&gt;Available on Windows &amp;amp; macOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#installing"&gt;Windows Portable Package&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Get the latest commits and completely portable.&lt;/li&gt; 
 &lt;li&gt;Available on Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;Manual Install&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;Supports all operating systems and GPU types (NVIDIA, AMD, Intel, Apple Silicon, Ascend).&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;Examples&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;See what ComfyUI can do with the &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;example workflows&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.&lt;/li&gt; 
 &lt;li&gt;Image Models 
  &lt;ul&gt; 
   &lt;li&gt;SD1.x, SD2.x (&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/unclip/"&gt;unCLIP&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/"&gt;SDXL&lt;/a&gt;, &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/"&gt;SDXL Turbo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/"&gt;Stable Cascade&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/sd3/"&gt;SD3 and SD3.5&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Pixart Alpha and Sigma&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/aura_flow/"&gt;AuraFlow&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_dit/"&gt;HunyuanDiT&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/flux/"&gt;Flux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lumina2/"&gt;Lumina Image 2.0&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hidream/"&gt;HiDream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/"&gt;Qwen Image&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_image/"&gt;Hunyuan Image 2.1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/flux2/"&gt;Flux 2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/z_image/"&gt;Z Image&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Image Editing Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/omnigen/"&gt;Omnigen 2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-kontext-image-editing-model"&gt;Flux Kontext&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hidream/#hidream-e11"&gt;HiDream E1.1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/qwen_image/#edit-model"&gt;Qwen Image Edit&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Video Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/video/"&gt;Stable Video Diffusion&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/mochi/"&gt;Mochi&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/ltxv/"&gt;LTX-Video&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/"&gt;Hunyuan Video&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/wan/"&gt;Wan 2.1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/wan22/"&gt;Wan 2.2&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.comfy.org/tutorials/video/hunyuan/hunyuan-video-1-5"&gt;Hunyuan Video 1.5&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Audio Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/audio/"&gt;Stable Audio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/audio/"&gt;ACE Step&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;3D Models 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.comfy.org/tutorials/3d/hunyuan3D-2"&gt;Hunyuan3D 2.0&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Asynchronous Queue system&lt;/li&gt; 
 &lt;li&gt;Many optimizations: Only re-executes the parts of the workflow that changes between executions.&lt;/li&gt; 
 &lt;li&gt;Smart memory management: can automatically run large models on GPUs with as low as 1GB vram with smart offloading.&lt;/li&gt; 
 &lt;li&gt;Works even if you don't have a GPU with: &lt;code&gt;--cpu&lt;/code&gt; (slow)&lt;/li&gt; 
 &lt;li&gt;Can load ckpt and safetensors: All in one checkpoints or standalone diffusion models, VAEs and CLIP models.&lt;/li&gt; 
 &lt;li&gt;Safe loading of ckpt, pt, pth, etc.. files.&lt;/li&gt; 
 &lt;li&gt;Embeddings/Textual inversion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lora/"&gt;Loras (regular, locon and loha)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/"&gt;Hypernetworks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Loading full workflows (with seeds) from generated PNG, WebP and FLAC files.&lt;/li&gt; 
 &lt;li&gt;Saving/Loading workflows as Json files.&lt;/li&gt; 
 &lt;li&gt;Nodes interface can be used to create complex workflows like one for &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/"&gt;Hires fix&lt;/a&gt; or much more advanced ones.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/"&gt;Area Composition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/"&gt;Inpainting&lt;/a&gt; with both regular and inpainting models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/"&gt;ControlNet and T2I-Adapter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/"&gt;Upscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/gligen/"&gt;GLIGEN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/"&gt;Model Merging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/lcm/"&gt;LCM models and Loras&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Latent previews with &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#how-to-show-high-quality-previews"&gt;TAESD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Works fully offline: core will never download anything unless you want to.&lt;/li&gt; 
 &lt;li&gt;Optional API nodes to use paid models from external providers through the online &lt;a href="https://docs.comfy.org/tutorials/api-nodes/overview"&gt;Comfy API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example"&gt;Config file&lt;/a&gt; to set the search paths for models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Workflow examples can be found on the &lt;a href="https://comfyanonymous.github.io/ComfyUI_examples/"&gt;Examples page&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release Process&lt;/h2&gt; 
&lt;p&gt;ComfyUI follows a weekly release cycle targeting Monday but this regularly changes because of model releases or large changes to the codebase. There are three interconnected repositories:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI Core&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Releases a new stable version (e.g., v0.7.0) roughly every week.&lt;/li&gt; 
   &lt;li&gt;Commits outside of the stable release tags may be very unstable and break many custom nodes.&lt;/li&gt; 
   &lt;li&gt;Serves as the foundation for the desktop release&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Comfy-Org/desktop"&gt;ComfyUI Desktop&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Builds a new release using the latest stable core version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Weekly frontend updates are merged into the core repository&lt;/li&gt; 
   &lt;li&gt;Features are frozen for the upcoming core release&lt;/li&gt; 
   &lt;li&gt;Development continues for the next release cycle&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Shortcuts&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Keybind&lt;/th&gt; 
   &lt;th&gt;Explanation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Queue up current graph for generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Queue up current graph as first for generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;Enter&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cancel current generation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Z&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Y&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Undo/Redo&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;S&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Save workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;O&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Load workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;A&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Select all nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt &lt;/code&gt;+ &lt;code&gt;C&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Collapse/uncollapse selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;M&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Mute/unmute selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;B&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Delete&lt;/code&gt;/&lt;code&gt;Backspace&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Delete selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Backspace&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Delete the current graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Space&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move the canvas around when held and moving the cursor&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt;/&lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Click&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Add clicked node to selection&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;V&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy and paste selected nodes (without maintaining connections to outputs of unselected nodes)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;C&lt;/code&gt;/&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;V&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Drag&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Move multiple selected nodes at the same time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;D&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Load default graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Alt&lt;/code&gt; + &lt;code&gt;-&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom out&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Shift&lt;/code&gt; + LMB + Vertical drag&lt;/td&gt; 
   &lt;td&gt;Canvas Zoom in/out&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;P&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pin/Unpin selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;G&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Group selected nodes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle visibility of the queue&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;H&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Toggle visibility of history&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;R&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Refresh graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;F&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show/Hide menu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;.&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Fit view to selection (Whole graph when nothing is selected)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Double-Click LMB&lt;/td&gt; 
   &lt;td&gt;Open node quick search palette&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Shift&lt;/code&gt; + Drag&lt;/td&gt; 
   &lt;td&gt;Move multiple wires at once&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Ctrl&lt;/code&gt; + &lt;code&gt;Alt&lt;/code&gt; + LMB&lt;/td&gt; 
   &lt;td&gt;Disconnect all wires from clicked slot&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;code&gt;Ctrl&lt;/code&gt; can also be replaced with &lt;code&gt;Cmd&lt;/code&gt; instead for macOS users&lt;/p&gt; 
&lt;h1&gt;Installing&lt;/h1&gt; 
&lt;h2&gt;Windows Portable&lt;/h2&gt; 
&lt;p&gt;There is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the &lt;a href="https://github.com/comfyanonymous/ComfyUI/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia.7z"&gt;Direct link to download&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Simply download, extract with &lt;a href="https://7-zip.org"&gt;7-Zip&lt;/a&gt; or with the windows explorer on recent windows versions and run. For smaller models you normally only need to put the checkpoints (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints but many of the larger models have multiple files. Make sure to follow the instructions to know which subfolder to put them in ComfyUI\models\&lt;/p&gt; 
&lt;p&gt;If you have trouble extracting it, right click the file -&amp;gt; properties -&amp;gt; unblock&lt;/p&gt; 
&lt;p&gt;Update your Nvidia drivers if it doesn't start.&lt;/p&gt; 
&lt;h4&gt;Alternative Downloads:&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_amd.7z"&gt;Experimental portable for AMD GPUs&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia_cu128.7z"&gt;Portable with pytorch cuda 12.8 and python 3.12&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/releases/latest/download/ComfyUI_windows_portable_nvidia_cu126.7z"&gt;Portable with pytorch cuda 12.6 and python 3.12&lt;/a&gt; (Supports Nvidia 10 series and older GPUs).&lt;/p&gt; 
&lt;h4&gt;How do I share models between another UI and ComfyUI?&lt;/h4&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/extra_model_paths.yaml.example"&gt;Config file&lt;/a&gt; to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://docs.comfy.org/comfy-cli/getting-started"&gt;comfy-cli&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;You can install and start ComfyUI using comfy-cli:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install comfy-cli
comfy install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Manual Install (Windows, Linux)&lt;/h2&gt; 
&lt;p&gt;Python 3.14 works but you may encounter issues with the torch compile node. The free threaded variant is still missing some dependencies.&lt;/p&gt; 
&lt;p&gt;Python 3.13 is very well supported. If you have trouble with some custom node dependencies on 3.13 you can try 3.12&lt;/p&gt; 
&lt;h3&gt;Instructions:&lt;/h3&gt; 
&lt;p&gt;Git clone this repo.&lt;/p&gt; 
&lt;p&gt;Put your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints&lt;/p&gt; 
&lt;p&gt;Put your VAE in: models/vae&lt;/p&gt; 
&lt;h3&gt;AMD GPUs (Linux)&lt;/h3&gt; 
&lt;p&gt;AMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.4&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install the nightly with ROCm 7.0 which might have some performance improvements:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm7.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;AMD GPUs (Experimental: Windows and Linux), RDNA 3, 3.5 and 4 only.&lt;/h3&gt; 
&lt;p&gt;These have less hardware support than the builds above but they work on windows. You also need to install the pytorch version specific to your hardware.&lt;/p&gt; 
&lt;p&gt;RDNA 3 (RX 7000 series):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx110X-dgpu/&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;RDNA 3.5 (Strix halo/Ryzen AI Max+ 365):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx1151/&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;RDNA 4 (RX 9000 series):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx120X-all/&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Intel GPUs (Windows and Linux)&lt;/h3&gt; 
&lt;p&gt;Intel Arc GPU users can install native PyTorch with torch.xpu support using pip. More information can be found &lt;a href="https://pytorch.org/docs/main/notes/get_start_xpu.html"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;To install PyTorch xpu, use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install the Pytorch xpu nightly which might have some performance improvements:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;NVIDIA&lt;/h3&gt; 
&lt;p&gt;Nvidia users should install stable pytorch using this command:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu130&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the command to install pytorch nightly instead which might have performance improvements.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Troubleshooting&lt;/h4&gt; 
&lt;p&gt;If you get the "Torch not compiled with CUDA enabled" error, uninstall torch with:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip uninstall torch&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;And install it again with the command above.&lt;/p&gt; 
&lt;h3&gt;Dependencies&lt;/h3&gt; 
&lt;p&gt;Install the dependencies by opening your terminal inside the ComfyUI folder and:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;After this you should have everything installed and can proceed to running ComfyUI.&lt;/p&gt; 
&lt;h3&gt;Others:&lt;/h3&gt; 
&lt;h4&gt;Apple Mac silicon&lt;/h4&gt; 
&lt;p&gt;You can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install pytorch nightly. For instructions, read the &lt;a href="https://developer.apple.com/metal/pytorch/"&gt;Accelerated PyTorch training on Mac&lt;/a&gt; Apple Developer guide (make sure to install the latest pytorch nightly).&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt; instructions for Windows and Linux.&lt;/li&gt; 
 &lt;li&gt;Install the ComfyUI &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#dependencies"&gt;dependencies&lt;/a&gt;. If you have another Stable Diffusion UI &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#i-already-have-another-ui-for-stable-diffusion-installed-do-i-really-have-to-install-all-of-these-dependencies"&gt;you might be able to reuse the dependencies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Ascend NPUs&lt;/h4&gt; 
&lt;p&gt;For models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the &lt;a href="https://ascend.github.io/docs/sources/ascend/quick_install.html"&gt;installation&lt;/a&gt; page. Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.&lt;/li&gt; 
 &lt;li&gt;Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.&lt;/li&gt; 
 &lt;li&gt;Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the &lt;a href="https://ascend.github.io/docs/sources/pytorch/install.html#pytorch"&gt;Installation&lt;/a&gt; page.&lt;/li&gt; 
 &lt;li&gt;Finally, adhere to the &lt;a href="https://raw.githubusercontent.com/comfyanonymous/ComfyUI/master/#manual-install-windows-linux"&gt;ComfyUI manual installation&lt;/a&gt; guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Cambricon MLUs&lt;/h4&gt; 
&lt;p&gt;For models compatible with Cambricon Extension for PyTorch (torch_mlu). Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the Cambricon CNToolkit by adhering to the platform-specific instructions on the &lt;a href="https://www.cambricon.com/docs/sdk_1.15.0/cntoolkit_3.7.2/cntoolkit_install_3.7.2/index.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Next, install the PyTorch(torch_mlu) following the instructions on the &lt;a href="https://www.cambricon.com/docs/sdk_1.15.0/cambricon_pytorch_1.17.0/user_guide_1.9/index.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Iluvatar Corex&lt;/h4&gt; 
&lt;p&gt;For models compatible with Iluvatar Extension for PyTorch. Here's a step-by-step guide tailored to your platform and installation method:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the Iluvatar Corex Toolkit by adhering to the platform-specific instructions on the &lt;a href="https://support.iluvatar.com/#/DocumentCentre?id=1&amp;amp;nameCenter=2&amp;amp;productId=520117912052801536"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Launch ComfyUI by running &lt;code&gt;python main.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Comfy-Org/ComfyUI-Manager/tree/manager-v4"&gt;ComfyUI-Manager&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ComfyUI-Manager&lt;/strong&gt; is an extension that allows you to easily install, update, and manage custom nodes for ComfyUI.&lt;/p&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install the manager dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r manager_requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable the manager with the &lt;code&gt;--enable-manager&lt;/code&gt; flag when running ComfyUI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --enable-manager
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Command Line Options&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--enable-manager&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable ComfyUI-Manager&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--enable-manager-legacy-ui&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Use the legacy manager UI instead of the new UI (requires &lt;code&gt;--enable-manager&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--disable-manager-ui&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disable the manager UI and endpoints while keeping background features like security checks and scheduled installation completion (requires &lt;code&gt;--enable-manager&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Running&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;For AMD cards not officially supported by ROCm&lt;/h3&gt; 
&lt;p&gt;Try running it with this command if you have issues:&lt;/p&gt; 
&lt;p&gt;For 6700, 6600 and maybe other RDNA2 or older: &lt;code&gt;HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;For AMD 7600 and maybe other RDNA3 cards: &lt;code&gt;HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;AMD ROCm Tips&lt;/h3&gt; 
&lt;p&gt;You can enable experimental memory efficient attention on recent pytorch in ComfyUI on some AMD GPUs using this command, it should already be enabled by default on RDNA3. If this improves speed for you on latest pytorch on your GPU please report it so that I can enable it by default.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 python main.py --use-pytorch-cross-attention&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also try setting this env variable &lt;code&gt;PYTORCH_TUNABLEOP_ENABLED=1&lt;/code&gt; which might speed things up at the cost of a very slow initial run.&lt;/p&gt; 
&lt;h1&gt;Notes&lt;/h1&gt; 
&lt;p&gt;Only parts of the graph that have an output with all the correct inputs will be executed.&lt;/p&gt; 
&lt;p&gt;Only parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.&lt;/p&gt; 
&lt;p&gt;Dragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.&lt;/p&gt; 
&lt;p&gt;You can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \( or \).&lt;/p&gt; 
&lt;p&gt;You can use {day|night}, for wildcard/dynamic prompts. With this syntax "{wild|card|test}" will be randomly replaced by either "wild", "card" or "test" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \{ or \}.&lt;/p&gt; 
&lt;p&gt;Dynamic prompts also support C-style comments, like &lt;code&gt;// comment&lt;/code&gt; or &lt;code&gt;/* comment */&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;embedding:embedding_filename.pt&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;How to show high-quality previews?&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;--preview-method auto&lt;/code&gt; to enable previews.&lt;/p&gt; 
&lt;p&gt;The default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with &lt;a href="https://github.com/madebyollin/taesd"&gt;TAESD&lt;/a&gt;, download the &lt;a href="https://github.com/madebyollin/taesd/"&gt;taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth&lt;/a&gt; and place them in the &lt;code&gt;models/vae_approx&lt;/code&gt; folder. Once they're installed, restart ComfyUI and launch it with &lt;code&gt;--preview-method taesd&lt;/code&gt; to enable high-quality previews.&lt;/p&gt; 
&lt;h2&gt;How to use TLS/SSL?&lt;/h2&gt; 
&lt;p&gt;Generate a self-signed certificate (not appropriate for shared/production use) and key by running the command: &lt;code&gt;openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj "/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;--tls-keyfile key.pem --tls-certfile cert.pem&lt;/code&gt; to enable TLS/SSL, the app will now be accessible with &lt;code&gt;https://...&lt;/code&gt; instead of &lt;code&gt;http://...&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Windows users can use &lt;a href="https://github.com/alexisrolland/docker-openssl"&gt;alexisrolland/docker-openssl&lt;/a&gt; or one of the &lt;a href="https://wiki.openssl.org/index.php/Binaries"&gt;3rd party binary distributions&lt;/a&gt; to run the command example above. &lt;br /&gt;&lt;br /&gt;If you use a container, note that the volume mount &lt;code&gt;-v&lt;/code&gt; can be a relative path so &lt;code&gt;... -v ".\:/openssl-certs" ...&lt;/code&gt; would create the key &amp;amp; cert files in the current directory of your command prompt or powershell terminal.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support and dev channel&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://comfy.org/discord"&gt;Discord&lt;/a&gt;: Try the #help or #feedback channels.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.element.io/#/room/%23comfyui_space%3Amatrix.org"&gt;Matrix space: #comfyui_space:matrix.org&lt;/a&gt; (it's like discord but open source).&lt;/p&gt; 
&lt;p&gt;See also: &lt;a href="https://www.comfy.org/"&gt;https://www.comfy.org/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Frontend Development&lt;/h2&gt; 
&lt;p&gt;As of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: &lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend&lt;/a&gt;. This repository now hosts the compiled JS (from TS/Vue) under the &lt;code&gt;web/&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Reporting Issues and Requesting Features&lt;/h3&gt; 
&lt;p&gt;For any bugs, issues, or feature requests related to the frontend, please use the &lt;a href="https://github.com/Comfy-Org/ComfyUI_frontend"&gt;ComfyUI Frontend repository&lt;/a&gt;. This will help us manage and address frontend-specific concerns more efficiently.&lt;/p&gt; 
&lt;h3&gt;Using the Latest Frontend&lt;/h3&gt; 
&lt;p&gt;The new frontend is now the default for ComfyUI. However, please note:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The frontend in the main ComfyUI repository is updated fortnightly.&lt;/li&gt; 
 &lt;li&gt;Daily releases are available in the separate frontend repository.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To use the most up-to-date frontend version:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;For the latest daily release, launch ComfyUI with this command line argument:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_frontend@latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For a specific version, replace &lt;code&gt;latest&lt;/code&gt; with the desired version number:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_frontend@1.2.2
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This approach allows you to easily switch between the stable fortnightly release and the cutting-edge daily updates, or even specific versions for testing purposes.&lt;/p&gt; 
&lt;h3&gt;Accessing the Legacy Frontend&lt;/h3&gt; 
&lt;p&gt;If you need to use the legacy frontend for any reason, you can access it using the following command line argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will use a snapshot of the legacy frontend preserved in the &lt;a href="https://github.com/Comfy-Org/ComfyUI_legacy_frontend"&gt;ComfyUI Legacy Frontend repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;QA&lt;/h1&gt; 
&lt;h3&gt;Which GPU should I buy for this?&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/comfyanonymous/ComfyUI/wiki/Which-GPU-should-I-buy-for-ComfyUI"&gt;See this page for some recommendations&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aliasrobotics/cai</title>
      <link>https://github.com/aliasrobotics/cai</link>
      <description>&lt;p&gt;Cybersecurity AI (CAI), the framework for AI Security&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/cai.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14317" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14317" alt="aliasrobotics%2Fcai | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://defiant.vc/api/european-open-source/badge?domain=aliasrobotics.com&amp;amp;style=most-starred-top-3" target="_blank"&gt;&lt;img src="https://defiant.vc/api/european-open-source/badge?domain=aliasrobotics.com&amp;amp;style=most-starred-top-3" alt="European Open Source - Most Starred Top 3" style=" height: 75px;" height="75" /&gt;&lt;/a&gt; &lt;a href="https://defiant.vc/api/european-open-source/badge?domain=aliasrobotics.com&amp;amp;style=most-forked-top-3" target="_blank"&gt;&lt;img src="https://defiant.vc/api/european-open-source/badge?domain=aliasrobotics.com&amp;amp;style=most-forked-top-3" alt="European Open Source - Most Forked Top 3" style="height: 75px;" height="75" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/cai-framework"&gt;&lt;img src="https://badge.fury.io/py/cai-framework.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/cai-framework"&gt;&lt;img src="https://static.pepy.tech/badge/cai-framework" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Linux-Supported-brightgreen?logo=linux&amp;amp;logoColor=white" alt="Linux" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/OS%20X-Supported-brightgreen?logo=apple&amp;amp;logoColor=white" alt="OS X" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Windows-Supported-brightgreen?logo=windows&amp;amp;logoColor=white" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aliasrobotics/cai"&gt;&lt;img src="https://img.shields.io/badge/Android-Supported-brightgreen?logo=android&amp;amp;logoColor=white" alt="Android" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fnUFcTaQAC"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2510.17521"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.17521-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2510.24317"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.24317-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- CAI PRO - Professional Edition Banner --&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://aliasrobotics.com/cybersecurityai.php" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai-banner.svg?sanitize=true" alt="CAI - Community and Professional Editions" width="100%" style="max-width: 900px;" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;sub&gt;&lt;i&gt;Professional Edition with unlimited &lt;code&gt;alias1&lt;/code&gt; tokens&lt;/i&gt; | &lt;a href="https://aliasrobotics.com/alias1.php#benchmarking"&gt;ğŸ“Š View Benchmarks&lt;/a&gt; | &lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;ğŸš€ Learn More&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt; 
 &lt;table style="border-collapse: collapse; width: 100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="padding: 0; border: none;"&gt; &lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai_poc.gif" alt="CAI Community Edition Demo" width="100%" /&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="padding: 0; border: none;"&gt; &lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/caipro_poc.gif" alt="CAI PRO Professional Edition Demo" width="100%" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;!-- Alternative HTML version (kept as comment for reference) --&gt; 
&lt;!--
&lt;div align="center"&gt;
  &lt;table style="border-collapse: collapse; width: 100%; max-width: 900px; box-shadow: 0 4px 12px rgba(82, 157, 134, 0.15);"&gt;
    &lt;tr&gt;
      &lt;td align="center" width="50%" style="padding: 20px; border: 3px solid #529d86; border-right: 1.5px solid #529d86; border-radius: 10px 0 0 10px; background: linear-gradient(135deg, #f0f8f6 0%, #ffffff 100%);"&gt;
        &lt;h3 style="color: #3d7b6b;"&gt;ğŸ”“ Community Edition&lt;/h3&gt;
        &lt;sub style="color: #529d86;"&gt;&lt;b&gt;Research &amp; Learning Â· Perfect for Researchers &amp; Students&lt;/b&gt;&lt;/sub&gt;&lt;br&gt;&lt;br&gt;
        &lt;code style="background: linear-gradient(135deg, #e8f5f1 0%, #d4ede5 100%); padding: 8px 16px; border-radius: 6px; font-size: 14px; border: 1px solid #529d86; color: #2d5a4d;"&gt;pip install cai-framework&lt;/code&gt;&lt;br&gt;&lt;br&gt;
        &lt;div align="left" style="margin: 10px auto; max-width: 200px; color: #2d2d2d;"&gt;
          âœ… &lt;b style="color: #529d86;"&gt;Free&lt;/b&gt; for research&lt;br&gt;
          ğŸ¤– &lt;b style="color: #529d86;"&gt;300+&lt;/b&gt; AI models&lt;br&gt;
          ğŸŒ &lt;b style="color: #529d86;"&gt;Community&lt;/b&gt; driven&lt;br&gt;
          ğŸ“š &lt;b style="color: #529d86;"&gt;Open&lt;/b&gt; source&lt;br&gt;
          ğŸ”§ &lt;b style="color: #529d86;"&gt;Extensible&lt;/b&gt; framework&lt;br&gt;
        &lt;/div&gt;
      &lt;/td&gt;
      &lt;td align="center" width="50%" style="padding: 20px; border: 3px solid #529d86; border-left: 1.5px solid #529d86; border-radius: 0 10px 10px 0; background: linear-gradient(135deg, #529d86 0%, #6bb09a 100%); position: relative; box-shadow: inset 0 0 30px rgba(255, 255, 255, 0.1);"&gt;
        &lt;h3 style="color: #ffffff; text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);"&gt;ğŸš€ &lt;a href="https://aliasrobotics.com/cybersecurityai.php" style="text-decoration: none; color: #ffffff;"&gt;Professional Edition&lt;/a&gt;&lt;/h3&gt;
        &lt;sub style="color: #e8f5f1;"&gt;&lt;b&gt;Enterprise &amp; Production Â· â‚¬350/month Â· Unlimited &lt;code style="background: rgba(255, 255, 255, 0.2); padding: 2px 6px; border-radius: 3px; color: #ffffff;"&gt;alias1&lt;/code&gt; Tokens&lt;/b&gt;&lt;/sub&gt;&lt;br&gt;&lt;br&gt;
        &lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;
          &lt;code style="background: linear-gradient(135deg, #ffffff 0%, #f0f8f6 100%); color: #529d86; padding: 10px 20px; border-radius: 6px; font-size: 14px; font-weight: bold; border: 2px solid #ffffff; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);"&gt;â†’ Upgrade to PRO&lt;/code&gt;
        &lt;/a&gt;&lt;br&gt;&lt;br&gt;
        &lt;div align="left" style="margin: 10px auto; max-width: 280px; color: #ffffff;"&gt;
          âš¡ &lt;b&gt;&lt;a href="https://aliasrobotics.com/alias1.php#benchmarking" style="color: #ffffff; text-decoration: underline;"&gt;alias1&lt;/a&gt;&lt;/b&gt; model - âˆ unlimited tokens&lt;br&gt;
          ğŸš« &lt;b&gt;Zero refusals&lt;/b&gt; - Unrestricted AI&lt;br&gt;
          ğŸ† &lt;b&gt;Beats GPT-5&lt;/b&gt; in CTF benchmarks&lt;br&gt;
          ğŸ›¡ï¸ &lt;b&gt;Professional&lt;/b&gt; support included&lt;br&gt;
          ğŸ‡ªğŸ‡º &lt;b&gt;European&lt;/b&gt; data sovereignty&lt;br&gt;
        &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan="2" align="center" style="padding: 10px; background: #f6f8fa;"&gt;
        &lt;sub&gt;
          &lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;&lt;/a&gt;&lt;br&gt;
          &lt;i&gt;CAI PRO w/ &lt;code&gt;alias1&lt;/code&gt; model outperforms GPT-5 in AI vs AI cybersecurity benchmarks&lt;/i&gt; | &lt;a href="https://aliasrobotics.com/alias1.php#benchmarking"&gt;View Full Benchmarks â†’&lt;/a&gt;
        &lt;/sub&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;
--&gt; 
&lt;p&gt;Cybersecurity AI (CAI) is a lightweight, open-source framework that empowers security professionals to build and deploy AI-powered offensive and defensive automation. CAI is the &lt;em&gt;de facto&lt;/em&gt; framework for AI Security, already used by thousands of individual users and hundreds of organizations. Whether you're a security researcher, ethical hacker, IT professional, or organization looking to enhance your security posture, CAI provides the building blocks to create specialized AI agents that can assist with mitigation, vulnerability discovery, exploitation, and security assessment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;300+ AI Models&lt;/strong&gt;: Support for OpenAI, Anthropic, DeepSeek, Ollama, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Built-in Security Tools&lt;/strong&gt;: Ready-to-use tools for reconnaissance, exploitation, and privilege escalation&lt;/li&gt; 
 &lt;li&gt;ğŸ† &lt;strong&gt;Battle-tested&lt;/strong&gt;: Proven in HackTheBox CTFs, bug bounties, and real-world security &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;case studies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Agent-based Architecture&lt;/strong&gt;: Modular framework design to build specialized agents for different security tasks&lt;/li&gt; 
 &lt;li&gt;ğŸ›¡ï¸ &lt;strong&gt;Guardrails Protection&lt;/strong&gt;: Built-in defenses against prompt injection and dangerous command execution&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Research-oriented&lt;/strong&gt;: Research foundation to democratize cybersecurity AI for the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Read the technical report: &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;CAI: An Open, Bug Bounty-Ready Cybersecurity AI&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;For further readings, refer to our &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;impact&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;CAI citation&lt;/a&gt; sections.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-humanoid-robot-g1.php"&gt;&lt;code&gt;Robotics&lt;/code&gt; - CAI and alias1 on: Unitree G1 Humanoid Robot&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-dragos-CTF.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias1 on: Dragos OT CTF 2025&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI uncovers vulnerabilities and privacy violations in Unitree G1 humanoid robots including unauthorized telemetry transmission to China-related servers, exposed RSA keys with world-writable permissions, and potential surveillance capabilities violating GDPR and international privacy laws.&lt;/td&gt; 
   &lt;td&gt;CAI powered by alias1, demonstrates exceptional performance in operational technology cybersecurity by achieving a Top-10 ranking in the Dragos OT CTF 2025. The AI agent reached Rank 1 during competition hours 7-8, completed 32 of 34 challenges, and maintained a 37% velocity advantage over top human teams.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-humanoid-robot-g1.php"&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/assets/images/case-study-humanoid-portada.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-dragos-CTF.php"&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/assets/images/case-study-dragosCTF.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-hackerone.php"&gt;&lt;code&gt;IT&lt;/code&gt; (Bug Bounty) - CAI on: HackerOne Platform&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: Ecoforest Heat Pumps&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HackerOne's top engineers leverage CAI to explore next-gen agentic AI architectures and build their own security products. CAI's Retester agent directly inspired HackerOne's AI-powered Deduplication Agent, now deployed in production to handle millions of vulnerability reports at scale.&lt;/td&gt; 
   &lt;td&gt;CAI discovers critical vulnerability in Ecoforest heat pumps allowing unauthorized remote access and potential catastrophic failures. AI-powered security testing reveals exposed credentials and DES encryption weaknesses affecting all of their deployed units across Europe.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-hackerone.php"&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/assets/images/case-study-hackerone.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-ecoforest.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-ecoforest.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;code&gt;Robotics&lt;/code&gt; - CAI and alias0 on: Mobile Industrial Robots (MiR)&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;code&gt;IT&lt;/code&gt; (Web) - CAI and alias0 on: Mercado Libre's e-commerce&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI-powered security testing of MiR (Mobile Industrial Robot) platform through automated ROS message injection attacks. This study demonstrates how AI-driven vulnerability discovery can expose unauthorized access to robot control systems and alarm triggers.&lt;/td&gt; 
   &lt;td&gt;CAI-powered API vulnerability discovery at Mercado Libre through automated enumeration attacks. This study demonstrates how AI-driven security testing can expose user data exposure risks in e-commerce platforms at scale.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mir.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mir-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-mercado-libre.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mercado-libre.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;code&gt;OT&lt;/code&gt; - CAI and alias0 on: MQTT broker&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://aliasrobotics.com/case-study-portswigger-1.php"&gt;&lt;code&gt;IT&lt;/code&gt; (Web) - CAI and alias0 on: PortSwigger Web Security Academy&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CAI-powered testing exposed critical flaws in an MQTT broker within a Dockerized OT network. Without authentication, CAI subscribed to temperature and humidity topics and injected false values, corrupting data shown in Grafana dashboards.&lt;/td&gt; 
   &lt;td&gt;CAI-powered race condition exploitation in file upload vulnerability. This study demonstrates how AI-driven security testing can identify and exploit timing windows in web applications, successfully uploading and executing web shells through automated parallel requests.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-cai-mqtt-broker.php"&gt;&lt;img src="https://aliasrobotics.com/img/case-study-portada-mqtt-broker-cai.png" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aliasrobotics.com/case-study-portswigger-1.php"&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/assets/images/portada-portswigger-web-1.jpg" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;span&gt;âš &lt;/span&gt; CAI is in active development, so don't expect it to work flawlessly. Instead, contribute by raising an issue or &lt;a href="https://github.com/aliasrobotics/cai/pulls"&gt;sending a PR&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Access to this library and the use of information, materials (or portions thereof), is &lt;strong&gt;&lt;u&gt;not intended&lt;/u&gt;, and is &lt;u&gt;prohibited&lt;/u&gt;, where such access or use violates applicable laws or regulations&lt;/strong&gt;. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don't use the source code in here for cybercrime. &lt;u&gt;Pentest for good instead&lt;/u&gt;&lt;/em&gt;. By downloading, using, or modifying this source code, you agree to the terms of the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; and the limitations outlined in the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/DISCLAIMER"&gt;&lt;code&gt;DISCLAIMER&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”–&lt;/span&gt; Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#cybersecurity-ai-cai"&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bookmark-table-of-contents"&gt;&lt;span&gt;ğŸ”–&lt;/span&gt; Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-impact"&gt;ğŸ¯ Impact&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-competitions-and-challenges"&gt;ğŸ† Competitions and challenges&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-impact"&gt;ğŸ“Š Research Impact&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-research-products-cybersecurity-ai"&gt;ğŸ“š Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#pocs"&gt;PoCs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#motivation"&gt;Motivation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#bust_in_silhouette-why-cai"&gt;&lt;span&gt;ğŸ‘¤&lt;/span&gt; Why CAI?&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ethical-principles-behind-cai"&gt;Ethical principles behind CAI&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#closed-source-alternatives"&gt;Closed-source alternatives&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#learn---cai-fluency"&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-install"&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Install&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#os-x"&gt;OS X&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2404"&gt;Ubuntu 24.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#ubuntu-2004"&gt;Ubuntu 20.04&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#windows-wsl"&gt;Windows WSL&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#android"&gt;Android&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#nut_and_bolt-setup-env-file"&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-custom-openai-base-url-support"&gt;ğŸ”¹ Custom OpenAI Base URL Support&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#triangular_ruler-architecture"&gt;&lt;span&gt;ğŸ“&lt;/span&gt; Architecture:&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-agent"&gt;ğŸ”¹ Agent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tools"&gt;ğŸ”¹ Tools&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-handoffs"&gt;ğŸ”¹ Handoffs&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-patterns"&gt;ğŸ”¹ Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-turns-and-interactions"&gt;ğŸ”¹ Turns and Interactions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-tracing"&gt;ğŸ”¹ Tracing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-guardrails"&gt;ğŸ”¹ Guardrails&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#-human-in-the-loop-hitl"&gt;ğŸ”¹ Human-In-The-Loop (HITL)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#rocket-quickstart"&gt;&lt;span&gt;ğŸš€&lt;/span&gt; Quickstart&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#openrouter-integration"&gt;OpenRouter Integration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#azure-openai"&gt;Azure OpenAI&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#mcp"&gt;MCP&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#contributions"&gt;Contributions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;Optional Requirements: caiextensions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#information_source-usage-data-collection"&gt;&lt;span&gt;â„¹&lt;/span&gt; Usage Data Collection&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#reproduce-ci-setup-locally"&gt;Reproduce CI-Setup locally&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#academic-collaborations"&gt;Academic Collaborations&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¯ Impact&lt;/h2&gt; 
&lt;h3&gt;ğŸ† Competitions and challenges&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_90_Spain_(5_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_50_Spain_(6_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_30_Spain_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://app.hackthebox.com/users/2268644"&gt;&lt;img src="https://img.shields.io/badge/HTB_ranking-top_500_World_(7_days)-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_(AIs)_world-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_1_Spain-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-top_20_World-red.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://ctf.hackthebox.com/event/2000/scoreboard"&gt;&lt;img src="https://img.shields.io/badge/HTB_%22Human_vs_AI%22_CTF-750_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://lu.ma/roboticshack?tk=RuryKF"&gt;&lt;img src="https://img.shields.io/badge/Mistral_AI_Robotics_Hackathon-2500_$-yellow.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ“Š Research Impact&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Pioneered LLM-powered AI Security with PentestGPT, establishing the foundation for the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research domain &lt;a href="https://arxiv.org/pdf/2308.06782"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2308.06782-4a9b8e.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Established the &lt;code&gt;Cybersecurity AI&lt;/code&gt; research line with &lt;strong&gt;8 papers and technical reports&lt;/strong&gt;, with active research collaborations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2510.17521"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.17521-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2510.24317"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.24317-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Demonstrated &lt;strong&gt;3,600Ã— performance improvement&lt;/strong&gt; over human penetration testers in standardized CTF benchmark evaluations &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Identified &lt;strong&gt;CVSS 4.3-7.5 severity vulnerabilities&lt;/strong&gt; in production systems through automated security assessment &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Democratization of AI-empowered vulnerability research&lt;/strong&gt;: CAI enables both non-security domain experts and experienced researchers to conduct more efficient vulnerability discovery, expanding the security research community while empowering small and medium enterprises to conduct autonomous security assessments &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Systematic evaluation of large language models&lt;/strong&gt; across both proprietary and open-weight architectures, revealing &lt;u&gt;substantial gaps&lt;/u&gt; between vendor-reported capabilities and empirical cybersecurity performance metrics &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Established the &lt;strong&gt;autonomy levels in cybersecurity&lt;/strong&gt; and argued about autonomy vs automation in the field &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Collaborative research initiatives&lt;/strong&gt; with international academic institutions focused on developing cybersecurity education curricula and training methodologies &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Contributed a comprehensive defense framework against prompt injection in AI security agents&lt;/strong&gt;: developed and empirically validated a multi-layered defense system that addresses the identified prompt injection issues &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Explord the Cybersecurity of Humanoid Robots with CAI and identified new attack vectors showing how it &lt;code&gt;(a)&lt;/code&gt; operates simultaneously as a covert surveillance node and &lt;code&gt;(b)&lt;/code&gt; can be purposed as an active cyber operations platform &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“š Research products: &lt;code&gt;Cybersecurity AI&lt;/code&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI, An Open, Bug Bounty-Ready Cybersecurity AI &lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2504.06017-63bfab.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;The Dangerous Gap Between Automation and Autonomy &lt;a href="https://arxiv.org/abs/2506.23592"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2506.23592-7dd3c0.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;CAI Fluency, A Framework for Cybersecurity AI Fluency &lt;a href="https://arxiv.org/abs/2508.13588"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.13588-52a896.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;Hacking the AI Hackers via Prompt Injection &lt;a href="https://arxiv.org/abs/2508.21669"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2508.21669-85e0d1.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2504.06017"&gt;&lt;img src="https://aliasrobotics.com/img/paper-cai.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arxiv.org/pdf/2506.23592"&gt;&lt;img src="https://aliasrobotics.com/img/cai_automation_vs_autonomy.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;&lt;img src="https://aliasrobotics.com/img/cai_fluency_cover.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2508.21669"&gt;&lt;img src="https://aliasrobotics.com/img/aihackers.jpeg" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Humanoid Robots as Attack Vectors &lt;a href="https://arxiv.org/abs/2509.14139"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14139-6bc7b5.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;The Cybersecurity of a Humanoid Robot &lt;a href="https://arxiv.org/abs/2509.14096"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2509.14096-3e8b7a.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;Evaluating Agentic Cybersecurity in Attack/Defense CTFs &lt;a href="https://arxiv.org/abs/2510.17521"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.17521-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;CAIBench: A Meta-Benchmark for Evaluating Cybersecurity AI Agents &lt;a href="https://arxiv.org/abs/2510.24317"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2510.24317-b31b1b.svg?sanitize=true" alt="arXiv" /&gt;&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2509.14139"&gt;&lt;img src="https://aliasrobotics.com/img/humanoids-cover.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2509.14096"&gt;&lt;img src="https://aliasrobotics.com/img/humanoid.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2510.17521"&gt;&lt;img src="https://aliasrobotics.com/img/cai_ad.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2510.24317"&gt;&lt;img src="https://aliasrobotics.com/img/caibench_banner2.png" width="350" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;PoCs&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on ROS message injection attacks in MiR-100 robot&lt;/th&gt; 
   &lt;th&gt;CAI with &lt;code&gt;alias0&lt;/code&gt; on API vulnerability discovery at Mercado Libre&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh"&gt;&lt;img src="https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww"&gt;&lt;img src="https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;CAI on JWT@PortSwigger CTF â€” Cybersecurity AI&lt;/th&gt; 
   &lt;th&gt;CAI on HackableII Boot2Root CTF â€” Cybersecurity AI&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713487"&gt;&lt;img src="https://asciinema.org/a/713487.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://asciinema.org/a/713485"&gt;&lt;img src="https://asciinema.org/a/713485.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More case studies and PoCs are available at &lt;a href="https://aliasrobotics.com/case-studies-robot-cybersecurity.php"&gt;https://aliasrobotics.com/case-studies-robot-cybersecurity.php&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ‘¤&lt;/span&gt; Why CAI?&lt;/h3&gt; 
&lt;p&gt;The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. &lt;strong&gt;We predict that by 2028, AI-powered security testing tools will outnumber human pentesters&lt;/strong&gt;. This shift represents a fundamental change in how we approach cybersecurity challenges. &lt;em&gt;AI is not just another tool - it's becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That's why we're releasing Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn't limited to well-funded private companies or state actors.&lt;/p&gt; 
&lt;p&gt;Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.&lt;/p&gt; 
&lt;h3&gt;Ethical principles behind CAI&lt;/h3&gt; 
&lt;p&gt;You might be wondering if releasing CAI &lt;em&gt;in-the-wild&lt;/em&gt; given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Democratizing Cybersecurity AI&lt;/strong&gt;: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transparency in AI Security Capabilities&lt;/strong&gt;: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;CAI is built on the following core principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cybersecurity oriented AI framework&lt;/strong&gt;: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open source, free for research&lt;/strong&gt;: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions &lt;a href="mailto:research@aliasrobotics.com"&gt;reach out&lt;/a&gt; to obtain a license.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: CAI is designed to be fast, and easy to use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular and agent-centric design&lt;/strong&gt;: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tool-integration&lt;/strong&gt;: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logging and tracing integrated&lt;/strong&gt;: using &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;, the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: more than 300 supported and empowered by &lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;. The most popular providers: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;: &lt;code&gt;Claude 3.7&lt;/code&gt;, &lt;code&gt;Claude 3.5&lt;/code&gt;, &lt;code&gt;Claude 3&lt;/code&gt;, &lt;code&gt;Claude 3 Opus&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: &lt;code&gt;O1&lt;/code&gt;, &lt;code&gt;O1 Mini&lt;/code&gt;, &lt;code&gt;O3 Mini&lt;/code&gt;, &lt;code&gt;GPT-4o&lt;/code&gt;, &lt;code&gt;GPT-4.5 Preview&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;code&gt;DeepSeek V3&lt;/code&gt;, &lt;code&gt;DeepSeek R1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: &lt;code&gt;Qwen2.5 72B&lt;/code&gt;, &lt;code&gt;Qwen2.5 14B&lt;/code&gt;, etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Closed-source alternatives&lt;/h3&gt; 
&lt;p&gt;Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source (&lt;em&gt;often third-party owned&lt;/em&gt;) models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.acyber.co/"&gt;Autonomous Cyber&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cracken.ai/"&gt;CrackenAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ethiack.com/"&gt;ETHIACK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://horizon3.ai/"&gt;Horizon3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.irregular.com/"&gt;Irregular&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kindo.ai/"&gt;Kindo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lakera.ai"&gt;Lakera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/www.mindfort.ai"&gt;Mindfort&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindgard.ai/"&gt;Mindgard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ndaysecurity.com/"&gt;NDAY Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://penligent.ai/"&gt;Penligent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.runsybil.com"&gt;Runsybil&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.selfhack.fi"&gt;Selfhack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sola.security/"&gt;Sola Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://squr.ai/"&gt;SQUR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staris.tech/"&gt;Staris&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sxipher.com/"&gt;Sxipher&lt;/a&gt; (seems discontinued)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.terra.security"&gt;Terra Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vibeproxy.app/"&gt;Vibeproxy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xint.io/"&gt;Xint&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.xbow.com"&gt;XBOW&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zeropath.com"&gt;ZeroPath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynap.com"&gt;Zynap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://7ai.com"&gt;7ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Learn - &lt;code&gt;CAI&lt;/code&gt; Fluency&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://github.com/aliasrobotics/CAI"&gt; &lt;img width="100%" src="https://github.com/aliasrobotics/cai/raw/main/media/caiedu.PNG" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;CAI Fluency technical report (&lt;a href="https://arxiv.org/pdf/2508.13588"&gt;arXiv:2508.13588&lt;/a&gt;) establishes formal educational frameworks for cybersecurity AI literacy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;English&lt;/th&gt; 
   &lt;th&gt;Spanish&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 0&lt;/strong&gt;: What is CAI?&lt;/td&gt; 
   &lt;td&gt;Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) explained&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=nBdTxbKM4oo"&gt;&lt;img src="https://img.youtube.com/vi/nBdTxbKM4oo/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=FaUL9HXrQ5k"&gt;&lt;img src="https://img.youtube.com/vi/FaUL9HXrQ5k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 1&lt;/strong&gt;: The &lt;code&gt;CAI&lt;/code&gt; Framework&lt;/td&gt; 
   &lt;td&gt;Vision &amp;amp; Ethics - Explore the core motivation behind CAI and delve into the crucial ethical principles guiding its development. Understand the motivation behind CAI and how you can actively contribute to the future of cybersecurity and the CAI framework.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=QEiGdsMf29M&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=3"&gt;&lt;img src="https://img.youtube.com/vi/QEiGdsMf29M/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 2&lt;/strong&gt;: From Zero to Cyber Hero&lt;/td&gt; 
   &lt;td&gt;Breaking into Cybersecurity with AI - A comprehensive guide for complete beginners to become cybersecurity practitioners using CAI and AI tools. Learn how to leverage artificial intelligence to accelerate your cybersecurity learning journey, from understanding basic security concepts to performing real-world security assessments, all without requiring prior cybersecurity experience.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=hSTLHOOcQoY&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=14"&gt;&lt;img src="https://img.youtube.com/vi/hSTLHOOcQoY/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 3&lt;/strong&gt;: Vibe-Hacking Tutorial&lt;/td&gt; 
   &lt;td&gt;"My first Hack" - A Vibe-Hacking guide for newbies. We demonstrate a simple web security hack using a default agent and show how to leverage tools and interpret CAI output with the help of the CAI Python API. You'll also learn to compare different LLM models to find the best fit for your hacking endeavors.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=9vZ_Iyex7uI&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=1"&gt;&lt;img src="https://img.youtube.com/vi/9vZ_Iyex7uI/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=iAOMaI1ftiA&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=2"&gt;&lt;img src="https://img.youtube.com/vi/iAOMaI1ftiA/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 4&lt;/strong&gt;: Intro ReAct&lt;/td&gt; 
   &lt;td&gt;The Evolution of LLMs - Learn how LLMs evolved from basic language models to advanced multiagency AI systems. From basic LLMs to Chain-of-Thought and Reasoning LLMs towards ReAct and Multi-Agent Architectures. Get to know the basic terms&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=tLdFO1flj_o&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/tLdFO1flj_o/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Episode 5&lt;/strong&gt;: CAI on CTF challenges&lt;/td&gt; 
   &lt;td&gt;Dive into Capture The Flag (CTF) competitions using CAI. Learn how to leverage AI agents to solve various cybersecurity challenges including web exploitation, cryptography, reverse engineering, and forensics. Discover how to configure CAI for competitive hacking scenarios and maximize your CTF performance with intelligent automation.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=MrXTQ0e2to4&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=13"&gt;&lt;img src="https://img.youtube.com/vi/MrXTQ0e2to4/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=r9US_JZa9_c&amp;amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;amp;index=12"&gt;&lt;img src="https://img.youtube.com/vi/r9US_JZa9_c/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 1&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.5.x release&lt;/td&gt; 
   &lt;td&gt;Introduce version 0.5 of &lt;code&gt;CAI&lt;/code&gt; including new multi-agent functionality, new commands such as &lt;code&gt;/history&lt;/code&gt;, &lt;code&gt;/compact&lt;/code&gt;, &lt;code&gt;/graph&lt;/code&gt; or &lt;code&gt;/memory&lt;/code&gt; and a case study showing how &lt;code&gt;CAI&lt;/code&gt; found a critical security flaw in OT heap pumps spread around the world.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=OPFH0ANUMMw"&gt;&lt;img src="https://img.youtube.com/vi/OPFH0ANUMMw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Q8AI4E4gH8k"&gt;&lt;img src="https://img.youtube.com/vi/Q8AI4E4gH8k/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 2&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; 0.4.x release and &lt;code&gt;alias0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Introducing version 0.4 of &lt;code&gt;CAI&lt;/code&gt; with &lt;em&gt;streaming&lt;/em&gt; and improved MCP support. We also introduce &lt;code&gt;alias0&lt;/code&gt;, the Privacy-First Cybersecurity AI, a Model-of-Models Intelligence that implements a Privacy-by-Design architecture and obtains state-of-the-art results in cybersecurity benchmarks.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=NZjzfnvAZcc"&gt;&lt;img src="https://img.youtube.com/vi/NZjzfnvAZcc/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 3&lt;/strong&gt;: Cybersecurity AI Community Meeting #1&lt;/td&gt; 
   &lt;td&gt;First Cybersecurity AI (&lt;code&gt;CAI&lt;/code&gt;) community meeting, over 40 participants from academia, industry, and defense gathered to discuss the open-source scaffolding behind CAI â€” a project designed to build agentic AI systems for cybersecurity that are open, modular, and Bug Bounty-ready.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=4JqaTiVlgsw"&gt;&lt;img src="https://img.youtube.com/vi/4JqaTiVlgsw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 4&lt;/strong&gt;: &lt;code&gt;CAI PRO&lt;/code&gt; PoC&lt;/td&gt; 
   &lt;td&gt;Short proof-of-concept demonstration of &lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;CAI PRO&lt;/a&gt; capabilities showcasing the Professional Edition with unlimited &lt;code&gt;alias1&lt;/code&gt; tokens, unrestricted AI, and enterprise-grade security testing features.&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/caipro_poc.gif" alt="CAI PRO Demo" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 5&lt;/strong&gt;: &lt;code&gt;CAI&lt;/code&gt; PoC&lt;/td&gt; 
   &lt;td&gt;Short proof-of-concept demonstration of CAI Community Edition showcasing the open-source framework's core capabilities for AI-powered security testing and vulnerability discovery.&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai_poc.gif" alt="CAI Demo" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Annex 6&lt;/strong&gt;: CAI in &lt;code&gt;Jaula del N00B&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;CAI (CIBERSEGURIDAD CON IA) LUIJAIT EN LA JAULA DEL N00B - Demonstration and discussion of CAI framework capabilities in the popular Spanish cybersecurity podcast/show.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=KD2_xzIOkWg"&gt;&lt;img src="https://img.youtube.com/vi/KD2_xzIOkWg/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Install&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;strong&gt;CAI Professional Edition Users&lt;/strong&gt;: If you have an active CAI Pro subscription, we provide dedicated installation guides for versions 0.5 and 0.6. Official support is available for Ubuntu 24.04 (x86_64). Installation instructions for other operating systems are provided as-is without official support:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/Installation_Guide_for_CAI_Pro_v0.6.md"&gt;CAI Pro v0.6 Installation Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/Installation_Guide_for_CAI_Pro_v0.5.md"&gt;CAI Pro v0.5 Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Community Edition Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install cai-framework
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Always create a new virtual environment to ensure proper dependency installation when updating CAI.&lt;/p&gt; 
&lt;p&gt;The following subsections provide a more detailed walkthrough on selected popular Operating Systems. Refer to the &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#development"&gt;Development&lt;/a&gt; section for developer-related install instructions. For API Keys env syntax check litellm Documentation. &lt;a href="https://docs.litellm.ai/docs/tutorials/installation"&gt;LiteLLM Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;OS X&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update &amp;amp;&amp;amp; \
    brew install git python@3.12

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 24.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3.12-venv

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ubuntu 20.04&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y software-properties-common

# Fetch Python 3.12
sudo add-apt-repository ppa:deadsnakes/ppa &amp;amp;&amp;amp; sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev -y

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows WSL&lt;/h3&gt; 
&lt;p&gt;Go to the Microsoft page: &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;https://learn.microsoft.com/en-us/windows/wsl/install&lt;/a&gt;. Here you will find all the instructions to install WSL&lt;/p&gt; 
&lt;p&gt;From Powershell write: wsl --install&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
sudo apt-get update &amp;amp;&amp;amp; \
    sudo apt-get install -y git python3-pip python3-venv

# Create the virtual environment
python3 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip install cai-framework

# Generate a .env file and set up with defaults. If Ollama runs on your windows host, wsl needs to use your host IP for it to become reachable
echo -e 'OPENAI_API_KEY="sk-1234"\nANTHROPIC_API_KEY=""\nOLLAMA=""\nOLLAMA_API_BASE="http://Your.Host.Ip.Here:11434"\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false' &amp;gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You might run into issues running cai on ubuntu since some agents assume they are running on a Kali Instance and are not able to find the tools needed. So as an alternative you can use the docker compose file in the dockerized folder instead. This also works from within wsl if docker is installed. in that case fetch the dockerized folder (no need for the whole repo) and run from within it. For API Keys env syntax check litellm Documentation. &lt;a href="https://docs.litellm.ai/docs/tutorials/installation"&gt;LiteLLM Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;#build and run docker compose Build takes around 20 min.
docker compose build &amp;amp;&amp;amp; docker compose up -d

#access cai
docker compose exec cai cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;We recommend having at least 8 GB of RAM:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;First of all, install userland &lt;a href="https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es"&gt;https://play.google.com/store/apps/details?id=tech.ula&amp;amp;hl=es&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install Kali minimal in basic options (for free). [Or any other kali option if preferred]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update apt keys like in this example: &lt;a href="https://superuser.com/questions/1644520/apt-get-update-issue-in-kali"&gt;https://superuser.com/questions/1644520/apt-get-update-issue-in-kali&lt;/a&gt;, inside UserLand's Kali terminal execute&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get new apt keys
wget http://http.kali.org/kali/pool/main/k/kali-archive-keyring/kali-archive-keyring_2024.1_all.deb

# Install new apt keys
sudo dpkg -i kali-archive-keyring_2024.1_all.deb &amp;amp;&amp;amp; rm kali-archive-keyring_2024.1_all.deb

# Update APT repository
sudo apt-get update

# CAI requieres python 3.12, lets install it (CAI for kali in Android)
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y git python3-pip build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev pkg-config
wget https://www.python.org/ftp/python/3.12.4/Python-3.12.4.tar.xz
tar xf Python-3.12.4.tar.xz
cd ./configure --enable-optimizations
sudo make altinstall # This command takes long to execute

# Clone CAI's source code
git clone https://github.com/aliasrobotics/cai &amp;amp;&amp;amp; cd cai

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;amp;&amp;amp; pip3 install -e .

# Generate a .env file and set up
cp .env.example .env  # edit here your keys/models

# Launch CAI
cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;span&gt;ğŸ”©&lt;/span&gt; Setup &lt;code&gt;.env&lt;/code&gt; file&lt;/h3&gt; 
&lt;p&gt;CAI leverages the &lt;code&gt;.env&lt;/code&gt; file to load configuration at launch. To facilitate the setup, the repo provides an exemplary &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file provides a template for configuring CAI's setup and your LLM API keys to work with desired LLM models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Important:&lt;/p&gt; 
&lt;p&gt;CAI does NOT provide API keys for any model by default. Don't ask us to provide keys, use your own or host your own models.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;The OPENAI_API_KEY must not be left blank. It should contain either "sk-123" (as a placeholder) or your actual API key. See &lt;a href="https://github.com/aliasrobotics/cai/issues/27"&gt;https://github.com/aliasrobotics/cai/issues/27&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;âš &lt;/span&gt; Note:&lt;/p&gt; 
&lt;p&gt;If you are using alias1 model, make sure that CAI is &amp;gt;0.4.0 version and here you have an .env example to be able to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY="sk-1234"
OLLAMA=""
ALIAS_API_KEY="&amp;lt;sk-your-key&amp;gt;"  # note, add yours
CAI_STEAM=False
CAI_MODEL="alias1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Custom OpenAI Base URL Support&lt;/h3&gt; 
&lt;p&gt;CAI supports configuring a custom OpenAI API base URL via the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; environment variable. This allows users to redirect API calls to a custom endpoint, such as a proxy or self-hosted OpenAI-compatible service.&lt;/p&gt; 
&lt;p&gt;Example &lt;code&gt;.env&lt;/code&gt; entry configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or directly from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE="https://custom-openai-proxy.com/v1" cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;span&gt;ğŸ“&lt;/span&gt; Architecture:&lt;/h2&gt; 
&lt;p&gt;CAI focuses on making cybersecurity agent &lt;strong&gt;coordination&lt;/strong&gt; and &lt;strong&gt;execution&lt;/strong&gt; lightweight, highly controllable, and useful for humans. To do so it builds upon 8 pillars: &lt;code&gt;Agents&lt;/code&gt;, &lt;code&gt;Tools&lt;/code&gt;, &lt;code&gt;Handoffs&lt;/code&gt;, &lt;code&gt;Patterns&lt;/code&gt;, &lt;code&gt;Turns&lt;/code&gt;, &lt;code&gt;Tracing&lt;/code&gt;, &lt;code&gt;Guardrails&lt;/code&gt; and &lt;code&gt;HITL&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚      HITL     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Turns   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patterns â”‚â—€â”€â”€â”€â”€â–¶â”‚  Handoffs â”‚â—€â”€â”€â”€â–¶ â”‚   Agents  â”‚â—€â”€â”€â”€â–¶â”‚    LLMs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                   â”‚
                          â”‚                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extensions â”‚â—€â”€â”€â”€â”€â–¶â”‚  Tracing  â”‚       â”‚   Tools   â”‚â—€â”€â”€â–¶â”‚ Guardrails â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â–¼             â–¼          â–¼             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ LinuxCmd  â”‚â”‚ WebSearch â”‚â”‚    Code    â”‚â”‚ SSHTunnel â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to dive deeper into the code, check the following files as a start point for using CAI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/__init__.py"&gt;&lt;strong&gt;init&lt;/strong&gt;.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/cli.py"&gt;cli.py&lt;/a&gt; - entrypoint for command line interface&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/util.py"&gt;util.py&lt;/a&gt; - utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/agents"&gt;agents&lt;/a&gt; - Agent implementations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/internal"&gt;internal&lt;/a&gt; - CAI internal functions (endpoints, metrics, logging, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/prompts"&gt;prompts&lt;/a&gt; - Agent Prompt Database&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/repl"&gt;repl&lt;/a&gt; - CLI aesthetics and commands&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/raw/main/src/cai/sdk"&gt;sdk&lt;/a&gt; - CAI command sdk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/tree/main/src/cai/tools"&gt;tools&lt;/a&gt; - agent tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”¹ Agent&lt;/h3&gt; 
&lt;p&gt;At its core, CAI abstracts its cybersecurity behavior via &lt;code&gt;Agents&lt;/code&gt; and agentic &lt;code&gt;Patterns&lt;/code&gt;. An Agent in &lt;em&gt;an intelligent system that interacts with some environment&lt;/em&gt;. More technically, within CAI we embrace a robotics-centric definition wherein an agent is anything that can be viewed as a system perceiving its environment through sensors, reasoning about its goals and and acting accordingly upon that environment through actuators (&lt;em&gt;adapted&lt;/em&gt; from Russel &amp;amp; Norvig, AI: A Modern Approach). In cybersecurity, an &lt;code&gt;Agent&lt;/code&gt; interacts with systems and networks, using peripherals and network interfaces as sensors, reasons accordingly and then executes network actions as if actuators. Correspondingly, in CAI, &lt;code&gt;Agent&lt;/code&gt;s implement the &lt;code&gt;ReACT&lt;/code&gt; (Reasoning and Action) agent model[^3]. For more information, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/hello_world.py"&gt;example here&lt;/a&gt; for the full execution code, and refer to this &lt;a href="https://github.com/aliasrobotics/cai/raw/main/fluency/my-first-hack/my_first_hack.ipynb"&gt;jupyter notebook&lt;/a&gt; for a tutorial on how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Tools&lt;/code&gt; let cybersecurity agents take actions by providing interfaces to execute system commands, run security scans, analyze vulnerabilities, and interact with target systems and APIs - they are the core capabilities that enable CAI agents to perform security tasks effectively; in CAI, tools include built-in cybersecurity utilities (like LinuxCmd for command execution, WebSearch for OSINT gathering, Code for dynamic script execution, and SSHTunnel for secure remote access), function calling mechanisms that allow integration of any Python function as a security tool, and agent-as-tool functionality that enables specialized security agents (such as reconnaissance or exploit agents) to be used by other agents, creating powerful collaborative security workflows without requiring formal handoffs between agents. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/basic/tools.py"&gt;example here&lt;/a&gt; for the complete configuration of custom functions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import Agent, Runner, OpenAIChatCompletionsModel
from cai.tools.reconnaissance.exec_code import execute_code
from cai.tools.reconnaissance.generic_linux_command import generic_linux_command

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

agent = Agent(
      name="Custom Agent",
      instructions="""You are a Cybersecurity expert Leader""",
      tools= [
        generic_linux_command,
        execute_code
      ],
      model=OpenAIChatCompletionsModel(
          model=os.getenv('CAI_MODEL', "openai/gpt-4o"),
          openai_client=AsyncOpenAI(),
          )
      )

message = "Tell me about recursion in programming."
result = await Runner.run(agent, message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may find different &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/tools"&gt;tools&lt;/a&gt;. They are grouped in 6 major categories inspired by the security kill chain [^2]:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Reconnaissance and weaponization - &lt;em&gt;reconnaissance&lt;/em&gt; (crypto, listing, etc)&lt;/li&gt; 
 &lt;li&gt;Exploitation - &lt;em&gt;exploitation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Privilege escalation - &lt;em&gt;escalation&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Lateral movement - &lt;em&gt;lateral&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Data exfiltration - &lt;em&gt;exfiltration&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Command and control - &lt;em&gt;control&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ”¹ Handoffs&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Handoffs&lt;/code&gt; allow an &lt;code&gt;Agent&lt;/code&gt; to delegate tasks to another agent, which is crucial in cybersecurity operations where specialized expertise is needed for different phases of an engagement. In our framework, &lt;code&gt;Handoffs&lt;/code&gt; are implemented as tools for the LLM, where a &lt;strong&gt;handoff/transfer function&lt;/strong&gt; like &lt;code&gt;transfer_to_flag_discriminator&lt;/code&gt; enables the &lt;code&gt;ctf_agent&lt;/code&gt; to pass control to the &lt;code&gt;flag_discriminator_agent&lt;/code&gt; once it believes it has found the flag. This creates a security validation chain where the first agent handles exploitation and flag discovery, while the second agent specializes in flag verification, ensuring proper segregation of duties and leveraging specialized capabilities of different models for distinct security tasks. For more information, please refer to the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/cai/agent_patterns/handoffs.py"&gt;example here&lt;/a&gt; for the full execution code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from cai.sdk.agents import function_tool
from cai.tools.common import run_command
from cai.sdk.agents import Agent, OpenAIChatCompletionsModel, HandoffInputData, Runner, function_tool, handoff, trace
from cai.sdk.agents.extensions import handoff_filters

import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()

@function_tool
def execute_cli_command(command: str) -&amp;gt; str:
    return run_command(command)

flag_discriminator = Agent(
    name="Flag discriminator",
    description="Agent focused on extracting the flag from the output",
    instructions="You are an agent tailored to extract the flag from a given output.",
    model=OpenAIChatCompletionsModel(
        model=os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ) 
)

ctf_agent = Agent(
    name="CTF agent",
    description="Agent focused on conquering security challenges",
    instructions="You are a Cybersecurity expert Leader facing a CTF",
    tools=[
        execute_cli_command,
    ],
    model=OpenAIChatCompletionsModel(
        model= os.getenv('CAI_MODEL', "qwen2.5:14b"),
        openai_client=AsyncOpenAI(),
    ), 
    handoffs = [flag_discriminator]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”¹ Patterns&lt;/h3&gt; 
&lt;p&gt;An agentic &lt;code&gt;Pattern&lt;/code&gt; is a &lt;em&gt;structured design paradigm&lt;/em&gt; in artificial intelligence systems where autonomous or semi-autonomous agents operate within a defined &lt;em&gt;interaction framework&lt;/em&gt; (the pattern) to achieve a goal. These &lt;code&gt;Patterns&lt;/code&gt; specify the organization, coordination, and communication methods among agents, guiding decision-making, task execution, and delegation.&lt;/p&gt; 
&lt;p&gt;An agentic pattern (&lt;code&gt;AP&lt;/code&gt;) can be formally defined as a tuple:&lt;/p&gt; 
&lt;p&gt;\[ AP = (A, H, D, C, E) \]&lt;/p&gt; 
&lt;p&gt;wherein:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;\(A\) (Agents):&lt;/strong&gt; A set of autonomous entities, \( A = \{a_1, a_2, ..., a_n\} \), each with defined roles, capabilities, and internal states.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(H\) (Handoffs):&lt;/strong&gt; A function \( H: A \times T \to A \) that governs how tasks \( T \) are transferred between agents based on predefined logic (e.g., rules, negotiation, bidding).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(D\) (Decision Mechanism):&lt;/strong&gt; A decision function \( D: S \to A \) where \( S \) represents system states, and \( D \) determines which agent takes action at any given time.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(C\) (Communication Protocol):&lt;/strong&gt; A messaging function \( C: A \times A \to M \), where \( M \) is a message space, defining how agents share information.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;\(E\) (Execution Model):&lt;/strong&gt; A function \( E: A \times I \to O \) where \( I \) is the input space and \( O \) is the output space, defining how agents perform tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When building &lt;code&gt;Patterns&lt;/code&gt;, we generall y classify them among one of the following categories, though others exist:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Agentic&lt;/strong&gt; &lt;code&gt;Pattern&lt;/code&gt; &lt;strong&gt;categories&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Swarm&lt;/code&gt; (Decentralized)&lt;/td&gt; 
   &lt;td&gt;Agents share tasks and self-assign responsibilities without a central orchestrator. Handoffs occur dynamically. &lt;em&gt;An example of a peer-to-peer agentic pattern is the &lt;code&gt;CTF Agentic Pattern&lt;/code&gt;, which involves a team of agents working together to solve a CTF challenge with dynamic handoffs.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Hierarchical&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A top-level agent (e.g., "PlannerAgent") assigns tasks via structured handoffs to specialized sub-agents. Alternatively, the structure of the agents is harcoded into the agentic pattern with pre-defined handoffs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Chain-of-Thought&lt;/code&gt; (Sequential Workflow)&lt;/td&gt; 
   &lt;td&gt;A structured pipeline where Agent A produces an output, hands it to Agent B for reuse or refinement, and so on. Handoffs follow a linear sequence. &lt;em&gt;An example of a chain-of-thought agentic pattern is the &lt;code&gt;ReasonerAgent&lt;/code&gt;, which involves a Reasoning-type LLM that provides context to the main agent to solve a CTF challenge with a linear sequence.&lt;/em&gt;[^1]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Auction-Based&lt;/code&gt; (Competitive Allocation)&lt;/td&gt; 
   &lt;td&gt;Agents "bid" on tasks based on priority, capability, or cost. A decision agent evaluates bids and hands off tasks to the best-fit agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Recursive&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;A single agent continuously refines its own output, treating itself as both executor and evaluator, with handoffs (internal or external) to itself. &lt;em&gt;An example of a recursive agentic pattern is the &lt;code&gt;CodeAgent&lt;/code&gt; (when used as a recursive agent), which continuously refines its own output by executing code and updating its own instructions.&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For more information and examples of common agentic patterns, see the &lt;a href="https://github.com/aliasrobotics/cai/raw/main/examples/agent_patterns/README.md"&gt;examples folder&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Turns and Interactions&lt;/h3&gt; 
&lt;p&gt;During the agentic flow (conversation), we distinguish between &lt;strong&gt;interactions&lt;/strong&gt; and &lt;strong&gt;turns&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Interactions&lt;/strong&gt; are sequential exchanges between one or multiple agents. Each agent executing its logic corresponds with one &lt;em&gt;interaction&lt;/em&gt;. Since an &lt;code&gt;Agent&lt;/code&gt; in CAI generally implements the &lt;code&gt;ReACT&lt;/code&gt; agent model[^3], each &lt;em&gt;interaction&lt;/em&gt; consists of 1) a reasoning step via an LLM inference and 2) act by calling zero-to-n &lt;code&gt;Tools&lt;/code&gt;. This is defined in&lt;code&gt;process_interaction()&lt;/code&gt; in &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Turns&lt;/strong&gt;: A turn represents a cycle of one ore more &lt;strong&gt;interactions&lt;/strong&gt; which finishes when the &lt;code&gt;Agent&lt;/code&gt; (or &lt;code&gt;Pattern&lt;/code&gt;) executing returns &lt;code&gt;None&lt;/code&gt;, judging there're no further actions to undertake. This is defined in &lt;code&gt;run()&lt;/code&gt;, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] CAI Agents are not related to Assistants in the Assistants API. They are named similarly for convenience, but are otherwise completely unrelated. CAI is entirely powered by the Chat Completions API and is hence stateless between calls.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ”¹ Tracing&lt;/h3&gt; 
&lt;p&gt;CAI implements AI observability by adopting the OpenTelemetry standard and to do so, it leverages &lt;a href="https://github.com/Arize-ai/phoenix"&gt;Phoenix&lt;/a&gt; which provides comprehensive tracing capabilities through OpenTelemetry-based instrumentation, allowing you to monitor and analyze your security operations in real-time. This integration enables detailed visibility into agent interactions, tool usage, and attack vectors throughout penetration testing workflows, making it easier to debug complex exploitation chains, track vulnerability discovery processes, and optimize agent performance for more effective security assessments.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/tracing.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Guardrails&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;Guardrails&lt;/code&gt; provide a critical security layer for CAI agents, protecting against prompt injection attacks and preventing execution of dangerous commands. These guardrails run in parallel to agents, validating both input and output to ensure safe operation. The framework includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Input Guardrails&lt;/strong&gt;: Detect and block prompt injection attempts before they reach agents, using pattern matching, Unicode homograph detection, and AI-powered analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Output Guardrails&lt;/strong&gt;: Validate agent outputs before execution, preventing dangerous commands like reverse shells, fork bombs, or data exfiltration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-layered Defense&lt;/strong&gt;: Protection at input, processing, and execution stages with tool-level validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Base64/Base32 Aware&lt;/strong&gt;: Automatically decodes and analyzes encoded payloads to detect hidden malicious commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable&lt;/strong&gt;: Can be enabled/disabled via &lt;code&gt;CAI_GUARDRAILS&lt;/code&gt; environment variable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed implementation, see &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/guardrails.md"&gt;docs/guardrails.md&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/docs/cai_prompt_injection.md"&gt;docs/cai_prompt_injection.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ”¹ Human-In-The-Loop (HITL)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                                 â”‚
                      â”‚      Cybersecurity AI (CAI)     â”‚
                      â”‚                                 â”‚
                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                      â”‚       â”‚  Autonomous AI  â”‚       â”‚
                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                      â”‚                â”‚                â”‚
                      â”‚                â”‚                â”‚
                      â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
                      â”‚       â”‚ HITL Interaction â”‚      â”‚
                      â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                      â”‚                â”‚                â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ Ctrl+C (cli.py)
                                       â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Human Operator(s)   â”‚
                           â”‚  Expertise | Judgment â”‚
                           â”‚    Teleoperation      â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CAI delivers a framework for building Cybersecurity AIs with a strong emphasis on &lt;em&gt;semi-autonomous&lt;/em&gt; operation, as the reality is that &lt;strong&gt;fully-autonomous&lt;/strong&gt; cybersecurity systems remain premature and face significant challenges when tackling complex tasks. While CAI explores autonomous capabilities, we recognize that effective security operations still require human teleoperation providing expertise, judgment, and oversight in the security process.&lt;/p&gt; 
&lt;p&gt;Accordingly, the Human-In-The-Loop (&lt;code&gt;HITL&lt;/code&gt;) module is a core design principle of CAI, acknowledging that human intervention and teleoperation are essential components of responsible security testing. Through the &lt;code&gt;cli.py&lt;/code&gt; interface, users can seamlessly interact with agents at any point during execution by simply pressing &lt;code&gt;Ctrl+C&lt;/code&gt;. This is implemented across &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/core.py"&gt;core.py&lt;/a&gt; and also in the REPL abstractions &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl"&gt;REPL&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;ğŸš€&lt;/span&gt; Quickstart&lt;/h2&gt; 
&lt;p&gt;To start CAI after installing it, just type &lt;code&gt;cai&lt;/code&gt; in the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;â””â”€# cai

          CCCCCCCCCCCCC      ++++++++   ++++++++      IIIIIIIIII
       CCC::::::::::::C  ++++++++++       ++++++++++  I::::::::I
     CC:::::::::::::::C ++++++++++         ++++++++++ I::::::::I
    C:::::CCCCCCCC::::C +++++++++    ++     +++++++++ II::::::II
   C:::::C       CCCCCC +++++++     +++++     +++++++   I::::I
  C:::::C                +++++     +++++++     +++++    I::::I
  C:::::C                ++++                   ++++    I::::I
  C:::::C                 ++                     ++     I::::I
  C:::::C                  +   +++++++++++++++   +      I::::I
  C:::::C                    +++++++++++++++++++        I::::I
  C:::::C                     +++++++++++++++++         I::::I
   C:::::C       CCCCCC        +++++++++++++++          I::::I
    C:::::CCCCCCCC::::C         +++++++++++++         II::::::II
     CC:::::::::::::::C           +++++++++           I::::::::I
       CCC::::::::::::C             +++++             I::::::::I
          CCCCCCCCCCCCC               ++              IIIIIIIIII

                      Cybersecurity AI (CAI), vX.Y.Z
                          Bug bounty-ready AI

CAI&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That should initialize CAI and provide a prompt to execute any security task you want to perform. The navigation bar at the bottom displays important system information. This information helps you understand your environment while working with CAI.&lt;/p&gt; 
&lt;p&gt;Here's a quick &lt;a href="https://asciinema.org/a/zm7wS5DA2o0S9pu1Tb44pnlvy"&gt;demo video&lt;/a&gt; to help you get started with CAI. We'll walk through the basic steps â€” from launching the tool to running your first AI-powered task in the terminal. Whether you're a beginner or just curious, this guide will show you how easy it is to begin using CAI.&lt;/p&gt; 
&lt;p&gt;From here on, type on &lt;code&gt;CAI&lt;/code&gt; and start your security exercise. Best way to learn is by example:&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;For using private models, you are given a &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/.env.example"&gt;&lt;code&gt;.env.example&lt;/code&gt;&lt;/a&gt; file. Copy it and rename it as &lt;code&gt;.env&lt;/code&gt;. Fill in your corresponding API keys, and you are ready to use CAI.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;List of Environment Variables&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Variable&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_NAME&lt;/td&gt; 
    &lt;td&gt;Name of the CTF challenge to run (e.g. "picoctf_static_flag")&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_CHALLENGE&lt;/td&gt; 
    &lt;td&gt;Specific challenge name within the CTF to test&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_SUBNET&lt;/td&gt; 
    &lt;td&gt;Network subnet for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_IP&lt;/td&gt; 
    &lt;td&gt;IP address for the CTF container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CTF_INSIDE&lt;/td&gt; 
    &lt;td&gt;Whether to conquer the CTF from within container&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for agents&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_DEBUG&lt;/td&gt; 
    &lt;td&gt;Set debug output level (0: Only tool outputs, 1: Verbose debug output, 2: CLI debug output)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_BRIEF&lt;/td&gt; 
    &lt;td&gt;Enable/disable brief output mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MAX_TURNS&lt;/td&gt; 
    &lt;td&gt;Maximum number of turns for agent interactions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_TRACING&lt;/td&gt; 
    &lt;td&gt;Enable/disable OpenTelemetry tracing&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_AGENT_TYPE&lt;/td&gt; 
    &lt;td&gt;Specify the agents to use (boot2root, one_tool...)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_STATE&lt;/td&gt; 
    &lt;td&gt;Enable/disable stateful mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY&lt;/td&gt; 
    &lt;td&gt;Enable/disable memory mode (episodic, semantic, all)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable online memory mode&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_OFFLINE&lt;/td&gt; 
    &lt;td&gt;Enable/disable offline memory&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_ENV_CONTEXT&lt;/td&gt; 
    &lt;td&gt;Add dirs and current env to llm context&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_MEMORY_ONLINE_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between online memory updates&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_PRICE_LIMIT&lt;/td&gt; 
    &lt;td&gt;Price limit for the conversation in dollars&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_REPORT&lt;/td&gt; 
    &lt;td&gt;Enable/disable reporter mode (ctf, nis2, pentesting)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_MODEL&lt;/td&gt; 
    &lt;td&gt;Model to use for the support agent&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_SUPPORT_INTERVAL&lt;/td&gt; 
    &lt;td&gt;Number of turns between support agent executions&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE&lt;/td&gt; 
    &lt;td&gt;Defines the name of the workspace&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_WORKSPACE_DIR&lt;/td&gt; 
    &lt;td&gt;Specifies the directory path where the workspace is located&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CAI_GUARDRAILS&lt;/td&gt; 
    &lt;td&gt;Enable/disable guardrails for prompt injection protection (default: true)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;OpenRouter Integration&lt;/h3&gt; 
&lt;p&gt;The Cybersecurity AI (CAI) platform offers seamless integration with OpenRouter, a unified interface for Large Language Models (LLMs). This integration is crucial for users who wish to leverage advanced AI capabilities in their cybersecurity tasks. OpenRouter acts as a bridge, allowing CAI to communicate with various LLMs, thereby enhancing the flexibility and power of the AI agents used within CAI.&lt;/p&gt; 
&lt;p&gt;To enable OpenRouter support in CAI, you need to configure your environment by adding specific entries to your &lt;code&gt;.env&lt;/code&gt; file. This setup ensures that CAI can interact with the OpenRouter API, facilitating the use of sophisticated models like Meta-LLaMA. Hereâ€™s how you can configure it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_AGENT_TYPE=redteam_agent
CAI_MODEL=openrouter/meta-llama/llama-4-maverick
OPENROUTER_API_KEY=&amp;lt;sk-your-key&amp;gt;  # note, add yours
OPENROUTER_API_BASE=https://openrouter.ai/api/v1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Azure OpenAI&lt;/h3&gt; 
&lt;p&gt;The Cybersecurity AI (CAI) platform integrates seamlessly with Azure OpenAI, enabling organizations to run CAI against enterprise-hosted models (e.g., gpt-4o). This pathway is ideal for teams that must operate within Azure governance while leveraging advanced model capabilities. To enable Azure OpenAI support in CAI, configure your environment by adding the following entries to your .env. This ensures CAI can reach your Azure deployment endpoint and authenticate correctly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_AGENT_TYPE=redteam_agent
CAI_MODEL=azure/&amp;lt;model-name-deployed&amp;gt;
# Required: keep non-empty even when using Azure
OPENAI_API_KEY=dummy
# Azure credentials and endpoint
AZURE_API_KEY=&amp;lt;your-azure-openai-key&amp;gt;
AZURE_API_BASE=https://&amp;lt;resource&amp;gt;.openai.azure.com/openai/deployments/&amp;lt;deployment-name&amp;gt;/chat/completions?api-version=2025-01-01-preview
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP&lt;/h3&gt; 
&lt;p&gt;CAI supports the Model Context Protocol (MCP) for integrating external tools and services with AI agents. MCP is supported via two transport mechanisms:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;SSE (Server-Sent Events)&lt;/strong&gt; - For web-based servers that push updates over HTTP connections:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load http://localhost:9876/sse burp
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;STDIO (Standard Input/Output)&lt;/strong&gt; - For local inter-process communication:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp load stdio myserver python mcp_server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once connected, you can add the MCP tools to any agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp add burp redteam_agent
Adding tools from MCP server 'burp' to agent 'Red Team Agent'...
                                 Adding tools to Red Team Agent
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Tool                              â”ƒ Status â”ƒ Details                                         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ send_http_request                 â”‚ Added  â”‚ Available as: send_http_request                 â”‚
â”‚ create_repeater_tab               â”‚ Added  â”‚ Available as: create_repeater_tab               â”‚
â”‚ send_to_intruder                  â”‚ Added  â”‚ Available as: send_to_intruder                  â”‚
â”‚ url_encode                        â”‚ Added  â”‚ Available as: url_encode                        â”‚
â”‚ url_decode                        â”‚ Added  â”‚ Available as: url_decode                        â”‚
â”‚ base64encode                      â”‚ Added  â”‚ Available as: base64encode                      â”‚
â”‚ base64decode                      â”‚ Added  â”‚ Available as: base64decode                      â”‚
â”‚ generate_random_string            â”‚ Added  â”‚ Available as: generate_random_string            â”‚
â”‚ output_project_options            â”‚ Added  â”‚ Available as: output_project_options            â”‚
â”‚ output_user_options               â”‚ Added  â”‚ Available as: output_user_options               â”‚
â”‚ set_project_options               â”‚ Added  â”‚ Available as: set_project_options               â”‚
â”‚ set_user_options                  â”‚ Added  â”‚ Available as: set_user_options                  â”‚
â”‚ get_proxy_http_history            â”‚ Added  â”‚ Available as: get_proxy_http_history            â”‚
â”‚ get_proxy_http_history_regex      â”‚ Added  â”‚ Available as: get_proxy_http_history_regex      â”‚
â”‚ get_proxy_websocket_history       â”‚ Added  â”‚ Available as: get_proxy_websocket_history       â”‚
â”‚ get_proxy_websocket_history_regex â”‚ Added  â”‚ Available as: get_proxy_websocket_history_regex â”‚
â”‚ set_task_execution_engine_state   â”‚ Added  â”‚ Available as: set_task_execution_engine_state   â”‚
â”‚ set_proxy_intercept_state         â”‚ Added  â”‚ Available as: set_proxy_intercept_state         â”‚
â”‚ get_active_editor_contents        â”‚ Added  â”‚ Available as: get_active_editor_contents        â”‚
â”‚ set_active_editor_contents        â”‚ Added  â”‚ Available as: set_active_editor_contents        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Added 20 tools from server 'burp' to agent 'Red Team Agent'.
CAI&amp;gt;/agent 13
CAI&amp;gt;Create a repeater tab
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can list all active MCP connections and their transport types:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/mcp list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f"&gt;https://github.com/user-attachments/assets/386a1fd3-3469-4f84-9396-2a5236febe1f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Development is facilitated via VS Code dev. environments. To try out our development environment, clone the repository, open VS Code and enter de dev. container mode:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/media/cai_devenv.gif" alt="CAI Development Environment" /&gt;&lt;/p&gt; 
&lt;h3&gt;Contributions&lt;/h3&gt; 
&lt;p&gt;If you want to contribute to this project, use &lt;a href="https://pre-commit.com/"&gt;&lt;strong&gt;Pre-commit&lt;/strong&gt;&lt;/a&gt; before your MR&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pre-commit
pre-commit # files staged
pre-commit run --all-files # all files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Requirements: caiextensions&lt;/h3&gt; 
&lt;p&gt;Currently, the extensions are not publicly available as the engineering endeavour to maintain them is significant. Instead, we're making selected custom caiextensions available for partner companies across collaborations.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;â„¹&lt;/span&gt; Usage Data Collection&lt;/h3&gt; 
&lt;p&gt;CAI is provided free of charge for researchers. To improve CAIâ€™s detection accuracy and publish open security research, instead of payment for research use cases, we ask you to contribute to the CAI community by allowing usage data collection. This data helps us identify areas for improvement, understand how the framework is being used, and prioritize new features. Legal basis of data collection is under Art. 6 (1)(f) GDPR â€” CAIâ€™s legitimate interest in maintaining and improving security tooling, with Art. 89 safeguards for research. The collected data includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic system information (OS type, Python version)&lt;/li&gt; 
 &lt;li&gt;Username and IP information&lt;/li&gt; 
 &lt;li&gt;Tool usage patterns and performance metrics&lt;/li&gt; 
 &lt;li&gt;Model interactions and token usage statistics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We take your privacy seriously and only collect what's needed to make CAI better. For further info, reach out to researchï¼ aliasrobotics.com. You can disable some of the data collection features via the &lt;code&gt;CAI_TELEMETRY&lt;/code&gt; environment variable but we encourage you to keep it enabled and contribute back to research:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CAI_TELEMETRY=False cai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproduce CI-Setup locally&lt;/h3&gt; 
&lt;p&gt;To simulate the CI/CD pipeline, you can run the following in the Gitlab runner machines:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it \
  --privileged \
  --network=exploitflow_net \
  --add-host="host.docker.internal:host-gateway" \
  -v /cache:/cache \
  -v /var/run/docker.sock:/var/run/docker.sock:rw \
  registry.gitlab.com/aliasrobotics/alias_research/cai:latest bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt;
 &lt;summary&gt;OLLAMA is giving me 404 errors&lt;/summary&gt; 
 &lt;p&gt;Ollama's API in OpenAI mode uses &lt;code&gt;/v1/chat/completions&lt;/code&gt; whereas the &lt;code&gt;openai&lt;/code&gt; library uses &lt;code&gt;base_url&lt;/code&gt; + &lt;code&gt;/chat/completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;We adopt the latter for overall alignment with the gen AI community and empower the former by allowing users to add the &lt;code&gt;v1&lt;/code&gt; themselves via:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_API_BASE=http://IP:PORT/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See the following issues that treat this topic in more detail:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/76"&gt;https://github.com/aliasrobotics/cai/issues/76&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/83"&gt;https://github.com/aliasrobotics/cai/issues/83&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aliasrobotics/cai/issues/82"&gt;https://github.com/aliasrobotics/cai/issues/82&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Where are all the caiextensions?&lt;/summary&gt; 
 &lt;p&gt;See &lt;a href="https://gitlab.com/aliasrobotics/alias_research/caiextensions"&gt;all caiextensions&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I install the report caiextension?&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/#optional-requirements-caiextensions"&gt;See here&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I set up SSH access for Gitlab?&lt;/summary&gt; 
 &lt;p&gt;Generate a new SSH key&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-keygen -t ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the key to the SSH agent&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh-add ~/.ssh/id_ed25519
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Add the public key to Gitlab Copy the key and add it to Gitlab under &lt;a href="https://gitlab.com/-/user_settings/ssh_keys"&gt;https://gitlab.com/-/user_settings/ssh_keys&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cat ~/.ssh/id_ed25519.pub
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To verify it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;ssh -T git@gitlab.com
Welcome to GitLab, @vmayoral!
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How do I clear Python cache?&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;find . -name "*.pyc" -delete &amp;amp;&amp;amp; find . -name "__pycache__" -delete
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;If host networking is not working with ollama check whether it has been disabled in Docker because you are not signed in&lt;/summary&gt; 
 &lt;p&gt;Docker in OS X behaves funny sometimes. Check if the following message has shown up:&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Host networking has been disabled because you are not signed in. Please sign in to enable it&lt;/em&gt;.&lt;/p&gt; 
 &lt;p&gt;Make sure this has been addressed and also that the Dev Container is not forwarding the 8000 port (click on x, if necessary in the ports section).&lt;/p&gt; 
 &lt;p&gt;To verify connection, from within the VSCode devcontainer:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -v http://host.docker.internal:8000/api/version
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Run CAI against any target&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-004-first-message.png" alt="cai-004-first-message" /&gt;&lt;/p&gt; 
 &lt;p&gt;The starting user prompt in this case is: &lt;code&gt;Target IP: 192.168.3.10, perform a full network scan&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;The agent started performing a nmap scan. You could either interact with the agent and give it more instructions, or let it run to see what it explores next.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I interact with the agent? Type twice CTRL + C &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-005-ctrl-c.png" alt="cai-005-ctrl-c" /&gt;&lt;/p&gt; 
 &lt;p&gt;If you want to use the HITL mode, you can do it by presssing twice &lt;code&gt;Ctrl + C&lt;/code&gt;. This will allow you to interact (prompt) with the agent whenever you want. The agent will not lose the previous context, as it is stored in the &lt;code&gt;history&lt;/code&gt; variable, which is passed to it and any agent that is called. This enables any agent to use the previous information and be more accurate and efficient.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Can I change the model while CAI is running? /model &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/model&lt;/code&gt; to change the model.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-007-model-change.png" alt="cai-007-model-change" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I list all the agents available? /agent &lt;/summary&gt; 
 &lt;p&gt;Use &lt;code&gt;/agent&lt;/code&gt; to list all the agents available.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-010-agents-menu.png" alt="cai-010-agents-menu" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; Where can I list all the environment variables? /config &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-008-config.png" alt="cai-008-config" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; How can I monitor context usage and token consumption? /context or /ctx ğŸš€ CAI PRO &lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;âš¡ CAI PRO Exclusive Feature&lt;/strong&gt; The &lt;code&gt;/context&lt;/code&gt; command is available exclusively in &lt;strong&gt;&lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;CAI PRO&lt;/a&gt;&lt;/strong&gt;. To access this feature and unlock advanced monitoring capabilities, visit &lt;a href="https://aliasrobotics.com/cybersecurityai.php"&gt;Alias Robotics&lt;/a&gt; for more information.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;Use &lt;code&gt;/context&lt;/code&gt; (or the short form &lt;code&gt;/ctx&lt;/code&gt;) to view your current context window usage and token statistics.&lt;/p&gt; 
 &lt;p&gt;This command displays:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Total context usage (used tokens / max tokens) with percentage&lt;/li&gt; 
  &lt;li&gt;Visual grid representation with the CAI logo showing filled context&lt;/li&gt; 
  &lt;li&gt;Detailed breakdown by category: 
   &lt;ul&gt; 
    &lt;li&gt;System prompt tokens&lt;/li&gt; 
    &lt;li&gt;Tool definitions tokens&lt;/li&gt; 
    &lt;li&gt;Memory/RAG tokens&lt;/li&gt; 
    &lt;li&gt;User prompts tokens&lt;/li&gt; 
    &lt;li&gt;Assistant responses tokens&lt;/li&gt; 
    &lt;li&gt;Tool calls tokens&lt;/li&gt; 
    &lt;li&gt;Tool results tokens&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Free space available&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Why this matters&lt;/strong&gt;: Different models have different context limits (e.g., GPT-4: 128k tokens, Claude: 200k tokens). Monitoring your context usage helps you avoid hitting these limits during long conversations, which could cause errors or require conversation truncation.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Show context usage
/context

# Or use the short form
/ctx
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt; How to know more about the CLI? /help &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-006-help.png" alt="cai-006-help" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How can I trace the whole execution?&lt;/summary&gt; The environment variable `CAI_TRACING` allows the user to set it to `CAI_TRACING=true` to enable tracing, or `CAI_TRACING=false` to disable it. When CAI is prompted by the first time, the user is provided with two paths, the execution log, and the tracing log. 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using previous run logs?&lt;/summary&gt; 
 &lt;p&gt;Yes. Today CAI performs best by relying on Inâ€‘Context Learning (ICL). Rather than building longâ€‘term stores, the recommended workflow is to load relevant prior logs directly into the current session so the model can reason with them in context.&lt;/p&gt; 
 &lt;p&gt;Use the &lt;code&gt;/load&lt;/code&gt; command to bring JSONL logs into CAIâ€™s context (this replaces the legacy memory-loading tool):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;CAI&amp;gt;/load logs/cai_20250408_111856.jsonl         # Load into current agent
CAI&amp;gt;/load &amp;lt;file&amp;gt; agent &amp;lt;name&amp;gt;                    # Load into a specific agent
CAI&amp;gt;/load &amp;lt;file&amp;gt; all                             # Distribute across all agents
CAI&amp;gt;/load &amp;lt;file&amp;gt; parallel                        # Match to configured parallel agents
# Tip: if you omit &amp;lt;file&amp;gt;, /load uses `logs/last`. Alias: /l
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;CAI prints the path to the current runâ€™s JSONL log at startup (highlighted in orange), which you can pass to &lt;code&gt;/load&lt;/code&gt;:&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aliasrobotics/cai/main/imgs/readme_imgs/cai-009-logs.png" alt="cai-009-logs" /&gt;&lt;/p&gt; 
 &lt;p&gt;Legacy notes: earlier â€œmemory extensionâ€ mechanisms (episodic/semantic stores and offline ingestion) are retained for reference only. See &lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/src/cai/agents/memory.py"&gt;src/cai/agents/memory.py&lt;/a&gt; for background and legacy details. Our current direction prioritizes ICL over persistent memory.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Can I expand CAI capabilities using scripts or extra information?&lt;/summary&gt; 
 &lt;p&gt;Currently, CAI supports text based information. You can add any extra information on the target you are facing by copy-pasting it directly into the system or user prompt.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; By adding it to the system (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/system_master_template.md"&gt;&lt;code&gt;system_master_template.md&lt;/code&gt;&lt;/a&gt;) or the user prompt (&lt;a href="https://raw.githubusercontent.com/aliasrobotics/cai/main/cai/repl/templates/user_master_template.md"&gt;&lt;code&gt;user_master_template.md&lt;/code&gt;&lt;/a&gt;). You can always directly prompt the path to the model, and it will &lt;code&gt;cat&lt;/code&gt; it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;How CAI licence works?&lt;/summary&gt; 
 &lt;p&gt;CAIâ€™s current license does not restrict usage for research purposes. You are free to use CAI for security assessments (pentests), to develop additional features, and to integrate it into your research activities, as long as you comply with local laws.&lt;/p&gt; 
 &lt;p&gt;If you or your organization start benefiting commercially from CAI (e.g., offering pentesting services powered by CAI), then a commercial license will be required to help sustain the project.&lt;/p&gt; 
 &lt;p&gt;CAI itself is not a profit-seeking initiative. Our goal is to build a sustainable open-source project. We simply ask that those who profit from CAI contribute back and support our ongoing development.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;I get a `Unable to locate package python3.12-venv` when installing the prerequisites on my debian based system!&lt;/summary&gt; 
 &lt;p&gt;The easiest way to get around this is to simply install &lt;a href="https://www.python.org/downloads/release/python-3120/"&gt;&lt;code&gt;python3.12&lt;/code&gt;&lt;/a&gt; from source.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want to cite our work, please use the following (ordered by publication date):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{mayoral2025cai,
  title={CAI: An Open, Bug Bounty-Ready Cybersecurity AI},
  author={Mayoral-Vilches, V{\'\i}ctor and Navarrete-Lozano, Luis Javier and Sanz-G{\'o}mez, Mar{\'\i}a and Espejo, Lidia Salas and Crespo-{\'A}lvarez, Marti{\~n}o and Oca-Gonzalez, Francisco and Balassone, Francesco and Glera-Pic{\'o}n, Alfonso and Ayucar-Carbajo, Unai and Ruiz-Alcalde, Jon Ander and Rass, Stefan and Pinzger, Martin and Gil-Uriarte, Endika},
  journal={arXiv preprint arXiv:2504.06017},
  year={2025}
}

@article{mayoral2025automation,
  title={Cybersecurity AI: The Dangerous Gap Between Automation and Autonomy},
  author={Mayoral-Vilches, V{\'\i}ctor},
  journal={arXiv preprint arXiv:2506.23592},
  year={2025}
}

@article{mayoral2025fluency,
  title={CAI Fluency: A Framework for Cybersecurity AI Fluency},
  author={Mayoral-Vilches, V{\'\i}ctor and Wachter, Jasmin and Chavez, Crist{\'o}bal RJ and Schachner, Cathrin and Navarrete-Lozano, Luis Javier and Sanz-G{\'o}mez, Mar{\'\i}a},
  journal={arXiv preprint arXiv:2508.13588},
  year={2025}
}

@article{mayoral2025hacking,
  title={Cybersecurity AI: Hacking the AI Hackers via Prompt Injection},
  author={Mayoral-Vilches, V{\'\i}ctor and Rynning, Per Mannermaa},
  journal={arXiv preprint arXiv:2508.21669},
  year={2025}
}

@article{mayoral2025humanoid,
  title={Cybersecurity AI: Humanoid Robots as Attack Vectors},
  author={Mayoral-Vilches, V{\'\i}ctor},
  journal={arXiv preprint arXiv:2509.14139},
  year={2025}
}

@article{balassone2025evaluation,
  title={Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs},
  author={Balassone, Francesco and Mayoral-Vilches, V{\'\i}ctor and Rass, Stefan and Pinzger, Martin and Perrone, Gaetano and Romano, Simon Pietro and Schartner, Peter},
  journal={arXiv preprint arXiv:2510.17521},
  year={2025}
}

@article{mayoral2025caibench,
  title={CAIBench: A Meta-Benchmark for Evaluating Cybersecurity AI Agents},
  author={Mayoral-Vilches, V{\'\i}ctor and Balassone, Francesco and Navarrete-Lozano, Luis Javier and Sanz-G{\'o}mez, Mar{\'\i}a and Crespo-{\'A}lvarez, Marti{\~n}o and Rass, Stefan and Pinzger, Martin},
  journal={arXiv preprint arXiv:2510.24317},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;CAI was initially developed by &lt;a href="https://aliasrobotics.com"&gt;Alias Robotics&lt;/a&gt; and co-funded by the European EIC accelerator project RIS (GA 101161136) - HORIZON-EIC-2023-ACCELERATOR-01 call. The original agentic principles are inspired from OpenAI's &lt;a href="https://github.com/openai/swarm"&gt;&lt;code&gt;swarm&lt;/code&gt;&lt;/a&gt; library and translated into newer prototypes. This project also makes use of other relevant open source building blocks including &lt;a href="https://github.com/BerriAI/litellm"&gt;&lt;code&gt;LiteLLM&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/Arize-ai/phoenix"&gt;&lt;code&gt;phoenix&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Academic Collaborations&lt;/h3&gt; 
&lt;p&gt;CAI benefits from ongoing research collaborations with academic institutions. Researchers interested in collaborative projects, dataset access, or academic licenses should contact &lt;a href="mailto:research@aliasrobotics.com"&gt;research@aliasrobotics.com&lt;/a&gt;. We provide special support for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PhD research projects&lt;/li&gt; 
 &lt;li&gt;Academic benchmarking studies&lt;/li&gt; 
 &lt;li&gt;Security education initiatives&lt;/li&gt; 
 &lt;li&gt;Open-source contributions from research labs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- Footnotes --&gt; 
&lt;p&gt;[^1]: Arguably, the Chain-of-Thought agentic pattern is a special case of the Hierarchical agentic pattern. [^2]: Kamhoua, C. A., Leslie, N. O., &amp;amp; Weisman, M. J. (2018). Game theoretic modeling of advanced persistent threat in internet of things. Journal of Cyber Security and Information Systems. [^3]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp;amp; Cao, Y. (2023, January). React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR). [^4]: Deng, G., Liu, Y., Mayoral-Vilches, V., Liu, P., Li, Y., Xu, Y., ... &amp;amp; Rass, S. (2024). {PentestGPT}: Evaluating and harnessing large language models for automated penetration testing. In 33rd USENIX Security Symposium (USENIX Security 24) (pp. 847-864).&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>