<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Fri, 25 Jul 2025 01:57:28 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>NanmiCoder/MediaCrawler</title>
      <link>https://github.com/NanmiCoder/MediaCrawler</link>
      <description>&lt;p&gt;小红书笔记 | 评论爬虫、抖音视频 | 评论爬虫、快手视频 | 评论爬虫、B 站视频 ｜ 评论爬虫、微博帖子 ｜ 评论爬虫、百度贴吧帖子 ｜ 百度贴吧评论回复爬虫 | 知乎问答文章｜评论爬虫&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🔥 MediaCrawler - 自媒体平台爬虫 🕷️&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/8291" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/8291" alt="NanmiCoder%2FMediaCrawler | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://github.com/NanmiCoder/MediaCrawler/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social" alt="GitHub Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social" alt="GitHub Forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/issues"&gt;&lt;img src="https://img.shields.io/github/issues/NanmiCoder/MediaCrawler" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler" alt="GitHub Pull Requests"&gt;&lt;/a&gt; &lt;a href="https://github.com/NanmiCoder/MediaCrawler/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/NanmiCoder/MediaCrawler" alt="License"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%A8%F0%9F%87%B3_%E4%B8%AD%E6%96%87-%E5%BD%93%E5%89%8D-blue" alt="中文"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_en.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%BA%F0%9F%87%B8_English-Available-green" alt="English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/README_es.md"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%87%AA%F0%9F%87%B8_Espa%C3%B1ol-Available-green" alt="Español"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;免责声明：&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;大家请以学习为目的使用本仓库⚠️⚠️⚠️⚠️，&lt;a href="https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China"&gt;爬虫违法违规的案件&lt;/a&gt; &lt;br&gt;&lt;/p&gt; 
 &lt;p&gt;本仓库的所有内容仅供学习和参考之用，禁止用于商业用途。任何人或组织不得将本仓库的内容用于非法用途或侵犯他人合法权益。本仓库所涉及的爬虫技术仅用于学习和研究，不得用于对其他平台进行大规模爬虫或其他非法行为。对于因使用本仓库内容而引起的任何法律责任，本仓库不承担任何责任。使用本仓库的内容即表示您同意本免责声明的所有条款和条件。&lt;/p&gt; 
 &lt;p&gt;点击查看更为详细的免责声明。&lt;a href="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/#disclaimer"&gt;点击跳转&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;📖 项目简介&lt;/h2&gt; 
&lt;p&gt;一个功能强大的&lt;strong&gt;多平台自媒体数据采集工具&lt;/strong&gt;，支持小红书、抖音、快手、B站、微博、贴吧、知乎等主流平台的公开信息抓取。&lt;/p&gt; 
&lt;h3&gt;🔧 技术原理&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;核心技术&lt;/strong&gt;：基于 &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; 浏览器自动化框架登录保存登录态&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;无需JS逆向&lt;/strong&gt;：利用保留登录态的浏览器上下文环境，通过 JS 表达式获取签名参数&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;优势特点&lt;/strong&gt;：无需逆向复杂的加密算法，大幅降低技术门槛&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;✨ 功能特性&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;平台&lt;/th&gt; 
   &lt;th&gt;关键词搜索&lt;/th&gt; 
   &lt;th&gt;指定帖子ID爬取&lt;/th&gt; 
   &lt;th&gt;二级评论&lt;/th&gt; 
   &lt;th&gt;指定创作者主页&lt;/th&gt; 
   &lt;th&gt;登录态缓存&lt;/th&gt; 
   &lt;th&gt;IP代理池&lt;/th&gt; 
   &lt;th&gt;生成评论词云图&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;小红书&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;抖音&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;快手&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;B 站&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;微博&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;贴吧&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;知乎&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details id="pro-version"&gt; 
 &lt;summary&gt;🔗 &lt;strong&gt;🚀 MediaCrawlerPro 重磅发布！更多的功能，更好的架构设计！&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;🚀 MediaCrawlerPro 重磅发布！&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;专注于学习成熟项目的架构设计，不仅仅是爬虫技术，Pro 版本的代码设计思路同样值得深入学习！&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro&lt;/a&gt; 相较于开源版本的核心优势：&lt;/p&gt; 
 &lt;h4&gt;🎯 核心功能升级&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;断点续爬功能&lt;/strong&gt;（重点特性）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;多账号 + IP代理池支持&lt;/strong&gt;（重点特性）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;去除 Playwright 依赖&lt;/strong&gt;，使用更简单&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;完整 Linux 环境支持&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;🏗️ 架构设计优化&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;代码重构优化&lt;/strong&gt;，更易读易维护（解耦 JS 签名逻辑）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;企业级代码质量&lt;/strong&gt;，适合构建大型爬虫项目&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;完美架构设计&lt;/strong&gt;，高扩展性，源码学习价值更大&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;🎁 额外功能&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;✅ &lt;strong&gt;自媒体视频下载器桌面端&lt;/strong&gt;（适合学习全栈开发）&lt;/li&gt; 
  &lt;li&gt;✅ &lt;strong&gt;多平台首页信息流推荐&lt;/strong&gt;（HomeFeed）&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; &lt;strong&gt;基于自媒体平台的AI Agent正在开发中 🚀🚀&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;点击查看：&lt;a href="https://github.com/MediaCrawlerPro"&gt;MediaCrawlerPro 项目主页&lt;/a&gt; 更多介绍&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;🚀 快速开始&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡 &lt;strong&gt;开源不易，如果这个项目对您有帮助，请给个 ⭐ Star 支持一下！&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;📋 前置依赖&lt;/h2&gt; 
&lt;h3&gt;🚀 uv 安装（推荐）&lt;/h3&gt; 
&lt;p&gt;在进行下一步操作之前，请确保电脑上已经安装了 uv：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;安装地址&lt;/strong&gt;：&lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv 官方安装指南&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;验证安装&lt;/strong&gt;：终端输入命令 &lt;code&gt;uv --version&lt;/code&gt;，如果正常显示版本号，证明已经安装成功&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;推荐理由&lt;/strong&gt;：uv 是目前最强的 Python 包管理工具，速度快、依赖解析准确&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🟢 Node.js 安装&lt;/h3&gt; 
&lt;p&gt;项目依赖 Node.js，请前往官网下载安装：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;下载地址&lt;/strong&gt;：&lt;a href="https://nodejs.org/en/download/"&gt;https://nodejs.org/en/download/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;版本要求&lt;/strong&gt;：&amp;gt;= 16.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 Python 包安装&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 进入项目目录
cd MediaCrawler

# 使用 uv sync 命令来保证 python 版本和相关依赖包的一致性
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🌐 浏览器驱动安装&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 安装浏览器驱动
uv run playwright install
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;💡 提示&lt;/strong&gt;：MediaCrawler 目前已经支持使用 playwright 连接你本地的 Chrome 浏览器了，一些因为 Webdriver 导致的问题迎刃而解了。&lt;/p&gt; 
 &lt;p&gt;目前开放了 &lt;code&gt;xhs&lt;/code&gt; 和 &lt;code&gt;dy&lt;/code&gt; 这两个使用 CDP 的方式连接本地浏览器，如有需要，查看 &lt;code&gt;config/base_config.py&lt;/code&gt; 中的配置项。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🚀 运行爬虫程序&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 项目默认是没有开启评论爬取模式，如需评论请在 config/base_config.py 中的 ENABLE_GET_COMMENTS 变量修改
# 一些其他支持项，也可以在 config/base_config.py 查看功能，写的有中文注释

# 从配置文件中读取关键词搜索相关的帖子并爬取帖子信息与评论
uv run main.py --platform xhs --lt qrcode --type search

# 从配置文件中读取指定的帖子ID列表获取指定帖子的信息与评论信息
uv run main.py --platform xhs --lt qrcode --type detail

# 打开对应APP扫二维码登录

# 其他平台爬虫使用示例，执行下面的命令查看
uv run main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;🔗 &lt;strong&gt;使用 Python 原生 venv 管理环境（不推荐）&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;创建并激活 Python 虚拟环境&lt;/h4&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;如果是爬取抖音和知乎，需要提前安装 nodejs 环境，版本大于等于：&lt;code&gt;16&lt;/code&gt; 即可&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# 进入项目根目录
cd MediaCrawler

# 创建虚拟环境
# 我的 python 版本是：3.9.6，requirements.txt 中的库是基于这个版本的
# 如果是其他 python 版本，可能 requirements.txt 中的库不兼容，需自行解决
python -m venv venv

# macOS &amp;amp; Linux 激活虚拟环境
source venv/bin/activate

# Windows 激活虚拟环境
venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;安装依赖库&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;安装 playwright 浏览器驱动&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;运行爬虫程序（原生环境）&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# 项目默认是没有开启评论爬取模式，如需评论请在 config/base_config.py 中的 ENABLE_GET_COMMENTS 变量修改
# 一些其他支持项，也可以在 config/base_config.py 查看功能，写的有中文注释

# 从配置文件中读取关键词搜索相关的帖子并爬取帖子信息与评论
python main.py --platform xhs --lt qrcode --type search

# 从配置文件中读取指定的帖子ID列表获取指定帖子的信息与评论信息
python main.py --platform xhs --lt qrcode --type detail

# 打开对应APP扫二维码登录

# 其他平台爬虫使用示例，执行下面的命令查看
python main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;💾 数据保存&lt;/h2&gt; 
&lt;p&gt;支持多种数据存储方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 数据库&lt;/strong&gt;：轻量级数据库，无需服务器，适合个人使用（推荐） 
  &lt;ul&gt; 
   &lt;li&gt;参数：&lt;code&gt;--save_data_option sqlite&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;自动创建数据库文件&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MySQL 数据库&lt;/strong&gt;：支持关系型数据库 MySQL 中保存（需要提前创建数据库） 
  &lt;ul&gt; 
   &lt;li&gt;执行 &lt;code&gt;python db.py&lt;/code&gt; 初始化数据库表结构（只在首次执行）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CSV 文件&lt;/strong&gt;：支持保存到 CSV 中（&lt;code&gt;data/&lt;/code&gt; 目录下）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON 文件&lt;/strong&gt;：支持保存到 JSON 中（&lt;code&gt;data/&lt;/code&gt; 目录下）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;使用示例：&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 使用 SQLite（推荐个人用户使用）
uv run main.py --platform xhs --lt qrcode --type search --save_data_option sqlite

# 使用 MySQL
uv run main.py --platform xhs --lt qrcode --type search --save_data_option db
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/MediaCrawlerPro"&gt;🚀 MediaCrawlerPro 重磅发布 🚀！更多的功能，更好的架构设计！&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 社区与支持&lt;/h2&gt; 
&lt;h3&gt;💬 交流群组&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;微信交流群&lt;/strong&gt;：&lt;a href="https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html"&gt;点击加入&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📚 文档与教程&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;在线文档&lt;/strong&gt;：&lt;a href="https://nanmicoder.github.io/MediaCrawler/"&gt;MediaCrawler 完整文档&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;爬虫教程&lt;/strong&gt;：&lt;a href="https://github.com/NanmiCoder/CrawlerTutorial"&gt;CrawlerTutorial 免费教程&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;其他常见问题可以查看在线文档&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;在线文档包含使用方法、常见问题、加入项目交流群等。 &lt;a href="https://nanmicoder.github.io/MediaCrawler/"&gt;MediaCrawler在线文档&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;作者提供的知识服务&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果想快速入门和学习该项目的使用、源码架构设计等、学习编程技术、亦或者想了解MediaCrawlerPro的源代码设计可以看下我的知识付费栏目。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://nanmicoder.github.io/MediaCrawler/%E7%9F%A5%E8%AF%86%E4%BB%98%E8%B4%B9%E4%BB%8B%E7%BB%8D.html"&gt;作者的知识付费栏目介绍&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;⭐ Star 趋势图&lt;/h2&gt; 
&lt;p&gt;如果这个项目对您有帮助，请给个 ⭐ Star 支持一下，让更多的人看到 MediaCrawler！&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#NanmiCoder/MediaCrawler&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;💰 赞助商展示&lt;/h3&gt; 
&lt;a href="https://www.swiftproxy.net/?ref=nanmi"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_5.png"&gt; &lt;br&gt; Swiftproxy - 90M+ 全球高质量纯净住宅IP，注册可领免费 500MB 测试流量，动态流量不过期！ &amp;gt; 专属折扣码：**GHB5** 立享九折优惠！ &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;a href="https://www.tkyds.com/?=MediaCrawler"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_6.png"&gt; &lt;br&gt; TK云大师,专业的TikTok矩阵系统,AI赋能自动化,单人轻松管理上万账号！ &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;a href="https://www.thordata.com/?ls=github&amp;amp;lk=Crawler"&gt; &lt;img src="https://raw.githubusercontent.com/NanmiCoder/MediaCrawler/main/docs/static/images/img_7.png"&gt; &lt;br&gt; Thordata是全球代理IP解决方案提供商，支持大规模采集公共网络数据，提供 195+ 国家城市、6000 万住宅IP，价格低至 $0.65/GB，支持不限流量、不限IP、不限并发；还包括本土独享ISP静态代理和高性能数据中心代理（均为 $0.75/IP，弹性定价）。点击图片注册后联系中文客服即可免费试用，现在首充还有赠送同额金额活动。可与EasySpider工具配合使用，高效采集网络数据。 &lt;/a&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://sider.ai/ad-land-redirect?source=github&amp;amp;p1=mi&amp;amp;p2=kk"&gt;&lt;strong&gt;Sider&lt;/strong&gt; - 全网最火的 ChatGPT 插件，体验拉满！&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🤝 成为赞助者&lt;/h3&gt; 
&lt;p&gt;成为赞助者，可以将您的产品展示在这里，每天获得大量曝光！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;联系方式&lt;/strong&gt;：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;微信：&lt;code&gt;yzglan&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;邮箱：&lt;code&gt;relakkes@gmail.com&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📚 参考&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;小红书客户端&lt;/strong&gt;：&lt;a href="https://github.com/ReaJason/xhs"&gt;ReaJason 的 xhs 仓库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;短信转发&lt;/strong&gt;：&lt;a href="https://github.com/pppscn/SmsForwarder"&gt;SmsForwarder 参考仓库&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;内网穿透工具&lt;/strong&gt;：&lt;a href="https://ngrok.com/docs/"&gt;ngrok 官方文档&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;免责声明&lt;/h1&gt; 
&lt;div id="disclaimer"&gt; 
 &lt;h2&gt;1. 项目目的与性质&lt;/h2&gt; 
 &lt;p&gt;本项目（以下简称“本项目”）是作为一个技术研究与学习工具而创建的，旨在探索和学习网络数据采集技术。本项目专注于自媒体平台的数据爬取技术研究，旨在提供给学习者和研究者作为技术交流之用。&lt;/p&gt; 
 &lt;h2&gt;2. 法律合规性声明&lt;/h2&gt; 
 &lt;p&gt;本项目开发者（以下简称“开发者”）郑重提醒用户在下载、安装和使用本项目时，严格遵守中华人民共和国相关法律法规，包括但不限于《中华人民共和国网络安全法》、《中华人民共和国反间谍法》等所有适用的国家法律和政策。用户应自行承担一切因使用本项目而可能引起的法律责任。&lt;/p&gt; 
 &lt;h2&gt;3. 使用目的限制&lt;/h2&gt; 
 &lt;p&gt;本项目严禁用于任何非法目的或非学习、非研究的商业行为。本项目不得用于任何形式的非法侵入他人计算机系统，不得用于任何侵犯他人知识产权或其他合法权益的行为。用户应保证其使用本项目的目的纯属个人学习和技术研究，不得用于任何形式的非法活动。&lt;/p&gt; 
 &lt;h2&gt;4. 免责声明&lt;/h2&gt; 
 &lt;p&gt;开发者已尽最大努力确保本项目的正当性及安全性，但不对用户使用本项目可能引起的任何形式的直接或间接损失承担责任。包括但不限于由于使用本项目而导致的任何数据丢失、设备损坏、法律诉讼等。&lt;/p&gt; 
 &lt;h2&gt;5. 知识产权声明&lt;/h2&gt; 
 &lt;p&gt;本项目的知识产权归开发者所有。本项目受到著作权法和国际著作权条约以及其他知识产权法律和条约的保护。用户在遵守本声明及相关法律法规的前提下，可以下载和使用本项目。&lt;/p&gt; 
 &lt;h2&gt;6. 最终解释权&lt;/h2&gt; 
 &lt;p&gt;关于本项目的最终解释权归开发者所有。开发者保留随时更改或更新本免责声明的权利，恕不另行通知。&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🙏 致谢&lt;/h2&gt; 
&lt;h3&gt;JetBrains 开源许可证支持&lt;/h3&gt; 
&lt;p&gt;感谢 JetBrains 为本项目提供免费的开源许可证支持！&lt;/p&gt; 
&lt;a href="https://www.jetbrains.com/?from=MediaCrawler"&gt; &lt;img src="https://www.jetbrains.com/company/brand/img/jetbrains_logo.png" width="100" alt="JetBrains"&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>snailyp/gemini-balance</title>
      <link>https://github.com/snailyp/gemini-balance</link>
      <description>&lt;p&gt;Gemini polling proxy service （gemini轮询代理服务）&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/README_ZH.md"&gt;Read this document in Chinese&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Gemini Balance - Gemini API Proxy and Load Balancer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/13692" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13692" alt="snailyp%2Fgemini-balance | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3.9%2B-blue.svg?sanitize=true" alt="Python"&gt;&lt;/a&gt; &lt;a href="https://fastapi.tiangolo.com/"&gt;&lt;img src="https://img.shields.io/badge/FastAPI-0.100%2B-green.svg?sanitize=true" alt="FastAPI"&gt;&lt;/a&gt; &lt;a href="https://www.uvicorn.org/"&gt;&lt;img src="https://img.shields.io/badge/Uvicorn-running-purple.svg?sanitize=true" alt="Uvicorn"&gt;&lt;/a&gt; &lt;a href="https://t.me/+soaHax5lyI0wZDVl"&gt;&lt;img src="https://img.shields.io/badge/Telegram-Group-blue.svg?logo=telegram" alt="Telegram Group"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;Important&lt;/strong&gt;: This project is licensed under the &lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/LICENSE"&gt;CC BY-NC 4.0&lt;/a&gt; license. &lt;strong&gt;Any form of commercial resale service is prohibited&lt;/strong&gt;. I have never sold this service on any platform. If you encounter someone selling this service, they are a reseller. Please do not be deceived.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h2&gt;📖 Project Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Gemini Balance&lt;/strong&gt; is an application built with Python FastAPI, designed to provide proxy and load balancing functions for the Google Gemini API. It allows you to manage multiple Gemini API Keys and implement key rotation, authentication, model filtering, and status monitoring through simple configuration. Additionally, the project integrates image generation and multiple image hosting upload functions, and supports proxying in the OpenAI API format.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;📂 View Project Structure&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-plaintext"&gt;app/
├── config/       # Configuration management
├── core/         # Core application logic (FastAPI instance creation, middleware, etc.)
├── database/     # Database models and connections
├── domain/       # Business domain objects
├── exception/    # Custom exceptions
├── handler/      # Request handlers
├── log/          # Logging configuration
├── main.py       # Application entry point
├── middleware/   # FastAPI middleware
├── router/       # API routes (Gemini, OpenAI, status page, etc.)
├── scheduler/    # Scheduled tasks (e.g., Key status check)
├── service/      # Business logic services (chat, Key management, statistics, etc.)
├── static/       # Static files (CSS, JS)
├── templates/    # HTML templates (e.g., Key status page)
└── utils/        # Utility functions
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;✨ Feature Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Key Load Balancing&lt;/strong&gt;: Supports configuring multiple Gemini API Keys (&lt;code&gt;API_KEYS&lt;/code&gt;) for automatic sequential polling.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Configuration&lt;/strong&gt;: Configurations modified through the admin backend take effect immediately without restarting. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image4.png" alt="Configuration Panel"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dual Protocol API Compatibility&lt;/strong&gt;: Supports both Gemini and OpenAI CHAT API formats. 
  &lt;ul&gt; 
   &lt;li&gt;OpenAI Base URL: &lt;code&gt;http://localhost:8000(/hf)/v1&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gemini Base URL: &lt;code&gt;http://localhost:8000(/gemini)/v1beta&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image-Text Chat &amp;amp; Modification&lt;/strong&gt;: Configure models with &lt;code&gt;IMAGE_MODELS&lt;/code&gt; to support image-text chat and editing. Use the &lt;code&gt;configured_model-image&lt;/code&gt; model name to invoke. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image6.png" alt="Chat with Image Generation"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image7.png" alt="Modify Image"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web Search&lt;/strong&gt;: Configure models with &lt;code&gt;SEARCH_MODELS&lt;/code&gt; to support web search. Use the &lt;code&gt;configured_model-search&lt;/code&gt; model name to invoke. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image8.png" alt="Web Search"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Key Status Monitoring&lt;/strong&gt;: Provides a &lt;code&gt;/keys_status&lt;/code&gt; page (authentication required) for real-time monitoring. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image.png" alt="Monitoring Panel"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Detailed Logging&lt;/strong&gt;: Provides detailed error logs for easy troubleshooting. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image1.png" alt="Call Details"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image2.png" alt="Log List"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image3.png" alt="Log Details"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Key Addition&lt;/strong&gt;: Add keys in batches using the &lt;code&gt;gemini_key&lt;/code&gt; regex, with automatic deduplication. &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/image5.png" alt="Add Key"&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Failure Retry &amp;amp; Auto-Disable&lt;/strong&gt;: Automatically retries failed API requests (&lt;code&gt;MAX_RETRIES&lt;/code&gt;) and disables keys after excessive failures (&lt;code&gt;MAX_FAILURES&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive API Compatibility&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Embeddings API&lt;/strong&gt;: Fully compatible with the OpenAI &lt;code&gt;embeddings&lt;/code&gt; API format.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Image Generation API&lt;/strong&gt;: Adapts the &lt;code&gt;imagen-3.0-generate-002&lt;/code&gt; model to the OpenAI image generation API format.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Model List Maintenance&lt;/strong&gt;: Automatically fetches and syncs the latest model lists from Gemini and OpenAI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy Support&lt;/strong&gt;: Supports HTTP/SOCKS5 proxies (&lt;code&gt;PROXIES&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Support&lt;/strong&gt;: Provides Docker images for both AMD and ARM architectures. 
  &lt;ul&gt; 
   &lt;li&gt;Image Address: &lt;code&gt;ghcr.io/snailyp/gemini-balance:latest&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Docker Compose (Recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Get &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/strong&gt;: Download the &lt;code&gt;docker-compose.yml&lt;/code&gt; file from the project repository.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prepare &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it. Ensure &lt;code&gt;DATABASE_TYPE&lt;/code&gt; is set to &lt;code&gt;mysql&lt;/code&gt; and fill in the &lt;code&gt;MYSQL_*&lt;/code&gt; details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start Services&lt;/strong&gt;: In the directory containing &lt;code&gt;docker-compose.yml&lt;/code&gt; and &lt;code&gt;.env&lt;/code&gt;, run: &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 2: Docker Command&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Pull Image&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/snailyp/gemini-balance:latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prepare &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run Container&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 8000:8000 --name gemini-balance \
-v ./data:/app/data \
--env-file .env \
ghcr.io/snailyp/gemini-balance:latest
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;-d&lt;/code&gt;: Detached mode.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-p 8000:8000&lt;/code&gt;: Map container port 8000 to host.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;-v ./data:/app/data&lt;/code&gt;: Mount volume for persistent data.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;--env-file .env&lt;/code&gt;: Load environment variables.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 3: Local Development&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone and Install&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/snailyp/gemini-balance.git
cd gemini-balance
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure Environment&lt;/strong&gt;: Copy &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start Application&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
&lt;/code&gt;&lt;/pre&gt; Access the application at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h2&gt;⚙️ API Endpoints&lt;/h2&gt; 
&lt;h3&gt;Gemini API Format (&lt;code&gt;/gemini/v1beta&lt;/code&gt;)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /models&lt;/code&gt;: List available Gemini models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /models/{model_name}:generateContent&lt;/code&gt;: Generate content.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /models/{model_name}:streamGenerateContent&lt;/code&gt;: Stream content generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;OpenAI API Format&lt;/h3&gt; 
&lt;h4&gt;Hugging Face (HF) Compatible&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /hf/v1/models&lt;/code&gt;: List models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/chat/completions&lt;/code&gt;: Chat completion.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/embeddings&lt;/code&gt;: Create text embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /hf/v1/images/generations&lt;/code&gt;: Generate images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Standard OpenAI&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /openai/v1/models&lt;/code&gt;: List models.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/chat/completions&lt;/code&gt;: Chat completion (Recommended).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/embeddings&lt;/code&gt;: Create text embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /openai/v1/images/generations&lt;/code&gt;: Generate images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;📋 View Full Configuration List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Configuration Item&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
    &lt;th align="left"&gt;Default Value&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Database&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;DATABASE_TYPE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;mysql&lt;/code&gt; or &lt;code&gt;sqlite&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;mysql&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SQLITE_DATABASE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Path for SQLite database file&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;default_db&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_HOST&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL host address&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;localhost&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_SOCKET&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL socket address&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;/var/run/mysqld/mysqld.sock&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_PORT&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL port&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3306&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_USER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL username&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your_db_user&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_PASSWORD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL password&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your_db_password&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MYSQL_DATABASE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;MySQL database name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;defaultdb&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;API&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;API_KEYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Required&lt;/strong&gt;, list of Gemini API keys&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;ALLOWED_TOKENS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Required&lt;/strong&gt;, list of access tokens&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTH_TOKEN&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Super admin token, defaults to the first of &lt;code&gt;ALLOWED_TOKENS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;sk-123456&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;ADMIN_SESSION_EXPIRE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Admin session expiration time in seconds (5 minutes to 24 hours)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3600&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TEST_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Model for testing key validity&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;gemini-1.5-flash&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;IMAGE_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting image generation&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;["gemini-2.0-flash-exp"]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SEARCH_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting web search&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;["gemini-2.0-flash-exp"]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FILTERED_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Disabled models&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TOOLS_CODE_EXECUTION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable code execution tool&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SHOW_SEARCH_LINK&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Display search result links in response&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SHOW_THINKING_PROCESS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Display model's thinking process&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;THINKING_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting thinking process&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;THINKING_BUDGET_MAP&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Budget map for thinking function (model:budget)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;{}&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_NORMALIZATION_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable smart URL routing&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_CONTEXT_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable URL context understanding&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;URL_CONTEXT_MODELS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Models supporting URL context&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Gemini API base URL&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;https://generativelanguage.googleapis.com/v1beta&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MAX_FAILURES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Max failures allowed per key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;MAX_RETRIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Max retries for failed API requests&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CHECK_INTERVAL_HOURS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Interval (hours) to re-check disabled keys&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TIMEZONE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Application timezone&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;Asia/Shanghai&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TIME_OUT&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Request timeout (seconds)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;300&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PROXIES&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;List of proxy servers&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Logging &amp;amp; Security&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Log level: &lt;code&gt;DEBUG&lt;/code&gt;, &lt;code&gt;INFO&lt;/code&gt;, &lt;code&gt;WARNING&lt;/code&gt;, &lt;code&gt;ERROR&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;INFO&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_ERROR_LOGS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Auto-delete error logs&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_ERROR_LOGS_DAYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Error log retention period (days)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;7&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_REQUEST_LOGS_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Auto-delete request logs&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;AUTO_DELETE_REQUEST_LOGS_DAYS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Request log retention period (days)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SAFETY_SETTINGS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Content safety thresholds (JSON string)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;[{"category": "HARM_CATEGORY_HARASSMENT", "threshold": "OFF"}, ...]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;TTS&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS model name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;gemini-2.5-flash-preview-tts&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_VOICE_NAME&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS voice name&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;Zephyr&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;TTS_SPEED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;TTS speed&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;normal&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Image Generation&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PAID_KEY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Paid API Key for advanced features&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-paid-api-key&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CREATE_IMAGE_MODEL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Image generation model&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;imagen-3.0-generate-002&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;UPLOAD_PROVIDER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Image upload provider: &lt;code&gt;smms&lt;/code&gt;, &lt;code&gt;picgo&lt;/code&gt;, &lt;code&gt;cloudflare_imgbed&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;smms&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;SMMS_SECRET_TOKEN&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;SM.MS API Token&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-smms-token&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;PICGO_API_KEY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;PicoGo API Key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-picogo-apikey&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed upload URL&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;https://xxxxxxx.pages.dev/upload&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_AUTH_CODE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed auth key&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;your-cloudflare-imgber-auth-code&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;CLOUDFLARE_IMGBED_UPLOAD_FOLDER&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;CloudFlare ImgBed upload folder&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;""&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Stream Optimizer&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_OPTIMIZER_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable stream output optimization&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_MIN_DELAY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Minimum stream output delay&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;0.016&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_MAX_DELAY&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Maximum stream output delay&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;0.024&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_SHORT_TEXT_THRESHOLD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Short text threshold&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_LONG_TEXT_THRESHOLD&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Long text threshold&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;50&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;STREAM_CHUNK_SIZE&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Stream output chunk size&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;Fake Stream&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FAKE_STREAM_ENABLED&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Enable fake streaming&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;FAKE_STREAM_EMPTY_DATA_INTERVAL_SECONDS&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Heartbeat interval for fake streaming (seconds)&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Pull Requests or Issues are welcome.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/snailyp/gemini-balance/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=snailyp/gemini-balance" alt="Contributors"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;⭐ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#snailyp/gemini-balance&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=snailyp/gemini-balance&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🎉 Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.picgo.net/"&gt;PicGo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smms.app/"&gt;SM.MS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MarSeventh/CloudFlare-ImgBed"&gt;CloudFlare-ImgBed&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🙏 Our Supporters&lt;/h2&gt; 
&lt;p&gt;A special shout-out to &lt;a href="https://m.do.co/c/b249dd7f3b4c"&gt;DigitalOcean&lt;/a&gt; for providing the rock-solid and dependable cloud infrastructure that keeps this project humming!&lt;/p&gt; 
&lt;a href="https://m.do.co/c/b249dd7f3b4c"&gt; &lt;img src="https://raw.githubusercontent.com/snailyp/gemini-balance/main/files/dataocean.svg?sanitize=true" alt="DigitalOcean Logo" width="200"&gt; &lt;/a&gt; 
&lt;p&gt;CDN acceleration and security protection for this project are sponsored by &lt;a href="https://edgeone.ai/?from=github"&gt;Tencent EdgeOne&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://edgeone.ai/?from=github"&gt; &lt;img src="https://edgeone.ai/media/34fe3a45-492d-4ea4-ae5d-ea1087ca7b4b.png" alt="EdgeOne Logo" width="200"&gt; &lt;/a&gt; 
&lt;h2&gt;💖 Friendly Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/chengtx809/OneLine"&gt;OneLine&lt;/a&gt;&lt;/strong&gt; by &lt;a href="https://github.com/chengtx809"&gt;chengtx809&lt;/a&gt; - AI-driven hot event timeline generation tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎁 Project Support&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, consider supporting me via &lt;a href="https://afdian.com/a/snaily"&gt;Afdian&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/snailyp/gemini-balance/main/LICENSE"&gt;CC BY-NC 4.0&lt;/a&gt; (Attribution-NonCommercial) license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opendatalab/MinerU</title>
      <link>https://github.com/opendatalab/MinerU</link>
      <description>&lt;p&gt;A high-quality tool for convert PDF to Markdown and JSON.一站式开源高质量数据提取工具，将PDF转换成Markdown和JSON格式。&lt;/p&gt;&lt;hr&gt;&lt;div align="center" xmlns="http://www.w3.org/1999/html"&gt; 
 &lt;!-- logo --&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/images/MinerU-logo.png" width="300px" style="vertical-align:middle;"&gt; &lt;/p&gt; 
 &lt;!-- icon --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU.svg?sanitize=true" alt="stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/forks/opendatalab/MinerU.svg?sanitize=true" alt="forks"&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;&lt;img src="https://img.shields.io/github/issues-raw/opendatalab/MinerU" alt="open issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;&lt;img src="https://img.shields.io/github/issues-closed-raw/opendatalab/MinerU" alt="issue resolution"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/mineru/"&gt;&lt;img src="https://img.shields.io/pypi/v/mineru" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/mineru/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/mineru" alt="PyPI - Python Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/mineru"&gt;&lt;img src="https://static.pepy.tech/badge/mineru" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/mineru"&gt;&lt;img src="https://static.pepy.tech/badge/mineru/month" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://mineru.net/OpenSourceTools/Extractor?source=github"&gt;&lt;img src="https://img.shields.io/badge/webapp_on_mineru.net-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTM0IiBoZWlnaHQ9IjEzNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJtMTIyLDljMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGQ9Im0xMjIsOWMwLDUtNCw5LTksOXMtOS00LTktOSw0LTksOS05LDksNCw5LDl6IiBmaWxsPSIjMDEwMTAxIi8+PHBhdGggZD0ibTkxLDE4YzAsNS00LDktOSw5cy05LTQtOS05LDQtOSw5LTksOSw0LDksOXoiIGZpbGw9InVybCgjYikiLz48cGF0aCBkPSJtOTEsMThjMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0iIzAxMDEwMSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0idXJsKCNjKSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0iIzAxMDEwMSIvPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYSIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYyIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=&amp;amp;labelColor=white" alt="OpenDataLab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-yellow.svg?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace"&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/gist/myhloli/3b3a00a4a0a61577b6c30f989092d20d/mineru_demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Colab"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2409.18839"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2409.18839-b31b1b.svg?logo=arXiv" alt="arXiv"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/opendatalab/MinerU"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11174" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11174" alt="opendatalab%2FMinerU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- language --&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/README_zh-CN.md"&gt;简体中文&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- hot link --&gt; 
 &lt;p align="center"&gt; 🚀&lt;a href="https://mineru.net/?source=github"&gt;Access MinerU Now→✅ Zero-Install Web Version ✅ Full-Featured Desktop Client ✅ Instant API Access; Skip deployment headaches – get all product formats in one click. Developers, dive in!&lt;/a&gt; &lt;/p&gt; 
 &lt;!-- join us --&gt; 
 &lt;p align="center"&gt; 👋 join us on &lt;a href="https://discord.gg/Tdedn9GTXq" target="_blank"&gt;Discord&lt;/a&gt; and &lt;a href="http://mineru.space/s/V85Yl" target="_blank"&gt;WeChat&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Changelog&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025/07/24 2.1.5 Released 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sglang&lt;/code&gt; 0.4.9 version adaptation, synchronously upgrading the dockerfile base image to sglang 0.4.9.post3&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;2025/07/23 2.1.4 Released 
  &lt;ul&gt; 
   &lt;li&gt;Bug Fixes 
    &lt;ul&gt; 
     &lt;li&gt;Fixed the issue of excessive memory consumption during the &lt;code&gt;MFR&lt;/code&gt; step in the &lt;code&gt;pipeline&lt;/code&gt; backend under certain scenarios #2771&lt;/li&gt; 
     &lt;li&gt;Fixed the inaccurate matching between &lt;code&gt;image&lt;/code&gt;/&lt;code&gt;table&lt;/code&gt; and &lt;code&gt;caption&lt;/code&gt;/&lt;code&gt;footnote&lt;/code&gt; under certain conditions #3129&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;2025/07/16 2.1.1 Released 
  &lt;ul&gt; 
   &lt;li&gt;Bug fixes 
    &lt;ul&gt; 
     &lt;li&gt;Fixed text block content loss issue that could occur in certain &lt;code&gt;pipeline&lt;/code&gt; scenarios #3005&lt;/li&gt; 
     &lt;li&gt;Fixed issue where &lt;code&gt;sglang-client&lt;/code&gt; required unnecessary packages like &lt;code&gt;torch&lt;/code&gt; #2968&lt;/li&gt; 
     &lt;li&gt;Updated &lt;code&gt;dockerfile&lt;/code&gt; to fix incomplete text content parsing due to missing fonts in Linux #2915&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Usability improvements 
    &lt;ul&gt; 
     &lt;li&gt;Updated &lt;code&gt;compose.yaml&lt;/code&gt; to facilitate direct startup of &lt;code&gt;sglang-server&lt;/code&gt;, &lt;code&gt;mineru-api&lt;/code&gt;, and &lt;code&gt;mineru-gradio&lt;/code&gt; services&lt;/li&gt; 
     &lt;li&gt;Launched brand new &lt;a href="https://opendatalab.github.io/MinerU/"&gt;online documentation site&lt;/a&gt;, simplified readme, providing better documentation experience&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;2025/07/05 Version 2.1.0 Released 
  &lt;ul&gt; 
   &lt;li&gt;This is the first major update of MinerU 2, which includes a large number of new features and improvements, covering significant performance optimizations, user experience enhancements, and bug fixes. The detailed update contents are as follows:&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Performance Optimizations:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Significantly improved preprocessing speed for documents with specific resolutions (around 2000 pixels on the long side).&lt;/li&gt; 
     &lt;li&gt;Greatly enhanced post-processing speed when the &lt;code&gt;pipeline&lt;/code&gt; backend handles batch processing of documents with fewer pages (&amp;lt;10 pages).&lt;/li&gt; 
     &lt;li&gt;Layout analysis speed of the &lt;code&gt;pipeline&lt;/code&gt; backend has been increased by approximately 20%.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Experience Enhancements:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Built-in ready-to-use &lt;code&gt;fastapi service&lt;/code&gt; and &lt;code&gt;gradio webui&lt;/code&gt;. For detailed usage instructions, please refer to &lt;a href="https://opendatalab.github.io/MinerU/usage/quick_usage/#advanced-usage-via-api-webui-sglang-clientserver"&gt;Documentation&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;Adapted to &lt;code&gt;sglang&lt;/code&gt; version &lt;code&gt;0.4.8&lt;/code&gt;, significantly reducing the GPU memory requirements for the &lt;code&gt;vlm-sglang&lt;/code&gt; backend. It can now run on graphics cards with as little as &lt;code&gt;8GB GPU memory&lt;/code&gt; (Turing architecture or newer).&lt;/li&gt; 
     &lt;li&gt;Added transparent parameter passing for all commands related to &lt;code&gt;sglang&lt;/code&gt;, allowing the &lt;code&gt;sglang-engine&lt;/code&gt; backend to receive all &lt;code&gt;sglang&lt;/code&gt; parameters consistently with the &lt;code&gt;sglang-server&lt;/code&gt;.&lt;/li&gt; 
     &lt;li&gt;Supports feature extensions based on configuration files, including &lt;code&gt;custom formula delimiters&lt;/code&gt;, &lt;code&gt;enabling heading classification&lt;/code&gt;, and &lt;code&gt;customizing local model directories&lt;/code&gt;. For detailed usage instructions, please refer to &lt;a href="https://opendatalab.github.io/MinerU/usage/quick_usage/#extending-mineru-functionality-with-configuration-files"&gt;Documentation&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;New Features:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Updated the &lt;code&gt;pipeline&lt;/code&gt; backend with the PP-OCRv5 multilingual text recognition model, supporting text recognition in 37 languages such as French, Spanish, Portuguese, Russian, and Korean, with an average accuracy improvement of over 30%. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Introduced limited support for vertical text layout in the &lt;code&gt;pipeline&lt;/code&gt; backend.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;History Log&lt;/summary&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/20 2.0.6 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed occasional parsing interruptions caused by invalid block content in &lt;code&gt;vlm&lt;/code&gt; mode&lt;/li&gt; 
   &lt;li&gt;Fixed parsing interruptions caused by incomplete table structures in &lt;code&gt;vlm&lt;/code&gt; mode&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/17 2.0.5 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where models were still required to be downloaded in the &lt;code&gt;sglang-client&lt;/code&gt; mode&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where the &lt;code&gt;sglang-client&lt;/code&gt; mode unnecessarily depended on packages like &lt;code&gt;torch&lt;/code&gt; during runtime.&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where only the first instance would take effect when attempting to launch multiple &lt;code&gt;sglang-client&lt;/code&gt; instances via multiple URLs within the same process&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/15 2.0.3 released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed a configuration file key-value update error that occurred when downloading model type was set to &lt;code&gt;all&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Fixed the issue where the formula and table feature toggle switches were not working in &lt;code&gt;command line mode&lt;/code&gt;, causing the features to remain enabled.&lt;/li&gt; 
   &lt;li&gt;Fixed compatibility issues with sglang version 0.4.7 in the &lt;code&gt;sglang-engine&lt;/code&gt; mode.&lt;/li&gt; 
   &lt;li&gt;Updated Dockerfile and installation documentation for deploying the full version of MinerU in sglang environment&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/06/13 2.0.0 Released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;New Architecture&lt;/strong&gt;: MinerU 2.0 has been deeply restructured in code organization and interaction methods, significantly improving system usability, maintainability, and extensibility. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Removal of Third-party Dependency Limitations&lt;/strong&gt;: Completely eliminated the dependency on &lt;code&gt;pymupdf&lt;/code&gt;, moving the project toward a more open and compliant open-source direction.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ready-to-use, Easy Configuration&lt;/strong&gt;: No need to manually edit JSON configuration files; most parameters can now be set directly via command line or API.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Automatic Model Management&lt;/strong&gt;: Added automatic model download and update mechanisms, allowing users to complete model deployment without manual intervention.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Offline Deployment Friendly&lt;/strong&gt;: Provides built-in model download commands, supporting deployment requirements in completely offline environments.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Streamlined Code Structure&lt;/strong&gt;: Removed thousands of lines of redundant code, simplified class inheritance logic, significantly improving code readability and development efficiency.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Unified Intermediate Format Output&lt;/strong&gt;: Adopted standardized &lt;code&gt;middle_json&lt;/code&gt; format, compatible with most secondary development scenarios based on this format, ensuring seamless ecosystem business migration.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;New Model&lt;/strong&gt;: MinerU 2.0 integrates our latest small-parameter, high-performance multimodal document parsing model, achieving end-to-end high-speed, high-precision document understanding. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Small Model, Big Capabilities&lt;/strong&gt;: With parameters under 1B, yet surpassing traditional 72B-level vision-language models (VLMs) in parsing accuracy.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multiple Functions in One&lt;/strong&gt;: A single model covers multilingual recognition, handwriting recognition, layout analysis, table parsing, formula recognition, reading order sorting, and other core tasks.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ultimate Inference Speed&lt;/strong&gt;: Achieves peak throughput exceeding 10,000 tokens/s through &lt;code&gt;sglang&lt;/code&gt; acceleration on a single NVIDIA 4090 card, easily handling large-scale document processing requirements.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Online Experience&lt;/strong&gt;: You can experience our brand-new VLM model on &lt;a href="https://mineru.net/OpenSourceTools/Extractor"&gt;MinerU.net&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;Hugging Face&lt;/a&gt;, and &lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;ModelScope&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Incompatible Changes Notice&lt;/strong&gt;: To improve overall architectural rationality and long-term maintainability, this version contains some incompatible changes: 
    &lt;ul&gt; 
     &lt;li&gt;Python package name changed from &lt;code&gt;magic-pdf&lt;/code&gt; to &lt;code&gt;mineru&lt;/code&gt;, and the command-line tool changed from &lt;code&gt;magic-pdf&lt;/code&gt; to &lt;code&gt;mineru&lt;/code&gt;. Please update your scripts and command calls accordingly.&lt;/li&gt; 
     &lt;li&gt;For modular system design and ecosystem consistency considerations, MinerU 2.0 no longer includes the LibreOffice document conversion module. If you need to process Office documents, we recommend converting them to PDF format through an independently deployed LibreOffice service before proceeding with subsequent parsing operations.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/05/24 Release 1.3.12&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added support for PPOCRv5 models, updated &lt;code&gt;ch_server&lt;/code&gt; model to &lt;code&gt;PP-OCRv5_rec_server&lt;/code&gt;, and &lt;code&gt;ch_lite&lt;/code&gt; model to &lt;code&gt;PP-OCRv5_rec_mobile&lt;/code&gt; (model update required) 
    &lt;ul&gt; 
     &lt;li&gt;In testing, we found that PPOCRv5(server) has some improvement for handwritten documents, but has slightly lower accuracy than v4_server_doc for other document types, so the default ch model remains unchanged as &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt;.&lt;/li&gt; 
     &lt;li&gt;Since PPOCRv5 has enhanced recognition capabilities for handwriting and special characters, you can manually choose the PPOCRv5 model for Japanese-Traditional Chinese mixed scenarios and handwritten documents&lt;/li&gt; 
     &lt;li&gt;You can select the appropriate model through the lang parameter &lt;code&gt;lang='ch_server'&lt;/code&gt; (Python API) or &lt;code&gt;--lang ch_server&lt;/code&gt; (command line): 
      &lt;ul&gt; 
       &lt;li&gt;&lt;code&gt;ch&lt;/code&gt;: &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; (default) (Chinese/English/Japanese/Traditional Chinese mixed/15K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_server&lt;/code&gt;: &lt;code&gt;PP-OCRv5_rec_server&lt;/code&gt; (Chinese/English/Japanese/Traditional Chinese mixed + handwriting/18K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_lite&lt;/code&gt;: &lt;code&gt;PP-OCRv5_rec_mobile&lt;/code&gt; (Chinese/English/Japanese/Traditional Chinese mixed + handwriting/18K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_server_v4&lt;/code&gt;: &lt;code&gt;PP-OCRv4_rec_server&lt;/code&gt; (Chinese/English mixed/6K dictionary)&lt;/li&gt; 
       &lt;li&gt;&lt;code&gt;ch_lite_v4&lt;/code&gt;: &lt;code&gt;PP-OCRv4_rec_mobile&lt;/code&gt; (Chinese/English mixed/6K dictionary)&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Added support for handwritten documents through optimized layout recognition of handwritten text areas 
    &lt;ul&gt; 
     &lt;li&gt;This feature is supported by default, no additional configuration required&lt;/li&gt; 
     &lt;li&gt;You can refer to the instructions above to manually select the PPOCRv5 model for better handwritten document parsing results&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;The &lt;code&gt;huggingface&lt;/code&gt; and &lt;code&gt;modelscope&lt;/code&gt; demos have been updated to versions that support handwriting recognition and PPOCRv5 models, which you can experience online&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/29 Release 1.3.10&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added support for custom formula delimiters, which can be configured by modifying the &lt;code&gt;latex-delimiter-config&lt;/code&gt; section in the &lt;code&gt;magic-pdf.json&lt;/code&gt; file in your user directory.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/27 Release 1.3.9&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Optimized formula parsing functionality, improved formula rendering success rate&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/23 Release 1.3.8&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The default &lt;code&gt;ocr&lt;/code&gt; model (&lt;code&gt;ch&lt;/code&gt;) has been updated to &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; (model update required) 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; is trained on a mixture of more Chinese document data and PP-OCR training data based on &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt;, adding recognition capabilities for some traditional Chinese characters, Japanese, and special characters. It can recognize over 15,000 characters and improves both document-specific and general text recognition abilities.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/ocr_modules/text_recognition.html#_3"&gt;Performance comparison of PP-OCRv4_server_rec_doc/PP-OCRv4_server_rec/PP-OCRv4_mobile_rec&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;After verification, the &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; model shows significant accuracy improvements in Chinese/English/Japanese/Traditional Chinese in both single language and mixed language scenarios, with comparable speed to &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt;, making it suitable for most use cases.&lt;/li&gt; 
     &lt;li&gt;In some pure English scenarios, &lt;code&gt;PP-OCRv4_server_rec_doc&lt;/code&gt; may have word adhesion issues, while &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt; performs better in these cases. Therefore, we've kept the &lt;code&gt;PP-OCRv4_server_rec&lt;/code&gt; model, which users can access by adding the parameter &lt;code&gt;lang='ch_server'&lt;/code&gt; (Python API) or &lt;code&gt;--lang ch_server&lt;/code&gt; (command line).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/22 Release 1.3.7&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the issue where the lang parameter was ineffective during table parsing model initialization&lt;/li&gt; 
   &lt;li&gt;Fixed the significant speed reduction of OCR and table parsing in &lt;code&gt;cpu&lt;/code&gt; mode&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/16 Release 1.3.4&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Slightly improved OCR-det speed by removing some unnecessary blocks&lt;/li&gt; 
   &lt;li&gt;Fixed page-internal sorting errors caused by footnotes in certain cases&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/12 Release 1.3.2&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed dependency version incompatibility issues when installing on Windows with Python 3.13&lt;/li&gt; 
   &lt;li&gt;Optimized memory usage during batch inference&lt;/li&gt; 
   &lt;li&gt;Improved parsing of tables rotated 90 degrees&lt;/li&gt; 
   &lt;li&gt;Enhanced parsing of oversized tables in financial report samples&lt;/li&gt; 
   &lt;li&gt;Fixed the occasional word adhesion issue in English text areas when OCR language is not specified (model update required)&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/08 Release 1.3.1&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed several compatibility issues 
    &lt;ul&gt; 
     &lt;li&gt;Added support for Python 3.13&lt;/li&gt; 
     &lt;li&gt;Made final adaptations for outdated Linux systems (such as CentOS 7) with no guarantee of continued support in future versions, &lt;a href="https://github.com/opendatalab/MinerU/issues/1004"&gt;installation instructions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/04/03 Release 1.3.0&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Installation and compatibility optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Resolved compatibility issues caused by &lt;code&gt;detectron2&lt;/code&gt; by removing &lt;code&gt;layoutlmv3&lt;/code&gt; usage in layout&lt;/li&gt; 
     &lt;li&gt;Extended torch version compatibility to 2.2~2.6 (excluding 2.5)&lt;/li&gt; 
     &lt;li&gt;Added CUDA compatibility for versions 11.8/12.4/12.6/12.8 (CUDA version determined by torch), solving compatibility issues for users with 50-series and H-series GPUs&lt;/li&gt; 
     &lt;li&gt;Extended Python compatibility to versions 3.10~3.12, fixing the issue of automatic downgrade to version 0.6.1 when installing in non-3.10 environments&lt;/li&gt; 
     &lt;li&gt;Optimized offline deployment process, eliminating the need to download any model files after successful deployment&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Performance optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Enhanced parsing speed for batches of small files by supporting batch processing of multiple PDF files (&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/demo/batch_demo.py"&gt;script example&lt;/a&gt;), with formula parsing speed improved by up to 1400% and overall parsing speed improved by up to 500% compared to version 1.0.1&lt;/li&gt; 
     &lt;li&gt;Reduced memory usage and improved parsing speed by optimizing MFR model loading and usage (requires re-running the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/how_to_download_models_zh_cn.md"&gt;model download process&lt;/a&gt; to get incremental updates to model files)&lt;/li&gt; 
     &lt;li&gt;Optimized GPU memory usage, requiring only 6GB minimum to run this project&lt;/li&gt; 
     &lt;li&gt;Improved running speed on MPS devices&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Parsing effect optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Updated MFR model to &lt;code&gt;unimernet(2503)&lt;/code&gt;, fixing line break loss issues in multi-line formulas&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Usability optimizations 
    &lt;ul&gt; 
     &lt;li&gt;Completely replaced the &lt;code&gt;paddle&lt;/code&gt; framework and &lt;code&gt;paddleocr&lt;/code&gt; in the project by using &lt;code&gt;paddleocr2torch&lt;/code&gt;, resolving conflicts between &lt;code&gt;paddle&lt;/code&gt; and &lt;code&gt;torch&lt;/code&gt;, as well as thread safety issues caused by the &lt;code&gt;paddle&lt;/code&gt; framework&lt;/li&gt; 
     &lt;li&gt;Added real-time progress bar display during parsing, allowing precise tracking of parsing progress and making the waiting process more bearable&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/03/03 1.2.1 released&lt;/summary&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed the impact on punctuation marks during full-width to half-width conversion of letters and numbers&lt;/li&gt; 
   &lt;li&gt;Fixed caption matching inaccuracies in certain scenarios&lt;/li&gt; 
   &lt;li&gt;Fixed formula span loss issues in certain scenarios&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/02/24 1.2.0 released&lt;/summary&gt; 
  &lt;p&gt;This version includes several fixes and improvements to enhance parsing efficiency and accuracy:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Performance Optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Increased classification speed for PDF documents in auto mode.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Parsing Optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Improved parsing logic for documents containing watermarks, significantly enhancing the parsing results for such documents.&lt;/li&gt; 
     &lt;li&gt;Enhanced the matching logic for multiple images/tables and captions within a single page, improving the accuracy of image-text matching in complex layouts.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Bug Fixes&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Fixed an issue where image/table spans were incorrectly filled into text blocks under certain conditions.&lt;/li&gt; 
     &lt;li&gt;Resolved an issue where title blocks were empty in some cases.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/01/22 1.1.0 released&lt;/summary&gt; 
  &lt;p&gt;In this version we have focused on improving parsing accuracy and efficiency:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Model capability upgrade&lt;/strong&gt; (requires re-executing the &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/how_to_download_models_en.md"&gt;model download process&lt;/a&gt; to obtain incremental updates of model files) 
    &lt;ul&gt; 
     &lt;li&gt;The layout recognition model has been upgraded to the latest &lt;code&gt;doclayout_yolo(2501)&lt;/code&gt; model, improving layout recognition accuracy.&lt;/li&gt; 
     &lt;li&gt;The formula parsing model has been upgraded to the latest &lt;code&gt;unimernet(2501)&lt;/code&gt; model, improving formula recognition accuracy.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Performance optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;On devices that meet certain configuration requirements (16GB+ VRAM), by optimizing resource usage and restructuring the processing pipeline, overall parsing speed has been increased by more than 50%.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Parsing effect optimization&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Added a new heading classification feature (testing version, enabled by default) to the online demo (&lt;a href="https://mineru.net/OpenSourceTools/Extractor"&gt;mineru.net&lt;/a&gt;/&lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;huggingface&lt;/a&gt;/&lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;modelscope&lt;/a&gt;), which supports hierarchical classification of headings, thereby enhancing document structuring.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2025/01/10 1.0.1 released&lt;/summary&gt; 
  &lt;p&gt;This is our first official release, where we have introduced a completely new API interface and enhanced compatibility through extensive refactoring, as well as a brand new automatic language identification feature:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;New API Interface&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;For the data-side API, we have introduced the Dataset class, designed to provide a robust and flexible data processing framework. This framework currently supports a variety of document formats, including images (.jpg and .png), PDFs, Word documents (.doc and .docx), and PowerPoint presentations (.ppt and .pptx). It ensures effective support for data processing tasks ranging from simple to complex.&lt;/li&gt; 
     &lt;li&gt;For the user-side API, we have meticulously designed the MinerU processing workflow as a series of composable Stages. Each Stage represents a specific processing step, allowing users to define new Stages according to their needs and creatively combine these stages to customize their data processing workflows.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Enhanced Compatibility&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;By optimizing the dependency environment and configuration items, we ensure stable and efficient operation on ARM architecture Linux systems.&lt;/li&gt; 
     &lt;li&gt;We have deeply integrated with Huawei Ascend NPU acceleration, providing autonomous and controllable high-performance computing capabilities. This supports the localization and development of AI application platforms in China. &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/README_Ascend_NPU_Acceleration_zh_CN.md"&gt;Ascend NPU Acceleration&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Automatic Language Identification&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;By introducing a new language recognition model, setting the &lt;code&gt;lang&lt;/code&gt; configuration to &lt;code&gt;auto&lt;/code&gt; during document parsing will automatically select the appropriate OCR language model, improving the accuracy of scanned document parsing.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/22 0.10.0 released&lt;/summary&gt; 
  &lt;p&gt;Introducing hybrid OCR text extraction capabilities:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Significantly improved parsing performance in complex text distribution scenarios such as dense formulas, irregular span regions, and text represented by images.&lt;/li&gt; 
   &lt;li&gt;Combines the dual advantages of accurate content extraction and faster speed in text mode, and more precise span/line region recognition in OCR mode.&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/15 0.9.3 released&lt;/summary&gt; 
  &lt;p&gt;Integrated &lt;a href="https://github.com/RapidAI/RapidTable"&gt;RapidTable&lt;/a&gt; for table recognition, improving single-table parsing speed by more than 10 times, with higher accuracy and lower GPU memory usage.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/11/06 0.9.2 released&lt;/summary&gt; 
  &lt;p&gt;Integrated the &lt;a href="https://huggingface.co/U4R/StructTable-InternVL2-1B"&gt;StructTable-InternVL2-1B&lt;/a&gt; model for table recognition functionality.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/10/31 0.9.0 released&lt;/summary&gt; 
  &lt;p&gt;This is a major new version with extensive code refactoring, addressing numerous issues, improving performance, reducing hardware requirements, and enhancing usability:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Refactored the sorting module code to use &lt;a href="https://github.com/ppaanngggg/layoutreader"&gt;layoutreader&lt;/a&gt; for reading order sorting, ensuring high accuracy in various layouts.&lt;/li&gt; 
   &lt;li&gt;Refactored the paragraph concatenation module to achieve good results in cross-column, cross-page, cross-figure, and cross-table scenarios.&lt;/li&gt; 
   &lt;li&gt;Refactored the list and table of contents recognition functions, significantly improving the accuracy of list blocks and table of contents blocks, as well as the parsing of corresponding text paragraphs.&lt;/li&gt; 
   &lt;li&gt;Refactored the matching logic for figures, tables, and descriptive text, greatly enhancing the accuracy of matching captions and footnotes to figures and tables, and reducing the loss rate of descriptive text to near zero.&lt;/li&gt; 
   &lt;li&gt;Added multi-language support for OCR, supporting detection and recognition of 84 languages. For the list of supported languages, see &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/ppocr/blog/multi_languages.html#5-support-languages-and-abbreviations"&gt;OCR Language Support List&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Added memory recycling logic and other memory optimization measures, significantly reducing memory usage. The memory requirement for enabling all acceleration features except table acceleration (layout/formula/OCR) has been reduced from 16GB to 8GB, and the memory requirement for enabling all acceleration features has been reduced from 24GB to 10GB.&lt;/li&gt; 
   &lt;li&gt;Optimized configuration file feature switches, adding an independent formula detection switch to significantly improve speed and parsing results when formula detection is not needed.&lt;/li&gt; 
   &lt;li&gt;Integrated &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit 1.0&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Added the self-developed &lt;code&gt;doclayout_yolo&lt;/code&gt; model, which speeds up processing by more than 10 times compared to the original solution while maintaining similar parsing effects, and can be freely switched with &lt;code&gt;layoutlmv3&lt;/code&gt; via the configuration file.&lt;/li&gt; 
     &lt;li&gt;Upgraded formula parsing to &lt;code&gt;unimernet 0.2.1&lt;/code&gt;, improving formula parsing accuracy while significantly reducing memory usage.&lt;/li&gt; 
     &lt;li&gt;Due to the repository change for &lt;code&gt;PDF-Extract-Kit 1.0&lt;/code&gt;, you need to re-download the model. Please refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/docs/how_to_download_models_en.md"&gt;How to Download Models&lt;/a&gt; for detailed steps.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/09/27 Version 0.8.1 released&lt;/summary&gt; 
  &lt;p&gt;Fixed some bugs, and providing a &lt;a href="https://github.com/opendatalab/MinerU/raw/master/projects/web_demo/README.md"&gt;localized deployment version&lt;/a&gt; of the &lt;a href="https://opendatalab.com/OpenSourceTools/Extractor/PDF/"&gt;online demo&lt;/a&gt; and the &lt;a href="https://github.com/opendatalab/MinerU/raw/master/projects/web/README.md"&gt;front-end interface&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/09/09 Version 0.8.0 released&lt;/summary&gt; 
  &lt;p&gt;Supporting fast deployment with Dockerfile, and launching demos on Huggingface and Modelscope.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/30 Version 0.7.1 released&lt;/summary&gt; 
  &lt;p&gt;Add paddle tablemaster table recognition option&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/09 Version 0.7.0b1 released&lt;/summary&gt; 
  &lt;p&gt;Simplified installation process, added table recognition functionality&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/08/01 Version 0.6.2b1 released&lt;/summary&gt; 
  &lt;p&gt;Optimized dependency conflict issues and installation documentation&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;2024/07/05 Initial open-source release&lt;/summary&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;h1&gt;MinerU&lt;/h1&gt; 
&lt;h2&gt;Project Introduction&lt;/h2&gt; 
&lt;p&gt;MinerU is a tool that converts PDFs into machine-readable formats (e.g., markdown, JSON), allowing for easy extraction into any format. MinerU was born during the pre-training process of &lt;a href="https://github.com/InternLM/InternLM"&gt;InternLM&lt;/a&gt;. We focus on solving symbol conversion issues in scientific literature and hope to contribute to technological development in the era of large models. Compared to well-known commercial products, MinerU is still young. If you encounter any issues or if the results are not as expected, please submit an issue on &lt;a href="https://github.com/opendatalab/MinerU/issues"&gt;issue&lt;/a&gt; and &lt;strong&gt;attach the relevant PDF&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4bea02c9-6d54-4cd6-97ed-dff14340982c"&gt;https://github.com/user-attachments/assets/4bea02c9-6d54-4cd6-97ed-dff14340982c&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove headers, footers, footnotes, page numbers, etc., to ensure semantic coherence.&lt;/li&gt; 
 &lt;li&gt;Output text in human-readable order, suitable for single-column, multi-column, and complex layouts.&lt;/li&gt; 
 &lt;li&gt;Preserve the structure of the original document, including headings, paragraphs, lists, etc.&lt;/li&gt; 
 &lt;li&gt;Extract images, image descriptions, tables, table titles, and footnotes.&lt;/li&gt; 
 &lt;li&gt;Automatically recognize and convert formulas in the document to LaTeX format.&lt;/li&gt; 
 &lt;li&gt;Automatically recognize and convert tables in the document to HTML format.&lt;/li&gt; 
 &lt;li&gt;Automatically detect scanned PDFs and garbled PDFs and enable OCR functionality.&lt;/li&gt; 
 &lt;li&gt;OCR supports detection and recognition of 84 languages.&lt;/li&gt; 
 &lt;li&gt;Supports multiple output formats, such as multimodal and NLP Markdown, JSON sorted by reading order, and rich intermediate formats.&lt;/li&gt; 
 &lt;li&gt;Supports various visualization results, including layout visualization and span visualization, for efficient confirmation of output quality.&lt;/li&gt; 
 &lt;li&gt;Supports running in a pure CPU environment, and also supports GPU(CUDA)/NPU(CANN)/MPS acceleration&lt;/li&gt; 
 &lt;li&gt;Compatible with Windows, Linux, and Mac platforms.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;p&gt;If you encounter any installation issues, please first consult the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/#faq"&gt;FAQ&lt;/a&gt;. &lt;br&gt; If the parsing results are not as expected, refer to the &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/#known-issues"&gt;Known Issues&lt;/a&gt;. &lt;br&gt;&lt;/p&gt; 
&lt;h2&gt;Online Experience&lt;/h2&gt; 
&lt;h3&gt;Official online web application&lt;/h3&gt; 
&lt;p&gt;The official online version has the same functionality as the client, with a beautiful interface and rich features, requires login to use&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mineru.net/OpenSourceTools/Extractor?source=github"&gt;&lt;img src="https://img.shields.io/badge/webapp_on_mineru.net-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTM0IiBoZWlnaHQ9IjEzNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJtMTIyLDljMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0idXJsKCNhKSIvPjxwYXRoIGQ9Im0xMjIsOWMwLDUtNCw5LTksOXMtOS00LTktOSw0LTksOS05LDksNCw5LDl6IiBmaWxsPSIjMDEwMTAxIi8+PHBhdGggZD0ibTkxLDE4YzAsNS00LDktOSw5cy05LTQtOS05LDQtOSw5LTksOSw0LDksOXoiIGZpbGw9InVybCgjYikiLz48cGF0aCBkPSJtOTEsMThjMCw1LTQsOS05LDlzLTktNC05LTksNC05LDktOSw5LDQsOSw5eiIgZmlsbD0iIzAxMDEwMSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0idXJsKCNjKSIvPjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJtMzksNjJjMCwxNiw4LDMwLDIwLDM4LDctNiwxMi0xNiwxMi0yNlY0OWMwLTQsMy03LDYtOGw0Ni0xMmM1LTEsMTEsMywxMSw4djMxYzAsMzctMzAsNjYtNjYsNjYtMzcsMC02Ni0zMC02Ni02NlY0NmMwLTQsMy03LDYtOGwyMC02YzUtMSwxMSwzLDExLDh2MjF6bS0yOSw2YzAsMTYsNiwzMCwxNyw0MCwzLDEsNSwxLDgsMSw1LDAsMTAtMSwxNS0zQzM3LDk1LDI5LDc5LDI5LDYyVjQybC0xOSw1djIweiIgZmlsbD0iIzAxMDEwMSIvPjxkZWZzPjxsaW5lYXJHcmFkaWVudCBpZD0iYSIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYiIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjxsaW5lYXJHcmFkaWVudCBpZD0iYyIgeDE9Ijg0IiB5MT0iNDEiIHgyPSI3NSIgeTI9IjEyMCIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiNmZmYiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiMyZTJlMmUiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=&amp;amp;labelColor=white" alt="OpenDataLab"&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Gradio-based online demo&lt;/h3&gt; 
&lt;p&gt;A WebUI developed based on Gradio, with a simple interface and only core parsing functionality, no login required&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/OpenDataLab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-yellow.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAF8AAABYCAMAAACkl9t/AAAAk1BMVEVHcEz/nQv/nQv/nQr/nQv/nQr/nQv/nQv/nQr/wRf/txT/pg7/yRr/rBD/zRz/ngv/oAz/zhz/nwv/txT/ngv/0B3+zBz/nQv/0h7/wxn/vRb/thXkuiT/rxH/pxD/ogzcqyf/nQvTlSz/czCxky7/SjifdjT/Mj3+Mj3wMj15aTnDNz+DSD9RTUBsP0FRO0Q6O0WyIxEIAAAAGHRSTlMADB8zSWF3krDDw8TJ1NbX5efv8ff9/fxKDJ9uAAAGKklEQVR42u2Z63qjOAyGC4RwCOfB2JAGqrSb2WnTw/1f3UaWcSGYNKTdf/P+mOkTrE+yJBulvfvLT2A5ruenaVHyIks33npl/6C4s/ZLAM45SOi/1FtZPyFur1OYofBX3w7d54Bxm+E8db+nDr12ttmESZ4zludJEG5S7TO72YPlKZFyE+YCYUJTBZsMiNS5Sd7NlDmKM2Eg2JQg8awbglfqgbhArjxkS7dgp2RH6hc9AMLdZYUtZN5DJr4molC8BfKrEkPKEnEVjLbgW1fLy77ZVOJagoIcLIl+IxaQZGjiX597HopF5CkaXVMDO9Pyix3AFV3kw4lQLCbHuMovz8FallbcQIJ5Ta0vks9RnolbCK84BtjKRS5uA43hYoZcOBGIG2Epbv6CvFVQ8m8loh66WNySsnN7htL58LNp+NXT8/PhXiBXPMjLSxtwp8W9f/1AngRierBkA+kk/IpUSOeKByzn8y3kAAAfh//0oXgV4roHm/kz4E2z//zRc3/lgwBzbM2mJxQEa5pqgX7d1L0htrhx7LKxOZlKbwcAWyEOWqYSI8YPtgDQVjpB5nvaHaSnBaQSD6hweDi8PosxD6/PT09YY3xQA7LTCTKfYX+QHpA0GCcqmEHvr/cyfKQTEuwgbs2kPxJEB0iNjfJcCTPyocx+A0griHSmADiC91oNGVwJ69RudYe65vJmoqfpul0lrqXadW0jFKH5BKwAeCq+Den7s+3zfRJzA61/Uj/9H/VzLKTx9jFPPdXeeP+L7WEvDLAKAIoF8bPTKT0+TM7W8ePj3Rz/Yn3kOAp2f1Kf0Weony7pn/cPydvhQYV+eFOfmOu7VB/ViPe34/EN3RFHY/yRuT8ddCtMPH/McBAT5s+vRde/gf2c/sPsjLK+m5IBQF5tO+h2tTlBGnP6693JdsvofjOPnnEHkh2TnV/X1fBl9S5zrwuwF8NFrAVJVwCAPTe8gaJlomqlp0pv4Pjn98tJ/t/fL++6unpR1YGC2n/KCoa0tTLoKiEeUPDl94nj+5/Tv3/eT5vBQ60X1S0oZr+IWRR8Ldhu7AlLjPISlJcO9vrFotky9SpzDequlwEir5beYAc0R7D9KS1DXva0jhYRDXoExPdc6yw5GShkZXe9QdO/uOvHofxjrV/TNS6iMJS+4TcSTgk9n5agJdBQbB//IfF/HpvPt3Tbi7b6I6K0R72p6ajryEJrENW2bbeVUGjfgoals4L443c7BEE4mJO2SpbRngxQrAKRudRzGQ8jVOL2qDVjjI8K1gc3TIJ5KiFZ1q+gdsARPB4NQS4AjwVSt72DSoXNyOWUrU5mQ9nRYyjp89Xo7oRI6Bga9QNT1mQ/ptaJq5T/7WcgAZywR/XlPGAUDdet3LE+qS0TI+g+aJU8MIqjo0Kx8Ly+maxLjJmjQ18rA0YCkxLQbUZP1WqdmyQGJLUm7VnQFqodmXSqmRrdVpqdzk5LvmvgtEcW8PMGdaS23EOWyDVbACZzUJPaqMbjDxpA3Qrgl0AikimGDbqmyT8P8NOYiqrldF8rX+YN7TopX4UoHuSCYY7cgX4gHwclQKl1zhx0THf+tCAUValzjI7Wg9EhptrkIcfIJjA94evOn8B2eHaVzvBrnl2ig0So6hvPaz0IGcOvTHvUIlE2+prqAxLSQxZlU2stql1NqCCLdIiIN/i1DBEHUoElM9dBravbiAnKqgpi4IBkw+utSPIoBijDXJipSVV7MpOEJUAc5Qmm3BnUN+w3hteEieYKfRZSIUcXKMVf0u5wD4EwsUNVvZOtUT7A2GkffHjByWpHqvRBYrTV72a6j8zZ6W0DTE86Hn04bmyWX3Ri9WH7ZU6Q7h+ZHo0nHUAcsQvVhXRDZHChwiyi/hnPuOsSEF6Exk3o6Y9DT1eZ+6cASXk2Y9k+6EOQMDGm6WBK10wOQJCBwren86cPPWUcRAnTVjGcU1LBgs9FURiX/e6479yZcLwCBmTxiawEwrOcleuu12t3tbLv/N4RLYIBhYexm7Fcn4OJcn0+zc+s8/VfPeddZHAGN6TT8eGczHdR/Gts1/MzDkThr23zqrVfAMFT33Nx1RJsx1k5zuWILLnG/vsH+Fv5D4NTVcp1Gzo8AAAAAElFTkSuQmCC&amp;amp;labelColor=white" alt="HuggingFace"&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Local Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Pre-installation Notice—Hardware and Software Environment Support&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;To ensure the stability and reliability of the project, we only optimize and test for specific hardware and software environments during development. This ensures that users deploying and running the project on recommended system configurations will get the best performance with the fewest compatibility issues.&lt;/p&gt; 
 &lt;p&gt;By focusing resources on the mainline environment, our team can more efficiently resolve potential bugs and develop new features.&lt;/p&gt; 
 &lt;p&gt;In non-mainline environments, due to the diversity of hardware and software configurations, as well as third-party dependency compatibility issues, we cannot guarantee 100% project availability. Therefore, for users who wish to use this project in non-recommended environments, we suggest carefully reading the documentation and FAQ first. Most issues already have corresponding solutions in the FAQ. We also encourage community feedback to help us gradually expand support.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;Parsing Backend&lt;/td&gt; 
   &lt;td&gt;pipeline&lt;/td&gt; 
   &lt;td&gt;vlm-transformers&lt;/td&gt; 
   &lt;td&gt;vlm-sglang&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating System&lt;/td&gt; 
   &lt;td&gt;Linux / Windows / macOS&lt;/td&gt; 
   &lt;td&gt;Linux / Windows&lt;/td&gt; 
   &lt;td&gt;Linux / Windows (via WSL2)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Inference Support&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td colspan="2"&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Requirements&lt;/td&gt; 
   &lt;td&gt;Turing architecture and later, 6GB+ VRAM or Apple Silicon&lt;/td&gt; 
   &lt;td colspan="2"&gt;Turing architecture and later, 8GB+ VRAM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory Requirements&lt;/td&gt; 
   &lt;td colspan="3"&gt;Minimum 16GB+, recommended 32GB+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Disk Space Requirements&lt;/td&gt; 
   &lt;td colspan="3"&gt;20GB+, SSD recommended&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python Version&lt;/td&gt; 
   &lt;td colspan="3"&gt;3.10-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Install MinerU&lt;/h3&gt; 
&lt;h4&gt;Install MinerU using pip or uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install uv
uv pip install -U "mineru[core]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install MinerU from source code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/opendatalab/MinerU.git
cd MinerU
uv pip install -e .[core]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;code&gt;mineru[core]&lt;/code&gt; includes all core features except &lt;code&gt;sglang&lt;/code&gt; acceleration, compatible with Windows / Linux / macOS systems, suitable for most users. If you need to use &lt;code&gt;sglang&lt;/code&gt; acceleration for VLM model inference or install a lightweight client on edge devices, please refer to the documentation &lt;a href="https://opendatalab.github.io/MinerU/quick_start/extension_modules/"&gt;Extension Modules Installation Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr&gt; 
&lt;h4&gt;Deploy MinerU using Docker&lt;/h4&gt; 
&lt;p&gt;MinerU provides a convenient Docker deployment method, which helps quickly set up the environment and solve some tricky environment compatibility issues. You can get the &lt;a href="https://opendatalab.github.io/MinerU/quick_start/docker_deployment/"&gt;Docker Deployment Instructions&lt;/a&gt; in the documentation.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Using MinerU&lt;/h3&gt; 
&lt;p&gt;The simplest command line invocation is:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mineru -p &amp;lt;input_path&amp;gt; -o &amp;lt;output_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can use MinerU for PDF parsing through various methods such as command line, API, and WebUI. For detailed instructions, please refer to the &lt;a href="https://opendatalab.github.io/MinerU/usage/"&gt;Usage Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;TODO&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Reading order based on the model&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Recognition of &lt;code&gt;index&lt;/code&gt; and &lt;code&gt;list&lt;/code&gt; in the main text&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Table recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Heading Classification&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Handwritten Text Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Vertical Text Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Latin Accent Mark Recognition&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Code block recognition in the main text&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; &lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/docs/chemical_knowledge_introduction/introduction.pdf"&gt;Chemical formula recognition&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Geometric shape recognition&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Known Issues&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reading order is determined by the model based on the spatial distribution of readable content, and may be out of order in some areas under extremely complex layouts.&lt;/li&gt; 
 &lt;li&gt;Limited support for vertical text.&lt;/li&gt; 
 &lt;li&gt;Tables of contents and lists are recognized through rules, and some uncommon list formats may not be recognized.&lt;/li&gt; 
 &lt;li&gt;Code blocks are not yet supported in the layout model.&lt;/li&gt; 
 &lt;li&gt;Comic books, art albums, primary school textbooks, and exercises cannot be parsed well.&lt;/li&gt; 
 &lt;li&gt;Table recognition may result in row/column recognition errors in complex tables.&lt;/li&gt; 
 &lt;li&gt;OCR recognition may produce inaccurate characters in PDFs of lesser-known languages (e.g., diacritical marks in Latin script, easily confused characters in Arabic script).&lt;/li&gt; 
 &lt;li&gt;Some formulas may not render correctly in Markdown.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you encounter any issues during usage, you can first check the &lt;a href="https://opendatalab.github.io/MinerU/faq/"&gt;FAQ&lt;/a&gt; for solutions.&lt;/li&gt; 
 &lt;li&gt;If your issue remains unresolved, you may also use &lt;a href="https://deepwiki.com/opendatalab/MinerU"&gt;DeepWiki&lt;/a&gt; to interact with an AI assistant, which can address most common problems.&lt;/li&gt; 
 &lt;li&gt;If you still cannot resolve the issue, you are welcome to join our community via &lt;a href="https://discord.gg/Tdedn9GTXq"&gt;Discord&lt;/a&gt; or &lt;a href="http://mineru.space/s/V85Yl"&gt;WeChat&lt;/a&gt; to discuss with other users and developers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;All Thanks To Our Contributors&lt;/h1&gt; 
&lt;a href="https://github.com/opendatalab/MinerU/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=opendatalab/MinerU"&gt; &lt;/a&gt; 
&lt;h1&gt;License Information&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/opendatalab/MinerU/master/LICENSE.md"&gt;LICENSE.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Currently, some models in this project are trained based on YOLO. However, since YOLO follows the AGPL license, it may impose restrictions on certain use cases. In future iterations, we plan to explore and replace these with models under more permissive licenses to enhance user-friendliness and flexibility.&lt;/p&gt; 
&lt;h1&gt;Acknowledgments&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/DocLayout-YOLO"&gt;DocLayout-YOLO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/UniMERNet"&gt;UniMERNet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RapidAI/RapidTable"&gt;RapidTable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;PaddleOCR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frotms/PaddleOCR2Pytorch"&gt;PaddleOCR2Pytorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ppaanngggg/layoutreader"&gt;layoutreader&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Sanster/xy-cut"&gt;xy-cut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LlmKira/fast-langdetect"&gt;fast-langdetect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypdfium2-team/pypdfium2"&gt;pypdfium2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datalab-to/pdftext"&gt;pdftext&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdfminer/pdfminer.six"&gt;pdfminer.six&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/py-pdf/pypdf"&gt;pypdf&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Citation&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2024mineruopensourcesolutionprecise,
      title={MinerU: An Open-Source Solution for Precise Document Content Extraction}, 
      author={Bin Wang and Chao Xu and Xiaomeng Zhao and Linke Ouyang and Fan Wu and Zhiyuan Zhao and Rui Xu and Kaiwen Liu and Yuan Qu and Fukai Shang and Bo Zhang and Liqun Wei and Zhihao Sui and Wei Li and Botian Shi and Yu Qiao and Dahua Lin and Conghui He},
      year={2024},
      eprint={2409.18839},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.18839}, 
}

@article{he2024opendatalab,
  title={Opendatalab: Empowering general artificial intelligence with open datasets},
  author={He, Conghui and Li, Wei and Jin, Zhenjiang and Xu, Chao and Wang, Bin and Lin, Dahua},
  journal={arXiv preprint arXiv:2407.13773},
  year={2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;a&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date&amp;amp;theme=dark"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date"&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=opendatalab/MinerU&amp;amp;type=Date"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Links&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenDCAI/DataFlow"&gt;Easy Data Preparation with latest LLMs-based Operators and Pipelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/Vis3"&gt;Vis3 (OSS browser based on s3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/labelU"&gt;LabelU (A Lightweight Multi-modal Data Annotation Tool)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/LabelLLM"&gt;LabelLLM (An Open-source LLM Dialogue Annotation Platform)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit (A Comprehensive Toolkit for High-Quality PDF Content Extraction)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/OmniDocBench"&gt;OmniDocBench (A Comprehensive Benchmark for Document Parsing and Evaluation)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opendatalab/magic-html"&gt;Magic-HTML (Mixed web page extraction tool)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/magic-doc"&gt;Magic-Doc (Fast speed ppt/pptx/doc/docx/pdf extraction tool)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>commaai/openpilot</title>
      <link>https://github.com/commaai/openpilot</link>
      <description>&lt;p&gt;openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-align: center;"&gt; 
 &lt;h1&gt;openpilot&lt;/h1&gt; 
 &lt;p&gt; &lt;b&gt;openpilot is an operating system for robotics.&lt;/b&gt; &lt;br&gt; Currently, it upgrades the driver assistance system in 300+ supported cars. &lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://docs.comma.ai"&gt;Docs&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://docs.comma.ai/contributing/roadmap/"&gt;Roadmap&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://discord.comma.ai"&gt;Community&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://comma.ai/shop"&gt;Try it on a comma 3X&lt;/a&gt; &lt;/h3&gt; 
 &lt;p&gt;Quick start: &lt;code&gt;bash &amp;lt;(curl -fsSL openpilot.comma.ai)&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml"&gt;&lt;img src="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml/badge.svg?sanitize=true" alt="openpilot tests"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT"&gt;&lt;/a&gt; &lt;a href="https://x.com/comma_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/comma_ai" alt="X Follow"&gt;&lt;/a&gt; &lt;a href="https://discord.comma.ai"&gt;&lt;img src="https://img.shields.io/discord/469524606043160576" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/NmBfgOanCyk" title="Video By Greer Viau"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/2f7112ae-f748-4f39-b617-fabd689c3772"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/VHKyqZ7t8Gw" title="Video By Logan LeGrand"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/92351544-2833-40d7-9e0b-7ef7ae37ec4c"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/SUIZYzxtMQs" title="A drive to Taco Bell"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/05ceefc5-2628-439c-a9b2-89ce77dc6f63"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Using openpilot in a car&lt;/h2&gt; 
&lt;p&gt;To use openpilot in a car, you need four things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Device:&lt;/strong&gt; a comma 3/3X, available at &lt;a href="https://comma.ai/shop/comma-3x"&gt;comma.ai/shop&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Software:&lt;/strong&gt; The setup procedure for the comma 3/3X allows users to enter a URL for custom software. Use the URL &lt;code&gt;openpilot.comma.ai&lt;/code&gt; to install the release version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Car:&lt;/strong&gt; Ensure that you have one of &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CARS.md"&gt;the 275+ supported cars&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Car Harness:&lt;/strong&gt; You will also need a &lt;a href="https://comma.ai/shop/car-harness"&gt;car harness&lt;/a&gt; to connect your comma 3/3X to your car.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We have detailed instructions for &lt;a href="https://comma.ai/setup"&gt;how to install the harness and device in a car&lt;/a&gt;. Note that it's possible to run openpilot on &lt;a href="https://blog.comma.ai/self-driving-car-for-free/"&gt;other hardware&lt;/a&gt;, although it's not plug-and-play.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;branch&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is openpilot's release branch.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3-staging&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-test.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the staging branch for releases. Use it to get new releases slightly early.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-nightly.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the bleeding edge development branch. Do not expect this to be stable.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly-dev&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;installer.comma.ai/commaai/nightly-dev&lt;/td&gt; 
   &lt;td&gt;Same as nightly, but includes experimental development features for some cars.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;secretgoodopenpilot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;installer.comma.ai/commaai/secretgoodopenpilot&lt;/td&gt; 
   &lt;td&gt;This is a preview branch from the autonomy team where new driving models get merged earlier than master.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;To start developing openpilot&lt;/h2&gt; 
&lt;p&gt;openpilot is developed by &lt;a href="https://comma.ai/"&gt;comma&lt;/a&gt; and by users like you. We welcome both pull requests and issues on &lt;a href="http://github.com/commaai/openpilot"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://discord.comma.ai"&gt;community Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CONTRIBUTING.md"&gt;the contributing docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/tools/"&gt;openpilot tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Code documentation lives at &lt;a href="https://docs.comma.ai"&gt;https://docs.comma.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Information about running openpilot lives on the &lt;a href="https://github.com/commaai/openpilot/wiki"&gt;community wiki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to get paid to work on openpilot? &lt;a href="https://comma.ai/jobs#open-positions"&gt;comma is hiring&lt;/a&gt; and offers lots of &lt;a href="https://comma.ai/bounties"&gt;bounties&lt;/a&gt; for external contributors.&lt;/p&gt; 
&lt;h2&gt;Safety and Testing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;openpilot observes &lt;a href="https://en.wikipedia.org/wiki/ISO_26262"&gt;ISO26262&lt;/a&gt; guidelines, see &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/SAFETY.md"&gt;SAFETY.md&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;openpilot has software-in-the-loop &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/.github/workflows/selfdrive_tests.yaml"&gt;tests&lt;/a&gt; that run on every commit.&lt;/li&gt; 
 &lt;li&gt;The code enforcing the safety model lives in panda and is written in C, see &lt;a href="https://github.com/commaai/panda#code-rigor"&gt;code rigor&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;panda has software-in-the-loop &lt;a href="https://github.com/commaai/panda/tree/master/tests/safety"&gt;safety tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.&lt;/li&gt; 
 &lt;li&gt;panda has additional hardware-in-the-loop &lt;a href="https://github.com/commaai/panda/raw/master/Jenkinsfile"&gt;tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;MIT Licensed&lt;/summary&gt; 
 &lt;p&gt;openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.&lt;/p&gt; 
 &lt;p&gt;Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;User Data and comma Account&lt;/summary&gt; 
 &lt;p&gt;By default, openpilot uploads the driving data to our servers. You can also access your data through &lt;a href="https://connect.comma.ai/"&gt;comma connect&lt;/a&gt;. We use your data to train better models and improve openpilot for everyone.&lt;/p&gt; 
 &lt;p&gt;openpilot is open source software: the user is free to disable data collection if they wish to do so.&lt;/p&gt; 
 &lt;p&gt;openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera and microphone are only logged if you explicitly opt-in in settings.&lt;/p&gt; 
 &lt;p&gt;By using openpilot, you agree to &lt;a href="https://comma.ai/privacy"&gt;our Privacy Policy&lt;/a&gt;. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you’ll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta – expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin’s YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it’ll be featured through agents on the platform. It’s a tall order, but we have big plans for the oTTomator community, and we’re confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;© 2024 Live Agent Studio. All rights reserved.&lt;br&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/WebAgent</title>
      <link>https://github.com/Alibaba-NLP/WebAgent</link>
      <description>&lt;p&gt;🌐 WebAgent for Information Seeking built by Tongyi Lab: WebWalker &amp; WebDancer &amp; WebSailor &amp; WebShaper https://arxiv.org/abs/2507.15061 https://arxiv.org/pdf/2507.02592&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;WebAgent for Information Seeking built by Tongyi Lab, Alibaba Group &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="30px" style="display:inline;"&gt;&lt;/h2&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/datasets/Alibaba-NLP/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/datasets/iic/WebShaper" target="_blank"&gt;WebShaperQA&lt;/a&gt; ｜ 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B" target="_blank"&gt;WebSailor-3B&lt;/a&gt; ｜ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebSailor-3B" target="_blank"&gt;ModelScope WebSailor-3B&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; 🤗 &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B" target="_blank"&gt;WebDancer-QwQ-32B&lt;/a&gt; | &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/tongyi.png" width="14px" style="display:inline;"&gt; &lt;a href="https://modelscope.cn/models/iic/WebDancer-32B" target="_blank"&gt;ModelScope WebDancer-QwQ-32B&lt;/a&gt; | 🤗 &lt;a href="https://huggingface.co/datasets/callanwu/WebWalkerQA" target="_blank"&gt;WebWalkerQA&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/roadmap.png" width="100%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can check the paper of &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💥 💥 💥 Stay tuned for more updates! We are working on building native agentic model based on the Browser and more open-domain environments!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebShaper"&gt;&lt;strong&gt;WebShaper&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor"&gt;&lt;strong&gt;WebSailor&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;strong&gt;WebDancer&lt;/strong&gt;&lt;/a&gt; (Preprint 2025) - WebDancer: Towards Autonomous Information Seeking Agency&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebWalker"&gt;&lt;strong&gt;WebWalker&lt;/strong&gt;&lt;/a&gt; (ACL 2025) - WebWalker: Benchmarking LLMs in Web Traversal&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📰 News and Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.22&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebShaper&lt;/strong&gt;: Agentically Data Synthesizing via Information-Seeking Formalization.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.11&lt;/code&gt; 🔥🔥🔥&lt;strong&gt;WebSailor-3B&lt;/strong&gt; is &lt;a href="https://huggingface.co/Alibaba-NLP/WebSailor-3B"&gt;released&lt;/a&gt;. You can deploy it with one click using &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/aliyun.png" width="14px" style="display:inline;"&gt; &lt;a href="https://functionai.console.aliyun.com/template-detail?template=Alibaba-NLP-WebSailor-3B"&gt;Alibaba Cloud's FunctionAI&lt;/a&gt; in ten minutes!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.07.03&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebSailor&lt;/strong&gt;, an agentic search model specialized in performing extremely complex information seeking tasks, achieving open-source SOTA on some of the most difficult browsing benchmarks. &lt;strong&gt;WebSailor&lt;/strong&gt; topped the HuggingFace &lt;a href="https://huggingface.co/papers/2507.02592"&gt;daily papers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.06.23&lt;/code&gt; 🔥🔥🔥The model, interactive demo, and some of the data of &lt;strong&gt;WebDancer&lt;/strong&gt; have been open-sourced. You're welcome to try them out!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.29&lt;/code&gt; 🔥🔥🔥We release &lt;strong&gt;WebDancer&lt;/strong&gt;, a native agentic search model towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.05.15&lt;/code&gt; &lt;strong&gt;WebWalker&lt;/strong&gt; is accepted by ACL 2025 main conference.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2025.01.14&lt;/code&gt; We release &lt;strong&gt;WebWalker&lt;/strong&gt;, a benchmark for LLMs in web traversal and a multi-agent framework for information seeking.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💎 Results Showcase&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-gaia.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/assets/webagent-bc.png" width="800%" height="400%"&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;💡 Features for WebShaper&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;strong&gt;&lt;code&gt;formalization-driven&lt;/code&gt;&lt;/strong&gt; data synthesis method for information-seeking agents, grounded in our proposed task formalization. Leveraging this method, we construct the &lt;strong&gt;WebShaper&lt;/strong&gt; dataset, which enables systematic generation of IS instances.&lt;/li&gt; 
 &lt;li&gt;We propose an agentic Expander that iteratively generates and validates questions in alignment with the formalization.&lt;/li&gt; 
 &lt;li&gt;We conduct extensive experiments across multiple benchmarks to evaluate the effectiveness of WebShaper. We achieve new state-of-the-art results on &lt;strong&gt;GAIA&lt;/strong&gt; (&lt;strong&gt;60.19&lt;/strong&gt;) and &lt;strong&gt;WebWalkerQA&lt;/strong&gt; (&lt;strong&gt;52.50&lt;/strong&gt;) benchmarks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;⛵️ Features for WebSailor&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A complete post-training methodology enabling models to engage in extended thinking and information seeking, ultimately allowing them to successfully complete extremely complex tasks previously considered unsolvable.&lt;/li&gt; 
 &lt;li&gt;Introduces &lt;strong&gt;SailorFog-QA&lt;/strong&gt;, a scalable QA benchmark with high uncertainty and difficulty, curated with a novel data synthesis method through graph sampling and information obfuscation. Example SailorFog-QA data samples can be found at: &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebSailor/dataset/sailorfog-QA.jsonl"&gt;&lt;code&gt;WebSailor/dataset/sailorfog-QA.jsonl&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Effective post-training pipeline consisting of (1) high-quality reconstruction of concise reasoning from expert trajectories for clean supervision, (2) a two-stage training process involving an RFT cold start stage, followed by &lt;strong&gt;Duplicating Sampling Policy Optimization (DUPO)&lt;/strong&gt;, an efficient agentic RL algorithm excelling in effectiveness and efficiency.&lt;/li&gt; 
 &lt;li&gt;WebSailor-72B significantly outperforms all open-source agents and frameworks while closing the performance gap with leading proprietary systems, achieving a score of &lt;strong&gt;12.0%&lt;/strong&gt; on BrowseComp-en, &lt;strong&gt;30.1%&lt;/strong&gt; on BrowseComp-zh, and &lt;strong&gt;55.4%&lt;/strong&gt; on GAIA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The checkpoint is coming soon.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌐 Features for WebDancer&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Native agentic search reasoning model using ReAct framework towards autonomous information seeking agency and &lt;em&gt;Deep Research&lt;/em&gt;-like model.&lt;/li&gt; 
 &lt;li&gt;We introduce a four-stage training paradigm comprising &lt;strong&gt;browsing data construction, trajectory sampling, supervised fine-tuning for effective cold start, and reinforcement learning for improved generalization&lt;/strong&gt;, enabling the agent to autonomously acquire autonomous search and reasoning skills.&lt;/li&gt; 
 &lt;li&gt;Our data-centric approach integrates trajectory-level supervision fine-tuning and reinforcement learning (DAPO) to develop a scalable pipeline for &lt;strong&gt;training agentic systems&lt;/strong&gt; via SFT or RL.&lt;/li&gt; 
 &lt;li&gt;WebDancer achieves a Pass@3 score of 64.1% on GAIA and 62.0% on WebWalkerQA.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;p&gt;You need to enter the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer"&gt;&lt;code&gt;WebDancer&lt;/code&gt;&lt;/a&gt; folder for the following commands.&lt;/p&gt; 
&lt;h3&gt;Step 0: Set Up the Environment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n webdancer python=3.12
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Deploy the Model&lt;/h3&gt; 
&lt;p&gt;Download the WebDancer model from &lt;a href="https://huggingface.co/Alibaba-NLP/WebDancer-32B"&gt;🤗 HuggingFace&lt;/a&gt; and deploy it using the provided scripts with &lt;a href="https://github.com/sgl-project/sglang"&gt;sglang&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash deploy_model.sh WebDancer_PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Replace &lt;code&gt;WebDancer_PATH&lt;/code&gt; with the actual path to the downloaded model.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Step 2: Run the Demo&lt;/h3&gt; 
&lt;p&gt;Edit the following keys in &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/WebDancer/scripts/run_demo.sh"&gt;&lt;code&gt;WebDancer/scripts/run_demo.sh&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GOOGLE_SEARCH_KEY&lt;/code&gt;, you can get it from &lt;a href="https://serper.dev/"&gt;serper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://jina.ai/api-dashboard/"&gt;jina&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DASHSCOPE_API_KEY&lt;/code&gt;, you can get it from &lt;a href="https://dashscope.aliyun.com/"&gt;dashscope&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, launch the demo with Gradio to interact with the WebDancer model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd scripts
bash run_demo.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🎥 WebSailor Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for BrowseComp-en, BrowseComp-zh and Daily Use. Our model can complete highly difficult and uncertain tasks requiring massive information acquisition and complex reasoning.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-en&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/2dc0b03a-c241-4f70-bf11-92fda28020fa"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;BrowseComp-zh&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/f9aed746-ffc8-4b76-b135-715ec0eab544"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/1299c5a8-cee3-4a70-b68b-c5d227cf8055"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎥 WebDancer Demos&lt;/h2&gt; 
&lt;p&gt;We provide demos for WebWalkerQA, GAIA and Daily Use. Our model can execute the long-horizon tasks with &lt;strong&gt;multiple steps&lt;/strong&gt; and &lt;strong&gt;complex reasoning&lt;/strong&gt;, such as web traversal, information seeking and question answering.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;WebWalkerQA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/0bbaf55b-897e-4c57-967d-a6e8bbd2167e"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;GAIA&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/935c668e-6169-4712-9c04-ac80f0531872"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;Daily Use&lt;/h3&gt; 
 &lt;video src="https://github.com/user-attachments/assets/d1d5b533-4009-478b-bd87-96b86389327d"&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;📃 License&lt;/h2&gt; 
&lt;p&gt;The content of this project itself is licensed under &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/WebAgent/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🚩 Citation&lt;/h2&gt; 
&lt;p&gt;If this work is helpful, please kindly cite as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bigquery"&gt;@misc{tao2025webshaper,
      title={WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization},
      author={Zhengwei Tao and Jialong Wu and Wenbiao Yin and Junkai Zhang and Baixuan Li and Haiyang Shen and Kuan Li and Liwen Zhang and Xinyu Wang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.15061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.15061},
}
@misc{li2025websailor,
      title={WebSailor: Navigating Super-human Reasoning for Web Agent},
      author={Kuan Li and Zhongwang Zhang and Huifeng Yin and Liwen Zhang and Litu Ou and Jialong Wu and Wenbiao Yin and Baixuan Li and Zhengwei Tao and Xinyu Wang and Weizhou Shen and Junkai Zhang and Dingchu Zhang and Xixi Wu and Yong Jiang and Ming Yan and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2507.02592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.02592},
}
@misc{wu2025webdancer,
      title={WebDancer: Towards Autonomous Information Seeking Agency},
      author={Jialong Wu and Baixuan Li and Runnan Fang and Wenbiao Yin and Liwen Zhang and Zhengwei Tao and Dingchu Zhang and Zekun Xi and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},
      year={2025},
      eprint={2505.22648},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.22648},
}
@misc{wu2025webwalker,
      title={WebWalker: Benchmarking LLMs in Web Traversal},
      author={Jialong Wu and Wenbiao Yin and Yong Jiang and Zhenglin Wang and Zekun Xi and Runnan Fang and Deyu Zhou and Pengjun Xie and Fei Huang},
      year={2025},
      eprint={2501.07572},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.07572},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🌟 Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/WebAgent&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/WebAgent&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🚩 Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;🔥🔥🔥 We are hiring! Research intern positions are open (based in Hangzhou、Beijing、Shanghai)&lt;/p&gt; 
&lt;p&gt;📚 &lt;strong&gt;Research Area&lt;/strong&gt;：Web Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;☎️ &lt;strong&gt;Contact&lt;/strong&gt;：&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.getzep.com/"&gt; &lt;img src="https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73" width="150" alt="Zep Logo"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align="center"&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/getzep/Graphiti/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat" alt="Lint"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true" alt="Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true" alt="MyPy Check"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/getzep/graphiti" alt="GitHub Repo stars"&gt; &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat" alt="arXiv"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/graphiti/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen" alt="Release"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12986" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12986" alt="getzep%2Fgraphiti | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif" alt="Graphiti temporal walkthrough" width="700px"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;"Kendra loves Adidas shoes."&lt;/em&gt; Each fact is a "triplet" represented by two entities, or nodes ("Kendra", "Adidas shoes"), and their relationship, or edge ("loves"). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep's Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href="https://www.getzep.com"&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we've demonstrated Zep is the &lt;a href="https://blog.getzep.com/state-of-the-art-agent-memory/"&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href="https://arxiv.org/abs/2501.13956"&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We're excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png" alt="Zep: A Temporal Knowledge Graph Architecture for Agent Memory" width="700px"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif" alt="Graphiti structured + unstructured demo" width="700px"&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href="https://neo4j.com/download/"&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti's ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md"&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j or FalkorDB database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti's knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md"&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="my_custom_database"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host="localhost",
    port=6379,
    username="falkor_user",  # Optional
    password="falkor_password",  # Optional
    database="my_custom_graph"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;USE_PARALLEL_RUNTIME&lt;/code&gt; is an optional boolean variable that can be set to true if you wish to enable Neo4j's parallel runtime feature for several of our search queries. Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances, as such this feature is off by default.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = "&amp;lt;your-api-key&amp;gt;"
api_version = "&amp;lt;your-api-version&amp;gt;"
llm_endpoint = "&amp;lt;your-llm-endpoint&amp;gt;"  # e.g., "https://your-llm-resource.openai.azure.com/"
embedding_endpoint = "&amp;lt;your-embedding-endpoint&amp;gt;"  # e.g., "https://your-embedding-resource.openai.azure.com/"

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model="gpt-4.1-nano",
    model="gpt-4.1-mini",
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=OpenAIClient(
        llm_config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model="text-embedding-3-small-deployment"  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        llm_config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google's Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you'll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add "graphiti-core[google-genai]"

# or

pip install "graphiti-core[google-genai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = "&amp;lt;your-google-api-key&amp;gt;"

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.0-flash"
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model="embedding-001"
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.5-flash-lite-preview-06-17"
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini's log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama's OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models: ollama pull deepseek-r1:7b # LLM ollama pull nomic-embed-text # embeddings&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key="abc",  # Ollama doesn't require a real API key
    model="deepseek-r1:7b",
    small_model="deepseek-r1:7b",
    base_url="http://localhost:11434/v1", # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key="abc",
            embedding_model="nomic-embed-text",
            embedding_dim=768,
            base_url="http://localhost:11434/v1",
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti"&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/lang-graph-agent"&gt;Building an agent with LangChain's LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here's exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you're using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don't Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py"&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ['GRAPHITI_TELEMETRY_ENABLED'] = 'false'

# Then initialize Graphiti as usual
from graphiti_core import Graphiti
graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it's code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>swisskyrepo/PayloadsAllTheThings</title>
      <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
      <description>&lt;p&gt;A list of useful payloads and bypass for Web Application Security and Pentest/CTF&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Payloads All The Things&lt;/h1&gt; 
&lt;p&gt;A list of useful payloads and bypasses for Web Application Security. Feel free to improve with your payloads and techniques ! I &lt;span&gt;❤️&lt;/span&gt; pull requests :)&lt;/p&gt; 
&lt;p&gt;You can also contribute with a &lt;span&gt;🍻&lt;/span&gt; IRL, or using the sponsor button&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/swisskyrepo"&gt;&lt;img src="https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;link=https://github.com/sponsors/swisskyrepo" alt="Sponsor"&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An alternative display version is available at &lt;a href="https://swisskyrepo.github.io/PayloadsAllTheThings/"&gt;PayloadsAllTheThingsWeb&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png" alt="banner"&gt; &lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;📖&lt;/span&gt; Documentation&lt;/h2&gt; 
&lt;p&gt;Every section contains the following files, you can use the &lt;code&gt;_template_vuln&lt;/code&gt; folder to create a new chapter:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;README.md - vulnerability description and how to exploit it, including several payloads&lt;/li&gt; 
 &lt;li&gt;Intruder - a set of files to give to Burp Intruder&lt;/li&gt; 
 &lt;li&gt;Images - pictures for the README.md&lt;/li&gt; 
 &lt;li&gt;Files - some files referenced in the README.md&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might also like the other projects from the AllTheThings family :&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/InternalAllTheThings/"&gt;InternalAllTheThings&lt;/a&gt; - Active Directory and Internal Pentest Cheatsheets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swisskyrepo.github.io/HardwareAllTheThings/"&gt;HardwareAllTheThings&lt;/a&gt; - Hardware/IOT Pentesting Wiki&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You want more ? Check the &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/BOOKS.md"&gt;Books&lt;/a&gt; and &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/_LEARNING_AND_SOCIALS/YOUTUBE.md"&gt;Youtube channel&lt;/a&gt; selections.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🧑💻&lt;/span&gt; Contributions&lt;/h2&gt; 
&lt;p&gt;Be sure to read &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;amp;max=36" alt="sponsors-list"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Thanks again for your contribution! &lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🍻&lt;/span&gt; Sponsors&lt;/h2&gt; 
&lt;p&gt;This project is proudly sponsored by these companies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Logo&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://serpapi.com"&gt;&lt;img src="https://avatars.githubusercontent.com/u/34724717?s=40&amp;amp;v=4" alt="sponsor-serpapi"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;SerpApi&lt;/strong&gt; is a real time API to access Google search results. It solves the issues of having to rent proxies, solving captchas, and JSON parsing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://projectdiscovery.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50994705?s=40&amp;amp;v=4" alt="sponsor-projectdiscovery"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ProjectDiscovery&lt;/strong&gt; - Detect real, exploitable vulnerabilities. Harness the power of Nuclei for fast and accurate findings without false positives.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.vaadata.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/48131541?s=40&amp;amp;v=4" alt="sponsor-vaadata"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;VAADATA&lt;/strong&gt; - Ethical Hacking Services&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Deep Research&lt;/h1&gt; 
&lt;img width="1388" height="298" alt="full_diagram" src="https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69"&gt; 
&lt;p&gt;Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read more in our &lt;a href="https://blog.langchain.com/open-deep-research/"&gt;blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See our &lt;a href="https://www.youtube.com/watch?v=agGiWUpxkhg"&gt;video&lt;/a&gt; for a quick overview&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository and activate a virtual environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install -r pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file to customize the environment variables (for model selection, search tools, and other configuration settings):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Launch the assistant with the LangGraph server locally to open LangGraph Studio in your browser:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use this to open the Studio UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- 🚀 API: http://127.0.0.1:2024
- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- 📚 API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="817" height="666" alt="Screenshot 2025-07-13 at 11 21 12 PM" src="https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f"&gt; 
&lt;p&gt;Ask a question in the &lt;code&gt;messages&lt;/code&gt; input field and click &lt;code&gt;Submit&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configurations&lt;/h3&gt; 
&lt;p&gt;Open Deep Research offers extensive configuration options to customize the research process and model behavior. All configurations can be set via the web UI, environment variables, or by modifying the configuration directly.&lt;/p&gt; 
&lt;h4&gt;General Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Max Structured Output Retries&lt;/strong&gt; (default: 3): Maximum number of retries for structured output calls from models when parsing fails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Allow Clarification&lt;/strong&gt; (default: true): Whether to allow the researcher to ask clarifying questions before starting research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Concurrent Research Units&lt;/strong&gt; (default: 5): Maximum number of research units to run concurrently using sub-agents. Higher values enable faster research but may hit rate limits&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Research Configuration&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search API&lt;/strong&gt; (default: Tavily): Choose from Tavily (works with all models), OpenAI Native Web Search, Anthropic Native Web Search, or None&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Researcher Iterations&lt;/strong&gt; (default: 3): Number of times the Research Supervisor will reflect on research and ask follow-up questions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max React Tool Calls&lt;/strong&gt; (default: 5): Maximum number of tool calling iterations in a single researcher step&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Models&lt;/h4&gt; 
&lt;p&gt;Open Deep Research uses multiple specialized models for different research tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Summarization Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-nano&lt;/code&gt;): Summarizes research results from search APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Conducts research and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-mini&lt;/code&gt;): Compresses research findings from sub-agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Final Report Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Writes the final comprehensive report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All models are configured using &lt;a href="https://python.langchain.com/docs/how_to/chat_models_universal_init/"&gt;init_chat_model() API&lt;/a&gt; which supports providers like OpenAI, Anthropic, Google Vertex AI, and others.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important Model Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: All models must support structured outputs. Check support &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search API Compatibility&lt;/strong&gt;: Research and Compression models must support your selected search API:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anthropic search requires Anthropic models with web search capability&lt;/li&gt; 
   &lt;li&gt;OpenAI search requires OpenAI models with web search capability&lt;/li&gt; 
   &lt;li&gt;Tavily works with all models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Calling&lt;/strong&gt;: All models must support tool calling functionality&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Special Configurations&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For OpenRouter: Follow &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408"&gt;this guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;For local models via Ollama: See &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318"&gt;setup instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Example MCP (Model Context Protocol) Servers&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports MCP servers to extend research capabilities.&lt;/p&gt; 
&lt;h4&gt;Local MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Filesystem MCP Server&lt;/strong&gt; provides secure file system operations with robust access control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read, write, and manage files and directories&lt;/li&gt; 
 &lt;li&gt;Perform operations like reading file contents, creating directories, moving files, and searching&lt;/li&gt; 
 &lt;li&gt;Restrict operations to predefined directories for security&lt;/li&gt; 
 &lt;li&gt;Support for both command-line configuration and dynamic MCP roots&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mcp-server-filesystem /path/to/allowed/dir1 /path/to/allowed/dir2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Remote MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Remote MCP servers&lt;/strong&gt; enable distributed agent coordination and support streamable HTTP requests. Unlike local servers, they can be multi-tenant and require more complex authentication.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Arcade MCP Server Example&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "url": "https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm",
  "tools": ["Search_SearchHotels", "Search_SearchOneWayFlights", "Search_SearchRoundtripFlights"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Remote servers can be configured as authenticated or unauthenticated and support JWT-based authentication through OAuth endpoints.&lt;/p&gt; 
&lt;h3&gt;Evaluation&lt;/h3&gt; 
&lt;p&gt;A comprehensive batch evaluation system designed for detailed analysis and comparative studies.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-dimensional Scoring&lt;/strong&gt;: Specialized evaluators with 0-1 scale ratings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dataset-driven Evaluation&lt;/strong&gt;: Batch processing across multiple test cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Key Files:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tests/run_evaluate.py&lt;/code&gt;: Main evaluation script&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/evaluators.py&lt;/code&gt;: Specialized evaluator functions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/prompts.py&lt;/code&gt;: Evaluation prompts for each dimension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deployments and Usages&lt;/h3&gt; 
&lt;h4&gt;LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;Follow the &lt;a href="https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart"&gt;quickstart&lt;/a&gt; to start LangGraph server locally and test the agent out on LangGraph Studio.&lt;/p&gt; 
&lt;h4&gt;Hosted deployment&lt;/h4&gt; 
&lt;p&gt;You can easily deploy to &lt;a href="https://langchain-ai.github.io/langgraph/concepts/#deployment-options"&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Open Agent Platform&lt;/h4&gt; 
&lt;p&gt;Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.&lt;/p&gt; 
&lt;p&gt;We've deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out &lt;a href="https://oap.langchain.com"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/quickstart"&gt;Deploy Open Agent Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/setup/agents"&gt;Add Deep Researcher to OAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Updates 🔥&lt;/h3&gt; 
&lt;h3&gt;Legacy Implementations 🏛️&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;src/legacy/&lt;/code&gt; folder contains two earlier implementations that provide alternative approaches to automated research:&lt;/p&gt; 
&lt;h4&gt;1. Workflow Implementation (&lt;code&gt;legacy/graph.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plan-and-Execute&lt;/strong&gt;: Structured workflow with human-in-the-loop planning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequential Processing&lt;/strong&gt;: Creates sections one by one with reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Control&lt;/strong&gt;: Allows feedback and approval of report plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Focused&lt;/strong&gt;: Emphasizes accuracy through iterative refinement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Multi-Agent Implementation (&lt;code&gt;legacy/multi_agent.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervisor-Researcher Architecture&lt;/strong&gt;: Coordinated multi-agent system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing&lt;/strong&gt;: Multiple researchers work simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Optimized&lt;/strong&gt;: Faster report generation through concurrency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Support&lt;/strong&gt;: Extensive Model Context Protocol integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;code&gt;src/legacy/legacy.md&lt;/code&gt; for detailed documentation, configuration options, and usage examples for both legacy implementations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>black-forest-labs/flux</title>
      <link>https://github.com/black-forest-labs/flux</link>
      <description>&lt;p&gt;Official inference repo for FLUX.1 models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FLUX&lt;/h1&gt; 
&lt;p&gt;by Black Forest Labs: &lt;a href="https://bfl.ai"&gt;https://bfl.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Documentation for our API can be found here: &lt;a href="https://docs.bfl.ai/"&gt;docs.bfl.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/black-forest-labs/flux/main/assets/grid.jpg" alt="grid"&gt;&lt;/p&gt; 
&lt;p&gt;This repo contains minimal inference code to run image generation &amp;amp; editing with our Flux open-weight models.&lt;/p&gt; 
&lt;h2&gt;Local installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd $HOME &amp;amp;&amp;amp; git clone https://github.com/black-forest-labs/flux
cd $HOME/flux
python3.10 -m venv .venv
source .venv/bin/activate
pip install -e ".[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local installation with TensorRT support&lt;/h3&gt; 
&lt;p&gt;If you would like to install the repository with &lt;a href="https://github.com/NVIDIA/TensorRT"&gt;TensorRT&lt;/a&gt; support, you currently need to install a PyTorch image from NVIDIA instead. First install &lt;a href="https://github.com/NVIDIA/enroot"&gt;enroot&lt;/a&gt;, next follow the steps below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd $HOME &amp;amp;&amp;amp; git clone https://github.com/black-forest-labs/flux
enroot import 'docker://$oauthtoken@nvcr.io#nvidia/pytorch:25.01-py3'
enroot create -n pti2501 nvidia+pytorch+25.01-py3.sqsh
enroot start --rw -m ${PWD}/flux:/workspace/flux -r pti2501
cd flux
pip install -e ".[tensorrt]" --extra-index-url https://pypi.nvidia.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Open-weight models&lt;/h3&gt; 
&lt;p&gt;We are offering an extensive suite of open-weight models. For more information about the individual models, please refer to the link under &lt;strong&gt;Usage&lt;/strong&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Usage&lt;/th&gt; 
   &lt;th&gt;HuggingFace repo&lt;/th&gt; 
   &lt;th&gt;License&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 [schnell]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/text-to-image.md"&gt;Text to Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-schnell"&gt;https://huggingface.co/black-forest-labs/FLUX.1-schnell&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-schnell"&gt;apache-2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/text-to-image.md"&gt;Text to Image&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Fill [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/fill.md"&gt;In/Out-painting&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Canny [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/structural-conditioning.md"&gt;Structural Conditioning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Depth [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/structural-conditioning.md"&gt;Structural Conditioning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Canny [dev] LoRA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/structural-conditioning.md"&gt;Structural Conditioning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev-lora"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev-lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Depth [dev] LoRA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/structural-conditioning.md"&gt;Structural Conditioning&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev-lora"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Depth-dev-lora&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Redux [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/image-variation.md"&gt;Image variation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FLUX.1 Kontext [dev]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/docs/image-editing.md"&gt;Image editing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev"&gt;https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/black-forest-labs/flux/main/model_licenses/LICENSE-FLUX1-dev"&gt;FLUX.1-dev Non-Commercial License&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The weights of the autoencoder are also released under &lt;a href="https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md"&gt;apache-2.0&lt;/a&gt; and can be found in the HuggingFace repos above.&lt;/p&gt; 
&lt;h2&gt;API usage&lt;/h2&gt; 
&lt;p&gt;Our API offers access to all models including our Pro tier non-open weight models. Check out our API documentation &lt;a href="https://docs.bfl.ai/"&gt;docs.bfl.ai&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Licensing models for commercial use&lt;/h2&gt; 
&lt;p&gt;You can license our models for commercial use here: &lt;a href="https://bfl.ai/pricing/licensing"&gt;https://bfl.ai/pricing/licensing&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;As the fee is based on a monthly usage, we provide code to automatically track your usage via the BFL API. To enable usage tracking please select &lt;em&gt;track_usage&lt;/em&gt; in the cli or click the corresponding checkmark in our provided demos.&lt;/p&gt; 
&lt;h3&gt;Example: Using FLUX.1 Kontext with usage tracking&lt;/h3&gt; 
&lt;p&gt;We provide a reference implementation for running FLUX.1 with usage tracking enabled for commercial licensing. This can be customized as needed as long as the usage reporting is accurate.&lt;/p&gt; 
&lt;p&gt;For the reporting logic to work you will need to set your API key as an environment variable before running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export BFL_API_KEY="your_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can call &lt;code&gt;FLUX.1 Kontext [dev]&lt;/code&gt; like this with tracking activated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m flux kontext --track_usage --loop
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a single generation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m flux kontext --track_usage --prompt "replace the logo with the text 'Black Forest Labs'"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above reporting logic works similarly for FLUX.1 [dev] and FLUX.1 Tools [dev].&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that this is only required when using one or more of our open weights models commercially. More information on the commercial licensing can be found at the &lt;a href="https://help.bfl.ai/collections/6939000511-licensing"&gt;BFL Helpdesk&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find the provided code or models useful for your research, consider citing them as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bib"&gt;@misc{labs2025flux1kontextflowmatching,
      title={FLUX.1 Kontext: Flow Matching for In-Context Image Generation and Editing in Latent Space},
      author={Black Forest Labs and Stephen Batifol and Andreas Blattmann and Frederic Boesel and Saksham Consul and Cyril Diagne and Tim Dockhorn and Jack English and Zion English and Patrick Esser and Sumith Kulal and Kyle Lacey and Yam Levi and Cheng Li and Dominik Lorenz and Jonas Müller and Dustin Podell and Robin Rombach and Harry Saini and Axel Sauer and Luke Smith},
      year={2025},
      eprint={2506.15742},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2506.15742},
}

@misc{flux2024,
    author={Black Forest Labs},
    title={FLUX},
    year={2024},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ihmily/DouyinLiveRecorder</title>
      <link>https://github.com/ihmily/DouyinLiveRecorder</link>
      <description>&lt;p&gt;可循环值守和多人录制的直播录制软件，支持抖音、TikTok、Youtube、快手、虎牙、斗鱼、B站、小红书、pandatv、sooplive、flextv、popkontv、twitcasting、winktv、百度、微博、酷狗、17Live、Twitch、Acfun、CHZZK、shopee等40+平台直播录制&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://socialify.git.ci/ihmily/DouyinLiveRecorder/image?font=Inter&amp;amp;forks=1&amp;amp;language=1&amp;amp;owner=1&amp;amp;pattern=Circuit%20Board&amp;amp;stargazers=1&amp;amp;theme=Light" alt="video_spider"&gt;&lt;/p&gt; 
&lt;h2&gt;💡简介&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/downloads/release/python-3116/"&gt;&lt;img src="https://img.shields.io/badge/python-3.11.6-blue.svg?sanitize=true" alt="Python Version"&gt;&lt;/a&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder"&gt;&lt;img src="https://img.shields.io/badge/platforms-Windows%20%7C%20Linux-blue.svg?sanitize=true" alt="Supported Platforms"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ihmily/douyin-live-recorder/tags"&gt;&lt;img src="https://img.shields.io/docker/pulls/ihmily/douyin-live-recorder?label=Docker%20Pulls&amp;amp;color=blue&amp;amp;logo=docker" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/issues/ihmily/DouyinLiveRecorder.svg?sanitize=true" alt="GitHub issues"&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ihmily/DouyinLiveRecorder" alt="Latest Release"&gt;&lt;/a&gt; &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases/latest"&gt;&lt;img src="https://img.shields.io/github/downloads/ihmily/DouyinLiveRecorder/total" alt="Downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;一款&lt;strong&gt;简易&lt;/strong&gt;的可循环值守的直播录制工具，基于FFmpeg实现多平台直播源录制，支持自定义配置录制以及直播状态推送。&lt;/p&gt;  
&lt;h2&gt;😺已支持平台&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 抖音&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TikTok&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 快手&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 虎牙&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 斗鱼&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; YY&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; B站&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 小红书&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; bigo&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; blued&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; SOOP(原AfreecaTV)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 网易cc&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 千度热播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; PandaTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 猫耳FM&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Look直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; WinkTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; FlexTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; PopkonTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TwitCasting&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 百度直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 微博直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 酷狗直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; TwitchTV&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; LiveMe&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 花椒直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 流星直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; ShowRoom&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Acfun&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 映客直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 音播直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 知乎直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; CHZZK&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 嗨秀直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; vv星球直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 17Live&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 浪Live&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 畅聊直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 飘飘直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 六间房直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 乐嗨直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 花猫直播&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Shopee&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Youtube&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 淘宝&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 京东&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Faceit&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; 更多平台正在更新中&lt;/li&gt; 
&lt;/ul&gt;  
&lt;h2&gt;🎈项目结构&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
└── DouyinLiveRecorder/
    ├── /config -&amp;gt; (config record)
    ├── /logs -&amp;gt; (save runing log file)
    ├── /backup_config -&amp;gt; (backup file)
    ├── /douyinliverecorder -&amp;gt; (package)
        ├── initializer.py-&amp;gt; (check and install nodejs)
    	├── spider.py-&amp;gt; (get live data)
    	├── stream.py-&amp;gt; (get live stream address)
    	├── utils.py -&amp;gt; (contains utility functions)
    	├── logger.py -&amp;gt; (logger handdle)
    	├── room.py -&amp;gt; (get room info)
    	├── /javascript -&amp;gt; (some decrypt code)
    ├── main.py -&amp;gt; (main file)
    ├── ffmpeg_install.py -&amp;gt; (ffmpeg install script)
    ├── demo.py -&amp;gt; (call package test demo)
    ├── msg_push.py -&amp;gt; (send live status update message)
    ├── ffmpeg.exe -&amp;gt; (record video)
    ├── index.html -&amp;gt; (play m3u8 and flv video)
    ├── requirements.txt -&amp;gt; (library dependencies)
    ├── docker-compose.yaml -&amp;gt; (Container Orchestration File)
    ├── Dockerfile -&amp;gt; (Application Build Recipe)
    ├── StopRecording.vbs -&amp;gt; (stop recording script on Windows)
    ...
&lt;/code&gt;&lt;/pre&gt;  
&lt;h2&gt;🌱使用说明&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;对于只想使用录制软件的小白用户，进入&lt;a href="https://github.com/ihmily/DouyinLiveRecorder/releases"&gt;Releases&lt;/a&gt; 中下载最新发布的 zip压缩包即可，里面有打包好的录制软件。（有些电脑可能会报毒，直接忽略即可，如果下载时被浏览器屏蔽，请更换浏览器下载）&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;压缩包解压后，在 &lt;code&gt;config&lt;/code&gt; 文件夹内的 &lt;code&gt;URL_config.ini&lt;/code&gt; 中添加录制直播间地址，一行一个直播间地址。如果要自定义配置录制，可以修改&lt;code&gt;config.ini&lt;/code&gt; 文件，推荐将录制格式修改为&lt;code&gt;ts&lt;/code&gt;。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;以上步骤都做好后，就可以运行&lt;code&gt;DouyinLiveRecorder.exe&lt;/code&gt; 程序进行录制了。录制的视频文件保存在同目录下的 &lt;code&gt;downloads&lt;/code&gt; 文件夹内。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;另外，如果需要录制TikTok、AfreecaTV等海外平台，请在配置文件中设置开启代理并添加proxy_addr链接 如：&lt;code&gt;127.0.0.1:7890&lt;/code&gt; （这只是示例地址，具体根据实际填写）。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;假如&lt;code&gt;URL_config.ini&lt;/code&gt;文件中添加的直播间地址，有个别直播间暂时不想录制又不想移除链接，可以在对应直播间的链接开头加上&lt;code&gt;#&lt;/code&gt;，那么将停止该直播间的监测以及录制。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;软件默认录制清晰度为 &lt;code&gt;原画&lt;/code&gt; ，如果要单独设置某个直播间的录制画质，可以在添加直播间地址时前面加上画质即可，如&lt;code&gt;超清，https://live.douyin.com/745964462470&lt;/code&gt; 记得中间要有&lt;code&gt;,&lt;/code&gt; 分隔。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;如果要长时间挂着软件循环监测直播，最好循环时间设置长一点（咱也不差没录制到的那几分钟），避免因请求频繁导致被官方封禁IP 。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;要停止直播录制，Windows平台可执行StopRecording.vbs脚本文件，或者在录制界面使用 &lt;code&gt;Ctrl+C &lt;/code&gt; 组合键中断录制，若要停止其中某个直播间的录制，可在&lt;code&gt;URL_config.ini&lt;/code&gt;文件中的地址前加#，会自动停止对应直播间的录制并正常保存已录制的视频。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;最后，欢迎右上角给本项目一个star，同时也非常乐意大家提交pr。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;p&gt;直播间链接示例：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;抖音:
https://live.douyin.com/745964462470
https://v.douyin.com/iQFeBnt/
https://live.douyin.com/yall1102  （链接+抖音号）
https://v.douyin.com/CeiU5cbX  （主播主页地址）

TikTok:
https://www.tiktok.com/@pearlgaga88/live

快手:
https://live.kuaishou.com/u/yall1102

虎牙:
https://www.huya.com/52333

斗鱼:
https://www.douyu.com/3637778?dyshid=
https://www.douyu.com/topic/wzDBLS6?rid=4921614&amp;amp;dyshid=

YY:
https://www.yy.com/22490906/22490906

B站:
https://live.bilibili.com/320

小红书（直播间分享地址):
http://xhslink.com/xpJpfM

bigo直播:
https://www.bigo.tv/cn/716418802

buled直播:
https://app.blued.cn/live?id=Mp6G2R

SOOP:
https://play.sooplive.co.kr/sw7love

网易cc:
https://cc.163.com/583946984

千度热播:
https://qiandurebo.com/web/video.php?roomnumber=33333

PandaTV:
https://www.pandalive.co.kr/live/play/bara0109

猫耳FM:
https://fm.missevan.com/live/868895007

Look直播:
https://look.163.com/live?id=65108820&amp;amp;position=3

WinkTV:
https://www.winktv.co.kr/live/play/anjer1004

FlexTV:
https://www.flextv.co.kr/channels/593127/live

PopkonTV:
https://www.popkontv.com/live/view?castId=wjfal007&amp;amp;partnerCode=P-00117
https://www.popkontv.com/channel/notices?mcid=wjfal007&amp;amp;mcPartnerCode=P-00117

TwitCasting:
https://twitcasting.tv/c:uonq

百度直播:
https://live.baidu.com/m/media/pclive/pchome/live.html?room_id=9175031377&amp;amp;tab_category

微博直播:
https://weibo.com/l/wblive/p/show/1022:2321325026370190442592

酷狗直播:
https://fanxing2.kugou.com/50428671?refer=2177&amp;amp;sourceFrom=

TwitchTV:
https://www.twitch.tv/gamerbee

LiveMe:
https://www.liveme.com/zh/v/17141543493018047815/index.html

花椒直播:
https://www.huajiao.com/l/345096174

流星直播:
https://www.7u66.com/100960

ShowRoom:
https://www.showroom-live.com/room/profile?room_id=480206  （主播主页地址）

Acfun:
https://live.acfun.cn/live/179922

映客直播:
https://www.inke.cn/liveroom/index.html?uid=22954469&amp;amp;id=1720860391070904

音播直播:
https://live.ybw1666.com/800002949

知乎直播:
https://www.zhihu.com/people/ac3a467005c5d20381a82230101308e9 (主播主页地址)

CHZZK:
https://chzzk.naver.com/live/458f6ec20b034f49e0fc6d03921646d2

嗨秀直播:
https://www.haixiutv.com/6095106

VV星球直播:
https://h5webcdn-pro.vvxqiu.com//activity/videoShare/videoShare.html?h5Server=https://h5p.vvxqiu.com&amp;amp;roomId=LP115924473&amp;amp;platformId=vvstar

17Live:
https://17.live/en/live/6302408

浪Live:
https://www.lang.live/en-US/room/3349463

畅聊直播:
https://live.tlclw.com/106188

飘飘直播:
https://m.pp.weimipopo.com/live/preview.html?uid=91648673&amp;amp;anchorUid=91625862&amp;amp;app=plpl

六间房直播:
https://v.6.cn/634435

乐嗨直播:
https://www.lehaitv.com/8059096

花猫直播:
https://h.catshow168.com/live/preview.html?uid=19066357&amp;amp;anchorUid=18895331

Shopee:
https://sg.shp.ee/GmpXeuf?uid=1006401066&amp;amp;session=802458

Youtube:
https://www.youtube.com/watch?v=cS6zS5hi1w0

淘宝(需cookie):
https://m.tb.cn/h.TWp0HTd

京东:
https://3.cn/28MLBy-E

Faceit:
https://www.faceit.com/zh/players/Compl1/stream
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;🎃源码运行&lt;/h2&gt; 
&lt;p&gt;使用源码运行，前提要有&lt;strong&gt;Python&amp;gt;=3.10&lt;/strong&gt;环境，如果没有请先自行安装Python，再执行下面步骤。&lt;/p&gt; 
&lt;p&gt;1.首先拉取或手动下载本仓库项目代码&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ihmily/DouyinLiveRecorder.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2.进入项目文件夹，安装依赖&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd DouyinLiveRecorder
pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.安装&lt;a href="https://ffmpeg.org/download.html#build-linux"&gt;FFmpeg&lt;/a&gt;，如果是Windows系统，这一步可跳过。对于Linux系统，执行以下命令安装&lt;/p&gt; 
&lt;p&gt;CentOS执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yum install epel-release
yum install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ubuntu则执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apt update
apt install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;macOS 执行&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;如果已经安装 Homebrew 请跳过这一步&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install ffmpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4.运行程序&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;其中Linux系统请使用&lt;code&gt;python3 main.py&lt;/code&gt; 运行。&lt;/p&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;🐋容器运行&lt;/h2&gt; 
&lt;p&gt;在运行命令之前，请确保您的机器上安装了 &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt; 和 &lt;a href="https://docs.docker.com/compose/install/"&gt;Docker Compose&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;1.快速启动&lt;/p&gt; 
&lt;p&gt;最简单方法是运行项目中的 &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/raw/main/docker-compose.yaml"&gt;docker-compose.yaml&lt;/a&gt; 文件，只需简单执行以下命令：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;可选 &lt;code&gt;-d&lt;/code&gt; 在后台运行。&lt;/p&gt; 
&lt;p&gt;2.构建镜像(可选)&lt;/p&gt; 
&lt;p&gt;如果你只想简单的运行程序，则不需要做这一步。Docker镜像仓库中代码版本可能不是最新的，如果要运行本仓库主分支最新代码，可以本地自定义构建，通过修改 &lt;a href="https://github.com/ihmily/DouyinLiveRecorder/raw/main/docker-compose.yaml"&gt;docker-compose.yaml&lt;/a&gt; 文件，如将镜像名修改为 &lt;code&gt;douyin-live-recorder:latest&lt;/code&gt;，并取消 &lt;code&gt;# build: .&lt;/code&gt; 注释，然后再执行&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t douyin-live-recorder:latest .
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;或者直接使用下面命令进行构建并启动&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose -f docker-compose.yaml up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3.停止容器实例&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4.注意事项&lt;/p&gt; 
&lt;p&gt;①在docker容器内运行本程序之前，请先在配置文件中添加要录制的直播间地址。&lt;/p&gt; 
&lt;p&gt;②在容器内时，如果手动中断容器运行停止录制，会导致正在录制的视频文件损坏！&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;无论哪种运行方式，为避免手动中断或者异常中断导致录制的视频文件损坏的情况，推荐使用 &lt;code&gt;ts&lt;/code&gt; 格式保存&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt; &lt;/p&gt; 
&lt;h2&gt;❤️贡献者&lt;/h2&gt; 
&lt;p&gt;   &lt;a href="https://github.com/ihmily"&gt;&lt;img src="https://github.com/ihmily.png?size=50" alt="Hmily"&gt;&lt;/a&gt; &lt;a href="https://github.com/iridescentGray"&gt;&lt;img src="https://github.com/iridescentGray.png?size=50" alt="iridescentGray"&gt;&lt;/a&gt; &lt;a href="https://github.com/annidy"&gt;&lt;img src="https://github.com/annidy.png?size=50" alt="annidy"&gt;&lt;/a&gt; &lt;a href="https://github.com/wwkk2580"&gt;&lt;img src="https://github.com/wwkk2580.png?size=50" alt="wwkk2580"&gt;&lt;/a&gt; &lt;a href="https://github.com/missuo"&gt;&lt;img src="https://github.com/missuo.png?size=50" alt="missuo"&gt;&lt;/a&gt; &lt;a href="https://github.com/xueli12" target="_blank"&gt;&lt;img src="https://github.com/xueli12.png?size=50" alt="xueli12" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/kaine1973" target="_blank"&gt;&lt;img src="https://github.com/kaine1973.png?size=50" alt="kaine1973" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/yinruiqing" target="_blank"&gt;&lt;img src="https://github.com/yinruiqing.png?size=50" alt="yinruiqing" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/Max-Tortoise" target="_blank"&gt;&lt;img src="https://github.com/Max-Tortoise.png?size=50" alt="Max-Tortoise" style="width:53px; height:51px;"&gt;&lt;/a&gt; &lt;a href="https://github.com/justdoiting"&gt;&lt;img src="https://github.com/justdoiting.png?size=50" alt="justdoiting"&gt;&lt;/a&gt; &lt;a href="https://github.com/dhbxs"&gt;&lt;img src="https://github.com/dhbxs.png?size=50" alt="dhbxs"&gt;&lt;/a&gt; &lt;a href="https://github.com/wujiyu115"&gt;&lt;img src="https://github.com/wujiyu115.png?size=50" alt="wujiyu115"&gt;&lt;/a&gt; &lt;a href="https://github.com/zhanghao333"&gt;&lt;img src="https://github.com/zhanghao333.png?size=50" alt="zhanghao333"&gt;&lt;/a&gt; &lt;a href="https://github.com/gyc0123" target="_blank"&gt;&lt;img src="https://github.com/gyc0123.png?size=50" alt="gyc0123" style="width:53px; height:51px;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;   &lt;a href="https://github.com/HoratioShaw"&gt;&lt;img src="https://github.com/HoratioShaw.png?size=50" alt="HoratioShaw"&gt;&lt;/a&gt; &lt;a href="https://github.com/nov30th"&gt;&lt;img src="https://github.com/nov30th.png?size=50" alt="nov30th"&gt;&lt;/a&gt;  &lt;/p&gt; 
&lt;h2&gt;⏳提交日志&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;20250127&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增淘宝、京东、faceit直播录制&lt;/li&gt; 
   &lt;li&gt;修复小红书直播流录制以及转码问题&lt;/li&gt; 
   &lt;li&gt;修复畅聊、VV星球、flexTV直播录制&lt;/li&gt; 
   &lt;li&gt;修复批量微信直播推送&lt;/li&gt; 
   &lt;li&gt;新增email发送ssl和port配置&lt;/li&gt; 
   &lt;li&gt;新增强制转h264配置&lt;/li&gt; 
   &lt;li&gt;更新ffmpeg版本&lt;/li&gt; 
   &lt;li&gt;重构包为异步函数！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241130&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增shopee、youtube直播录制&lt;/li&gt; 
   &lt;li&gt;新增支持自定义m3u8、flv地址录制&lt;/li&gt; 
   &lt;li&gt;新增自定义执行脚本，支持python、bat、bash等&lt;/li&gt; 
   &lt;li&gt;修复YY直播、花椒直播和小红书直播录制&lt;/li&gt; 
   &lt;li&gt;修复b站标题获取错误&lt;/li&gt; 
   &lt;li&gt;修复log日志错误&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241030&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增嗨秀直播、vv星球直播、17Live、浪Live、SOOP、畅聊直播(原时光直播)、飘飘直播、六间房直播、乐嗨直播、花猫直播等10个平台直播录制&lt;/li&gt; 
   &lt;li&gt;修复小红书直播录制，支持小红书作者主页地址录制直播&lt;/li&gt; 
   &lt;li&gt;新增支持ntfy消息推送，以及新增支持批量推送多个地址（逗号分隔多个推送地址)&lt;/li&gt; 
   &lt;li&gt;修复Liveme直播录制、twitch直播录制&lt;/li&gt; 
   &lt;li&gt;新增Windows平台一键停止录制VB脚本程序&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20241005&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增邮箱和Bark推送&lt;/li&gt; 
   &lt;li&gt;新增直播注释停止录制&lt;/li&gt; 
   &lt;li&gt;优化分段录制&lt;/li&gt; 
   &lt;li&gt;重构部分代码&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240928&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增知乎直播、CHZZK直播录制&lt;/li&gt; 
   &lt;li&gt;修复音播直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240903&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增抖音双屏录制、音播直播录制&lt;/li&gt; 
   &lt;li&gt;修复PandaTV、bigo直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240713&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增映客直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240705&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增时光直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240701&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复虎牙直播录制2分钟断流问题&lt;/li&gt; 
   &lt;li&gt;新增自定义直播推送内容&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240621&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增Acfun、ShowRoom直播录制&lt;/li&gt; 
   &lt;li&gt;修复微博录制、新增直播源线路&lt;/li&gt; 
   &lt;li&gt;修复斗鱼直播60帧录制&lt;/li&gt; 
   &lt;li&gt;修复酷狗直播录制&lt;/li&gt; 
   &lt;li&gt;修复TikTok部分无法解析直播源&lt;/li&gt; 
   &lt;li&gt;修复抖音无法录制连麦直播&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240510&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复部分虎牙直播间录制错误&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240508&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复花椒直播录制&lt;/li&gt; 
   &lt;li&gt;更改文件路径解析方式 &lt;a href="https://github.com/kaine1973"&gt;@kaine1973&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240506&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复抖音录制画质解析bug&lt;/li&gt; 
   &lt;li&gt;修复虎牙录制 60帧最高画质问题&lt;/li&gt; 
   &lt;li&gt;新增流星直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240427&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增LiveMe、花椒直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240425&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增TwitchTV直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240424&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增酷狗直播录制、优化PopkonTV直播录制&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240423&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;新增百度直播录制、微博直播录制&lt;/li&gt; 
   &lt;li&gt;修复斗鱼录制直播回放的问题&lt;/li&gt; 
   &lt;li&gt;新增直播源地址显示以及输出到日志文件设置&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240311&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复海外平台录制bug，增加画质选择，增强录制稳定性&lt;/li&gt; 
   &lt;li&gt;修复虎牙录制bug (虎牙&lt;code&gt;一起看&lt;/code&gt;频道 有特殊限制，有时无法录制)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240309&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;修复虎牙直播、小红书直播和B站直播录制&lt;/li&gt; 
   &lt;li&gt;新增5个直播平台录制，包括winktv、flextv、look、popkontv、twitcasting&lt;/li&gt; 
   &lt;li&gt;新增部分海外平台账号密码配置，实现自动登录并更新配置文件中的cookie&lt;/li&gt; 
   &lt;li&gt;新增自定义配置需要使用代理录制的平台&lt;/li&gt; 
   &lt;li&gt;新增只推送开播消息不进行录制设置&lt;/li&gt; 
   &lt;li&gt;修复了一些bug&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;20240209&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;优化AfreecaTV录制，新增账号密码登录获取cookie以及持久保存&lt;/li&gt; 
   &lt;li&gt;修复了小红书直播因官方更新直播域名，导致无法录制直播的问题&lt;/li&gt; 
   &lt;li&gt;修复了更新URL配置文件的bug&lt;/li&gt; 
   &lt;li&gt;最后，祝大家新年快乐！&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;点击展开更多提交日志&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;20240129 
   &lt;ul&gt; 
    &lt;li&gt;新增猫耳FM直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240127 
   &lt;ul&gt; 
    &lt;li&gt;新增千度热播直播录制、新增pandaTV(韩国)直播录制&lt;/li&gt; 
    &lt;li&gt;新增telegram直播状态消息推送，修复了某些bug&lt;/li&gt; 
    &lt;li&gt;新增自定义设置不同直播间的录制画质(即每个直播间录制画质可不同)&lt;/li&gt; 
    &lt;li&gt;修改录制视频保存路径为 &lt;code&gt;downloads&lt;/code&gt; 文件夹，并且分平台进行保存。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240114 
   &lt;ul&gt; 
    &lt;li&gt;新增网易cc直播录制，优化ffmpeg参数，修改AfreecaTV输入直播地址格式&lt;/li&gt; 
    &lt;li&gt;修改日志记录器 @&lt;a href="https://github.com/iridescentGray"&gt;iridescentGray&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20240102 
   &lt;ul&gt; 
    &lt;li&gt;修复Linux上运行，新增docker配置文件&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231210 
   &lt;ul&gt; 
    &lt;li&gt;修复录制分段bug，修复bigo录制检测bug&lt;/li&gt; 
    &lt;li&gt;新增自定义修改录制主播名&lt;/li&gt; 
    &lt;li&gt;新增AfreecaTV直播录制，修复某些可能会发生的bug&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231207 
   &lt;ul&gt; 
    &lt;li&gt;新增blued直播录制，修复YY直播录制，新增直播结束消息推送&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231206 
   &lt;ul&gt; 
    &lt;li&gt;新增bigo直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231203 
   &lt;ul&gt; 
    &lt;li&gt;新增小红书直播录制（全网首发），目前小红书官方没有切换清晰度功能，因此直播录制也只有默认画质&lt;/li&gt; 
    &lt;li&gt;小红书录制暂时无法循环监测，每次主播开启直播，都要重新获取一次链接&lt;/li&gt; 
    &lt;li&gt;获取链接的方式为 将直播间转发到微信，在微信中打开后，复制页面的链接。&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20231030 
   &lt;ul&gt; 
    &lt;li&gt;本次更新只是进行修复，没时间新增功能。&lt;/li&gt; 
    &lt;li&gt;欢迎各位大佬提pr 帮忙更新维护&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230930 
   &lt;ul&gt; 
    &lt;li&gt;新增抖音从接口获取直播流，增强稳定性&lt;/li&gt; 
    &lt;li&gt;修改快手获取直播流的方式，改用从官方接口获取&lt;/li&gt; 
    &lt;li&gt;祝大家中秋节快乐！&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230919 
   &lt;ul&gt; 
    &lt;li&gt;修复了快手版本更新后录制出错的问题，增加了其自动获取cookie(&lt;del&gt;稳定性未知&lt;/del&gt;)&lt;/li&gt; 
    &lt;li&gt;修复了TikTok显示正在直播但不进行录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230907 
   &lt;ul&gt; 
    &lt;li&gt;修复了因抖音官方更新了版本导致的录制出错以及短链接转换出错&lt;/li&gt; 
    &lt;li&gt;修复B站无法录制原画视频的bug&lt;/li&gt; 
    &lt;li&gt;修改了配置文件字段，新增各平台自定义设置Cookie&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230903 
   &lt;ul&gt; 
    &lt;li&gt;修复了TikTok录制时报644无法录制的问题&lt;/li&gt; 
    &lt;li&gt;新增直播状态推送到钉钉和微信的功能，如有需要请看 &lt;a href="https://d04vqdiqwr3.feishu.cn/docx/XFPwdDDvfobbzlxhmMYcvouynDh?from=from_copylink"&gt;设置推送教程&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;最近比较忙，其他问题有时间再更新&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230816 
   &lt;ul&gt; 
    &lt;li&gt;修复斗鱼直播（官方更新了字段）和快手直播录制出错的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230814 
   &lt;ul&gt; 
    &lt;li&gt;新增B站直播录制&lt;/li&gt; 
    &lt;li&gt;写了一个在线播放M3U8和FLV视频的网页源码，打开即可食用&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230812 
   &lt;ul&gt; 
    &lt;li&gt;新增YY直播录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230808 
   &lt;ul&gt; 
    &lt;li&gt;修复主播重新开播无法再次录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230807 
   &lt;ul&gt; 
    &lt;li&gt;新增了斗鱼直播录制&lt;/li&gt; 
    &lt;li&gt;修复显示录制完成之后会重新开始录制的问题&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230805 
   &lt;ul&gt; 
    &lt;li&gt;新增了虎牙直播录制，其暂时只能用flv视频流进行录制&lt;/li&gt; 
    &lt;li&gt;Web API 新增了快手和虎牙这两个平台的直播流解析（TikTok要代理）&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230804 
   &lt;ul&gt; 
    &lt;li&gt;新增了快手直播录制，优化了部分代码&lt;/li&gt; 
    &lt;li&gt;上传了一个自动化获取抖音直播间页面Cookie的代码，可以用于录制&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230803 
   &lt;ul&gt; 
    &lt;li&gt;通宵更新&lt;/li&gt; 
    &lt;li&gt;新增了国际版抖音TikTok的直播录制，去除冗余 简化了部分代码&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;20230724 
   &lt;ul&gt; 
    &lt;li&gt;新增了一个通过抖音直播间地址获取直播视频流链接的API接口，上传即可用&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;     
&lt;h2&gt;有问题可以提issue, 我会在这里持续添加更多直播平台的录制 欢迎Star&lt;/h2&gt; 
&lt;h4&gt;&lt;/h4&gt;</description>
    </item>
    
    <item>
      <title>stanford-oval/storm</title>
      <link>https://github.com/stanford-oval/storm</link>
      <description>&lt;p&gt;An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/logo.svg?sanitize=true" style="width: 25%; height: auto;"&gt; &lt;/p&gt; 
&lt;h1&gt;STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking&lt;/h1&gt; 
&lt;p align="center"&gt; | &lt;a href="http://storm.genie.stanford.edu"&gt;&lt;b&gt;Research preview&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2402.14207"&gt;&lt;b&gt;STORM Paper&lt;/b&gt;&lt;/a&gt;| &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;&lt;b&gt;Co-STORM Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://storm-project.stanford.edu/"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; **Latest News** 🔥 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;[2025/01] We add &lt;a href="https://github.com/BerriAI/litellm"&gt;litellm&lt;/a&gt; integration for language models and embedding models in &lt;code&gt;knowledge-storm&lt;/code&gt; v1.1.0.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/09] Co-STORM codebase is now released and integrated into &lt;code&gt;knowledge-storm&lt;/code&gt; python package v1.0.0. Run &lt;code&gt;pip install knowledge-storm --upgrade&lt;/code&gt; to check it out.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/09] We introduce collaborative STORM (Co-STORM) to support human-AI collaborative knowledge curation! &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;Co-STORM Paper&lt;/a&gt; has been accepted to EMNLP 2024 main conference.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] You can now install our package with &lt;code&gt;pip install knowledge-storm&lt;/code&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] We add &lt;code&gt;VectorRM&lt;/code&gt; to support grounding on user-provided documents, complementing existing support of search engines (&lt;code&gt;YouRM&lt;/code&gt;, &lt;code&gt;BingSearch&lt;/code&gt;). (check out &lt;a href="https://github.com/stanford-oval/storm/pull/58"&gt;#58&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/07] We release demo light for developers a minimal user interface built with streamlit framework in Python, handy for local development and demo hosting (checkout &lt;a href="https://github.com/stanford-oval/storm/pull/54"&gt;#54&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/06] We will present STORM at NAACL 2024! Find us at Poster Session 2 on June 17 or check our &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/storm_naacl2024_slides.pdf"&gt;presentation material&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/05] We add Bing Search support in &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/rm.py"&gt;rm.py&lt;/a&gt;. Test STORM with &lt;code&gt;GPT-4o&lt;/code&gt; - we now configure the article generation part in our demo using &lt;code&gt;GPT-4o&lt;/code&gt; model.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[2024/04] We release refactored version of STORM codebase! We define &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/interface.py"&gt;interface&lt;/a&gt; for STORM pipeline and reimplement STORM-wiki (check out &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/storm_wiki"&gt;&lt;code&gt;src/storm_wiki&lt;/code&gt;&lt;/a&gt;) to demonstrate how to instantiate the pipeline. We provide API to support customization of different language models and retrieval/search integration.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview &lt;a href="https://storm.genie.stanford.edu/"&gt;(Try STORM now!)&lt;/a&gt;&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/overview.svg?sanitize=true" style="width: 90%; height: auto;"&gt; &lt;/p&gt; STORM is a LLM system that writes Wikipedia-like articles from scratch based on Internet search. Co-STORM further enhanced its feature by enabling human to collaborative LLM system to support more aligned and preferred information seeking and knowledge curation. 
&lt;p&gt;While the system cannot produce publication-ready articles that often require a significant number of edits, experienced Wikipedia editors have found it helpful in their pre-writing stage.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;More than 70,000 people have tried our &lt;a href="https://storm.genie.stanford.edu/"&gt;live research preview&lt;/a&gt;. Try it out to see how STORM can help your knowledge exploration journey and please provide feedback to help us improve the system 🙏!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;How STORM &amp;amp; Co-STORM works&lt;/h2&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;STORM breaks down generating long articles with citations into two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-writing stage&lt;/strong&gt;: The system conducts Internet-based research to collect references and generates an outline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Writing stage&lt;/strong&gt;: The system uses the outline and references to generate the full-length article with citations.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/two_stages.jpg" style="width: 60%; height: auto;"&gt; &lt;/p&gt; 
&lt;p&gt;STORM identifies the core of automating the research process as automatically coming up with good questions to ask. Directly prompting the language model to ask questions does not work well. To improve the depth and breadth of the questions, STORM adopts two strategies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Perspective-Guided Question Asking&lt;/strong&gt;: Given the input topic, STORM discovers different perspectives by surveying existing articles from similar topics and uses them to control the question-asking process.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simulated Conversation&lt;/strong&gt;: STORM simulates a conversation between a Wikipedia writer and a topic expert grounded in Internet sources to enable the language model to update its understanding of the topic and ask follow-up questions.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;CO-STORM&lt;/h3&gt; 
&lt;p&gt;Co-STORM proposes &lt;strong&gt;a collaborative discourse protocol&lt;/strong&gt; which implements a turn management policy to support smooth collaboration among&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Co-STORM LLM experts&lt;/strong&gt;: This type of agent generates answers grounded on external knowledge sources and/or raises follow-up questions based on the discourse history.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Moderator&lt;/strong&gt;: This agent generates thought-provoking questions inspired by information discovered by the retriever but not directly used in previous turns. Question generation can also be grounded!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human user&lt;/strong&gt;: The human user will take the initiative to either (1) observe the discourse to gain deeper understanding of the topic, or (2) actively engage in the conversation by injecting utterances to steer the discussion focus.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/stanford-oval/storm/main/assets/co-storm-workflow.jpg" style="width: 60%; height: auto;"&gt; &lt;/p&gt; 
&lt;p&gt;Co-STORM also maintains a dynamic updated &lt;strong&gt;mind map&lt;/strong&gt;, which organize collected information into a hierarchical concept structure, aiming to &lt;strong&gt;build a shared conceptual space between the human user and the system&lt;/strong&gt;. The mind map has been proven to help reduce the mental load when the discourse goes long and in-depth.&lt;/p&gt; 
&lt;p&gt;Both STORM and Co-STORM are implemented in a highly modular way using &lt;a href="https://github.com/stanfordnlp/dspy"&gt;dspy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install the knowledge storm library, use &lt;code&gt;pip install knowledge-storm&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You could also install the source code which allows you to modify the behavior of STORM engine directly.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the git repository.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/stanford-oval/storm.git
cd storm
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the required packages.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;conda create -n storm python=3.11
conda activate storm
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;Currently, our package support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Language model components: All language models supported by litellm as listed &lt;a href="https://docs.litellm.ai/docs/providers"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Embedding model components: All embedding models supported by litellm as listed &lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;retrieval module components: &lt;code&gt;YouRM&lt;/code&gt;, &lt;code&gt;BingSearch&lt;/code&gt;, &lt;code&gt;VectorRM&lt;/code&gt;, &lt;code&gt;SerperRM&lt;/code&gt;, &lt;code&gt;BraveRM&lt;/code&gt;, &lt;code&gt;SearXNG&lt;/code&gt;, &lt;code&gt;DuckDuckGoSearchRM&lt;/code&gt;, &lt;code&gt;TavilySearchRM&lt;/code&gt;, &lt;code&gt;GoogleSearch&lt;/code&gt;, and &lt;code&gt;AzureAISearch&lt;/code&gt; as&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;span&gt;🌟&lt;/span&gt; &lt;strong&gt;PRs for integrating more search engines/retrievers into &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/knowledge_storm/rm.py"&gt;knowledge_storm/rm.py&lt;/a&gt; are highly appreciated!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Both STORM and Co-STORM are working in the information curation layer, you need to set up the information retrieval module and language model module to create their &lt;code&gt;Runner&lt;/code&gt; classes respectively.&lt;/p&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;The STORM knowledge curation engine is defined as a simple Python &lt;code&gt;STORMWikiRunner&lt;/code&gt; class. Here is an example of using You.com search engine and OpenAI models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs
from knowledge_storm.lm import LitellmModel
from knowledge_storm.rm import YouRM

lm_configs = STORMWikiLMConfigs()
openai_kwargs = {
    'api_key': os.getenv("OPENAI_API_KEY"),
    'temperature': 1.0,
    'top_p': 0.9,
}
# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.
# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.
# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.
gpt_35 = LitellmModel(model='gpt-3.5-turbo', max_tokens=500, **openai_kwargs)
gpt_4 = LitellmModel(model='gpt-4o', max_tokens=3000, **openai_kwargs)
lm_configs.set_conv_simulator_lm(gpt_35)
lm_configs.set_question_asker_lm(gpt_35)
lm_configs.set_outline_gen_lm(gpt_4)
lm_configs.set_article_gen_lm(gpt_4)
lm_configs.set_article_polish_lm(gpt_4)
# Check out the STORMWikiRunnerArguments class for more configurations.
engine_args = STORMWikiRunnerArguments(...)
rm = YouRM(ydc_api_key=os.getenv('YDC_API_KEY'), k=engine_args.search_top_k)
runner = STORMWikiRunner(engine_args, lm_configs, rm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;STORMWikiRunner&lt;/code&gt; instance can be evoked with the simple &lt;code&gt;run&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;topic = input('Topic: ')
runner.run(
    topic=topic,
    do_research=True,
    do_generate_outline=True,
    do_generate_article=True,
    do_polish_article=True,
)
runner.post_run()
runner.summary()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;do_research&lt;/code&gt;: if True, simulate conversations with difference perspectives to collect information about the topic; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_generate_outline&lt;/code&gt;: if True, generate an outline for the topic; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_generate_article&lt;/code&gt;: if True, generate an article for the topic based on the outline and the collected information; otherwise, load the results.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;do_polish_article&lt;/code&gt;: if True, polish the article by adding a summarization section and (optionally) removing duplicate content; otherwise, load the results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Co-STORM&lt;/h3&gt; 
&lt;p&gt;The Co-STORM knowledge curation engine is defined as a simple Python &lt;code&gt;CoStormRunner&lt;/code&gt; class. Here is an example of using Bing search engine and OpenAI models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from knowledge_storm.collaborative_storm.engine import CollaborativeStormLMConfigs, RunnerArgument, CoStormRunner
from knowledge_storm.lm import LitellmModel
from knowledge_storm.logging_wrapper import LoggingWrapper
from knowledge_storm.rm import BingSearch

# Co-STORM adopts the same multi LM system paradigm as STORM 
lm_config: CollaborativeStormLMConfigs = CollaborativeStormLMConfigs()
openai_kwargs = {
    "api_key": os.getenv("OPENAI_API_KEY"),
    "api_provider": "openai",
    "temperature": 1.0,
    "top_p": 0.9,
    "api_base": None,
} 
question_answering_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)
discourse_manage_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
utterance_polishing_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=2000, **openai_kwargs)
warmstart_outline_gen_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
question_asking_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=300, **openai_kwargs)
knowledge_base_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)

lm_config.set_question_answering_lm(question_answering_lm)
lm_config.set_discourse_manage_lm(discourse_manage_lm)
lm_config.set_utterance_polishing_lm(utterance_polishing_lm)
lm_config.set_warmstart_outline_gen_lm(warmstart_outline_gen_lm)
lm_config.set_question_asking_lm(question_asking_lm)
lm_config.set_knowledge_base_lm(knowledge_base_lm)

# Check out the Co-STORM's RunnerArguments class for more configurations.
topic = input('Topic: ')
runner_argument = RunnerArgument(topic=topic, ...)
logging_wrapper = LoggingWrapper(lm_config)
bing_rm = BingSearch(bing_search_api_key=os.environ.get("BING_SEARCH_API_KEY"),
                     k=runner_argument.retrieve_top_k)
costorm_runner = CoStormRunner(lm_config=lm_config,
                               runner_argument=runner_argument,
                               logging_wrapper=logging_wrapper,
                               rm=bing_rm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;CoStormRunner&lt;/code&gt; instance can be evoked with the &lt;code&gt;warmstart()&lt;/code&gt; and &lt;code&gt;step(...)&lt;/code&gt; methods.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Warm start the system to build shared conceptual space between Co-STORM and users
costorm_runner.warm_start()

# Step through the collaborative discourse 
# Run either of the code snippets below in any order, as many times as you'd like
# To observe the conversation:
conv_turn = costorm_runner.step()
# To inject your utterance to actively steer the conversation:
costorm_runner.step(user_utterance="YOUR UTTERANCE HERE")

# Generate report based on the collaborative discourse
costorm_runner.knowledge_base.reorganize()
article = costorm_runner.generate_report()
print(article)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start with Example Scripts&lt;/h2&gt; 
&lt;p&gt;We provide scripts in our &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/examples"&gt;examples folder&lt;/a&gt; as a quick start to run STORM and Co-STORM with different configurations.&lt;/p&gt; 
&lt;p&gt;We suggest using &lt;code&gt;secrets.toml&lt;/code&gt; to set up the API keys. Create a file &lt;code&gt;secrets.toml&lt;/code&gt; under the root directory and add the following content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# ============ language model configurations ============ 
# Set up OpenAI API key.
OPENAI_API_KEY="your_openai_api_key"
# If you are using the API service provided by OpenAI, include the following line:
OPENAI_API_TYPE="openai"
# If you are using the API service provided by Microsoft Azure, include the following lines:
OPENAI_API_TYPE="azure"
AZURE_API_BASE="your_azure_api_base_url"
AZURE_API_VERSION="your_azure_api_version"
# ============ retriever configurations ============ 
BING_SEARCH_API_KEY="your_bing_search_api_key" # if using bing search
# ============ encoder configurations ============ 
ENCODER_API_TYPE="openai" # if using openai encoder
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;STORM examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;To run STORM with &lt;code&gt;gpt&lt;/code&gt; family models with default configurations:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python examples/storm_examples/run_storm_wiki_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever bing \
    --do-research \
    --do-generate-outline \
    --do-generate-article \
    --do-polish-article
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To run STORM using your favorite language models or grounding on your own corpus:&lt;/strong&gt; Check out &lt;a href="https://raw.githubusercontent.com/stanford-oval/storm/main/examples/storm_examples/README.md"&gt;examples/storm_examples/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Co-STORM examples&lt;/h3&gt; 
&lt;p&gt;To run Co-STORM with &lt;code&gt;gpt&lt;/code&gt; family models with default configurations,&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Add &lt;code&gt;BING_SEARCH_API_KEY="xxx"&lt;/code&gt; and &lt;code&gt;ENCODER_API_TYPE="xxx"&lt;/code&gt; to &lt;code&gt;secrets.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python examples/costorm_examples/run_costorm_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever bing
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Customization of the Pipeline&lt;/h2&gt; 
&lt;h3&gt;STORM&lt;/h3&gt; 
&lt;p&gt;If you have installed the source code, you can customize STORM based on your own use case. STORM engine consists of 4 modules:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Knowledge Curation Module: Collects a broad coverage of information about the given topic.&lt;/li&gt; 
 &lt;li&gt;Outline Generation Module: Organizes the collected information by generating a hierarchical outline for the curated knowledge.&lt;/li&gt; 
 &lt;li&gt;Article Generation Module: Populates the generated outline with the collected information.&lt;/li&gt; 
 &lt;li&gt;Article Polishing Module: Refines and enhances the written article for better presentation.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The interface for each module is defined in &lt;code&gt;knowledge_storm/interface.py&lt;/code&gt;, while their implementations are instantiated in &lt;code&gt;knowledge_storm/storm_wiki/modules/*&lt;/code&gt;. These modules can be customized according to your specific requirements (e.g., generating sections in bullet point format instead of full paragraphs).&lt;/p&gt; 
&lt;h3&gt;Co-STORM&lt;/h3&gt; 
&lt;p&gt;If you have installed the source code, you can customize Co-STORM based on your own use case&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Co-STORM introduces multiple LLM agent types (i.e. Co-STORM experts and Moderator). LLM agent interface is defined in &lt;code&gt;knowledge_storm/interface.py&lt;/code&gt; , while its implementation is instantiated in &lt;code&gt;knowledge_storm/collaborative_storm/modules/co_storm_agents.py&lt;/code&gt;. Different LLM agent policies can be customized.&lt;/li&gt; 
 &lt;li&gt;Co-STORM introduces a collaborative discourse protocol, with its core function centered on turn policy management. We provide an example implementation of turn policy management through &lt;code&gt;DiscourseManager&lt;/code&gt; in &lt;code&gt;knowledge_storm/collaborative_storm/engine.py&lt;/code&gt;. It can be customized and further improved.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Datasets&lt;/h2&gt; 
&lt;p&gt;To facilitate the study of automatic knowledge curation and complex information seeking, our project releases the following datasets:&lt;/p&gt; 
&lt;h3&gt;FreshWiki&lt;/h3&gt; 
&lt;p&gt;The FreshWiki Dataset is a collection of 100 high-quality Wikipedia articles focusing on the most-edited pages from February 2022 to September 2023. See Section 2.1 in &lt;a href="https://arxiv.org/abs/2402.14207"&gt;STORM paper&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can download the dataset from &lt;a href="https://huggingface.co/datasets/EchoShao8899/FreshWiki"&gt;huggingface&lt;/a&gt; directly. To ease the data contamination issue, we archive the &lt;a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup/FreshWiki"&gt;source code&lt;/a&gt; for the data construction pipeline that can be repeated at future dates.&lt;/p&gt; 
&lt;h3&gt;WildSeek&lt;/h3&gt; 
&lt;p&gt;To study users’ interests in complex information seeking tasks in the wild, we utilized data collected from the web research preview to create the WildSeek dataset. We downsampled the data to ensure the diversity of the topics and the quality of the data. Each data point is a pair comprising a topic and the user’s goal for conducting deep search on the topic. For more details, please refer to Section 2.2 and Appendix A of &lt;a href="https://www.arxiv.org/abs/2408.15232"&gt;Co-STORM paper&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The WildSeek dataset is available &lt;a href="https://huggingface.co/datasets/YuchengJiang/WildSeek"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Replicate STORM &amp;amp; Co-STORM paper result&lt;/h2&gt; 
&lt;p&gt;For STORM paper experiments, please switch to the branch &lt;code&gt;NAACL-2024-code-backup&lt;/code&gt; &lt;a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For Co-STORM paper experiments, please switch to the branch &lt;code&gt;EMNLP-2024-code-backup&lt;/code&gt; (placeholder for now, will be updated soon).&lt;/p&gt; 
&lt;h2&gt;Roadmap &amp;amp; Contributions&lt;/h2&gt; 
&lt;p&gt;Our team is actively working on:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Human-in-the-Loop Functionalities: Supporting user participation in the knowledge curation process.&lt;/li&gt; 
 &lt;li&gt;Information Abstraction: Developing abstractions for curated information to support presentation formats beyond the Wikipedia-style report.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you have any questions or suggestions, please feel free to open an issue or pull request. We welcome contributions to improve the system and the codebase!&lt;/p&gt; 
&lt;p&gt;Contact person: &lt;a href="mailto:shaoyj@stanford.edu"&gt;Yijia Shao&lt;/a&gt; and &lt;a href="mailto:yuchengj@stanford.edu"&gt;Yucheng Jiang&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;We would like to thank Wikipedia for its excellent open-source content. The FreshWiki dataset is sourced from Wikipedia, licensed under the Creative Commons Attribution-ShareAlike (CC BY-SA) license.&lt;/p&gt; 
&lt;p&gt;We are very grateful to &lt;a href="https://michelle123lam.github.io/"&gt;Michelle Lam&lt;/a&gt; for designing the logo for this project and &lt;a href="https://dekun.me"&gt;Dekun Ma&lt;/a&gt; for leading the UI development.&lt;/p&gt; 
&lt;p&gt;Thanks to Vercel for their support of &lt;a href="https://storm.genie.stanford.edu"&gt;open-source software&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite our paper if you use this code or part of it in your work:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{jiang-etal-2024-unknown,
    title = "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations",
    author = "Jiang, Yucheng  and
      Shao, Yijia  and
      Ma, Dekun  and
      Semnani, Sina  and
      Lam, Monica",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.554/",
    doi = "10.18653/v1/2024.emnlp-main.554",
    pages = "9917--9955",
}

@inproceedings{shao-etal-2024-assisting,
    title = "Assisting in Writing {W}ikipedia-like Articles From Scratch with Large Language Models",
    author = "Shao, Yijia  and
      Jiang, Yucheng  and
      Kanell, Theodore  and
      Xu, Peter  and
      Khattab, Omar  and
      Lam, Monica",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.347/",
    doi = "10.18653/v1/2024.naacl-long.347",
    pages = "6252--6278",
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>LMCache/LMCache</title>
      <link>https://github.com/LMCache/LMCache</link>
      <description>&lt;p&gt;Supercharge Your LLM with the Fastest KV Cache Layer&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/LMCache/LMCache/dev/asset/logo.png" width="720" alt="lmcache logo"&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://docs.lmcache.ai/"&gt;&lt;img src="https://img.shields.io/badge/docs-live-brightgreen" alt="Docs"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/lmcache/"&gt;&lt;img src="https://img.shields.io/pypi/v/lmcache" alt="PyPI"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/lmcache/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/lmcache" alt="PyPI - Python Version"&gt;&lt;/a&gt; &lt;a href="https://buildkite.com/lmcache/lmcache-unittests"&gt;&lt;img src="https://badge.buildkite.com/ce25f1819a274b7966273bfa54f0e02f092c3de0d7563c5c9d.svg?sanitize=true" alt="Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://github.com/LMCache/LMCache/actions/workflows/code_quality_checks.yml"&gt;&lt;img src="https://github.com/lmcache/lmcache/actions/workflows/code_quality_checks.yml/badge.svg?branch=dev&amp;amp;label=tests" alt="Code Quality"&gt;&lt;/a&gt; &lt;a href="https://buildkite.com/lmcache/lmcache-vllm-integration-tests"&gt;&lt;img src="https://badge.buildkite.com/108ddd4ab482a2480999dec8c62a640a3315ed4e6c4e86798e.svg?sanitize=true" alt="Integration Tests"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://www.bestpractices.dev/projects/10841"&gt;&lt;img src="https://www.bestpractices.dev/projects/10841/badge" alt="OpenSSF Best Practices"&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/LMCache/LMCache"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/LMCache/LMCache/badge" alt="OpenSSF Scorecard"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/LMCache/LMCache/"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt; &lt;a href="https://github.com/LMCache/LMCache/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/w/LMCache/LMCache" alt="GitHub commit activity"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/lmcache/"&gt;&lt;img src="https://img.shields.io/pypi/dm/lmcache" alt="PyPI - Downloads"&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UC58zMz55n70rtf1Ak2PULJA"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UC58zMz55n70rtf1Ak2PULJA" alt="YouTube Channel Views"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;p&gt;| &lt;a href="https://blog.lmcache.ai/"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://docs.lmcache.ai/"&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://join.slack.com/t/lmcacheworkspace/shared_invite/zt-36x1m765z-8FgDA_73vcXtlZ_4XvpE6Q"&gt;&lt;strong&gt;Join Slack&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://forms.gle/MHwLiYDU6kcW3dLj7"&gt;&lt;strong&gt;Interest Form&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://github.com/LMCache/LMCache/issues/574"&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🔥 &lt;strong&gt;NEW: For enterprise-scale deployment of LMCache and vLLM, please check out vLLM &lt;a href="https://github.com/vllm-project/production-stack"&gt;Production Stack&lt;/a&gt;. LMCache is also officially supported in &lt;a href="https://github.com/llm-d/llm-d/"&gt;llm-d&lt;/a&gt; and &lt;a href="https://github.com/kserve/kserve"&gt;KServe&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Summary&lt;/h2&gt; 
&lt;p&gt;LMCache is an &lt;strong&gt;LLM&lt;/strong&gt; serving engine extension to &lt;strong&gt;reduce TTFT&lt;/strong&gt; and &lt;strong&gt;increase throughput&lt;/strong&gt;, especially under long-context scenarios. By storing the KV caches of reusable texts across various locations, including (GPU, CPU DRAM, Local Disk), LMCache reuses the KV caches of &lt;strong&gt;&lt;em&gt;any&lt;/em&gt;&lt;/strong&gt; reused text (not necessarily prefix) in &lt;strong&gt;&lt;em&gt;any&lt;/em&gt;&lt;/strong&gt; serving engine instance. Thus, LMCache saves precious GPU cycles and reduces user response delay.&lt;/p&gt; 
&lt;p&gt;By combining LMCache with vLLM, developers achieve 3-10x delay savings and GPU cycle reduction in many LLM use cases, including multi-round QA and RAG.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/86137f17-f216-41a0-96a7-e537764f7a4c" alt="performance"&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 🔥 Integration with vLLM v1 with the following features: 
  &lt;ul&gt; 
   &lt;li&gt;High performance CPU KVCache offloading&lt;/li&gt; 
   &lt;li&gt;Disaggregated prefill&lt;/li&gt; 
   &lt;li&gt;P2P KVCache sharing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; LMCache is supported in the &lt;a href="https://github.com/vllm-project/production-stack/"&gt;vLLM production stack&lt;/a&gt;, &lt;a href="https://github.com/llm-d/llm-d/"&gt;llm-d&lt;/a&gt;, and &lt;a href="https://github.com/kserve/kserve"&gt;KServe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Stable support for non-prefix KV caches&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Storage support as follows: 
  &lt;ul&gt; 
   &lt;li&gt;CPU&lt;/li&gt; 
   &lt;li&gt;Disk&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ai-dynamo/nixl"&gt;NIXL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Installation support through pip and latest vLLM&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To use LMCache, simply install &lt;code&gt;lmcache&lt;/code&gt; from your package manager, e.g. pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install lmcache
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Works on Linux NVIDIA GPU platform.&lt;/p&gt; 
&lt;p&gt;More &lt;a href="https://docs.lmcache.ai/getting_started/installation"&gt;detailed installation instructions&lt;/a&gt; are available in the docs.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The best way to get started is to checkout the &lt;a href="https://docs.lmcache.ai/getting_started/quickstart/"&gt;Quickstart Examples&lt;/a&gt; in the docs.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Check out the LMCache &lt;a href="https://docs.lmcache.ai/"&gt;documentation&lt;/a&gt; which is available online.&lt;/p&gt; 
&lt;p&gt;We also post regularly in &lt;a href="https://blog.lmcache.ai/"&gt;LMCache blogs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Go hands-on with our &lt;a href="https://github.com/LMCache/LMCache/tree/dev/examples"&gt;examples&lt;/a&gt;, demonstrating how to address different use cases with LMCache.&lt;/p&gt; 
&lt;h2&gt;Interested in Connecting?&lt;/h2&gt; 
&lt;p&gt;Fill out the &lt;a href="https://forms.gle/mQfQDUXbKfp2St1z7"&gt;interest form&lt;/a&gt;, &lt;a href="https://mailchi.mp/tensormesh/lmcache-sign-up-newsletter"&gt;sign up for our newsletter&lt;/a&gt;, &lt;a href="https://join.slack.com/t/lmcacheworkspace/shared_invite/zt-2viziwhue-5Amprc9k5hcIdXT7XevTaQ"&gt;join LMCache slack&lt;/a&gt;, &lt;a href="https://lmcache.ai/"&gt;check out LMCache website&lt;/a&gt;, or &lt;a href="https://raw.githubusercontent.com/LMCache/LMCache/dev/contact@lmcache.ai"&gt;drop an email&lt;/a&gt;, and our team will reach out to you!&lt;/p&gt; 
&lt;h2&gt;Community meeting&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://uchicago.zoom.us/j/6603596916?pwd=Z1E5MDRWUSt2am5XbEt4dTFkNGx6QT09"&gt;community meeting&lt;/a&gt; for LMCache is hosted bi-weekly. All are welcome to join!&lt;/p&gt; 
&lt;p&gt;Meetings are held bi-weekly on: Tuesdays at 9:00 AM PT – &lt;a href="https://drive.usercontent.google.com/u/0/uc?id=1f5EXbooGcwNwzIpTgn5u4PHqXgfypMtu&amp;amp;export=download"&gt;Add to Calendar&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We keep notes from each meeting on this &lt;a href="https://docs.google.com/document/d/1_Fl3vLtERFa3vTH00cezri78NihNBtSClK-_1tSrcow"&gt;document&lt;/a&gt; for summaries of standups, discussion, and action items.&lt;/p&gt; 
&lt;p&gt;Recordings of meetings are available on the &lt;a href="https://www.youtube.com/channel/UC58zMz55n70rtf1Ak2PULJA"&gt;YouTube LMCache channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value all contributions and collaborations. Please check out &lt;a href="https://raw.githubusercontent.com/LMCache/LMCache/dev/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; on how to contribute.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use LMCache for your research, please cite our papers:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@inproceedings{liu2024cachegen,
  title={Cachegen: Kv cache compression and streaming for fast large language model serving},
  author={Liu, Yuhan and Li, Hanchen and Cheng, Yihua and Ray, Siddhant and Huang, Yuyang and Zhang, Qizheng and Du, Kuntai and Yao, Jiayi and Lu, Shan and Ananthanarayanan, Ganesh and others},
  booktitle={Proceedings of the ACM SIGCOMM 2024 Conference},
  pages={38--56},
  year={2024}
}

@article{cheng2024large,
  title={Do Large Language Models Need a Content Delivery Network?},
  author={Cheng, Yihua and Du, Kuntai and Yao, Jiayi and Jiang, Junchen},
  journal={arXiv preprint arXiv:2409.13761},
  year={2024}
}

@inproceedings{10.1145/3689031.3696098,
  author = {Yao, Jiayi and Li, Hanchen and Liu, Yuhan and Ray, Siddhant and Cheng, Yihua and Zhang, Qizheng and Du, Kuntai and Lu, Shan and Jiang, Junchen},
  title = {CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion},
  year = {2025},
  url = {https://doi.org/10.1145/3689031.3696098},
  doi = {10.1145/3689031.3696098},
  booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
  pages = {94–109},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Socials&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.linkedin.com/company/lmcache-lab/?viewAsMember=true"&gt;Linkedin&lt;/a&gt; | &lt;a href="https://x.com/lmcache"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.youtube.com/@LMCacheTeam"&gt;Youtube&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The LMCache codebase is licensed under Apache License 2.0. See the &lt;a href="https://raw.githubusercontent.com/LMCache/LMCache/dev/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>Genesis-Embodied-AI/Genesis</title>
      <link>https://github.com/Genesis-Embodied-AI/Genesis</link>
      <description>&lt;p&gt;A generative world for general-purpose robotics &amp; embodied AI learning.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/big_text.png" alt="Genesis"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/imgs/teaser.png" alt="Teaser"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/genesis-world/"&gt;&lt;img src="https://img.shields.io/pypi/v/genesis-world" alt="PyPI - Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/genesis-world"&gt;&lt;img src="https://static.pepy.tech/badge/genesis-world" alt="PyPI Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;&lt;img src="https://img.shields.io/github/issues/Genesis-Embodied-AI/Genesis" alt="GitHub Issues"&gt;&lt;/a&gt; &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/Genesis-Embodied-AI/Genesis" alt="GitHub Discussions"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/nukCuhB47p"&gt;&lt;img src="https://img.shields.io/discord/1322086972302430269?logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" height="20" style="display:inline"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/English-d9d9d9" alt="README in English"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_FR.md"&gt;&lt;img src="https://img.shields.io/badge/Francais-d9d9d9" alt="README en Français"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_KR.md"&gt;&lt;img src="https://img.shields.io/badge/%ED%95%9C%EA%B5%AD%EC%96%B4-d9d9d9" alt="한국어 README"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-d9d9d9" alt="简体中文版自述文件"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/README_JA.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%97%A5%E6%9C%AC%E8%AA%9E-d9d9d9" alt="日本語版 README"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Genesis&lt;/h1&gt; 
&lt;h2&gt;🔥 News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025-07-02] The development of Genesis is now officially supported by &lt;a href="https://genesis-ai.company/"&gt;Genesis AI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025-01-09] We released a &lt;a href="https://github.com/zhouxian/genesis-speed-benchmark"&gt;detailed performance benchmarking and comparison report&lt;/a&gt; on Genesis, together with all the test scripts.&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Released v0.2.1 🎊 🎉&lt;/li&gt; 
 &lt;li&gt;[2025-01-08] Created &lt;a href="https://discord.gg/nukCuhB47p"&gt;Discord&lt;/a&gt; and &lt;a href="https://drive.google.com/uc?export=view&amp;amp;id=1ZS9nnbQ-t1IwkzJlENBYqYIIOOZhXuBZ"&gt;Wechat&lt;/a&gt; group.&lt;/li&gt; 
 &lt;li&gt;[2024-12-25] Added a &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;docker&lt;/a&gt; including support for the ray-tracing renderer&lt;/li&gt; 
 &lt;li&gt;[2024-12-24] Added guidelines for &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#what-is-genesis"&gt;What is Genesis?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#quick-installation"&gt;Quick Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#contributing-to-genesis"&gt;Contributing to Genesis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#license-and-acknowledgments"&gt;License and Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;Associated Papers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#citation"&gt;Citation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;What is Genesis?&lt;/h2&gt; 
&lt;p&gt;Genesis is a physics platform designed for general-purpose &lt;em&gt;Robotics/Embodied AI/Physical AI&lt;/em&gt; applications. It is simultaneously multiple things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A &lt;strong&gt;universal physics engine&lt;/strong&gt; re-built from the ground up, capable of simulating a wide range of materials and physical phenomena.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;lightweight&lt;/strong&gt;, &lt;strong&gt;ultra-fast&lt;/strong&gt;, &lt;strong&gt;pythonic&lt;/strong&gt;, and &lt;strong&gt;user-friendly&lt;/strong&gt; robotics simulation platform.&lt;/li&gt; 
 &lt;li&gt;A powerful and fast &lt;strong&gt;photo-realistic rendering system&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;A &lt;strong&gt;generative data engine&lt;/strong&gt; that transforms user-prompted natural language description into various modalities of data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Powered by a universal physics engine re-designed and re-built from the ground up, Genesis integrates various physics solvers and their coupling into a unified framework. This core physics engine is further enhanced by a generative agent framework that operates at an upper level, aiming towards fully automated data generation for robotics and beyond.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, we are open-sourcing the &lt;em&gt;underlying physics engine&lt;/em&gt; and the &lt;em&gt;simulation platform&lt;/em&gt;. Our &lt;em&gt;generative framework&lt;/em&gt; is a modular system that incorporates many different generative modules, each handling a certain range of data modalities, routed by a high level agent. Some of the modules integrated existing papers and some are still under submission. Access to our generative feature will be gradually rolled out in the near future. If you are interested, feel free to explore more in the &lt;a href="https://raw.githubusercontent.com/Genesis-Embodied-AI/Genesis/main/#associated-papers"&gt;paper list&lt;/a&gt; below.&lt;/p&gt; 
&lt;p&gt;Genesis aims to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lower the barrier&lt;/strong&gt; to using physics simulations, making robotics research accessible to everyone. See our &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/overview/mission.html"&gt;mission statement&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unify diverse physics solvers&lt;/strong&gt; into a single framework to recreate the physical world with the highest fidelity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate data generation&lt;/strong&gt;, reducing human effort and letting the data flywheel spin on its own.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Project Page: &lt;a href="https://genesis-embodied-ai.github.io/"&gt;https://genesis-embodied-ai.github.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Over 43 million FPS when simulating a Franka robotic arm with a single RTX 4090 (430,000 times faster than real-time).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-platform&lt;/strong&gt;: Runs on Linux, macOS, Windows, and supports multiple compute backends (CPU, Nvidia/AMD GPUs, Apple Metal).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration of diverse physics solvers&lt;/strong&gt;: Rigid body, MPM, SPH, FEM, PBD, Stable Fluid.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wide range of material models&lt;/strong&gt;: Simulation and coupling of rigid bodies, liquids, gases, deformable objects, thin-shell objects, and granular materials.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compatibility with various robots&lt;/strong&gt;: Robotic arms, legged robots, drones, &lt;em&gt;soft robots&lt;/em&gt;, and support for loading &lt;code&gt;MJCF (.xml)&lt;/code&gt;, &lt;code&gt;URDF&lt;/code&gt;, &lt;code&gt;.obj&lt;/code&gt;, &lt;code&gt;.glb&lt;/code&gt;, &lt;code&gt;.ply&lt;/code&gt;, &lt;code&gt;.stl&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Photo-realistic rendering&lt;/strong&gt;: Native ray-tracing-based rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Differentiability&lt;/strong&gt;: Genesis is designed to be fully differentiable. Currently, our MPM solver and Tool Solver support differentiability, with other solvers planned for future versions (starting with rigid &amp;amp; articulated body solver).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Physics-based tactile simulation&lt;/strong&gt;: Differentiable &lt;a href="https://github.com/Genesis-Embodied-AI/DiffTactile"&gt;tactile sensor simulation&lt;/a&gt; coming soon (expected in version 0.3.0).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-friendliness&lt;/strong&gt;: Designed for simplicity, with intuitive installation and APIs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Installation&lt;/h2&gt; 
&lt;p&gt;Install &lt;strong&gt;PyTorch&lt;/strong&gt; first following the &lt;a href="https://pytorch.org/get-started/locally/"&gt;official instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Then, install Genesis via PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install genesis-world  # Requires Python&amp;gt;=3.10,&amp;lt;3.13;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest version to date, make sure that &lt;code&gt;pip&lt;/code&gt; is up-to-date via &lt;code&gt;pip install --upgrade pip&lt;/code&gt;, then run command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/Genesis-Embodied-AI/Genesis.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the package must still be updated manually to sync with main branch.&lt;/p&gt; 
&lt;p&gt;Users seeking to edit the source code of Genesis are encourage to install Genesis in editable mode. First, make sure that &lt;code&gt;genesis-world&lt;/code&gt; has been uninstalled, then clone the repository and install locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Genesis-Embodied-AI/Genesis.git
cd Genesis
pip install -e ".[dev]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;If you want to use Genesis from Docker, you can first build the Docker image as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t genesis -f docker/Dockerfile docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can run the examples inside the docker image (mounted to &lt;code&gt;/workspace/examples&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;xhost +local:root # Allow the container to access the display

docker run --gpus all --rm -it \
-e DISPLAY=$DISPLAY \
-v /dev/dri:/dev/dri \
-v /tmp/.X11-unix/:/tmp/.X11-unix \
-v $PWD:/workspace \
genesis
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD users&lt;/h3&gt; 
&lt;p&gt;AMD users can use Genesis using the &lt;code&gt;docker/Dockerfile.amdgpu&lt;/code&gt; file, which is built by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build -t genesis-amd -f docker/Dockerfile.amdgpu docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and can then be used by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xhost"&gt;docker run -it --network=host \
 --device=/dev/kfd \
 --device=/dev/dri \
 --group-add=video \
 --ipc=host \
 --cap-add=SYS_PTRACE \
 --security-opt seccomp=unconfined \
 --shm-size 8G \
 -v $PWD:/workspace \
 -e DISPLAY=$DISPLAY \
 genesis-amd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The examples will be accessible from &lt;code&gt;/workspace/examples&lt;/code&gt;. Note: AMD users should use the vulkan backend. This means you will need to call &lt;code&gt;gs.init(vulkan)&lt;/code&gt; to initialise Genesis.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Comprehensive documentation is available in &lt;a href="https://genesis-world.readthedocs.io/en/latest/user_guide/index.html"&gt;English&lt;/a&gt;, &lt;a href="https://genesis-world.readthedocs.io/zh-cn/latest/user_guide/index.html"&gt;Chinese&lt;/a&gt;, and &lt;a href="https://genesis-world.readthedocs.io/ja/latest/user_guide/index.html"&gt;Japanese&lt;/a&gt;. This includes detailed installation steps, tutorials, and API references.&lt;/p&gt; 
&lt;h2&gt;Contributing to Genesis&lt;/h2&gt; 
&lt;p&gt;The Genesis project is an open and collaborative effort. We welcome all forms of contributions from the community, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pull requests&lt;/strong&gt; for new features or bug fixes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bug reports&lt;/strong&gt; through GitHub Issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Suggestions&lt;/strong&gt; to improve Genesis's usability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/raw/main/.github/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs or request features via GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/issues"&gt;Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join discussions or ask questions on GitHub &lt;a href="https://github.com/Genesis-Embodied-AI/Genesis/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License and Acknowledgments&lt;/h2&gt; 
&lt;p&gt;The Genesis source code is licensed under Apache 2.0.&lt;/p&gt; 
&lt;p&gt;Genesis's development has been made possible thanks to these open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taichi-dev/taichi"&gt;Taichi&lt;/a&gt;: High-performance cross-platform compute backend. Kudos to the Taichi team for their technical support!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhouxian/FluidLab"&gt;FluidLab&lt;/a&gt;: Reference MPM solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erizmr/SPH_Taichi"&gt;SPH_Taichi&lt;/a&gt;: Reference SPH solver implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matthias-research.github.io/pages/tenMinutePhysics/index.html"&gt;Ten Minute Physics&lt;/a&gt; and &lt;a href="https://github.com/WASD4959/PBF3D"&gt;PBF3D&lt;/a&gt;: Reference PBD solver implementations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google-deepmind/mujoco"&gt;MuJoCo&lt;/a&gt;: Reference for rigid body dynamics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danfis/libccd"&gt;libccd&lt;/a&gt;: Reference for collision detection.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmatl/pyrender"&gt;PyRender&lt;/a&gt;: Rasterization-based renderer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LuisaGroup/LuisaCompute"&gt;LuisaCompute&lt;/a&gt; and &lt;a href="https://github.com/LuisaGroup/LuisaRender"&gt;LuisaRender&lt;/a&gt;: Ray-tracing DSL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Associated Papers&lt;/h2&gt; 
&lt;p&gt;Genesis is a large scale effort that integrates state-of-the-art technologies of various existing and on-going research work into a single system. Here we include a non-exhaustive list of all the papers that contributed to the Genesis project in one way or another:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Xian, Zhou, et al. "Fluidlab: A differentiable environment for benchmarking complex fluid manipulation." arXiv preprint arXiv:2303.02346 (2023).&lt;/li&gt; 
 &lt;li&gt;Xu, Zhenjia, et al. "Roboninja: Learning an adaptive cutting policy for multi-material objects." arXiv preprint arXiv:2302.11553 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yufei, et al. "Robogen: Towards unleashing infinite data for automated robot learning via generative simulation." arXiv preprint arXiv:2311.01455 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan, et al. "Softzoo: A soft robot co-design benchmark for locomotion in diverse environments." arXiv preprint arXiv:2303.09555 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Tsun-Hsuan Johnson, et al. "Diffusebot: Breeding soft robots with physics-augmented generative diffusion models." Advances in Neural Information Processing Systems 36 (2023): 44398-44423.&lt;/li&gt; 
 &lt;li&gt;Katara, Pushkal, Zhou Xian, and Katerina Fragkiadaki. "Gen2sim: Scaling up robot learning in simulation with generative models." 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2024.&lt;/li&gt; 
 &lt;li&gt;Si, Zilin, et al. "DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation." arXiv preprint arXiv:2403.08716 (2024).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Thin-Shell Object Manipulations With Differentiable Physics Simulations." arXiv preprint arXiv:2404.00451 (2024).&lt;/li&gt; 
 &lt;li&gt;Lin, Chunru, et al. "UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded Soft Environments." arXiv preprint arXiv:2411.12711 (2024).&lt;/li&gt; 
 &lt;li&gt;Zhou, Wenyang, et al. "EMDM: Efficient motion diffusion model for fast and high-quality motion generation." European Conference on Computer Vision. Springer, Cham, 2025.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Scalable differentiable physics for learning and control." International Conference on Machine Learning. PMLR, 2020.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming C. Lin. "Efficient differentiable simulation of articulated bodies." In International Conference on Machine Learning, PMLR, 2021.&lt;/li&gt; 
 &lt;li&gt;Qiao, Yi-Ling, Junbang Liang, Vladlen Koltun, and Ming Lin. "Differentiable simulation of soft multi-body systems." Advances in Neural Information Processing Systems 34 (2021).&lt;/li&gt; 
 &lt;li&gt;Wan, Weilin, et al. "Tlcontrol: Trajectory and language control for human motion synthesis." arXiv preprint arXiv:2311.17135 (2023).&lt;/li&gt; 
 &lt;li&gt;Wang, Yian, et al. "Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting." arXiv preprint arXiv:2411.09823 (2024).&lt;/li&gt; 
 &lt;li&gt;Zheng, Shaokun, et al. "LuisaRender: A high-performance rendering framework with layered and unified interfaces on stream architectures." ACM Transactions on Graphics (TOG) 41.6 (2022): 1-19.&lt;/li&gt; 
 &lt;li&gt;Fan, Yingruo, et al. "Faceformer: Speech-driven 3d facial animation with transformers." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.&lt;/li&gt; 
 &lt;li&gt;Wu, Sichun, Kazi Injamamul Haque, and Zerrin Yumak. "ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE." Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games. 2024.&lt;/li&gt; 
 &lt;li&gt;Dou, Zhiyang, et al. "C· ase: Learning conditional adversarial skill embeddings for physics-based characters." SIGGRAPH Asia 2023 Conference Papers. 2023.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;... and many more on-going work.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Genesis in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{Genesis,
  author = {Genesis Authors},
  title = {Genesis: A Generative and Universal Physics Engine for Robotics and Beyond},
  month = {December},
  year = {2024},
  url = {https://github.com/Genesis-Embodied-AI/Genesis}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Netflix/metaflow</title>
      <link>https://github.com/Netflix/metaflow</link>
      <description>&lt;p&gt;Build, Manage and Deploy AI/ML Systems&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/763451/89453116-96a57e00-d713-11ea-9fa6-82b29d4d6eff.png" alt="Metaflow_Logo_Horizontal_FullColor_Ribbon_Dark_RGB"&gt;&lt;/p&gt; 
&lt;h1&gt;Metaflow&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://metaflow.org"&gt;Metaflow&lt;/a&gt; is a human-centric framework designed to help scientists and engineers &lt;strong&gt;build and manage real-life AI and ML systems&lt;/strong&gt;. Serving teams of all sizes and scale, Metaflow streamlines the entire development lifecycle—from rapid prototyping in notebooks to reliable, maintainable production deployments—enabling teams to iterate quickly and deliver robust systems efficiently.&lt;/p&gt; 
&lt;p&gt;Originally developed at &lt;a href="https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9"&gt;Netflix&lt;/a&gt; and now supported by &lt;a href="https://outerbounds.com"&gt;Outerbounds&lt;/a&gt;, Metaflow is designed to boost the productivity for research and engineering teams working on &lt;a href="https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d"&gt;a wide variety of projects&lt;/a&gt;, from classical statistics to state-of-the-art deep learning and foundation models. By unifying code, data, and compute at every stage, Metaflow ensures seamless, end-to-end management of real-world AI and ML systems.&lt;/p&gt; 
&lt;p&gt;Today, Metaflow powers thousands of AI and ML experiences across a diverse array of companies, large and small, including Amazon, Doordash, Dyson, Goldman Sachs, Ramp, and &lt;a href="https://raw.githubusercontent.com/Netflix/metaflow/master/ADOPTERS.md"&gt;many others&lt;/a&gt;. At Netflix alone, Metaflow supports over 3000 AI and ML projects, executes hundreds of millions of data-intensive high-performance compute jobs processing petabytes of data and manages tens of petabytes of models and artifacts for hundreds of users across its AI, ML, data science, and engineering teams.&lt;/p&gt; 
&lt;h2&gt;From prototype to production (and back)&lt;/h2&gt; 
&lt;p&gt;Metaflow provides a simple and friendly pythonic &lt;a href="https://docs.metaflow.org"&gt;API&lt;/a&gt; that covers foundational needs of AI and ML systems: &lt;img src="https://raw.githubusercontent.com/Netflix/metaflow/master/docs/prototype-to-prod.png" width="800px"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/metaflow/basics"&gt;Rapid local prototyping&lt;/a&gt;, &lt;a href="https://docs.metaflow.org/metaflow/managing-flows/notebook-runs"&gt;support for notebooks&lt;/a&gt;, and built-in support for &lt;a href="https://docs.metaflow.org/metaflow/client"&gt;experiment tracking, versioning&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/metaflow/visualizing-results"&gt;visualization&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/scaling/remote-tasks/introduction"&gt;Effortlessly scale horizontally and vertically in your cloud&lt;/a&gt;, utilizing both CPUs and GPUs, with &lt;a href="https://docs.metaflow.org/scaling/data"&gt;fast data access&lt;/a&gt; for running &lt;a href="https://docs.metaflow.org/metaflow/basics#foreach"&gt;massive embarrassingly parallel&lt;/a&gt; as well as &lt;a href="https://docs.metaflow.org/scaling/remote-tasks/distributed-computing"&gt;gang-scheduled&lt;/a&gt; compute workloads &lt;a href="https://docs.metaflow.org/scaling/failures"&gt;reliably&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/scaling/checkpoint/introduction"&gt;efficiently&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/scaling/dependencies"&gt;Easily manage dependencies&lt;/a&gt; and &lt;a href="https://docs.metaflow.org/production/introduction"&gt;deploy with one-click&lt;/a&gt; to highly available production orchestrators with built in support for &lt;a href="https://docs.metaflow.org/production/event-triggering"&gt;reactive orchestration&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For full documentation, check out our &lt;a href="https://docs.metaflow.org/api"&gt;API Reference&lt;/a&gt; or see our &lt;a href="https://github.com/Netflix/metaflow/releases"&gt;Release Notes&lt;/a&gt; for the latest features and improvements.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Getting up and running is easy. If you don't know where to start, &lt;a href="https://outerbounds.com/sandbox"&gt;Metaflow sandbox&lt;/a&gt; will have you running and exploring in seconds.&lt;/p&gt; 
&lt;h3&gt;Installing Metaflow&lt;/h3&gt; 
&lt;p&gt;To install Metaflow in your Python environment from &lt;a href="https://pypi.org/project/metaflow/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install metaflow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, using &lt;a href="https://anaconda.org/conda-forge/metaflow"&gt;conda-forge&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge metaflow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once installed, a great way to get started is by following our &lt;a href="https://docs.metaflow.org/getting-started/tutorials"&gt;tutorial&lt;/a&gt;. It walks you through creating and running your first Metaflow flow step by step.&lt;/p&gt; 
&lt;p&gt;For more details on Metaflow’s features and best practices, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/metaflow/basics"&gt;How Metaflow works&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.metaflow.org/introduction/metaflow-resources"&gt;Additional resources&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need help, don’t hesitate to reach out on our &lt;a href="http://slack.outerbounds.co/"&gt;Slack community&lt;/a&gt;!&lt;/p&gt; 
&lt;h3&gt;Deploying infrastructure for Metaflow in your cloud&lt;/h3&gt; 
&lt;img src="https://raw.githubusercontent.com/Netflix/metaflow/master/docs/multicloud.png" width="800px"&gt; 
&lt;p&gt;While you can get started with Metaflow easily on your laptop, the main benefits of Metaflow lie in its ability to &lt;a href="https://docs.metaflow.org/scaling/remote-tasks/introduction"&gt;scale out to external compute clusters&lt;/a&gt; and to &lt;a href="https://docs.metaflow.org/production/introduction"&gt;deploy to production-grade workflow orchestrators&lt;/a&gt;. To benefit from these features, follow this &lt;a href="https://outerbounds.com/engineering/welcome/"&gt;guide&lt;/a&gt; to configure Metaflow and the infrastructure behind it appropriately.&lt;/p&gt; 
&lt;h2&gt;Get in touch&lt;/h2&gt; 
&lt;p&gt;We'd love to hear from you. Join our community &lt;a href="http://slack.outerbounds.co/"&gt;Slack workspace&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to Metaflow. Please see our &lt;a href="https://docs.metaflow.org/introduction/contributing-to-metaflow"&gt;contribution guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vinta/awesome-python</title>
      <link>https://github.com/vinta/awesome-python</link>
      <description>&lt;p&gt;An opinionated list of awesome Python frameworks, libraries, software and resources.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Awesome Python &lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome"&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;An opinionated list of awesome Python frameworks, libraries, software and resources.&lt;/p&gt; 
&lt;p&gt;Inspired by &lt;a href="https://github.com/ziadoz/awesome-php"&gt;awesome-php&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#awesome-python"&gt;Awesome Python&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#admin-panels"&gt;Admin Panels&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#algorithms-and-design-patterns"&gt;Algorithms and Design Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#asgi-servers"&gt;ASGI Servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#asynchronous-programming"&gt;Asynchronous Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#audio"&gt;Audio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#authentication"&gt;Authentication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#build-tools"&gt;Build Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#built-in-classes-enhancement"&gt;Built-in Classes Enhancement&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#caching"&gt;Caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#chatops-tools"&gt;ChatOps Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#cms"&gt;CMS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#code-analysis"&gt;Code Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#command-line-interface-development"&gt;Command-line Interface Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#command-line-tools"&gt;Command-line Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#computer-vision"&gt;Computer Vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#configuration-files"&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#cryptography"&gt;Cryptography&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#data-analysis"&gt;Data Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#data-validation"&gt;Data Validation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#data-visualization"&gt;Data Visualization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#database-drivers"&gt;Database Drivers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#database"&gt;Database&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#date-and-time"&gt;Date and Time&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#debugging-tools"&gt;Debugging Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#deep-learning"&gt;Deep Learning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#devops-tools"&gt;DevOps Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#distributed-computing"&gt;Distributed Computing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#distribution"&gt;Distribution&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#downloader"&gt;Downloader&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#editor-plugins-and-ides"&gt;Editor Plugins and IDEs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#email"&gt;Email&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#environment-management"&gt;Environment Management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#file-manipulation"&gt;File Manipulation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#functional-programming"&gt;Functional Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#game-development"&gt;Game Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#geolocation"&gt;Geolocation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#gui-development"&gt;GUI Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#hardware"&gt;Hardware&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#html-manipulation"&gt;HTML Manipulation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#http-clients"&gt;HTTP Clients&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#image-processing"&gt;Image Processing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#implementations"&gt;Implementations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#interactive-interpreter"&gt;Interactive Interpreter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#internationalization"&gt;Internationalization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#job-scheduler"&gt;Job Scheduler&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#machine-learning"&gt;Machine Learning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#natural-language-processing"&gt;Natural Language Processing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#network-virtualization"&gt;Network Virtualization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#news-feed"&gt;News Feed&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#orm"&gt;ORM&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#package-management"&gt;Package Management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#package-repositories"&gt;Package Repositories&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#penetration-testing"&gt;Penetration testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#permissions"&gt;Permissions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#processes"&gt;Processes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#recommender-systems"&gt;Recommender Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#refactoring"&gt;Refactoring&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#restful-api"&gt;RESTful API&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#robotics"&gt;Robotics&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#rpc-servers"&gt;RPC Servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#science"&gt;Science&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#search"&gt;Search&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#serialization"&gt;Serialization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#serverless-frameworks"&gt;Serverless Frameworks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#shell"&gt;Shell&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#specific-formats-processing"&gt;Specific Formats Processing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#static-site-generator"&gt;Static Site Generator&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#tagging"&gt;Tagging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#task-queues"&gt;Task Queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#template-engine"&gt;Template Engine&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#text-processing"&gt;Text Processing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#third-party-apis"&gt;Third-party APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#url-manipulation"&gt;URL Manipulation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#video"&gt;Video&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#web-asset-management"&gt;Web Asset Management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#web-content-extracting"&gt;Web Content Extracting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#web-crawling"&gt;Web Crawling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#web-frameworks"&gt;Web Frameworks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#websocket"&gt;WebSocket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#wsgi-servers"&gt;WSGI Servers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#resources"&gt;Resources&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#newsletters"&gt;Newsletters&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#podcasts"&gt;Podcasts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vinta/awesome-python/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Admin Panels&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for administrative interfaces.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ajenti/ajenti"&gt;ajenti&lt;/a&gt; - The admin panel your servers deserve.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sehmaschine/django-grappelli"&gt;django-grappelli&lt;/a&gt; - A jazzy skin for the Django Admin-Interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flask-admin/flask-admin"&gt;flask-admin&lt;/a&gt; - Simple and extensible administrative interface framework for Flask.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mher/flower"&gt;flower&lt;/a&gt; - Real-time monitor and web admin for Celery.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jet-admin/jet-bridge"&gt;jet-bridge&lt;/a&gt; - Admin panel framework for any application with nice UI (ex Jet Django).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wooey/wooey"&gt;wooey&lt;/a&gt; - A Django app which creates automatic web UIs for Python scripts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/streamlit/streamlit"&gt;streamlit&lt;/a&gt; - A framework which lets you build dashboards, generate reports, or create chat apps in minutes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Algorithms and Design Patterns&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Python implementation of data structures, algorithms and design patterns. Also see &lt;a href="https://github.com/tayllan/awesome-algorithms"&gt;awesome-algorithms&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Algorithms 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/keon/algorithms"&gt;algorithms&lt;/a&gt; - Minimal examples of data structures and algorithms.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/prabhupant/python-ds"&gt;python-ds&lt;/a&gt; - A collection of data structure and algorithms for coding interviews.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grantjenks/python-sortedcontainers"&gt;sortedcontainers&lt;/a&gt; - Fast and pure-Python implementation of sorted collections.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/TheAlgorithms/Python"&gt;thealgorithms&lt;/a&gt; - All Algorithms implemented in Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Design Patterns 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tylerlaberge/PyPattyrn"&gt;pypattyrn&lt;/a&gt; - A simple yet effective library for implementing common design patterns.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/faif/python-patterns"&gt;python-patterns&lt;/a&gt; - A collection of design patterns in Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pytransitions/transitions"&gt;transitions&lt;/a&gt; - A lightweight, object-oriented finite state machine implementation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ASGI Servers&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://asgi.readthedocs.io/en/latest/"&gt;ASGI&lt;/a&gt;-compatible web servers.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django/daphne"&gt;daphne&lt;/a&gt; - A HTTP, HTTP2 and WebSocket protocol server for ASGI and ASGI-HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/encode/uvicorn"&gt;uvicorn&lt;/a&gt; - A lightning-fast ASGI server implementation, using uvloop and httptools.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgjones/hypercorn"&gt;hypercorn&lt;/a&gt; - An ASGI and WSGI Server based on Hyper libraries and inspired by Gunicorn.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronous Programming&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for asynchronous, concurrent and parallel execution. Also see &lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/asyncio.html"&gt;asyncio&lt;/a&gt; - (Python standard library) Asynchronous I/O, event loop, coroutines and tasks. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timofurrer/awesome-asyncio"&gt;awesome-asyncio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/concurrent.futures.html"&gt;concurrent.futures&lt;/a&gt; - (Python standard library) A high-level interface for asynchronously executing callables.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/multiprocessing.html"&gt;multiprocessing&lt;/a&gt; - (Python standard library) Process-based parallelism.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-trio/trio"&gt;trio&lt;/a&gt; - A friendly library for async concurrency and I/O.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/twisted/twisted"&gt;twisted&lt;/a&gt; - An event-driven networking engine.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MagicStack/uvloop"&gt;uvloop&lt;/a&gt; - Ultra fast asyncio event loop.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/eventlet/eventlet"&gt;eventlet&lt;/a&gt; - Asynchronous framework with WSGI support.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gevent/gevent"&gt;gevent&lt;/a&gt; - A coroutine-based Python networking library that uses &lt;a href="https://github.com/python-greenlet/greenlet"&gt;greenlet&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Audio&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for manipulating audio and its metadata.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Audio 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/beetbox/audioread"&gt;audioread&lt;/a&gt; - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/libAudioFlux/audioFlux"&gt;audioFlux&lt;/a&gt; - A library for audio and music analysis, feature extraction.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/worldveil/dejavu"&gt;dejavu&lt;/a&gt; - Audio fingerprinting and recognition.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/keunwoochoi/kapre"&gt;kapre&lt;/a&gt; - Keras Audio Preprocessors.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/librosa/librosa"&gt;librosa&lt;/a&gt; - Python library for audio and music analysis.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sergree/matchering"&gt;matchering&lt;/a&gt; - A library for automated reference audio mastering.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://bspaans.github.io/python-mingus/"&gt;mingus&lt;/a&gt; - An advanced music theory and notation package with MIDI file and playback support.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tyiannak/pyAudioAnalysis"&gt;pyaudioanalysis&lt;/a&gt; - Audio feature extraction, classification, segmentation and applications.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jiaaro/pydub"&gt;pydub&lt;/a&gt; - Manipulate audio with a simple and easy high level interface.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Parisson/TimeSide"&gt;timeside&lt;/a&gt; - Open web audio processing framework.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Metadata 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/beetbox/beets"&gt;beets&lt;/a&gt; - A music library manager and &lt;a href="https://musicbrainz.org/"&gt;MusicBrainz&lt;/a&gt; tagger.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/nicfit/eyeD3"&gt;eyed3&lt;/a&gt; - A tool for working with audio files, specifically MP3 files containing ID3 metadata.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;mutagen&lt;/a&gt; - A Python module to handle audio metadata.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/devsnd/tinytag"&gt;tinytag&lt;/a&gt; - A library for reading music meta data of MP3, OGG, FLAC and Wave files.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for implementing authentications schemes.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OAuth 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lepture/authlib"&gt;authlib&lt;/a&gt; - JavaScript Object Signing and Encryption draft implementation.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pennersr/django-allauth"&gt;django-allauth&lt;/a&gt; - Authentication app for Django that "just works."&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jazzband/django-oauth-toolkit"&gt;django-oauth-toolkit&lt;/a&gt; - OAuth 2 goodies for Django.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/oauthlib/oauthlib"&gt;oauthlib&lt;/a&gt; - A generic and thorough implementation of the OAuth request-signing logic.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;JWT 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jpadilla/pyjwt"&gt;pyjwt&lt;/a&gt; - JSON Web Token implementation in Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mpdavis/python-jose/"&gt;python-jose&lt;/a&gt; - A JOSE implementation in Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build Tools&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Compile software from source code.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openembedded/bitbake"&gt;bitbake&lt;/a&gt; - A make-like build tool for embedded Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buildout/buildout"&gt;buildout&lt;/a&gt; - A build system for creating, assembling and deploying applications from multiple parts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/platformio/platformio-core"&gt;platformio&lt;/a&gt; - A console tool to build code with different development platforms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pybuilder/pybuilder"&gt;pybuilder&lt;/a&gt; - A continuous build tool written in pure Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SCons/scons"&gt;scons&lt;/a&gt; - A software construction tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in Classes Enhancement&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for enhancing Python built-in classes.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-attrs/attrs"&gt;attrs&lt;/a&gt; - Replacement for &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;__eq__&lt;/code&gt;, &lt;code&gt;__repr__&lt;/code&gt;, etc. boilerplate in class definitions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jab/bidict"&gt;bidict&lt;/a&gt; - Efficient, Pythonic bidirectional map data structures and related functionality..&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cdgriffith/Box"&gt;box&lt;/a&gt; - Python dictionaries with advanced dot notation access.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/dataclasses.html"&gt;dataclasses&lt;/a&gt; - (Python standard library) Data classes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carlosescri/DottedDict"&gt;dotteddict&lt;/a&gt; - A library that provides a method of accessing lists and dicts with a dotted path notation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;CMS&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Content Management Systems.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/feincms/feincms"&gt;feincms&lt;/a&gt; - One of the most advanced Content Management Systems built on Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/indico/indico"&gt;indico&lt;/a&gt; - A feature-rich event management system, made @ &lt;a href="https://en.wikipedia.org/wiki/CERN"&gt;CERN&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wagtail/wagtail"&gt;wagtail&lt;/a&gt; - A Django content management system.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Caching&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for caching data.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bbangert/beaker"&gt;beaker&lt;/a&gt; - A WSGI middleware for sessions and caching.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django-cache-machine/django-cache-machine"&gt;django-cache-machine&lt;/a&gt; - Automatic caching and invalidation for Django models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Suor/django-cacheops"&gt;django-cacheops&lt;/a&gt; - A slick ORM cache with automatic granular event-driven invalidation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sqlalchemy/dogpile.cache"&gt;dogpile.cache&lt;/a&gt; - dogpile.cache is a next generation replacement for Beaker made by the same authors.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/HermesCache/"&gt;hermescache&lt;/a&gt; - Python caching library with tag-based invalidation and dogpile effect prevention.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lericson/pylibmc"&gt;pylibmc&lt;/a&gt; - A Python wrapper around the &lt;a href="https://libmemcached.org/libMemcached.html"&gt;libmemcached&lt;/a&gt; interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grantjenks/python-diskcache"&gt;python-diskcache&lt;/a&gt; - SQLite and file backed cache backend with faster lookups than memcached and redis.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ChatOps Tools&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for chatbot development.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/errbotio/errbot/"&gt;errbot&lt;/a&gt; - The easiest and most popular chatbot to implement ChatOps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Code Analysis&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Tools of static analysis, linters and code quality checkers. Also see &lt;a href="https://github.com/mre/awesome-static-analysis"&gt;awesome-static-analysis&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Code Analysis 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/scottrogowski/code2flow"&gt;code2flow&lt;/a&gt; - Turn your Python and JavaScript code into DOT flowcharts.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PyCQA/prospector"&gt;prospector&lt;/a&gt; - A tool to analyse Python code.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jendrikseipp/vulture"&gt;vulture&lt;/a&gt; - A tool for finding and analysing dead Python code.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Code Linters 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PyCQA/flake8"&gt;flake8&lt;/a&gt; - A wrapper around &lt;code&gt;pycodestyle&lt;/code&gt;, &lt;code&gt;pyflakes&lt;/code&gt; and McCabe. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/DmytroLitvinov/awesome-flake8-extensions"&gt;awesome-flake8-extensions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pylint-dev/pylint"&gt;pylint&lt;/a&gt; - A fully customizable source code analyzer.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/astral-sh/ruff"&gt;ruff&lt;/a&gt; - An extremely fast Python linter and code formatter.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Code Formatters 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/psf/black"&gt;black&lt;/a&gt; - The uncompromising Python code formatter.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timothycrosley/isort"&gt;isort&lt;/a&gt; - A Python utility / library to sort imports.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; - Yet another Python code formatter from Google.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Static Type Checkers, also see &lt;a href="https://github.com/typeddjango/awesome-python-typing"&gt;awesome-python-typing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python/mypy"&gt;mypy&lt;/a&gt; - Check variable types during compile time.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/facebook/pyre-check"&gt;pyre-check&lt;/a&gt; - Performant type checking.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python/typeshed"&gt;typeshed&lt;/a&gt; - Collection of library stubs for Python, with static types.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Static Type Annotations Generators 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Instagram/MonkeyType"&gt;monkeytype&lt;/a&gt; - A system for Python that generates static type annotations by collecting runtime types.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/google/pytype"&gt;pytype&lt;/a&gt; - Pytype checks and infers types for Python code - without requiring type annotations.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command-line Interface Development&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for building command-line applications.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Command-line Application Development 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/datafolklabs/cement"&gt;cement&lt;/a&gt; - CLI Application Framework for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pallets/click/"&gt;click&lt;/a&gt; - A package for creating beautiful command line interfaces in a composable way.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/openstack/cliff"&gt;cliff&lt;/a&gt; - A framework for creating command-line programs with multi-level commands.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/google/python-fire"&gt;python-fire&lt;/a&gt; - A library for creating command line interfaces from absolutely any Python object.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/prompt-toolkit/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt; - A library for building powerful interactive command lines.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Terminal Rendering 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/rsalmei/alive-progress"&gt;alive-progress&lt;/a&gt; - A new kind of Progress Bar, with real-time throughput, eta and very cool animations.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/peterbrittain/asciimatics"&gt;asciimatics&lt;/a&gt; - A package to create full-screen text UIs (from interactive forms to ASCII animations).&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/glamp/bashplotlib"&gt;bashplotlib&lt;/a&gt; - Making basic plots in the terminal.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tartley/colorama"&gt;colorama&lt;/a&gt; - Cross-platform colored terminal text.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Textualize/rich"&gt;rich&lt;/a&gt; - Python library for rich text and beautiful formatting in the terminal. Also provides a great &lt;code&gt;RichHandler&lt;/code&gt; log handler.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tqdm/tqdm"&gt;tqdm&lt;/a&gt; - Fast, extensible progress bar for loops and CLI.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command-line Tools&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Useful CLI-based tools for productivity.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Productivity Tools 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/copier-org/copier"&gt;copier&lt;/a&gt; - A library and command-line utility for rendering projects templates.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/cookiecutter/cookiecutter"&gt;cookiecutter&lt;/a&gt; - A command-line utility that creates projects from cookiecutters (project templates).&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sloria/doitlive"&gt;doitlive&lt;/a&gt; - A tool for live presentations in the terminal.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/gleitz/howdoi"&gt;howdoi&lt;/a&gt; - Instant coding answers via the command line.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pyinvoke/invoke"&gt;invoke&lt;/a&gt; - A tool for managing shell-oriented subprocesses and organizing executable Python code into CLI-invokable tasks.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/facebook/PathPicker"&gt;pathpicker&lt;/a&gt; - Select files out of bash output.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/nvbn/thefuck"&gt;thefuck&lt;/a&gt; - Correcting your previous console command.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tmux-python/tmuxp"&gt;tmuxp&lt;/a&gt; - A &lt;a href="https://github.com/tmux/tmux"&gt;tmux&lt;/a&gt; session manager.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timofurrer/try"&gt;try&lt;/a&gt; - A dead simple CLI to try out python packages - it's never been easier.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;CLI Enhancements 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/httpie/cli"&gt;httpie&lt;/a&gt; - A command line HTTP client, a user-friendly cURL replacement.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/laixintao/iredis"&gt;iredis&lt;/a&gt; - Redis CLI with autocompletion and syntax highlighting.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dbcli/litecli"&gt;litecli&lt;/a&gt; - SQLite CLI with autocompletion and syntax highlighting.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dbcli/mycli"&gt;mycli&lt;/a&gt; - MySQL CLI with autocompletion and syntax highlighting.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dbcli/pgcli"&gt;pgcli&lt;/a&gt; - PostgreSQL CLI with autocompletion and syntax highlighting.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Computer Vision&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for Computer Vision.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JaidedAI/EasyOCR"&gt;easyocr&lt;/a&gt; - Ready-to-use OCR with 40+ languages supported.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kornia/kornia/"&gt;kornia&lt;/a&gt; - Open Source Differentiable Computer Vision Library for PyTorch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opencv.org/"&gt;opencv&lt;/a&gt; - Open Source Computer Vision Library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/madmaze/pytesseract"&gt;pytesseract&lt;/a&gt; - A wrapper for &lt;a href="https://github.com/tesseract-ocr"&gt;Google Tesseract OCR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sirfz/tesserocr"&gt;tesserocr&lt;/a&gt; - Another simple, Pillow-friendly, wrapper around the &lt;code&gt;tesseract-ocr&lt;/code&gt; API for OCR.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration Files&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for storing and parsing configuration options.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/configparser.html"&gt;configparser&lt;/a&gt; - (Python standard library) INI file parser.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DiffSK/configobj"&gt;configobj&lt;/a&gt; - INI file parser with validation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/hydra"&gt;hydra&lt;/a&gt; - Hydra is a framework for elegantly configuring complex applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HBNetwork/python-decouple"&gt;python-decouple&lt;/a&gt; - Strict separation of settings from code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cryptography&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyca/cryptography"&gt;cryptography&lt;/a&gt; - A package designed to expose cryptographic primitives and recipes to Python developers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paramiko/paramiko"&gt;paramiko&lt;/a&gt; - The leading native Python SSHv2 protocol library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyca/pynacl"&gt;pynacl&lt;/a&gt; - Python binding to the Networking and Cryptography (NaCl) library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Data Analysis&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for data analyzing.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://pandas.pydata.org/"&gt;pandas&lt;/a&gt; - A library providing high-performance, easy-to-use data structures and data analysis tools.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws/aws-sdk-pandas"&gt;aws-sdk-pandas&lt;/a&gt; - Pandas on AWS.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/simonw/datasette"&gt;datasette&lt;/a&gt; - An open source multi-tool for exploring and publishing data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hi-primus/optimus"&gt;optimus&lt;/a&gt; - Agile Data Science Workflows made easy with PySpark.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Data Validation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for validating data. Used for forms in many cases.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyeve/cerberus"&gt;cerberus&lt;/a&gt; - A lightweight and extensible data validation library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Pylons/colander"&gt;colander&lt;/a&gt; - Validating and deserializing data obtained via XML, JSON, an HTML form post.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-jsonschema/jsonschema"&gt;jsonschema&lt;/a&gt; - An implementation of &lt;a href="http://json-schema.org/"&gt;JSON Schema&lt;/a&gt; for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/keleshev/schema"&gt;schema&lt;/a&gt; - A library for validating Python data structures.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/schematics/schematics"&gt;schematics&lt;/a&gt; - Data Structure Validation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alecthomas/voluptuous"&gt;voluptuous&lt;/a&gt; - A Python data validation library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pydantic/pydantic"&gt;pydantic&lt;/a&gt; - Data validation using Python type hints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Data Visualization&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for visualizing data. Also see &lt;a href="https://github.com/sorrycc/awesome-javascript#data-visualization"&gt;awesome-javascript&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/altair-viz/altair"&gt;altair&lt;/a&gt; - Declarative statistical visualization library for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bokeh/bokeh"&gt;bokeh&lt;/a&gt; - Interactive Web Plotting for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bloomberg/bqplot"&gt;bqplot&lt;/a&gt; - Interactive Plotting Library for the Jupyter Notebook.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciTools/cartopy"&gt;cartopy&lt;/a&gt; - A cartographic python library with matplotlib support.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mingrammer/diagrams"&gt;diagrams&lt;/a&gt; - Diagram as Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/matplotlib/matplotlib"&gt;matplotlib&lt;/a&gt; - A Python 2D plotting library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/has2k1/plotnine"&gt;plotnine&lt;/a&gt; - A grammar of graphics for Python based on ggplot2.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Kozea/pygal"&gt;pygal&lt;/a&gt; - A Python SVG Charts Creator.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pygraphviz/pygraphviz/"&gt;pygraphviz&lt;/a&gt; - Python interface to &lt;a href="http://www.graphviz.org/"&gt;Graphviz&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyqtgraph/pyqtgraph"&gt;pyqtgraph&lt;/a&gt; - Interactive and realtime 2D/3D/Image plotting and science/engineering widgets.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mwaskom/seaborn"&gt;seaborn&lt;/a&gt; - Statistical data visualization using Matplotlib.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vispy/vispy"&gt;vispy&lt;/a&gt; - High-performance scientific visualization based on OpenGL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Databases implemented in Python.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/patx/pickledb"&gt;pickleDB&lt;/a&gt; - A simple and lightweight key-value store for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/msiemens/tinydb"&gt;tinydb&lt;/a&gt; - A tiny, document-oriented database.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zopefoundation/ZODB"&gt;zodb&lt;/a&gt; - A native object database for Python. A key-value and object graph database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database Drivers&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for connecting and operating databases.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL - &lt;a href="http://shlomi-noach.github.io/awesome-mysql/"&gt;awesome-mysql&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PyMySQL/mysqlclient"&gt;mysqlclient&lt;/a&gt; - MySQL connector with Python 3 support (&lt;a href="https://sourceforge.net/projects/mysql-python/"&gt;mysql-python&lt;/a&gt; fork).&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PyMySQL/PyMySQL"&gt;pymysql&lt;/a&gt; - A pure Python MySQL driver compatible to mysql-python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;PostgreSQL - &lt;a href="https://github.com/dhamaniasad/awesome-postgres"&gt;awesome-postgres&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/psycopg/psycopg"&gt;psycopg&lt;/a&gt; - The most popular PostgreSQL adapter for Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;SQlite - &lt;a href="https://github.com/planetopendata/awesome-sqlite"&gt;awesome-sqlite&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.python.org/3/library/sqlite3.html"&gt;sqlite3&lt;/a&gt; - (Python standard library) SQlite interface compliant with DB-API 2.0.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/simonw/sqlite-utils"&gt;sqlite-utils&lt;/a&gt; - Python CLI utility and library for manipulating SQLite databases.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Other Relational Databases 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pymssql/pymssql"&gt;pymssql&lt;/a&gt; - A simple database interface to Microsoft SQL Server.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mymarilyn/clickhouse-driver"&gt;clickhouse-driver&lt;/a&gt; - Python driver with native interface for ClickHouse.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;NoSQL Databases 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/datastax/python-driver"&gt;cassandra-driver&lt;/a&gt; - The Python Driver for Apache Cassandra.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python-happybase/happybase"&gt;happybase&lt;/a&gt; - A developer-friendly library for Apache HBase.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dpkp/kafka-python"&gt;kafka-python&lt;/a&gt; - The Python client for Apache Kafka.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mongodb/mongo-python-driver"&gt;pymongo&lt;/a&gt; - The official Python client for MongoDB.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mongodb/motor"&gt;motor&lt;/a&gt; - The async Python driver for MongoDB.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/redis/redis-py"&gt;redis-py&lt;/a&gt; - The Python client for Redis.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Date and Time&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with dates and times.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arrow-py/arrow"&gt;arrow&lt;/a&gt; - A Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dateutil/dateutil"&gt;dateutil&lt;/a&gt; - Extensions to the standard Python &lt;a href="https://docs.python.org/3/library/datetime.html"&gt;datetime&lt;/a&gt; module.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sdispater/pendulum"&gt;pendulum&lt;/a&gt; - Python datetimes made easy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pytz/"&gt;pytz&lt;/a&gt; - World timezone definitions, modern and historical. Brings the &lt;a href="https://en.wikipedia.org/wiki/Tz_database"&gt;tz database&lt;/a&gt; into Python.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Debugging Tools&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for debugging code.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;pdb-like Debugger 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/gotcha/ipdb"&gt;ipdb&lt;/a&gt; - IPython-enabled &lt;a href="https://docs.python.org/3/library/pdb.html"&gt;pdb&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/inducer/pudb"&gt;pudb&lt;/a&gt; - A full-screen, console-based Python debugger.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Tracing 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ionelmc/python-manhole"&gt;manhole&lt;/a&gt; - Debugging UNIX socket connections and present the stacktraces for all threads and an interactive prompt.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ionelmc/python-hunter"&gt;python-hunter&lt;/a&gt; - A flexible code tracing toolkit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Profiler 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/benfred/py-spy"&gt;py-spy&lt;/a&gt; - A sampling profiler for Python programs. Written in Rust.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/nvdv/vprof"&gt;vprof&lt;/a&gt; - Visual Python profiler.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Others 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jazzband/django-debug-toolbar"&gt;django-debug-toolbar&lt;/a&gt; - Display various debug information for Django.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pallets-eco/flask-debugtoolbar"&gt;flask-debugtoolbar&lt;/a&gt; - A port of the django-debug-toolbar to flask.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/gruns/icecream"&gt;icecream&lt;/a&gt; - Inspect variables, expressions, and program execution with a single, simple function call.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/eliben/pyelftools"&gt;pyelftools&lt;/a&gt; - Parsing and analyzing ELF files and DWARF debugging information.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Deep Learning&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Frameworks for Neural Networks and Deep Learning. Also see &lt;a href="https://github.com/ChristosChristofidis/awesome-deep-learning"&gt;awesome-deep-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/keras-team/keras"&gt;keras&lt;/a&gt; - A high-level neural networks library and capable of running on top of either TensorFlow or Theano.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;pytorch&lt;/a&gt; - Tensors and Dynamic neural networks in Python with strong GPU acceleration.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Lightning-AI/pytorch-lightning"&gt;pytorch-lightning&lt;/a&gt; - Deep learning framework to train, deploy, and ship AI products Lightning fast.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DLR-RM/stable-baselines3"&gt;stable-baselines3&lt;/a&gt; - PyTorch implementations of Stable Baselines (deep) reinforcement learning algorithms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow"&gt;tensorflow&lt;/a&gt; - The most popular Deep Learning framework created by Google.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Theano/Theano"&gt;theano&lt;/a&gt; - A library for fast numerical computation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;DevOps Tools&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Software and libraries for DevOps.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configuration Management 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ansible/ansible"&gt;ansible&lt;/a&gt; - A radically simple IT automation platform.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/canonical/cloud-init"&gt;cloudinit&lt;/a&gt; - A multi-distribution package that handles early initialization of a cloud instance.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.openstack.org/"&gt;openstack&lt;/a&gt; - Open source software for building private and public clouds.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pyinfra-dev/pyinfra"&gt;pyinfra&lt;/a&gt; - A versatile CLI tools and python libraries to automate infrastructure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/saltstack/salt"&gt;saltstack&lt;/a&gt; - Infrastructure automation and management system.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;SSH-style Deployment 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sebastien/cuisine"&gt;cuisine&lt;/a&gt; - Chef-like functionality for Fabric.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/fabric/fabric"&gt;fabric&lt;/a&gt; - A simple, Pythonic tool for remote execution and deployment.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Process Management 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Supervisor/supervisor"&gt;supervisor&lt;/a&gt; - Supervisor process control system for UNIX.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Monitoring 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/giampaolo/psutil"&gt;psutil&lt;/a&gt; - A cross-platform process and system utilities module.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Backup 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/borgbackup/borg"&gt;borg&lt;/a&gt; - A deduplicating archiver with compression and encryption.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Distributed Computing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Frameworks and libraries for Distributed Computing.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Batch Processing 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dask/dask"&gt;dask&lt;/a&gt; - A flexible parallel computing library for analytic computing.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/spotify/luigi"&gt;luigi&lt;/a&gt; - A module that helps you build complex pipelines of batch jobs.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/apache/spark"&gt;PySpark&lt;/a&gt; - &lt;a href="https://spark.apache.org/"&gt;Apache Spark&lt;/a&gt; Python API.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ray-project/ray/"&gt;Ray&lt;/a&gt; - A system for parallel and distributed Python that unifies the machine learning ecosystem.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Stream Processing 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/robinhood/faust"&gt;faust&lt;/a&gt; - A stream processing library, porting the ideas from &lt;a href="https://kafka.apache.org/documentation/streams/"&gt;Kafka Streams&lt;/a&gt; to Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Parsely/streamparse"&gt;streamparse&lt;/a&gt; - Run Python code against real-time streams of data via &lt;a href="http://storm.apache.org/"&gt;Apache Storm&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries to create packaged executables for release distribution.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ronaldoussoren/py2app"&gt;py2app&lt;/a&gt; - Freezes Python scripts (Mac OS X).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/py2exe/py2exe"&gt;py2exe&lt;/a&gt; - Freezes Python scripts (Windows).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dashingsoft/pyarmor"&gt;pyarmor&lt;/a&gt; - A tool used to obfuscate python scripts, bind obfuscated scripts to fixed machine or expire obfuscated scripts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyinstaller/pyinstaller"&gt;pyinstaller&lt;/a&gt; - Converts Python programs into stand-alone executables (cross-platform).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/linkedin/shiv"&gt;shiv&lt;/a&gt; - A command line utility for building fully self-contained zipapps (PEP 441), but with all their dependencies included.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for generating project documentation.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sphinx-doc/sphinx/"&gt;sphinx&lt;/a&gt; - Python Documentation generator. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yoloseem/awesome-sphinxdoc"&gt;awesome-sphinxdoc&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitmproxy/pdoc"&gt;pdoc&lt;/a&gt; - Epydoc replacement to auto generate API documentation for Python libraries.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloader&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for downloading.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jindaxiang/akshare"&gt;akshare&lt;/a&gt; - A financial data interface library, built for human beings!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s3tools/s3cmd"&gt;s3cmd&lt;/a&gt; - A command line tool for managing Amazon S3 and CloudFront.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ytdl-org/youtube-dl/"&gt;youtube-dl&lt;/a&gt; - A command-line program to download videos from YouTube and other video sites.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Editor Plugins and IDEs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Emacs 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jorgenschaefer/elpy"&gt;elpy&lt;/a&gt; - Emacs Python Development Environment.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Vim 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/davidhalter/jedi-vim"&gt;jedi-vim&lt;/a&gt; - Vim bindings for the Jedi auto-completion library for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python-mode/python-mode"&gt;python-mode&lt;/a&gt; - An all in one plugin for turning Vim into a Python IDE.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Valloric/YouCompleteMe"&gt;YouCompleteMe&lt;/a&gt; - Includes &lt;a href="https://github.com/davidhalter/jedi"&gt;Jedi&lt;/a&gt;-based completion engine for Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Visual Studio 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Microsoft/PTVS"&gt;PTVS&lt;/a&gt; - Python Tools for Visual Studio.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Visual Studio Code 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-python.python"&gt;Python&lt;/a&gt; - The official VSCode extension with rich support for Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;IDE 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.jetbrains.com/pycharm/"&gt;PyCharm&lt;/a&gt; - Commercial Python IDE by JetBrains. Has free community edition available.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/spyder-ide/spyder"&gt;spyder&lt;/a&gt; - Open Source Python IDE.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Email&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for sending and parsing email.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Mail Servers 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/modoboa/modoboa"&gt;modoboa&lt;/a&gt; - A mail hosting and management platform including a modern Web UI.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/moggers87/salmon"&gt;salmon&lt;/a&gt; - A Python Mail Server.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Clients 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/martinrusev/imbox"&gt;imbox&lt;/a&gt; - Python IMAP for Humans.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kootenpv/yagmail"&gt;yagmail&lt;/a&gt; - Yet another Gmail/SMTP client.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Others 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mailgun/flanker"&gt;flanker&lt;/a&gt; - An email address and Mime parsing library.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/marrow/mailer"&gt;mailer&lt;/a&gt; - High-performance extensible mail delivery framework.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment Management&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for Python version and virtual environment management.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; - Simple Python version management.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/virtualenv"&gt;virtualenv&lt;/a&gt; - A tool to create isolated Python environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;File Manipulation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for file manipulation.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/mimetypes.html"&gt;mimetypes&lt;/a&gt; - (Python standard library) Map filenames to MIME types.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/pathlib.html"&gt;pathlib&lt;/a&gt; - (Python standard library) An cross-platform, object-oriented path library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jaraco/path.py"&gt;path.py&lt;/a&gt; - A module wrapper for &lt;a href="https://docs.python.org/3/library/os.path.html"&gt;os.path&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ahupp/python-magic"&gt;python-magic&lt;/a&gt; - A Python interface to the libmagic file type identification library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gorakhargosh/watchdog"&gt;watchdog&lt;/a&gt; - API and shell utilities to monitor file system events.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Functional Programming&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Functional Programming with Python.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evhub/coconut"&gt;coconut&lt;/a&gt; - A variant of Python built for simple, elegant, Pythonic functional programming.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Suor/funcy"&gt;funcy&lt;/a&gt; - A fancy and practical functional tools.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erikrose/more-itertools"&gt;more-itertools&lt;/a&gt; - More routines for operating on iterables, beyond &lt;code&gt;itertools&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dry-python/returns"&gt;returns&lt;/a&gt; - A set of type-safe monads, transformers, and composition utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytoolz/cytoolz/"&gt;cytoolz&lt;/a&gt; - Cython implementation of &lt;code&gt;Toolz&lt;/code&gt;: High performance functional utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytoolz/toolz"&gt;toolz&lt;/a&gt; - A collection of functional utilities for iterators, functions, and dictionaries.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GUI Development&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with graphical user interface applications.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/curses.html"&gt;curses&lt;/a&gt; - Built-in wrapper for &lt;a href="http://www.gnu.org/software/ncurses/"&gt;ncurses&lt;/a&gt; used to create terminal GUI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChrisKnott/Eel"&gt;Eel&lt;/a&gt; - A library for making simple Electron-like offline HTML/JS GUI apps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nucleic/enaml"&gt;enaml&lt;/a&gt; - Creating beautiful user-interfaces with Declarative Syntax like QML.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zoofIO/flexx"&gt;Flexx&lt;/a&gt; - Flexx is a pure Python toolkit for creating GUI's, that uses web technology for its rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chriskiehl/Gooey"&gt;Gooey&lt;/a&gt; - Turn command line programs into a full GUI application with one line.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kivy.org/"&gt;kivy&lt;/a&gt; - A library for creating NUI applications, running on Windows, Linux, Mac OS X, Android and iOS.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyglet/pyglet"&gt;pyglet&lt;/a&gt; - A cross-platform windowing and multimedia library for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pygobject.readthedocs.io/"&gt;PyGObject&lt;/a&gt; - Python Bindings for GLib/GObject/GIO/GTK+ (GTK+3).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.qt.io/qtforpython/"&gt;PyQt&lt;/a&gt; - Python bindings for the &lt;a href="https://www.qt.io/"&gt;Qt&lt;/a&gt; cross-platform application and UI framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PySimpleGUI/PySimpleGUI"&gt;PySimpleGUI&lt;/a&gt; - Wrapper for tkinter, Qt, WxPython and Remi.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/r0x0r/pywebview/"&gt;pywebview&lt;/a&gt; - A lightweight cross-platform native wrapper around a webview component.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wiki.python.org/moin/TkInter"&gt;Tkinter&lt;/a&gt; - Tkinter is Python's de-facto standard GUI package.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pybee/toga"&gt;Toga&lt;/a&gt; - A Python native, OS native GUI toolkit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://urwid.org/"&gt;urwid&lt;/a&gt; - A library for creating terminal GUI applications with strong support for widgets, events, rich colors, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wxpython.org/"&gt;wxPython&lt;/a&gt; - A blending of the wxWidgets C++ class library with the Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RaylockLLC/DearPyGui/"&gt;DearPyGui&lt;/a&gt; - A Simple GPU accelerated Python GUI framework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;GraphQL&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with GraphQL.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/graphql-python/graphene/"&gt;graphene&lt;/a&gt; - GraphQL framework for Python.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Game Development&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Awesome game development libraries.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://api.arcade.academy/en/latest/"&gt;Arcade&lt;/a&gt; - Arcade is a modern Python framework for crafting games with compelling graphics and sound.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cocos.com/en/cocos2d-x"&gt;Cocos2d&lt;/a&gt; - cocos2d is a framework for building 2D games, demos, and other graphical/interactive applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.harfang3d.com"&gt;Harfang3D&lt;/a&gt; - Python framework for 3D, VR and game development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.panda3d.org/"&gt;Panda3D&lt;/a&gt; - 3D game engine developed by Disney.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.pygame.org/news.html"&gt;Pygame&lt;/a&gt; - Pygame is a set of Python modules designed for writing games.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.ogre3d.org/tikiwiki/PyOgre"&gt;PyOgre&lt;/a&gt; - Python bindings for the Ogre 3D render engine, can be used for games, simulations, anything 3D.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://pyopengl.sourceforge.net/"&gt;PyOpenGL&lt;/a&gt; - Python ctypes bindings for OpenGL and it's related APIs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pysdl2.readthedocs.io"&gt;PySDL2&lt;/a&gt; - A ctypes based wrapper for the SDL2 library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.renpy.org/"&gt;RenPy&lt;/a&gt; - A Visual Novel engine.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Geolocation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for geocoding addresses and working with latitudes and longitudes.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SmileyChris/django-countries"&gt;django-countries&lt;/a&gt; - A Django app that provides a country field for models and forms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/ref/contrib/gis/"&gt;geodjango&lt;/a&gt; - A world-class geographic web framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jazzband/geojson"&gt;geojson&lt;/a&gt; - Python bindings and utilities for GeoJSON.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/geopy/geopy"&gt;geopy&lt;/a&gt; - Python Geocoding Toolbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;HTML Manipulation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with HTML and XML.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;beautifulsoup&lt;/a&gt; - Providing Pythonic idioms for iterating, searching, and modifying HTML or XML.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla/bleach"&gt;bleach&lt;/a&gt; - A whitelist-based HTML sanitization and text linkification library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/cssutils/"&gt;cssutils&lt;/a&gt; - A CSS library for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/html5lib/html5lib-python"&gt;html5lib&lt;/a&gt; - A standards-compliant library for parsing and serializing HTML documents and fragments.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt; - A very fast, easy-to-use and versatile library for handling HTML and XML.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pallets/markupsafe"&gt;markupsafe&lt;/a&gt; - Implements a XML/HTML/XHTML Markup safe string for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gawel/pyquery"&gt;pyquery&lt;/a&gt; - A jQuery-like library for parsing HTML.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stchris/untangle"&gt;untangle&lt;/a&gt; - Converts XML documents to Python objects for easy access.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://weasyprint.org"&gt;WeasyPrint&lt;/a&gt; - A visual rendering engine for HTML and CSS that can export to PDF.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xmldataset.readthedocs.io/en/latest/"&gt;xmldataset&lt;/a&gt; - Simple XML Parsing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/martinblech/xmltodict"&gt;xmltodict&lt;/a&gt; - Working with XML feel like you are working with JSON.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;HTTP Clients&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with HTTP.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/encode/httpx"&gt;httpx&lt;/a&gt; - A next generation HTTP client for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;requests&lt;/a&gt; - HTTP Requests for Humans.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/twisted/treq"&gt;treq&lt;/a&gt; - Python requests like API built on top of Twisted's HTTP client.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/urllib3/urllib3"&gt;urllib3&lt;/a&gt; - A HTTP library with thread-safe connection pooling, file post support, sanity friendly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hardware&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for programming with hardware.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/boppreh/keyboard"&gt;keyboard&lt;/a&gt; - Hook and simulate global keyboard events on Windows and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/boppreh/mouse"&gt;mouse&lt;/a&gt; - Hook and simulate global mouse events on Windows and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moses-palmer/pynput"&gt;pynput&lt;/a&gt; - A library to control and monitor input devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/secdev/scapy"&gt;scapy&lt;/a&gt; - A brilliant packet manipulation library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Image Processing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for manipulating images.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-pillow/Pillow"&gt;pillow&lt;/a&gt; - Pillow is the friendly &lt;a href="http://www.pythonware.com/products/pil/"&gt;PIL&lt;/a&gt; fork.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WhyNotHugo/python-barcode"&gt;python-barcode&lt;/a&gt; - Create barcodes in Python with no extra dependencies.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://github.com/pymatting/pymatting"&gt;pymatting&lt;/a&gt; - A library for alpha matting.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lincolnloop/python-qrcode"&gt;python-qrcode&lt;/a&gt; - A pure Python QR Code generator.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dylanaraps/pywal"&gt;pywal&lt;/a&gt; - A tool that generates color schemes from images.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/libvips/pyvips"&gt;pyvips&lt;/a&gt; - A fast image processing library with low memory needs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fogleman/Quads"&gt;quads&lt;/a&gt; - Computer art based on quadtrees.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://scikit-image.org/"&gt;scikit-image&lt;/a&gt; - A Python library for (scientific) image processing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thumbor/thumbor"&gt;thumbor&lt;/a&gt; - A smart imaging service. It enables on-demand crop, re-sizing and flipping of images.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emcconville/wand"&gt;wand&lt;/a&gt; - Python bindings for &lt;a href="http://www.imagemagick.org/script/magick-wand.php"&gt;MagickWand&lt;/a&gt;, C API for ImageMagick.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Implementations&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Implementations of Python.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python/cpython"&gt;cpython&lt;/a&gt; - &lt;strong&gt;Default, most widely used implementation of the Python programming language written in C.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cython/cython"&gt;cython&lt;/a&gt; - Optimizing Static Compiler for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metawilm/cl-python"&gt;clpython&lt;/a&gt; - Implementation of the Python programming language written in Common Lisp.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/IronLanguages/ironpython3"&gt;ironpython&lt;/a&gt; - Implementation of the Python programming language written in C#.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/micropython/micropython"&gt;micropython&lt;/a&gt; - A lean and efficient Python programming language implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/numba/numba"&gt;numba&lt;/a&gt; - Python JIT compiler to LLVM aimed at scientific Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Maratyszcza/PeachPy"&gt;peachpy&lt;/a&gt; - x86-64 assembler embedded in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://foss.heptapod.net/pypy/pypy"&gt;pypy&lt;/a&gt; - A very fast and compliant implementation of the Python language.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyston/pyston/"&gt;pyston&lt;/a&gt; - A Python implementation using JIT techniques.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Interactive Interpreter&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Interactive Python interpreters (REPL).&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bpython/bpython"&gt;bpython&lt;/a&gt; - A fancy interface to the Python interpreter.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jupyter.org"&gt;Jupyter Notebook (IPython)&lt;/a&gt; - A rich toolkit to help you make the most out of using Python interactively. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/markusschanta/awesome-jupyter"&gt;awesome-jupyter&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanslenders/ptpython"&gt;ptpython&lt;/a&gt; - Advanced Python REPL built on top of the &lt;a href="https://github.com/jonathanslenders/python-prompt-toolkit"&gt;python-prompt-toolkit&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Internationalization&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with i18n.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://babel.pocoo.org/en/latest/"&gt;Babel&lt;/a&gt; - An internationalization library for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ovalhub/pyicu"&gt;PyICU&lt;/a&gt; - A wrapper of International Components for Unicode C++ library (&lt;a href="http://site.icu-project.org/"&gt;ICU&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Job Scheduler&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for scheduling jobs.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt; - Airflow is a platform to programmatically author, schedule and monitor workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://apscheduler.readthedocs.io/en/latest/"&gt;APScheduler&lt;/a&gt; - A light but powerful in-process task scheduler that lets you schedule functions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thauber/django-schedule"&gt;django-schedule&lt;/a&gt; - A calendaring app for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://pydoit.org/"&gt;doit&lt;/a&gt; - A task runner and build tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gunnery/gunnery"&gt;gunnery&lt;/a&gt; - Multipurpose task execution tool for distributed systems with web-based interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://joblib.readthedocs.io/"&gt;Joblib&lt;/a&gt; - A set of tools to provide lightweight pipelining in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengsp/plan"&gt;Plan&lt;/a&gt; - Writing crontab file in Python like a charm.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PrefectHQ/prefect"&gt;Prefect&lt;/a&gt; - A modern workflow orchestration framework that makes it easy to build, schedule and monitor robust data pipelines.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbader/schedule"&gt;schedule&lt;/a&gt; - Python job scheduling for humans.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/knipknap/SpiffWorkflow"&gt;Spiff&lt;/a&gt; - A powerful workflow engine implemented in pure Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openstack.org/developer/taskflow/"&gt;TaskFlow&lt;/a&gt; - A Python library that helps to make task execution easy, consistent and reliable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Logging&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for generating and working with logs.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://logbook.readthedocs.io/en/stable/"&gt;logbook&lt;/a&gt; - Logging replacement for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.python.org/3/library/logging.html"&gt;logging&lt;/a&gt; - (Python standard library) Logging facility for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Delgan/loguru"&gt;loguru&lt;/a&gt; - Library which aims to bring enjoyable logging in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getsentry/sentry-python"&gt;sentry-python&lt;/a&gt; - Sentry SDK for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.structlog.org/en/stable/"&gt;structlog&lt;/a&gt; - Structured logging made easy.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Machine Learning&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for Machine Learning. Also see &lt;a href="https://github.com/josephmisiti/awesome-machine-learning#python"&gt;awesome-machine-learning&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openai/gym"&gt;gym&lt;/a&gt; - A toolkit for developing and comparing reinforcement learning algorithms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h2oai/h2o-3"&gt;H2O&lt;/a&gt; - Open Source Fast Scalable Machine Learning Platform.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhamner/Metrics"&gt;Metrics&lt;/a&gt; - Machine learning evaluation metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/numenta/nupic"&gt;NuPIC&lt;/a&gt; - Numenta Platform for Intelligent Computing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://scikit-learn.org/"&gt;scikit-learn&lt;/a&gt; - The most popular Python library for Machine Learning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://spark.apache.org/docs/latest/ml-guide.html"&gt;Spark ML&lt;/a&gt; - &lt;a href="http://spark.apache.org/"&gt;Apache Spark&lt;/a&gt;'s scalable Machine Learning library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josephreisinger/vowpal_porpoise"&gt;vowpal_porpoise&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://github.com/JohnLangford/vowpal_wabbit/"&gt;Vowpal Wabbit&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmlc/xgboost"&gt;xgboost&lt;/a&gt; - A scalable, portable, and distributed gradient boosting library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb"&gt;MindsDB&lt;/a&gt; - MindsDB is an open source AI layer for existing databases that allows you to effortlessly develop, train and deploy state-of-the-art machine learning models using standard queries.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Microsoft Windows&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Python programming on Microsoft Windows.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://python-xy.github.io/"&gt;Python(x,y)&lt;/a&gt; - Scientific-applications-oriented Python Distribution based on Qt and Spyder.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/"&gt;pythonlibs&lt;/a&gt; - Unofficial Windows binaries for Python extension packages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythonnet/pythonnet"&gt;PythonNet&lt;/a&gt; - Python Integration with the .NET Common Language Runtime (CLR).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mhammond/pywin32"&gt;PyWin32&lt;/a&gt; - Python Extensions for Windows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://winpython.github.io/"&gt;WinPython&lt;/a&gt; - Portable development environment for Windows 7/8.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Miscellaneous&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Useful libraries or tools that don't fit in the categories above.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jek/blinker"&gt;blinker&lt;/a&gt; - A fast Python in-process signal/event dispatching system.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mahmoud/boltons"&gt;boltons&lt;/a&gt; - A set of pure-Python utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pallets/itsdangerous"&gt;itsdangerous&lt;/a&gt; - Various helpers to pass trusted data to untrusted environments.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/magenta/magenta"&gt;magenta&lt;/a&gt; - A tool to generate music and art using artificial intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitsuhiko/pluginbase"&gt;pluginbase&lt;/a&gt; - A simple but flexible plugin system for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.tryton.org/"&gt;tryton&lt;/a&gt; - A general purpose business framework.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Natural Language Processing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with human languages.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;General 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/RaRe-Technologies/gensim"&gt;gensim&lt;/a&gt; - Topic Modeling for Humans.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/saffsd/langid.py"&gt;langid.py&lt;/a&gt; - Stand-alone language identification system.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www.nltk.org/"&gt;nltk&lt;/a&gt; - A leading platform for building Python programs to work with human language data.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/clips/pattern"&gt;pattern&lt;/a&gt; - A web mining module.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/aboSamoor/polyglot"&gt;polyglot&lt;/a&gt; - Natural language pipeline supporting hundreds of languages.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/facebookresearch/pytext"&gt;pytext&lt;/a&gt; - A natural language modeling framework based on PyTorch.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/PetrochukM/PyTorch-NLP"&gt;PyTorch-NLP&lt;/a&gt; - A toolkit enabling rapid deep learning NLP prototyping for research.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://spacy.io/"&gt;spacy&lt;/a&gt; - A library for industrial-strength natural language processing in Python and Cython.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/stanfordnlp/stanza"&gt;Stanza&lt;/a&gt; - The Stanford NLP Group's official Python library, supporting 60+ languages.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Chinese 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/fighting41love/funNLP"&gt;funNLP&lt;/a&gt; - A collection of tools and datasets for Chinese NLP.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/fxsjy/jieba"&gt;jieba&lt;/a&gt; - The most popular Chinese text segmentation library.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lancopku/pkuseg-python"&gt;pkuseg-python&lt;/a&gt; - A toolkit for Chinese word segmentation in various domains.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/isnowfy/snownlp"&gt;snownlp&lt;/a&gt; - A library for processing Chinese text.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Network Virtualization&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Tools and libraries for Virtual Networking and SDN (Software Defined Networking).&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mininet/mininet"&gt;mininet&lt;/a&gt; - A popular network emulator and API written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/napalm-automation/napalm"&gt;napalm&lt;/a&gt; - Cross-vendor API to manipulate network devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/noxrepo/pox"&gt;pox&lt;/a&gt; - A Python-based SDN control applications, such as OpenFlow SDN controllers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;News Feed&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for building user's activities.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/justquick/django-activity-stream"&gt;django-activity-stream&lt;/a&gt; - Generating generic activity streams from the actions on your site.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tschellenbach/Stream-Framework"&gt;Stream Framework&lt;/a&gt; - Building news feed and notification systems using Cassandra and Redis.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ORM&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries that implement Object-Relational Mapping or data mapping techniques.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Relational Databases 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.djangoproject.com/en/dev/topics/db/models/"&gt;Django Models&lt;/a&gt; - The Django ORM.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt; - The Python SQL Toolkit and Object Relational Mapper. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/dahlia/awesome-sqlalchemy"&gt;awesome-sqlalchemy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pudo/dataset"&gt;dataset&lt;/a&gt; - Store Python dicts in a database - works with SQLite, MySQL, and PostgreSQL.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sdispater/orator"&gt;orator&lt;/a&gt; - The Orator ORM provides a simple yet beautiful ActiveRecord implementation.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/encode/orm"&gt;orm&lt;/a&gt; - An async ORM.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/coleifer/peewee"&gt;peewee&lt;/a&gt; - A small, expressive ORM.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ponyorm/pony/"&gt;pony&lt;/a&gt; - ORM that provides a generator-oriented interface to SQL.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/web2py/pydal/"&gt;pydal&lt;/a&gt; - A pure Python Database Abstraction Layer.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;NoSQL Databases 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/stephenmcd/hot-redis"&gt;hot-redis&lt;/a&gt; - Rich Python data types for Redis.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/MongoEngine/mongoengine"&gt;mongoengine&lt;/a&gt; - A Python Object-Document-Mapper for working with MongoDB.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pynamodb/PynamoDB"&gt;PynamoDB&lt;/a&gt; - A Pythonic interface for &lt;a href="https://aws.amazon.com/dynamodb/"&gt;Amazon DynamoDB&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kiddouk/redisco"&gt;redisco&lt;/a&gt; - A Python Library for Simple Models and Containers Persisted in Redis.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Package Management&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for package and dependency management.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pip.pypa.io/en/stable/"&gt;pip&lt;/a&gt; - The package installer for Python. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jazzband/pip-tools"&gt;pip-tools&lt;/a&gt; - A set of tools to keep your pinned Python dependencies fresh.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/conda/conda/"&gt;conda&lt;/a&gt; - Cross-platform, Python-agnostic binary package manager.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sdispater/poetry"&gt;poetry&lt;/a&gt; - Python dependency management and packaging made easy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; - An extremely fast Python package and project manager, written in Rust.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Package Repositories&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Local PyPI repository server and proxies.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/bandersnatch/"&gt;bandersnatch&lt;/a&gt; - PyPI mirroring tool provided by Python Packaging Authority (PyPA).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/devpi/devpi"&gt;devpi&lt;/a&gt; - PyPI server and packaging/testing/release tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jazzband/localshop"&gt;localshop&lt;/a&gt; - Local PyPI server (custom packages and auto-mirroring of pypi).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/warehouse"&gt;warehouse&lt;/a&gt; - Next generation Python Package Repository (PyPI).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Penetration Testing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Frameworks and tools for penetration testing.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Manisso/fsociety"&gt;fsociety&lt;/a&gt; - A Penetration testing framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trustedsec/social-engineer-toolkit"&gt;setoolkit&lt;/a&gt; - A toolkit for social engineering.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sqlmapproject/sqlmap"&gt;sqlmap&lt;/a&gt; - Automatic SQL injection and database takeover tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Permissions&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries that allow or deny users access to data or functionality.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django-guardian/django-guardian"&gt;django-guardian&lt;/a&gt; - Implementation of per object permissions for Django 1.2+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dfunckt/django-rules"&gt;django-rules&lt;/a&gt; - A tiny but powerful app providing object-level permissions to Django, without requiring a database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Processes&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for starting and communicating with OS processes.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/amitt001/delegator.py"&gt;delegator.py&lt;/a&gt; - &lt;a href="https://docs.python.org/3/library/subprocess.html"&gt;Subprocesses&lt;/a&gt; for Humans 2.0.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sarge.readthedocs.io/en/latest/"&gt;sarge&lt;/a&gt; - Yet another wrapper for subprocess.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/amoffat/sh"&gt;sh&lt;/a&gt; - A full-fledged subprocess replacement for Python.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Recommender Systems&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for building recommender systems.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spotify/annoy"&gt;annoy&lt;/a&gt; - Approximate Nearest Neighbors in C++/Python optimized for memory usage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibayer/fastFM"&gt;fastFM&lt;/a&gt; - A library for Factorization Machines.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benfred/implicit"&gt;implicit&lt;/a&gt; - A fast Python implementation of collaborative filtering for implicit datasets.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/guestwalk/libffm"&gt;libffm&lt;/a&gt; - A library for Field-aware Factorization Machine (FFM).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lyst/lightfm"&gt;lightfm&lt;/a&gt; - A Python implementation of a number of popular recommendation algorithms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/maciejkula/spotlight"&gt;spotlight&lt;/a&gt; - Deep recommender models using PyTorch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NicolasHug/Surprise"&gt;Surprise&lt;/a&gt; - A scikit for building and analyzing recommender systems.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jfkirk/tensorrec"&gt;tensorrec&lt;/a&gt; - A Recommendation Engine Framework in TensorFlow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Refactoring&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Refactoring tools and libraries for Python&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://bicyclerepair.sourceforge.net/"&gt;Bicycle Repair Man&lt;/a&gt; - Bicycle Repair Man, a refactoring tool for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pybowler.io/"&gt;Bowler&lt;/a&gt; - Safe code refactoring for modern Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-rope/rope"&gt;Rope&lt;/a&gt; - Rope is a python refactoring library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RESTful API&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for building RESTful APIs.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Django 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/encode/django-rest-framework"&gt;django-rest-framework&lt;/a&gt; - A powerful and flexible toolkit to build web APIs.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/django-tastypie/django-tastypie"&gt;django-tastypie&lt;/a&gt; - Creating delicious APIs for Django apps.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Flask 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pyeve/eve"&gt;eve&lt;/a&gt; - REST API framework powered by Flask, MongoDB and good intentions.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/flask-api/flask-api"&gt;flask-api&lt;/a&gt; - Browsable Web APIs for Flask.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/flask-restful/flask-restful"&gt;flask-restful&lt;/a&gt; - Quickly building REST APIs for Flask.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Pyramid 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/Cornices/cornice"&gt;cornice&lt;/a&gt; - A RESTful framework for Pyramid.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Framework agnostic 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/falconry/falcon"&gt;falcon&lt;/a&gt; - A high-performance framework for building cloud APIs and web app backends.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;fastapi&lt;/a&gt; - A modern, fast, web framework for building APIs with Python 3.6+ based on standard Python type hints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hugapi/hug"&gt;hug&lt;/a&gt; - A Python 3 framework for cleanly exposing APIs.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jeffknupp/sandman2"&gt;sandman2&lt;/a&gt; - Automated REST APIs for existing database-driven systems.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sanic-org/sanic"&gt;sanic&lt;/a&gt; - A Python 3.6+ web server and web framework that's written to go fast.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Robotics&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for robotics.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics"&gt;PythonRobotics&lt;/a&gt; - This is a compilation of various robotics algorithms with visualizations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://wiki.ros.org/rospy"&gt;rospy&lt;/a&gt; - This is a library for ROS (Robot Operating System).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RPC Servers&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;RPC-compatible servers.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tomerfiliba/rpyc"&gt;RPyC&lt;/a&gt; (Remote Python Call) - A transparent and symmetric RPC library for Python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0rpc/zerorpc-python"&gt;zeroRPC&lt;/a&gt; - zerorpc is a flexible RPC implementation based on &lt;a href="http://zeromq.org/"&gt;ZeroMQ&lt;/a&gt; and &lt;a href="http://msgpack.org/"&gt;MessagePack&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Science&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for scientific computing. Also see &lt;a href="https://github.com/TomNicholas/Python-for-Scientists"&gt;Python-for-Scientists&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.astropy.org/"&gt;astropy&lt;/a&gt; - A community Python library for Astronomy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbio-nextgen"&gt;bcbio-nextgen&lt;/a&gt; - Providing best-practice pipelines for fully automated high throughput sequencing analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chapmanb/bcbb"&gt;bccb&lt;/a&gt; - Collection of useful code related to biological analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://biopython.org/wiki/Main_Page"&gt;Biopython&lt;/a&gt; - Biopython is a set of freely available tools for biological computation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://cclib.github.io/"&gt;cclib&lt;/a&gt; - A library for parsing and interpreting the results of computational chemistry packages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://colour-science.org/"&gt;Colour&lt;/a&gt; - Implementing a comprehensive number of colour theory transformations and algorithms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benedekrozemberczki/karateclub"&gt;Karate Club&lt;/a&gt; - Unsupervised machine learning toolbox for graph structured data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://networkx.github.io/"&gt;NetworkX&lt;/a&gt; - A high-productivity software for complex networks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://nipy.org"&gt;NIPY&lt;/a&gt; - A collection of neuroimaging toolkits.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.numpy.org/"&gt;NumPy&lt;/a&gt; - A fundamental package for scientific computing with Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/obspy/obspy/wiki/"&gt;ObsPy&lt;/a&gt; - A Python toolbox for seismology.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://open-babel.readthedocs.io/"&gt;Open Babel&lt;/a&gt; - A chemical toolbox designed to speak the many languages of chemical data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.pydy.org/"&gt;PyDy&lt;/a&gt; - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pymc-devs/pymc3"&gt;PyMC&lt;/a&gt; - Markov Chain Monte Carlo sampling toolkit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://qutip.org/"&gt;QuTiP&lt;/a&gt; - Quantum Toolbox in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.rdkit.org/"&gt;RDKit&lt;/a&gt; - Cheminformatics and Machine Learning Software.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scipy.org/"&gt;SciPy&lt;/a&gt; - A Python-based ecosystem of open-source software for mathematics, science, and engineering.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/team-simpy/simpy"&gt;SimPy&lt;/a&gt; - A process-based discrete-event simulation framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/statsmodels/statsmodels"&gt;statsmodels&lt;/a&gt; - Statistical modeling and econometrics in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sympy/sympy"&gt;SymPy&lt;/a&gt; - A Python library for symbolic mathematics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quantopian/zipline"&gt;Zipline&lt;/a&gt; - A Pythonic algorithmic trading library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Search&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries and software for indexing and performing search queries on data.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django-haystack/django-haystack"&gt;django-haystack&lt;/a&gt; - Modular search for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elastic/elasticsearch-dsl-py"&gt;elasticsearch-dsl-py&lt;/a&gt; - The official high-level Python client for Elasticsearch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html"&gt;elasticsearch-py&lt;/a&gt; - The official low-level Python client for &lt;a href="https://www.elastic.co/products/elasticsearch"&gt;Elasticsearch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django-haystack/pysolr"&gt;pysolr&lt;/a&gt; - A lightweight Python wrapper for &lt;a href="https://lucene.apache.org/solr/"&gt;Apache Solr&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://whoosh.readthedocs.io/en/latest/"&gt;whoosh&lt;/a&gt; - A fast, pure Python search engine library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Serialization&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for serializing complex data types&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marshmallow-code/marshmallow"&gt;marshmallow&lt;/a&gt; - A lightweight library for converting complex objects to and from simple Python datatypes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TkTech/pysimdjson"&gt;pysimdjson&lt;/a&gt; - A Python bindings for &lt;a href="https://github.com/lemire/simdjson"&gt;simdjson&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-rapidjson/python-rapidjson"&gt;python-rapidjson&lt;/a&gt; - A Python wrapper around &lt;a href="https://github.com/Tencent/rapidjson"&gt;RapidJSON&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/esnme/ultrajson"&gt;ultrajson&lt;/a&gt; - A fast JSON decoder and encoder written in C with Python bindings.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Serverless Frameworks&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Frameworks for developing serverless Python code.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nficano/python-lambda"&gt;python-lambda&lt;/a&gt; - A toolkit for developing and deploying Python code in AWS Lambda.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zappa/Zappa"&gt;Zappa&lt;/a&gt; - A tool for deploying WSGI applications on AWS Lambda and API Gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Shell&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Shells based on Python.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xonsh/xonsh/"&gt;xonsh&lt;/a&gt; - A Python-powered, cross-platform, Unix-gazing shell language and command prompt.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Specific Formats Processing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating specific text formats.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;General 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jazzband/tablib"&gt;tablib&lt;/a&gt; - A module for Tabular Datasets in XLS, CSV, JSON, YAML.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Office 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/elapouya/python-docx-template"&gt;docxtpl&lt;/a&gt; - Editing a docx document by jinja2 template&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://openpyxl.readthedocs.io/en/stable/"&gt;openpyxl&lt;/a&gt; - A library for reading and writing Excel 2010 xlsx/xlsm/xltx/xltm files.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pyexcel/pyexcel"&gt;pyexcel&lt;/a&gt; - Providing one API for reading, manipulating and writing csv, ods, xls, xlsx and xlsm files.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python-openxml/python-docx"&gt;python-docx&lt;/a&gt; - Reads, queries and modifies Microsoft Word 2007/2008 docx files.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/scanny/python-pptx"&gt;python-pptx&lt;/a&gt; - Python library for creating and updating PowerPoint (.pptx) files.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/unoconv/unoconv"&gt;unoconv&lt;/a&gt; - Convert between any document format supported by LibreOffice/OpenOffice.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jmcnamara/XlsxWriter"&gt;XlsxWriter&lt;/a&gt; - A Python module for creating Excel .xlsx files.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ZoomerAnalytics/xlwings"&gt;xlwings&lt;/a&gt; - A BSD-licensed library that makes it easy to call Python from Excel and vice versa.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/python-excel/xlwt"&gt;xlwt&lt;/a&gt; / &lt;a href="https://github.com/python-excel/xlrd"&gt;xlrd&lt;/a&gt; - Writing and reading data and formatting information from Excel files.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;PDF 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pdfminer/pdfminer.six"&gt;pdfminer.six&lt;/a&gt; - Pdfminer.six is a community maintained fork of the original PDFMiner.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mstamy2/PyPDF2"&gt;PyPDF2&lt;/a&gt; - A library capable of splitting, merging and transforming PDF pages.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.reportlab.com/opensource/"&gt;ReportLab&lt;/a&gt; - Allowing Rapid creation of rich PDF documents.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Markdown 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lepture/mistune"&gt;Mistune&lt;/a&gt; - Fastest and full featured pure Python parsers of Markdown.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/waylan/Python-Markdown"&gt;Python-Markdown&lt;/a&gt; - A Python implementation of John Gruber’s Markdown.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;YAML 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://pyyaml.org/"&gt;PyYAML&lt;/a&gt; - YAML implementations for Python.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;CSV 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/wireservice/csvkit"&gt;csvkit&lt;/a&gt; - Utilities for converting to and working with CSV.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Archive 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mitsuhiko/unp"&gt;unp&lt;/a&gt; - A command line tool that can unpack archives easily.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Static Site Generator&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Static site generator is a software that takes some text + templates as input and produces HTML files on the output.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lektor/lektor"&gt;lektor&lt;/a&gt; - An easy to use static CMS and blog engine.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mkdocs/mkdocs/"&gt;mkdocs&lt;/a&gt; - Markdown friendly documentation generator.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunainapai/makesite"&gt;makesite&lt;/a&gt; - Simple, lightweight, and magic-free static site/blog generator (&amp;lt; 130 lines).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getnikola/nikola"&gt;nikola&lt;/a&gt; - A static website and blog generator.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/getpelican/pelican"&gt;pelican&lt;/a&gt; - Static site generator that supports Markdown and reST syntax.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tagging&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for tagging items.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jazzband/django-taggit"&gt;django-taggit&lt;/a&gt; - Simple tagging for Django.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Task Queues&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with task queues.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.celeryproject.org/en/stable/"&gt;celery&lt;/a&gt; - An asynchronous task queue/job queue based on distributed message passing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bogdanp/dramatiq"&gt;dramatiq&lt;/a&gt; - A fast and reliable background task processing library for Python 3.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/coleifer/huey"&gt;huey&lt;/a&gt; - Little multi-threaded task queue.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pricingassistant/mrq"&gt;mrq&lt;/a&gt; - A distributed worker task queue in Python using Redis &amp;amp; gevent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rq/rq"&gt;rq&lt;/a&gt; - Simple job queues for Python.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Template Engine&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries and tools for templating and lexing.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://genshi.edgewall.org/"&gt;Genshi&lt;/a&gt; - Python templating toolkit for generation of web-aware output.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pallets/jinja"&gt;Jinja2&lt;/a&gt; - A modern and designer friendly templating language.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.makotemplates.org/"&gt;Mako&lt;/a&gt; - Hyperfast and lightweight templating for the Python platform.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for testing codebases and generating test data.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Testing Frameworks 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/HypothesisWorks/hypothesis"&gt;hypothesis&lt;/a&gt; - Hypothesis is an advanced Quickcheck style property based testing library.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/nose-devs/nose2"&gt;nose2&lt;/a&gt; - The successor to &lt;code&gt;nose&lt;/code&gt;, based on `unittest2.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.pytest.org/en/latest/"&gt;pytest&lt;/a&gt; - A mature full-featured Python testing tool.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/robotframework/robotframework"&gt;Robot Framework&lt;/a&gt; - A generic test automation framework.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.html"&gt;unittest&lt;/a&gt; - (Python standard library) Unit testing framework.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Test Runners 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/CleanCut/green"&gt;green&lt;/a&gt; - A clean, colorful test runner.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://nestorsalceda.github.io/mamba/"&gt;mamba&lt;/a&gt; - The definitive testing tool for Python. Born under the banner of BDD.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://tox.readthedocs.io/en/latest/"&gt;tox&lt;/a&gt; - Auto builds and tests distributions in multiple Python versions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;GUI / Web Testing 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/locustio/locust"&gt;locust&lt;/a&gt; - Scalable user load testing tool written in Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/asweigart/pyautogui"&gt;PyAutoGUI&lt;/a&gt; - PyAutoGUI is a cross-platform GUI automation Python module for human beings.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kiwicom/schemathesis"&gt;Schemathesis&lt;/a&gt; - A tool for automatic property-based testing of web applications built with Open API / Swagger specifications.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/project/selenium/"&gt;Selenium&lt;/a&gt; - Python bindings for &lt;a href="http://www.seleniumhq.org/"&gt;Selenium&lt;/a&gt; WebDriver.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/seatgeek/sixpack"&gt;sixpack&lt;/a&gt; - A language-agnostic A/B Testing framework.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/cobrateam/splinter"&gt;splinter&lt;/a&gt; - Open source tool for testing web applications.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Mock 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/project/doublex/"&gt;doublex&lt;/a&gt; - Powerful test doubles framework for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/spulec/freezegun"&gt;freezegun&lt;/a&gt; - Travel through time by mocking the datetime module.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/patrys/httmock"&gt;httmock&lt;/a&gt; - A mocking library for requests for Python 2.6+ and 3.2+.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/gabrielfalcao/HTTPretty"&gt;httpretty&lt;/a&gt; - HTTP request mock tool for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.python.org/3/library/unittest.mock.html"&gt;mock&lt;/a&gt; - (Python standard library) A mocking and patching library.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mindflayer/python-mocket"&gt;mocket&lt;/a&gt; - A socket mock framework with gevent/asyncio/SSL support.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/getsentry/responses"&gt;responses&lt;/a&gt; - A utility library for mocking out the requests Python library.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/kevin1024/vcrpy"&gt;VCR.py&lt;/a&gt; - Record and replay HTTP interactions on your tests.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Object Factories 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/FactoryBoy/factory_boy"&gt;factory_boy&lt;/a&gt; - A test fixtures replacement for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/klen/mixer"&gt;mixer&lt;/a&gt; - Another fixtures replacement. Supports Django, Flask, SQLAlchemy, Peewee and etc.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vandersonmota/model_mommy"&gt;model_mommy&lt;/a&gt; - Creating random fixtures for testing in Django.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Code Coverage 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/project/coverage/"&gt;coverage&lt;/a&gt; - Code coverage measurement.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fake Data 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/emirozer/fake2db"&gt;fake2db&lt;/a&gt; - Fake database generator.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/joke2k/faker"&gt;faker&lt;/a&gt; - A Python package that generates fake data.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/lk-geimfari/mimesis"&gt;mimesis&lt;/a&gt; - is a Python library that help you generate fake data.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/project/radar/"&gt;radar&lt;/a&gt; - Generate random datetime / time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Text Processing&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for parsing and manipulating plain texts.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;General 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/chardet/chardet"&gt;chardet&lt;/a&gt; - Python 2/3 compatible character encoding detector.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.python.org/3/library/difflib.html"&gt;difflib&lt;/a&gt; - (Python standard library) Helpers for computing deltas.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/LuminosoInsight/python-ftfy"&gt;ftfy&lt;/a&gt; - Makes Unicode text less broken and more consistent automagically.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/seatgeek/fuzzywuzzy"&gt;fuzzywuzzy&lt;/a&gt; - Fuzzy String Matching.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ztane/python-Levenshtein/"&gt;Levenshtein&lt;/a&gt; - Fast computation of Levenshtein distance and string similarity.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vinta/pangu.py"&gt;pangu.py&lt;/a&gt; - Paranoid text spacing.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pwaller/pyfiglet"&gt;pyfiglet&lt;/a&gt; - An implementation of figlet written in Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mozillazg/python-pinyin"&gt;pypinyin&lt;/a&gt; - Convert Chinese hanzi (漢字) to pinyin (拼音).&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/orsinium/textdistance"&gt;textdistance&lt;/a&gt; - Compute distance between sequences with 30+ algorithms.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pypi.org/project/Unidecode/"&gt;unidecode&lt;/a&gt; - ASCII transliterations of Unicode text.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Slugify 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dimka665/awesome-slugify"&gt;awesome-slugify&lt;/a&gt; - A Python slugify library that can preserve unicode.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/un33k/python-slugify"&gt;python-slugify&lt;/a&gt; - A Python slugify library that translates unicode to ASCII.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/mozilla/unicode-slugify"&gt;unicode-slugify&lt;/a&gt; - A slugifier that generates unicode slugs with Django as a dependency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Unique identifiers 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/davidaurelio/hashids-python"&gt;hashids&lt;/a&gt; - Implementation of &lt;a href="http://hashids.org"&gt;hashids&lt;/a&gt; in Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/skorokithakis/shortuuid"&gt;shortuuid&lt;/a&gt; - A generator library for concise, unambiguous and URL-safe UUIDs.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Parser 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/dabeaz/ply"&gt;ply&lt;/a&gt; - Implementation of lex and yacc parsing tools for Python.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://pygments.org/"&gt;pygments&lt;/a&gt; - A generic syntax highlighter.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pyparsing/pyparsing"&gt;pyparsing&lt;/a&gt; - A general purpose framework for generating parsers.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/derek73/python-nameparser"&gt;python-nameparser&lt;/a&gt; - Parsing human names into their individual components.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/daviddrysdale/python-phonenumbers"&gt;python-phonenumbers&lt;/a&gt; - Parsing, formatting, storing and validating international phone numbers.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/selwin/python-user-agents"&gt;python-user-agents&lt;/a&gt; - Browser user agent parser.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/andialbrecht/sqlparse"&gt;sqlparse&lt;/a&gt; - A non-validating SQL parser.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Third-party APIs&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for accessing third party services APIs. Also see &lt;a href="https://github.com/realpython/list-of-python-api-wrappers"&gt;List of Python API Wrappers and Libraries&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://libcloud.apache.org/"&gt;apache-libcloud&lt;/a&gt; - One Python library for all clouds.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/boto/boto3"&gt;boto3&lt;/a&gt; - Python interface to Amazon Web Services.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/istrategylabs/django-wordpress"&gt;django-wordpress&lt;/a&gt; - WordPress models and views for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mobolic/facebook-sdk"&gt;facebook-sdk&lt;/a&gt; - Facebook Platform Python SDK.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/google-api-python-client"&gt;google-api-python-client&lt;/a&gt; - Google APIs Client Library for Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/burnash/gspread"&gt;gspread&lt;/a&gt; - Google Spreadsheets Python API.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ryanmcgrath/twython"&gt;twython&lt;/a&gt; - A Python wrapper for the Twitter API.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;URL Manipulation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for parsing URLs.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gruns/furl"&gt;furl&lt;/a&gt; - A small Python library that makes parsing and manipulating URLs easy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeinthehole/purl"&gt;purl&lt;/a&gt; - A simple, immutable URL class with a clean API for interrogation and manipulation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ellisonleao/pyshorteners"&gt;pyshorteners&lt;/a&gt; - A pure Python URL shortening lib.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marshmallow-code/webargs"&gt;webargs&lt;/a&gt; - A friendly library for parsing HTTP request arguments with built-in support for popular web frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Video&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for manipulating video and GIFs.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zulko.github.io/moviepy/"&gt;moviepy&lt;/a&gt; - A module for script-based movie editing with many formats, including animated GIFs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aizvorski/scikit-video"&gt;scikit-video&lt;/a&gt; - Video processing routines for SciPy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abhiTronix/vidgear"&gt;vidgear&lt;/a&gt; - Most Powerful multi-threaded Video Processing framework.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Web Asset Management&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Tools for managing, compressing and minifying website assets.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django-compressor/django-compressor"&gt;django-compressor&lt;/a&gt; - Compresses linked and inline JavaScript or CSS into a single cached file.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jazzband/django-pipeline"&gt;django-pipeline&lt;/a&gt; - An asset packaging library for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jschneier/django-storages"&gt;django-storages&lt;/a&gt; - A collection of custom storage back ends for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.fanstatic.org/en/latest/"&gt;fanstatic&lt;/a&gt; - Packages, optimizes, and serves static file dependencies as Python packages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://wimleers.com/fileconveyor"&gt;fileconveyor&lt;/a&gt; - A daemon to detect and sync files to CDNs, S3 and FTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miracle2k/flask-assets"&gt;flask-assets&lt;/a&gt; - Helps you integrate webassets into your Flask app.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miracle2k/webassets"&gt;webassets&lt;/a&gt; - Bundles, optimizes, and manages unique cache-busting URLs for static resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Web Content Extracting&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for extracting web contents.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Alir3z4/html2text"&gt;html2text&lt;/a&gt; - Convert HTML to Markdown-formatted text.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/michaelhelmick/lassie"&gt;lassie&lt;/a&gt; - Web Content Retrieval for Humans.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/coleifer/micawber"&gt;micawber&lt;/a&gt; - A small library for extracting rich content from URLs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codelucas/newspaper"&gt;newspaper&lt;/a&gt; - News extraction, article extraction and content curation in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buriy/python-readability"&gt;python-readability&lt;/a&gt; - Fast Python port of arc90's readability tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests-html"&gt;requests-html&lt;/a&gt; - Pythonic HTML Parsing for Humans.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miso-belica/sumy"&gt;sumy&lt;/a&gt; - A module for automatic summarization of text documents and HTML pages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt; - Extract text from any document, Word, PowerPoint, PDFs, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gaojiuli/toapi"&gt;toapi&lt;/a&gt; - Every web site provides APIs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Web Crawling&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries to automate web scraping.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kurtmckee/feedparser"&gt;feedparser&lt;/a&gt; - Universal feed parser.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lorien/grab"&gt;grab&lt;/a&gt; - Site scraping framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MechanicalSoup/MechanicalSoup"&gt;mechanicalsoup&lt;/a&gt; - A Python library for automating interaction with websites.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scrapy/scrapy"&gt;scrapy&lt;/a&gt; - A fast high-level screen scraping and web crawling framework.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Web Frameworks&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Traditional full stack web frameworks. Also see &lt;a href="https://github.com/vinta/awesome-python#restful-api"&gt;RESTful API&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Synchronous 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/django/django"&gt;django&lt;/a&gt; - The most popular web framework in Python. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/shahraizali/awesome-django"&gt;awesome-django&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://github.com/wsvincent/awesome-django"&gt;awesome-django&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/pallets/flask"&gt;flask&lt;/a&gt; - A microframework for Python. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/humiaozuzu/awesome-flask"&gt;awesome-flask&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pylonsproject.org/"&gt;pyramid&lt;/a&gt; - A small, fast, down-to-earth, open source Python web framework. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://github.com/uralbash/awesome-pyramid"&gt;awesome-pyramid&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/MasoniteFramework/masonite"&gt;masonite&lt;/a&gt; - The modern and developer centric Python web framework.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Asynchronous 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tornadoweb/tornado"&gt;tornado&lt;/a&gt; - A web framework and asynchronous networking library.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;WebSocket&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Libraries for working with WebSocket.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crossbario/autobahn-python"&gt;autobahn-python&lt;/a&gt; - WebSocket &amp;amp; WAMP for Python on Twisted and &lt;a href="https://docs.python.org/3/library/asyncio.html"&gt;asyncio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/django/channels"&gt;channels&lt;/a&gt; - Developer-friendly asynchrony for Django.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;websockets&lt;/a&gt; - A library for building WebSocket servers and clients with a focus on correctness and simplicity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;WSGI Servers&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;WSGI-compatible web servers.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benoitc/gunicorn"&gt;gunicorn&lt;/a&gt; - Pre-forked, ported from Ruby's Unicorn project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://uwsgi-docs.readthedocs.io/en/latest/"&gt;uwsgi&lt;/a&gt; - A project aims at developing a full stack for building hosting services, written in C.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Pylons/waitress"&gt;waitress&lt;/a&gt; - Multi-threaded, powers Pyramid.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pallets/werkzeug"&gt;werkzeug&lt;/a&gt; - A WSGI utility library for Python that powers Flask and can easily be embedded into your own projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;p&gt;Where to discover learning resources or new Python libraries.&lt;/p&gt; 
&lt;h2&gt;Newsletters&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://python.libhunt.com/newsletter"&gt;Awesome Python Newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pycoders.com/"&gt;Pycoder's Weekly&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://realpython.com/python-tricks/"&gt;Python Tricks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pythonweekly.com/"&gt;Python Weekly&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Podcasts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://djangochat.com/"&gt;Django Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pythonbytes.fm"&gt;Python Bytes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://talkpython.fm/"&gt;Talk Python To Me&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podcast.pythontest.com/"&gt;Python Test&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://realpython.com/podcasts/rpp/"&gt;The Real Python Podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Your contributions are always welcome! Please take a look at the &lt;a href="https://github.com/vinta/awesome-python/raw/master/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;If you have any question about this opinionated list, do not hesitate to contact me &lt;a href="https://twitter.com/VintaChen"&gt;@VintaChen&lt;/a&gt; on Twitter or open an issue on GitHub.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>