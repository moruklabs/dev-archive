<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Fri, 25 Jul 2025 01:29:29 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo"&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png"&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png"&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png"&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3</title>
      <link>https://github.com/QwenLM/Qwen3</link>
      <description>&lt;p&gt;Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Qwen3&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/logo_qwen3.png" width="400"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 💜 &lt;a href="https://chat.qwen.ai/"&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤗 &lt;a href="https://huggingface.co/Qwen"&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤖 &lt;a href="https://modelscope.cn/organization/qwen"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://arxiv.org/abs/2505.09388"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ｜ &amp;nbsp;&amp;nbsp;📖 &lt;a href="https://qwen.readthedocs.io/"&gt;Documentation&lt;/a&gt; &lt;br&gt; 🖥️ &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo"&gt;Demo&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;💬 &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat (微信)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🫨 &lt;a href="https://discord.gg/CV4E9rpNSD"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-&lt;/code&gt; or visit the &lt;a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f"&gt;Qwen3 collection&lt;/a&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;p&gt;To learn more about Qwen3, feel free to read our documentation [&lt;a href="https://qwen.readthedocs.io/en/latest/"&gt;EN&lt;/a&gt;|&lt;a href="https://qwen.readthedocs.io/zh-cn/latest/"&gt;ZH&lt;/a&gt;]. Our documentation consists of the following sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quickstart: the basic usages and demonstrations;&lt;/li&gt; 
 &lt;li&gt;Inference: the guidance for the inference with Transformers, including batch inference, streaming, etc.;&lt;/li&gt; 
 &lt;li&gt;Run Locally: the instructions for running LLM locally on CPU and GPU, with frameworks like llama.cpp and Ollama;&lt;/li&gt; 
 &lt;li&gt;Deployment: the demonstration of how to deploy Qwen for large-scale inference with frameworks like SGLang, vLLM, TGI, etc.;&lt;/li&gt; 
 &lt;li&gt;Quantization: the practice of quantizing LLMs with GPTQ, AWQ, as well as the guidance for how to make high-quality quantized GGUF files;&lt;/li&gt; 
 &lt;li&gt;Training: the instructions for post-training, including SFT and RLHF (TODO) with frameworks like Axolotl, LLaMA-Factory, etc.&lt;/li&gt; 
 &lt;li&gt;Framework: the usage of Qwen with frameworks for application, e.g., RAG, Agent, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;We are excited to introduce the updated version of the &lt;strong&gt;Qwen3-235B-A22B non-thinking mode&lt;/strong&gt;, named &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt;, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significant improvements&lt;/strong&gt; in general capabilities, including &lt;strong&gt;instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Substantial gains&lt;/strong&gt; in long-tail knowledge coverage across &lt;strong&gt;multiple languages&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better alignment&lt;/strong&gt; with user preferences in &lt;strong&gt;subjective and open-ended tasks&lt;/strong&gt;, enabling more helpful responses and higher-quality text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced capabilities&lt;/strong&gt; in &lt;strong&gt;256K-token long-context understanding&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-235B-A22B-Instruct-2507.jpeg" alt="Qwen3-235B-A22B-Instruct-2507"&gt;&lt;/p&gt; 
&lt;p&gt;The updated versions of &lt;strong&gt;more Qwen3 model sizes&lt;/strong&gt; and for &lt;strong&gt;thinking mode&lt;/strong&gt; are also expected to be released very soon. Stay tuned🚀&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Previous News for Qwen3 Release&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; We are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. These models represent our most advanced and intelligent systems to date, improving from our experience in building QwQ and Qwen2.5. We are making the weights of Qwen3 available to the public, including both dense and Mixture-of-Expert (MoE) models. &lt;br&gt;&lt;br&gt; The highlights from Qwen3 include: &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;b&gt;Dense and Mixture-of-Experts (MoE) models of various sizes&lt;/b&gt;, available in 0.6B, 1.7B, 4B, 8B, 14B, 32B and 30B-A3B, 235B-A22B.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Seamless switching between thinking mode&lt;/b&gt; (for complex logical reasoning, math, and coding) and &lt;b&gt;non-thinking mode&lt;/b&gt; (for efficient, general-purpose chat), ensuring optimal performance across various scenarios.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Significantly enhancement in reasoning capabilities&lt;/b&gt;, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Superior human preference alignment&lt;/b&gt;, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Expertise in agent capabilities&lt;/b&gt;, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Support of 100+ languages and dialects&lt;/b&gt; with strong capabilities for &lt;b&gt;multilingual instruction following&lt;/b&gt; and &lt;b&gt;translation&lt;/b&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.07.21: We released the updated version of Qwen3-235B-A22B non-thinking mode, named Qwen3-235B-A22B-Instruct-2507, featuring significant enhancements over the previous version and supporting 256K-token long-context understanding. Check our &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.04.29: We released the Qwen3 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen3"&gt;blog&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2.5"&gt;blog&lt;/a&gt; for more!&lt;/li&gt; 
 &lt;li&gt;2024.06.06: We released the Qwen2 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2/"&gt;blog&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;2024.03.28: We released the first MoE model of Qwen: Qwen1.5-MoE-A2.7B! Temporarily, only HF transformers and vLLM support the model. We will soon add the support of llama.cpp, mlx-lm, etc. Check our &lt;a href="https://qwenlm.github.io/blog/qwen-moe/"&gt;blog&lt;/a&gt; for more information!&lt;/li&gt; 
 &lt;li&gt;2024.02.05: We released the Qwen1.5 series.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Detailed evaluation results are reported in this &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;📑 blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For requirements on GPU memory and the respective throughput, see results &lt;a href="https://qwen.readthedocs.io/en/latest/getting_started/speed_benchmark.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Run Qwen3&lt;/h2&gt; 
&lt;h3&gt;🤗 Transformers&lt;/h3&gt; 
&lt;p&gt;Transformers is a library of pretrained natural language processing for inference and training. The latest version of &lt;code&gt;transformers&lt;/code&gt; is recommended and &lt;code&gt;transformers&amp;gt;=4.51.0&lt;/code&gt; is required.&lt;/p&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-235B-A22B-Instruct-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-235B-A22B-Instruct-2507"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=16384
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

content = tokenizer.decode(output_ids, skip_special_tokens=True)

print("content:", content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] The updated version of Qwen3-235B-A22B, namely &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt; supports &lt;strong&gt;only non-thinking mode&lt;/strong&gt; and &lt;strong&gt;does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks&lt;/strong&gt; in its output. Meanwhile, &lt;strong&gt;specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Switching Thinking/Non-thinking Modes for Previous Qwen3 Hybrid Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; By default, Qwen3 models will think before response. This could be controlled by &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;enable_thinking=False&lt;/code&gt;: Passing &lt;code&gt;enable_thinking=False&lt;/code&gt; to `tokenizer.apply_chat_template` will strictly prevent the model from generating thinking content.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;/think&lt;/code&gt; and &lt;code&gt;/no_think&lt;/code&gt; instructions: Use those words in the system or user message to signify whether Qwen3 should think. In multi-turn conversations, the latest instruction is followed.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;ModelScope&lt;/h3&gt; 
&lt;p&gt;We strongly advise users especially those in mainland China to use ModelScope. ModelScope adopts a Python API similar to Transformers. The CLI tool &lt;code&gt;modelscope download&lt;/code&gt; can help you solve issues concerning downloading checkpoints.&lt;/p&gt; 
&lt;h3&gt;llama.cpp&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; enables LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware. &lt;code&gt;llama.cpp&amp;gt;=b5092&lt;/code&gt; is required for the support of Qwen3 architecture. &lt;code&gt;llama.cpp&amp;gt;=b5401&lt;/code&gt; is recommended for the full support of the official Qwen3 chat template.&lt;/p&gt; 
&lt;p&gt;To use the CLI, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-cli -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --color -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift
# CTRL+C to exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the API server, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-server -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --reasoning-format deepseek -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A simple web front end will be at &lt;code&gt;http://localhost:8080&lt;/code&gt; and an OpenAI-compatible API will be at &lt;code&gt;http://localhost:8080/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For additional guides, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] llama.cpp adopts "rotating context management" and infinite generation is made possible by evicting earlier tokens. It could configured by parameters and the commands above effectively disable it. For more details, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html#llama-cli"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Ollama&lt;/h3&gt; 
&lt;p&gt;After &lt;a href="https://ollama.com/"&gt;installing Ollama&lt;/a&gt;, you can initiate the Ollama service with the following command (Ollama v0.6.6 or higher is required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama serve
# You need to keep this service running whenever you are using ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To pull a model checkpoint and run the model, use the &lt;code&gt;ollama run&lt;/code&gt; command. You can specify a model size by adding a suffix to &lt;code&gt;qwen3&lt;/code&gt;, such as &lt;code&gt;:8b&lt;/code&gt; or &lt;code&gt;:30b-a3b&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run qwen3:8b
# Setting parameters, type "/set parameter num_ctx 40960" and "/set parameter num_predict 32768"
# To exit, type "/bye" and press ENTER
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also access the Ollama service via its OpenAI-compatible API. Please note that you need to (1) keep &lt;code&gt;ollama serve&lt;/code&gt; running while using the API, and (2) execute &lt;code&gt;ollama run qwen3:8b&lt;/code&gt; before utilizing this API to ensure that the model checkpoint is prepared. The API is at &lt;code&gt;http://localhost:11434/v1/&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;For additional details, please visit &lt;a href="https://ollama.com/"&gt;ollama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Ollama adopts the same "rotating context management" with llama.cpp. However, its default settings (&lt;code&gt;num_ctx&lt;/code&gt; 2048 and &lt;code&gt;num_predict&lt;/code&gt; -1), suggesting infinite generation with a 2048-token context, could lead to trouble for Qwen3 models. We recommend setting &lt;code&gt;num_ctx&lt;/code&gt; and &lt;code&gt;num_predict&lt;/code&gt; properly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LMStudio&lt;/h3&gt; 
&lt;p&gt;Qwen3 has already been supported by &lt;a href="https://lmstudio.ai/"&gt;lmstudio.ai&lt;/a&gt;. You can directly use LMStudio with our GGUF files.&lt;/p&gt; 
&lt;h3&gt;ExecuTorch&lt;/h3&gt; 
&lt;p&gt;To export and run on ExecuTorch (iOS, Android, Mac, Linux, and more), please follow this &lt;a href="https://github.com/pytorch/executorch/raw/main/examples/models/qwen3/README.md"&gt;example&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MNN&lt;/h3&gt; 
&lt;p&gt;To export and run on MNN, which supports Qwen3 on mobile devices, please visit &lt;a href="https://github.com/alibaba/MNN"&gt;Alibaba MNN&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MLX LM&lt;/h3&gt; 
&lt;p&gt;If you are running on Apple Silicon, &lt;a href="https://github.com/ml-explore/mlx-lm"&gt;&lt;code&gt;mlx-lm&lt;/code&gt;&lt;/a&gt; also supports Qwen3 (&lt;code&gt;mlx-lm&amp;gt;=0.24.0&lt;/code&gt;). Look for models ending with MLX on Hugging Face Hub.&lt;/p&gt; 
&lt;h3&gt;OpenVINO&lt;/h3&gt; 
&lt;p&gt;If you are running on Intel CPU or GPU, &lt;a href="https://github.com/openvinotoolkit"&gt;OpenVINO toolkit&lt;/a&gt; supports Qwen3. You can follow this &lt;a href="https://github.com/openvinotoolkit/openvino_notebooks/raw/latest/notebooks/llm-chatbot/llm-chatbot.ipynb"&gt;chatbot example&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ### Text generation web UI

You can directly use [`text-generation-webui`](https://github.com/oobabooga/text-generation-webui) for creating a web UI demo. If you use GGUF, remember to install the latest wheel of `llama.cpp` with the support of Qwen2.5. --&gt; 
&lt;!-- ### llamafile

Clone [`llamafile`](https://github.com/Mozilla-Ocho/llamafile), run source install, and then create your own llamafile with the GGUF file following the guide [here](https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#creating-llamafiles). You are able to run one line of command, say `./qwen.llamafile`, to create a demo. --&gt; 
&lt;h2&gt;Deploy Qwen3&lt;/h2&gt; 
&lt;p&gt;Qwen3 is supported by multiple inference frameworks. Here we demonstrate the usage of &lt;code&gt;SGLang&lt;/code&gt;, &lt;code&gt;vLLM&lt;/code&gt; and &lt;code&gt;TensorRT-LLM&lt;/code&gt;. You can also find Qwen3 models from various inference providers, e.g., &lt;a href="https://www.alibabacloud.com/en/product/modelstudio"&gt;Alibaba Cloud Model Studio&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SGLang&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt; is a fast serving framework for large language models and vision language models. SGLang could be used to launch a server with OpenAI-compatible API service. &lt;code&gt;sglang&amp;gt;=0.4.6.post1&lt;/code&gt; is required. It is as easy as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-8B --port 30000 --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:30000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;vLLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt; is a high-throughput and memory-efficient inference and serving engine for LLMs. &lt;code&gt;vllm&amp;gt;=0.8.5&lt;/code&gt; is recommended.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-8B --port 8000 --enable-reasoning --reasoning-parser deepseek_r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM"&gt;TensorRT-LLM&lt;/a&gt; is an open-source LLM inference engine from NVIDIA, which provides optimizations including custom attention kernels, quantization and more on NVIDIA GPUs. Qwen3 is supported in its re-architected &lt;a href="https://nvidia.github.io/TensorRT-LLM/torch.html"&gt;PyTorch backend&lt;/a&gt;. &lt;code&gt;tensorrt_llm&amp;gt;=0.20.0rc3&lt;/code&gt; is recommended. Please refer to the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/examples/models/core/qwen/README.md#qwen3"&gt;README&lt;/a&gt; page for more details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;trtllm-serve Qwen/Qwen3-8B --host localhost --port 8000 --backend pytorch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;MindIE&lt;/h3&gt; 
&lt;p&gt;For deployment on Ascend NPUs, please visit &lt;a href="https://modelers.cn/"&gt;Modelers&lt;/a&gt; and search for Qwen3.&lt;/p&gt; 
&lt;!-- 
### OpenLLM

[OpenLLM](https://github.com/bentoml/OpenLLM) allows you to easily run Qwen2.5 as OpenAI-compatible APIs. You can start a model server using `openllm serve`. For example:

```bash
openllm serve qwen2.5:7b
```

The server is active at `http://localhost:3000/`, providing OpenAI-compatible APIs. You can create an OpenAI client to call its chat API. For more information, refer to [our documentation](https://qwen.readthedocs.io/en/latest/deployment/openllm.html). --&gt; 
&lt;h2&gt;Build with Qwen3&lt;/h2&gt; 
&lt;h3&gt;Tool Use&lt;/h3&gt; 
&lt;p&gt;For tool use capabilities, we recommend taking a look at &lt;a href="https://github.com/QwenLM/Qwen-Agent"&gt;Qwen-Agent&lt;/a&gt;, which provides a wrapper around these APIs to support tool use or function calling with MCP support. Tool use with Qwen3 can also be conducted with SGLang, vLLM, Transformers, llama.cpp, Ollama, etc. Follow guides in our documentation to see how to enable the support.&lt;/p&gt; 
&lt;h3&gt;Finetuning&lt;/h3&gt; 
&lt;p&gt;We advise you to use training frameworks, including &lt;a href="https://github.com/OpenAccess-AI-Collective/axolotl"&gt;Axolotl&lt;/a&gt;, &lt;a href="https://github.com/unslothai/unsloth"&gt;UnSloth&lt;/a&gt;, &lt;a href="https://github.com/modelscope/swift"&gt;Swift&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/LLaMA-Factory"&gt;Llama-Factory&lt;/a&gt;, etc., to finetune your models with SFT, DPO, GRPO, etc.&lt;/p&gt; 
&lt;h2&gt;License Agreement&lt;/h2&gt; 
&lt;p&gt;All our open-weight models are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{qwen3,
    title={Qwen3 Technical Report}, 
    author={An Yang and Anfeng Li and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Gao and Chengen Huang and Chenxu Lv and Chujie Zheng and Dayiheng Liu and Fan Zhou and Fei Huang and Feng Hu and Hao Ge and Haoran Wei and Huan Lin and Jialong Tang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jing Zhou and Jingren Zhou and Junyang Lin and Kai Dang and Keqin Bao and Kexin Yang and Le Yu and Lianghao Deng and Mei Li and Mingfeng Xue and Mingze Li and Pei Zhang and Peng Wang and Qin Zhu and Rui Men and Ruize Gao and Shixuan Liu and Shuang Luo and Tianhao Li and Tianyi Tang and Wenbiao Yin and Xingzhang Ren and Xinyu Wang and Xinyu Zhang and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yinger Zhang and Yu Wan and Yuqiong Liu and Zekun Wang and Zeyu Cui and Zhenru Zhang and Zhipeng Zhou and Zihan Qiu},
    journal = {arXiv preprint arXiv:2505.09388},
    year={2025}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{qwen2,
    title   = {Qwen2 Technical Report}, 
    author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal = {arXiv preprint arXiv:2407.10671},
    year    = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href="https://discord.gg/z3GAxXZ9Ce"&gt;Discord&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/QwenLM/Qwen3/main/assets/wechat.png"&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aaPanel/BillionMail</title>
      <link>https://github.com/aaPanel/BillionMail</link>
      <description>&lt;p&gt;BillionMail gives you open-source MailServer, NewsLetter, Email Marketing — fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://www.billionmail.com/" target="_blank"&gt;BillionMail 📧&lt;/a&gt;&lt;/h1&gt; 
 &lt;h2&gt;An Open-Source MailServer, NewsLetter, Email Marketing Solution for Smarter Campaigns&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0.html"&gt;&lt;img src="https://img.shields.io/github/license/aaPanel/BillionMail" alt=""&gt;&lt;/a&gt; &lt;a href="https://www.billionmail.com/"&gt;&lt;img src="https://img.shields.io/badge/documentation-148F76" alt=""&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/aaPanel/BillionMail" alt=""&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail"&gt;&lt;img src="https://img.shields.io/github/stars/aaPanel/BillionMail?color=%231890FF&amp;amp;style=flat-square%C2%A0%C2%A0%C2%A0" alt=""&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-zh_CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-ja.md"&gt;日本語&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13842" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13842" alt="aaPanel%2FBillionMail | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is BillionMail?&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;future open-source Mail server, Email marketing platform&lt;/strong&gt; designed to help businesses and individuals manage their email campaigns with ease. Whether you're sending newsletters, promotional emails, or transactional messages, this tool will provide &lt;strong&gt;full control&lt;/strong&gt; over your email marketing efforts. With features like &lt;strong&gt;advanced analytics&lt;/strong&gt;, and &lt;strong&gt;customer management&lt;/strong&gt;, you'll be able to create, send, and track emails like a pro.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://www.billionmail.com/home.png?v1" alt="BillionMail Banner"&gt;&lt;/p&gt; 
&lt;h1&gt;Just 3 steps to send a billion emails!&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Billion emails. Any business. Guaranteed.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Step 1️⃣ Install BillionMail:&lt;/h3&gt; 
&lt;p&gt;✅ It takes &lt;strong&gt;only 8️⃣ minutes&lt;/strong&gt; from installation to &lt;strong&gt;✅ successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2️⃣: Connect Your Domain&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add the sending domain&lt;/li&gt; 
 &lt;li&gt;Verify DNS records&lt;/li&gt; 
 &lt;li&gt;Auto-enable free SSL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3️⃣: Build Your Campaign&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Write or paste your email&lt;/li&gt; 
 &lt;li&gt;Choose list &amp;amp; tags&lt;/li&gt; 
 &lt;li&gt;Set send time or send now&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/embed/UHgxZa_9jGs?si=0-f1B5hDtcWImvQv" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/UHgxZa_9jGs/maxresdefault.jpg" alt="" width="80%"&gt; &lt;br&gt; &lt;img src="https://www.iconfinder.com/icons/317714/download/png/16" alt="YouTube" width="16"&gt; &lt;b&gt;Watch on Youtube&lt;/b&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Other installation methods&lt;/h2&gt; 
&lt;h3&gt;One-click installation on aaPanel&lt;/h3&gt; 
&lt;p&gt;👉 &lt;a href="https://www.aapanel.com/new/download.html"&gt;https://www.aapanel.com/new/download.html&lt;/a&gt; (Log in to ✅aaPanel --&amp;gt; 🐳Docker --&amp;gt; 1️⃣OneClick install)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Management script&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Management help&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm help&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;View Login default info&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm default&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Show domain DNS record&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm show-record&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update BillionMail&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm update&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Live Demo&lt;/h2&gt; 
&lt;p&gt;BillionMail Demo: &lt;a href="https://demo.billionmail.com/billionmail"&gt;https://demo.billionmail.com/billionmail&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Username: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Password: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;WebMail&lt;/h2&gt; 
&lt;p&gt;BillionMail has integrated &lt;strong&gt;RoundCube&lt;/strong&gt;, you can access WebMail via &lt;code&gt;/roundcube/&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Why BillionMail?&lt;/h2&gt; 
&lt;p&gt;Most email marketing platforms are either &lt;strong&gt;expensive&lt;/strong&gt;, &lt;strong&gt;closed-source&lt;/strong&gt;, or &lt;strong&gt;lack essential features&lt;/strong&gt;. BillionMail aims to be different:&lt;/p&gt; 
&lt;p&gt;✅ &lt;strong&gt;Fully Open-Source&lt;/strong&gt; – No hidden costs, no vendor lock-in.&lt;br&gt; 📊 &lt;strong&gt;Advanced Analytics&lt;/strong&gt; – Track email delivery, open rates, click-through rates, and more.&lt;br&gt; 📧 &lt;strong&gt;Unlimited Sending&lt;/strong&gt; – No restrictions on the number of emails you can send.&lt;br&gt; 🎨 &lt;strong&gt;Customizable Templates&lt;/strong&gt; – Custom professional marketing templates for reuse. 🔒 &lt;strong&gt;Privacy-First&lt;/strong&gt; – Your data stays with you, no third-party tracking.&lt;br&gt; 🚀 &lt;strong&gt;Self-Hosted&lt;/strong&gt; – Run it on your own server for complete control.&lt;/p&gt; 
&lt;h2&gt;How You Can Help 🌟&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;community-driven project&lt;/strong&gt;, and we need your support to get started! Here's how you can help:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Star This Repository&lt;/strong&gt;: Show your interest by starring this repo.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spread the Word&lt;/strong&gt;: Share BillionMail with your network—developers, marketers, and open-source enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Share Feedback&lt;/strong&gt;: Let us know what features you'd like to see in BillionMail by opening an issue or joining the discussion.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute&lt;/strong&gt;: Once development begins, we'll welcome contributions from the community. Stay tuned for updates!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;p&gt;📧 &lt;strong&gt;BillionMail – The Future of Open-Source Email Marketing.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Issues&lt;/h2&gt; 
&lt;p&gt;If you encounter any issues or have feature requests, please &lt;a href="https://github.com/aaPanel/BillionMail/issues"&gt;open an issue&lt;/a&gt;. Be sure to include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A clear description of the problem or request.&lt;/li&gt; 
 &lt;li&gt;Steps to reproduce the issue (if applicable).&lt;/li&gt; 
 &lt;li&gt;Screenshots or error logs (if applicable).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install Now:&lt;/h2&gt; 
&lt;p&gt;✅It takes &lt;strong&gt;only 8 minutes&lt;/strong&gt; from installation to &lt;strong&gt;successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install with Docker:&lt;/strong&gt; (Please install Docker and docker-compose-plugin manually, and modify .env file)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#aapanel/billionmail&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=aapanel/billionmail&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BillionMail is licensed under the &lt;strong&gt;AGPLv3 License&lt;/strong&gt;. This means you can:&lt;/p&gt; 
&lt;p&gt;✅ Use the software for free.&lt;br&gt; ✅ Modify and distribute the code.&lt;br&gt; ✅ Use it privately without restrictions.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- BillionMail official link --&gt; 
&lt;!-- BillionMail Other link--&gt; 
&lt;!-- Shield link--&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;p&gt;🔹 S3 API Compatible – Seamless integration with existing S3 tools 🔹 Built for AI &amp;amp; Analytics – Optimized for large-scale data pipelines 🔹 High Performance – Ideal for demanding storage workloads.&lt;/p&gt; 
&lt;p&gt;AI storage documentation (&lt;a href="https://min.io/solutions/object-storage-for-ai"&gt;https://min.io/solutions/object-storage-for-ai&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;This README provides quickstart instructions on running MinIO on bare metal hardware, including container-based installations. For Kubernetes environments, use the &lt;a href="https://github.com/minio/operator/raw/master/README.md"&gt;MinIO Kubernetes Operator&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Container Installation&lt;/h2&gt; 
&lt;p&gt;Use the following commands to run a standalone MinIO server as a container.&lt;/p&gt; 
&lt;p&gt;Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a &lt;em&gt;minimum&lt;/em&gt; of 4 drives per MinIO server. See &lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt; for more complete documentation.&lt;/p&gt; 
&lt;h3&gt;Stable&lt;/h3&gt; 
&lt;p&gt;Run the following command to run the latest stable image of MinIO as a container using an ephemeral data volume:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;podman run -p 9000:9000 -p 9001:9001 \
  quay.io/minio/minio server /data --console-address ":9001"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To deploy MinIO on with persistent storage, you must map local persistent directories from the host OS to the container using the &lt;code&gt;podman -v&lt;/code&gt; option. For example, &lt;code&gt;-v /mnt/data:/data&lt;/code&gt; maps the host OS drive at &lt;code&gt;/mnt/data&lt;/code&gt; to &lt;code&gt;/data&lt;/code&gt; on the container.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;macOS&lt;/h2&gt; 
&lt;p&gt;Use the following commands to run a standalone MinIO server on macOS.&lt;/p&gt; 
&lt;p&gt;Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a &lt;em&gt;minimum&lt;/em&gt; of 4 drives per MinIO server. See &lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt; for more complete documentation.&lt;/p&gt; 
&lt;h3&gt;Homebrew (recommended)&lt;/h3&gt; 
&lt;p&gt;Run the following command to install the latest stable MinIO package using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;. Replace &lt;code&gt;/data&lt;/code&gt; with the path to the drive or directory in which you want MinIO to store data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install minio/stable/minio
minio server /data
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you previously installed minio using &lt;code&gt;brew install minio&lt;/code&gt; then it is recommended that you reinstall minio from &lt;code&gt;minio/stable/minio&lt;/code&gt; official repo instead.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew uninstall minio
brew install minio/stable/minio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html/"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;h3&gt;Binary Download&lt;/h3&gt; 
&lt;p&gt;Use the following command to download and run a standalone MinIO server on macOS. Replace &lt;code&gt;/data&lt;/code&gt; with the path to the drive or directory in which you want MinIO to store data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;wget https://dl.min.io/server/minio/release/darwin-amd64/minio
chmod +x minio
./minio server /data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;h2&gt;GNU/Linux&lt;/h2&gt; 
&lt;p&gt;Use the following command to run a standalone MinIO server on Linux hosts running 64-bit Intel/AMD architectures. Replace &lt;code&gt;/data&lt;/code&gt; with the path to the drive or directory in which you want MinIO to store data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
./minio server /data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following table lists supported architectures. Replace the &lt;code&gt;wget&lt;/code&gt; URL with the architecture for your Linux host.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;64-bit Intel/AMD&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://dl.min.io/server/minio/release/linux-amd64/minio"&gt;https://dl.min.io/server/minio/release/linux-amd64/minio&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;64-bit ARM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://dl.min.io/server/minio/release/linux-arm64/minio"&gt;https://dl.min.io/server/minio/release/linux-arm64/minio&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;64-bit PowerPC LE (ppc64le)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://dl.min.io/server/minio/release/linux-ppc64le/minio"&gt;https://dl.min.io/server/minio/release/linux-ppc64le/minio&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a &lt;em&gt;minimum&lt;/em&gt; of 4 drives per MinIO server. See &lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html#"&gt;MinIO Erasure Code Overview&lt;/a&gt; for more complete documentation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Microsoft Windows&lt;/h2&gt; 
&lt;p&gt;To run MinIO on 64-bit Windows hosts, download the MinIO executable from the following URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;https://dl.min.io/server/minio/release/windows-amd64/minio.exe
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the following command to run a standalone MinIO server on the Windows host. Replace &lt;code&gt;D:\&lt;/code&gt; with the path to the drive or directory in which you want MinIO to store data. You must change the terminal or powershell directory to the location of the &lt;code&gt;minio.exe&lt;/code&gt; executable, &lt;em&gt;or&lt;/em&gt; add the path to that directory to the system &lt;code&gt;$PATH&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;minio.exe server D:\
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a &lt;em&gt;minimum&lt;/em&gt; of 4 drives per MinIO server. See &lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html#"&gt;MinIO Erasure Code Overview&lt;/a&gt; for more complete documentation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. Source installation is only intended for developers and advanced users. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool. See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://min.io/docs/minio/linux/developers/minio-drivers.html"&gt;https://min.io/docs/minio/linux/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Standalone MinIO servers are best suited for early development and evaluation. Certain features such as versioning, object locking, and bucket replication require distributed deploying MinIO with Erasure Coding. For extended development and production, deploy MinIO with Erasure Coding enabled - specifically, with a &lt;em&gt;minimum&lt;/em&gt; of 4 drives per MinIO server. See &lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt; for more complete documentation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MinIO strongly recommends &lt;em&gt;against&lt;/em&gt; using compiled-from-source MinIO servers for production environments.&lt;/p&gt; 
&lt;h2&gt;Deployment Recommendations&lt;/h2&gt; 
&lt;h3&gt;Allow port access for Firewalls&lt;/h3&gt; 
&lt;p&gt;By default MinIO uses the port 9000 to listen for incoming connections. If your platform blocks the port by default, you may need to enable access to the port.&lt;/p&gt; 
&lt;h3&gt;ufw&lt;/h3&gt; 
&lt;p&gt;For hosts with ufw enabled (Debian based distros), you can use &lt;code&gt;ufw&lt;/code&gt; command to allow traffic to specific ports. Use below command to allow access to port 9000&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ufw allow 9000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Below command enables all incoming traffic to ports ranging from 9000 to 9010.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;ufw allow 9000:9010/tcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;firewall-cmd&lt;/h3&gt; 
&lt;p&gt;For hosts with firewall-cmd enabled (CentOS), you can use &lt;code&gt;firewall-cmd&lt;/code&gt; command to allow traffic to specific ports. Use below commands to allow access to port 9000&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;firewall-cmd --get-active-zones
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command gets the active zone(s). Now, apply port rules to the relevant zones returned above. For example if the zone is &lt;code&gt;public&lt;/code&gt;, use&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;firewall-cmd --zone=public --add-port=9000/tcp --permanent
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;code&gt;permanent&lt;/code&gt; makes sure the rules are persistent across firewall start, restart or reload. Finally reload the firewall for changes to take effect.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;iptables&lt;/h3&gt; 
&lt;p&gt;For hosts with iptables enabled (RHEL, CentOS, etc), you can use &lt;code&gt;iptables&lt;/code&gt; command to enable all traffic coming to specific ports. Use below command to allow access to port 9000&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;iptables -A INPUT -p tcp --dport 9000 -j ACCEPT
service iptables restart
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Below command enables all incoming traffic to ports ranging from 9000 to 9010.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;iptables -A INPUT -p tcp --dport 9000:9010 -j ACCEPT
service iptables restart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Things to consider&lt;/h3&gt; 
&lt;p&gt;MinIO redirects browser access requests to the configured server port (i.e. &lt;code&gt;127.0.0.1:9000&lt;/code&gt;) to the configured Console port. MinIO uses the hostname or IP address specified in the request when building the redirect URL. The URL and port &lt;em&gt;must&lt;/em&gt; be accessible by the client for the redirection to work.&lt;/p&gt; 
&lt;p&gt;For deployments behind a load balancer, proxy, or ingress rule where the MinIO host IP address or port is not public, use the &lt;code&gt;MINIO_BROWSER_REDIRECT_URL&lt;/code&gt; environment variable to specify the external hostname for the redirect. The LB/Proxy must have rules for directing traffic to the Console port specifically.&lt;/p&gt; 
&lt;p&gt;For example, consider a MinIO deployment behind a proxy &lt;code&gt;https://minio.example.net&lt;/code&gt;, &lt;code&gt;https://console.minio.example.net&lt;/code&gt; with rules for forwarding traffic on port :9000 and :9001 to MinIO and the MinIO Console respectively on the internal network. Set &lt;code&gt;MINIO_BROWSER_REDIRECT_URL&lt;/code&gt; to &lt;code&gt;https://console.minio.example.net&lt;/code&gt; to ensure the browser receives a valid reachable URL.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dashboard&lt;/th&gt; 
   &lt;th&gt;Creating a bucket&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/minio/minio/raw/master/docs/screenshots/pic1.png?raw=true" alt="Dashboard"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/minio/minio/raw/master/docs/screenshots/pic2.png?raw=true" alt="Dashboard"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services. Follow the MinIO Client &lt;a href="https://min.io/docs/minio/linux/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Upgrading MinIO&lt;/h2&gt; 
&lt;p&gt;Upgrades require zero downtime in MinIO, all upgrades are non-disruptive, all transactions on MinIO are atomic. So upgrading all the servers simultaneously is the recommended way to upgrade MinIO.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] requires internet access to update directly from &lt;a href="https://dl.min.io"&gt;https://dl.min.io&lt;/a&gt;, optionally you can host any mirrors at &lt;a href="https://my-artifactory.example.com/minio/"&gt;https://my-artifactory.example.com/minio/&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;For deployments that installed the MinIO server binary by hand, use &lt;a href="https://min.io/docs/minio/linux/reference/minio-mc-admin/mc-admin-update.html"&gt;&lt;code&gt;mc admin update&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc admin update &amp;lt;minio alias, e.g., myminio&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;For deployments without external internet access (e.g. airgapped environments), download the binary from &lt;a href="https://dl.min.io"&gt;https://dl.min.io&lt;/a&gt; and replace the existing MinIO binary let's say for example &lt;code&gt;/opt/bin/minio&lt;/code&gt;, apply executable permissions &lt;code&gt;chmod +x /opt/bin/minio&lt;/code&gt; and proceed to perform &lt;code&gt;mc admin service restart alias/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For installations using Systemd MinIO service, upgrade via RPM/DEB packages &lt;strong&gt;parallelly&lt;/strong&gt; on all servers or replace the binary lets say &lt;code&gt;/opt/bin/minio&lt;/code&gt; on all nodes, apply executable permissions &lt;code&gt;chmod +x /opt/bin/minio&lt;/code&gt; and process to perform &lt;code&gt;mc admin service restart alias/&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Upgrade Checklist&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Test all upgrades in a lower environment (DEV, QA, UAT) before applying to production. Performing blind upgrades in production environments carries significant risk.&lt;/li&gt; 
 &lt;li&gt;Read the release notes for MinIO &lt;em&gt;before&lt;/em&gt; performing any upgrade, there is no forced requirement to upgrade to latest release upon every release. Some release may not be relevant to your setup, avoid upgrading production environments unnecessarily.&lt;/li&gt; 
 &lt;li&gt;If you plan to use &lt;code&gt;mc admin update&lt;/code&gt;, MinIO process must have write access to the parent directory where the binary is present on the host system.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mc admin update&lt;/code&gt; is not supported and should be avoided in kubernetes/container environments, please upgrade containers by upgrading relevant container images.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;We do not recommend upgrading one MinIO server at a time, the product is designed to support parallel upgrades please follow our recommended guidelines.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://min.io/docs/minio/linux/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://min.io/docs/minio/linux/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://min.io/docs/minio/linux/developers/go/minio-go.html"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://min.io/docs/minio/linux/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; 🚅 LiteLLM &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://render.com/deploy?repo=https://github.com/BerriAI/litellm" target="_blank" rel="nofollow"&gt;&lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Render"&gt;&lt;/a&gt; &lt;a href="https://railway.app/template/HLP0Ub?referralCode=jch2ME"&gt; &lt;img src="https://railway.app/button.svg?sanitize=true" alt="Deploy on Railway"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;&lt;a href="https://docs.litellm.ai/docs/simple_proxy" target="_blank"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/hosted" target="_blank"&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/enterprise" target="_blank"&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://pypi.org/project/litellm/" target="_blank"&gt; &lt;img src="https://img.shields.io/pypi/v/litellm.svg?sanitize=true" alt="PyPI Version"&gt; &lt;/a&gt; &lt;a href="https://www.ycombinator.com/companies/berriai"&gt; &lt;img src="https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square" alt="Y Combinator W23"&gt; &lt;/a&gt; &lt;a href="https://wa.link/huol9n"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square" alt="Whatsapp"&gt; &lt;/a&gt; &lt;a href="https://discord.gg/wuPM9dRgDw"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square" alt="Discord"&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square" alt="Slack"&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider's &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/completion/output"&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;['choices'][0]['message']['content']&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href="https://docs.litellm.ai/docs/routing"&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs"&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs"&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🚨 &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href="https://docs.litellm.ai/docs/proxy/release_cycle"&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href="https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+"&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href="https://docs.litellm.ai/docs/migration"&gt;here&lt;/a&gt;&lt;br&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target="_blank" href="https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
import os

## set ENV variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"

messages = [{ "content": "Hello, how are you?","role": "user"}]

# openai call
response = completion(model="openai/gpt-4o", messages=messages)

# anthropic call
response = completion(model="anthropic/claude-sonnet-4-20250514", messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de",
    "created": 1751494488,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
            }
        }
    ],
    "usage": {
        "completion_tokens": 39,
        "prompt_tokens": 13,
        "total_tokens": 52,
        "completion_tokens_details": null,
        "prompt_tokens_details": {
            "audio_tokens": null,
            "cached_tokens": 0
        },
        "cache_creation_input_tokens": 0,
        "cache_read_input_tokens": 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href="https://docs.litellm.ai/docs/providers"&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = "Hello, how are you?"
    messages = [{"content": user_message, "role": "user"}]
    response = await acompletion(model="openai/gpt-4o", messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href="https://docs.litellm.ai/docs/completion/stream"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response.&lt;br&gt; Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
response = completion(model="openai/gpt-4o", messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")

# claude sonnet 4
response = completion('anthropic/claude-sonnet-4-20250514', messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca",
    "created": 1751494808,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion.chunk",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": null,
            "index": 0,
            "delta": {
                "provider_specific_fields": null,
                "content": "Hello",
                "role": "assistant",
                "function_call": null,
                "tool_calls": null,
                "audio": null
            },
            "logprobs": null
        }
    ],
    "provider_specific_fields": null,
    "stream_options": null,
    "citations": null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href="https://docs.litellm.ai/docs/observability/callbacks"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ["LUNARY_PUBLIC_KEY"] = "your-lunary-public-key"
os.environ["HELICONE_API_KEY"] = "your-helicone-auth-key"
os.environ["LANGFUSE_PUBLIC_KEY"] = ""
os.environ["LANGFUSE_SECRET_KEY"] = ""
os.environ["ATHINA_API_KEY"] = "your-athina-api-key"

os.environ["OPENAI_API_KEY"] = "your-openai-key"

# set callbacks
litellm.success_callback = ["lunary", "mlflow", "langfuse", "athina", "helicone"] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model="openai/gpt-4o", messages=[{"role": "user", "content": "Hi 👋 - i'm openai"}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/hosted"&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth"&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class"&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend"&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/users#set-rate-limits"&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📖 Proxy Endpoints - &lt;a href="https://litellm-api.up.railway.app/"&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'litellm[proxy]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] 💡 &lt;a href="https://docs.litellm.ai/docs/proxy/user_keys"&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "this is a test request, write a short poem"
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo 'LITELLM_MASTER_KEY="sk-1234"' &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/ 
# password generator to get a random hash for litellm salt key
echo 'LITELLM_SALT_KEY="sk-1234"' &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src="https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033" alt="ui_3"&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl 'http://0.0.0.0:4000/key/generate' \
--header 'Authorization: Bearer sk-1234' \
--header 'Content-Type: application/json' \
--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4", "claude-2"], "duration": "20m","metadata": {"user": "ishaan@berri.ai", "team": "core-infra"}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;{
    "key": "sk-kdEXbIqZRwEeEiHwdg7sFA", # Bearer token
    "expires": "2023-11-19T01:38:25.838000+00:00" # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href="https://docs.litellm.ai/docs/providers"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/#basic-usage"&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#streaming-responses"&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-streaming"&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/image_generation"&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openai"&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/meta_llama"&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/azure"&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aiml"&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aws_sagemaker"&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/bedrock"&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vertex"&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/palm"&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/gemini"&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/mistral"&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cloudflare_workers"&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cohere"&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anthropic"&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/empower"&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/huggingface"&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/replicate"&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/togetherai"&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openrouter"&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ai21"&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/baseten"&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vllm"&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nlp_cloud"&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aleph_alpha"&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/petals"&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ollama"&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepinfra"&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/perplexity"&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/groq"&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepseek"&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anyscale"&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/watsonx"&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/voyage"&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/xinference"&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/friendliai"&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/galadriel"&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link"&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/featherless_ai"&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nebius"&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; → &lt;code&gt;make install-dev&lt;/code&gt; → &lt;code&gt;make format&lt;/code&gt; → &lt;code&gt;make lint&lt;/code&gt; → &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat"&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Features under the &lt;a href="https://docs.litellm.ai/docs/proxy/enterprise"&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you're fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href="https://google.github.io/styleguide/pyguide.html"&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run all checks locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint           # Run all linting (matches CI)
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version"&gt;Schedule Demo 👋&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/wuPM9dRgDw"&gt;Community Discord 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt;Community Slack 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers 📞 +1 (770) 8783-106 / ‭+1 (412) 618-6238‬&lt;/li&gt; 
 &lt;li&gt;Our emails ✉️ &lt;a href="mailto:ishaan@berri.ai"&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href="mailto:krrish@berri.ai"&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href="https://github.com/BerriAI/litellm/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=BerriAI/litellm"&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e ".[all]"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;uvicorn litellm.proxy.proxy_server:app --host localhost --port 4000 --reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>srbhr/Resume-Matcher</title>
      <link>https://github.com/srbhr/Resume-Matcher</link>
      <description>&lt;p&gt;Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.resumematcher.fyi"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/page_2.png" alt="Resume Matcher"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Resume Matcher&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;𝙹𝚘𝚒𝚗 𝙳𝚒𝚜𝚌𝚘𝚛𝚍&lt;/a&gt; ✦ &lt;a href="https://resumematcher.fyi"&gt;𝚆𝚎𝚋𝚜𝚒𝚝𝚎&lt;/a&gt; ✦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#how-to-install"&gt;𝙷𝚘𝚠 𝚝𝚘 𝙸𝚗𝚜𝚝𝚊𝚕𝚕 &lt;/a&gt; ✦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#contributors"&gt;𝙲𝚘𝚗𝚝𝚛𝚒𝚋𝚞𝚝𝚘𝚛𝚜&lt;/a&gt; ✦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#support-the-development-by-donating"&gt;𝙳𝚘𝚗𝚊𝚝𝚎&lt;/a&gt; ✦ &lt;a href="https://twitter.com/_srbhr_"&gt;𝚃𝚠𝚒𝚝𝚝𝚎𝚛/𝚇&lt;/a&gt; ✦ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;𝙻𝚒𝚗𝚔𝚎𝚍𝙸𝚗&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Stop getting auto-rejected by ATS bots.&lt;/strong&gt; Resume Matcher is the AI-powered platform that reverse-engineers hiring algorithms to show you exactly how to tailor your resume. Get the keywords, formatting, and insights that actually get you past the first screen and into human hands.&lt;/p&gt; 
 &lt;p&gt;Hoping to make this, &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Stars"&gt; &lt;img src="https://img.shields.io/github/license/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Apache 2.0"&gt; &lt;img src="https://img.shields.io/github/forks/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Forks"&gt; &lt;img src="https://img.shields.io/badge/Version-0.1%20Veridis%20Quo-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="version"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://img.shields.io/discord/1122069176962531400?labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=c20a71&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://resumematcher.fyi"&gt;&lt;img src="https://img.shields.io/badge/website-Resume%20Matcher-FFF?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Website"&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-Resume%20Matcher-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="LinkedIn"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/565" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/565" alt="srbhr%2FResume-Matcher | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;This project is in active development. New features are being added continuously, and we welcome contributions from the community. There are some breaking changes on the &lt;code&gt;main&lt;/code&gt; branch. If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started with Resume Matcher&lt;/h2&gt; 
&lt;p&gt;Resume Matcher is designed to help you optimize your resume with the aim to highlight your skills and experience in a way that resonates with potential employers.&lt;/p&gt; 
&lt;p&gt;We're working on actively improving the platform, towards building a &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;, and adding new features. The best way to stay updated is to join the discord discussion and be part of the active development community.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Join our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; community 👇 &lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_discord.png" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Follow us on &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;LinkedIn&lt;/a&gt; ✨ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_linkedin.png" alt="LinkedIn"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⭐ Star Resume Matcher to support the development and get updates on GitHub. &lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/star_resume_matcher.png" alt="Star Resume Matcher"&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_features.png" alt="resume_matcher_features"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Works locally&lt;/strong&gt;: No need to upload your resume to a server. Everything runs on your machine with open source AI models by Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ATS Compatibility&lt;/strong&gt;: Get a detailed analysis of your resume's compatibility with ATS systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Match Score&lt;/strong&gt;: Upload resume &amp;amp; job description for a quick match score and key improvement areas.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keyword Optimizer&lt;/strong&gt;: Align your resume with job keywords and identify critical content gaps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guided Improvements&lt;/strong&gt;: Get clear suggestions to make your resume stand out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual keyword highlighting.&lt;/li&gt; 
 &lt;li&gt;AI Canvas, which can help to craft impactful, metric-driven resume content.&lt;/li&gt; 
 &lt;li&gt;Multi-job description optimization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_install_resumematcher.png" alt="Installation"&gt;&lt;/p&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/SETUP.md"&gt;SETUP.md&lt;/a&gt; file to set up the project locally. The setup script will install all the necessary dependencies and configure your environment.&lt;/p&gt; 
&lt;p&gt;The project is built using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FastAPI for the backend.&lt;/li&gt; 
 &lt;li&gt;Next.js for the frontend.&lt;/li&gt; 
 &lt;li&gt;Ollama for local AI model serving.&lt;/li&gt; 
 &lt;li&gt;Tailwind CSS for styling.&lt;/li&gt; 
 &lt;li&gt;SQLite for the database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Technology&lt;/th&gt; 
   &lt;th&gt;Info/Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;3.12+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Next.js&lt;/td&gt; 
   &lt;td&gt;15+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;0.6.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Join Us and Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_contribute.png" alt="how to contribute"&gt;&lt;/p&gt; 
&lt;p&gt;We welcome contributions from everyone! Whether you're a developer, designer, or just someone who wants to help out. All the contriburtors are listed in the &lt;a href="https://resumematcher.fyi/about"&gt;about page&lt;/a&gt; on our website and on the GitHub Readme here.&lt;/p&gt; 
&lt;p&gt;Checkout the roadmap if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/contributors.png" alt="Contributors"&gt;&lt;/p&gt; 
&lt;a href="https://github.com/srbhr/Resume-Matcher/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=srbhr/Resume-Matcher"&gt; &lt;/a&gt; 
&lt;h2&gt;Support the Development by Donating&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/supporting_resume_matcher.png" alt="donate"&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to support the development of Resume Matcher, you can do so by donating. Your contributions will help us keep the project alive and continue adding new features.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GitHub&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sponsors/srbhr"&gt;&lt;img src="https://img.shields.io/github/sponsors/srbhr?style=for-the-badge&amp;amp;color=c20a71&amp;amp;labelColor=black&amp;amp;logo=github" alt="GitHub Sponsors"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Buy Me a Coffee&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.buymeacoffee.com/srbhr"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;color=c20a72&amp;amp;logoColor=white" alt="BuyMeACoffee"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date"&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date"&gt; 
 &lt;/picture&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/rag-from-scratch</title>
      <link>https://github.com/langchain-ai/rag-from-scratch</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RAG From Scratch&lt;/h1&gt; 
&lt;p&gt;LLMs are trained on a large but fixed corpus of data, limiting their ability to reason about private or recent information. Fine-tuning is one way to mitigate this, but is often &lt;a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts"&gt;not well-suited for factual recall&lt;/a&gt; and &lt;a href="https://www.glean.com/blog/how-to-build-an-ai-assistant-for-the-enterprise"&gt;can be costly&lt;/a&gt;. Retrieval augmented generation (RAG) has emerged as a popular and powerful mechanism to expand an LLM's knowledge base, using documents retrieved from an external data source to ground the LLM generation via in-context learning. These notebooks accompany a &lt;a href="https://youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&amp;amp;feature=shared"&gt;video playlist&lt;/a&gt; that builds up an understanding of RAG from scratch, starting with the basics of indexing, retrieval, and generation. &lt;img src="https://github.com/langchain-ai/rag-from-scratch/assets/122662504/54a2d76c-b07e-49e7-b4ce-fc45667360a1" alt="rag_detail_v2"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x"&gt;Video playlist&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yeongpin/cursor-free-vip</title>
      <link>https://github.com/yeongpin/cursor-free-vip</link>
      <description>&lt;p&gt;[Support 0.49.x]（Reset Cursor AI MachineID &amp; Bypass Higher Token Limit） Cursor Ai ，自动重置机器ID ， 免费升级使用Pro功能: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;➤ Cursor Free VIP&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/logo.png" alt="Cursor Pro Logo" width="200" style="border-radius: 6px;"&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;&lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip" alt="Release"&gt;&lt;/a&gt; &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg?sanitize=true" alt="License: CC BY-NC-ND 4.0"&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/stargazers"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip" alt="Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/yeongpin" target="_blank"&gt;&lt;img alt="Buy Me a Coffee" src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/yeongpin/cursor-free-vip"&gt;&lt;img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/13425" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13425" alt="yeongpin%2Fcursor-free-vip | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://www.buymeacoffee.com/yeongpin" target="_blank"&gt; &lt;img src="https://img.buymeacoffee.com/button-api/?text=buy%20me%20a%20coffee&amp;amp;emoji=%E2%98%95&amp;amp;slug=yeongpin&amp;amp;button_colour=ffda33&amp;amp;font_colour=000000&amp;amp;font_family=Bree&amp;amp;outline_colour=000000&amp;amp;coffee_colour=FFDD00&amp;amp;latest=2" width="160" height="55" alt="Buy Me a Coffee"&gt; &lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Support Latest 0.49.x Version | 支持最新 0.49.x 版本&lt;/h4&gt; 
 &lt;p&gt;This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project. This tool will not generate any fake email accounts and OAuth access.&lt;/p&gt; 
 &lt;p&gt;Supports Windows, macOS and Linux.&lt;/p&gt; 
 &lt;p&gt;For optimal performance, run with privileges and always stay up to date.&lt;/p&gt; 
 &lt;p&gt;這是一款用於學習和研究的工具，目前 repo 沒有違反任何法律。請支持原作者。 這款工具不會生成任何假的電子郵件帳戶和 OAuth 訪問。&lt;/p&gt; 
 &lt;p&gt;支持 Windows、macOS 和 Linux。&lt;/p&gt; 
 &lt;p&gt;對於最佳性能，請以管理員身份運行並始終保持最新。&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/product_2025-04-16_10-40-21.png" alt="new" width="800" style="border-radius: 6px;"&gt;&lt;br&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🔄 Change Log | 更新日志&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/CHANGELOG.md"&gt;Watch Change Log | 查看更新日志&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features | 功能特點&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Support Windows macOS and Linux systems&lt;br&gt;支持 Windows、macOS 和 Linux 系統&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reset Cursor's configuration&lt;br&gt;重置 Cursor 的配置&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-language support (English, 简体中文, 繁體中文, Vietnamese)&lt;br&gt;多語言支持（英文、简体中文、繁體中文、越南語）&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💻 System Support | 系統支持&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Supported&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;x64, x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;Intel, Apple Silicon&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;x64, x86, ARM64&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;👀 How to use | 如何使用&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;⭐ Auto Run Script | 腳本自動化運行&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;&lt;strong&gt;Linux/macOS&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Archlinux&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;Install via &lt;a href="https://aur.archlinux.org/packages/cursor-free-vip-git"&gt;AUR&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;yay -S cursor-free-vip-git
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;If you want to stop the script, please press Ctrl+C&lt;br&gt;要停止腳本，請按 Ctrl+C&lt;/p&gt; 
&lt;h2&gt;❗ Note | 注意事項&lt;/h2&gt; 
&lt;p&gt;📝 Config | 文件配置 &lt;code&gt;Win / Macos / Linux Path | 路徑 [Documents/.cursor-free-vip/config.ini]&lt;/code&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;⭐ Config | 文件配置&lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;[Chrome]
# Default Google Chrome Path | 默認Google Chrome 遊覽器路徑
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | 等待人機驗證時間
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | 等待人機驗證隨機時間（必須是 1-3 或者 1,3 這樣的組合）
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | 存儲路徑
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLite路徑
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | 機器ID路徑
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | 最小隨機時間
min_random_time = 0.1
# Max Random Time | 最大隨機時間
max_random_time = 0.8
# Page Load Wait | 頁面加載等待時間
page_load_wait = 0.1-0.8
# Input Wait | 輸入等待時間
input_wait = 0.3-0.8
# Submit Wait | 提交等待時間
submit_wait = 0.5-1.5
# Verification Code Input | 驗證碼輸入等待時間
verification_code_input = 0.1-0.3
# Verification Success Wait | 驗證成功等待時間
verification_success_wait = 2-3
# Verification Retry Wait | 驗證重試等待時間
verification_retry_wait = 2-3
# Email Check Initial Wait | 郵件檢查初始等待時間
email_check_initial_wait = 4-6
# Email Refresh Wait | 郵件刷新等待時間
email_refresh_wait = 2-4
# Settings Page Load Wait | 設置頁面加載等待時間
settings_page_load_wait = 1-2
# Failed Retry Time | 失敗重試時間
failed_retry_time = 0.5-1
# Retry Interval | 重試間隔
retry_interval = 8-12
# Max Timeout | 最大超時時間
max_timeout = 160

[Utils]
# Check Update | 檢查更新
check_update = True
# Show Account Info | 顯示賬號信息
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | 啓用 TempMailPlus（任何轉發到TempMailPlus的郵件都支持獲取驗證碼，例如cloudflare郵件Catch-all）
enabled = false
# TempMailPlus Email | TempMailPlus 電子郵件
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pin碼
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use administrator privileges to run the script &lt;br&gt;請使用管理員身份運行腳本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Confirm that Cursor is closed before running the script &lt;br&gt;請確保在運行腳本前已經關閉 Cursor&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;This tool is only for learning and research purposes &lt;br&gt;此工具僅供學習和研究使用&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Please comply with the relevant software usage terms when using this tool &lt;br&gt;使用本工具時請遵守相關軟件使用條款&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚨 Common Issues | 常見問題&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;如果遇到權限問題，請確保：&lt;/th&gt; 
   &lt;th align="center"&gt;此腳本以管理員身份運行&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;If you encounter permission issues, please ensure:&lt;/td&gt; 
   &lt;td align="center"&gt;This script is run with administrator privileges&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Error 'User is not authorized'&lt;/td&gt; 
   &lt;td align="center"&gt;This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🤩 Contribution | 貢獻&lt;/h2&gt; 
&lt;p&gt;歡迎提交 Issue 和 Pull Request！&lt;/p&gt; 
&lt;a href="https://github.com/yeongpin/cursor-free-vip/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;amp;preview=true&amp;amp;max=&amp;amp;columns="&gt; &lt;/a&gt; 
&lt;br&gt;
&lt;br&gt; 
&lt;h2&gt;📩 Disclaimer | 免責聲明&lt;/h2&gt; 
&lt;p&gt;本工具僅供學習和研究使用，使用本工具所產生的任何後果由使用者自行承擔。 &lt;br&gt;&lt;/p&gt; 
&lt;p&gt;This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne by the user.&lt;/p&gt; 
&lt;h2&gt;💰 Buy Me a Coffee | 請我喝杯咖啡&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/provi-code.jpg" alt="buy_me_a_coffee" width="280"&gt;&lt;br&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/paypal.png" alt="buy_me_a_coffee" width="280"&gt;&lt;br&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;⭐ Star History | 星星數&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#yeongpin/cursor-free-vip&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📝 License | 授權&lt;/h2&gt; 
&lt;p&gt;本項目採用 &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;CC BY-NC-ND 4.0&lt;/a&gt; 授權。 Please refer to the &lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/generative-ai-for-beginners</title>
      <link>https://github.com/microsoft/generative-ai-for-beginners</link>
      <description>&lt;p&gt;21 Lessons, Get Started Building with Generative AI 🔗 https://microsoft.github.io/generative-ai-for-beginners/&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/images/repo-thumbnailv4-fixed.png?WT.mc_id=academic-105485-koreyst" alt="Generative AI For Beginners"&gt;&lt;/p&gt; 
&lt;h3&gt;21 Lessons teaching everything you need to know to start building Generative AI applications&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/Generative-AI-For-Beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub license"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub issues"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub pull-requests"&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks"&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt=""&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Generative AI for Beginners (Version 3) - A Course&lt;/h1&gt; 
&lt;p&gt;Learn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 21 lessons. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;Lessons are labeled either "Learn" lessons explaining a Generative AI concept or "Build" lessons that explain a concept and code examples in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt; when possible.&lt;/p&gt; 
&lt;p&gt;For .NET Developers checkout &lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners (.NET Edition)&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Each lesson also includes a "Keep Learning" section with additional learning tools.&lt;/p&gt; 
&lt;h2&gt;What You Need&lt;/h2&gt; 
&lt;h3&gt;To run the code of this course, you can use either:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/azure-open-ai?WT.mc_id=academic-105485-koreyst"&gt;Azure OpenAI Service&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "aoai-assignment"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/gh-models?WT.mc_id=academic-105485-koreyst"&gt;GitHub Marketplace Model Catalog&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "githubmodels"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/open-ai?WT.mc_id=academic-105485-koreyst"&gt;OpenAI API&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "oai-assignment"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these &lt;a href="https://aka.ms/genai-beginners/python?WT.mc_id=academic-105485-koreyst"&gt;Python&lt;/a&gt; and &lt;a href="https://aka.ms/genai-beginners/typescript?WT.mc_id=academic-105485-koreyst"&gt;TypeScript&lt;/a&gt; courses&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A GitHub account to &lt;a href="https://aka.ms/genai-beginners/github?WT.mc_id=academic-105485-koreyst"&gt;fork this entire repo&lt;/a&gt; to your own GitHub account&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We have created a &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst"&gt;Course Setup&lt;/a&gt;&lt;/strong&gt; lesson to help you with setting up your development environment.&lt;/p&gt; 
&lt;p&gt;Don't forget to &lt;a href="https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst"&gt;star (🌟) this repo&lt;/a&gt; to find it easier later.&lt;/p&gt; 
&lt;h2&gt;🧠 Ready to Deploy?&lt;/h2&gt; 
&lt;p&gt;If you are looking for more advanced code samples, check out our &lt;a href="https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst"&gt;collection of Generative AI Code Samples&lt;/a&gt; in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;🗣️ Meet Other Learners, Get Support&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst"&gt;official Azure AI Foundry Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;Ask questions or share product feedback in our &lt;a href="https://aka.ms/azureaifoundry/forum"&gt;Azure AI Foundry Developer Forum&lt;/a&gt; on Github.&lt;/p&gt; 
&lt;h2&gt;🚀 Building a Startup?&lt;/h2&gt; 
&lt;p&gt;Sign up for &lt;a href="https://aka.ms/genai-foundershub?WT.mc_id=academic-105485-koreyst"&gt;Microsoft for Startups Founders Hub&lt;/a&gt; to receive &lt;strong&gt;free OpenAI credits&lt;/strong&gt; and up to &lt;strong&gt;$150k towards Azure credits to access OpenAI models through Azure OpenAI Services&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href="https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst"&gt;Raise an issue&lt;/a&gt; or &lt;a href="https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst"&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A short video introduction to the topic&lt;/li&gt; 
 &lt;li&gt;A written lesson located in the README&lt;/li&gt; 
 &lt;li&gt;Python and TypeScript code samples supporting Azure OpenAI and OpenAI API&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson Link&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst"&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to Setup Your Development Environment&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst"&gt;Introduction to Generative AI and LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Understanding what Generative AI is and how Large Language Models (LLMs) work.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst"&gt;Exploring and comparing different LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to select the right model for your use case&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst"&gt;Using Generative AI Responsibly&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to build Generative AI Applications responsibly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst"&gt;Understanding Prompt Engineering Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Hands-on Prompt Engineering Best Practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst"&gt;Creating Advanced Prompts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply prompt engineering techniques that improve the outcome of your prompts.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Text Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A text generation app using Azure OpenAI / OpenAI API&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Chat Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; Techniques for efficiently building and integrating chat applications.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Search Apps Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A search application that uses Embeddings to search for data.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Image Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An image generation application&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Low Code AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A Generative AI application using Low Code tools&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst"&gt;Integrating External Applications with Function Calling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; What is function calling and its use cases for applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Designing UX for AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply UX design principles when developing Generative AI Applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Securing Your Generative AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The threats and risks to AI systems and methods to secure these systems.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst"&gt;The Generative AI Application Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The tools and metrics to manage the LLM Lifecycle and LLMOps&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst"&gt;Retrieval Augmented Generation (RAG) and Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using a RAG Framework to retrieve embeddings from a Vector Databases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst"&gt;Open Source Models and Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using open source models available on Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst"&gt;AI Agents&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using an AI Agent Framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst"&gt;Fine-Tuning LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The what, why and how of fine-tuning LLMs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/19-slm/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with SLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The benefits of building with Small Language Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/20-mistral/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with Mistral Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Mistral Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/21-meta/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with Meta Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Meta Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;🌟 Special thanks&lt;/h3&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://www.linkedin.com/in/john0isaac/"&gt;&lt;strong&gt;John Aziz&lt;/strong&gt;&lt;/a&gt; for creating all of the GitHub Actions and workflows&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/bernhard-merkle-738b73/"&gt;&lt;strong&gt;Bernhard Merkle&lt;/strong&gt;&lt;/a&gt; for making key contributions to each lesson to improve the learner and code experience.&lt;/p&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;&lt;strong&gt;NEW&lt;/strong&gt; Model Context Protocol for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/genai-js-course?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>HumanSignal/label-studio</title>
      <link>https://github.com/HumanSignal/label-studio</link>
      <description>&lt;p&gt;Label Studio is a multi-type data labeling and annotation tool with standardized output format&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/12534576/192582340-4c9e4401-1fe6-4dbb-95bb-fdbba5493f61.png"&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/license/heartexlabs/label-studio?logo=heartex" alt="GitHub"&gt; &lt;img src="https://github.com/HumanSignal/label-studio/workflows/label-studio:build/badge.svg?sanitize=true" alt="label-studio:build"&gt; &lt;img src="https://img.shields.io/github/v/release/heartexlabs/label-studio?include_prereleases" alt="GitHub release"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://labelstud.io/"&gt;Website&lt;/a&gt; • &lt;a href="https://labelstud.io/guide/"&gt;Docs&lt;/a&gt; • &lt;a href="https://slack.labelstud.io/?source=github-1"&gt;Join Slack Community &lt;img src="https://app.heartex.ai/docs/images/slack-mini.png" width="18px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Label Studio?&lt;/h2&gt; 
&lt;!-- &lt;a href="https://labelstud.io/blog/release-130.html"&gt;&lt;img src="https://github.com/HumanSignal/label-studio/raw/master/docs/themes/htx/source/images/release-130/LS-Hits-v1.3.png" align="right" /&gt;&lt;/a&gt; --&gt; 
&lt;p&gt;Label Studio is an open source data labeling tool. It lets you label data types like audio, text, images, videos, and time series with a simple and straightforward UI and export to various model formats. It can be used to prepare raw data or improve existing training data to get more accurate ML models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#try-out-label-studio"&gt;Try out Label Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#what-you-get-from-label-studio"&gt;What you get from Label Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#included-templates-for-labeling-data-in-label-studio"&gt;Included templates for labeling data in Label Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#set-up-machine-learning-models-with-Label-Studio"&gt;Set up machine learning models with Label Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#integrate-label-studio-with-your-existing-tools"&gt;Integrate Label Studio with your existing tools&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/images/annotation_examples.gif" alt="Gif of Label Studio annotating different types of data"&gt;&lt;/p&gt; 
&lt;p&gt;Have a custom dataset? You can customize Label Studio to fit your needs. Read an &lt;a href="https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881"&gt;introductory blog post&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Try out Label Studio&lt;/h2&gt; 
&lt;p&gt;Install Label Studio locally or deploy it in a cloud instance. &lt;a href="https://humansignal.com/platform/starter-cloud/"&gt;Or sign up for a free trial of our Starter Cloud edition!&lt;/a&gt; You can learn more about what each edition offers &lt;a href="https://labelstud.io/guide/label_studio_compare"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#install-locally-with-docker"&gt;Install locally with Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#run-with-docker-compose"&gt;Run with Docker Compose (Label Studio + Nginx + PostgreSQL)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#install-locally-with-pip"&gt;Install locally with pip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#install-locally-with-poetry"&gt;Install locally with poetry&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#install-locally-with-anaconda"&gt;Install locally with Anaconda&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#install-for-local-development"&gt;Install for local development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/#deploy-in-a-cloud-instance"&gt;Deploy in a cloud instance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Install locally with Docker&lt;/h3&gt; 
&lt;p&gt;Official Label Studio docker image is &lt;a href="https://hub.docker.com/r/heartexlabs/label-studio"&gt;here&lt;/a&gt; and it can be downloaded with &lt;code&gt;docker pull&lt;/code&gt;. Run Label Studio in a Docker container and access it at &lt;code&gt;http://localhost:8080&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull heartexlabs/label-studio:latest
docker run -it -p 8080:8080 -v $(pwd)/mydata:/label-studio/data heartexlabs/label-studio:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find all the generated assets, including SQLite3 database storage &lt;code&gt;label_studio.sqlite3&lt;/code&gt; and uploaded files, in the &lt;code&gt;./mydata&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h4&gt;Override default Docker install&lt;/h4&gt; 
&lt;p&gt;You can override the default launch command by appending the new arguments:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it -p 8080:8080 -v $(pwd)/mydata:/label-studio/data heartexlabs/label-studio:latest label-studio --log-level DEBUG
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Build a local image with Docker&lt;/h4&gt; 
&lt;p&gt;If you want to build a local image, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t heartexlabs/label-studio:latest .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run with Docker Compose&lt;/h3&gt; 
&lt;p&gt;Docker Compose script provides production-ready stack consisting of the following components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Label Studio&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/"&gt;Nginx&lt;/a&gt; - proxy web server used to load various static data, including uploaded audio, images, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; - production-ready database that replaces less performant SQLite3.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To start using the app from &lt;code&gt;http://localhost&lt;/code&gt; run this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run with Docker Compose + MinIO&lt;/h3&gt; 
&lt;p&gt;You can also run it with an additional MinIO server for local S3 storage. This is particularly useful when you want to test the behavior with S3 storage on your local system. To start Label Studio in this way, you need to run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Add sudo on Linux if you are not a member of the docker group
docker compose -f docker-compose.yml -f docker-compose.minio.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you do not have a static IP address, you must create an entry in your hosts file so that both Label Studio and your browser can access the MinIO server. For more detailed instructions, please refer to &lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/docs/source/guide/storedata.md"&gt;our guide on storing data&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Install locally with pip&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Requires Python &amp;gt;=3.8
pip install label-studio

# Start the server at http://localhost:8080
label-studio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install locally with poetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;### install poetry
pip install poetry

### set poetry environment
poetry new my-label-studio
cd my-label-studio
poetry add label-studio

### activate poetry environment
poetry shell

### Start the server at http://localhost:8080
label-studio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install locally with Anaconda&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create --name label-studio
conda activate label-studio
conda install psycopg2
pip install label-studio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install for local development&lt;/h3&gt; 
&lt;p&gt;You can run the latest Label Studio version locally without installing the package from pypi.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install all package dependencies
pip install poetry
poetry install
# Run database migrations
python label_studio/manage.py migrate
python label_studio/manage.py collectstatic
# Start the server in development mode at http://localhost:8080
python label_studio/manage.py runserver
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Deploy in a cloud instance&lt;/h3&gt; 
&lt;p&gt;You can deploy Label Studio with one click in Heroku, Microsoft Azure, or Google Cloud Platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.heroku.com/deploy?template=https://github.com/HumanSignal/label-studio/tree/heroku-persistent-pg"&gt;&lt;img src="https://www.herokucdn.com/deploy/button.svg?sanitize=true" alt="Deploy" height="30px"&gt;&lt;/a&gt; &lt;a href="https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fhumansignal%2Flabel-studio%2Fdevelop%2Fazuredeploy.json"&gt;&lt;img src="https://aka.ms/deploytoazurebutton" height="30px"&gt;&lt;/a&gt; &lt;a href="https://deploy.cloud.run"&gt;&lt;img src="https://deploy.cloud.run/button.svg?sanitize=true" height="30px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Apply frontend changes&lt;/h4&gt; 
&lt;p&gt;For information about updating the frontend, see &lt;a href="https://github.com/HumanSignal/label-studio/raw/develop/web/README.md#installation-instructions"&gt;label-studio/web/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Install dependencies on Windows&lt;/h4&gt; 
&lt;p&gt;To run Label Studio on Windows, download and install the following wheel packages from &lt;a href="https://www.lfd.uci.edu/~gohlke/pythonlibs"&gt;Gohlke builds&lt;/a&gt; to ensure you're using the correct version of Python:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml"&gt;lxml&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Upgrade pip 
pip install -U pip

# If you're running Win64 with Python 3.8, install the packages downloaded from Gohlke:
pip install lxml‑4.5.0‑cp38‑cp38‑win_amd64.whl

# Install label studio
pip install label-studio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run test suite&lt;/h3&gt; 
&lt;p&gt;To add the tests' dependencies to your local install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install --with test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, it is possible to run the unit tests from a Docker container in which the test dependencies are installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make build-testing-image
make docker-testing-shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In either case, to run the unit tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd label_studio

# sqlite3
DJANGO_DB=sqlite DJANGO_SETTINGS_MODULE=core.settings.label_studio pytest -vv

# postgres (assumes default postgres user,db,pass. Will not work in Docker
# testing container without additional configuration)
DJANGO_DB=default DJANGO_SETTINGS_MODULE=core.settings.label_studio pytest -vv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What you get from Label Studio&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/525ad5ff-6904-4398-b507-7e8954268d69"&gt;https://github.com/user-attachments/assets/525ad5ff-6904-4398-b507-7e8954268d69&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user labeling&lt;/strong&gt; sign up and login, when you create an annotation it's tied to your account.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple projects&lt;/strong&gt; to work on all your datasets in one instance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Streamlined design&lt;/strong&gt; helps you focus on your task, not how to use the software.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable label formats&lt;/strong&gt; let you customize the visual interface to meet your specific labeling needs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support for multiple data types&lt;/strong&gt; including images, audio, text, HTML, time-series, and video.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import from files or from cloud storage&lt;/strong&gt; in Amazon AWS S3, Google Cloud Storage, or JSON, CSV, TSV, RAR, and ZIP archives.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration with machine learning models&lt;/strong&gt; so that you can visualize and compare predictions from different models and perform pre-labeling.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embed it in your data pipeline&lt;/strong&gt; REST API makes it easy to make it a part of your pipeline&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Included templates for labeling data in Label Studio&lt;/h2&gt; 
&lt;p&gt;Label Studio includes a variety of templates to help you label your data, or you can create your own using specifically designed configuration language. The most common templates and use cases for labeling include the following cases:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/images/template-types.png"&gt; 
&lt;h2&gt;Set up machine learning models with Label Studio&lt;/h2&gt; 
&lt;p&gt;Connect your favorite machine learning model using the Label Studio Machine Learning SDK. Follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start your own machine learning backend server. See &lt;a href="https://github.com/HumanSignal/label-studio-ml-backend"&gt;more detailed instructions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Connect Label Studio to the server on the model page found in project settings.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This lets you:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-label&lt;/strong&gt; your data using model predictions.&lt;/li&gt; 
 &lt;li&gt;Do &lt;strong&gt;online learning&lt;/strong&gt; and retrain your model while new annotations are being created.&lt;/li&gt; 
 &lt;li&gt;Do &lt;strong&gt;active learning&lt;/strong&gt; by labeling only the most complex examples in your data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Integrate Label Studio with your existing tools&lt;/h2&gt; 
&lt;p&gt;You can use Label Studio as an independent part of your machine learning workflow or integrate the frontend or backend into your existing tools.&lt;/p&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;label-studio&lt;/td&gt; 
   &lt;td&gt;Server, distributed as a pip package&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/web/libs/editor/"&gt;Frontend library&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The Label Studio frontend library. This uses React to build the UI and mobx-state-tree for state management.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/web/libs/datamanager/"&gt;Data Manager library&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A library for the Data Manager, our data exploration tool.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/HumanSignal/label-studio-sdk/tree/master/src/label_studio_sdk/converter"&gt;label-studio-converter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Encode labels in the format of your favorite machine learning library&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/HumanSignal/label-studio-transformers"&gt;label-studio-transformers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformers library connected and configured for use with Label Studio&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Include a citation for Label Studio in the &lt;strong&gt;References&lt;/strong&gt; section of your articles:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-tex"&gt;@misc{Label Studio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/HumanSignal/label-studio},
  note={Open source software available from https://github.com/HumanSignal/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2025},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This software is licensed under the &lt;a href="https://raw.githubusercontent.com/HumanSignal/label-studio/develop/LICENSE"&gt;Apache 2.0 LICENSE&lt;/a&gt; © &lt;a href="https://www.heartex.com/"&gt;Heartex&lt;/a&gt;. 2020-2025&lt;/p&gt; 
&lt;img src="https://user-images.githubusercontent.com/12534576/192582529-cf628f58-abc5-479b-a0d4-8a3542a4b35e.png" title="Hey everyone!" width="180"&gt;</description>
    </item>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only" alt="Hyperswitch-Logo" width="40%"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only" alt="Hyperswitch-Logo" width="40%"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif" alt="Quickstart demo"&gt; &lt;/p&gt; 
&lt;!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} --&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain"&gt; &lt;img src="https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/juspay/hyperswitch"&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/Made_in-Rust-orange"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/company/hyperswitch/"&gt; &lt;img src="https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;amp;labelColor=grey"&gt; &lt;/a&gt; &lt;a href="https://x.com/hyperswitchio"&gt; &lt;img src="https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;amp;labelColor=grey"&gt; &lt;/a&gt; &lt;a href="https://inviter.co/hyperswitch-slack"&gt; &lt;img src="https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;amp;labelColor=grey&amp;amp;color=%233f0e40"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📁 Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-what-can-i-do-with-hyperswitch"&gt;What Can I Do with Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-quickstart-local-setup"&gt;Quickstart (Local Setup)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#hosted-sandbox-no-setup-required"&gt;Hosted Sandbox (No Setup Required)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-why-hyperswitch"&gt;Why Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt;Architectural Overview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#our-vision"&gt;Our Vision&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#community--contributions"&gt;Community &amp;amp; Contributions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests--bugs"&gt;Feature Requests &amp;amp; Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt;Team Behind Hyperswitch&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt; 
&lt;p&gt;Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack — without unnecessary complexity or vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Each module is independent and purpose-built to optimize different aspects of payment processing.&lt;/p&gt; 
&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt; 
&lt;details&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cost Observability&lt;/strong&gt;&lt;br&gt; Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revenue Recovery&lt;/strong&gt;&lt;br&gt; Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vault&lt;/strong&gt;&lt;br&gt; A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intelligent Routing&lt;/strong&gt;&lt;br&gt; Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconciliation&lt;/strong&gt;&lt;br&gt; Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Payment Methods&lt;/strong&gt;&lt;br&gt; Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt; Local Setup via Docker &lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detects Docker/Podman&lt;/li&gt; 
  &lt;li&gt;Offers multiple deployment profiles: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt;: App server + Control Center&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Full&lt;/strong&gt;: Includes monitoring + schedulers&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt;: Standalone App server&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Provides access links when done&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you need further help, check out our &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker"&gt;video tutorial&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;👉 After setup, &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor"&gt;configure a connector&lt;/a&gt; and &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment"&gt;test a payment&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt; 
&lt;p&gt;Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.&lt;/p&gt; 
&lt;a href="https://app.hyperswitch.io"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/try-the-sandbox.png?raw=true" height="35"&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Access the full Control Center&lt;/li&gt; 
  &lt;li&gt;Configure payment connectors&lt;/li&gt; 
  &lt;li&gt;View logs, routing rules, and retry strategies&lt;/li&gt; 
  &lt;li&gt;Try payments directly from the UI&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:&lt;/p&gt; 
&lt;p&gt;Click to deploy via AWS:&lt;/p&gt; 
&lt;a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/aws_button.png?raw=true" height="35"&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Click the AWS deployment button above to launch the stack.&lt;/li&gt; 
  &lt;li&gt;Follow the guided steps in the AWS Console (approx. 30–45 mins).&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;✅ This setup provisions Hyperswitch on your cloud account using CloudFormation.&lt;/p&gt; 
 &lt;p&gt;📘 For full instructions and Helm-based deployments, check out the&lt;br&gt; &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm"&gt;Cloud Install Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt; &lt;h2 id="architectural-overview"&gt;Architectural Overview&lt;/h2&gt; &lt;/a&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png"&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png"&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png"&gt; 
&lt;h2&gt;Why Hyperswitch?&lt;/h2&gt; 
&lt;p&gt;Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need—whether it’s routing, retries, vaulting, or observability—without vendor lock-in or bloated integrations.&lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;“Linux for Payments”&lt;/strong&gt; — Hyperswitch is a well-architected reference for teams who want to own their payments stack.&lt;/p&gt; 
&lt;p&gt;We believe in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choice—across payment methods, processors, and flows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.&lt;/p&gt; 
&lt;p&gt;Please read our &lt;a href="https://github.com/juspay/hyperswitch/raw/main/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Join the conversation on &lt;a href="https://inviter.co/hyperswitch-slack"&gt;Slack&lt;/a&gt; or explore open issues on &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests"&gt; &lt;h2 id="feature-requests"&gt;Feature requests &amp;amp; Bugs&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our &lt;a href="https://github.com/juspay/hyperswitch/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For reporting a bug, please read the issue guidelines and search for &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;existing and closed issues&lt;/a&gt;. If your problem or idea is not addressed yet, please &lt;a href="https://github.com/juspay/hyperswitch/issues/new/choose"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt; &lt;h2 id="versioning"&gt;Versioning&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt; &lt;h2 id="copyright-and-license"&gt;Copyright and License&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;This product is licensed under the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt; &lt;h2 id="team-behind-hyperswitch"&gt;Team behind Hyperswitch&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;The core team of 150+ engineers building Hyperswitch. Keep up the great work! 🥂&lt;/p&gt; 
&lt;a href="https://github.com/juspay/hyperswitch/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=juspay/hyperswitch" alt="Contributors"&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>