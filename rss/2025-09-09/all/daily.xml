<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Mon, 08 Sep 2025 01:31:09 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu" /&gt; &lt;br /&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka/"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured/"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;⚠️ Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard" /&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph" /&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you’ll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta – expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin’s YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it’ll be featured through agents on the platform. It’s a tall order, but we have big plans for the oTTomator community, and we’re confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;© 2024 Live Agent Studio. All rights reserved.&lt;br /&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;❗️&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)📌&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;• If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;• If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>emcie-co/parlant</title>
      <link>https://github.com/emcie-co/parlant</link>
      <description>&lt;p&gt;LLM agents built for control. Designed for real-world use. Deployed in minutes.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true" /&gt; 
  &lt;img alt="Parlant - AI Agent Framework" src="https://github.com/emcie-co/parlant/raw/develop/docs/LogoTransparentDark.png?raw=true" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://www.parlant.io/" target="_blank"&gt;🌐 Website&lt;/a&gt; • &lt;a href="https://www.parlant.io/docs/quickstart/installation" target="_blank"&gt;⚡ Quick Start&lt;/a&gt; • &lt;a href="https://discord.gg/duxWqxKk6J" target="_blank"&gt;💬 Discord&lt;/a&gt; • &lt;a href="https://www.parlant.io/docs/quickstart/examples" target="_blank"&gt;📖 Examples&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://zdoc.app/de/emcie-co/parlant"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/emcie-co/parlant"&gt;Español&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/emcie-co/parlant"&gt;français&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/emcie-co/parlant"&gt;日本語&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/emcie-co/parlant"&gt;한국어&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/emcie-co/parlant"&gt;Português&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/emcie-co/parlant"&gt;Русский&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/emcie-co/parlant"&gt;中文&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://pypi.org/project/parlant/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/parlant?color=blue" /&gt;&lt;/a&gt; &lt;img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue" /&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/badge/license-Apache%202.0-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/duxWqxKk6J"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1312378700993663007?color=7289da&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/emcie-co/parlant?style=social" /&gt; &lt;/p&gt; 
 &lt;a href="https://trendshift.io/repositories/12768" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/12768" alt="Trending on TrendShift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎯 The Problem Every AI Developer Faces&lt;/h2&gt; 
&lt;p&gt;You build an AI agent. It works great in testing. Then real users start talking to it and...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;❌ It ignores your carefully crafted system prompts&lt;/li&gt; 
 &lt;li&gt;❌ It hallucinates responses in critical moments&lt;/li&gt; 
 &lt;li&gt;❌ It can't handle edge cases consistently&lt;/li&gt; 
 &lt;li&gt;❌ Each conversation feels like a roll of the dice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sound familiar?&lt;/strong&gt; You're not alone. This is the #1 pain point for developers building production AI agents.&lt;/p&gt; 
&lt;h2&gt;⚡ The Solution: Stop Fighting Prompts, Teach Principles&lt;/h2&gt; 
&lt;p&gt;Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, &lt;strong&gt;Parlant ensures it&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Traditional approach: Cross your fingers 🤞
system_prompt = "You are a helpful assistant. Please follow these 47 rules..."

# Parlant approach: Ensured compliance ✅
await agent.create_guideline(
    condition="Customer asks about refunds",
    action="Check order status first to see if eligible",
    tools=[check_order_status],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/journeys"&gt;Journeys&lt;/a&gt;&lt;/strong&gt;: Define clear customer journeys and how your agent should respond at each step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/guidelines"&gt;Behavioral Guidelines&lt;/a&gt;&lt;/strong&gt;: Easily craft agent behavior; Parlant will match the relevant elements contextually.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/tools"&gt;Tool Use&lt;/a&gt;&lt;/strong&gt;: Attach external APIs, data fetchers, or backend services to specific interaction events.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/glossary"&gt;Domain Adaptation&lt;/a&gt;&lt;/strong&gt;: Teach your agent domain-specific terminology and craft personalized responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/canned-responses"&gt;Canned Responses&lt;/a&gt;&lt;/strong&gt;: Use response templates to eliminate hallucinations and guarantee style consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/advanced/explainability"&gt;Explainability&lt;/a&gt;&lt;/strong&gt;: Understand why and when each guideline was matched and followed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;🚀 Get Your Agent Running in 60 Seconds&lt;/h2&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install parlant
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&amp;gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f"Sunny, 72°F in {city}")

@p.tool
async def get_datetime(context: p.ToolContext) -&amp;gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name="WeatherBot",
            description="Helpful weather assistant"
        )

        # Have the agent's context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name="current-datetime", tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition="User asks about weather",
            action="Get current weather and provide a friendly response with suggestions",
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # 🎉 Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your agent is running with ensured rule-following behavior.&lt;/p&gt; 
&lt;h2&gt;🎬 See It In Action&lt;/h2&gt; 
&lt;img alt="Parlant Demo" src="https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true" width="100%" /&gt; 
&lt;h2&gt;🔥 Why Developers Are Switching to Parlant&lt;/h2&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🏗️ &lt;strong&gt;Traditional AI Frameworks&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;⚡ &lt;strong&gt;Parlant&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Write complex system prompts&lt;/li&gt; 
     &lt;li&gt;Hope the LLM follows them&lt;/li&gt; 
     &lt;li&gt;Debug unpredictable behaviors&lt;/li&gt; 
     &lt;li&gt;Scale by prompt engineering&lt;/li&gt; 
     &lt;li&gt;Cross fingers for reliability&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Define rules in natural language&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ensured&lt;/strong&gt; rule compliance&lt;/li&gt; 
     &lt;li&gt;Predictable, consistent behavior&lt;/li&gt; 
     &lt;li&gt;Scale by adding guidelines&lt;/li&gt; 
     &lt;li&gt;Production-ready from day one&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;🎯 Perfect For Your Use Case&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Financial Services&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;E-commerce&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Legal Tech&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Compliance-first design&lt;/td&gt; 
    &lt;td align="center"&gt;HIPAA-ready agents&lt;/td&gt; 
    &lt;td align="center"&gt;Customer service at scale&lt;/td&gt; 
    &lt;td align="center"&gt;Precise legal guidance&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Built-in risk management&lt;/td&gt; 
    &lt;td align="center"&gt;Patient data protection&lt;/td&gt; 
    &lt;td align="center"&gt;Order processing automation&lt;/td&gt; 
    &lt;td align="center"&gt;Document review assistance&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;🛠️ Enterprise-Grade Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🧭 Conversational Journeys&lt;/strong&gt; - Lead the customer step-by-step to a goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 Dynamic Guideline Matching&lt;/strong&gt; - Context-aware rule application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Reliable Tool Integration&lt;/strong&gt; - APIs, databases, external services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📊 Conversation Analytics&lt;/strong&gt; - Deep insights into agent behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔄 Iterative Refinement&lt;/strong&gt; - Continuously improve agent responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🛡️ Built-in Guardrails&lt;/strong&gt; - Prevent hallucination and off-topic responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📱 React Widget&lt;/strong&gt; - &lt;a href="https://github.com/emcie-co/parlant-chat-react"&gt;Drop-in chat UI for any web app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Full Explainability&lt;/strong&gt; - Understand every decision your agent makes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📈 Join 8,000+ Developers Building Better AI&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Companies using Parlant:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Financial institutions • Healthcare providers • Legal firms • E-commerce platforms&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#emcie-co/parlant&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=emcie-co/parlant&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🌟 What Developers Are Saying&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy."&lt;/em&gt; &lt;strong&gt;— Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🏃‍♂️ Quick Start Paths&lt;/h2&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🎯 I want to test it myself&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/installation"&gt;→ 5-minute quickstart&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🛠️ I want to see an example&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/examples"&gt;→ Healthcare agent example&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🚀 I want to get involved&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;→ Join our Discord community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;🤝 Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💬 &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help from the team and community&lt;/li&gt; 
 &lt;li&gt;📖 &lt;strong&gt;&lt;a href="https://parlant.io/docs/quickstart/installation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and examples&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;&lt;a href="https://github.com/emcie-co/parlant/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;📧 &lt;strong&gt;&lt;a href="https://parlant.io/contact"&gt;Direct Support&lt;/a&gt;&lt;/strong&gt; - Direct line to our engineering team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Use it anywhere, including commercial projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Ready to build AI agents that actually work?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;⭐ &lt;strong&gt;Star this repo&lt;/strong&gt; • 🚀 &lt;strong&gt;&lt;a href="https://parlant.io/"&gt;Try Parlant now&lt;/a&gt;&lt;/strong&gt; • 💬 &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Join Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with ❤️ by the team at &lt;a href="https://emcie.co"&gt;Emcie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>openwrt/openwrt</title>
      <link>https://github.com/openwrt/openwrt</link>
      <description>&lt;p&gt;This repository is a mirror of https://git.openwrt.org/openwrt/openwrt.git It is for reference only and is not active for check-ins. We will continue to accept Pull Requests here. They will be merged via staging trees then into openwrt.git.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openwrt/openwrt/main/include/logo.png" alt="OpenWrt logo" /&gt;&lt;/p&gt; 
&lt;p&gt;OpenWrt Project is a Linux operating system targeting embedded devices. Instead of trying to create a single, static firmware, OpenWrt provides a fully writable filesystem with package management. This frees you from the application selection and configuration provided by the vendor and allows you to customize the device through the use of packages to suit any application. For developers, OpenWrt is the framework to build an application without having to build a complete firmware around it; for users this means the ability for full customization, to use the device in ways never envisioned.&lt;/p&gt; 
&lt;p&gt;Sunshine!&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;Built firmware images are available for many architectures and come with a package selection to be used as WiFi home router. To quickly find a factory image usable to migrate from a vendor stock firmware to OpenWrt, try the &lt;em&gt;Firmware Selector&lt;/em&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://firmware-selector.openwrt.org/"&gt;OpenWrt Firmware Selector&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If your device is supported, please follow the &lt;strong&gt;Info&lt;/strong&gt; link to see install instructions or consult the support resources listed below.&lt;/p&gt; 
&lt;h2&gt;&lt;/h2&gt; 
&lt;p&gt;An advanced user may require additional or specific package. (Toolchain, SDK, ...) For everything else than simple firmware download, try the wiki download page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://openwrt.org/downloads"&gt;OpenWrt Wiki Download&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;To build your own firmware you need a GNU/Linux, BSD or macOS system (case sensitive filesystem required). Cygwin is unsupported because of the lack of a case sensitive file system.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;You need the following tools to compile OpenWrt, the package names vary between distributions. A complete list with distribution specific packages is found in the &lt;a href="https://openwrt.org/docs/guide-developer/build-system/install-buildsystem"&gt;Build System Setup&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;binutils bzip2 diff find flex gawk gcc-6+ getopt grep install libc-dev libz-dev
make4.1+ perl python3.7+ rsync subversion unzip which
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;./scripts/feeds update -a&lt;/code&gt; to obtain all the latest package definitions defined in feeds.conf / feeds.conf.default&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;./scripts/feeds install -a&lt;/code&gt; to install symlinks for all obtained packages into package/feeds/&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;make menuconfig&lt;/code&gt; to select your preferred configuration for the toolchain, target system &amp;amp; firmware packages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;make&lt;/code&gt; to build your firmware. This will download all sources, build the cross-compile toolchain and then cross-compile the GNU/Linux kernel &amp;amp; all chosen applications for your target system.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Related Repositories&lt;/h3&gt; 
&lt;p&gt;The main repository uses multiple sub-repositories to manage packages of different categories. All packages are installed via the OpenWrt package manager called &lt;code&gt;opkg&lt;/code&gt;. If you're looking to develop the web interface or port packages to OpenWrt, please find the fitting repository below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/openwrt/luci"&gt;LuCI Web Interface&lt;/a&gt;: Modern and modular interface to control the device via a web browser.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/openwrt/packages"&gt;OpenWrt Packages&lt;/a&gt;: Community repository of ported packages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/openwrt/routing"&gt;OpenWrt Routing&lt;/a&gt;: Packages specifically focused on (mesh) routing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/openwrt/video"&gt;OpenWrt Video&lt;/a&gt;: Packages specifically focused on display servers and clients (Xorg and Wayland).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support Information&lt;/h2&gt; 
&lt;p&gt;For a list of supported devices see the &lt;a href="https://openwrt.org/supported_devices"&gt;OpenWrt Hardware Database&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://openwrt.org/docs/guide-quick-start/start"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openwrt.org/docs/guide-user/start"&gt;User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openwrt.org/docs/guide-developer/start"&gt;Developer Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openwrt.org/docs/techref/start"&gt;Technical Reference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Support Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://forum.openwrt.org"&gt;Forum&lt;/a&gt;: For usage, projects, discussions and hardware advise.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://webchat.oftc.net/#openwrt"&gt;Support Chat&lt;/a&gt;: Channel &lt;code&gt;#openwrt&lt;/code&gt; on &lt;strong&gt;oftc.net&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bugs.openwrt.org"&gt;Bug Reports&lt;/a&gt;: Report bugs in OpenWrt&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lists.openwrt.org/mailman/listinfo/openwrt-devel"&gt;Dev Mailing List&lt;/a&gt;: Send patches&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://webchat.oftc.net/#openwrt-devel"&gt;Dev Chat&lt;/a&gt;: Channel &lt;code&gt;#openwrt-devel&lt;/code&gt; on &lt;strong&gt;oftc.net&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenWrt is licensed under GPL-2.0&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zama-ai/fhevm</title>
      <link>https://github.com/zama-ai/fhevm</link>
      <description>&lt;p&gt;FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/fhevm-header-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/fhevm-header-light.png" /&gt; 
  &lt;img width="500" alt="fhevm" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt; 📃 Read white paper&lt;/a&gt; |&lt;a href="https://docs.zama.ai/protocol"&gt; 📒 Documentation&lt;/a&gt; | &lt;a href="https://zama.ai/community"&gt; 💛 Community support&lt;/a&gt; | &lt;a href="https://github.com/zama-ai/awesome-zama"&gt; 📚 FHE resources by Zama&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zama-ai/fhevm/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/fhevm/raw/main/LICENSE"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/bounty-program"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img alt="SLSA 3" src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;h3&gt;What is FHEVM?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;FHEVM&lt;/strong&gt; is the core framework of the &lt;em&gt;Zama Confidential Blockchain Protocol&lt;/em&gt;. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.&lt;/p&gt; 
&lt;p&gt;FHEVM ensures both confidentiality and composability, with the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end encryption of transactions and state:&lt;/strong&gt; Data included in transactions is encrypted and never visible to anyone.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Composability and data availability on-chain:&lt;/strong&gt; States are updated while remaining encrypted at all times.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No impact on existing dApps and state:&lt;/strong&gt; Encrypted state co-exists alongside public one, and doesn't impact existing dApps. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Table of contents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt;About&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#what-is-fhevm"&gt;What is FHEVM?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#project-structure"&gt;Project structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#main-features"&gt;Main features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#use-cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#working-with-fhevm"&gt;Working with FHEVM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#citations"&gt;Citations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#support"&gt;Support&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project structure&lt;/h3&gt; 
&lt;p&gt;The directories of this repository are organized in the following way:&lt;/p&gt; 
&lt;h6&gt;FHEVM Contracts&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;gateway-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart contracts managing the gateway between on-chain and off-chain components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;host-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart Contracts deployed on the host chain for orchestrating FHE workflows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Compute Engines&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;coprocessor/&lt;/code&gt;&lt;/strong&gt;: Rust-based coprocessor implementation for FHE operations.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;kms-connector/&lt;/code&gt;&lt;/strong&gt;: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Utilities&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;charts/&lt;/code&gt;&lt;/strong&gt;: Helm charts and deployment configurations for the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;golden-container-images/&lt;/code&gt;&lt;/strong&gt;: Docker golden images for Node.js and Rust environments used as base images by the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;test-suite/&lt;/code&gt;&lt;/strong&gt;: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.&lt;/p&gt; &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Main features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy by design:&lt;/strong&gt; Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solidity integration:&lt;/strong&gt; Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains — such as Hardhat and Foundry (&lt;em&gt;coming soon&lt;/em&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programmable privacy:&lt;/strong&gt; Define exactly what data is encrypted and write the access control logic directly in your smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High precision encrypted integers :&lt;/strong&gt; Up to 256 bits of precision for integers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full range of operators:&lt;/strong&gt; All typical operators are available: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, ternary-if, boolean operations…. Consecutive FHE operations are not limited.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security:&lt;/strong&gt; The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Symbolic execution of FHE computations:&lt;/strong&gt; All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more about FHEVM features in the &lt;a href="https://docs.zama.ai/protocol"&gt;documentation&lt;/a&gt; and in our &lt;a href="https://github.com/zama-ai/fhevm/raw/main/fhevm-whitepaper.pdf"&gt;whitepaper&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;p&gt;FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential transfers&lt;/strong&gt;: Keep balances and amounts private, without using mixers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Swap tokens and RWAs on-chain without others seeing the amounts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blind auctions&lt;/strong&gt;: Bid on items without revealing the amount or the winner.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-chain games&lt;/strong&gt;: Keep moves, selections, cards, or items hidden until ready to reveal.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential voting&lt;/strong&gt;: Prevents bribery and blackmailing by keeping votes private.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encrypted DIDs&lt;/strong&gt;: Store identities on-chain and generate attestations without ZK.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more use cases in the &lt;a href="https://docs.zama.ai/protocol/examples"&gt;list of examples&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol"&gt;Documentation&lt;/a&gt; — Official documentation of FHEVM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt;Whitepaper&lt;/a&gt; — Technical overview of FHEVM's cryptographic design.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol/examples"&gt;Examples&lt;/a&gt; — Examples of building confidential smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm"&gt;Awesome Zama – FHEVM&lt;/a&gt; — Curated articles, talks, and ecosystem projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Working with FHEVM&lt;/h2&gt; 
&lt;h3&gt;Citations&lt;/h3&gt; 
&lt;p&gt;To cite FHEVM or the whitepaper in academic papers, please use the following entries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;There are two ways to contribute to FHEVM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/fhevm/issues/new/choose"&gt;Open issues&lt;/a&gt; to report bugs and typos, or to suggest new ideas&lt;/li&gt; 
 &lt;li&gt;Request to become an official contributor by emailing &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do! &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This software is distributed under the &lt;strong&gt;BSD-3-Clause-Clear&lt;/strong&gt; license. Read &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/LICENSE"&gt;this&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Is Zama’s technology free to use?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama’s commercial patent license.&lt;/p&gt; 
 &lt;p&gt;Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in &lt;a href="https://www.zama.ai/post/open-source"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;What do I need to do if I want to use Zama’s technology for commercial purposes?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Do you file IP on your technology?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Yes, all Zama’s technologies are patented.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Can you customize a solution for my specific use case?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;a target="_blank" href="https://community.zama.ai"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/support-banner-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/support-banner-light.png" /&gt; 
  &lt;img alt="Support" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.&lt;/p&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uutils/coreutils</title>
      <link>https://github.com/uutils/coreutils</link>
      <description>&lt;p&gt;Cross-platform Rust rewrite of the GNU coreutils&lt;/p&gt;&lt;hr&gt;&lt;div class="oranda-hide"&gt; 
 &lt;div align="center"&gt; 
  &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/logo.svg?sanitize=true" alt="uutils logo" /&gt;&lt;/p&gt; 
  &lt;h1&gt;uutils coreutils&lt;/h1&gt; 
  &lt;p&gt;&lt;a href="https://crates.io/crates/coreutils"&gt;&lt;img src="https://img.shields.io/crates/v/coreutils.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/wQVJbvJ"&gt;&lt;img src="https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;amp;longCache=true&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uutils/coreutils/raw/main/LICENSE"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/repo/github/uutils/coreutils"&gt;&lt;img src="https://deps.rs/repo/github/uutils/coreutils/status.svg?sanitize=true" alt="dependency status" /&gt;&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;a href="https://codecov.io/gh/uutils/coreutils"&gt;&lt;img src="https://codecov.io/gh/uutils/coreutils/branch/master/graph/badge.svg?sanitize=true" alt="CodeCov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/MSRV-1.85.0-brightgreen" alt="MSRV" /&gt; &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;&lt;img src="https://hosted.weblate.org/widget/rust-coreutils/svg-badge.svg?sanitize=true" alt="Weblate" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p&gt;uutils coreutils is a cross-platform reimplementation of the GNU coreutils in &lt;a href="http://www.rust-lang.org"&gt;Rust&lt;/a&gt;. While all programs have been implemented, some options might be missing or different behavior might be experienced.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;p&gt;To install it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install coreutils
~/.cargo/bin/coreutils
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;!-- markdownlint-disable-next-line MD026 --&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;uutils coreutils aims to be a drop-in replacement for the GNU utils. Differences with GNU are treated as bugs.&lt;/p&gt; 
&lt;p&gt;Our key objectives include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Matching GNU's output (stdout and error code) exactly&lt;/li&gt; 
 &lt;li&gt;Better error messages&lt;/li&gt; 
 &lt;li&gt;Providing comprehensive internationalization support (UTF-8)&lt;/li&gt; 
 &lt;li&gt;Improved performances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/extensions.md"&gt;Extensions&lt;/a&gt; when relevant (example: --progress)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uutils aims to work on as many platforms as possible, to be able to use the same utils on Linux, macOS, Windows and other platforms. This ensures, for example, that scripts can be easily transferred between platforms.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;h2&gt;Documentation&lt;/h2&gt; 
 &lt;p&gt;uutils has both user and developer documentation available:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://uutils.github.io/coreutils/docs/"&gt;User Manual&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.rs/crate/coreutils/"&gt;Developer Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Both can also be generated locally, the instructions for that can be found in the &lt;a href="https://github.com/uutils/uutils.github.io"&gt;coreutils docs&lt;/a&gt; repository.&lt;/p&gt; 
 &lt;p&gt;Use &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;weblate/rust-coreutils&lt;/a&gt; to translate the Rust coreutils into your language.&lt;/p&gt; 
 &lt;!-- ANCHOR: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;Requirements&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Rust (&lt;code&gt;cargo&lt;/code&gt;, &lt;code&gt;rustc&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;GNU Make (optional)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Rust Version&lt;/h3&gt; 
 &lt;p&gt;uutils follows Rust's release channels and is tested against stable, beta and nightly. The current Minimum Supported Rust Version (MSRV) is &lt;code&gt;1.85.0&lt;/code&gt;.&lt;/p&gt; 
 &lt;h2&gt;Building&lt;/h2&gt; 
 &lt;p&gt;There are currently two methods to build the uutils binaries: either Cargo or GNU Make.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Building the full package, including all documentation, requires both Cargo and GNU Make on a Unix platform.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;For either method, we first need to fetch the repository:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/uutils/coreutils
cd coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Cargo&lt;/h3&gt; 
 &lt;p&gt;Building uutils using Cargo is easy because the process is the same as for every other Rust program:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command builds the most portable common core set of uutils into a multicall (BusyBox-type) binary, named 'coreutils', on most Rust-supported platforms.&lt;/p&gt; 
 &lt;p&gt;Additional platform-specific uutils are often available. Building these expanded sets of uutils for a platform (on that platform) is as simple as specifying it as a feature:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release --features macos
# or ...
cargo build --release --features windows
# or ...
cargo build --release --features unix
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you don't want to build every utility available on your platform into the final binary, you can also specify which ones you want to build manually. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --features "base32 cat echo rm" --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you don't want to build the multicall binary and would prefer to build the utilities as individual binaries, that is also possible. Each utility is contained in its own package within the main repository, named "uu_UTILNAME". To build individual utilities, use cargo to build just the specific packages (using the &lt;code&gt;--package&lt;/code&gt; [aka &lt;code&gt;-p&lt;/code&gt;] option). For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;GNU Make&lt;/h3&gt; 
 &lt;p&gt;Building using &lt;code&gt;make&lt;/code&gt; is a simple process as well.&lt;/p&gt; 
 &lt;p&gt;To simply build all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;In release mode:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROFILE=release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Installation&lt;/h2&gt; 
 &lt;h3&gt;Install with Cargo&lt;/h3&gt; 
 &lt;p&gt;Likewise, installing can simply be done using:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --path . --locked
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command will install uutils into Cargo's &lt;em&gt;bin&lt;/em&gt; folder (&lt;em&gt;e.g.&lt;/em&gt; &lt;code&gt;$HOME/.cargo/bin&lt;/code&gt;).&lt;/p&gt; 
 &lt;p&gt;This does not install files necessary for shell completion or manpages. For manpages or shell completion to work, use &lt;code&gt;GNU Make&lt;/code&gt; or see &lt;code&gt;Manually install shell completions&lt;/code&gt;/&lt;code&gt;Manually install manpages&lt;/code&gt;.&lt;/p&gt; 
 &lt;h3&gt;Install with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To install all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install using &lt;code&gt;sudo&lt;/code&gt; switch &lt;code&gt;-E&lt;/code&gt; must be used:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;sudo -E make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install every program with a prefix (e.g. uu-echo uu-cat):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Set install parent directory (default value is /usr/local):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Installing with &lt;code&gt;make&lt;/code&gt; installs shell completions for all installed utilities for &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt;. Completions for &lt;code&gt;elvish&lt;/code&gt; and &lt;code&gt;powershell&lt;/code&gt; can also be generated; See &lt;code&gt;Manually install shell completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;To skip installation of completions and manpages:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make COMPLETIONS=n MANPAGES=n install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install shell completions&lt;/h3&gt; 
 &lt;p&gt;The &lt;code&gt;coreutils&lt;/code&gt; binary can generate completions for the &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;elvish&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt;, &lt;code&gt;powershell&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt; shells. It prints the result to stdout.&lt;/p&gt; 
 &lt;p&gt;The syntax is:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo run completion &amp;lt;utility&amp;gt; &amp;lt;shell&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install completions for &lt;code&gt;ls&lt;/code&gt; on &lt;code&gt;bash&lt;/code&gt; to &lt;code&gt;/usr/local/share/bash-completion/completions/ls&lt;/code&gt;, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo run completion ls bash &amp;gt; /usr/local/share/bash-completion/completions/ls
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install manpages&lt;/h3&gt; 
 &lt;p&gt;To generate manpages, the syntax is:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run manpage &amp;lt;utility&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install the manpage for &lt;code&gt;ls&lt;/code&gt; to &lt;code&gt;/usr/local/share/man/man1/ls.1&lt;/code&gt; run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run manpage ls &amp;gt; /usr/local/share/man/man1/ls.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Un-installation&lt;/h2&gt; 
 &lt;p&gt;Un-installation differs depending on how you have installed uutils. If you used Cargo to install, use Cargo to uninstall. If you used GNU Make to install, use Make to uninstall.&lt;/p&gt; 
 &lt;h3&gt;Uninstall with Cargo&lt;/h3&gt; 
 &lt;p&gt;To uninstall uutils:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo uninstall coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Uninstall with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To uninstall all utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall every program with a set prefix:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall from a custom parent directory:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- ANCHOR_END: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;GNU test suite compatibility&lt;/h2&gt; 
 &lt;p&gt;Below is the evolution of how many GNU tests uutils passes. A more detailed breakdown of the GNU test results of the main branch can be found &lt;a href="https://uutils.github.io/coreutils/docs/test_coverage.html"&gt;in the user manual&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/orgs/uutils/projects/1"&gt;https://github.com/orgs/uutils/projects/1&lt;/a&gt; for the main meta bugs (many are missing).&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/uutils/coreutils-tracking/raw/main/gnu-results.svg?raw=true" alt="Evolution over time" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- close oranda-hide div --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to uutils, please see &lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uutils is licensed under the MIT License - see the &lt;code&gt;LICENSE&lt;/code&gt; file for details&lt;/p&gt; 
&lt;p&gt;GNU Coreutils is licensed under the GPL 3.0 or later.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kilo-Org/kilocode</title>
      <link>https://github.com/Kilo-Org/kilocode</link>
      <description>&lt;p&gt;Open Source AI coding assistant for planning, building, and fixing code. We frequently merge features from open-source projects like Roo Code and Cline, while building our own vision. Follow us: kilocode.ai/social&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=kilocode.Kilo-Code"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/kilocode.Kilo-Code.svg?label=VS%20Code%20Marketplace" alt="VS Code Marketplace" /&gt;&lt;/a&gt; &lt;a href="https://x.com/kilo_code"&gt;&lt;img src="https://img.shields.io/twitter/follow/kilo_code?style=flat&amp;amp;logo=x&amp;amp;color=555" alt="X (Twitter)" /&gt;&lt;/a&gt; &lt;a href="https://blog.kilocode.ai"&gt;&lt;img src="https://img.shields.io/badge/Blog-555?style=flat&amp;amp;logo=substack&amp;amp;logoColor=white" alt="Substack Blog" /&gt;&lt;/a&gt; &lt;a href="https://kilocode.ai/discord"&gt;&lt;img src="https://img.shields.io/discord/1349288496988160052?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/kilocode/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/kilocode?style=flat&amp;amp;logo=reddit&amp;amp;logoColor=white" alt="Reddit" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;🚀 Kilo Code&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open-source VS Code AI agent. We frequently merge features from open-source projects, such as &lt;a href="https://github.com/RooVetGit/Roo-Code"&gt;Roo Code&lt;/a&gt; and &lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt;, while building our own vision.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;✨ Generate code from natural language&lt;/li&gt; 
 &lt;li&gt;✅ Checks its own work&lt;/li&gt; 
 &lt;li&gt;🧪 Run terminal commands&lt;/li&gt; 
 &lt;li&gt;🌐 Automate the browser&lt;/li&gt; 
 &lt;li&gt;🤖 Latest AI models&lt;/li&gt; 
 &lt;li&gt;🎁 API keys optional&lt;/li&gt; 
 &lt;li&gt;💡 &lt;strong&gt;Get $20 in bonus credits when you top-up for the first time&lt;/strong&gt; Credits can be used with 400+ models like Gemini 2.5 Pro, Claude 4 Sonnet &amp;amp; Opus, and GPT-5&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Kilo-Org/kilocode/refs/heads/main/kilo.gif" width="100%" /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kilocode.ai/vscode-marketplace?utm_source=Readme"&gt;VS Code Marketplace&lt;/a&gt; (download)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kilocode.ai"&gt;Official KiloCode.ai Home page&lt;/a&gt; (learn more)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code Generation:&lt;/strong&gt; Generate code using natural language.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Automation:&lt;/strong&gt; Automate repetitive coding tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Refactoring:&lt;/strong&gt; Refactor and improve existing code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Server Marketplace&lt;/strong&gt;: Easily find, and use MCP servers to extend the agent capabilities.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi Mode&lt;/strong&gt;: Plan with Architect, Code with Coder, and Debug with Debugger, and make your own custom modes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to get started with Kilo Code&lt;/h2&gt; 
&lt;h2&gt;How to get started with Kilo Code&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the Kilo Code extension from the &lt;a href="https://marketplace.visualstudio.com/items?itemName=kilocode.Kilo-Code"&gt;VS Code Marketplace&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Create your account to access 400+ cutting-edge AI models including Gemini 2.5 Pro, Claude 4 Sonnet &amp;amp; Opus, and GPT-5 – with transparent pricing that matches provider rates exactly.&lt;/li&gt; 
 &lt;li&gt;Start coding with AI that adapts to your workflow. Watch our quick-start guide to see Kilo Code in action:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/pqGfYXgrhig"&gt;&lt;img src="https://img.youtube.com/vi/pqGfYXgrhig/maxresdefault.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Difference between Kilo Code, Roo Code and Cline&lt;/h2&gt; 
&lt;p&gt;Kilo Code started as a fork of Roo Code, which itself is a fork of Cline. We frequently merge features from these open-source projects and contribute improvements back. Built on these foundations, Kilo Code is independently developed with our own vision for AI coding agents.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No need to fiddle with API keys, Kilo Code ships with the latest AI models plugged in, including Gemini 2.5 Pro, Claude 4 Sonnet &amp;amp; Opus, and GPT-5&lt;/li&gt; 
 &lt;li&gt;MCP Server Marketplace: Easily find, and use MCP servers to extend the agent capabilities.&lt;/li&gt; 
 &lt;li&gt;Autocomplete (experimental)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Kilo Code is a direct fork from Roo Code, and also includes the following features from Cline (and our own features):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;System notifications: Get notified when the agent is done with a task.&lt;/li&gt; 
 &lt;li&gt;Easy model connection: batteries included.&lt;/li&gt; 
 &lt;li&gt;Editing previous messages&lt;/li&gt; 
 &lt;li&gt;Assisted commit messages: we write git commit messages for you based on what changed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Extension Development&lt;/h2&gt; 
&lt;p&gt;For details on building and developing the extension, see &lt;a href="https://raw.githubusercontent.com/Kilo-Org/kilocode/main/DEVELOPMENT.md"&gt;DEVELOPMENT.md&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/llm-app</title>
      <link>https://github.com/pathwaycom/llm-app</link>
      <description>&lt;p&gt;Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. 🐳Docker-friendly.⚡Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Pathway AI Pipelines&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/4400" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4400" alt="pathwaycom%2Fllm-app | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&amp;amp;logo=linux&amp;amp;logoColor=black" alt="Linux" /&gt; &lt;img src="https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="macOS" /&gt; &lt;a href="https://discord.gg/pathway"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/intent/follow?screen_name=pathway_com"&gt;&lt;img src="https://img.shields.io/badge/X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="follow on X" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Pathway's &lt;strong&gt;AI Pipelines&lt;/strong&gt; allow you to quickly put in production AI applications that offer &lt;strong&gt;high-accuracy RAG and AI enterprise search at scale&lt;/strong&gt; using the most &lt;strong&gt;up-to-date knowledge&lt;/strong&gt; available in your data sources. It provides you ready-to-deploy &lt;strong&gt;LLM (Large Language Model) App Templates&lt;/strong&gt;. You can test them on your own machine and deploy on-cloud (GCP, AWS, Azure, Render,...) or on-premises.&lt;/p&gt; 
&lt;p&gt;The apps connect and sync (all new data additions, deletions, updates) with data sources on your &lt;strong&gt;file system, Google Drive, Sharepoint, S3, Kafka, PostgreSQL, real-time data APIs&lt;/strong&gt;. They come with no infrastructure dependencies that would need a separate setup. They include &lt;strong&gt;built-in data indexing&lt;/strong&gt; enabling vector search, hybrid search, and full-text search - all done in-memory, with cache.&lt;/p&gt; 
&lt;h2&gt;Application Templates&lt;/h2&gt; 
&lt;p&gt;The application templates provided in this repo scale up to &lt;strong&gt;millions of pages of documents&lt;/strong&gt;. Some of them are optimized for simplicity, some are optimized for amazing accuracy. Pick the one that suits you best. You can use it out of the box, or change some steps of the pipeline - for example, if you would like to add a new data source, or change a Vector Index into a Hybrid Index, it's just a one-line change.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Application (template)&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/demo-question-answering/"&gt;&lt;code&gt;Question-Answering RAG App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Basic end-to-end RAG app. A question-answering pipeline that uses the GPT model of choice to provide answers to queries to your documents (PDF, DOCX,...) on a live connected data source (files, Google Drive, Sharepoint,...). You can also try out a &lt;a href="https://pathway.com/solutions/rag-pipelines#try-it-out"&gt;demo REST endpoint&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/demo-document-indexing/"&gt;&lt;code&gt;Live Document Indexing (Vector Store / Retriever)&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A real-time document indexing pipeline for RAG that acts as a vector store service. It performs live indexing on your documents (PDF, DOCX,...) from a connected data source (files, Google Drive, Sharepoint,...). It can be used with any frontend, or integrated as a retriever backend for a &lt;a href="https://pathway.com/blog/langchain-integration"&gt;Langchain&lt;/a&gt; or &lt;a href="https://pathway.com/blog/llamaindex-pathway"&gt;Llamaindex&lt;/a&gt; application. You can also try out a &lt;a href="https://pathway.com/solutions/ai-contract-management#try-it-out"&gt;demo REST endpoint&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/gpt_4o_multimodal_rag/"&gt;&lt;code&gt;Multimodal RAG pipeline with GPT4o&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Multimodal RAG using GPT-4o in the parsing stage to index PDFs and other documents from a connected data source files, Google Drive, Sharepoint,...). It is perfect for extracting information from unstructured financial documents in your folders (including charts and tables), updating results as documents change or new ones arrive.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/unstructured_to_sql_on_the_fly/"&gt;&lt;code&gt;Unstructured-to-SQL pipeline + SQL question-answering&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG example which connects to unstructured financial data sources (financial report PDFs), structures the data into SQL, and loads it into a PostgreSQL table. It also answers natural language user queries to these financial documents by translating them into SQL using an LLM and executing the query on the PostgreSQL table.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/adaptive-rag/"&gt;&lt;code&gt;Adaptive RAG App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A RAG application using Adaptive RAG, a technique developed by Pathway to reduce token cost in RAG up to 4x while maintaining accuracy.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/private-rag/"&gt;&lt;code&gt;Private RAG App with Mistral and Ollama&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A fully private (local) version of the &lt;code&gt;demo-question-answering&lt;/code&gt; RAG pipeline using Pathway, Mistral, and Ollama.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/slides_ai_search/"&gt;&lt;code&gt;Slides AI Search App&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;An indexing pipeline for retrieving slides. It performs multi-modal of PowerPoint and PDF and maintains live index of your slides."&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How do these AI Pipelines work?&lt;/h2&gt; 
&lt;p&gt;The apps can be run as &lt;strong&gt;Docker containers&lt;/strong&gt;, and expose an &lt;strong&gt;HTTP API&lt;/strong&gt; to connect the frontend. To allow quick testing and demos, some app templates also include an optional Streamlit UI which connects to this API.&lt;/p&gt; 
&lt;p&gt;The apps rely on the &lt;a href="https://github.com/pathwaycom/pathway"&gt;Pathway Live Data framework&lt;/a&gt; for data source synchronization and for serving API requests (Pathway is a standalone Python library with a Rust engine built into it). They bring you a &lt;strong&gt;simple and unified application logic&lt;/strong&gt; for back-end, embedding, retrieval, LLM tech stack. There is no need to integrate and maintain separate modules for your Gen AI app: &lt;del&gt;Vector Database (e.g. Pinecone/Weaviate/Qdrant) + Cache (e.g. Redis) + API Framework (e.g. Fast API)&lt;/del&gt;. Pathway's default choice of &lt;strong&gt;built-in vector index&lt;/strong&gt; is based on the lightning-fast &lt;a href="https://github.com/unum-cloud/usearch"&gt;usearch&lt;/a&gt; library, and &lt;strong&gt;hybrid full-text indexes&lt;/strong&gt; make use of &lt;a href="https://github.com/quickwit-oss/tantivy"&gt;Tantivy&lt;/a&gt; library. Everything works out of the box.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Each of the &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/"&gt;App templates&lt;/a&gt; in this repo contains a README.md with instructions on how to run it.&lt;/p&gt; 
&lt;p&gt;You can also find &lt;a href="https://pathway.com/developers/templates/"&gt;more ready-to-run code templates&lt;/a&gt; on the Pathway website.&lt;/p&gt; 
&lt;h2&gt;Some visual highlights&lt;/h2&gt; 
&lt;p&gt;Effortlessly extract and organize table and chart data from PDFs, docs, and more with multimodal RAG - in real-time:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/pathwaycom/llm-app/raw/main/examples/pipelines/gpt_4o_multimodal_rag/gpt4o_with_pathway_comparison.gif" alt="Effortlessly extract and organize table and chart data from PDFs, docs, and more with multimodal RAG - in real-time" /&gt;&lt;/p&gt; 
&lt;p&gt;(Check out &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/gpt_4o_multimodal_rag/"&gt;&lt;code&gt;Multimodal RAG pipeline with GPT4o&lt;/code&gt;&lt;/a&gt; to see the whole pipeline in the works. You may also check out the &lt;a href="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/unstructured_to_sql_on_the_fly/"&gt;&lt;code&gt;Unstructured-to-SQL pipeline&lt;/code&gt;&lt;/a&gt; for a minimal example that works with non-multimodal models as well.)&lt;/p&gt; 
&lt;p&gt;Automated real-time knowledge mining and alerting:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/pathwaycom/llm-app/main/examples/pipelines/drive_alert/drive_alert_demo.gif" alt="Automated real-time knowledge mining and alerting" /&gt;&lt;/p&gt; 
&lt;p&gt;(Check out the &lt;a href="https://github.com/pathwaycom/llm-app/tree/main/examples/pipelines/drive_alert"&gt;&lt;code&gt;Alerting when answers change on Google Drive&lt;/code&gt;&lt;/a&gt; app example.)&lt;/p&gt; 
&lt;h3&gt;Do-it-Yourself Videos&lt;/h3&gt; 
&lt;p&gt;▶️ &lt;a href="https://www.youtube.com/watch?v=kcrJSk00duw"&gt;An introduction to building LLM apps with Pathway&lt;/a&gt; - by &lt;a href="https://scholar.google.com/citations?user=Yc94070AAAAJ"&gt;Jan Chorowski&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;▶️ &lt;a href="https://www.youtube.com/watch?v=k1XGo7ts4tI"&gt;Let's build a real-world LLM app in 11 minutes&lt;/a&gt; - by &lt;a href="https://substack.com/@paulabartabajo"&gt;Pau Labarta Bajo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;To provide feedback or report a bug, please &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;raise an issue on our issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Anyone who wishes to contribute to this project, whether documentation, features, bug fixes, code cleanup, testing, or code reviews, is very much encouraged to do so. If this is your first contribution to a GitHub project, here is a &lt;a href="https://docs.github.com/en/get-started/quickstart/contributing-to-projects"&gt;Get Started Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you'd like to make a contribution that needs some more work, just raise your hand on the &lt;a href="https://discord.com/invite/pathway"&gt;Pathway Discord server&lt;/a&gt; (#get-help) and let us know what you are planning!&lt;/p&gt; 
&lt;h2&gt;Supported and maintained by&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/"&gt;&lt;img src="https://pathway.com/logo-light.svg?sanitize=true" alt="Pathway" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pathway.com/solutions/llm-app"&gt; &lt;img src="https://img.shields.io/badge/See%20Pathway's%20offering%20for%20AI%20applications-0000FF" alt="See Pathway's offering for AI applications" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Vector-Wangel/XLeRobot</title>
      <link>https://github.com/Vector-Wangel/XLeRobot</link>
      <description>&lt;p&gt;XLeRobot: Practical Dual-Arm Mobile Home Robot for $660&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;XLeRobot 🤖&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/lang-en-blue.svg?sanitize=true" alt="en" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/lang-%E4%B8%AD%E6%96%87-brown.svg?sanitize=true" alt="中文" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt; &lt;img width="1725" height="1140" alt="front" src="https://github.com/user-attachments/assets/f9c454ee-2c46-42b4-a5d7-88834a1c95ab" /&gt; &lt;/a&gt; 
&lt;h2&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="Apache License" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/VectorWang2"&gt;&lt;img src="https://img.shields.io/twitter/follow/VectorWang?style=social" alt="Twitter/X" /&gt;&lt;/a&gt; &lt;a href="https://xlerobot.readthedocs.io/en/latest/"&gt;&lt;img src="https://img.shields.io/badge/docs-passing-brightgreen.svg?sanitize=true" alt="Docs status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/bjZveEUh6F"&gt;&lt;img src="https://img.shields.io/badge/Discord-XLeRobot-7289da?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;🚀 Bringing Embodied AI to Everyone - Cheaper Than an iPhone! 📱&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;💵 Starts from $660 cost and ⏰ &amp;lt;4hrs total assembly time!!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Built upon the giants: &lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;, &lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100/SO-101&lt;/a&gt;, &lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, &lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/17e31979-bd5e-4790-be70-566ea8bb181e" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/96ff4a3e-3402-47a2-bc6b-b45137ee3fdd" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f6d52acc-bc8d-46f6-b3cd-8821f0306a7f" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/59086300-3e6f-4a3c-b5e0-db893eeabc0c" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/4ddbc0ff-ca42-4ad0-94c6-4e0f4047fd01" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7abc890e-9c9c-4983-8b25-122573028de5" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e74a602b-0146-49c4-953d-3fa3b038a7f7" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d8090b15-97f3-4abc-98c8-208ae79894d5" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8b54adc3-d61b-42a0-8985-ea28f2e8f64c" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;💵 Total Cost 💵&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Cost excludes 3D printing, tools, shipping, and taxes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Price (Buy all the parts yourself)&lt;/th&gt; 
   &lt;th&gt;US&lt;/th&gt; 
   &lt;th&gt;EU&lt;/th&gt; 
   &lt;th&gt;CN&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Basic&lt;/strong&gt; (use your laptop, single RGB head cam)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~$660&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~€680&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~¥3999&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;↑ Stereo dual-eye RGB head cam&lt;/td&gt; 
   &lt;td&gt;+$30&lt;/td&gt; 
   &lt;td&gt;+€30&lt;/td&gt; 
   &lt;td&gt;+¥199&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;+ RasberryPi&lt;/td&gt; 
   &lt;td&gt;+$79&lt;/td&gt; 
   &lt;td&gt;+€79&lt;/td&gt; 
   &lt;td&gt;+¥399&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;↑ RealSense RGBD head cam&lt;/td&gt; 
   &lt;td&gt;+$220&lt;/td&gt; 
   &lt;td&gt;+€230&lt;/td&gt; 
   &lt;td&gt;+¥1499&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h1&gt;📰 News&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2025-08-30: XLeRobot 0.3.0 Release with final outfit touch up and household chores showcase demos. Assembly kit ready for purchase soon, stay tuned!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-30: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Control XLeRobot in real life&lt;/a&gt; with &lt;strong&gt;keyboard/Xbox controller/Switch joycon&lt;/strong&gt; in the wild anywhere. All bluetooth, no wifi needed and zero latency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/de8f50ad-a370-406c-97fb-fc01638d5624" alt="rea" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-08: &lt;a href="https://xlerobot.readthedocs.io/en/latest/simulation/index.html"&gt;&lt;strong&gt;Simulation&lt;/strong&gt;&lt;/a&gt; with updated urdfs, control scripts (support Quest3 VR, keyboard, Xbox controller, switch joycon), support for new hardware and cameras, RL environment. Get started in 15 min.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/68b77bea-fdcf-4f42-9cf0-efcf1b188358" alt="vr" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-01: &lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;&lt;strong&gt;Documentation&lt;/strong&gt; website&lt;/a&gt; out for more orgainized tutorials, demos and resources.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-06-13: &lt;a href="https://xlerobot.readthedocs.io"&gt;&lt;strong&gt;XLeRobot 0.2.0&lt;/strong&gt;&lt;/a&gt; hardware setup, the 1st version fully capable for autonomous household tasks, starts from 660$.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Get Started 🚀&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you are totally new to programming, please spend at least a day to get yourself familiar with basic Python, Ubuntu and Github (with the help of Google and AI). At least you should know how to setup ubuntu system, git clone, pip install, use intepreters (VS Code, Cursor, Pycharm, etc.) and directly run commands in the terminals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;💵 &lt;strong&gt;Buy your parts&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/material.html"&gt;Bill of Materials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🖨️ &lt;strong&gt;Print your stuff&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/3d.html"&gt;3D printing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔨 &lt;del&gt;Avengers&lt;/del&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/assemble.html"&gt;&lt;strong&gt;Assemble&lt;/strong&gt;!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💻 &lt;strong&gt;Software&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Get your robot moving!&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;👋 Want to contribute to XLeRobot?&lt;/strong&gt; Please refer to &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidance on how to get involved!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Main Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lzhuoyi.github.io/Zhuoyi_Lu.github.io/"&gt;Zhuoyi Lu&lt;/a&gt;: RL sim2real deploy, teleop on real robot (Xbox, VR, Joycon)&lt;/li&gt; 
 &lt;li&gt;Nicole Yue: Documentation website setup&lt;/li&gt; 
 &lt;li&gt;Yuesong Wang: Mujoco simulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is just a small brick in the pyramid, made possible by&amp;nbsp;&lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, and&amp;nbsp;&lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;. Thanks to all the talented contributors behind these detailed and professional projects.&lt;/p&gt; 
&lt;p&gt;Looking forward to collaborating with anyone interested in contributing to this project!&lt;/p&gt; 
&lt;h2&gt;About me&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;I am a CS graduate student at Rice University &lt;a href="https://robotpilab.github.io/"&gt;RobotPi Lab&lt;/a&gt;, focusing on robust object manipulation, where we propse virtual cages and funnels and physics-aware world models to close the Sim2real gap and achieve robust manipulation under uncertainties. One of my papers, Caging in Time, has recently been accepted by International Journal of Robotics Research (IJRR).&lt;/p&gt; 
&lt;p&gt;I built XLeRobot as a personal hobby to instantiate my research theory, also to provide a low-cost platform for people who are interested in robotics and embodied AI to work with.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://star-history.com/#Vector-Wangel/XLeRobot&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=Vector-Wangel/XLeRobot&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025xlerobot,
    author = {Wang, Gaotian and Lu, Zhuoyi},
    title = {XLeRobot: A Practical Low-cost Household Dual-Arm Mobile Robot Design for General Manipulation},
    howpublished = "\url{https://github.com/Vector-Wangel/XLeRobot}",
    year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;---&lt;img src="https://github.com/user-attachments/assets/682ef049-bb42-4b50-bf98-74d6311e774d" alt="Generated Image August 27, 2025 - 4_58PM" /&gt;&lt;/p&gt; 
&lt;h2&gt;🪧 Disclaimer 🪧&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you build, buy, or develop a XLeRobot based on this repo, you will be fully responsible for all the physical and mental damages it does to you or others.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Eventual-Inc/Daft</title>
      <link>https://github.com/Eventual-Inc/Daft</link>
      <description>&lt;p&gt;Distributed query engine providing simple and reliable data processing for any modality and scale&lt;/p&gt;&lt;hr&gt;&lt;p&gt;|Banner|&lt;/p&gt; 
&lt;p&gt;|CI| |PyPI| |Latest Tag| |Coverage| |Slack|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Website &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Docs &amp;lt;https://docs.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Installation &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Community and Support &amp;lt;https://github.com/Eventual-Inc/Daft/discussions&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;h1&gt;Daft: Unified Engine for Data Analytics, Engineering &amp;amp; ML/AI&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;Daft &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ is a distributed query engine for large-scale data processing using Python or SQL, implemented in Rust.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar interactive API:&lt;/strong&gt; Lazy Python Dataframe for rapid and interactive iteration, or SQL for analytical queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus on the what:&lt;/strong&gt; Powerful Query Optimizer that rewrites queries to be as efficient as possible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Catalog integrations:&lt;/strong&gt; Full integration with data catalogs such as Apache Iceberg&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich multimodal type-system:&lt;/strong&gt; Supports multimodal types such as Images, URLs, Tensors and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Interchange&lt;/strong&gt;: Built on the &lt;code&gt;Apache Arrow &amp;lt;https://arrow.apache.org/docs/index.html&amp;gt;&lt;/code&gt;_ In-Memory Format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built for the cloud:&lt;/strong&gt; &lt;code&gt;Record-setting &amp;lt;https://www.daft.ai/blog/announcing-daft-02&amp;gt;&lt;/code&gt;_ I/O performance for integrations with S3 cloud storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;About Daft&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Benchmarks&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Contributing&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Telemetry&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Related Projects&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;License&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About Daft&lt;/h2&gt; 
&lt;p&gt;Daft was designed with the following principles in mind:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Any Data&lt;/strong&gt;: Beyond the usual strings/numbers/dates, Daft columns can also hold complex or nested multimodal data such as Images, Embeddings and Python objects efficiently with its Arrow based memory representation. Ingestion and basic transformations of multimodal data is extremely easy and performant in Daft.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Computing&lt;/strong&gt;: Daft is built for the interactive developer experience through notebooks or REPLs - intelligent caching/query optimizations accelerates your experimentation and data exploration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Computing&lt;/strong&gt;: Some workloads can quickly outgrow your local laptop's computational resources - Daft integrates natively with &lt;code&gt;Ray &amp;lt;https://www.ray.io&amp;gt;&lt;/code&gt;_ for running dataframes on large clusters of machines with thousands of CPUs/GPUs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Installation ^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Install Daft with &lt;code&gt;pip install daft&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For more advanced installations (e.g. installing from source or with extra dependencies such as Ray and AWS utilities), please see our &lt;code&gt;Installation Guide &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;Quickstart ^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_!&lt;/p&gt; 
&lt;p&gt;In this example, we load images from an AWS S3 bucket's URLs and resize each image in the dataframe:&lt;/p&gt; 
&lt;p&gt;.. code:: python&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import daft

# Load a dataframe from filepaths in an S3 bucket
df = daft.from_glob_path("s3://daft-public-data/laion-sample-images/*")

# 1. Download column of image URLs as a column of bytes
# 2. Decode the column of bytes into a column of images
df = df.with_column("image", df["path"].url.download().image.decode())

# Resize each image into 32x32
df = df.with_column("resized", df["image"].image.resize(32, 32))

df.show(3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;|Quickstart Image|&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;|Benchmark Image|&lt;/p&gt; 
&lt;p&gt;To see the full benchmarks, detailed setup, and logs, check out our &lt;code&gt;benchmarking page. &amp;lt;https://docs.daft.ai/en/stable/resources/benchmarks/tpch/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;More Resources ^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ - learn more about Daft's full range of capabilities including dataloading from URLs, joins, user-defined functions (UDF), groupby, aggregations and more.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;User Guide &amp;lt;https://docs.daft.ai/en/stable/&amp;gt;&lt;/code&gt;_ - take a deep-dive into each topic within Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API Reference &amp;lt;https://docs.daft.ai/en/stable/api/&amp;gt;&lt;/code&gt;_ - API reference for public classes/functions of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SQL Reference &amp;lt;https://docs.daft.ai/en/stable/sql/&amp;gt;&lt;/code&gt;_ - Daft SQL reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We &amp;lt;3 developers! To start contributing to Daft, please read &lt;code&gt;CONTRIBUTING.md &amp;lt;https://github.com/Eventual-Inc/Daft/blob/main/CONTRIBUTING.md&amp;gt;&lt;/code&gt;_. This document describes the development lifecycle and toolchain for working on Daft. It also details how to add new functionality to the core engine and expose it through a Python API.&lt;/p&gt; 
&lt;p&gt;Here's a list of &lt;code&gt;good first issues &amp;lt;https://github.com/Eventual-Inc/Daft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22&amp;gt;&lt;/code&gt;_ to get yourself warmed up with Daft. Comment in the issue to pick it up, and feel free to ask any questions!&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;To help improve Daft, we collect non-identifiable data via Scarf (&lt;a href="https://scarf.sh"&gt;https://scarf.sh&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;To disable this behavior, set the environment variable &lt;code&gt;DO_NOT_TRACK=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The data that we collect is:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Non-identifiable:&lt;/strong&gt; Events are keyed by a session ID which is generated on import of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata-only:&lt;/strong&gt; We do not collect any of our users’ proprietary code or data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For development only:&lt;/strong&gt; We do not buy or sell any user data&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please see our &lt;code&gt;documentation &amp;lt;https://docs.daft.ai/en/stable/resources/telemetry/&amp;gt;&lt;/code&gt;_ for more details.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6"&gt;https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | Engine | Query Optimizer | Multimodal | Distributed | Arrow Backed | Vectorized Execution Engine | Out-of-core | +===================================================+=================+===============+=============+=================+=============================+=============+ | Daft | Yes | Yes | Yes | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pandas &amp;lt;https://github.com/pandas-dev/pandas&amp;gt;&lt;/code&gt;_ | No | Python object | No | optional &amp;gt;= 2.0 | Some(Numpy) | No | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Polars &amp;lt;https://github.com/pola-rs/polars&amp;gt;&lt;/code&gt;_ | Yes | Python object | No | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Modin &amp;lt;https://github.com/modin-project/modin&amp;gt;&lt;/code&gt;_ | Yes | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pyspark &amp;lt;https://github.com/apache/spark&amp;gt;&lt;/code&gt;_ | Yes | No | Yes | Pandas UDF/IO | Pandas UDF | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Dask DF &amp;lt;https://github.com/dask/dask&amp;gt;&lt;/code&gt;_ | No | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;engine comparison page &amp;lt;https://docs.daft.ai/en/stable/resources/engine_comparison/&amp;gt;&lt;/code&gt;_ for more details!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Daft has an Apache 2.0 license - please see the LICENSE file.&lt;/p&gt; 
&lt;p&gt;.. |Quickstart Image| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8"&gt;https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8&lt;/a&gt; :alt: Dataframe code to load a folder of images from AWS S3 and create thumbnails :height: 256&lt;/p&gt; 
&lt;p&gt;.. |Benchmark Image| image:: &lt;a href="https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png"&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png&lt;/a&gt; :alt: Benchmarks for SF100 TPCH&lt;/p&gt; 
&lt;p&gt;.. |Banner| image:: &lt;a href="https://daft.ai/images/diagram.png"&gt;https://daft.ai/images/diagram.png&lt;/a&gt; :target: &lt;a href="https://www.daft.ai"&gt;https://www.daft.ai&lt;/a&gt; :alt: Daft dataframes can load any data such as PDF documents, images, protobufs, csv, parquet and audio files into a table dataframe structure for easy querying&lt;/p&gt; 
&lt;p&gt;.. |CI| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main&lt;/a&gt; :alt: GitHub Actions tests&lt;/p&gt; 
&lt;p&gt;.. |PyPI| image:: &lt;a href="https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white"&gt;https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/daft"&gt;https://pypi.org/project/daft&lt;/a&gt; :alt: PyPI&lt;/p&gt; 
&lt;p&gt;.. |Latest Tag| image:: &lt;a href="https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub"&gt;https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/tags"&gt;https://github.com/Eventual-Inc/Daft/tags&lt;/a&gt; :alt: latest tag&lt;/p&gt; 
&lt;p&gt;.. |Coverage| image:: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89"&gt;https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89&lt;/a&gt; :target: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft"&gt;https://codecov.io/gh/Eventual-Inc/Daft&lt;/a&gt; :alt: Coverage&lt;/p&gt; 
&lt;p&gt;.. |Slack| image:: &lt;a href="https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack"&gt;https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack&lt;/a&gt; :target: &lt;a href="https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg"&gt;https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg&lt;/a&gt; :alt: slack community&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LadybirdBrowser/ladybird</title>
      <link>https://github.com/LadybirdBrowser/ladybird</link>
      <description>&lt;p&gt;Truly independent web browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ladybird&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://ladybird.org"&gt;Ladybird&lt;/a&gt; is a truly independent web browser, using a novel engine based on web standards.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Ladybird is in a pre-alpha state, and only suitable for use by developers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;We aim to build a complete, usable browser for the modern web.&lt;/p&gt; 
&lt;p&gt;Ladybird uses a multi-process architecture with a main UI process, several WebContent renderer processes, an ImageDecoder process, and a RequestServer process.&lt;/p&gt; 
&lt;p&gt;Image decoding and network connections are done out of process to be more robust against malicious content. Each tab has its own renderer process, which is sandboxed from the rest of the system.&lt;/p&gt; 
&lt;p&gt;At the moment, many core library support components are inherited from SerenityOS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LibWeb: Web rendering engine&lt;/li&gt; 
 &lt;li&gt;LibJS: JavaScript engine&lt;/li&gt; 
 &lt;li&gt;LibWasm: WebAssembly implementation&lt;/li&gt; 
 &lt;li&gt;LibCrypto/LibTLS: Cryptography primitives and Transport Layer Security&lt;/li&gt; 
 &lt;li&gt;LibHTTP: HTTP/1.1 client&lt;/li&gt; 
 &lt;li&gt;LibGfx: 2D Graphics Library, Image Decoding and Rendering&lt;/li&gt; 
 &lt;li&gt;LibUnicode: Unicode and locale support&lt;/li&gt; 
 &lt;li&gt;LibMedia: Audio and video playback&lt;/li&gt; 
 &lt;li&gt;LibCore: Event loop, OS abstraction layer&lt;/li&gt; 
 &lt;li&gt;LibIPC: Inter-process communication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do I build and run this?&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/BuildInstructionsLadybird.md"&gt;build instructions&lt;/a&gt; for information on how to build Ladybird.&lt;/p&gt; 
&lt;p&gt;Ladybird runs on Linux, macOS, Windows (with WSL2), and many other *Nixes.&lt;/p&gt; 
&lt;h2&gt;How do I read the documentation?&lt;/h2&gt; 
&lt;p&gt;Code-related documentation can be found in the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/"&gt;documentation&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Get in touch and participate!&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://discord.gg/nvfjVJ4Svh"&gt;our Discord server&lt;/a&gt; to participate in development discussion.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/Documentation/GettingStartedContributing.md"&gt;Getting started contributing&lt;/a&gt; if you plan to contribute to Ladybird for the first time.&lt;/p&gt; 
&lt;p&gt;Before opening an issue, please see the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md#issue-policy"&gt;issue policy&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/ISSUES.md"&gt;detailed issue-reporting guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The full contribution guidelines can be found in &lt;a href="https://raw.githubusercontent.com/LadybirdBrowser/ladybird/master/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ladybird is licensed under a 2-clause BSD license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stirling-Tools/Stirling-PDF</title>
      <link>https://github.com/Stirling-Tools/Stirling-PDF</link>
      <description>&lt;p&gt;#1 Locally hosted web application that allows you to perform various operations on PDF files&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/docs/stirling.png" width="80" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Stirling-PDF&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/frooodle/s-pdf"&gt;&lt;img src="https://img.shields.io/docker/pulls/frooodle/s-pdf" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HYmhKj45pU"&gt;&lt;img src="https://img.shields.io/discord/1068636748814483718?label=Discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/Stirling-Tools/Stirling-PDF"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/Stirling-Tools/Stirling-PDF/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Stirling-Tools/stirling-pdf"&gt;&lt;img src="https://img.shields.io/github/stars/stirling-tools/stirling-pdf?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/stirling-pdf?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-stirling-pdf" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=641239&amp;amp;theme=light" alt="Stirling PDF - Open source locally hosted web PDF editor | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://cloud.digitalocean.com/apps/new?repo=https://github.com/Stirling-Tools/Stirling-PDF/tree/digitalOcean&amp;amp;refcode=c3210994b1af"&gt;&lt;img src="https://www.deploytodo.com/do-btn-blue.svg?sanitize=true" alt="Deploy to DO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.stirlingpdf.com"&gt;Stirling-PDF&lt;/a&gt; is a robust, locally hosted web-based PDF manipulation tool using Docker. It enables you to carry out various operations on PDF files, including splitting, merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application has evolved to encompass a comprehensive set of features, addressing all your PDF requirements.&lt;/p&gt; 
&lt;p&gt;All files and PDFs exist either exclusively on the client side, reside in server memory only during task execution, or temporarily reside in a file solely for the execution of the task. Any file downloaded by the user will have been deleted from the server by that point.&lt;/p&gt; 
&lt;p&gt;Homepage: &lt;a href="https://stirlingpdf.com"&gt;https://stirlingpdf.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;All documentation available at &lt;a href="https://docs.stirlingpdf.com/"&gt;https://docs.stirlingpdf.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/images/stirling-home.jpg" alt="stirling-home" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;50+ PDF Operations&lt;/li&gt; 
 &lt;li&gt;Parallel file processing and downloads&lt;/li&gt; 
 &lt;li&gt;Dark mode support&lt;/li&gt; 
 &lt;li&gt;Custom download options&lt;/li&gt; 
 &lt;li&gt;Custom 'Pipelines' to run multiple features in a automated queue&lt;/li&gt; 
 &lt;li&gt;API for integration with external scripts&lt;/li&gt; 
 &lt;li&gt;Optional Login and Authentication support (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/System%20and%20Security"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Database Backup and Import (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/DATABASE"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Enterprise features like SSO (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/Single%20Sign-On%20Configuration"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PDF Features&lt;/h2&gt; 
&lt;h3&gt;Page Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;View and modify PDFs - View multi-page PDFs with custom viewing, sorting, and searching. Plus, on-page edit features like annotating, drawing, and adding text and images. (Using PDF.js with Joxit and Liberation fonts)&lt;/li&gt; 
 &lt;li&gt;Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages&lt;/li&gt; 
 &lt;li&gt;Merge multiple PDFs into a single resultant file&lt;/li&gt; 
 &lt;li&gt;Split PDFs into multiple files at specified page numbers or extract all pages as individual files&lt;/li&gt; 
 &lt;li&gt;Reorganize PDF pages into different orders&lt;/li&gt; 
 &lt;li&gt;Rotate PDFs in 90-degree increments&lt;/li&gt; 
 &lt;li&gt;Remove pages&lt;/li&gt; 
 &lt;li&gt;Multi-page layout (format PDFs into a multi-paged page)&lt;/li&gt; 
 &lt;li&gt;Scale page contents size by set percentage&lt;/li&gt; 
 &lt;li&gt;Adjust contrast&lt;/li&gt; 
 &lt;li&gt;Crop PDF&lt;/li&gt; 
 &lt;li&gt;Auto-split PDF (with physically scanned page dividers)&lt;/li&gt; 
 &lt;li&gt;Extract page(s)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Overlay PDFs on top of each other&lt;/li&gt; 
 &lt;li&gt;PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Split PDF by sections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Conversion Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert PDFs to and from images&lt;/li&gt; 
 &lt;li&gt;Convert any common file to PDF (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to Word/PowerPoint/others (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert HTML to PDF&lt;/li&gt; 
 &lt;li&gt;Convert PDF to XML&lt;/li&gt; 
 &lt;li&gt;Convert PDF to CSV&lt;/li&gt; 
 &lt;li&gt;URL to PDF&lt;/li&gt; 
 &lt;li&gt;Markdown to PDF&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security &amp;amp; Permissions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add and remove passwords&lt;/li&gt; 
 &lt;li&gt;Change/set PDF permissions&lt;/li&gt; 
 &lt;li&gt;Add watermark(s)&lt;/li&gt; 
 &lt;li&gt;Certify/sign PDFs&lt;/li&gt; 
 &lt;li&gt;Sanitize PDFs&lt;/li&gt; 
 &lt;li&gt;Auto-redact text&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/generate/write signatures&lt;/li&gt; 
 &lt;li&gt;Split by Size or PDF&lt;/li&gt; 
 &lt;li&gt;Repair PDFs&lt;/li&gt; 
 &lt;li&gt;Detect and remove blank pages&lt;/li&gt; 
 &lt;li&gt;Compare two PDFs and show differences in text&lt;/li&gt; 
 &lt;li&gt;Add images to PDFs&lt;/li&gt; 
 &lt;li&gt;Compress PDFs to decrease their filesize (using qpdf)&lt;/li&gt; 
 &lt;li&gt;Extract images from PDF&lt;/li&gt; 
 &lt;li&gt;Remove images from PDF&lt;/li&gt; 
 &lt;li&gt;Extract images from scans&lt;/li&gt; 
 &lt;li&gt;Remove annotations&lt;/li&gt; 
 &lt;li&gt;Add page numbers&lt;/li&gt; 
 &lt;li&gt;Auto-rename files by detecting PDF header text&lt;/li&gt; 
 &lt;li&gt;OCR on PDF (using Tesseract OCR)&lt;/li&gt; 
 &lt;li&gt;PDF/A conversion (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Edit metadata&lt;/li&gt; 
 &lt;li&gt;Flatten PDFs&lt;/li&gt; 
 &lt;li&gt;Get all information on a PDF to view or export as JSON&lt;/li&gt; 
 &lt;li&gt;Show/detect embedded JavaScript&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📖 Get Started&lt;/h1&gt; 
&lt;p&gt;Visit our comprehensive documentation at &lt;a href="https://docs.stirlingpdf.com"&gt;docs.stirlingpdf.com&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation guides for all platforms&lt;/li&gt; 
 &lt;li&gt;Configuration options&lt;/li&gt; 
 &lt;li&gt;Feature documentation&lt;/li&gt; 
 &lt;li&gt;API reference&lt;/li&gt; 
 &lt;li&gt;Security setup&lt;/li&gt; 
 &lt;li&gt;Enterprise features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Stirling-PDF currently supports 40 languages!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Progress&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arabic (العربية) (ar_AR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azerbaijani (Azərbaycan Dili) (az_AZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Basque (Euskara) (eu_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/36" alt="36%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bulgarian (Български) (bg_BG)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Catalan (Català) (ca_CA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Croatian (Hrvatski) (hr_HR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Czech (Česky) (cs_CZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/69" alt="69%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Danish (Dansk) (da_DK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dutch (Nederlands) (nl_NL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (English) (en_GB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (US) (en_US)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French (Français) (fr_FR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;German (Deutsch) (de_DE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/97" alt="97%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Greek (Ελληνικά) (el_GR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hindi (हिंदी) (hi_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hungarian (Magyar) (hu_HU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indonesian (Bahasa Indonesia) (id_ID)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Irish (Gaeilge) (ga_IE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Italian (Italiano) (it_IT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/98" alt="98%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Japanese (日本語) (ja_JP)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/92" alt="92%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Korean (한국어) (ko_KR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Norwegian (Norsk) (no_NB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/66" alt="66%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Persian (فارسی) (fa_IR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/64" alt="64%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Polish (Polski) (pl_PL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/72" alt="72%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese (Português) (pt_PT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese Brazilian (Português) (pt_BR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/76" alt="76%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Romanian (Română) (ro_RO)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Russian (Русский) (ru_RU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Serbian Latin alphabet (Srpski) (sr_LATN_RS)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/94" alt="94%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Simplified Chinese (简体中文) (zh_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/93" alt="93%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovakian (Slovensky) (sk_SK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/51" alt="51%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovenian (Slovenščina) (sl_SI)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/71" alt="71%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Spanish (Español) (es_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/74" alt="74%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Swedish (Svenska) (sv_SE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Thai (ไทย) (th_TH)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/59" alt="59%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tibetan (བོད་ཡིག་) (bo_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional Chinese (繁體中文) (zh_TW)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Turkish (Türkçe) (tr_TR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ukrainian (Українська) (uk_UA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/70" alt="70%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vietnamese (Tiếng Việt) (vi_VN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Malayalam (മലയാളം) (ml_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/73" alt="73%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Stirling PDF Enterprise&lt;/h2&gt; 
&lt;p&gt;Stirling PDF offers an Enterprise edition of its software. This is the same great software but with added features, support and comforts. Check out our &lt;a href="https://docs.stirlingpdf.com/Pro"&gt;Enterprise docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 Looking to contribute?&lt;/h2&gt; 
&lt;p&gt;Join our community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/HowToAddNewLanguage.md"&gt;Translation Guide (How to add custom languages)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/DeveloperGuide.md"&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stirling-Tools/Stirling-PDF/issues"&gt;Issue Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/HYmhKj45pU"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>henrygd/beszel</title>
      <link>https://github.com/henrygd/beszel</link>
      <description>&lt;p&gt;Lightweight server monitoring hub with historical data, docker stats, and alerts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Beszel&lt;/h1&gt; 
&lt;p&gt;Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.&lt;/p&gt; 
&lt;p&gt;It has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/henrygd/beszel-agent"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&amp;amp;label=agent%20image%20size" alt="agent Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/henrygd/beszel"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&amp;amp;label=hub%20image%20size" alt="hub Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/henrygd/beszel/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/henrygd/beszel?color=%239944ee" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/beszel"&gt;&lt;img src="https://badges.crowdin.net/beszel/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png" alt="Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system." /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Smaller and less resource-intensive than leading solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy setup with little manual configuration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker stats&lt;/strong&gt;: Tracks CPU, memory, and network usage history for each container.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;: Users manage their own systems. Admins can share systems across users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OAuth / OIDC&lt;/strong&gt;: Supports many OAuth2 providers. Password auth can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic backups&lt;/strong&gt;: Save to and restore from disk or S3-compatible storage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - **REST API**: Use or update your data in your own scripts and applications. --&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Beszel consists of two main components: the &lt;strong&gt;hub&lt;/strong&gt; and the &lt;strong&gt;agent&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hub&lt;/strong&gt;: A web application built on &lt;a href="https://pocketbase.io/"&gt;PocketBase&lt;/a&gt; that provides a dashboard for viewing and managing connected systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: Runs on each system you want to monitor and communicates system metrics to the hub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://beszel.dev/guide/getting-started"&gt;quick start guide&lt;/a&gt; and other documentation is available on our website, &lt;a href="https://beszel.dev"&gt;beszel.dev&lt;/a&gt;. You'll be up and running in a few minutes.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://beszel.dev/image/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://beszel.dev/image/system-full.png" alt="System page" /&gt; &lt;img src="https://beszel.dev/image/settings-notifications.png" alt="Notification Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;Supported metrics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU usage&lt;/strong&gt; - Host system and Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory usage&lt;/strong&gt; - Host system and containers. Includes swap and ZFS ARC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk usage&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk I/O&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network usage&lt;/strong&gt; - Host system and containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Load average&lt;/strong&gt; - Host system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; - Host system sensors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU usage / temperature / power draw&lt;/strong&gt; - Nvidia and AMD only. Must use binary agent.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt; - Host system battery charge.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Help and discussion&lt;/h2&gt; 
&lt;p&gt;Please search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.&lt;/p&gt; 
&lt;h4&gt;Bug reports and feature requests&lt;/h4&gt; 
&lt;p&gt;Bug reports and detailed feature requests should be posted on &lt;a href="https://github.com/henrygd/beszel/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Support and general discussion&lt;/h4&gt; 
&lt;p&gt;Support requests and general discussion can be posted on &lt;a href="https://github.com/henrygd/beszel/discussions"&gt;GitHub discussions&lt;/a&gt; or the community-run &lt;a href="https://matrix.to/#/#beszel:matrix.org"&gt;Matrix room&lt;/a&gt;: &lt;code&gt;#beszel:matrix.org&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Beszel is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/henrygd/beszel/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ossu/computer-science</title>
      <link>https://github.com/ossu/computer-science</link>
      <description>&lt;p&gt;🎓 Path to a free self-taught education in Computer Science!&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-align: center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/ossu/computer-science/master/images/ossu-logo.webp" alt="Open Source Society logo" /&gt; 
 &lt;h3&gt;Open Source Society University&lt;/h3&gt; 
 &lt;p&gt; Path to a free self-taught education in Computer Science! &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://github.com/sindresorhus/awesome"&gt; &lt;img alt="Awesome" src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ossu/computer-science"&gt; &lt;img alt="Open Source Society University - Computer Science" src="https://img.shields.io/badge/OSSU-computer--science-blue.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#curriculum"&gt;Curriculum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#code-of-conduct"&gt;Code of conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#team"&gt;Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Summary&lt;/h1&gt; 
&lt;p&gt;The OSSU curriculum is a &lt;strong&gt;complete education in computer science&lt;/strong&gt; using online materials. It's not merely for career training or professional development. It's for those who want a proper, &lt;em&gt;well-rounded&lt;/em&gt; grounding in concepts fundamental to all computing disciplines, and for those who have the discipline, will, and (most importantly!) good habits to obtain this education largely on their own, but with support from a worldwide community of fellow learners.&lt;/p&gt; 
&lt;p&gt;It is designed according to the degree requirements of undergraduate computer science majors, minus general education (non-CS) requirements, as it is assumed most of the people following this curriculum are already educated outside the field of CS. The courses themselves are among the very best in the world, often coming from Harvard, Princeton, MIT, etc., but specifically chosen to meet the following criteria.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Courses must&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Be open for enrollment&lt;/li&gt; 
 &lt;li&gt;Run regularly (ideally in self-paced format, otherwise running multiple times per year)&lt;/li&gt; 
 &lt;li&gt;Be of generally high quality in teaching materials and pedagogical principles&lt;/li&gt; 
 &lt;li&gt;Match the curricular standards of the &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/CURRICULAR_GUIDELINES.md"&gt;CS 2013&lt;/a&gt;: Curriculum Guidelines for Undergraduate Degree Programs in Computer Science&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When no course meets the above criteria, the coursework is supplemented with a book. When there are courses or books that don't fit into the curriculum but are otherwise of high quality, they belong in &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/extras/courses.md"&gt;extras/courses&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/extras/readings.md"&gt;extras/readings&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Organization&lt;/strong&gt;. The curriculum is designed as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Intro CS&lt;/em&gt;: for students to try out CS and see if it's right for them&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Core CS&lt;/em&gt;: corresponds roughly to the first three years of a computer science curriculum, taking classes that all majors would be required to take&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Advanced CS&lt;/em&gt;: corresponds roughly to the final year of a computer science curriculum, taking electives according to the student's interests&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Final Project&lt;/em&gt;: a project for students to validate, consolidate, and display their knowledge, to be evaluated by their peers worldwide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Duration&lt;/strong&gt;. It is possible to finish within about 2 years if you plan carefully and devote roughly 20 hours/week to your studies. Learners can use &lt;a href="https://docs.google.com/spreadsheets/u/3/d/1Std_G_5dnajzm289vlsthIJPFnuxN5yOYNDOoiz9Juc/copy"&gt;this spreadsheet&lt;/a&gt; to estimate their end date. Make a copy and input your start date and expected hours per week in the &lt;code&gt;Timeline&lt;/code&gt; sheet. As you work through courses you can enter your actual course completion dates in the &lt;code&gt;Curriculum Data&lt;/code&gt; sheet and get updated completion estimates.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; While the spreadsheet is a useful tool to estimate the time you need to complete this curriculum, it may not always be up-to-date with the curriculum. Use the &lt;a href="https://cs.ossu.dev"&gt;OSSU CS website&lt;/a&gt; or &lt;a href="https://github.com/ossu/computer-science"&gt;the repo&lt;/a&gt; to see what courses to do.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Cost&lt;/strong&gt;. All or nearly all course material is available for free. However, some courses may charge money for assignments/tests/projects to be graded. Note that both &lt;a href="https://www.coursera.support/s/article/209819033-Apply-for-Financial-Aid-or-a-Scholarship?language=en_US"&gt;Coursera&lt;/a&gt; and &lt;a href="https://courses.edx.org/financial-assistance/"&gt;edX&lt;/a&gt; offer financial aid.&lt;/p&gt; 
&lt;p&gt;Decide how much or how little to spend based on your own time and budget; just remember that you can't purchase success!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt;. Students can work through the curriculum alone or in groups, in order or out of order.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We recommend doing all courses in Core CS, only skipping a course when you are certain that you've already learned the material previously.&lt;/li&gt; 
 &lt;li&gt;For simplicity, we recommend working through courses (especially Core CS) in order from top to bottom. Some students choose to study multiple courses at a time in order to vary the material they are working on in a day/week. A popular option is to take the math courses in parallel with the introductory courses. Course prerequisites are listed to help you determine if you are prepared for a given course.&lt;/li&gt; 
 &lt;li&gt;Courses in Advanced CS are electives. Choose one subject (e.g. Advanced programming) you want to become an expert in and take all the courses under that heading. You can also create your own custom subject; the Discord community may provide feedback on your planned subject.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Content policy&lt;/strong&gt;. If you plan on showing off some of your coursework publicly, you must share only files that you are allowed to. &lt;em&gt;Respect the code of conduct&lt;/em&gt; that you signed in the beginning of each course!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/CONTRIBUTING.md"&gt;How to contribute&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/HELP.md"&gt;Getting help&lt;/a&gt;&lt;/strong&gt; (Details about our FAQ and chatroom)&lt;/p&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;We have a Discord server! &lt;a href="https://discord.gg/wuytwK5s9h"&gt;&lt;img src="https://img.shields.io/discord/744385009028431943.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord" /&gt;&lt;/a&gt; This should be your first stop to talk with other OSSU students. Why don't you introduce yourself right now? &lt;a href="https://discord.gg/wuytwK5s9h"&gt;Join the OSSU Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;You can also interact through GitHub issues. If there is a problem with a course, or a change needs to be made to the curriculum, this is the place to start the conversation. Read more &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add &lt;strong&gt;Open Source Society University&lt;/strong&gt; to your &lt;a href="https://www.linkedin.com/school/11272443/"&gt;Linkedin&lt;/a&gt; profile!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; There are a few third-party/deprecated/outdated material that you might find when searching for OSSU. We recommend you to ignore them, and only use the &lt;a href="https://cs.ossu.dev"&gt;OSSU CS website&lt;/a&gt; or &lt;a href="https://github.com/ossu/computer-science"&gt;OSSU CS Github Repo&lt;/a&gt;. Some known outdated materials are:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An unmaintained and deprecated firebase app. Read more in the &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/FAQ.md#why-is-the-firebase-ossu-app-different-or-broken"&gt;FAQ&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;An unmaintained and deprecated trello board&lt;/li&gt; 
  &lt;li&gt;Third-party notion templates&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Curriculum&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#intro-cs"&gt;Intro CS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-cs"&gt;Core CS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-programming"&gt;Core programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-math"&gt;Core math&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#cs-tools"&gt;CS Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-systems"&gt;Core systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-theory"&gt;Core theory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-security"&gt;Core security&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-applications"&gt;Core applications&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-ethics"&gt;Core ethics&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-cs"&gt;Advanced CS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-programming"&gt;Advanced programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-systems"&gt;Advanced systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-theory"&gt;Advanced theory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-information-security"&gt;Advanced information security&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-math"&gt;Advanced math&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#final-project"&gt;Final project&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#core-cs"&gt;Core CS&lt;/a&gt; assumes the student has already taken &lt;a href="https://ossu.dev/precollege-math"&gt;high school math&lt;/a&gt;, including algebra, geometry, and pre-calculus.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-cs"&gt;Advanced CS&lt;/a&gt; assumes the student has already taken the entirety of Core CS and is knowledgeable enough now to decide which electives to take.&lt;/li&gt; 
 &lt;li&gt;Note that &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/#advanced-systems"&gt;Advanced systems&lt;/a&gt; assumes the student has taken a basic physics course (e.g. AP Physics in high school).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Intro CS&lt;/h2&gt; 
&lt;p&gt;This course will introduce you to the world of computer science and programming. This course gives you a flavor of the material to come. If you finish the course wanting more, Computer Science is likely for you!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;computation&lt;/code&gt; &lt;code&gt;imperative programming&lt;/code&gt; &lt;code&gt;basic data structures and algorithms&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/coursepages/intro-cs/README.md"&gt;Introduction to Computer Science and Programming using Python&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;14 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://ossu.dev/precollege-math"&gt;high school algebra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/jvchSm9"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Core CS&lt;/h2&gt; 
&lt;p&gt;All coursework under Core CS is &lt;strong&gt;required&lt;/strong&gt;, unless otherwise indicated.&lt;/p&gt; 
&lt;h3&gt;Core programming&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;functional programming&lt;/code&gt; &lt;code&gt;design for testing&lt;/code&gt; &lt;code&gt;program requirements&lt;/code&gt; &lt;code&gt;common design patterns&lt;/code&gt; &lt;code&gt;unit testing&lt;/code&gt; &lt;code&gt;object-oriented design&lt;/code&gt; &lt;code&gt;static typing&lt;/code&gt; &lt;code&gt;dynamic typing&lt;/code&gt; &lt;code&gt;ML-family languages (via Standard ML)&lt;/code&gt; &lt;code&gt;Lisp-family languages (via Racket)&lt;/code&gt; &lt;code&gt;Ruby&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/coursepages/spd/README.md"&gt;Systematic Program Design&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;8-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
   &lt;td align="center"&gt;chat: &lt;a href="https://discord.gg/RfqAmGJ"&gt;part 1&lt;/a&gt; / &lt;a href="https://discord.gg/kczJzpm"&gt;part 2&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://course.ccs.neu.edu/cs2510sp22/index.html"&gt;Class-based Program Design&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Systematic Program Design, High School Math&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.com/channels/744385009028431943/891411727294562314"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://courses.cs.washington.edu/courses/cse341/19au/#lectures"&gt;Programming Languages&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;11 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Systematic Program Design&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/8BkJtXN"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://course.ccs.neu.edu/cs3500f19/"&gt;Object-Oriented Design&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Class Based Program Design&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.com/channels/744385009028431943/891412022120579103"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/software-architecture"&gt;Software Architecture&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Object Oriented Design&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.com/channels/744385009028431943/891412169638432788"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core math&lt;/h3&gt; 
&lt;p&gt;Discrete math (Math for CS) is a prerequisite and closely related to the study of algorithms and data structures. Calculus both prepares students for discrete math and helps students develop mathematical maturity.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;discrete mathematics&lt;/code&gt; &lt;code&gt;mathematical proofs&lt;/code&gt; &lt;code&gt;basic statistics&lt;/code&gt; &lt;code&gt;O-notation&lt;/code&gt; &lt;code&gt;discrete probability&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Notes&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openlearninglibrary.mit.edu/courses/course-v1:MITx+18.01.1x+2T2019/about"&gt;Calculus 1A: Differentiation&lt;/a&gt; (&lt;a href="https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/index.htm"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;The alternate covers this and the following 2 courses&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://ossu.dev/precollege-math"&gt;high school math&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/mPCt45F"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openlearninglibrary.mit.edu/courses/course-v1:MITx+18.01.2x+3T2019/about"&gt;Calculus 1B: Integration&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;Calculus 1A&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/sddAsZg"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openlearninglibrary.mit.edu/courses/course-v1:MITx+18.01.3x+1T2020/about"&gt;Calculus 1C: Coordinate Systems &amp;amp; Infinite Series&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;6 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;Calculus 1B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/FNEcNNq"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about"&gt;Mathematics for Computer Science&lt;/a&gt; (&lt;a href="https://ocw.mit.edu/courses/6-042j-mathematics-for-computer-science-fall-2010/"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/spamegg1/Math-for-CS-solutions"&gt;2015/2019 solutions&lt;/a&gt; &lt;a href="https://github.com/frevib/mit-cs-math-6042-fall-2010-problems"&gt;2010 solutions&lt;/a&gt; &lt;a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2005/assignments/"&gt;2005 solutions&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="center"&gt;Calculus 1C&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/EuTzNbF"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;CS Tools&lt;/h3&gt; 
&lt;p&gt;Understanding theory is important, but you will also be expected to create programs. There are a number of tools that are widely used to make that process easier. Learn them now to ease your future work writing programs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;terminals and shell scripting&lt;/code&gt; &lt;code&gt;vim&lt;/code&gt; &lt;code&gt;command line environments&lt;/code&gt; &lt;code&gt;version control&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://missing.csail.mit.edu/"&gt;The Missing Semester of Your CS Education&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;2 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/5FvKycS"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core systems&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;procedural programming&lt;/code&gt; &lt;code&gt;manual memory management&lt;/code&gt; &lt;code&gt;boolean algebra&lt;/code&gt; &lt;code&gt;gate logic&lt;/code&gt; &lt;code&gt;memory&lt;/code&gt; &lt;code&gt;computer architecture&lt;/code&gt; &lt;code&gt;assembly&lt;/code&gt; &lt;code&gt;machine language&lt;/code&gt; &lt;code&gt;virtual machines&lt;/code&gt; &lt;code&gt;high-level languages&lt;/code&gt; &lt;code&gt;compilers&lt;/code&gt; &lt;code&gt;operating systems&lt;/code&gt; &lt;code&gt;network protocols&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Additional Text / Assignments&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/build-a-computer"&gt;Build a Modern Computer from First Principles: From Nand to Tetris&lt;/a&gt; (&lt;a href="https://www.nand2tetris.org/"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;6 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;7-13 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;C-like programming language&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/vxB2DRV"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/nand2tetris2"&gt;Build a Modern Computer from First Principles: Nand to Tetris Part II &lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;6 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;12-18 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;one of &lt;a href="https://user-images.githubusercontent.com/2046800/35426340-f6ce6358-026a-11e8-8bbb-4e95ac36b1d7.png"&gt;these programming languages&lt;/a&gt;, From Nand to Tetris Part I&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/AsUXcPu"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/coursepages/ostep/README.md"&gt;Operating Systems: Three Easy Pieces&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;10-12 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;Nand to Tetris Part II&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/wZNgpep"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="http://gaia.cs.umass.edu/kurose_ross/online_lectures.htm"&gt;Computer Networking: a Top-Down Approach&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;8 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4–12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="http://gaia.cs.umass.edu/kurose_ross/wireshark.php"&gt;Wireshark Labs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;algebra, probability, basic CS&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/MJ9YXyV"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core theory&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;divide and conquer&lt;/code&gt; &lt;code&gt;sorting and searching&lt;/code&gt; &lt;code&gt;randomized algorithms&lt;/code&gt; &lt;code&gt;graph search&lt;/code&gt; &lt;code&gt;shortest paths&lt;/code&gt; &lt;code&gt;data structures&lt;/code&gt; &lt;code&gt;greedy algorithms&lt;/code&gt; &lt;code&gt;minimum spanning trees&lt;/code&gt; &lt;code&gt;dynamic programming&lt;/code&gt; &lt;code&gt;NP-completeness&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/algorithms-divide-conquer"&gt;Divide and Conquer, Sorting and Searching, and Randomized Algorithms&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;any programming language, Mathematics for Computer Science&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/mKRS7tY"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/algorithms-graphs-data-structures"&gt;Graph Search, Shortest Paths, and Data Structures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Divide and Conquer, Sorting and Searching, and Randomized Algorithms&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/Qstqe4t"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/algorithms-greedy"&gt;Greedy Algorithms, Minimum Spanning Trees, and Dynamic Programming&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Graph Search, Shortest Paths, and Data Structures&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/dWVvjuz"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/algorithms-npcomplete"&gt;Shortest Paths Revisited, NP-Complete Problems and What To Do About Them&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Greedy Algorithms, Minimum Spanning Trees, and Dynamic Programming&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/dYuY78u"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core security&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt; &lt;code&gt;Confidentiality, Integrity, Availability&lt;/code&gt; &lt;code&gt;Secure Design&lt;/code&gt; &lt;code&gt;Defensive Programming&lt;/code&gt; &lt;code&gt;Threats and Attacks&lt;/code&gt; &lt;code&gt;Network Security&lt;/code&gt; &lt;code&gt;Cryptography&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/cybersecurity/rochester-institute-of-technology-cybersecurity-fundamentals"&gt;Cybersecurity Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;8 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;10-12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/XdY3AwTFK4"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/secure-coding-principles"&gt;Principles of Secure Coding&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/5gMdeSK"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/identifying-security-vulnerabilities"&gt;Identifying Security Vulnerabilities&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/V78MjUS"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Choose &lt;strong&gt;one&lt;/strong&gt; of the following:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/identifying-security-vulnerabilities-c-programming"&gt;Identifying Security Vulnerabilities in C/C++Programming&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/Vbxce7A"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/exploiting-securing-vulnerabilities-java-applications"&gt;Exploiting and Securing Vulnerabilities in Java Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/QxC22rR"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core applications&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;Agile methodology&lt;/code&gt; &lt;code&gt;REST&lt;/code&gt; &lt;code&gt;software specifications&lt;/code&gt; &lt;code&gt;refactoring&lt;/code&gt; &lt;code&gt;relational databases&lt;/code&gt; &lt;code&gt;transaction processing&lt;/code&gt; &lt;code&gt;data modeling&lt;/code&gt; &lt;code&gt;neural networks&lt;/code&gt; &lt;code&gt;supervised learning&lt;/code&gt; &lt;code&gt;unsupervised learning&lt;/code&gt; &lt;code&gt;OpenGL&lt;/code&gt; &lt;code&gt;ray tracing&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/databases/stanford-university-databases-modeling-and-theory"&gt;Databases: Modeling and Theory&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;2 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;core programming&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/pMFqNf4"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/relational-databases/stanford-university-databases-relational-databases-and-sql"&gt;Databases: Relational Databases and SQL&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;2 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;core programming&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/P8SPPyF"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/relational-databases/stanford-university-databases-semistructured-data"&gt;Databases: Semistructured Data&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;2 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;core programming&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/duCJ3GN"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/machine-learning-introduction"&gt;Machine Learning&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;11 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;9 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Basic coding&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/NcXHDjy"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/computer-graphics/the-university-of-california-san-diego-computer-graphics"&gt;Computer Graphics&lt;/a&gt; (&lt;a href="https://cseweb.ucsd.edu/~viscomp/classes/cse167/wi22/schedule.html"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;6 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;C++ or Java, &lt;a href="https://ossu.dev/precollege-math/coursepages/precalculus"&gt;Basic Linear Algebra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/68WqMNV"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/software-engineering/university-of-british-columbia-software-engineering-introduction"&gt;Software Engineering: Introduction&lt;/a&gt; (&lt;a href="https://github.com/ubccpsc/310/raw/main/resources/README.md"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;6 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;8-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Core Programming, and a &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/FAQ.md#why-require-experience-with-a-sizable-project-before-the-Software-Engineering-courses"&gt;sizable project&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/5Qtcwtz"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core ethics&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;Social Context&lt;/code&gt; &lt;code&gt;Analytical Tools&lt;/code&gt; &lt;code&gt;Professional Ethics&lt;/code&gt; &lt;code&gt;Intellectual Property&lt;/code&gt; &lt;code&gt;Privacy and Civil Liberties&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/ethics-technology-engineering"&gt;Ethics, Technology and Engineering&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;9 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/6ttjPmzZbe"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/introduction-intellectual-property"&gt;Introduction to Intellectual Property&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/YbuERswpAK"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/northeastern-data-privacy"&gt;Data Privacy Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;3 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;3 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/64J34ajNBd"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Advanced CS&lt;/h2&gt; 
&lt;p&gt;After completing &lt;strong&gt;every required course&lt;/strong&gt; in Core CS, students should choose a subset of courses from Advanced CS based on interest. Not every course from a subcategory needs to be taken. But students should take &lt;em&gt;every&lt;/em&gt; course that is relevant to the field they intend to go into.&lt;/p&gt; 
&lt;h3&gt;Advanced programming&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;debugging theory and practice&lt;/code&gt; &lt;code&gt;goal-oriented programming&lt;/code&gt; &lt;code&gt;parallel computing&lt;/code&gt; &lt;code&gt;object-oriented analysis and design&lt;/code&gt; &lt;code&gt;UML&lt;/code&gt; &lt;code&gt;large-scale software architecture and design&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/scala-parallel-programming"&gt;Parallel Programming&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Scala programming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/computer-science/stanford-university-compilers"&gt;Compilers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;9 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.seas.upenn.edu/~cis194/fall16/"&gt;Introduction to Haskell&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;14 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.let.rug.nl/bos/lpn//lpnpage.php?pageid=online"&gt;Learn Prolog Now!&lt;/a&gt; (&lt;a href="https://github.com/ossu/computer-science/files/6085884/lpn.pdf"&gt;alternative&lt;/a&gt;)*&lt;/td&gt; 
   &lt;td align="center"&gt;12 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.youtube.com/playlist?list=PLAwxTw4SYaPkxK63TiT88oEe-AIBhr96A"&gt;Software Debugging&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;8 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Python, object-oriented programming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.youtube.com/playlist?list=PLAwxTw4SYaPkWVHeC_8aSIbSxE_NXI76g"&gt;Software Testing&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;4 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Python, programming experience&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;(*) book by Blackburn, Bos, Striegnitz (compiled from &lt;a href="https://github.com/LearnPrologNow/lpn"&gt;source&lt;/a&gt;, redistributed under &lt;a href="https://creativecommons.org/licenses/by-sa/4.0/"&gt;CC license&lt;/a&gt;)&lt;/p&gt; 
&lt;h3&gt;Advanced systems&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;digital signaling&lt;/code&gt; &lt;code&gt;combinational logic&lt;/code&gt; &lt;code&gt;CMOS technologies&lt;/code&gt; &lt;code&gt;sequential logic&lt;/code&gt; &lt;code&gt;finite state machines&lt;/code&gt; &lt;code&gt;processor instruction sets&lt;/code&gt; &lt;code&gt;caches&lt;/code&gt; &lt;code&gt;pipelining&lt;/code&gt; &lt;code&gt;virtualization&lt;/code&gt; &lt;code&gt;parallel processing&lt;/code&gt; &lt;code&gt;virtual memory&lt;/code&gt; &lt;code&gt;synchronization primitives&lt;/code&gt; &lt;code&gt;system call interface&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://learning.edx.org/course/course-v1:MITx+6.004.1x_3+3T2016"&gt;Computation Structures 1: Digital Circuits&lt;/a&gt; &lt;a href="https://ocw.mit.edu/courses/6-004-computation-structures-spring-2017/"&gt;alternative 1&lt;/a&gt; &lt;a href="https://ocw.mit.edu/courses/6-004-computation-structures-spring-2009/"&gt;alternative 2&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;10 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://www.coursera.org/learn/nand2tetris2"&gt;Nand2Tetris II&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;Alternate links contain all 3 courses.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://learning.edx.org/course/course-v1:MITx+6.004.2x+3T2015"&gt;Computation Structures 2: Computer Architecture&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;10 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Computation Structures 1&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://learning.edx.org/course/course-v1:MITx+6.004.3x_2+1T2017"&gt;Computation Structures 3: Computer Organization&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;10 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Computation Structures 2&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Advanced theory&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Topics covered&lt;/strong&gt;: &lt;code&gt;formal languages&lt;/code&gt; &lt;code&gt;Turing machines&lt;/code&gt; &lt;code&gt;computability&lt;/code&gt; &lt;code&gt;event-driven concurrency&lt;/code&gt; &lt;code&gt;automata&lt;/code&gt; &lt;code&gt;distributed shared memory&lt;/code&gt; &lt;code&gt;consensus algorithms&lt;/code&gt; &lt;code&gt;state machine replication&lt;/code&gt; &lt;code&gt;computational geometry theory&lt;/code&gt; &lt;code&gt;propositional logic&lt;/code&gt; &lt;code&gt;relational logic&lt;/code&gt; &lt;code&gt;Herbrand logic&lt;/code&gt; &lt;code&gt;game trees&lt;/code&gt; &lt;code&gt;and more&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ocw.mit.edu/courses/18-404j-theory-of-computation-fall-2020/"&gt;Theory of Computation&lt;/a&gt; (&lt;a href="https://www.youtube.com/playlist?list=PLEE7DF8F5E0203A56"&gt;alternative&lt;/a&gt;)&lt;/td&gt; 
   &lt;td align="center"&gt;13 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about"&gt;Mathematics for Computer Science&lt;/a&gt;, logic, algorithms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/geometry/tsinghua-university-ji-suan-ji-he-computational-geometry"&gt;Computational Geometry&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;16 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;algorithms, C++&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/game-theory-1"&gt;Game Theory&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;8 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;3 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;mathematical thinking, probability, calculus&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Advanced Information Security&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/computer-security/ku-leuven-web-security-fundamentals"&gt;Web Security Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;5 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;understanding basic web technologies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/security-governance-compliance"&gt;Security Governance &amp;amp; Compliance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;3 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;3 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/learn/digital-forensics-concepts"&gt;Digital Forensics Concepts&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;3 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2-3 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Core Security&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/software-development/the-linux-foundation-secure-software-development-requirements-design-and-reuse"&gt;Secure Software Development: Requirements, Design, and Reuse&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;7 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;1-2 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Core Programming and Core Security&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/software-development/the-linux-foundation-secure-software-development-implementation"&gt;Secure Software Development: Implementation&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;7 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;1-2 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Secure Software Development: Requirements, Design, and Reuse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.edx.org/learn/software-engineering/the-linux-foundation-secure-software-development-verification-and-more-specialized-topics"&gt;Secure Software Development: Verification and More Specialized Topics&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;7 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;1-2 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;Secure Software Development: Implementation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Advanced math&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
   &lt;th align="center"&gt;Discussion&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;Essence of Linear Algebra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;-&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://ossu.dev/precollege-math"&gt;high school math&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/m6wHbP6"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/"&gt;Linear Algebra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;14 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;corequisite: Essence of Linear Algebra&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/k7nSWJH"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-335j-introduction-to-numerical-methods-spring-2019/index.htm"&gt;Introduction to Numerical Methods&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;14 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;12 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/"&gt;Linear Algebra&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/FNEcNNq"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://forallx.openlogicproject.org/"&gt;Introduction to Formal Logic&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;10 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-8 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://www.youtube.com/playlist?list=PL5KkMZvBpo5AH_5GpxMiryJT6Dkj32H6N"&gt;Set Theory&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/MbM2Gg5"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://stat110.hsites.harvard.edu/"&gt;Probability&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;15 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;5-10 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://www.edx.org/course/calculus-1b-integration"&gt;Differentiation and Integration&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://discord.gg/UVjs9BU"&gt;chat&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Final project&lt;/h2&gt; 
&lt;p&gt;Part of learning is doing. The assignments and exams for each course are to prepare you to use your knowledge to solve real-world problems.&lt;/p&gt; 
&lt;p&gt;After you've completed Core CS and the parts of Advanced CS relevant to you, you should identify a problem that you can solve using the knowledge you've acquired. You can create something entirely new, or you can improve some tool/program that you use and wish were better.&lt;/p&gt; 
&lt;p&gt;Students who would like more guidance in creating a project may choose to use a series of project oriented courses. Here is a sample of options (many more are available, at this point you should be capable of identifying a series that is interesting and relevant to you):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Courses&lt;/th&gt; 
   &lt;th align="center"&gt;Duration&lt;/th&gt; 
   &lt;th align="center"&gt;Effort&lt;/th&gt; 
   &lt;th align="center"&gt;Prerequisites&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://fullstackopen.com/en/"&gt;Fullstack Open&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;12 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;15 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;programming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/modernrobotics"&gt;Modern Robotics (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;26 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;freshman-level physics, linear algebra, calculus, &lt;a href="https://www.khanacademy.org/math/differential-equations"&gt;linear ordinary differential equations&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/data-mining"&gt;Data Mining (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;machine learning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/big-data"&gt;Big Data (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;3-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/internet-of-things"&gt;Internet of Things (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;1-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;strong programming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/cloud-computing"&gt;Cloud Computing (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;2-6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;C++ programming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/jhu-data-science"&gt;Data Science (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;43 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;1-6 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;none&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/scala"&gt;Functional Programming in Scala (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;29 weeks&lt;/td&gt; 
   &lt;td align="center"&gt;4-5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;One year programming experience&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coursera.org/specializations/game-design-and-development"&gt;Game Design and Development with Unity 2020 (Specialization)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;6 months&lt;/td&gt; 
   &lt;td align="center"&gt;5 hours/week&lt;/td&gt; 
   &lt;td align="center"&gt;programming, interactive design&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Congratulations&lt;/h2&gt; 
&lt;p&gt;After completing the requirements of the curriculum above, you will have completed the equivalent of a full bachelor's degree in Computer Science. Congratulations!&lt;/p&gt; 
&lt;p&gt;What is next for you? The possibilities are boundless and overlapping:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for a job as a developer!&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/ossu/computer-science/master/extras/readings.md"&gt;readings&lt;/a&gt; for classic books you can read that will sharpen your skills and expand your knowledge.&lt;/li&gt; 
 &lt;li&gt;Join a local developer meetup (e.g. via &lt;a href="https://www.meetup.com/"&gt;meetup.com&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Pay attention to emerging technologies in the world of software development: 
  &lt;ul&gt; 
   &lt;li&gt;Explore the &lt;strong&gt;actor model&lt;/strong&gt; through &lt;a href="https://elixir-lang.org/"&gt;Elixir&lt;/a&gt;, a new functional programming language for the web based on the battle-tested Erlang Virtual Machine!&lt;/li&gt; 
   &lt;li&gt;Explore &lt;strong&gt;borrowing and lifetimes&lt;/strong&gt; through &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, a systems language which achieves memory- and thread-safety without a garbage collector!&lt;/li&gt; 
   &lt;li&gt;Explore &lt;strong&gt;dependent type systems&lt;/strong&gt; through &lt;a href="https://www.idris-lang.org/"&gt;Idris&lt;/a&gt;, a new Haskell-inspired language with unprecedented support for type-driven development.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ossu/computer-science/master/images/keep-learning.webp" alt="keep learning" /&gt;&lt;/p&gt; 
&lt;h1&gt;Code of conduct&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/ossu/code-of-conduct"&gt;OSSU's code of conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How to show your progress&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.freecodecamp.org/news/how-to-fork-a-github-repository/"&gt;Fork&lt;/a&gt; the &lt;a href="https://github.com/ossu/computer-science"&gt;GitHub repo&lt;/a&gt; into your own GitHub account and put ✅ next to the stuff you've completed as you complete it. This can serve as your &lt;a href="https://en.wikipedia.org/wiki/Kanban_board"&gt;kanban board&lt;/a&gt; and will be faster to implement than any other solution (giving you time to spend on the courses).&lt;/p&gt; 
&lt;h1&gt;Team&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ericdouglas"&gt;Eric Douglas&lt;/a&gt;&lt;/strong&gt;: founder of OSSU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/joshmhanson"&gt;Josh Hanson&lt;/a&gt;&lt;/strong&gt;: lead technical maintainer&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/waciumawanjohi"&gt;Waciuma Wanjohi&lt;/a&gt;&lt;/strong&gt;: lead academic maintainer&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ossu/computer-science/graphs/contributors"&gt;Contributors&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>FIRST-Tech-Challenge/FtcRobotController</title>
      <link>https://github.com/FIRST-Tech-Challenge/FtcRobotController</link>
      <description>&lt;p&gt;FTC Android Studio Workspace for robot programming in Android Studio&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;NOTICE&lt;/h2&gt; 
&lt;p&gt;This repository contains the public FTC SDK for the DECODE (2025-2026) competition season.&lt;/p&gt; 
&lt;h2&gt;Welcome!&lt;/h2&gt; 
&lt;p&gt;This GitHub repository contains the source code that is used to build an Android app to control a &lt;em&gt;FIRST&lt;/em&gt; Tech Challenge competition robot. To use this SDK, download/clone the entire project to your local computer.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;To use this Android Studio project, you will need Android Studio Ladybug (2024.2) or later.&lt;/p&gt; 
&lt;p&gt;To program your robot in Blocks or OnBot Java, you do not need Android Studio.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you are new to robotics or new to the &lt;em&gt;FIRST&lt;/em&gt; Tech Challenge, then you should consider reviewing the &lt;a href="https://ftc-docs.firstinspires.org/programming_resources/blocks/Blocks-Tutorial.html"&gt;FTC Blocks Tutorial&lt;/a&gt; to get familiar with how to use the control system:&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://ftc-docs.firstinspires.org/programming_resources/blocks/Blocks-Tutorial.html"&gt;FTC Blocks Online Tutorial&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Even if you are an advanced Java programmer, it is helpful to start with the &lt;a href="https://ftc-docs.firstinspires.org/programming_resources/blocks/Blocks-Tutorial.html"&gt;FTC Blocks tutorial&lt;/a&gt;, and then migrate to the &lt;a href="https://ftc-docs.firstinspires.org/programming_resources/onbot_java/OnBot-Java-Tutorial.html"&gt;OnBot Java Tool&lt;/a&gt; or to &lt;a href="https://ftc-docs.firstinspires.org/programming_resources/android_studio_java/Android-Studio-Tutorial.html"&gt;Android Studio&lt;/a&gt; afterwards.&lt;/p&gt; 
&lt;h2&gt;Downloading the Project&lt;/h2&gt; 
&lt;p&gt;If you are an Android Studio programmer, there are several ways to download this repo. Note that if you use the Blocks or OnBot Java Tool to program your robot, then you do not need to download this repository.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are a git user, you can clone the most current version of the repository:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;git clone https://github.com/FIRST-Tech-Challenge/FtcRobotController.git&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Or, if you prefer, you can use the "Download Zip" button available through the main repository page. Downloading the project as a .ZIP file will keep the size of the download manageable.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can also download the project folder (as a .zip or .tar.gz archive file) from the Downloads subsection of the &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/releases"&gt;Releases&lt;/a&gt; page for this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The Releases page also contains prebuilt APKs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once you have downloaded and uncompressed (if needed) your folder, you can use Android Studio to import the folder ("Import project (Eclipse ADT, Gradle, etc.)").&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;h3&gt;User Documentation and Tutorials&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;FIRST&lt;/em&gt; maintains online documentation with information and tutorials on how to use the &lt;em&gt;FIRST&lt;/em&gt; Tech Challenge software and robot control system. You can access this documentation using the following link:&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://ftc-docs.firstinspires.org/index.html"&gt;FIRST Tech Challenge Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Note that the online documentation is an "evergreen" document that is constantly being updated and edited. It contains the most current information about the &lt;em&gt;FIRST&lt;/em&gt; Tech Challenge software and control system.&lt;/p&gt; 
&lt;h3&gt;Javadoc Reference Material&lt;/h3&gt; 
&lt;p&gt;The Javadoc reference documentation for the FTC SDK is now available online. Click on the following link to view the FTC SDK Javadoc documentation as a live website:&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://javadoc.io/doc/org.firstinspires.ftc"&gt;FTC Javadoc Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Online User Forum&lt;/h3&gt; 
&lt;p&gt;For technical questions regarding the Control System or the FTC SDK, please visit the FIRST Tech Challenge Community site:&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://ftc-community.firstinspires.org/"&gt;FIRST Tech Challenge Community&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Sample OpModes&lt;/h3&gt; 
&lt;p&gt;This project contains a large selection of Sample OpModes (robot code examples) which can be cut and pasted into your /teamcode folder to be used as-is, or modified to suit your team's needs.&lt;/p&gt; 
&lt;p&gt;Samples Folder: &amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples"&gt;/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The readme.md file located in the &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/TeamCode/src/main/java/org/firstinspires/ftc/teamcode"&gt;/TeamCode/src/main/java/org/firstinspires/ftc/teamcode&lt;/a&gt; folder contains an explanation of the sample naming convention, and instructions on how to copy them to your own project space.&lt;/p&gt; 
&lt;h1&gt;Release Information&lt;/h1&gt; 
&lt;h2&gt;Version 11.0 (20250827-105138)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;OnBotJava now has the concept of a project.&lt;br /&gt; A project is a collection of related files. A project may be chosen by selecting 'Example Project' from the 'File type:' dropdown. Doing so will populate the dropdown to the immediate right with a list of projects to choose from. When selecting a project all of the related files appear in the left pane of the workspace underneath a directory with the chosen project name. This is useful for example for ConceptExternalHardwareClass which has a dependency upon RobotHardware. This feature simplifies the usage of this Concept example by automatically pulling in dependent classes.&lt;/li&gt; 
 &lt;li&gt;Adds support for AndyMark ToF, IMU, and Color sensors.&lt;/li&gt; 
 &lt;li&gt;The Driver Station app indicates if WiFi is disabled on the device.&lt;/li&gt; 
 &lt;li&gt;Adds several features to the Color Processing software: 
  &lt;ul&gt; 
   &lt;li&gt;DECODE colors &lt;code&gt;ARTIFACT_GREEN&lt;/code&gt; and &lt;code&gt;ARTIFACT_PURPLE&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Choice of the order of pre-processing steps Erode and Dilate&lt;/li&gt; 
   &lt;li&gt;Best-fit preview shape called &lt;code&gt;circleFit&lt;/code&gt;, an alternate to the existing &lt;code&gt;boxFit&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Sample OpMode &lt;code&gt;ConceptVisionColorLocator_Circle&lt;/code&gt;, an alternate to the renamed &lt;code&gt;ConceptVisionColorLocator_Rectangle&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The Driver Station app play button has a green background with a white play symbol if 
  &lt;ul&gt; 
   &lt;li&gt;the driver station and robot controller are connected and have the same team number&lt;/li&gt; 
   &lt;li&gt;there is at least one gamepad attached&lt;/li&gt; 
   &lt;li&gt;the timer is enabled (for an Autonomous OpMode)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updated AprilTag Library for DECODE. Notably, getCurrentGameTagLibrary() now returns DECODE tags. 
  &lt;ul&gt; 
   &lt;li&gt;Since the AprilTags on the Obelisk should not be used for localization, the ConceptAprilTagLocalization samples only use those tags without the name 'Obelisk' in them.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;OctoQuad I2C driver updated to support firmware v3.x 
  &lt;ul&gt; 
   &lt;li&gt;Adds support for odometry localizer on MK2 hardware revision&lt;/li&gt; 
   &lt;li&gt;Adds ability to track position for an absolute encoder across multiple rotations&lt;/li&gt; 
   &lt;li&gt;Note that some driver APIs have changed; minor updates to user software may be required&lt;/li&gt; 
   &lt;li&gt;Requires firmware v3.x. For instructions on updating firmware, see &lt;a href="https://github.com/DigitalChickenLabs/OctoQuad/raw/master/documentation/OctoQuadDatasheet_Rev_3.0C.pdf"&gt;https://github.com/DigitalChickenLabs/OctoQuad/blob/master/documentation/OctoQuadDatasheet_Rev_3.0C.pdf&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 10.3 (20250625-090416)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The behavior of setGlobalErrorMsg() is changed. Note that this is an SDK internal method that is not meant to be used by team software or third party libraries. Teams or libraries using this method should find another means to communicate failure. The design intent of setGlobalErrorMsg() is to report an error and force the user to restart the robot, which in certain circumstances when used inappropriately could cause a robot to continue running while Driver Station controls are disabled. To prevent this, processing of a call to setGlobalErrorMsg() is deferred until the robot is in a known safe state. This may mean that a call to setGlobalErrorMsg() that does not also result in stopping a running OpMode will appear as though nothing happened until the robot is stopped, at which point, if clearGlobalErrorMsg() has not been called the message will appear on the Driver Station and a restart will be required. Addresses issue &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1381"&gt;1381&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes getLatestResult in Limelight3A so if the Limelight hasn't provided data yet, it still returns an LLResult but valid will be false 
  &lt;ul&gt; 
   &lt;li&gt;If you previously used to check and see if this was &lt;code&gt;null&lt;/code&gt; to see if the Limelight had been contacted, you now need to use &lt;code&gt;isValid()&lt;/code&gt; on the result. That is because now it always returns an LLResult even before it talks to the Limelight, but if it doesn't have valid data, the &lt;code&gt;isValid()&lt;/code&gt; will be &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Changed all omni samples to use front_left_drive, front_right_drive, back_left_drive, back_right_drive 
  &lt;ul&gt; 
   &lt;li&gt;This is only breaking for you if you copy one of the changed samples to your own project and expect to use the same robot configuration as before.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Known Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The redesigned OnBotJava new file workflow allows the user to use a lowercase letter as the first character of a filename. This is a regression from 10.2 which required the first character to be uppercase. Software will build, but if the user tries to rename the file, the rename will fail.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Improved the OBJ new file creation flow workflow. The new flow allows you to easily use samples, craft new custom OpModes and make new Java classes.&lt;/li&gt; 
 &lt;li&gt;Added support for gamepad edge detection. 
  &lt;ul&gt; 
   &lt;li&gt;A new sample program &lt;code&gt;ConceptGamepadEdgeDetection&lt;/code&gt; demonstrates its use.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds a blackboard member to the Opmode that maintains state between opmodes (but not between robot resets). See the ConceptBlackboard sample for how to use it.&lt;/li&gt; 
 &lt;li&gt;Updated PredominantColorProcessor to also return the predominant color in RGB, HSV and YCrCb color spaces. Updated ConceptVisionColorSensor sample OpMode to display the getAnalysis() result in all three color spaces.&lt;/li&gt; 
 &lt;li&gt;Adds support for the GoBilda Pinpoint 
  &lt;ul&gt; 
   &lt;li&gt;Also adds &lt;code&gt;SensorGoBildaPinpoint&lt;/code&gt; sample to show how to use it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;getArcLength()&lt;/code&gt; and &lt;code&gt;getCircularity()&lt;/code&gt; to ColorBlobLocatorProcessor.Blob. Added BY_ARC_LENGTH and BY_CIRCULARITY as additional BlobCriteria.&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;filterByCriteria()&lt;/code&gt; and &lt;code&gt;sortByCriteria()&lt;/code&gt; to ColorBlobLocatorProcessor.Util. 
  &lt;ul&gt; 
   &lt;li&gt;The filter and sort methods for specific criteria have been deprecated.&lt;/li&gt; 
   &lt;li&gt;The updated sample program &lt;code&gt;ConceptVisionColorLocator&lt;/code&gt; provides more details on the new syntax.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Add Help menu item and Help page that is available when connected to the robot controller via Program and Manage. The Help page has links to team resources such as &lt;a href="https://ftc-docs.firstinspires.org/"&gt;FTC Documentation&lt;/a&gt;, &lt;a href="https://ftc-community.firstinspires.org"&gt;FTC Discussion Forums&lt;/a&gt;, &lt;a href="https://javadoc.io/doc/org.firstinspires.ftc"&gt;Java FTC SDK API Documentation&lt;/a&gt;, and &lt;a href="https://ftc.game/"&gt;FTC Game Information&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Self inspection changes: 
  &lt;ul&gt; 
   &lt;li&gt;List both the Driver Station Name and Robot Controller Name when inspecting the Driver Station.&lt;/li&gt; 
   &lt;li&gt;Report if the team number portion of the device names do not match.&lt;/li&gt; 
   &lt;li&gt;-rc is no longer valid as part of a Robot Controller name, must be -RC.&lt;/li&gt; 
   &lt;li&gt;Use Robot Controller Name or Driver Station Name labels on the inspection screens instead of WIFI Access Point or WIFI Direct Name.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes issue &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1478"&gt;1478&lt;/a&gt; in AnnotatedHooksClassFilter that ignored exceptions if they occur in one of the SDK app hooks.&lt;/li&gt; 
 &lt;li&gt;Fix initialize in distance sensor (Rev 2m) to prevent bad data in first call to getDistance.&lt;/li&gt; 
 &lt;li&gt;Fixes issue &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1470"&gt;1470&lt;/a&gt; Scaling a servo range is now irrespective of reverse() being called. For example, if you set the scale range to [0.0, 0.5] and the servo is reversed, it will be from 0.5 to 0.0, NOT 1.0 to 0.5.&lt;/li&gt; 
 &lt;li&gt;Fixes issue &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1232"&gt;1232&lt;/a&gt;, a rare race condition where using the log rapidly along with other telemetry could cause a crash.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 10.2 (20250121-174034)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add ability to upload the pipeline for Limelight3A which allows teams to version control their limelight pipelines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix an internal bug where if the RUN_TO_POSITION run mode was specified before a target position, recovery would require a power cycle. A side effect of this fix is that a stack trace identifying the location of the error is always produced in the log. Fixes issue &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1345"&gt;1345&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Throws a helpful exception if region of interest is set to null when building a PredominantColorProcessor. Also sets the default RoI to the full frame. Addresses issue &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FIRST-Tech-Challenge/FtcRobotController#1076"&gt;1076&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Throws a helpful exception if user tries to construct an ImageRegion with malformed boundaries. Addresses issue &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FIRST-Tech-Challenge/FtcRobotController#1078"&gt;1078&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 10.1.1 (20241102-092223)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for Android Studio Ladybug. Requires Android Studio Ladybug.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Known Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Android Studio Ladybug's bundled JDK is version 21. JDK 21 has deprecated support for Java 1.8, and Ladybug will warn on this deprecation. OnBotJava only supports Java 1.8, therefore, in order to ensure that software developed using Android Studio will run within the OnBotJava environment, the targetCompatibility and sourceCompatibility versions for the SDK have been left at VERSION_1_8. FIRST has decided that until it can devote the resources to migrating OnBotJava to a newer version of Java, the deprecation is the lesser of two non-optimal situations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added &lt;code&gt;toString()&lt;/code&gt; method to Pose2D&lt;/li&gt; 
 &lt;li&gt;Added &lt;code&gt;toString()&lt;/code&gt; method to SparkFunOTOS.Pose2D&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 10.1 (20240919-122750)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds new OpenCV-based &lt;code&gt;VisionProcessor&lt;/code&gt;s (which may be attached to a VisionPortal in either Java or Blocks) to help teams implement color processing via computer vision in the INTO THE DEEP game 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ColorBlobLocatorProcessor&lt;/code&gt; implements OpenCV color "blob" detection. A new sample program &lt;code&gt;ConceptVisionColorLocator&lt;/code&gt; demonstrates its use. 
    &lt;ul&gt; 
     &lt;li&gt;A choice is offered between pre-defined color ranges, or creating a custom one in RGB, HSV, or YCrCb color space&lt;/li&gt; 
     &lt;li&gt;The ability is provided to restrict detection to a specified Region of Interest on the screen&lt;/li&gt; 
     &lt;li&gt;Functions for applying erosion / dilation morphing to the threshold mask are provided&lt;/li&gt; 
     &lt;li&gt;Functions for sorting and filtering the returned data are provided&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;PredominantColorProcessor&lt;/code&gt; allows using a region of the camera as a "long range color sensor" to determine the predominant color of that region. A new sample program &lt;code&gt;ConceptVisionColorSensor&lt;/code&gt; demonstrates its use. 
    &lt;ul&gt; 
     &lt;li&gt;The determined predominant color is selected from a discrete set of color "swatches", similar to the MINDSTORMS NXT color sensor&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Documentation on this Color Processing feature can be found here: &lt;a href="https://ftc-docs.firstinspires.org/color-processing"&gt;https://ftc-docs.firstinspires.org/color-processing&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Added Blocks sample programs for color sensors: RobotAutoDriveToLine and SensorColor.&lt;/li&gt; 
 &lt;li&gt;Updated Self-Inspect to identify mismatched RC/DS software versions as a "caution" rather than a "failure."&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/1070"&gt;AngularVelocity conversion regression&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 10.0 (20240828-111152)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java classes and Blocks for TensorFlow Object Detection have been removed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AngularVelocity.unit&lt;/code&gt; which was of type &lt;code&gt;AngleUnit&lt;/code&gt; has been renamed &lt;code&gt;AngularVelocity.angleUnit&lt;/code&gt; of type &lt;code&gt;UnnormalizedAngleUnit&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sample for REV Digital Indicator has been added - ConceptRevLED&lt;/li&gt; 
 &lt;li&gt;Adds support for the &lt;a href="https://www.sparkfun.com/products/18354"&gt;Sparkfun QWIIC LED Stick&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;To connect it directly, you need this &lt;a href="https://www.sparkfun.com/products/25596"&gt;cable&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds ConceptLEDStick OpMode&lt;/li&gt; 
 &lt;li&gt;Adds Blocks for colors black, blue, cyan, dkgray, gray, green, ltgray, magenta, red, white, and yellow.&lt;/li&gt; 
 &lt;li&gt;Adds an "evaluate but ignore result" Block that executes the connected block and ignores the result. Allows you to call a function and ignore the return value.&lt;/li&gt; 
 &lt;li&gt;Adds I2C driver for Maxbotix Maxsonar I2CXL sonar rangefinder&lt;/li&gt; 
 &lt;li&gt;Adds Blocks for setPwmEnable, setPwmDisable, and isPwmEnabled for servos and CR servos.&lt;/li&gt; 
 &lt;li&gt;In the Blocks editor: a \n in the ExportToBlocks annotation's comment field is displayed as a line break.&lt;/li&gt; 
 &lt;li&gt;Telemetry has new method setNumDecimalPlaces&lt;/li&gt; 
 &lt;li&gt;Telemetry now formats doubles and floats (not inside objects, just by themselves)&lt;/li&gt; 
 &lt;li&gt;Adds support for the Limelight 3A.&lt;/li&gt; 
 &lt;li&gt;Adds initial support for the REV Servo Hub 
  &lt;ul&gt; 
   &lt;li&gt;Both the Robot Controller and Driver Station need to be updated to version 10.0 in order for Servo Hubs to be configurable as Servo Hubs. If the app on either device is outdated, the Servo Hub will show up as an Expansion Hub, and some functionality will not work as expected. You should wait to create a configuration that includes a Servo Hub until both the Driver Station and Robot Controller apps have been updated to version 10.0.&lt;/li&gt; 
   &lt;li&gt;Updating the Servo Hub's firmware and changing its address can only be done using the REV Hardware Client at this time&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for the REV 9-Axis IMU (REV-31-3332) 
  &lt;ul&gt; 
   &lt;li&gt;The REV 9-Axis IMU is only supported by the &lt;a href="https://ftc-docs.firstinspires.org/en/latest/programming_resources/imu/imu.html"&gt;Universal IMU interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Adds &lt;code&gt;Rev9AxisImuOrientationOnRobot&lt;/code&gt; Java class.&lt;/li&gt; 
   &lt;li&gt;If you mentally substitute this IMU's I2C port for the Control Hub's USB ports, &lt;code&gt;RevHubOrientationOnRobot&lt;/code&gt; is also compatible with this sensor&lt;/li&gt; 
   &lt;li&gt;Adds Blocks for Rev9AxisImuOrientationOnRobot, including RevHubImuOrientationOnRobot.xyzOrientation and RevHubImuOrientationOnRobot.zyxOrientation.&lt;/li&gt; 
   &lt;li&gt;Adds Blocks samples SensorRev9AxisIMUOrthogonal and SensorRev9AxisIMUNonOrthogonal.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves Blocks support for RevHubImuOrientationOnRobot. 
  &lt;ul&gt; 
   &lt;li&gt;Adds Blocks for RevHubImuOrientationOnRobot.xyzOrientation and RevHubImuOrientationOnRobot.zyxOrientation.&lt;/li&gt; 
   &lt;li&gt;Adds Blocks samples SensorHubIMUOrthogonal (replaces SensorIMU) and SensorHubIMUNonOrthogonal.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updates EasyOpenCV, AprilTag, OpenCV, and &lt;code&gt;libjpeg-turbo&lt;/code&gt; versions&lt;/li&gt; 
 &lt;li&gt;Adds Blocks for max and min that take two numbers.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks OpModes ConceptRevSPARKMini, RobotAutoDriveByEncoder, RobotAutoDriveByGyro, RobotAutoDriveByTime, RobotAutoDriveToAprilTagOmni, and RobotAutoDriveToAprilTagTank.&lt;/li&gt; 
 &lt;li&gt;Two OpModes with the same name now automatically get renamed with the name followed by a "-" and the class name allowing them to both be on the device.&lt;/li&gt; 
 &lt;li&gt;Shows the name of the active configuration on the Manage page of the Robot Controller Console&lt;/li&gt; 
 &lt;li&gt;Updated AprilTag Library for INTO THE DEEP. Notably, &lt;code&gt;getCurrentGameTagLibrary()&lt;/code&gt; now returns INTO THE DEEP tags.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks for Telemetry.setMsTransmissionInterval and Telemetry.getMsTransmissionInterval.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks sample SensorOctoQuad.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes a bug where the RevBlinkinLedDriver Blocks were under Actuators in the Blocks editor toolbox. They are now Other Devices.&lt;/li&gt; 
 &lt;li&gt;Fixes a bug where &lt;code&gt;Exception&lt;/code&gt;s thrown in user code after a stop was requested by the Driver Station would be silently eaten&lt;/li&gt; 
 &lt;li&gt;Fixed a bug where if you asked for &lt;code&gt;AngularVelocity&lt;/code&gt; in a unit different than the device reported it in, it would normalize it between -PI and PI for radians, and -180 and 180 for degrees.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 9.2 (20240701-085519)&lt;/h2&gt; 
&lt;h3&gt;Important Notes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Java classes and Blocks for TensorFlow Object Detection have been deprecated and will be removed in Version 10.0.&lt;/li&gt; 
 &lt;li&gt;The samples that use TensorFlow Object Detection have been removed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds explanatory text to failed items on the inspection activities. To view the explanatory text tap the red warning icon for a failed item.&lt;/li&gt; 
 &lt;li&gt;In the Blocks editor: added a new kind of variable set block that sets the variable and also returns the new value.&lt;/li&gt; 
 &lt;li&gt;Changes the way that camera controls behave for a SwitchableCamera. Now, each method (such as getExposure, getMinExposure, getMaxExposure, setExposure for ExposureControl) acts on the currently active camera.&lt;/li&gt; 
 &lt;li&gt;Adds support for the REV USB PS4 Compatible Gamepad (REV-31-2983)&lt;/li&gt; 
 &lt;li&gt;Adds ConceptAprilTagMultiPortal OpMode&lt;/li&gt; 
 &lt;li&gt;Adds support for OctoQuad Quadrature Encoder &amp;amp; Pulse Width Interface Module&lt;/li&gt; 
 &lt;li&gt;Adds the ExportAprilTagLibraryToBlocks annotation that indicates that a static method that returns an AprilTagLibrary is exported to the Blocks programming environment. The corresponding block will appear in the Blocks toolbox along with the built-in tag libraries.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks OpMode ConceptAprilTagOptimizeExposure.&lt;/li&gt; 
 &lt;li&gt;Adds support for the SparkFun Optical Tracking Odometry sensor.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/942"&gt;https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/942&lt;/a&gt; where visionPortal.close() can cause an IndexOutOfBoundsError.&lt;/li&gt; 
 &lt;li&gt;Fixes a bug in the blocks editor where collapsed function blocks show a warning "Collapsed blocks contain warnings." when the Blocks OpMode is reopened.&lt;/li&gt; 
 &lt;li&gt;Fixes a bug where the blocks editor wouldn't warn you that you have unsaved changes when you try to leave. This bug was introduced due to a behavior change in Chrome 119.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/764"&gt;Issue #764&lt;/a&gt; - Get gain control returns a null pointer for a switchable camera&lt;/li&gt; 
 &lt;li&gt;Fixes a bug where the correct deadzone for certain gamepads was not applied when Advanced Gamepad Features was enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 9.1 (20240215-115542)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes a problem with Blocks: if the user closes a Block's warning balloon, it will still be closed next time the project is opened in the Blocks editor.&lt;/li&gt; 
 &lt;li&gt;In the Blocks editor, an alert concerning missing hardware devices is not shown if all the Blocks that use the missing hardware devices are disabled.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks to support comparing property values CRServo.Direction, DCMotor.Direction, DCMotor.Mode, DCMotor.ZeroPowerBehavior, DigitalChannel.Mode, GyroSensor.HeadingMode, IrSeekerSensor.Mode, and Servo.Direction, to the corresponding enum Block.&lt;/li&gt; 
 &lt;li&gt;Improves OnBotJava auto-import to correctly import classes when used in certain situations.&lt;/li&gt; 
 &lt;li&gt;Improves OnBotJava autocomplete to provide better completion options in most cases. 
  &lt;ul&gt; 
   &lt;li&gt;This fixes an issue where autocomplete would fail if a method with two or more formal parameters was defined.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;In OnBotJava, code folding support was added to expand and collapse code sections&lt;/li&gt; 
 &lt;li&gt;In OnBotJava, the copyright header is now automatically collapsed loading new files&lt;/li&gt; 
 &lt;li&gt;For all Blocks OpMode samples, intro comments have been moved to the RunOpMode comment balloon.&lt;/li&gt; 
 &lt;li&gt;The Clean up Blocks command in the Blocks editor now positions function Blocks so their comment balloons don't overlap other function Blocks.&lt;/li&gt; 
 &lt;li&gt;Added Blocks OpMode sample SensorTouch.&lt;/li&gt; 
 &lt;li&gt;Added Java OpMode sample SensorDigitalTouch.&lt;/li&gt; 
 &lt;li&gt;Several improvements to VisionPortal 
  &lt;ul&gt; 
   &lt;li&gt;Adds option to control whether the stream is automatically started following a &lt;code&gt;.build()&lt;/code&gt; call on a VisionPortal Builder&lt;/li&gt; 
   &lt;li&gt;Adds option to control whether the vision processing statistics overlay is rendered or not&lt;/li&gt; 
   &lt;li&gt;VisionPortals now implement the &lt;code&gt;CameraStreamSource&lt;/code&gt; interface, allowing multiportal users to select which portal is routed to the DS in INIT by calling CameraStreamServer.getInstance().setSource(visionPortal). Can be selected via gamepad, between Camera Stream sessions.&lt;/li&gt; 
   &lt;li&gt;Add option to &lt;code&gt;AprilTagProcessor&lt;/code&gt; to suppress calibration warnings&lt;/li&gt; 
   &lt;li&gt;Improves camera calibration warnings 
    &lt;ul&gt; 
     &lt;li&gt;If a calibration is scaled, the resolution it was scaled from will be listed&lt;/li&gt; 
     &lt;li&gt;If calibrations exist with the wrong aspect ratio, the calibrated resolutions will be listed&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Fixes race condition which caused app crash when calling &lt;code&gt;stopStreaming()&lt;/code&gt; immediately followed by &lt;code&gt;close()&lt;/code&gt; on a VisionPortal&lt;/li&gt; 
   &lt;li&gt;Fixes IllegalStateException when calling &lt;code&gt;stopStreaming()&lt;/code&gt; immediately after building a VisionPortal&lt;/li&gt; 
   &lt;li&gt;Added FTC Blocks counterparts to new Java methods: 
    &lt;ul&gt; 
     &lt;li&gt;VisionPortal.Builder.setAutoStartStreamOnBuild&lt;/li&gt; 
     &lt;li&gt;VisionPortal.Builder.setShowStatsOverlay&lt;/li&gt; 
     &lt;li&gt;AprilTagProcessor.Builder.setSuppressCalibrationWarnings&lt;/li&gt; 
     &lt;li&gt;CameraStreamServer.setSource​&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes a problem where OnBotJava does not apply font size settings to the editor.&lt;/li&gt; 
 &lt;li&gt;Updates EasyOpenCV dependency to v1.7.1 
  &lt;ul&gt; 
   &lt;li&gt;Fixes inability to use EasyOpenCV CameraFactory in OnBotJava&lt;/li&gt; 
   &lt;li&gt;Fixes entire RC app crash when user pipeline throws an exception&lt;/li&gt; 
   &lt;li&gt;Fixes entire RC app crash when user user canvas annotator throws an exception&lt;/li&gt; 
   &lt;li&gt;Use the modern stacktrace display when handling user exceptions instead of the legacy ESTOP telemetry message&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 9.0.1 (20230929-083754)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updates AprilTag samples to include Decimation and additional Comments. Also corrects misleading tag ID warnings&lt;/li&gt; 
 &lt;li&gt;Increases maximum size of Blocks inline comments to 140 characters&lt;/li&gt; 
 &lt;li&gt;Adds Blocks sample BasicOmniOpMode.&lt;/li&gt; 
 &lt;li&gt;Updated CENTERSTAGE library AprilTag orientation quaternions 
  &lt;ul&gt; 
   &lt;li&gt;Thanks &lt;a href="https://github.com/FromenActual"&gt;@FromenActual&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updated Java Sample ConceptTensorFlowObjectDetection.java to include missing elements needed for custom model support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes a problem where after October 1 the Driver Station will report as obsolete on v9.0 and prompt the user to update.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 9.0 (20230830-154348)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Removes Vuforia&lt;/li&gt; 
 &lt;li&gt;Fields in &lt;code&gt;AprilTagDetection&lt;/code&gt; and &lt;code&gt;AprilTagPose(ftc/raw)&lt;/code&gt; objects are now &lt;code&gt;final&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;VisionPortal builder method &lt;code&gt;setCameraMonitorViewId()&lt;/code&gt; has been renamed to &lt;code&gt;setLiveViewContainerId()&lt;/code&gt; and &lt;code&gt;enableCameraMonitoring()&lt;/code&gt; has been renamed to &lt;code&gt;enableLiveView()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds support for the DFRobot HuskyLens Vision Sensor.&lt;/li&gt; 
 &lt;li&gt;Blocks teams can now perform webcam calibration. 
  &lt;ul&gt; 
   &lt;li&gt;Added a Block for System.currentTimeMillis (under Utilities/Time)&lt;/li&gt; 
   &lt;li&gt;Added a Block for VisionPortal.saveNextFrameRaw (under Vision/VisionPortal)&lt;/li&gt; 
   &lt;li&gt;Added a new sample Blocks OpMode called UtilityCameraFrameCapture.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The RobotDriveByGyro sample has been updated to use the new universal IMU interface. It now supports both IMU types.&lt;/li&gt; 
 &lt;li&gt;Removed some error-prone ElapsedTime Blocks from the Blocks editor's toolbox. This is not a breaking change: old Blocks OpModes that use these Blocks will still function, both in the Blocks editor and at runtime.&lt;/li&gt; 
 &lt;li&gt;Standardizes on the form "OpMode" for the term OpMode. 
  &lt;ul&gt; 
   &lt;li&gt;The preferred way to refer to OpModes that specifically extend &lt;code&gt;LinearOpMode&lt;/code&gt; (including Blocks OpModes) is "linear OpMode".&lt;/li&gt; 
   &lt;li&gt;The preferred way to refer to OpModes that specifically extend &lt;code&gt;OpMode&lt;/code&gt; directly is "iterative OpMode".&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Overhauls &lt;code&gt;OpMode&lt;/code&gt; and &lt;code&gt;LinearOpMode&lt;/code&gt; Javadoc comments to be easier to read and include more detail.&lt;/li&gt; 
 &lt;li&gt;Makes minor enhancements to Java samples 
  &lt;ul&gt; 
   &lt;li&gt;Javadoc comments in samples that could be rendered badly in Android Studio have been converted to standard multi-line comments&lt;/li&gt; 
   &lt;li&gt;Consistency between samples has been improved&lt;/li&gt; 
   &lt;li&gt;The SensorDigitalTouch sample has been replaced with a new SensorTouch sample that uses the &lt;code&gt;TouchSensor&lt;/code&gt; interface instead of &lt;code&gt;DigitalChannel&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The ConceptCompassCalibration, SensorMRCompass, and SensorMRIRSeeker samples have been deleted, as they are not useful for modern FTC competitions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes a bug which prevented PlayStation gamepads from being used in bluetooth mode. Bluetooth is NOT legal for competition but may be useful to allow a DS device to be used while charging, or at an outreach event.&lt;/li&gt; 
 &lt;li&gt;Fixes a bug where a Blocks OpMode's Date Modified value can change to December 31, 1969, if the Control Hub is rebooted while the Blocks OpMode is being edited.&lt;/li&gt; 
 &lt;li&gt;Fixes the automatic TeleOp preselection feature (was broken in 8.2)&lt;/li&gt; 
 &lt;li&gt;Fixes a bug where passing an integer number such as 123 to the Telemetry.addData block that takes a number shows up as 123.0 in the telemetry.&lt;/li&gt; 
 &lt;li&gt;Fixes OnBotJava autocomplete issues: 
  &lt;ul&gt; 
   &lt;li&gt;Autocomplete would incorrectly provide values for the current class when autocompleting a local variable&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;hardwareMap&lt;/code&gt; autocomplete would incorrectly include lambda class entries&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes OnBotJava not automatically importing classes.&lt;/li&gt; 
 &lt;li&gt;Fixes OnBotJava tabs failing to close when their file is deleted.&lt;/li&gt; 
 &lt;li&gt;Fixes a project view refresh not happening when a file is renamed in OnBotJava.&lt;/li&gt; 
 &lt;li&gt;Fixes the "Download" context menu item for external libraries in the OnBotJava interface.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where Driver Station telemetry would intermittently freeze when set to Monospace mode.&lt;/li&gt; 
 &lt;li&gt;Fixes performance regression for certain REV Hub operations that was introduced in version 8.2.&lt;/li&gt; 
 &lt;li&gt;Fixes TagID comparison logic in DriveToTag samples.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 8.2 (20230707-131020)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Non-linear (iterative) OpModes are no longer allowed to manipulate actuators in their &lt;code&gt;stop()&lt;/code&gt; method. Attempts to do so will be ignored and logged. 
  &lt;ul&gt; 
   &lt;li&gt;When an OpMode attempts to illegally manipulate an actuator, the Robot Controller will print a log message including the text &lt;code&gt;CANCELLED_FOR_SAFETY&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Additionally, LinearOpModes are no longer able to regain the ability to manipulate actuators by removing their thread's interrupt or using another thread.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Removes support for Android version 6.0 (Marshmallow). The minSdkVersion is now 24.&lt;/li&gt; 
 &lt;li&gt;Increases the Robocol version. 
  &lt;ul&gt; 
   &lt;li&gt;This means an 8.2 or later Robot Controller or Driver Station will not be able to communicate with an 8.1 or earlier Driver Station or Robot Controller.&lt;/li&gt; 
   &lt;li&gt;If you forget to update both apps at the same time, an error message will be shown explaining which app is older and should be updated.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;FTC_FieldCoordinateSystemDefinition.pdf has been moved. It is still in the git history, but has been removed from the git snapshot corresponding with the 8.2 tag. The official version now lives at &lt;a href="https://ftc-docs.firstinspires.org/field-coordinate-system"&gt;Field Coordinate System&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;LynxUsbDevice.addConfiguredModule()&lt;/code&gt; and &lt;code&gt;LynxUsbDevice.getConfiguredModule()&lt;/code&gt; have been replaced with &lt;code&gt;LynxUsbDevice.getOrAddModule()&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Old Blocks for Vuforia and TensorFlow Object Detection are obsolete and have been removed from the Blocks editor's toolbox. Existing Blocks OpModes that contain the old Blocks for Vuforia or TensorFlow Object Detection can be opened in the Blocks editor, but running them will not work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds new &lt;code&gt;VisionPortal&lt;/code&gt; API for computer vision 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;This API may be subject to change for final kickoff release!&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Several new samples added.&lt;/li&gt; 
   &lt;li&gt;Adds support for detecting AprilTags.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;VisionPortal&lt;/code&gt; is the new entry point for both AprilTag and TFOD processing.&lt;/li&gt; 
   &lt;li&gt;Vuforia will be removed in a future release.&lt;/li&gt; 
   &lt;li&gt;Updated TensorFlow dependencies.&lt;/li&gt; 
   &lt;li&gt;Added support for webcam camera controls to blocks.&lt;/li&gt; 
   &lt;li&gt;The Blocks editor's toolbox now has a Vision category, directly above the Utilities category.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Related documentation for associated technologies can be found at 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://ftc-docs.firstinspires.org/apriltag-intro"&gt;AprilTag Introduction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ftc-docs.firstinspires.org/apriltag-sdk"&gt;AprilTag SDK Guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ftc-docs.firstinspires.org/apriltag-detection-values"&gt;AprilTag Detection Values&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ftc-docs.firstinspires.org/apriltag-test-images"&gt;AprilTag Test Images&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ftc-docs.firstinspires.org/camera-calibration"&gt;Camera Calibration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds Driver Station support for Logitech Dual Action and Sony PS5 DualSense gamepads. 
  &lt;ul&gt; 
   &lt;li&gt;This &lt;strong&gt;does not&lt;/strong&gt; include support for the Sony PS5 DualSense Edge gamepad.&lt;/li&gt; 
   &lt;li&gt;Always refer to Game Manual 1 to determine gamepad legality in competition.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for MJPEG payload streaming to UVC driver (external JPEG decompression routine required for use).&lt;/li&gt; 
 &lt;li&gt;Shows a hint on the Driver Station UI about how to bind a gamepad when buttons are pressed or the sticks are moved on an unbound gamepad.&lt;/li&gt; 
 &lt;li&gt;Adds option for fullscreening "Camera Stream" on Driver Station.&lt;/li&gt; 
 &lt;li&gt;OnBotJava source code is automatically saved as a ZIP file on every build with a rolling window of the last 30 builds kept; allows recovering source code from previous builds if code is accidentally deleted or corrupted.&lt;/li&gt; 
 &lt;li&gt;Adds support for changing the addresses of Expansion Hubs that are not connected directly via USB. 
  &lt;ul&gt; 
   &lt;li&gt;The Expansion Hub Address Change screen now has an Apply button that changes the addresses without leaving the screen.&lt;/li&gt; 
   &lt;li&gt;Addresses that are assigned to other hubs connected to the same USB connection or Control Hub are no longer able to be selected.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Increases maximum size of Blocks inline comments to 100 characters&lt;/li&gt; 
 &lt;li&gt;Saves position of open Blocks comment balloons&lt;/li&gt; 
 &lt;li&gt;Adds new AprilTag Driving samples: RobotDriveToAprilTagTank &amp;amp; RobotDriveToAprilTagOmni&lt;/li&gt; 
 &lt;li&gt;Adds Sample to illustrate optimizing camera exposure for AprilTags: ConceptAprilTagOptimizeExposure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Corrects inspection screen to report app version using the SDK version defined in the libraries instead of the version specified in &lt;code&gt;AndroidManifest.xml&lt;/code&gt;. This corrects the case where the app could show matching versions numbers to the user but still state that the versions did not match. 
  &lt;ul&gt; 
   &lt;li&gt;If the version specified in &lt;code&gt;AndroidManifest.xml&lt;/code&gt; does not match the SDK version, an SDK version entry will be displayed on the Manage webpage.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes no error being displayed when saving a configuration file with duplicate names from the Driver Station.&lt;/li&gt; 
 &lt;li&gt;Fixes a deadlock in the UVC driver which manifested in &lt;a href="https://github.com/OpenFTC/EasyOpenCV/issues/57"&gt;https://github.com/OpenFTC/EasyOpenCV/issues/57&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Fixes a deadlock in the UVC driver that could occur when hot-plugging cameras.&lt;/li&gt; 
 &lt;li&gt;Fixes UVC driver compatibility with Arducam OV9281 global shutter camera.&lt;/li&gt; 
 &lt;li&gt;Fixes Emergency Stop condition when an OnBotJava build with duplicate OpMode names occurs.&lt;/li&gt; 
 &lt;li&gt;Fixes known causes of "Attempted use of a closed LynxModule instance" logspam.&lt;/li&gt; 
 &lt;li&gt;Fixes the visual identification LED pattern when configuring Expansion Hubs connected via RS-485.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 8.1.1 (20221201-150726)&lt;/h2&gt; 
&lt;p&gt;This is a bug fix only release to address the following four issues.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/492"&gt;Issue #492&lt;/a&gt; - Can't create new blocks opmodes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/495"&gt;Issue #495&lt;/a&gt; - Remove the final modifier from the OpMode's Telemetry object.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/500"&gt;Issue #500&lt;/a&gt; - Some devices cannot be configured when the Driver Station app has been updated to 8.1 
  &lt;ul&gt; 
   &lt;li&gt;Updating either the Robot Controller app or the Driver Station app to 8.1.1 or later will fix this issue.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The Modern Robotics touch sensor was configurable as a Digital Device. It can only be used as an Analog Device.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 8.1 (20221121-115119)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deprecates the &lt;code&gt;OpMode&lt;/code&gt; fields &lt;code&gt;msStuckDetectInit&lt;/code&gt;, &lt;code&gt;msStuckDetectInitLoop&lt;/code&gt;, &lt;code&gt;msStuckDetectStart&lt;/code&gt;, &lt;code&gt;msStuckDetectLoop&lt;/code&gt;, and &lt;code&gt;msStuckDetectStop&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;OpModes no longer have a time limit for &lt;code&gt;init()&lt;/code&gt;, &lt;code&gt;init_loop()&lt;/code&gt;, &lt;code&gt;start()&lt;/code&gt; or &lt;code&gt;loop()&lt;/code&gt;, so the fields corresponding to those methods are no longer used.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stop()&lt;/code&gt; still has a time limit, but it is now hardcoded to be 1 second, and cannot be changed using &lt;code&gt;msStuckDetectStop&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Deprecates the &lt;code&gt;OpMode&lt;/code&gt; methods &lt;code&gt;internalPreInit()&lt;/code&gt;, &lt;code&gt;internalPostInitLoop()&lt;/code&gt;, and &lt;code&gt;internalPostLoop()&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Iterative &lt;code&gt;OpMode&lt;/code&gt;s will continue to call these methods in case they were overridden.&lt;/li&gt; 
   &lt;li&gt;These methods will not be called at all for &lt;code&gt;LinearOpMode&lt;/code&gt;s.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Deprecates (and stops respecting) &lt;code&gt;DeviceProperties.xmlTagAliases&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds a new &lt;code&gt;IMU&lt;/code&gt; interface to Blocks and Java that can be used with both the original BNO055 IMU included in all older Control Hubs and Expansion Hubs, and the new alternative BHI260AP IMU. 
  &lt;ul&gt; 
   &lt;li&gt;You can determine which type of IMU is in your Control Hub by navigating to the Manage page of the web interface.&lt;/li&gt; 
   &lt;li&gt;To learn how to use the new &lt;code&gt;IMU&lt;/code&gt; interface, see &lt;a href="https://ftc-docs.firstinspires.org/programming_resources/imu/imu.html"&gt;https://ftc-docs.firstinspires.org/programming_resources/imu/imu.html&lt;/a&gt;. The &lt;code&gt;SensorIMU&lt;/code&gt; Blocks sample was also updated to use the new &lt;code&gt;IMU&lt;/code&gt; interface, and the following Java samples were added: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;SensorIMUOrthogonal&lt;/code&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Use this sample if your REV Hub is mounted so that it is parallel or perpendicular to the bottom of your robot.&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;SensorIMUNonOrthogonal&lt;/code&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Use this sample if your REV Hub is mounted to your robot in any other orientation&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;ConceptExploringIMUOrientations&lt;/code&gt; 
      &lt;ul&gt; 
       &lt;li&gt;This OpMode is a tool to help you understand how the orthogonal orientations work, and which one applies to your robot.&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;The BHI260AP IMU can only be accessed via the new &lt;code&gt;IMU&lt;/code&gt; interface. The BNO055 IMU can be programmed using the new &lt;code&gt;IMU&lt;/code&gt; interface, or you can continue to program it using the old &lt;code&gt;BNO055IMU&lt;/code&gt; interface. If you want to be able to quickly switch to a new Control Hub that may contain the BHI260AP IMU, you should migrate your code to use the new &lt;code&gt;IMU&lt;/code&gt; interface.&lt;/li&gt; 
   &lt;li&gt;Unlike the old &lt;code&gt;BNO055IMU&lt;/code&gt; interface, which only worked correctly when the REV Hub was mounted flat on your robot, the &lt;code&gt;IMU&lt;/code&gt; interface allows you to specify the orientation of the REV Hub on your robot. It will account for this, and give you your orientation in a Robot Coordinate System, instead of a special coordinate system for the REV Hub. As a result, your pitch and yaw will be 0 when your &lt;em&gt;robot&lt;/em&gt; is level, instead of when the REV Hub is level, which will result in much more reliable orientation angle values for most mounting orientations.&lt;/li&gt; 
   &lt;li&gt;Because of the new robot-centric coordinate system, the pitch and roll angles returned by the &lt;code&gt;IMU&lt;/code&gt; interface will be different from the ones returned by the &lt;code&gt;BNO055IMU&lt;/code&gt; interface. When you are migrating your code, pay careful attention to the documentation.&lt;/li&gt; 
   &lt;li&gt;If you have calibrated your BNO055, you can provide that calibration data to the new &lt;code&gt;IMU&lt;/code&gt; interface by passing a &lt;code&gt;BNO055IMUNew.Parameters&lt;/code&gt; instance to &lt;code&gt;IMU.initialize()&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The &lt;code&gt;IMU&lt;/code&gt; interface is also suitable for implementation by third-party vendors for IMUs that support providing the orientation in the form of a quaternion.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Iterative &lt;code&gt;OpMode&lt;/code&gt;s (as opposed to &lt;code&gt;LinearOpMode&lt;/code&gt;s) now run on a dedicated thread. 
  &lt;ul&gt; 
   &lt;li&gt;Cycle times should not be as impacted by everything else going on in the system.&lt;/li&gt; 
   &lt;li&gt;Slow &lt;code&gt;OpMode&lt;/code&gt;s can no longer increase the amount of time it takes to process network commands, and vice versa.&lt;/li&gt; 
   &lt;li&gt;The &lt;code&gt;init()&lt;/code&gt;, &lt;code&gt;init_loop()&lt;/code&gt;, &lt;code&gt;start()&lt;/code&gt; and &lt;code&gt;loop()&lt;/code&gt; methods no longer need to return within a certain time frame.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;BNO055 IMU legacy driver: restores the ability to initialize in one OpMode, and then have another OpMode re-use that initialization. This allows you to maintain the 0-yaw position between OpModes, if desired.&lt;/li&gt; 
 &lt;li&gt;Allows customized versions of device drivers in the FTC SDK to use the same XML tag. 
  &lt;ul&gt; 
   &lt;li&gt;Before, if you wanted to customize a device driver, you had to copy it to a new class &lt;em&gt;and&lt;/em&gt; give it a new XML tag. Giving it a new XML tag meant that to switch which driver was being used, you had to modify your configuration file.&lt;/li&gt; 
   &lt;li&gt;Now, to use your custom driver, all you have to do is specify your custom driver's class when calling &lt;code&gt;hardwareMap.get()&lt;/code&gt;. To go back to the original driver, specify the original driver class. If you specify an interface that is implemented by both the original driver and the custom driver, there is no guarantee about which implementation will be returned.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug Fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes accessing the "Manage TensorFlow Lite Models" and "Manage Sounds" links and performing Blocks and OnBotJava OpMode downloads from the REV Hardware Client.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where an I2C device driver would be auto-initialized using the parameters assigned in a previous OpMode run.&lt;/li&gt; 
 &lt;li&gt;Improves Driver Station popup menu placement in the landscape layout.&lt;/li&gt; 
 &lt;li&gt;Fixes NullPointerException when attempting to get a non-configured BNO055 IMU in a Blocks OpMode on an RC phone.&lt;/li&gt; 
 &lt;li&gt;Fixes problem with Blocks if a variable is named &lt;code&gt;orientation&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 8.0 (20220907-131644)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Increases the Robocol version. 
  &lt;ul&gt; 
   &lt;li&gt;This means an 8.0 or later Robot Controller or Driver Station will not be able to communicate with a 7.2 or earlier Driver Station or Robot Controller.&lt;/li&gt; 
   &lt;li&gt;If you forget to update both apps at the same time, an error message will be shown explaining which app is older and should be updated.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Initializing I2C devices now happens when you retrieve them from the &lt;code&gt;HardwareMap&lt;/code&gt; for the first time. 
  &lt;ul&gt; 
   &lt;li&gt;Previously, all I2C devices would be initialized before the OpMode even began executing, whether you were actually going to use them or not. This could result in reduced performance and unnecessary warnings.&lt;/li&gt; 
   &lt;li&gt;With this change, it is very important for Java users to retrieve all needed devices from the &lt;code&gt;HardwareMap&lt;/code&gt; &lt;strong&gt;during the Init phase of the OpMode&lt;/strong&gt;. Namely, declare a variable for each hardware device the OpMode will use, and assign a value to each. Do not do this during the Run phase, or your OpMode may briefly hang while the devices you are retrieving get initialized.&lt;/li&gt; 
   &lt;li&gt;OpModes that do not use all of the I2C devices specified in the configuration file should take less time to initialize. OpModes that do use all of the specified I2C devices should take the same amount of time as previously.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/251"&gt;issue #251&lt;/a&gt; by changing the order in which axis rotation rates are read from the angular velocity vector in the BNO055 IMU driver.&lt;/li&gt; 
 &lt;li&gt;Deprecates &lt;code&gt;pitchMode&lt;/code&gt; in &lt;code&gt;BNO055IMU.Parameters&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Setting &lt;code&gt;pitchMode&lt;/code&gt; to &lt;code&gt;PitchMode.WINDOWS&lt;/code&gt; would break the coordinate conventions used by the driver.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Moves &lt;code&gt;OpModeManagerImpl&lt;/code&gt; to the &lt;code&gt;com.qualcomm.robotcore.eventloop.opmode&lt;/code&gt; package. 
  &lt;ul&gt; 
   &lt;li&gt;This breaks third party libraries EasyOpenCV (version 1.5.1 and earlier) and FTC Dashboard (version 0.4.4 and earlier).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Deletes the deprecated &lt;code&gt;OpMode&lt;/code&gt; method &lt;code&gt;resetStartTime()&lt;/code&gt; (use &lt;code&gt;resetRuntime()&lt;/code&gt; instead).&lt;/li&gt; 
 &lt;li&gt;Deletes the protected &lt;code&gt;LinearOpMode.LinearOpModeHelper&lt;/code&gt; class (which was not meant for use by OpModes).&lt;/li&gt; 
 &lt;li&gt;Removes I2C Device (Synchronous) config type (deprecated since 2018)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Uncaught exceptions in OpModes no longer require a Restart Robot 
  &lt;ul&gt; 
   &lt;li&gt;A blue screen popping up with a stacktrace is not an SDK error; this replaces the red text in the telemetry area.&lt;/li&gt; 
   &lt;li&gt;Since the very first SDK release, OpMode crashes have put the robot into "EMERGENCY STOP" state, only showing the first line of the exception, and requiring the user to press "Restart Robot" to continue&lt;/li&gt; 
   &lt;li&gt;Exceptions during an OpMode now open a popup window with the same color scheme as the log viewer, containing 15 lines of the exception stacktrace to allow easily tracing down the offending line without needing to connect to view logs over ADB or scroll through large amounts of logs in the log viewer.&lt;/li&gt; 
   &lt;li&gt;The exception text in the popup window is both zoomable and scrollable just like a webpage.&lt;/li&gt; 
   &lt;li&gt;Pressing the "OK" button in the popup window will return to the main screen of the Driver Station and allow an OpMode to be run again immediately, without the need to perform a "Restart Robot"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds new Java sample to demonstrate using a hardware class to abstract robot actuators, and share them across multiple OpModes. 
  &lt;ul&gt; 
   &lt;li&gt;Sample OpMode is &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples/ConceptExternalHardwareClass.java"&gt;ConceptExternalHardwareClass.java&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Abstracted hardware class is &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples/RobotHardware.java"&gt;RobotHardware.java&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updates RobotAutoDriveByGyro_Linear Java sample to use REV Control/Expansion hub IMU.&lt;/li&gt; 
 &lt;li&gt;Updates Vuforia samples to reference PowerPlay assets and have correct names and field locations of image targets.&lt;/li&gt; 
 &lt;li&gt;Updates TensorFlow samples to reference PowerPlay assets.&lt;/li&gt; 
 &lt;li&gt;Adds opt-in support for Java 8 language features to the OnBotJava editor. 
  &lt;ul&gt; 
   &lt;li&gt;To opt in, open the OnBotJava Settings, and check &lt;code&gt;Enable beta Java 8 support&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Note that Java 8 code will only compile when the Robot Controller runs Android 7.0 Nougat or later.&lt;/li&gt; 
   &lt;li&gt;Please report issues &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;In OnBotJava, clicking on build errors now correctly jumps to the correct location.&lt;/li&gt; 
 &lt;li&gt;Improves OnBotJava autocomplete behavior, to provide better completion options in most cases.&lt;/li&gt; 
 &lt;li&gt;Adds a QR code to the Robot Controller Inspection Report when viewed from the Driver Station for scanning by inspectors at competition.&lt;/li&gt; 
 &lt;li&gt;Improves I2C performance and reliability in some scenarios.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 7.2 (20220723-130006)&lt;/h2&gt; 
&lt;h3&gt;Breaking Changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updates the build tooling. For Android Studio users, this change requires Android Studio Chipmunk 2021.2.1.&lt;/li&gt; 
 &lt;li&gt;Removes support for devices that are not competition legal, including Modern Robotics Core Control Modules, the Matrix Controller, and HiTechnic/NXT controllers and sensors. Support remains for Modern Robotics I2C sensors.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Increases the height of the 3-dots Landscape menu touch area on the Driver Station, making it much easier to select.&lt;/li&gt; 
 &lt;li&gt;Adds &lt;code&gt;terminateOpModeNow()&lt;/code&gt; method to allow OpModes to cleanly self-exit immediately.&lt;/li&gt; 
 &lt;li&gt;Adds &lt;code&gt;opModeInInit()&lt;/code&gt; method to &lt;code&gt;LinearOpMode&lt;/code&gt; to facilitate init-loops. Similar to &lt;code&gt;opModeIsActive()&lt;/code&gt; but for the init phase.&lt;/li&gt; 
 &lt;li&gt;Warns user if they have a Logitech F310 gamepad connected that is set to DirectInput mode.&lt;/li&gt; 
 &lt;li&gt;Allows SPARKmini motor controllers to react more quickly to speed changes.&lt;/li&gt; 
 &lt;li&gt;Hides the version number of incorrectly installed sister app (i.e. DS installed on RC device or vice-versa) on inspection screen.&lt;/li&gt; 
 &lt;li&gt;Adds support for allowing the user to edit the comment for the runOpMode block.&lt;/li&gt; 
 &lt;li&gt;Adds parameterDefaultValues field to @ExportToBlocks. This provides the ability for a java method with an @ExportToBlocks annotation to specify default values for method parameters when it is shown in the block editor.&lt;/li&gt; 
 &lt;li&gt;Make LinearOpMode blocks more readable. The opmode name is displayed on the runOpMode block, but not on the other LinearOpMode blocks.&lt;/li&gt; 
 &lt;li&gt;Added support to TensorFlow Object Detection for using a different frame generator, instead of Vuforia. Using Vuforia to pass the camera frame to TFOD is still supported.&lt;/li&gt; 
 &lt;li&gt;Removes usage of Renderscript.&lt;/li&gt; 
 &lt;li&gt;Fixes logspam on app startup of repeated stacktraces relating to &lt;code&gt;"Failed resolution of: Landroid/net/wifi/p2p/WifiP2pManager$DeviceInfoListener"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Allows disabling bluetooth radio from inspection screen&lt;/li&gt; 
 &lt;li&gt;Improves warning messages when I2C devices are not responding&lt;/li&gt; 
 &lt;li&gt;Adds support for controlling the RGB LED present on PS4/Etpark gamepads from OpModes&lt;/li&gt; 
 &lt;li&gt;Removes legacy Pushbot references from OpMode samples. Renames "Pushbot" samples to "Robot". Motor directions reversed to be compatible with "direct Drive" drive train.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/316"&gt;issue #316&lt;/a&gt; (MatrixF.inverted() returned an incorrectly-sized matrix for 1x1 and 2x2 matrixes).&lt;/li&gt; 
 &lt;li&gt;Self inspect now allows for Driver Station and Robot Controller compatibility between point releases.&lt;/li&gt; 
 &lt;li&gt;Fixes bug where if the same &lt;code&gt;RumbleEffect&lt;/code&gt; object instance was queued for multiple gamepads, it could happen that both rumble commands would be sent to just one gamepad.&lt;/li&gt; 
 &lt;li&gt;Fixes bug in Driver Station where on the Driver Hub, if Advanced Gamepad Features was disabled and an officially supported gamepad was connected, then opening the Advanced Gamepad Features or Gamepad Type Overrides screens would cause the gamepad to be rebound by the custom USB driver even though advanced gamepad features was disabled.&lt;/li&gt; 
 &lt;li&gt;Protects against (unlikely) null pointer exception in Vuforia Localizer.&lt;/li&gt; 
 &lt;li&gt;Harden OnBotJava and Blocks saves to protect against save issues when disconnecting from Program and Manage&lt;/li&gt; 
 &lt;li&gt;Fixes issue where the RC app would hang if a REV Hub I2C write failed because the previous I2C operation was still in progress. This hang most commonly occurred during REV 2M Distance Sensor initialization&lt;/li&gt; 
 &lt;li&gt;Removes ConceptWebcam.java sample program. This sample is not compatible with OnBotJava.&lt;/li&gt; 
 &lt;li&gt;Fixes bug where using html tags in an @ExportToBlocks comment field prevented the blocks editor from loading.&lt;/li&gt; 
 &lt;li&gt;Fixes blocks editor so it doesn't ask you to save when you haven't modified anything.&lt;/li&gt; 
 &lt;li&gt;Fixes uploading a very large blocks project to offline blocks editor.&lt;/li&gt; 
 &lt;li&gt;Fixes bug that caused blocks for DcMotorEx to be omitted from the blocks editor toolbox.&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://ftcforum.firstinspires.org/forum/ftc-technology/blocks-programming/87035-blocks-programs-stripped-of-blocks"&gt;Blocks Programs Stripped of Blocks (due to using TensorFlow Label block)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 7.1 (20211223-120805)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes crash when calling &lt;code&gt;isPwmEnabled()&lt;/code&gt; (&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/233"&gt;issue #223&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Fixes lint error (&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/4"&gt;issue #4&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Fixes Driver Station crash when attempting to use DualShock4 v1 gamepad with Advanced Gamepad Features enabled (&lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/173"&gt;issue #173&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Fixes possible (but unlikely) Driver Station crash when connecting gamepads of any type.&lt;/li&gt; 
 &lt;li&gt;Fixes bug where Driver Station would use generic 20% deadzone for Xbox360 and Logitech F310 gamepads when Advanced Gamepad Features was disabled.&lt;/li&gt; 
 &lt;li&gt;Added SimpleOmniDrive sample OpMode.&lt;/li&gt; 
 &lt;li&gt;Adds UVC white balance control API.&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/259"&gt;issue #259&lt;/a&gt; Most blocks samples for TensorFlow can't be used for a different model. 
  &lt;ul&gt; 
   &lt;li&gt;The blocks previously labeled TensorFlowObjectDetectionFreightFrenzy (from the subcategory named "Optimized for Freight Frenzy") and TensorFlowObjectDetectionCustomModel (from the subcategory named "Custom Model") have been replaced with blocks labeled TensorFlowObjectDetection. Blocks in existing opmodes will be automatically updated to the new blocks when opened in the blocks editor.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/260"&gt;issue #260&lt;/a&gt; Blocks can't call java method that has a VuforiaLocalizer parameter. 
  &lt;ul&gt; 
   &lt;li&gt;Blocks now has a block labeled VuforiaFreightFrenzy.getVuforiaLocalizer for this.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Added a page to manage the TensorFlow Lite models in /sdcard/FIRST/tflitemodels. To get to the TFLite Models page: 
  &lt;ul&gt; 
   &lt;li&gt;You can click on the link at the bottom of the Manage page.&lt;/li&gt; 
   &lt;li&gt;You can click on the link at the upper-right the Blocks project page.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes logspam when &lt;code&gt;isBusy()&lt;/code&gt; is called on a motor not in RTP mode.&lt;/li&gt; 
 &lt;li&gt;Hides the "RC Password" item on the inspection screen for phone-based Robot Controllers. (It is only applicable for Control Hubs).&lt;/li&gt; 
 &lt;li&gt;Adds channel 165 to Wi-Fi Direct channel selection menu in the settings screen. (165 was previously available through the web UI, but not locally in the app).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 7.0 (20210915-141025)&lt;/h2&gt; 
&lt;h3&gt;Enhancements and New Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds support for external libraries to OnBotJava and Blocks. 
  &lt;ul&gt; 
   &lt;li&gt;Upload .jar and .aar files in OnBotJava. 
    &lt;ul&gt; 
     &lt;li&gt;Known limitation - RobotController device must be running Android 7.0 or greater.&lt;/li&gt; 
     &lt;li&gt;Known limitation - .aar files with assets are not supported.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;External libraries can provide support for hardware devices by using the annotation in the com.qualcomm.robotcore.hardware.configuration.annotations package.&lt;/li&gt; 
   &lt;li&gt;External libraries can include .so files for native code.&lt;/li&gt; 
   &lt;li&gt;External libraries can be used from OnBotJava OpModes.&lt;/li&gt; 
   &lt;li&gt;External libraries that use the following annotations can be used from Blocks OpModes. 
    &lt;ul&gt; 
     &lt;li&gt;org.firstinspires.ftc.robotcore.external.ExportClassToBlocks&lt;/li&gt; 
     &lt;li&gt;org.firstinspires.ftc.robotcore.external.ExportToBlocks&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;External libraries that use the following annotations can add new hardware devices: 
    &lt;ul&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.AnalogSensorType&lt;/li&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.DeviceProperties&lt;/li&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.DigitalIoDeviceType&lt;/li&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.I2cDeviceType&lt;/li&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.MotorType&lt;/li&gt; 
     &lt;li&gt;com.qualcomm.robotcore.hardware.configuration.annotations.ServoType&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;External libraries that use the following annotations can add new functionality to the Robot Controller: 
    &lt;ul&gt; 
     &lt;li&gt;org.firstinspires.ftc.ftccommon.external.OnCreate&lt;/li&gt; 
     &lt;li&gt;org.firstinspires.ftc.ftccommon.external.OnCreateEventLoop&lt;/li&gt; 
     &lt;li&gt;org.firstinspires.ftc.ftccommon.external.OnCreateMenu&lt;/li&gt; 
     &lt;li&gt;org.firstinspires.ftc.ftccommon.external.OnDestroy&lt;/li&gt; 
     &lt;li&gt;org.firstinspires.ftc.ftccommon.external.WebHandlerRegistrar&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for REV Robotics Driver Hub.&lt;/li&gt; 
 &lt;li&gt;Adds fully custom userspace USB gamepad driver to Driver Station (see "Advanced Gamepad Features" menu in DS settings). 
  &lt;ul&gt; 
   &lt;li&gt;Allows gamepads to work on devices without native Linux kernel support (e.g. some Romanian Motorola devices).&lt;/li&gt; 
   &lt;li&gt;Allows the DS to read the unique serial number of each gamepad, enabling auto-recovery of dropped gamepads even if two gamepads of the same model drop. &lt;em&gt;(NOTE: unfortunately this does not apply to Etpark gamepads, because they do not have a unique serial)&lt;/em&gt;.&lt;/li&gt; 
   &lt;li&gt;Reading the unique serial number also provides the ability to configure the DS to assign gamepads to a certain position by default (so no need to do start+a/b at all).&lt;/li&gt; 
   &lt;li&gt;The LED ring on the Xbox360 gamepad and the RGB LED bar on the PS4 gamepad is used to indicate the driver position the gamepad is bound to.&lt;/li&gt; 
   &lt;li&gt;The rumble motors on the Xbox360, PS4, and Etpark gamepads can be controlled from OpModes.&lt;/li&gt; 
   &lt;li&gt;The 2-point touchpad on the PS4 gamepad can be read from OpModes.&lt;/li&gt; 
   &lt;li&gt;The "back" and "guide" buttons on the gamepad can now be safely bound to robot controls (Previously, on many devices, Android would intercept these buttons as home button presses and close the app).&lt;/li&gt; 
   &lt;li&gt;Advanced Gamepad features are enabled by default, but may be disabled through the settings menu in order to revert to gamepad support provided natively by Android.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves accuracy of ping measurement. 
  &lt;ul&gt; 
   &lt;li&gt;Fixes issue where the ping time showed as being higher than reality when initially connecting to or restarting the robot.&lt;/li&gt; 
   &lt;li&gt;To see the full improvement, you must update both the Robot Controller and Driver Station apps.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updates samples located at &lt;a href="https://raw.githubusercontent.com/FIRST-Tech-Challenge/FtcRobotController/master/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples"&gt;/FtcRobotController/src/main/java/org/firstinspires/ftc/robotcontroller/external/samples&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Added ConceptGamepadRumble and ConceptGamepadTouchpad samples to illustrate the use of these new gampad capabilities.&lt;/li&gt; 
   &lt;li&gt;Condensed existing Vuforia samples into just 2 samples (ConceptVuforiaFieldNavigation &amp;amp; ConceptVuforiaFieldNavigationWebcam) showing how to determine the robot's location on the field using Vuforia. These both use the current season's Target images.&lt;/li&gt; 
   &lt;li&gt;Added ConceptVuforiaDriveToTargetWebcam to illustrate an easy way to drive directly to any visible Vuforia target.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Makes many improvements to the warning system and individual warnings. 
  &lt;ul&gt; 
   &lt;li&gt;Warnings are now much more spaced out, so that they are easier to read.&lt;/li&gt; 
   &lt;li&gt;New warnings were added for conditions that should be resolved before competing.&lt;/li&gt; 
   &lt;li&gt;The mismatched apps warning now uses the major and minor app versions, not the version code.&lt;/li&gt; 
   &lt;li&gt;The warnings are automatically re-enabled when a Robot Controller app from a new FTC season is installed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for I2C transactions on the Expansion Hub / Control Hub without specifying a register address. 
  &lt;ul&gt; 
   &lt;li&gt;See section 3 of the &lt;a href="https://www.ti.com/lit/an/slva704/slva704.pdf"&gt;TI I2C spec&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Calling these new methods when using Modern Robotics hardware will result in an UnsupportedOperationException.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Changes VuforiaLocalizer &lt;code&gt;close()&lt;/code&gt; method to be public.&lt;/li&gt; 
 &lt;li&gt;Adds support for TensorFlow v2 object detection models.&lt;/li&gt; 
 &lt;li&gt;Reduces ambiguity of the Self Inspect language and graphics.&lt;/li&gt; 
 &lt;li&gt;OnBotJava now warns about potentially unintended file overwrites.&lt;/li&gt; 
 &lt;li&gt;Improves behavior of the Wi-Fi band and channel selector on the Manage webpage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes Robot Controller app crash on Android 9+ when a Driver Station connects.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where an OpMode was responsible for calling shutdown on the TensorFlow TFObjectDetector. Now this is done automatically.&lt;/li&gt; 
 &lt;li&gt;Fixes Vuforia initialization blocks to allow user to chose AxesOrder. Updated relevant blocks sample opmodes.&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/114"&gt;FtcRobotController issue #114&lt;/a&gt; LED blocks and Java class do not work.&lt;/li&gt; 
 &lt;li&gt;Fixes match logging for OpModes that contain special characters in their names.&lt;/li&gt; 
 &lt;li&gt;Fixes Driver Station OpMode controls becoming unresponsive if the Driver Station was set to the landscape layout and an OnBotJava build was triggered while an OpMode was running.&lt;/li&gt; 
 &lt;li&gt;Fixes the Driver Station app closing itself when it is switched away from, or the screen is turned off.&lt;/li&gt; 
 &lt;li&gt;Fixes "black swirl of doom" (Infinite "configuring Wi-Fi Direct" message) on older devices.&lt;/li&gt; 
 &lt;li&gt;Updates the wiki comment on the OnBotJava intro page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 6.2 (20210218-074821)&lt;/h2&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Attempts to automatically fix the condition where a Control Hub's internal Expansion Hub is not working by re-flashing its firmware&lt;/li&gt; 
 &lt;li&gt;Makes various improvements to the Wi-Fi Direct pairing screen, especially in landscape mode&lt;/li&gt; 
 &lt;li&gt;Makes the Robot Controller service no longer be categorically restarted when the main activity is brought to foreground 
  &lt;ul&gt; 
   &lt;li&gt;(e.g. the service is no longer restarted simply by viewing the Self Inspect screen and pressing the back button)&lt;/li&gt; 
   &lt;li&gt;It is still restarted if the Settings menu or Configure Robot menu is opened&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/71"&gt;FtcRobotController issue #71&lt;/a&gt; Cannot open OpModes in v6.1 Blocks offline editor&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/issues/79"&gt;FtcRobotController issue #79&lt;/a&gt; 6.1 causes a soft reboot on the Motorola E5 Play&lt;/li&gt; 
 &lt;li&gt;Fixes issue where the Control Hub OS's watchdog would restart the Robot Controller app if the Control Hub was not able to communicate with its internal Expansion Hub&lt;/li&gt; 
 &lt;li&gt;Fixes certain I2C devices not showing up in the appropriate &lt;code&gt;HardwareMap&lt;/code&gt; fields (such as &lt;code&gt;hardwareMap.colorSensor&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Fixes issue where performing a Wi-Fi factory reset on the Control Hub would not set the Wi-Fi band to 2.4 GHz&lt;/li&gt; 
 &lt;li&gt;Fixes issue where OnBotJava might fail to create a new file if the option to "Setup Code for Configured Hardware" was selected&lt;/li&gt; 
 &lt;li&gt;Fixes issue where performing certain operations after an OpMode crashes would temporarily break Control/Expansion Hub communication&lt;/li&gt; 
 &lt;li&gt;Fixes issue where a Control Hub with a configured USB-connected Expansion Hub would not work if the Expansion Hub was missing at startup&lt;/li&gt; 
 &lt;li&gt;Fixes potential issues caused by having mismatched Control/Expansion Hub firmware versions&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/673"&gt;ftc_app issue 673&lt;/a&gt; Latest matchlog is being deleted instead of old ones by RobotLog&lt;/li&gt; 
 &lt;li&gt;Fixes ConceptVuforiaUltimateGoalNavigationWebcam sample opmode by correctly orienting camera on robot.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where logcat would be spammed with InterruptedExceptions when stop is requested from the Driver Station (this behavior was accidentally introduced in v5.3). This change has no impact on functionality.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where the blocks editor fails to load if the name of any TeleOp opmode contains an apostrophe.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 6.1 (20201209-113742)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Makes the scan button on the configuration screen update the list of Expansion Hubs connected via RS-485 
  &lt;ul&gt; 
   &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/143"&gt;SkyStone issue #143&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves web interface compatibility with older browser and Android System WebView versions.&lt;/li&gt; 
 &lt;li&gt;Fixes issue in UVC driver where some cameras (e.g. certain MS Lifecams) which reported frame intervals as rounded rather than truncated values (e.g. &lt;code&gt;666667*100ns&lt;/code&gt; instead of &lt;code&gt;666666*100ns&lt;/code&gt; for 15FPS) would fail to start streaming.&lt;/li&gt; 
 &lt;li&gt;Adds support in UVC driver for virtual PTZ control&lt;/li&gt; 
 &lt;li&gt;Adds support in UVC driver for gain (ISO) control&lt;/li&gt; 
 &lt;li&gt;Adds support in UVC driver for enabling/disable AE priority. This setting provides a means to tell the camera firmware either 
  &lt;ul&gt; 
   &lt;li&gt;A) It can undershoot the requested frame rate in order to provide a theoretically better image (i.e. with a longer exposure than the inter-frame period of the selected frame rate allows)&lt;/li&gt; 
   &lt;li&gt;B) It &lt;em&gt;must&lt;/em&gt; meet the inter-frame deadline for the selected frame rate, even if the image may be underexposed as a result&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for the Control Hub OS 1.1.2 Robot Controller watchdog 
  &lt;ul&gt; 
   &lt;li&gt;The Robot Controller app will be restarted if it stops responding for more than 10 seconds&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for using the Driver Station app on Android 10+&lt;/li&gt; 
 &lt;li&gt;Introduces an automatic TeleOp preselection feature 
  &lt;ul&gt; 
   &lt;li&gt;For details and usage guide, please see &lt;a href="https://github.com/FIRST-Tech-Challenge/FtcRobotController/wiki/Automatically-Loading-a-Driver-Controlled-Op-Mode"&gt;this wiki entry&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Shows icon next to OpMode name in the OpMode list dropdown on the Driver Station to indicate the source of the OpMode (i.e. the programming tool used to create it)&lt;/li&gt; 
 &lt;li&gt;Fixes issue where the Driver Station app would exit after displaying the Configuring Wi-Fi Direct screen&lt;/li&gt; 
 &lt;li&gt;Fixes Blocks and OnBotJava prompts when accessed via the REV Hardware Client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 6.0 (20200921-085816)&lt;/h2&gt; 
&lt;h3&gt;Important Notes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Version 6.0 is the version for the Ultimate Goal season.&lt;/li&gt; 
 &lt;li&gt;Requires Android Studio 4.0.&lt;/li&gt; 
 &lt;li&gt;Android Studio users need to be connected to the Internet the first time they build the app (in order to download needed packages for the build).&lt;/li&gt; 
 &lt;li&gt;Version 5.5 was a moderately large off-season, August 2020, drop. It's worth reviewing those release notes below also.&lt;/li&gt; 
 &lt;li&gt;Version 5.5 and greater will not work on older Android 4.x and 5.x phones. Users must upgrade to an approved Android 6.x device or newer.&lt;/li&gt; 
 &lt;li&gt;The default PIDF values for REV motors have been reverted to the default PID values that were used in the 2018-2019 season 
  &lt;ul&gt; 
   &lt;li&gt;This change was made because the 2018-2019 values turned out to work better for many mechanisms&lt;/li&gt; 
   &lt;li&gt;This brings the behavior of the REV motors in line with the behavior of all other motors&lt;/li&gt; 
   &lt;li&gt;If you prefer the 2019-2020 season's behavior for REV motors, here are the PIDF values that were in place, so that you can manually set them in your OpModes: &lt;br /&gt; &lt;strong&gt;HD Hex motors (all gearboxes):&lt;/strong&gt; Velocity PIDF values: &lt;code&gt;P = 1.17&lt;/code&gt;, &lt;code&gt;I = 0.117&lt;/code&gt;, &lt;code&gt;F = 11.7&lt;/code&gt; Position PIDF values: &lt;code&gt;P = 5.0&lt;/code&gt; &lt;strong&gt;Core Hex motor:&lt;/strong&gt; Velocity PIDF values: &lt;code&gt;P = 4.96&lt;/code&gt;, &lt;code&gt;I = 0.496&lt;/code&gt;, &lt;code&gt;F = 49.6&lt;/code&gt; Position PIDF values: &lt;code&gt;P = 5.0&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes TensorFlow inference model and sample OpModes to detect Ultimate Goal Starter Stacks (four rings vs single ring stack).&lt;/li&gt; 
 &lt;li&gt;Includes Vuforia Ultimate Goal vision targets and sample OpModes.&lt;/li&gt; 
 &lt;li&gt;Introduces a digital zoom feature for TensorFlow object detection (to detect objects more accurately at greater distances).&lt;/li&gt; 
 &lt;li&gt;Adds configuration entry for the REV UltraPlanetary HD Hex motor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds setGain() and getGain() methods to the NormalizedColorSensor interface 
  &lt;ul&gt; 
   &lt;li&gt;By setting the gain of a color sensor, you can adjust for different lighting conditions. For example, if you detect lower color values than expected, you can increase the gain.&lt;/li&gt; 
   &lt;li&gt;The gain value is only applied to the argb() and getNormalizedColors() methods, not to the raw color methods. The getNormalizedColors() method is recommended for ease-of-use and clarity, since argb() has to be converted.&lt;/li&gt; 
   &lt;li&gt;Updates SensorColor Java sample to demonstrate gain usage&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Merges SensorREVColorDistance Java sample into SensorColor Java sample, which showcases best practices for all color sensors&lt;/li&gt; 
 &lt;li&gt;Improves retrieving values from the REV Color Sensor V3 
  &lt;ul&gt; 
   &lt;li&gt;Updates the normalization calculation of the RGB channels&lt;/li&gt; 
   &lt;li&gt;Improves the calculation of the alpha channel (can be used as an overall brightness indicator)&lt;/li&gt; 
   &lt;li&gt;Fixes the default sensor resolution, which caused issues with bright environments&lt;/li&gt; 
   &lt;li&gt;Adds support for changing the resolution and measuring rate of the Broadcom sensor chip&lt;/li&gt; 
   &lt;li&gt;Removes IR readings and calculations not meant for the Broadcom sensor chip&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Improves reliability of BNO055IMU IMU initialization to prevent random initialization failures (which manifested as &lt;code&gt;Problem with 'imu'&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.5 (20200824-090813)&lt;/h2&gt; 
&lt;p&gt;Version 5.5 requires Android Studio 4.0 or later.&lt;/p&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adds support for calling custom Java classes from Blocks OpModes (fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/161"&gt;SkyStone issue #161&lt;/a&gt;). 
  &lt;ul&gt; 
   &lt;li&gt;Classes must be in the org.firstinspires.ftc.teamcode package.&lt;/li&gt; 
   &lt;li&gt;To have easy access to the opMode, hardwareMap, telemetry, gamepad1, and gamepad2, classes can extends org.firstinspires.ftc.robotcore.external.BlocksOpModeCompanion.&lt;/li&gt; 
   &lt;li&gt;Methods must be public static and have no more than 21 parameters.&lt;/li&gt; 
   &lt;li&gt;Methods must be annotated with org.firstinspires.ftc.robotcore.external.ExportToBlocks.&lt;/li&gt; 
   &lt;li&gt;Parameters declared as OpMode, LinearOpMode, Telemetry, and HardwareMap are supported and the argument is provided automatically, regardless of the order of the parameters. On the block, the sockets for those parameters are automatically filled in.&lt;/li&gt; 
   &lt;li&gt;Parameters declared as char or java.lang.Character will accept any block that returns text and will only use the first character in the text.&lt;/li&gt; 
   &lt;li&gt;Parameters declared as boolean or java.lang.Boolean will accept any block that returns boolean.&lt;/li&gt; 
   &lt;li&gt;Parameters declared as byte, java.lang.Byte, short, java.lang.Short, int, java.lang.Integer, long, or java.lang.Long, will accept any block that returns a number and will round that value to the nearest whole number.&lt;/li&gt; 
   &lt;li&gt;Parameters declared as float, java.lang.Float, double, java.lang.Double will accept any block that returns a number.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds telemetry API method for setting display format 
  &lt;ul&gt; 
   &lt;li&gt;Classic&lt;/li&gt; 
   &lt;li&gt;Monospace&lt;/li&gt; 
   &lt;li&gt;HTML (certain tags only)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds blocks support for switching cameras.&lt;/li&gt; 
 &lt;li&gt;Adds Blocks support for TensorFlow Object Detection with a custom model.&lt;/li&gt; 
 &lt;li&gt;Adds support for uploading a custom TensorFlow Object Detection model in the Manage page, which is especially useful for Blocks and OnBotJava users.&lt;/li&gt; 
 &lt;li&gt;Shows new Control Hub blink codes when the Wi-Fi band is switched using the Control Hub's button (only possible on Control Hub OS 1.1.2)&lt;/li&gt; 
 &lt;li&gt;Adds new warnings which can be disabled in the Advanced RC Settings 
  &lt;ul&gt; 
   &lt;li&gt;Mismatched app versions warning&lt;/li&gt; 
   &lt;li&gt;Unnecessary 2.4 GHz Wi-Fi usage warning&lt;/li&gt; 
   &lt;li&gt;REV Hub is running outdated firmware (older than version 1.8.2)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds support for Sony PS4 gamepad, and reworks how gamepads work on the Driver Station 
  &lt;ul&gt; 
   &lt;li&gt;Removes preference which sets gamepad type based on driver position. Replaced with menu which allows specifying type for gamepads with unknown VID and PID&lt;/li&gt; 
   &lt;li&gt;Attempts to auto-detect gamepad type based on USB VID and PID&lt;/li&gt; 
   &lt;li&gt;If gamepad VID and PID is not known, use type specified by user for that VID and PID&lt;/li&gt; 
   &lt;li&gt;If gamepad VID and PID is not known AND the user has not specified a type for that VID and PID, an educated guess is made about how to map the gamepad&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Driver Station will now attempt to automatically recover from a gamepad disconnecting, and re-assign it to the position it was assigned to when it dropped 
  &lt;ul&gt; 
   &lt;li&gt;If only one gamepad is assigned and it drops: it can be recovered&lt;/li&gt; 
   &lt;li&gt;If two gamepads are assigned, and have &lt;strong&gt;different&lt;/strong&gt; VID/PID signatures, and only one drops: it will be recovered&lt;/li&gt; 
   &lt;li&gt;If two gamepads are assigned, and have &lt;strong&gt;different&lt;/strong&gt; VID/PID signatures, and BOTH drop: both will be recovered&lt;/li&gt; 
   &lt;li&gt;If two gamepads are assigned, and have &lt;strong&gt;the same&lt;/strong&gt; VID/PID signatures, and only one drops: it will be recovered&lt;/li&gt; 
   &lt;li&gt;If two gamepads are assigned, and have &lt;strong&gt;the same&lt;/strong&gt; VID/PID signatures, and BOTH drop: &lt;strong&gt;neither&lt;/strong&gt; will be recovered, because of the ambiguity of the gamepads when they re-appear on the USB bus.&lt;/li&gt; 
   &lt;li&gt;There is currently one known edge case: if there are &lt;strong&gt;two&lt;/strong&gt; gamepads with &lt;strong&gt;the same&lt;/strong&gt; VID/PID signature plugged in, &lt;strong&gt;but only one is assigned&lt;/strong&gt;, and they BOTH drop, it's a 50-50 chance of which one will be chosen for automatic recovery to the assigned position: it is determined by whichever one is re-enumerated first by the USB bus controller.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds landscape user interface to Driver Station 
  &lt;ul&gt; 
   &lt;li&gt;New feature: practice timer with audio cues&lt;/li&gt; 
   &lt;li&gt;New feature (Control Hub only): wireless network connection strength indicator (0-5 bars)&lt;/li&gt; 
   &lt;li&gt;New feature (Control Hub only): tapping on the ping/channel display will switch to an alternate display showing radio RX dBm and link speed (tap again to switch back)&lt;/li&gt; 
   &lt;li&gt;The layout will NOT autorotate. You can switch the layout from the Driver Station's settings menu.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Breaking changes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Removes support for Android versions 4.4 through 5.1 (KitKat and Lollipop). The minSdkVersion is now 23.&lt;/li&gt; 
 &lt;li&gt;Removes the deprecated &lt;code&gt;LinearOpMode&lt;/code&gt; methods &lt;code&gt;waitOneFullHardwareCycle()&lt;/code&gt; and &lt;code&gt;waitForNextHardwareCycle()&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enhancements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Handles RS485 address of Control Hub automatically 
  &lt;ul&gt; 
   &lt;li&gt;The Control Hub is automatically given a reserved address&lt;/li&gt; 
   &lt;li&gt;Existing configuration files will continue to work&lt;/li&gt; 
   &lt;li&gt;All addresses in the range of 1-10 are still available for Expansion Hubs&lt;/li&gt; 
   &lt;li&gt;The Control Hub light will now normally be solid green, without blinking to indicate the address&lt;/li&gt; 
   &lt;li&gt;The Control Hub will not be shown on the Expansion Hub Address Change settings page&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves REV Hub firmware updater 
  &lt;ul&gt; 
   &lt;li&gt;The user can now choose between all available firmware update files&lt;/li&gt; 
   &lt;li&gt;Version 1.8.2 of the REV Hub firmware is bundled into the Robot Controller app.&lt;/li&gt; 
   &lt;li&gt;Text was added to clarify that Expansion Hubs can only be updated via USB.&lt;/li&gt; 
   &lt;li&gt;Firmware update speed was reduced to improve reliability&lt;/li&gt; 
   &lt;li&gt;Allows REV Hub firmware to be updated directly from the Manage webpage&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves log viewer on Robot Controller 
  &lt;ul&gt; 
   &lt;li&gt;Horizontal scrolling support (no longer word wrapped)&lt;/li&gt; 
   &lt;li&gt;Supports pinch-to-zoom&lt;/li&gt; 
   &lt;li&gt;Uses a monospaced font&lt;/li&gt; 
   &lt;li&gt;Error messages are highlighted&lt;/li&gt; 
   &lt;li&gt;New color scheme&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Attempts to force-stop a runaway/stuck OpMode without restarting the entire app 
  &lt;ul&gt; 
   &lt;li&gt;Not all types of runaway conditions are stoppable, but if the user code attempts to talk to hardware during the runaway, the system should be able to capture it.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Makes various tweaks to the Self Inspect screen 
  &lt;ul&gt; 
   &lt;li&gt;Renames "OS version" entry to "Android version"&lt;/li&gt; 
   &lt;li&gt;Renames "Wi-Fi Direct Name" to "Wi-Fi Name"&lt;/li&gt; 
   &lt;li&gt;Adds Control Hub OS version, when viewing the report of a Control Hub&lt;/li&gt; 
   &lt;li&gt;Hides the airplane mode entry, when viewing the report of a Control Hub&lt;/li&gt; 
   &lt;li&gt;Removes check for ZTE Speed Channel Changer&lt;/li&gt; 
   &lt;li&gt;Shows firmware version for &lt;strong&gt;all&lt;/strong&gt; Expansion and Control Hubs&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Reworks network settings portion of Manage page 
  &lt;ul&gt; 
   &lt;li&gt;All network settings are now applied with a single click&lt;/li&gt; 
   &lt;li&gt;The Wi-Fi Direct channel of phone-based Robot Controllers can now be changed from the Manage page&lt;/li&gt; 
   &lt;li&gt;Wi-Fi channels are filtered by band (2.4 vs 5 GHz) and whether they overlap with other channels&lt;/li&gt; 
   &lt;li&gt;The current Wi-Fi channel is pre-selected on phone-based Robot Controllers, and Control Hubs running OS 1.1.2 or later.&lt;/li&gt; 
   &lt;li&gt;On Control Hubs running OS 1.1.2 or later, you can choose to have the system automatically select a channel on the 5 GHz band&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves OnBotJava 
  &lt;ul&gt; 
   &lt;li&gt;New light and dark themes replace the old themes (chaos, github, chrome,...) 
    &lt;ul&gt; 
     &lt;li&gt;the new default theme is &lt;code&gt;light&lt;/code&gt; and will be used when you first update to this version&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;OnBotJava now has a tabbed editor&lt;/li&gt; 
   &lt;li&gt;Read-only offline mode&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improves function of "exit" menu item on Robot Controller and Driver Station 
  &lt;ul&gt; 
   &lt;li&gt;Now guaranteed to be fully stopped and unloaded from memory&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Shows a warning message if a LinearOpMode exists prematurely due to failure to monitor for the start condition&lt;/li&gt; 
 &lt;li&gt;Improves error message shown when the Driver Station and Robot Controller are incompatible with each other&lt;/li&gt; 
 &lt;li&gt;Driver Station OpMode Control Panel now disabled while a Restart Robot is in progress&lt;/li&gt; 
 &lt;li&gt;Disables advanced settings related to Wi-Fi Direct when the Robot Controller is a Control Hub.&lt;/li&gt; 
 &lt;li&gt;Tint phone battery icons on Driver Station when low/critical.&lt;/li&gt; 
 &lt;li&gt;Uses names "Control Hub Portal" and "Control Hub" (when appropriate) in new configuration files&lt;/li&gt; 
 &lt;li&gt;Improve I2C read performance 
  &lt;ul&gt; 
   &lt;li&gt;Very large improvement on Control Hub; up to ~2x faster with small (e.g. 6 byte) reads&lt;/li&gt; 
   &lt;li&gt;Not as apparent on Expansion Hubs connected to a phone&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Update/refresh build infrastructure 
  &lt;ul&gt; 
   &lt;li&gt;Update to 'androidx' support library from 'com.android.support:appcompat', which is end-of-life&lt;/li&gt; 
   &lt;li&gt;Update targetSdkVersion and compileSdkVersion to 28&lt;/li&gt; 
   &lt;li&gt;Update Android Studio's Android plugin to latest&lt;/li&gt; 
   &lt;li&gt;Fix reported build timestamp in 'About' screen&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Add sample illustrating manual webcam use: ConceptWebcam&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bug fixes&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/248"&gt;SkyStone issue #248&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/232"&gt;SkyStone issue #232&lt;/a&gt; and modifies bulk caching semantics to allow for cache-preserving MANUAL/AUTO transitions.&lt;/li&gt; 
 &lt;li&gt;Improves performance when REV 2M distance sensor is unplugged&lt;/li&gt; 
 &lt;li&gt;Improves readability of Toast messages on certain devices&lt;/li&gt; 
 &lt;li&gt;Allows a Driver Station to connect to a Robot Controller after another has disconnected&lt;/li&gt; 
 &lt;li&gt;Improves generation of fake serial numbers for UVC cameras which do not provide a real serial number 
  &lt;ul&gt; 
   &lt;li&gt;Previously some devices would assign such cameras a serial of &lt;code&gt;0:0&lt;/code&gt; and fail to open and start streaming&lt;/li&gt; 
   &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/638"&gt;ftc_app issue #638&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes a slew of bugs with the Vuforia camera monitor including: 
  &lt;ul&gt; 
   &lt;li&gt;Fixes bug where preview could be displayed with a wonky aspect ratio&lt;/li&gt; 
   &lt;li&gt;Fixes bug where preview could be cut off in landscape&lt;/li&gt; 
   &lt;li&gt;Fixes bug where preview got totally messed up when rotating phone&lt;/li&gt; 
   &lt;li&gt;Fixes bug where crosshair could drift off target when using webcams&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes issue in UVC driver on some devices (&lt;a href="https://github.com/ftctechnh/ftc_app/issues/681"&gt;ftc_app 681&lt;/a&gt;) if streaming was started/stopped multiple times in a row 
  &lt;ul&gt; 
   &lt;li&gt;Issue manifested as kernel panic on devices which do not have &lt;a href="https://lore.kernel.org/patchwork/patch/352400/"&gt;this kernel patch&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;On affected devices which &lt;strong&gt;do&lt;/strong&gt; have the patch, the issue was manifest as simply a failure to start streaming.&lt;/li&gt; 
   &lt;li&gt;The Tech Team believes that the root cause of the issue is a bug in the Linux kernel XHCI driver. A workaround was implemented in the SDK UVC driver.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes bug in UVC driver where often half the frames from the camera would be dropped (e.g. only 15FPS delivered during a streaming session configured for 30FPS).&lt;/li&gt; 
 &lt;li&gt;Fixes issue where TensorFlow Object Detection would show results whose confidence was lower than the minimum confidence parameter.&lt;/li&gt; 
 &lt;li&gt;Fixes a potential exploitation issue of &lt;a href="https://www.cvedetails.com/cve/CVE-2019-11358/"&gt;CVE-2019-11358&lt;/a&gt; in OnBotJava&lt;/li&gt; 
 &lt;li&gt;Fixes changing the address of an Expansion Hub with additional Expansion Hubs connected to it&lt;/li&gt; 
 &lt;li&gt;Preserves the Control Hub's network connection when "Restart Robot" is selected&lt;/li&gt; 
 &lt;li&gt;Fixes issue where device scans would fail while the Robot was restarting&lt;/li&gt; 
 &lt;li&gt;Fix RenderScript usage 
  &lt;ul&gt; 
   &lt;li&gt;Use androidx.renderscript variant: increased compatibility&lt;/li&gt; 
   &lt;li&gt;Use RenderScript in Java mode, not native: simplifies build&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fixes webcam-frame-to-bitmap conversion problem: alpha channel wasn't being initialized, only R, G, &amp;amp; B&lt;/li&gt; 
 &lt;li&gt;Fixes possible arithmetic overflow in Deadline&lt;/li&gt; 
 &lt;li&gt;Fixes deadlock in Vuforia webcam support which could cause 5-second delays when stopping OpMode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.4 (20200108-101156)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/88"&gt;SkyStone issue #88&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Adds an inspection item that notes when a robot controller (Control Hub) is using the factory default password.&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/61"&gt;SkyStone issue #61&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/142"&gt;SkyStone issue #142&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/417"&gt;ftc_app issue #417&lt;/a&gt; by adding more current and voltage monitoring capabilities for REV Hubs.&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://ftcforum.firstinspires.org/forum/ftc-technology/76217-onbotjava-crashes-robot-controller"&gt;a crash sometimes caused by OnBotJava activity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Improves OnBotJava autosave functionality &lt;a href="https://github.com/ftctechnh/ftc_app/issues/738"&gt;ftc_app #738&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes system responsiveness issue when an Expansion Hub is disconnected&lt;/li&gt; 
 &lt;li&gt;Fixes issue where IMU initialization could prevent OpModes from stopping&lt;/li&gt; 
 &lt;li&gt;Fixes issue where AndroidTextToSpeech.speak() would fail if it was called too early&lt;/li&gt; 
 &lt;li&gt;Adds telemetry.speak() methods and blocks, which cause the Driver Station (if also updated) to speak text&lt;/li&gt; 
 &lt;li&gt;Adds and improves Expansion Hub-related warnings 
  &lt;ul&gt; 
   &lt;li&gt;Improves Expansion Hub low battery warning 
    &lt;ul&gt; 
     &lt;li&gt;Displays the warning immediately after the hub reports it&lt;/li&gt; 
     &lt;li&gt;Specifies whether the condition is current or occurred temporarily during an OpMode run&lt;/li&gt; 
     &lt;li&gt;Displays which hubs reported low battery&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Displays warning when hub loses and regains power during an OpMode run 
    &lt;ul&gt; 
     &lt;li&gt;Fixes the hub's LED pattern after this condition&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Displays warning when Expansion Hub is not responding to commands 
    &lt;ul&gt; 
     &lt;li&gt;Specifies whether the condition is current or occurred temporarily during an OpMode run&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Clarifies warning when Expansion Hub is not present at startup 
    &lt;ul&gt; 
     &lt;li&gt;Specifies that this condition requires a Robot Restart before the hub can be used.&lt;/li&gt; 
     &lt;li&gt;The hub light will now accurately reflect this state&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Improves logging and reduces log spam during these conditions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Syncs the Control Hub time and timezone to a connected web browser programming the robot, if a Driver Station is not available.&lt;/li&gt; 
 &lt;li&gt;Adds bulk read functionality for REV Hubs 
  &lt;ul&gt; 
   &lt;li&gt;A bulk caching mode must be set at the Hub level with &lt;code&gt;LynxModule#setBulkCachingMode()&lt;/code&gt;. This applies to all relevant SDK hardware classes that reference that Hub.&lt;/li&gt; 
   &lt;li&gt;The following following Hub bulk caching modes are available: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;BulkCachingMode.OFF&lt;/code&gt; (default): All hardware calls operate as usual. Bulk data can read through &lt;code&gt;LynxModule#getBulkData()&lt;/code&gt; and processed manually.&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;BulkCachingMode.AUTO&lt;/code&gt;: Applicable hardware calls are served from a bulk read cache that is cleared/refreshed automatically to ensure identical commands don't hit the same cache. The cache can also be cleared manually with &lt;code&gt;LynxModule#clearBulkCache()&lt;/code&gt;, although this is not recommended.&lt;/li&gt; 
     &lt;li&gt;(advanced users) &lt;code&gt;BulkCachingMode.MANUAL&lt;/code&gt;: Same as &lt;code&gt;BulkCachingMode.AUTO&lt;/code&gt; except the cache is never cleared automatically. To avoid getting stale data, the cache must be manually cleared at the beginning of each loop body or as the user deems appropriate.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Removes PIDF Annotation values added in Rev 5.3 (to AndyMark, goBILDA and TETRIX motor configurations). 
  &lt;ul&gt; 
   &lt;li&gt;The new motor types will still be available but their Default control behavior will revert back to Rev 5.2&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds new &lt;code&gt;ConceptMotorBulkRead&lt;/code&gt; sample Opmode to demonstrate and compare Motor Bulk-Read modes for reducing I/O latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.3 (20191004-112306)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes external USB/UVC webcam support&lt;/li&gt; 
 &lt;li&gt;Makes various bugfixes and improvements to Blocks page, including but not limited to: 
  &lt;ul&gt; 
   &lt;li&gt;Many visual tweaks&lt;/li&gt; 
   &lt;li&gt;Browser zoom and window resize behave better&lt;/li&gt; 
   &lt;li&gt;Resizing the Java preview pane works better and more consistently across browsers&lt;/li&gt; 
   &lt;li&gt;The Java preview pane consistently gets scrollbars when needed&lt;/li&gt; 
   &lt;li&gt;The Java preview pane is hidden by default on phones&lt;/li&gt; 
   &lt;li&gt;Internet Explorer 11 should work&lt;/li&gt; 
   &lt;li&gt;Large dropdown lists display properly on lower res screens&lt;/li&gt; 
   &lt;li&gt;Disabled buttons are now visually identifiable as disabled&lt;/li&gt; 
   &lt;li&gt;A warning is shown if a user selects a TFOD sample, but their device is not compatible&lt;/li&gt; 
   &lt;li&gt;Warning messages in a Blocks OpMode are now visible by default.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds goBILDA 5201 and 5202 motors to Robot Configurator&lt;/li&gt; 
 &lt;li&gt;Adds PIDF Annotation values to AndyMark, goBILDA and TETRIX motor configurations. This has the effect of causing the RUN_USING_ENCODERS and RUN_TO_POSITION modes to use PIDF vs PID closed loop control on these motors. This should provide more responsive, yet stable, speed control. PIDF adds Feedforward control to the basic PID control loop. Feedforward is useful when controlling a motor's speed because it "anticipates" how much the control voltage must change to achieve a new speed set-point, rather than requiring the integrated error to change sufficiently. The PIDF values were chosen to provide responsive, yet stable, speed control on a lightly loaded motor. The more heavily a motor is loaded (drag or friction), the more noticable the PIDF improvement will be.&lt;/li&gt; 
 &lt;li&gt;Fixes startup crash on Android 10&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/712"&gt;ftc_app issue #712&lt;/a&gt; (thanks to FROGbots-4634)&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/542"&gt;ftc_app issue #542&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Allows "A" and lowercase letters when naming device through RC and DS apps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.2 (20190905-083277)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes extra-wide margins on settings activities, and placement of the new configuration button&lt;/li&gt; 
 &lt;li&gt;Adds Skystone Vuforia image target data. 
  &lt;ul&gt; 
   &lt;li&gt;Includes sample Skystone Vuforia Navigation OpModes (Java).&lt;/li&gt; 
   &lt;li&gt;Includes sample Skystone Vuforia Navigation OpModes (Blocks).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds TensorFlow inference model (.tflite) for Skystone game elements. 
  &lt;ul&gt; 
   &lt;li&gt;Includes sample Skystone TensorFlow OpModes (Java).&lt;/li&gt; 
   &lt;li&gt;Includes sample Skystone TensorFlow OpModes (Blocks).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Removes older (season-specific) sample OpModes.&lt;/li&gt; 
 &lt;li&gt;Includes 64-bit support (to comply with &lt;a href="https://android-developers.googleblog.com/2019/01/get-your-apps-ready-for-64-bit.html"&gt;Google Play requirements&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;Protects against Stuck OpModes when a Restart Robot is requested. (Thanks to FROGbots-4634) (&lt;a href="https://github.com/ftctechnh/ftc_app/issues/709"&gt;ftc_app issue #709&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Blocks related changes: 
  &lt;ul&gt; 
   &lt;li&gt;Fixes bug with blocks generated code when hardware device name is a java or javascript reserved word.&lt;/li&gt; 
   &lt;li&gt;Shows generated java code for blocks, even when hardware items are missing from the active configuration.&lt;/li&gt; 
   &lt;li&gt;Displays warning icon when outdated Vuforia and TensorFlow blocks are used (&lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/27"&gt;SkyStone issue #27&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.1 (20190820-222104)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Defines default PIDF parameters for the following motors: 
  &lt;ul&gt; 
   &lt;li&gt;REV Core Hex Motor&lt;/li&gt; 
   &lt;li&gt;REV 20:1 HD Hex Motor&lt;/li&gt; 
   &lt;li&gt;REV 40:1 HD Hex Motor&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds back button when running on a device without a system back button (such as a Control Hub)&lt;/li&gt; 
 &lt;li&gt;Allows a REV Control Hub to update the firmware on a REV Expansion Hub via USB&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/FIRST-Tech-Challenge/SkyStone/issues/9"&gt;SkyStone issue #9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fixes &lt;a href="https://github.com/ftctechnh/ftc_app/issues/715"&gt;ftc_app issue #715&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prevents extra DS User clicks by filtering based on current state.&lt;/li&gt; 
 &lt;li&gt;Prevents incorrect DS UI state changes when receiving new OpMode list from RC&lt;/li&gt; 
 &lt;li&gt;Adds support for REV Color Sensor V3&lt;/li&gt; 
 &lt;li&gt;Adds a manual-refresh DS Camera Stream for remotely viewing RC camera frames. 
  &lt;ul&gt; 
   &lt;li&gt;To show the stream on the DS, initialize &lt;strong&gt;but do not run&lt;/strong&gt; a stream-enabled opmode, select the Camera Stream option in the DS menu, and tap the image to refresh. This feature is automatically enabled when using Vuforia or TFOD—no additional RC configuration is required for typical use cases. To hide the stream, select the same menu item again.&lt;/li&gt; 
   &lt;li&gt;Note that gamepads are disabled and the selected opmode cannot be started while the stream is open as a safety precaution.&lt;/li&gt; 
   &lt;li&gt;To use custom streams, consult the API docs for &lt;code&gt;CameraStreamServer#setSource&lt;/code&gt; and &lt;code&gt;CameraStreamSource&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Adds many Star Wars sounds to RobotController resources.&lt;/li&gt; 
 &lt;li&gt;Added Skystone Sounds Chooser Sample Program.&lt;/li&gt; 
 &lt;li&gt;Switches out startup, connect chimes, and error/warning sounds for Star Wars sounds&lt;/li&gt; 
 &lt;li&gt;Updates OnBot Java to use a WebSocket for communication with the robot 
  &lt;ul&gt; 
   &lt;li&gt;The OnBot Java page no longer has to do a full refresh when a user switches from editing one file to another&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Camera Stream 
  &lt;ul&gt; 
   &lt;li&gt;The Vuforia camera stream inherits the issues present in the phone preview (namely &lt;a href="https://github.com/ftctechnh/ftc_app/issues/574"&gt;ftc_app issue #574&lt;/a&gt;). This problem does not affect the TFOD camera stream even though it receives frames from Vuforia.&lt;/li&gt; 
   &lt;li&gt;The orientation of the stream frames may not always match the phone preview. For now, these frames may be rotated manually via a custom &lt;code&gt;CameraStreamSource&lt;/code&gt; if desired.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;OnBotJava 
  &lt;ul&gt; 
   &lt;li&gt;Browser back button may not always work correctly&lt;/li&gt; 
   &lt;li&gt;It's possible for a build to be queued, but not started. The OnBot Java build console will display a warning if this occurs.&lt;/li&gt; 
   &lt;li&gt;A user might not realize they are editing a different file if the user inadvertently switches from one file to another since this switch is now seamless. The name of the currently open file is displayed in the browser tab.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 5.0 (built on 19.06.14)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for the REV Robotics Control Hub.&lt;/li&gt; 
 &lt;li&gt;Adds a Java preview pane to the Blocks editor.&lt;/li&gt; 
 &lt;li&gt;Adds a new offline export feature to the Blocks editor.&lt;/li&gt; 
 &lt;li&gt;Display Wi-Fi channel in Network circle on Driver Station.&lt;/li&gt; 
 &lt;li&gt;Adds calibration for Logitech C270&lt;/li&gt; 
 &lt;li&gt;Updates build tooling and target SDK.&lt;/li&gt; 
 &lt;li&gt;Compliance with Google's permissions infrastructure (Required after build tooling update).&lt;/li&gt; 
 &lt;li&gt;Keep Alives to mitigate the Motorola Wi-Fi scanning problem. Telemetry substitute no longer necessary.&lt;/li&gt; 
 &lt;li&gt;Improves Vuforia error reporting.&lt;/li&gt; 
 &lt;li&gt;Fixes ftctechnh/ftc_app issues 621, 713.&lt;/li&gt; 
 &lt;li&gt;Miscellaneous bug fixes and improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 4.3 (built on 18.10.31)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes missing TensorFlow-related libraries and files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 4.2 (built on 18.10.30)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes fix to avoid deadlock situation with WatchdogMonitor which could result in USB communication errors. 
  &lt;ul&gt; 
   &lt;li&gt;Comm error appeared to require that user disconnect USB cable and restart the Robot Controller app to recover.&lt;/li&gt; 
   &lt;li&gt;robotControllerLog.txt would have error messages that included the words "E RobotCore: lynx xmit lock: #### abandoning lock:"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Includes fix to correctly list the parent module address for a REV Robotics Expansion Hub in a configuration (.xml) file. 
  &lt;ul&gt; 
   &lt;li&gt;Bug in versions 4.0 and 4.1 would incorrect list the address module for a parent REV Robotics device as "1".&lt;/li&gt; 
   &lt;li&gt;If the parent module had a higher address value than the daisy-chained module, then this bug would prevent the Robot Controller from communicating with the downstream Expansion Hub.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Added requirement for ACCESS_COARSE_LOCATION to allow a Driver Station running Android Oreo to scan for Wi-Fi Direct devices.&lt;/li&gt; 
 &lt;li&gt;Added google() repo to build.gradle because aapt2 must be downloaded from the google() repository beginning with version 3.2 of the Android Gradle Plugin. 
  &lt;ul&gt; 
   &lt;li&gt;Important Note: Android Studio users will need to be connected to the Internet the first time build the ftc_app project.&lt;/li&gt; 
   &lt;li&gt;Internet connectivity is required for the first build so the appropriate files can be downloaded from the Google repository.&lt;/li&gt; 
   &lt;li&gt;Users should not need to be connected to the Internet for subsequent builds.&lt;/li&gt; 
   &lt;li&gt;This should also fix buid issue where Android Studio would complain that it "Could not find com.android.tools.lint:lint-gradle:26.1.4" (or similar).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Added support for REV Spark Mini motor controller as part of the configuration menu for a servo/PWM port on the REV Expansion Hub.&lt;/li&gt; 
 &lt;li&gt;Provide examples for playing audio files in an OpMode.&lt;/li&gt; 
 &lt;li&gt;Block Development Tool Changes 
  &lt;ul&gt; 
   &lt;li&gt;Includes a fix for a problem with the Velocity blocks that were reported in the FTC Technology forum (Blocks Programming subforum).&lt;/li&gt; 
   &lt;li&gt;Change the "Save completed successfully." message to a white color so it will contrast with a green background.&lt;/li&gt; 
   &lt;li&gt;Fixed the "Download image" feature so it will work if there are text blocks in the OpMode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Introduce support for Google's TensorFlow Lite technology for object detetion for 2018-2019 game. 
  &lt;ul&gt; 
   &lt;li&gt;TensorFlow lite can recognize Gold Mineral and Silver Mineral from 2018-2019 game.&lt;/li&gt; 
   &lt;li&gt;Example Java and Block OpModes are included to show how to determine the relative position of the gold block (left, center, right).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 4.1 (released on 18.09.24)&lt;/h2&gt; 
&lt;p&gt;Changes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix to prevent crash when deprecated configuration annotations are used.&lt;/li&gt; 
 &lt;li&gt;Change to allow FTC Robot Controller APK to be auto-updated using FIRST Global Control Hub update scripts.&lt;/li&gt; 
 &lt;li&gt;Removed samples for non supported / non legal hardware.&lt;/li&gt; 
 &lt;li&gt;Improvements to Telemetry.addData block with "text" socket.&lt;/li&gt; 
 &lt;li&gt;Updated Blocks sample OpMode list to include Rover Ruckus Vuforia example.&lt;/li&gt; 
 &lt;li&gt;Update SDK library version number.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 4.0 (released on 18.09.12)&lt;/h2&gt; 
&lt;p&gt;Changes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Initial support for UVC compatible cameras&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If UVC camera has a unique serial number, RC will detect and enumerate by serial number.&lt;/li&gt; 
   &lt;li&gt;If UVC camera lacks a unique serial number, RC will only support one camera of that type connected.&lt;/li&gt; 
   &lt;li&gt;Calibration settings for a few cameras are included (see TeamCode/src/main/res/xml/teamwebcamcalibrations.xml for details).&lt;/li&gt; 
   &lt;li&gt;User can upload calibration files from Program and Manage web interface.&lt;/li&gt; 
   &lt;li&gt;UVC cameras seem to draw a fair amount of electrical current from the USB bus. 
    &lt;ul&gt; 
     &lt;li&gt;This does not appear to present any problems for the REV Robotics Control Hub.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;This does seem to create stability problems when using some cameras with an Android phone-based Robot Controller.&lt;/li&gt; 
   &lt;li&gt;FTC Tech Team is investigating options to mitigate this issue with the phone-based Robot Controllers.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Updated sample Vuforia Navigation and VuMark OpModes to demonstrate how to use an internal phone-based camera and an external UVC webcam.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Support for improved motor control.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;REV Robotics Expansion Hub firmware 1.8 and greater will support a feed forward mechanism for closed loop motor control.&lt;/li&gt; 
   &lt;li&gt;FTC SDK has been modified to support PIDF coefficients (proportional, integral, derivative, and feed forward).&lt;/li&gt; 
   &lt;li&gt;FTC Blocks development tool modified to include PIDF programming blocks.&lt;/li&gt; 
   &lt;li&gt;Deprecated older PID-related methods and variables.&lt;/li&gt; 
   &lt;li&gt;REV's 1.8.x PIDF-related changes provide a more linear and accurate way to control a motor.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wireless&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Added 5GHz support for wireless channel changing for those devices that support it. 
    &lt;ul&gt; 
     &lt;li&gt;Tested with Moto G5 and E4 phones.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also tested with other (currently non-approved) phones such as Samsung Galaxy S8.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Improved Expansion Hub firmware update support in Robot Controller app&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Changes to make the system more robust during the firmware update process (when performed through Robot Controller app).&lt;/li&gt; 
   &lt;li&gt;User no longer has to disconnect a downstream daisy-chained Expansion Hub when updating an Expansion Hub's firmware. 
    &lt;ul&gt; 
     &lt;li&gt;If user is updating an Expansion Hub's firmware through a USB connection, he/she does not have to disconnect RS485 connection to other Expansion Hubs.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The user still must use a USB connection to update an Expansion Hub's firmware.&lt;/li&gt; 
   &lt;li&gt;The user cannot update the Expansion Hub firmware for a downstream device that is daisy chained through an RS485 connection.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If an Expansion Hub accidentally gets "bricked" the Robot Controller app is now more likely to recognize the Hub when it scans the USB bus. 
    &lt;ul&gt; 
     &lt;li&gt;Robot Controller app should be able to detect an Expansion Hub, even if it accidentally was bricked in a previous update attempt.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Robot Controller app should be able to install the firmware onto the Hub, even if if accidentally was bricked in a previous update attempt.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Resiliency&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;FTC software can detect and enable an FTDI reset feature that is available with REV Robotics v1.8 Expansion Hub firmware and greater. 
    &lt;ul&gt; 
     &lt;li&gt;When enabled, the Expansion Hub can detect if it hasn't communicated with the Robot Controller over the FTDI (USB) connection.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If the Hub hasn't heard from the Robot Controller in a while, it will reset the FTDI connection.&lt;/li&gt; 
   &lt;li&gt;This action helps system recover from some ESD-induced disruptions.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Various fixes to improve reliability of FTC software.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Blocks&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed errors with string and list indices in blocks export to java.&lt;/li&gt; 
   &lt;li&gt;Support for USB connected UVC webcams.&lt;/li&gt; 
   &lt;li&gt;Refactored optimized Blocks Vuforia code to support Rover Ruckus image targets.&lt;/li&gt; 
   &lt;li&gt;Added programming blocks to support PIDF (proportional, integral, derivative and feed forward) motor control.&lt;/li&gt; 
   &lt;li&gt;Added formatting options (under Telemetry and Miscellaneous categories) so user can set how many decimal places to display a numerical value.&lt;/li&gt; 
   &lt;li&gt;Support to play audio files (which are uploaded through Blocks web interface) on Driver Station in addition to the Robot Controller.&lt;/li&gt; 
   &lt;li&gt;Fixed bug with Download Image of Blocks feature.&lt;/li&gt; 
   &lt;li&gt;Support for REV Robotics Blinkin LED Controller.&lt;/li&gt; 
   &lt;li&gt;Support for REV Robotics 2m Distance Sensor.&lt;/li&gt; 
   &lt;li&gt;Added support for a REV Touch Sensor (no longer have to configure as a generic digital device).&lt;/li&gt; 
   &lt;li&gt;Added blocks for DcMotorEx methods. 
    &lt;ul&gt; 
     &lt;li&gt;These are enhanced methods that you can use when supported by the motor controller hardware.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The REV Robotics Expansion Hub supports these enhanced methods.&lt;/li&gt; 
   &lt;li&gt;Enhanced methods include methods to get/set motor velocity (in encoder pulses per second), get/set PIDF coefficients, etc..&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Modest Improvements in Logging&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Decrease frequency of battery checker voltage statements.&lt;/li&gt; 
   &lt;li&gt;Removed non-FTC related log statements (wherever possible).&lt;/li&gt; 
   &lt;li&gt;Introduced a "Match Logging" feature. 
    &lt;ul&gt; 
     &lt;li&gt;Under "Settings" a user can enable/disable this feature (it's disabled by default).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If enabled, user provides a "Match Number" through the Driver Station user interface (top of the screen). 
    &lt;ul&gt; 
     &lt;li&gt;The Match Number is used to create a log file specifically with log statements from that particular OpMode run.&lt;/li&gt; 
     &lt;li&gt;Match log files are stored in /sdcard/FIRST/matlogs on the Robot Controller.&lt;/li&gt; 
     &lt;li&gt;Once an OpMode run is complete, the Match Number is cleared.&lt;/li&gt; 
     &lt;li&gt;This is a convenient way to create a separate match log with statements only related to a specific OpMode run.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;New Devices&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Support for REV Robotics Blinkin LED Controller.&lt;/li&gt; 
   &lt;li&gt;Support for REV Robotics 2m Distance Sensor.&lt;/li&gt; 
   &lt;li&gt;Added configuration option for REV 20:1 HD Hex Motor.&lt;/li&gt; 
   &lt;li&gt;Added support for a REV Touch Sensor (no longer have to configure as a generic digital device).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Miscellaneous&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fixed some errors in the definitions for acceleration and velocity in our javadoc documentation.&lt;/li&gt; 
   &lt;li&gt;Added ability to play audio files on Driver Station&lt;/li&gt; 
   &lt;li&gt;When user is configuring an Expansion Hub, the LED on the Expansion Hub will change blink pattern (purple-cyan) to indicate which Hub is currently being configured.&lt;/li&gt; 
   &lt;li&gt;Renamed I2cSensorType to I2cDeviceType.&lt;/li&gt; 
   &lt;li&gt;Added an external sample OpMode that demonstrates localization using 2018-2019 (Rover Ruckus presented by QualComm) Vuforia targets.&lt;/li&gt; 
   &lt;li&gt;Added an external sample OpMode that demonstrates how to use the REV Robotics 2m Laser Distance Sensor.&lt;/li&gt; 
   &lt;li&gt;Added an external sample OpMode that demonstrates how to use the REV Robotics Blinkin LED Controller.&lt;/li&gt; 
   &lt;li&gt;Re-categorized external Java sample OpModes to "TeleOp" instead of "Autonomous".&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Initial support for UVC compatible cameras&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;UVC cameras seem to draw significant amount of current from the USB bus. 
    &lt;ul&gt; 
     &lt;li&gt;This does not appear to present any problems for the REV Robotics Control Hub.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;This does seem to create stability problems when using some cameras with an Android phone-based Robot Controller.&lt;/li&gt; 
   &lt;li&gt;FTC Tech Team is investigating options to mitigate this issue with the phone-based Robot Controllers.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;There might be a possible deadlock which causes the RC to become unresponsive when using a UVC webcam with a Nougat Android Robot Controller.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wireless&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When user selects a wireless channel, this channel does not necessarily persist if the phone is power cycled. 
    &lt;ul&gt; 
     &lt;li&gt;Tech Team is hoping to eventually address this issue in a future release.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Issue has been present since apps were introduced (i.e., it is not new with the v4.0 release).&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Wireless channel is not currently displayed for Wi-Fi Direct connections.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Miscellaneous&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The blink indication feature that shows which Expansion Hub is currently being configured does not work for a newly created configuration file. 
    &lt;ul&gt; 
     &lt;li&gt;User has to first save a newly created configuration file and then close and re-edit the file in order for blink indicator to work.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.6 (built on 17.12.18)&lt;/h2&gt; 
&lt;p&gt;Changes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blocks Changes 
  &lt;ul&gt; 
   &lt;li&gt;Uses updated Google Blockly software to allow users to edit their OpModes on Apple iOS devices (including iPad and iPhone).&lt;/li&gt; 
   &lt;li&gt;Improvement in Blocks tool to handle corrupt OpMode files.&lt;/li&gt; 
   &lt;li&gt;Autonomous OpModes should no longer get switched back to tele-op after re-opening them to be edited.&lt;/li&gt; 
   &lt;li&gt;The system can now detect type mismatches during runtime and alert the user with a message on the Driver Station.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updated javadoc documentation for setPower() method to reflect correct range of values (-1 to +1).&lt;/li&gt; 
 &lt;li&gt;Modified VuforiaLocalizerImpl to allow for user rendering of frames 
  &lt;ul&gt; 
   &lt;li&gt;Added a user-overrideable onRenderFrame() method which gets called by the class's renderFrame() method.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.5 (built on 17.10.30)&lt;/h2&gt; 
&lt;p&gt;Changes with version 3.5 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introduced a fix to prevent random OpMode stops, which can occur after the Robot Controller app has been paused and then resumed (for example, when a user temporarily turns off the display of the Robot Controller phone, and then turns the screen back on).&lt;/li&gt; 
 &lt;li&gt;Introduced a fix to prevent random OpMode stops, which were previously caused by random peer disconnect events on the Driver Station.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where log files would be closed on pause of the RC or DS, but not re-opened upon resume.&lt;/li&gt; 
 &lt;li&gt;Fixes issue with battery handler (voltage) start/stop race.&lt;/li&gt; 
 &lt;li&gt;Fixes issue where Android Studio generated OpModes would disappear from available list in certain situations.&lt;/li&gt; 
 &lt;li&gt;Fixes problem where OnBot Java would not build on REV Robotics Control Hub.&lt;/li&gt; 
 &lt;li&gt;Fixes problem where OnBot Java would not build if the date and time on the Robot Controller device was "rewound" (set to an earlier date/time).&lt;/li&gt; 
 &lt;li&gt;Improved error message on OnBot Java that occurs when renaming a file fails.&lt;/li&gt; 
 &lt;li&gt;Removed unneeded resources from android.jar binaries used by OnBot Java to reduce final size of Robot Controller app.&lt;/li&gt; 
 &lt;li&gt;Added MR_ANALOG_TOUCH_SENSOR block to Blocks Programming Tool.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.4 (built on 17.09.06)&lt;/h2&gt; 
&lt;p&gt;Changes with version 3.4 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added telemetry.update() statement for BlankLinearOpMode template.&lt;/li&gt; 
 &lt;li&gt;Renamed sample Block OpModes to be more consistent with Java samples.&lt;/li&gt; 
 &lt;li&gt;Added some additional sample Block OpModes.&lt;/li&gt; 
 &lt;li&gt;Reworded OnBot Java readme slightly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.3 (built on 17.09.04)&lt;/h2&gt; 
&lt;p&gt;This version of the software includes improves for the FTC Blocks Programming Tool and the OnBot Java Programming Tool.&lt;/p&gt; 
&lt;p&gt;Changes with verion 3.3 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Android Studio ftc_app project has been updated to use Gradle Plugin 2.3.3.&lt;/li&gt; 
 &lt;li&gt;Android Studio ftc_app project is already using gradle 3.5 distribution.&lt;/li&gt; 
 &lt;li&gt;Robot Controller log has been renamed to /sdcard/RobotControllerLog.txt (note that this change was actually introduced w/ v3.2).&lt;/li&gt; 
 &lt;li&gt;Improvements in I2C reliability.&lt;/li&gt; 
 &lt;li&gt;Optimized I2C read for REV Expansion Hub, with v1.7 firmware or greater.&lt;/li&gt; 
 &lt;li&gt;Updated all external/samples (available through OnBot and in Android project folder).&lt;/li&gt; 
 &lt;li&gt;Vuforia 
  &lt;ul&gt; 
   &lt;li&gt;Added support for VuMarks that will be used for the 2017-2018 season game.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Blocks 
  &lt;ul&gt; 
   &lt;li&gt;Update to latest Google Blockly release.&lt;/li&gt; 
   &lt;li&gt;Sample OpModes can be selected as a template when creating new OpMode.&lt;/li&gt; 
   &lt;li&gt;Fixed bug where the blocks would disappear temporarily when mouse button is held down.&lt;/li&gt; 
   &lt;li&gt;Added blocks for Range.clip and Range.scale.&lt;/li&gt; 
   &lt;li&gt;User can now disable/enable Block OpModes.&lt;/li&gt; 
   &lt;li&gt;Fix to prevent occasional Blocks deadlock.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;OnBot Java 
  &lt;ul&gt; 
   &lt;li&gt;Significant improvements with autocomplete function for OnBot Java editor.&lt;/li&gt; 
   &lt;li&gt;Sample OpModes can be selected as a template when creating new OpMode.&lt;/li&gt; 
   &lt;li&gt;Fixes and changes to complete hardware setup feature.&lt;/li&gt; 
   &lt;li&gt;Updated (and more useful) onBot welcome message.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Android Studio 
  &lt;ul&gt; 
   &lt;li&gt;After updating to the new v3.3 Android Studio project folder, if you get error messages indicating "InvalidVirtualFileAccessException" then you might need to do a File-&amp;gt;Invalidate Caches / Restart to clear the error.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;OnBot Java 
  &lt;ul&gt; 
   &lt;li&gt;Sometimes when you push the build button to build all OpModes, the RC returns an error message that the build failed. If you press the build button a second time, the build typically suceeds.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.2 (built on 17.08.02)&lt;/h2&gt; 
&lt;p&gt;This version of the software introduces the "OnBot Java" Development Tool. Similar to the FTC Blocks Development Tool, the FTC OnBot Java Development Tool allows a user to create, edit and build OpModes dynamically using only a Javascript-enabled web browser.&lt;/p&gt; 
&lt;p&gt;The OnBot Java Development Tool is an integrated development environment (IDE) that is served up by the Robot Controller. OpModes are created and edited using a Javascript-enabled browser (Google Chromse is recommended). OpModes are saved on the Robot Controller Android device directly.&lt;/p&gt; 
&lt;p&gt;The OnBot Java Development Tool provides a Java programming environment that does NOT need Android Studio.&lt;/p&gt; 
&lt;p&gt;Changes with version 3.2 include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Enhanced web-based development tools&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Introduction of OnBot Java Development Tool.&lt;/li&gt; 
   &lt;li&gt;Web-based programming and management features are "always on" (user no longer needs to put Robot Controller into programming mode).&lt;/li&gt; 
   &lt;li&gt;Web-based management interface (where user can change Robot Controller name and also easily download Robot Controller log file).&lt;/li&gt; 
   &lt;li&gt;OnBot Java, Blocks and Management features available from web based interface.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Blocks Programming Development Tool:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Changed "LynxI2cColorRangeSensor" block to "REV Color/range sensor" block.&lt;/li&gt; 
   &lt;li&gt;Fixed tooltip for ColorSensor.isLightOn block. Added blocks for ColorSensor.getNormalizedColors and LynxI2cColorRangeSensor.getNormalizedColors.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Added example OpModes for digital touch sensor and REV Robotics Color Distance sensor.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User selectable color themes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Includes many minor enhancements and fixes (too numerous to list).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auto complete function is incomplete and does not support the following (for now): 
  &lt;ul&gt; 
   &lt;li&gt;Access via &lt;em&gt;this&lt;/em&gt; keyword&lt;/li&gt; 
   &lt;li&gt;Access via &lt;em&gt;super&lt;/em&gt; keyword&lt;/li&gt; 
   &lt;li&gt;Members of the super cloass, not overridden by the class&lt;/li&gt; 
   &lt;li&gt;Any methods provided in the current class&lt;/li&gt; 
   &lt;li&gt;Inner classes&lt;/li&gt; 
   &lt;li&gt;Can't handle casted objects&lt;/li&gt; 
   &lt;li&gt;Any objects coming from an parenthetically enclosed expression&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 3.10 (built on 17.05.09)&lt;/h2&gt; 
&lt;p&gt;This version of the software provides support for the REV Robotics Expansion Hub. This version also includes improvements in the USB communication layer in an effort to enhance system resiliency. If you were using a 2.x version of the software previously, updating to version 3.1 requires that you also update your Driver Station software in addition to updating the Robot Controller software.&lt;/p&gt; 
&lt;p&gt;Also note that in version 3.10 software, the setMaxSpeed and getMaxSpeed methods are no longer available (not deprecated, they have been removed from the SDK). Also note that the new 3.x software incorporates motor profiles that a user can select as he/she configures the robot.&lt;/p&gt; 
&lt;p&gt;Changes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blocks changes 
  &lt;ul&gt; 
   &lt;li&gt;Added VuforiaTrackableDefaultListener.getPose and Vuforia.trackPose blocks.&lt;/li&gt; 
   &lt;li&gt;Added optimized blocks support for Vuforia extended tracking.&lt;/li&gt; 
   &lt;li&gt;Added atan2 block to the math category.&lt;/li&gt; 
   &lt;li&gt;Added useCompetitionFieldTargetLocations parameter to Vuforia.initialize block. If set to false, the target locations are placed at (0,0,0) with target orientation as specified in &lt;a href="https://github.com/gearsincorg/FTCVuforiaDemo/raw/master/Robot_Navigation.java"&gt;https://github.com/gearsincorg/FTCVuforiaDemo/blob/master/Robot_Navigation.java&lt;/a&gt; tutorial OpMode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Incorporates additional improvements to USB comm layer to improve system resiliency (to recover from a greater number of communication disruptions).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;Additional Notes Regarding Version 3.00 (built on 17.04.13)&lt;/p&gt; 
&lt;p&gt;In addition to the release changes listed below (see section labeled "Version 3.00 (built on 17.04.013)"), version 3.00 has the following important changes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Version 3.00 software uses a new version of the FTC Robocol (robot protocol). If you upgrade to v3.0 on the Robot Controller and/or Android Studio side, you must also upgrade the Driver Station software to match the new Robocol.&lt;/li&gt; 
 &lt;li&gt;Version 3.00 software removes the setMaxSpeed and getMaxSpeed methods from the DcMotor class. If you have an OpMode that formerly used these methods, you will need to remove the references/calls to these methods. Instead, v3.0 provides the max speed information through the use of motor profiles that are selected by the user during robot configuration.&lt;/li&gt; 
 &lt;li&gt;Version 3.00 software currently does not have a mechanism to disable extra i2c sensors. We hope to re-introduce this function with a release in the near future.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Version 3.00 (built on 17.04.13)&lt;/h2&gt; 
&lt;p&gt;*** Use this version of the software at YOUR OWN RISK!!! ***&lt;/p&gt; 
&lt;p&gt;This software is being released as an "alpha" version. Use this version at your own risk!&lt;/p&gt; 
&lt;p&gt;This pre-release software contains SIGNIFICANT changes, including changes to the Wi-Fi Direct pairing mechanism, rewrites of the I2C sensor classes, changes to the USB/FTDI layer, and the introduction of support for the REV Robotics Expansion Hub and the REV Robotics color-range-light sensor. These changes were implemented to improve the reliability and resiliency of the FTC control system.&lt;/p&gt; 
&lt;p&gt;Please note, however, that version 3.00 is considered "alpha" code. This code is being released so that the FIRST community will have an opportunity to test the new REV Expansion Hub electronics module when it becomes available in May. The developers do not recommend using this code for critical applications (i.e., competition use).&lt;/p&gt; 
&lt;p&gt;*** Use this version of the software at YOUR OWN RISK!!! ***&lt;/p&gt; 
&lt;p&gt;Changes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Major rework of sensor-related infrastructure. Includes rewriting sensor classes to implement synchronous I2C communication.&lt;/li&gt; 
 &lt;li&gt;Fix to reset Autonomous timer back to 30 seconds.&lt;/li&gt; 
 &lt;li&gt;Implementation of specific motor profiles for approved 12V motors (includes Tetrix, AndyMark, Matrix and REV models).&lt;/li&gt; 
 &lt;li&gt;Modest improvements to enhance Wi-Fi P2P pairing.&lt;/li&gt; 
 &lt;li&gt;Fixes telemetry log addition race.&lt;/li&gt; 
 &lt;li&gt;Publishes all the sources (not just a select few).&lt;/li&gt; 
 &lt;li&gt;Includes Block programming improvements 
  &lt;ul&gt; 
   &lt;li&gt;Addition of optimized Vuforia blocks.&lt;/li&gt; 
   &lt;li&gt;Auto scrollbar to projects and sounds pages.&lt;/li&gt; 
   &lt;li&gt;Fixed blocks paste bug.&lt;/li&gt; 
   &lt;li&gt;Blocks execute after while-opModeIsActive loop (to allow for cleanup before exiting OpMode).&lt;/li&gt; 
   &lt;li&gt;Added gyro integratedZValue block.&lt;/li&gt; 
   &lt;li&gt;Fixes bug with projects page for Firefox browser.&lt;/li&gt; 
   &lt;li&gt;Added IsSpeaking block to AndroidTextToSpeech.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Implements support for the REV Robotics Expansion Hub 
  &lt;ul&gt; 
   &lt;li&gt;Implements support for integral REV IMU (physically installed on I2C bus 0, uses same Bosch BNO055 9 axis absolute orientation sensor as Adafruit 9DOF abs orientation sensor). - Implements support for REV color/range/light sensor.&lt;/li&gt; 
   &lt;li&gt;Provides support to update Expansion Hub firmware through FTC SDK.&lt;/li&gt; 
   &lt;li&gt;Detects REV firmware version and records in log file.&lt;/li&gt; 
   &lt;li&gt;Includes support for REV Control Hub (note that the REV Control Hub is not yet approved for FTC use).&lt;/li&gt; 
   &lt;li&gt;Implements FTC Blocks programming support for REV Expansion Hub and sensor hardware.&lt;/li&gt; 
   &lt;li&gt;Detects and alerts when I2C device disconnect.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.62 (built on 17.01.07)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added null pointer check before calling modeToByte() in finishModeSwitchIfNecessary method for ModernRoboticsUsbDcMotorController class.&lt;/li&gt; 
 &lt;li&gt;Changes to enhance Modern Robotics USB protocol robustness.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.61 (released on 16.12.19)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blocks Programming mode changes: 
  &lt;ul&gt; 
   &lt;li&gt;Fix to correct issue when an exception was thrown because an OpticalDistanceSensor object appears twice in the hardware map (the second time as a LightSensor).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.6 (released on 16.12.16)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixes for Gyro class: 
  &lt;ul&gt; 
   &lt;li&gt;Improve (decrease) sensor refresh latency.&lt;/li&gt; 
   &lt;li&gt;fix isCalibrating issues.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Blocks Programming mode changes: 
  &lt;ul&gt; 
   &lt;li&gt;Blocks now ignores a device in the configuration xml if the name is empty. Other devices work in configuration work fine.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.5 (internal release on released on 16.12.13)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blocks Programming mode changes: 
  &lt;ul&gt; 
   &lt;li&gt;Added blocks support for AdafruitBNO055IMU.&lt;/li&gt; 
   &lt;li&gt;Added Download OpMode button to FtcBocks.html.&lt;/li&gt; 
   &lt;li&gt;Added support for copying blocks in one OpMode and pasting them in an other OpMode. The clipboard content is stored on the phone, so the programming mode server must be running.&lt;/li&gt; 
   &lt;li&gt;Modified Utilities section of the toolbox.&lt;/li&gt; 
   &lt;li&gt;In Programming Mode, display information about the active connections.&lt;/li&gt; 
   &lt;li&gt;Fixed paste location when workspace has been scrolled.&lt;/li&gt; 
   &lt;li&gt;Added blocks support for the android Accelerometer.&lt;/li&gt; 
   &lt;li&gt;Fixed issue where Blocks Upload OpMode truncated name at first dot.&lt;/li&gt; 
   &lt;li&gt;Added blocks support for Android SoundPool.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Acceleration.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for AdafruitBNO055IMU.Parameters.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for AnalogInput.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for AngularVelocity.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Color.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for ColorSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for CompassSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for CRServo.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for DigitalChannel.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for ElapsedTime.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Gamepad.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for GyroSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for IrSeekerSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for LED.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for LightSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for LinearOpMode.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for MagneticFlux.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for MatrixF.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for MrI2cCompassSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for MrI2cRangeSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for OpticalDistanceSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Orientation.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Position.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Quaternion.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Servo.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for ServoController.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Telemetry.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Temperature.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for TouchSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for UltrasonicSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for VectorF.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for Velocity.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for VoltageSensor.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for VuforiaLocalizer.Parameters.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for VuforiaTrackable.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for VuforiaTrackables.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for enums in AdafruitBNO055IMU.Parameters.&lt;/li&gt; 
   &lt;li&gt;Added type safety to blocks for AndroidAccelerometer, AndroidGyroscope, AndroidOrientation, and AndroidTextToSpeech.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.4 (released on 16.11.13)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix to avoid crashing for nonexistent resources.&lt;/li&gt; 
 &lt;li&gt;Blocks Programming mode changes: 
  &lt;ul&gt; 
   &lt;li&gt;Added blocks to support OpenGLMatrix, MatrixF, and VectorF.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support AngleUnit, AxesOrder, AxesReference, CameraDirection, CameraMonitorFeedback, DistanceUnit, and TempUnit.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support Acceleration.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support LinearOpMode.getRuntime.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support MagneticFlux and Position.&lt;/li&gt; 
   &lt;li&gt;Fixed typos.&lt;/li&gt; 
   &lt;li&gt;Made blocks for ElapsedTime more consistent with other objects.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support Quaternion, Velocity, Orientation, AngularVelocity.&lt;/li&gt; 
   &lt;li&gt;Added blocks to support VuforiaTrackables, VuforiaTrackable, VuforiaLocalizer, VuforiaTrackableDefaultListener.&lt;/li&gt; 
   &lt;li&gt;Fixed a few blocks.&lt;/li&gt; 
   &lt;li&gt;Added type checking to new blocks.&lt;/li&gt; 
   &lt;li&gt;Updated to latest blockly.&lt;/li&gt; 
   &lt;li&gt;Added default variable blocks to navigation and matrix blocks.&lt;/li&gt; 
   &lt;li&gt;Fixed toolbox entry for openGLMatrix_rotation_withAxesArgs.&lt;/li&gt; 
   &lt;li&gt;When user downloads Blocks-generated OpMode, only the .blk file is downloaded.&lt;/li&gt; 
   &lt;li&gt;When user uploads Blocks-generated OpMode (.blk file), Javascript code is auto generated.&lt;/li&gt; 
   &lt;li&gt;Added DbgLog support.&lt;/li&gt; 
   &lt;li&gt;Added logging when a blocks file is read/written.&lt;/li&gt; 
   &lt;li&gt;Fixed bug to properly render blocks even if missing devices from configuration file.&lt;/li&gt; 
   &lt;li&gt;Added support for additional characters (not just alphanumeric) for the block file names (for download and upload).&lt;/li&gt; 
   &lt;li&gt;Added support for OpMode flavor (“Autonomous” or “TeleOp”) and group.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Changes to Samples to prevent tutorial issues.&lt;/li&gt; 
 &lt;li&gt;Incorporated suggested changes from public pull 216 (“Replace .. paths”).&lt;/li&gt; 
 &lt;li&gt;Remove Servo Glitches when robot stopped.&lt;/li&gt; 
 &lt;li&gt;if user hits “Cancels” when editing a configuration file, clears the unsaved changes and reverts to original unmodified configuration.&lt;/li&gt; 
 &lt;li&gt;Added log info to help diagnose why the Robot Controller app was terminated (for example, by watch dog function).&lt;/li&gt; 
 &lt;li&gt;Added ability to transfer log from the controller.&lt;/li&gt; 
 &lt;li&gt;Fixed inconsistency for AngularVelocity&lt;/li&gt; 
 &lt;li&gt;Limit unbounded growth of data for telemetry. If user does not call telemetry.update() for LinearOpMode in a timely manner, data added for telemetry might get lost if size limit is exceeded.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.35 (released on 16.10.06)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blockly programming mode - Removed unnecesary idle() call from blocks for new project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.30 (released on 16.10.05)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blockly programming mode: 
  &lt;ul&gt; 
   &lt;li&gt;Mechanism added to save Blockly OpModes from Programming Mode Server onto local device&lt;/li&gt; 
   &lt;li&gt;To avoid clutter, blocks are displayed in categorized folders&lt;/li&gt; 
   &lt;li&gt;Added support for DigitalChannel&lt;/li&gt; 
   &lt;li&gt;Added support for ModernRoboticsI2cCompassSensor&lt;/li&gt; 
   &lt;li&gt;Added support for ModernRoboticsI2cRangeSensor&lt;/li&gt; 
   &lt;li&gt;Added support for VoltageSensor&lt;/li&gt; 
   &lt;li&gt;Added support for AnalogInput&lt;/li&gt; 
   &lt;li&gt;Added support for AnalogOutput&lt;/li&gt; 
   &lt;li&gt;Fix for CompassSensor setMode block&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Vuforia 
  &lt;ul&gt; 
   &lt;li&gt;Fix deadlock / make camera data available while Vuforia is running.&lt;/li&gt; 
   &lt;li&gt;Update to Vuforia 6.0.117 (recommended by Vuforia and Google to close security loophole).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Fix for autonomous 30 second timer bug (where timer was in effect, even though it appeared to have timed out).&lt;/li&gt; 
 &lt;li&gt;opModeIsActive changes to allow cleanup after OpMode is stopped (with enforced 2 second safety timeout).&lt;/li&gt; 
 &lt;li&gt;Fix to avoid reading i2c twice.&lt;/li&gt; 
 &lt;li&gt;Updated sample OpModes.&lt;/li&gt; 
 &lt;li&gt;Improved logging and fixed intermittent freezing.&lt;/li&gt; 
 &lt;li&gt;Added digital I/O sample.&lt;/li&gt; 
 &lt;li&gt;Cleaned up device names in sample OpModes to be consistent with Pushbot guide.&lt;/li&gt; 
 &lt;li&gt;Fix to allow use of IrSeekerSensorV3.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.20 (released on 16.09.08)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for Modern Robotics Compass Sensor.&lt;/li&gt; 
 &lt;li&gt;Support for Modern Robotics Range Sensor.&lt;/li&gt; 
 &lt;li&gt;Revise device names for Pushbot templates to match the names used in Pushbot guide.&lt;/li&gt; 
 &lt;li&gt;Fixed bug so that IrSeekerSensorV3 device is accessible as IrSeekerSensor in hardwareMap.&lt;/li&gt; 
 &lt;li&gt;Modified computer vision code to require an individual Vuforia license (per legal requirement from PTC).&lt;/li&gt; 
 &lt;li&gt;Minor fixes.&lt;/li&gt; 
 &lt;li&gt;Blockly enhancements: 
  &lt;ul&gt; 
   &lt;li&gt;Support for Voltage Sensor.&lt;/li&gt; 
   &lt;li&gt;Support for Analog Input.&lt;/li&gt; 
   &lt;li&gt;Support for Analog Output.&lt;/li&gt; 
   &lt;li&gt;Support for Light Sensor.&lt;/li&gt; 
   &lt;li&gt;Support for Servo Controller.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.10 (released on 16.09.03)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for Adafruit IMU.&lt;/li&gt; 
 &lt;li&gt;Improvements to ModernRoboticsI2cGyro class 
  &lt;ul&gt; 
   &lt;li&gt;Block on reset of z axis.&lt;/li&gt; 
   &lt;li&gt;isCalibrating() returns true while gyro is calibration.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Updated sample gyro program.&lt;/li&gt; 
 &lt;li&gt;Blockly enhancements 
  &lt;ul&gt; 
   &lt;li&gt;support for android.graphics.Color.&lt;/li&gt; 
   &lt;li&gt;added support for ElapsedTime.&lt;/li&gt; 
   &lt;li&gt;improved look and legibility of blocks.&lt;/li&gt; 
   &lt;li&gt;support for compass sensor.&lt;/li&gt; 
   &lt;li&gt;support for ultrasonic sensor.&lt;/li&gt; 
   &lt;li&gt;support for IrSeeker.&lt;/li&gt; 
   &lt;li&gt;support for LED.&lt;/li&gt; 
   &lt;li&gt;support for color sensor.&lt;/li&gt; 
   &lt;li&gt;support for CRServo&lt;/li&gt; 
   &lt;li&gt;prompt user to configure robot before using programming mode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Provides ability to disable audio cues.&lt;/li&gt; 
 &lt;li&gt;various bug fixes and improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Version 2.00 (released on 16.08.19)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;This is the new release for the upcoming 2016-2017 FIRST Tech Challenge Season.&lt;/li&gt; 
 &lt;li&gt;Channel change is enabled in the FTC Robot Controller app for Moto G 2nd and 3rd Gen phones.&lt;/li&gt; 
 &lt;li&gt;Users can now use annotations to register/disable their OpModes.&lt;/li&gt; 
 &lt;li&gt;Changes in the Android SDK, JDK and build tool requirements (minsdk=19, java 1.7, build tools 23.0.3).&lt;/li&gt; 
 &lt;li&gt;Standardized units in analog input.&lt;/li&gt; 
 &lt;li&gt;Cleaned up code for existing analog sensor classes.&lt;/li&gt; 
 &lt;li&gt;setChannelMode and getChannelMode were REMOVED from the DcMotorController class. This is important - we no longer set the motor modes through the motor controller.&lt;/li&gt; 
 &lt;li&gt;setMode and getMode were added to the DcMotor class.&lt;/li&gt; 
 &lt;li&gt;ContinuousRotationServo class has been added to the FTC SDK.&lt;/li&gt; 
 &lt;li&gt;Range.clip() method has been overloaded so it can support this operation for int, short and byte integers.&lt;/li&gt; 
 &lt;li&gt;Some changes have been made (new methods added) on how a user can access items from the hardware map.&lt;/li&gt; 
 &lt;li&gt;Users can now set the zero power behavior for a DC motor so that the motor will brake or float when power is zero.&lt;/li&gt; 
 &lt;li&gt;Prototype Blockly Programming Mode has been added to FTC Robot Controller. Users can place the Robot Controller into this mode, and then use a device (such as a laptop) that has a Javascript enabled browser to write Blockly-based OpModes directly onto the Robot Controller.&lt;/li&gt; 
 &lt;li&gt;Users can now configure the robot remotely through the FTC Driver Station app.&lt;/li&gt; 
 &lt;li&gt;Android Studio project supports Android Studio 2.1.x and compile SDK Version 23 (Marshmallow).&lt;/li&gt; 
 &lt;li&gt;Vuforia Computer Vision SDK integrated into FTC SDK. Users can use sample vision targets to get localization information on a standard FTC field.&lt;/li&gt; 
 &lt;li&gt;Project structure has been reorganized so that there is now a TeamCode package that users can use to place their local/custom OpModes into this package.&lt;/li&gt; 
 &lt;li&gt;Inspection function has been integrated into the FTC Robot Controller and Driver Station Apps (Thanks Team HazMat… 9277 &amp;amp; 10650!).&lt;/li&gt; 
 &lt;li&gt;Audio cues have been incorporated into FTC SDK.&lt;/li&gt; 
 &lt;li&gt;Swap mechanism added to FTC Robot Controller configuration activity. For example, if you have two motor controllers on a robot, and you misidentified them in your configuration file, you can use the Swap button to swap the devices within the configuration file (so you do not have to manually re-enter in the configuration info for the two devices).&lt;/li&gt; 
 &lt;li&gt;Fix mechanism added to all user to replace an electronic module easily. For example, suppose a servo controller dies on your robot. You replace the broken module with a new module, which has a different serial number from the original servo controller. You can use the Fix button to automatically reconfigure your configuration file to use the serial number of the new module.&lt;/li&gt; 
 &lt;li&gt;Improvements made to fix resiliency and responsiveness of the system.&lt;/li&gt; 
 &lt;li&gt;For LinearOpMode the user now must for a telemetry.update() to update the telemetry data on the driver station. This update() mechanism ensures that the driver station gets the updated data properly and at the same time.&lt;/li&gt; 
 &lt;li&gt;The Auto Configure function of the Robot Controller is now template based. If there is a commonly used robot configuration, a template can be created so that the Auto Configure mechanism can be used to quickly configure a robot of this type.&lt;/li&gt; 
 &lt;li&gt;The logic to detect a runaway OpMode (both in the LinearOpMode and OpMode types) and to abort the run, then auto recover has been improved/implemented.&lt;/li&gt; 
 &lt;li&gt;Fix has been incorporated so that Logitech F310 gamepad mappings will be correct for Marshmallow users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 16.07.08&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For the ftc_app project, the gradle files have been modified to support Android Studio 2.1.x.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 16.03.30&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For the MIT App Inventor, the design blocks have new icons that better represent the function of each design component.&lt;/li&gt; 
 &lt;li&gt;Some changes were made to the shutdown logic to ensure the robust shutdown of some of our USB services.&lt;/li&gt; 
 &lt;li&gt;A change was made to LinearOpMode so as to allow a given instance to be executed more than once, which is required for the App Inventor.&lt;/li&gt; 
 &lt;li&gt;Javadoc improved/updated.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 16.03.09&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Changes made to make the FTC SDK synchronous (significant change!) 
  &lt;ul&gt; 
   &lt;li&gt;waitOneFullHardwareCycle() and waitForNextHardwareCycle() are no longer needed and have been deprecated.&lt;/li&gt; 
   &lt;li&gt;runOpMode() (for a LinearOpMode) is now decoupled from the system's hardware read/write thread.&lt;/li&gt; 
   &lt;li&gt;loop() (for an OpMode) is now decoupled from the system's hardware read/write thread.&lt;/li&gt; 
   &lt;li&gt;Methods are synchronous.&lt;/li&gt; 
   &lt;li&gt;For example, if you call setMode(DcMotorController.RunMode.RESET_ENCODERS) for a motor, the encoder is guaranteed to be reset when the method call is complete.&lt;/li&gt; 
   &lt;li&gt;For legacy module (NXT compatible), user no longer has to toggle between read and write modes when reading from or writing to a legacy device.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Changes made to enhance reliability/robustness during ESD event.&lt;/li&gt; 
 &lt;li&gt;Changes made to make code thread safe.&lt;/li&gt; 
 &lt;li&gt;Debug keystore added so that user-generated robot controller APKs will all use the same signed key (to avoid conflicts if a team has multiple developer laptops for example).&lt;/li&gt; 
 &lt;li&gt;Firmware version information for Modern Robotics modules are now logged.&lt;/li&gt; 
 &lt;li&gt;Changes made to improve USB comm reliability and robustness.&lt;/li&gt; 
 &lt;li&gt;Added support for voltage indicator for legacy (NXT-compatible) motor controllers.&lt;/li&gt; 
 &lt;li&gt;Changes made to provide auto stop capabilities for OpModes. 
  &lt;ul&gt; 
   &lt;li&gt;A LinearOpMode class will stop when the statements in runOpMode() are complete. User does not have to push the stop button on the driver station.&lt;/li&gt; 
   &lt;li&gt;If an OpMode is stopped by the driver station, but there is a run away/uninterruptible thread persisting, the app will log an error message then force itself to crash to stop the runaway thread.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Driver Station UI modified to display lowest measured voltage below current voltage (12V battery).&lt;/li&gt; 
 &lt;li&gt;Driver Station UI modified to have color background for current voltage (green=good, yellow=caution, red=danger, extremely low voltage).&lt;/li&gt; 
 &lt;li&gt;javadoc improved (edits and additional classes).&lt;/li&gt; 
 &lt;li&gt;Added app build time to About activity for driver station and robot controller apps.&lt;/li&gt; 
 &lt;li&gt;Display local IP addresses on Driver Station About activity.&lt;/li&gt; 
 &lt;li&gt;Added I2cDeviceSynchImpl.&lt;/li&gt; 
 &lt;li&gt;Added I2cDeviceSync interface.&lt;/li&gt; 
 &lt;li&gt;Added seconds() and milliseconds() to ElapsedTime for clarity.&lt;/li&gt; 
 &lt;li&gt;Added getCallbackCount() to I2cDevice.&lt;/li&gt; 
 &lt;li&gt;Added missing clearI2cPortActionFlag.&lt;/li&gt; 
 &lt;li&gt;Added code to create log messages while waiting for LinearOpMode shutdown.&lt;/li&gt; 
 &lt;li&gt;Fix so Wi-Fi Direct Config activity will no longer launch multiple times.&lt;/li&gt; 
 &lt;li&gt;Added the ability to specify an alternate i2c address in software for the Modern Robotics gyro.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 16.02.09&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Improved battery checker feature so that voltage values get refreshed regularly (every 250 msec) on Driver Station (DS) user interface.&lt;/li&gt; 
 &lt;li&gt;Improved software so that Robot Controller (RC) is much more resilient and “self-healing” to USB disconnects: 
  &lt;ul&gt; 
   &lt;li&gt;If user attempts to start/restart RC with one or more module missing, it will display a warning but still start up.&lt;/li&gt; 
   &lt;li&gt;When running an OpMode, if one or more modules gets disconnected, the RC &amp;amp; DS will display warnings,and robot will keep on working in spite of the missing module(s).&lt;/li&gt; 
   &lt;li&gt;If a disconnected module gets physically reconnected the RC will auto detect the module and the user will regain control of the recently connected module.&lt;/li&gt; 
   &lt;li&gt;Warning messages are more helpful (identifies the type of module that’s missing plus its USB serial number).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Code changes to fix the null gamepad reference when users try to reference the gamepads in the init() portion of their OpMode.&lt;/li&gt; 
 &lt;li&gt;NXT light sensor output is now properly scaled. Note that teams might have to readjust their light threshold values in their OpModes.&lt;/li&gt; 
 &lt;li&gt;On DS user interface, gamepad icon for a driver will disappear if the matching gamepad is disconnected or if that gamepad gets designated as a different driver.&lt;/li&gt; 
 &lt;li&gt;Robot Protocol (ROBOCOL) version number info is displayed in About screen on RC and DS apps.&lt;/li&gt; 
 &lt;li&gt;Incorporated a display filter on pairing screen to filter out devices that don’t use the “
  &lt;team number&gt;
   -“ format. This filter can be turned off to show all Wi-Fi Direct devices.
  &lt;/team&gt;&lt;/li&gt; 
 &lt;li&gt;Updated text in License file.&lt;/li&gt; 
 &lt;li&gt;Fixed formatting error in OpticalDistanceSensor.toString().&lt;/li&gt; 
 &lt;li&gt;Fixed issue on with a blank (“”) device name that would disrupt Wi-Fi Direct Pairing.&lt;/li&gt; 
 &lt;li&gt;Made a change so that the Wi-Fi info and battery info can be displayed more quickly on the DS upon connecting to RC.&lt;/li&gt; 
 &lt;li&gt;Improved javadoc generation.&lt;/li&gt; 
 &lt;li&gt;Modified code to make it easier to support language localization in the future.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 16.01.04&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updated compileSdkVersion for apps&lt;/li&gt; 
 &lt;li&gt;Prevent Wi-Fi from entering power saving mode&lt;/li&gt; 
 &lt;li&gt;removed unused import from driver station&lt;/li&gt; 
 &lt;li&gt;Corrrected "Dead zone" joystick code.&lt;/li&gt; 
 &lt;li&gt;LED.getDeviceName and .getConnectionInfo() return null&lt;/li&gt; 
 &lt;li&gt;apps check for ROBOCOL_VERSION mismatch&lt;/li&gt; 
 &lt;li&gt;Fix for Telemetry also has off-by-one errors in its data string sizing / short size limitations error&lt;/li&gt; 
 &lt;li&gt;User telemetry output is sorted.&lt;/li&gt; 
 &lt;li&gt;added formatting variants to DbgLog and RobotLog APIs&lt;/li&gt; 
 &lt;li&gt;code modified to allow for a long list of OpMode names.&lt;/li&gt; 
 &lt;li&gt;changes to improve thread safety of RobocolDatagramSocket&lt;/li&gt; 
 &lt;li&gt;Fix for "missing hardware leaves robot controller disconnected from driver station" error&lt;/li&gt; 
 &lt;li&gt;fix for "fast tapping of Init/Start causes problems" (toast is now only instantiated on UI thread).&lt;/li&gt; 
 &lt;li&gt;added some log statements for thread life cycle.&lt;/li&gt; 
 &lt;li&gt;moved gamepad reset logic inside of initActiveOpMode() for robustness&lt;/li&gt; 
 &lt;li&gt;changes made to mitigate risk of race conditions on public methods.&lt;/li&gt; 
 &lt;li&gt;changes to try and flag when Wi-Fi Direct name contains non-printable characters.&lt;/li&gt; 
 &lt;li&gt;fix to correct race condition between .run() and .close() in ReadWriteRunnableStandard.&lt;/li&gt; 
 &lt;li&gt;updated FTDI driver&lt;/li&gt; 
 &lt;li&gt;made ReadWriteRunnableStanard interface public.&lt;/li&gt; 
 &lt;li&gt;fixed off-by-one errors in Command constructor&lt;/li&gt; 
 &lt;li&gt;moved specific hardware implmentations into their own package.&lt;/li&gt; 
 &lt;li&gt;moved specific gamepad implemnatations to the hardware library.&lt;/li&gt; 
 &lt;li&gt;changed LICENSE file to new BSD version.&lt;/li&gt; 
 &lt;li&gt;fixed race condition when shutting down Modern Robotics USB devices.&lt;/li&gt; 
 &lt;li&gt;methods in the ColorSensor classes have been synchronized.&lt;/li&gt; 
 &lt;li&gt;corrected isBusy() status to reflect end of motion.&lt;/li&gt; 
 &lt;li&gt;corrected "back" button keycode.&lt;/li&gt; 
 &lt;li&gt;the notSupported() method of the GyroSensor class was changed to protected (it should not be public).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 15.11.04.001&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added Support for Modern Robotics Gyro.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;The GyroSensor class now supports the MR Gyro Sensor.&lt;/li&gt; 
 &lt;li&gt;Users can access heading data (about Z axis)&lt;/li&gt; 
 &lt;li&gt;Users can also access raw gyro data (X, Y, &amp;amp; Z axes).&lt;/li&gt; 
 &lt;li&gt;Example MRGyroTest.java OpMode included.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Improved error messages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;More descriptive error messages for exceptions in user code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updated DcMotor API&lt;/li&gt; 
 &lt;li&gt;Enable read mode on new address in setI2cAddress&lt;/li&gt; 
 &lt;li&gt;Fix so that driver station app resets the gamepads when switching OpModes.&lt;/li&gt; 
 &lt;li&gt;USB-related code changes to make USB comm more responsive and to display more explicit error messages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix so that USB will recover properly if the USB bus returns garbage data.&lt;/li&gt; 
 &lt;li&gt;Fix USB initializtion race condition.&lt;/li&gt; 
 &lt;li&gt;Better error reporting during FTDI open.&lt;/li&gt; 
 &lt;li&gt;More explicit messages during USB failures.&lt;/li&gt; 
 &lt;li&gt;Fixed bug so that USB device is closed if event loop teardown method was not called.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fixed timer UI issue&lt;/li&gt; 
 &lt;li&gt;Fixed duplicate name UI bug (Legacy Module configuration).&lt;/li&gt; 
 &lt;li&gt;Fixed race condition in EventLoopManager.&lt;/li&gt; 
 &lt;li&gt;Fix to keep references stable when updating gamepad.&lt;/li&gt; 
 &lt;li&gt;For legacy Matrix motor/servo controllers removed necessity of appending "Motor" and "Servo" to controller names.&lt;/li&gt; 
 &lt;li&gt;Updated HT color sensor driver to use constants from ModernRoboticsUsbLegacyModule class.&lt;/li&gt; 
 &lt;li&gt;Updated MR color sensor driver to use constants from ModernRoboticsUsbDeviceInterfaceModule class.&lt;/li&gt; 
 &lt;li&gt;Correctly handle I2C Address change in all color sensors&lt;/li&gt; 
 &lt;li&gt;Updated/cleaned up OpModes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updated comments in LinearI2cAddressChange.java example OpMode.&lt;/li&gt; 
 &lt;li&gt;Replaced the calls to "setChannelMode" with "setMode" (to match the new of the DcMotor method).&lt;/li&gt; 
 &lt;li&gt;Removed K9AutoTime.java OpMode.&lt;/li&gt; 
 &lt;li&gt;Added MRGyroTest.java OpMode (demonstrates how to use MR Gyro Sensor).&lt;/li&gt; 
 &lt;li&gt;Added MRRGBExample.java OpMode (demonstrates how to use MR Color Sensor).&lt;/li&gt; 
 &lt;li&gt;Added HTRGBExample.java OpMode (demonstrates how to use HT legacy color sensor).&lt;/li&gt; 
 &lt;li&gt;Added MatrixControllerDemo.java (demonstrates how to use legacy Matrix controller).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ul&gt; 
 &lt;li&gt;Updated javadoc documentation.&lt;/li&gt; 
 &lt;li&gt;Updated release .apk files for Robot Controller and Driver Station apps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 15.10.06.002&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Added support for Legacy Matrix 9.6V motor/servo controller.&lt;/li&gt; 
 &lt;li&gt;Cleaned up build.gradle file.&lt;/li&gt; 
 &lt;li&gt;Minor UI and bug fixes for driver station and robot controller apps.&lt;/li&gt; 
 &lt;li&gt;Throws error if Ultrasonic sensor (NXT) is not configured for legacy module port 4 or 5.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release 15.08.03.001&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;New user interfaces for FTC Driver Station and FTC Robot Controller apps.&lt;/li&gt; 
 &lt;li&gt;An init() method is added to the OpMode class. 
  &lt;ul&gt; 
   &lt;li&gt;For this release, init() is triggered right before the start() method.&lt;/li&gt; 
   &lt;li&gt;Eventually, the init() method will be triggered when the user presses an "INIT" button on driver station.&lt;/li&gt; 
   &lt;li&gt;The init() and loop() methods are now required (i.e., need to be overridden in the user's OpMode).&lt;/li&gt; 
   &lt;li&gt;The start() and stop() methods are optional.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;A new LinearOpMode class is introduced. 
  &lt;ul&gt; 
   &lt;li&gt;Teams can use the LinearOpMode mode to create a linear (not event driven) program model.&lt;/li&gt; 
   &lt;li&gt;Teams can use blocking statements like Thread.sleep() within a linear OpMode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The API for the Legacy Module and Core Device Interface Module have been updated. 
  &lt;ul&gt; 
   &lt;li&gt;Support for encoders with the Legacy Module is now working.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;The hardware loop has been updated for better performance.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>