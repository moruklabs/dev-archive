<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Mon, 08 Sep 2025 01:38:13 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Vector-Wangel/XLeRobot</title>
      <link>https://github.com/Vector-Wangel/XLeRobot</link>
      <description>&lt;p&gt;XLeRobot: Practical Dual-Arm Mobile Home Robot for $660&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;XLeRobot ü§ñ&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/lang-en-blue.svg?sanitize=true" alt="en" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/README_CN.md"&gt;&lt;img src="https://img.shields.io/badge/lang-%E4%B8%AD%E6%96%87-brown.svg?sanitize=true" alt="‰∏≠Êñá" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt; &lt;img width="1725" height="1140" alt="front" src="https://github.com/user-attachments/assets/f9c454ee-2c46-42b4-a5d7-88834a1c95ab" /&gt; &lt;/a&gt; 
&lt;h2&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="Apache License" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/VectorWang2"&gt;&lt;img src="https://img.shields.io/twitter/follow/VectorWang?style=social" alt="Twitter/X" /&gt;&lt;/a&gt; &lt;a href="https://xlerobot.readthedocs.io/en/latest/"&gt;&lt;img src="https://img.shields.io/badge/docs-passing-brightgreen.svg?sanitize=true" alt="Docs status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/bjZveEUh6F"&gt;&lt;img src="https://img.shields.io/badge/Discord-XLeRobot-7289da?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;üöÄ Bringing Embodied AI to Everyone - Cheaper Than an iPhone! üì±&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;üíµ Starts from $660 cost and ‚è∞ &amp;lt;4hrs total assembly time!!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Built upon the giants: &lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;, &lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100/SO-101&lt;/a&gt;, &lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, &lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/17e31979-bd5e-4790-be70-566ea8bb181e" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/96ff4a3e-3402-47a2-bc6b-b45137ee3fdd" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/f6d52acc-bc8d-46f6-b3cd-8821f0306a7f" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/59086300-3e6f-4a3c-b5e0-db893eeabc0c" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/4ddbc0ff-ca42-4ad0-94c6-4e0f4047fd01" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7abc890e-9c9c-4983-8b25-122573028de5" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e74a602b-0146-49c4-953d-3fa3b038a7f7" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d8090b15-97f3-4abc-98c8-208ae79894d5" width="250" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8b54adc3-d61b-42a0-8985-ea28f2e8f64c" width="250" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üíµ Total Cost üíµ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Cost excludes 3D printing, tools, shipping, and taxes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Price (Buy all the parts yourself)&lt;/th&gt; 
   &lt;th&gt;US&lt;/th&gt; 
   &lt;th&gt;EU&lt;/th&gt; 
   &lt;th&gt;CN&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Basic&lt;/strong&gt; (use your laptop, single RGB head cam)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~$660&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~‚Ç¨680&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~¬•3999&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üë Stereo dual-eye RGB head cam&lt;/td&gt; 
   &lt;td&gt;+$30&lt;/td&gt; 
   &lt;td&gt;+‚Ç¨30&lt;/td&gt; 
   &lt;td&gt;+¬•199&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;+ RasberryPi&lt;/td&gt; 
   &lt;td&gt;+$79&lt;/td&gt; 
   &lt;td&gt;+‚Ç¨79&lt;/td&gt; 
   &lt;td&gt;+¬•399&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üë RealSense RGBD head cam&lt;/td&gt; 
   &lt;td&gt;+$220&lt;/td&gt; 
   &lt;td&gt;+‚Ç¨230&lt;/td&gt; 
   &lt;td&gt;+¬•1499&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üì∞ News&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;2025-08-30: XLeRobot 0.3.0 Release with final outfit touch up and household chores showcase demos. Assembly kit ready for purchase soon, stay tuned!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-30: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Control XLeRobot in real life&lt;/a&gt; with &lt;strong&gt;keyboard/Xbox controller/Switch joycon&lt;/strong&gt; in the wild anywhere. All bluetooth, no wifi needed and zero latency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/de8f50ad-a370-406c-97fb-fc01638d5624" alt="rea" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-08: &lt;a href="https://xlerobot.readthedocs.io/en/latest/simulation/index.html"&gt;&lt;strong&gt;Simulation&lt;/strong&gt;&lt;/a&gt; with updated urdfs, control scripts (support Quest3 VR, keyboard, Xbox controller, switch joycon), support for new hardware and cameras, RL environment. Get started in 15 min.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/68b77bea-fdcf-4f42-9cf0-efcf1b188358" alt="vr" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-07-01: &lt;a href="https://xlerobot.readthedocs.io/en/latest/index.html"&gt;&lt;strong&gt;Documentation&lt;/strong&gt; website&lt;/a&gt; out for more orgainized tutorials, demos and resources.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;2025-06-13: &lt;a href="https://xlerobot.readthedocs.io"&gt;&lt;strong&gt;XLeRobot 0.2.0&lt;/strong&gt;&lt;/a&gt; hardware setup, the 1st version fully capable for autonomous household tasks, starts from 660$.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Get Started üöÄ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you are totally new to programming, please spend at least a day to get yourself familiar with basic Python, Ubuntu and Github (with the help of Google and AI). At least you should know how to setup ubuntu system, git clone, pip install, use intepreters (VS Code, Cursor, Pycharm, etc.) and directly run commands in the terminals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;üíµ &lt;strong&gt;Buy your parts&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/material.html"&gt;Bill of Materials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñ®Ô∏è &lt;strong&gt;Print your stuff&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/3d.html"&gt;3D printing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî® &lt;del&gt;Avengers&lt;/del&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/hardware/getting_started/assemble.html"&gt;&lt;strong&gt;Assemble&lt;/strong&gt;!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;Software&lt;/strong&gt;: &lt;a href="https://xlerobot.readthedocs.io/en/latest/software/index.html"&gt;Get your robot moving!&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;üëã Want to contribute to XLeRobot?&lt;/strong&gt; Please refer to &lt;a href="https://raw.githubusercontent.com/Vector-Wangel/XLeRobot/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidance on how to get involved!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Main Contributors&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lzhuoyi.github.io/Zhuoyi_Lu.github.io/"&gt;Zhuoyi Lu&lt;/a&gt;: RL sim2real deploy, teleop on real robot (Xbox, VR, Joycon)&lt;/li&gt; 
 &lt;li&gt;Nicole Yue: Documentation website setup&lt;/li&gt; 
 &lt;li&gt;Yuesong Wang: Mujoco simulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is just a small brick in the pyramid, made possible by&amp;nbsp;&lt;a href="https://github.com/huggingface/lerobot"&gt;LeRobot&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/TheRobotStudio/SO-ARM100"&gt;SO-100&lt;/a&gt;,&amp;nbsp;&lt;a href="https://github.com/SIGRobotics-UIUC/LeKiwi"&gt;Lekiwi&lt;/a&gt;, and&amp;nbsp;&lt;a href="https://github.com/timqian/bambot"&gt;Bambot&lt;/a&gt;. Thanks to all the talented contributors behind these detailed and professional projects.&lt;/p&gt; 
&lt;p&gt;Looking forward to collaborating with anyone interested in contributing to this project!&lt;/p&gt; 
&lt;h2&gt;About me&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://vector-wangel.github.io/"&gt;Gaotian/Vector Wang&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;I am a CS graduate student at Rice University &lt;a href="https://robotpilab.github.io/"&gt;RobotPi Lab&lt;/a&gt;, focusing on robust object manipulation, where we propse virtual cages and funnels and physics-aware world models to close the Sim2real gap and achieve robust manipulation under uncertainties. One of my papers, Caging in Time, has recently been accepted by International Journal of Robotics Research (IJRR).&lt;/p&gt; 
&lt;p&gt;I built XLeRobot as a personal hobby to instantiate my research theory, also to provide a low-cost platform for people who are interested in robotics and embodied AI to work with.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://star-history.com/#Vector-Wangel/XLeRobot&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=Vector-Wangel/XLeRobot&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025xlerobot,
    author = {Wang, Gaotian and Lu, Zhuoyi},
    title = {XLeRobot: A Practical Low-cost Household Dual-Arm Mobile Robot Design for General Manipulation},
    howpublished = "\url{https://github.com/Vector-Wangel/XLeRobot}",
    year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;---&lt;img src="https://github.com/user-attachments/assets/682ef049-bb42-4b50-bf98-74d6311e774d" alt="Generated Image August 27, 2025 - 4_58PM" /&gt;&lt;/p&gt; 
&lt;h2&gt;ü™ß Disclaimer ü™ß&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you build, buy, or develop a XLeRobot based on this repo, you will be fully responsible for all the physical and mental damages it does to you or others.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>emcie-co/parlant</title>
      <link>https://github.com/emcie-co/parlant</link>
      <description>&lt;p&gt;LLM agents built for control. Designed for real-world use. Deployed in minutes.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true" /&gt; 
  &lt;img alt="Parlant - AI Agent Framework" src="https://github.com/emcie-co/parlant/raw/develop/docs/LogoTransparentDark.png?raw=true" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://www.parlant.io/" target="_blank"&gt;üåê Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.parlant.io/docs/quickstart/installation" target="_blank"&gt;‚ö° Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/duxWqxKk6J" target="_blank"&gt;üí¨ Discord&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.parlant.io/docs/quickstart/examples" target="_blank"&gt;üìñ Examples&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://zdoc.app/de/emcie-co/parlant"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/emcie-co/parlant"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/emcie-co/parlant"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/emcie-co/parlant"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/emcie-co/parlant"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/emcie-co/parlant"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/emcie-co/parlant"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/emcie-co/parlant"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://pypi.org/project/parlant/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/parlant?color=blue" /&gt;&lt;/a&gt; &lt;img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue" /&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/badge/license-Apache%202.0-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/duxWqxKk6J"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1312378700993663007?color=7289da&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/emcie-co/parlant?style=social" /&gt; &lt;/p&gt; 
 &lt;a href="https://trendshift.io/repositories/12768" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/12768" alt="Trending on TrendShift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéØ The Problem Every AI Developer Faces&lt;/h2&gt; 
&lt;p&gt;You build an AI agent. It works great in testing. Then real users start talking to it and...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ùå It ignores your carefully crafted system prompts&lt;/li&gt; 
 &lt;li&gt;‚ùå It hallucinates responses in critical moments&lt;/li&gt; 
 &lt;li&gt;‚ùå It can't handle edge cases consistently&lt;/li&gt; 
 &lt;li&gt;‚ùå Each conversation feels like a roll of the dice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sound familiar?&lt;/strong&gt; You're not alone. This is the #1 pain point for developers building production AI agents.&lt;/p&gt; 
&lt;h2&gt;‚ö° The Solution: Stop Fighting Prompts, Teach Principles&lt;/h2&gt; 
&lt;p&gt;Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, &lt;strong&gt;Parlant ensures it&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Traditional approach: Cross your fingers ü§û
system_prompt = "You are a helpful assistant. Please follow these 47 rules..."

# Parlant approach: Ensured compliance ‚úÖ
await agent.create_guideline(
    condition="Customer asks about refunds",
    action="Check order status first to see if eligible",
    tools=[check_order_status],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/journeys"&gt;Journeys&lt;/a&gt;&lt;/strong&gt;: Define clear customer journeys and how your agent should respond at each step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/guidelines"&gt;Behavioral Guidelines&lt;/a&gt;&lt;/strong&gt;: Easily craft agent behavior; Parlant will match the relevant elements contextually.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/tools"&gt;Tool Use&lt;/a&gt;&lt;/strong&gt;: Attach external APIs, data fetchers, or backend services to specific interaction events.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/glossary"&gt;Domain Adaptation&lt;/a&gt;&lt;/strong&gt;: Teach your agent domain-specific terminology and craft personalized responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/canned-responses"&gt;Canned Responses&lt;/a&gt;&lt;/strong&gt;: Use response templates to eliminate hallucinations and guarantee style consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/advanced/explainability"&gt;Explainability&lt;/a&gt;&lt;/strong&gt;: Understand why and when each guideline was matched and followed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;üöÄ Get Your Agent Running in 60 Seconds&lt;/h2&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install parlant
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&amp;gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f"Sunny, 72¬∞F in {city}")

@p.tool
async def get_datetime(context: p.ToolContext) -&amp;gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name="WeatherBot",
            description="Helpful weather assistant"
        )

        # Have the agent's context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name="current-datetime", tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition="User asks about weather",
            action="Get current weather and provide a friendly response with suggestions",
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # üéâ Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your agent is running with ensured rule-following behavior.&lt;/p&gt; 
&lt;h2&gt;üé¨ See It In Action&lt;/h2&gt; 
&lt;img alt="Parlant Demo" src="https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true" width="100%" /&gt; 
&lt;h2&gt;üî• Why Developers Are Switching to Parlant&lt;/h2&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;üèóÔ∏è &lt;strong&gt;Traditional AI Frameworks&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;‚ö° &lt;strong&gt;Parlant&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Write complex system prompts&lt;/li&gt; 
     &lt;li&gt;Hope the LLM follows them&lt;/li&gt; 
     &lt;li&gt;Debug unpredictable behaviors&lt;/li&gt; 
     &lt;li&gt;Scale by prompt engineering&lt;/li&gt; 
     &lt;li&gt;Cross fingers for reliability&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Define rules in natural language&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ensured&lt;/strong&gt; rule compliance&lt;/li&gt; 
     &lt;li&gt;Predictable, consistent behavior&lt;/li&gt; 
     &lt;li&gt;Scale by adding guidelines&lt;/li&gt; 
     &lt;li&gt;Production-ready from day one&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üéØ Perfect For Your Use Case&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Financial Services&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;E-commerce&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Legal Tech&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Compliance-first design&lt;/td&gt; 
    &lt;td align="center"&gt;HIPAA-ready agents&lt;/td&gt; 
    &lt;td align="center"&gt;Customer service at scale&lt;/td&gt; 
    &lt;td align="center"&gt;Precise legal guidance&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Built-in risk management&lt;/td&gt; 
    &lt;td align="center"&gt;Patient data protection&lt;/td&gt; 
    &lt;td align="center"&gt;Order processing automation&lt;/td&gt; 
    &lt;td align="center"&gt;Document review assistance&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üõ†Ô∏è Enterprise-Grade Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üß≠ Conversational Journeys&lt;/strong&gt; - Lead the customer step-by-step to a goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Dynamic Guideline Matching&lt;/strong&gt; - Context-aware rule application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Reliable Tool Integration&lt;/strong&gt; - APIs, databases, external services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Conversation Analytics&lt;/strong&gt; - Deep insights into agent behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Iterative Refinement&lt;/strong&gt; - Continuously improve agent responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ°Ô∏è Built-in Guardrails&lt;/strong&gt; - Prevent hallucination and off-topic responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üì± React Widget&lt;/strong&gt; - &lt;a href="https://github.com/emcie-co/parlant-chat-react"&gt;Drop-in chat UI for any web app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Full Explainability&lt;/strong&gt; - Understand every decision your agent makes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìà Join 8,000+ Developers Building Better AI&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Companies using Parlant:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Financial institutions ‚Ä¢ Healthcare providers ‚Ä¢ Legal firms ‚Ä¢ E-commerce platforms&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#emcie-co/parlant&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=emcie-co/parlant&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü What Developers Are Saying&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy."&lt;/em&gt; &lt;strong&gt;‚Äî Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üèÉ‚Äç‚ôÇÔ∏è Quick Start Paths&lt;/h2&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üéØ I want to test it myself&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/installation"&gt;‚Üí 5-minute quickstart&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üõ†Ô∏è I want to see an example&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/examples"&gt;‚Üí Healthcare agent example&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üöÄ I want to get involved&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;‚Üí Join our Discord community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help from the team and community&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;&lt;a href="https://parlant.io/docs/quickstart/installation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and examples&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;&lt;a href="https://github.com/emcie-co/parlant/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;üìß &lt;strong&gt;&lt;a href="https://parlant.io/contact"&gt;Direct Support&lt;/a&gt;&lt;/strong&gt; - Direct line to our engineering team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Use it anywhere, including commercial projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Ready to build AI agents that actually work?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star this repo&lt;/strong&gt; ‚Ä¢ üöÄ &lt;strong&gt;&lt;a href="https://parlant.io/"&gt;Try Parlant now&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Join Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with ‚ù§Ô∏è by the team at &lt;a href="https://emcie.co"&gt;Emcie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>pathwaycom/pathway</title>
      <link>https://github.com/pathwaycom/pathway</link>
      <description>&lt;p&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://pathway.com/"&gt; &lt;img src="https://pathway.com/logo-light.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;a href="https://trendshift.io/repositories/10388" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10388" alt="pathwaycom%2Fpathway | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg?sanitize=true" alt="ubuntu" /&gt; &lt;br /&gt; &lt;/a&gt;&lt;a href="https://github.com/pathwaycom/pathway/actions/workflows/release.yml"&gt; &lt;img src="https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Last release" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://badge.fury.io/py/pathway.svg?sanitize=true" alt="PyPI version" height="18" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/pathway"&gt;&lt;img src="https://static.pepy.tech/badge/pathway" alt="PyPI downloads" height="18" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt; &lt;img src="https://img.shields.io/badge/license-BSL-green" alt="License: BSL" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/pathway"&gt; &lt;img src="https://img.shields.io/discord/1042405378304004156?logo=discord" alt="chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=pathway_com"&gt; &lt;img src="https://img.shields.io/twitter/follow/pathwaycom" alt="follow on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/company/pathway"&gt; &lt;img src="https://img.shields.io/badge/pathway-0077B5?style=social&amp;amp;logo=linkedin" alt="follow on LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dylanhogg/awesome-python/raw/main/README.md"&gt; &lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome Python" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pathway"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF" alt="Pathway Guru" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#deployment"&gt;Deployment&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#resources"&gt;Documentation and Support&lt;/a&gt; | &lt;a href="https://pathway.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/pathwaycom/pathway/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Pathway&lt;a id="pathway"&gt; Live Data Framework&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pathway.com"&gt;Pathway&lt;/a&gt; is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/p&gt; 
&lt;p&gt;Pathway comes with an &lt;strong&gt;easy-to-use Python API&lt;/strong&gt;, allowing you to seamlessly integrate your favorite Python ML libraries. Pathway code is versatile and robust: &lt;strong&gt;you can use it in both development and production environments, handling both batch and streaming data effectively&lt;/strong&gt;. The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.&lt;/p&gt; 
&lt;p&gt;Pathway is powered by a &lt;strong&gt;scalable Rust engine&lt;/strong&gt; based on Differential Dataflow and performs incremental computation. Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations. All the pipeline is kept in memory and can be easily deployed with &lt;strong&gt;Docker and Kubernetes&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Pathway with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For any questions, you will find the community and team behind the project &lt;a href="https://discord.com/invite/pathway"&gt;on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Use-cases and templates&lt;/h2&gt; 
&lt;p&gt;Ready to see what Pathway can do?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pathway.com/developers/templates"&gt;Try one of our easy-to-run examples&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!&lt;/p&gt; 
&lt;h3&gt;Event processing and real-time analytics pipelines&lt;/h3&gt; 
&lt;p&gt;With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It's the ideal solution for a wide range of data processing pipelines, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/kafka-etl"&gt;Showcase: Real-time ETL.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/realtime-log-monitoring"&gt;Showcase: Event-driven pipelines with alerting.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/linear_regression_with_kafka/"&gt;Showcase: Realtime analytics.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming"&gt;Docs: Switch from batch to streaming.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;AI Pipelines&lt;/h3&gt; 
&lt;p&gt;Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/overview"&gt;LLM xpack documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Don't hesitate to try one of our runnable examples featuring LLM tooling. You can find such examples &lt;a href="https://pathway.com/developers/user-guide/llm-xpack/llm-examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/unstructured-to-structured/"&gt;Template: Unstructured data to SQL on-the-fly.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/private-rag-ollama-mistral"&gt;Template: Private RAG with Ollama and Mistral AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/adaptive-rag"&gt;Template: Adaptive RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pathway.com/developers/templates/multimodal-rag"&gt;Template: Multimodal RAG with gpt-4o&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A wide range of connectors&lt;/strong&gt;: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless and stateful transformations&lt;/strong&gt;: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistence&lt;/strong&gt;: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the "at least once" consistency while the enterprise version provides the "exactly once" consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Rust engine&lt;/strong&gt;: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM helpers&lt;/strong&gt;: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;a id="installation"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Pathway requires Python 3.10 or above.&lt;/p&gt; 
&lt;p&gt;You can install the current release of Pathway using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install -U pathway
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚ö†Ô∏è Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.&lt;/p&gt; 
&lt;h3&gt;Example: computing the sum of positive values in real time.&lt;a id="example"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  "./input/",
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&amp;gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, "output.jsonl")

# Run the computation
pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run Pathway &lt;a href="https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing"&gt;in Google Colab&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can find more examples &lt;a href="https://github.com/pathwaycom/pathway/tree/main/examples"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;a id="deployment"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Locally&lt;a id="running-pathway-locally"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To use Pathway, you only need to import it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pathway as pw
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pw.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then run your Pathway project (say, &lt;code&gt;main.py&lt;/code&gt;) just like a normal Python script: &lt;code&gt;$ python main.py&lt;/code&gt;. Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages.&lt;/p&gt; 
&lt;img src="https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png" width="1326" alt="Pathway dashboard" /&gt; 
&lt;p&gt;Alternatively, you can use the pathway'ish version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pathway natively supports multithreading. To launch your application with 3 threads, you can do as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pathway spawn --threads 3 python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To jumpstart a Pathway project, you can use our &lt;a href="https://github.com/pathwaycom/cookiecutter-pathway"&gt;cookiecutter template&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;a id="docker"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can easily run Pathway using docker.&lt;/p&gt; 
&lt;h4&gt;Pathway image&lt;/h4&gt; 
&lt;p&gt;You can use the &lt;a href="https://hub.docker.com/r/pathwaycom/pathway"&gt;Pathway docker image&lt;/a&gt;, using a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ "python", "./your-script.py" ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then build and run the Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run a single Python script&lt;/h4&gt; 
&lt;p&gt;When dealing with single-file projects, creating a full-fledged &lt;code&gt;Dockerfile&lt;/code&gt; might seem unnecessary. In such scenarios, you can execute a Python script directly using the Pathway Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;docker run -it --rm --name my-pathway-app -v "$PWD":/app pathwaycom/pathway:latest python my-pathway-app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python docker image&lt;/h4&gt; 
&lt;p&gt;You can also use a standard Python image and install Pathway using pip with a Dockerfile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-dockerfile"&gt;FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD ["python", "-u", "pathway-script.py"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Kubernetes and cloud&lt;a id="k8s"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Docker containers are ideally suited for deployment on the cloud with Kubernetes. If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise. Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics. It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.&lt;/p&gt; 
&lt;p&gt;You can easily deploy Pathway using services like Render: see &lt;a href="https://pathway.com/developers/user-guide/deployment/render-deploy/"&gt;how to deploy Pathway in a few clicks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested, don't hesitate to &lt;a href="mailto:contact@pathway.com"&gt;contact us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;a id="performance"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF's in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).&lt;/p&gt; 
&lt;p&gt;If you are curious, here are &lt;a href="https://github.com/pathwaycom/pathway-benchmarks"&gt;some benchmarks to play with&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png" width="1326" alt="WordCount Graph" /&gt; 
&lt;h2&gt;Documentation and Support&lt;a id="resources"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The entire documentation of Pathway is available at &lt;a href="https://pathway.com/developers/user-guide/introduction/welcome"&gt;pathway.com/developers/&lt;/a&gt;, including the &lt;a href="https://pathway.com/developers/api-docs/pathway"&gt;API Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have any question, don't hesitate to &lt;a href="https://github.com/pathwaycom/pathway/issues"&gt;open an issue on GitHub&lt;/a&gt;, join us on &lt;a href="https://discord.com/invite/pathway"&gt;Discord&lt;/a&gt;, or send us an email at &lt;a href="mailto:contact@pathway.com"&gt;contact@pathway.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pathway is distributed on a &lt;a href="https://github.com/pathwaycom/pathway/raw/main/LICENSE.txt"&gt;BSL 1.1 License&lt;/a&gt; which allows for unlimited non-commercial use, as well as use of the Pathway package &lt;a href="https://pathway.com/license/"&gt;for most commercial purposes&lt;/a&gt;, free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some &lt;a href="https://github.com/pathwaycom"&gt;public repos&lt;/a&gt; which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines&lt;a id="contribution-guidelines"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don't hesitate to engage with Pathway's &lt;a href="https://discord.gg/pathway"&gt;Discord community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md"&gt;English&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;Portugu√™s do Brasil&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;◊¢◊ë◊®◊ô◊™&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;Espa√±ol&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;T√ºrk√ße&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;ti·∫øng Vi·ªát&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md"&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns"&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns"&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer"&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer"&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql"&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design"&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://leetcode.com/discuss/career/229177/My-System-Design-Template"&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono"&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/"&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=k-Yaq8AHlFA"&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/"&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.jscape.com/blog/load-balancing-algorithms"&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html"&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html"&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/"&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href="https://www.consul.io/intro/getting-started/checks.html"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction"&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers"&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html"&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/"&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database"&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://adayinthelifeof.nl/2011/02/06/memcache-internals/"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database"&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neo4j.com/"&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb"&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_user(self, user_id):
    user = cache.get("user.{0}", user_id)
    if user is None:
        user = db.query("SELECT * FROM users WHERE user_id = {0}", user_id)
        if user is not None:
            key = "user.{0}".format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://memcached.org/"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;set_user(12345, {"foo":"bar"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def set_user(user_id, values):
    user = db.query("UPDATE Users WHERE id = {0}", user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.celeryproject.org/en/stable/"&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law"&gt;Little's law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol"&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking"&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control"&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/"&gt;memcached&lt;/a&gt; server. &lt;a href="https://en.wikipedia.org/wiki/Connection_pool"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/"&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/"&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/raw/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br /&gt;{&lt;br /&gt;"personid": "1234"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person‚Äôs items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a person‚Äôs items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br /&gt;{&lt;br /&gt;"personid": "1234";&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456";&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br /&gt;{&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt; &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/"&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege"&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two"&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" /&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407"&gt;queue.acm.org&lt;/a&gt;&lt;br /&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search"&gt;stackexchange.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/"&gt;ardendertat.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch"&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/"&gt;code.google.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://neil.fraser.name/writing/sync/"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html"&gt;hulu.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;highscalability.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf"&gt;erlang-factory.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/"&gt;michael-noll.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake"&gt;blog.twitter.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br /&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html"&gt;indieflashblog.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf"&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/b1e4t2k2KJY"&gt;Jane Street&lt;/a&gt;&lt;br /&gt;&lt;a href="https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/"&gt;Golang Implementation&lt;/a&gt;&lt;br /&gt;&lt;a href="http://bhomnick.net/building-a-simple-limit-order-in-go/"&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/google-architecture"&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br /&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br /&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf"&gt;TAO: Facebook‚Äôs distributed data store for the social graph&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook‚Äôs photo storage&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Timelines at scale&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8"&gt;YouTube scalability&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/youtube-architecture"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://nerds.airbnb.com/"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://word.bitly.com/"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://blog.cloudera.com/"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tech.dropbox.com/"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/q/quoraengineering"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.ebaytechblog.com/"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.evernote.com/tech/"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://codeascraft.com/"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.facebook.com/Engineering"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://code.flickr.net/"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.foursquare.com/"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.blog/category/engineering"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.groupon.com/"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.heroku.com/"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.microsoft.com/"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://techblog.netflix.com/"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/paypal-engineering"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.redditblog.com/"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.engineering/"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://labs.spotify.com/"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stripe.com/blog/engineering"&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.twilio.com/engineering"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://eng.uber.com/"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dancres.github.io/Pages/"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you‚Äôll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta ‚Äì expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin‚Äôs YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it‚Äôll be featured through agents on the platform. It‚Äôs a tall order, but we have big plans for the oTTomator community, and we‚Äôre confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2024 Live Agent Studio. All rights reserved.&lt;br /&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Alvin9999/new-pac</title>
      <link>https://github.com/Alvin9999/new-pac</link>
      <description>&lt;p&gt;ÁøªÂ¢ô-ÁßëÂ≠¶‰∏äÁΩë„ÄÅËá™Áî±‰∏äÁΩë„ÄÅÂÖçË¥πÁßëÂ≠¶‰∏äÁΩë„ÄÅÂÖçË¥πÁøªÂ¢ô„ÄÅfanqiang„ÄÅÊ≤πÁÆ°youtube/ËßÜÈ¢ë‰∏ãËΩΩ„ÄÅËΩØ‰ª∂„ÄÅVPN„ÄÅ‰∏ÄÈîÆÁøªÂ¢ôÊµèËßàÂô®Ôºåvps‰∏ÄÈîÆÊê≠Âª∫ÁøªÂ¢ôÊúçÂä°Âô®ËÑöÊú¨/ÊïôÁ®ãÔºåÂÖçË¥πshadowsocks/ss/ssr/v2ray/goflywayË¥¶Âè∑/ËäÇÁÇπÔºåÁøªÂ¢ôÊ¢ØÂ≠êÔºåÁîµËÑë„ÄÅÊâãÊú∫„ÄÅiOS„ÄÅÂÆâÂçì„ÄÅwindows„ÄÅMac„ÄÅLinux„ÄÅË∑ØÁî±Âô®ÁøªÂ¢ô„ÄÅÁßëÂ≠¶‰∏äÁΩë„ÄÅyoutubeËßÜÈ¢ë‰∏ãËΩΩ„ÄÅyoutubeÊ≤πÁÆ°ÈïúÂÉè/ÂÖçÁøªÂ¢ôÁΩëÁ´ô„ÄÅÁæéÂå∫apple idÂÖ±‰∫´Ë¥¶Âè∑„ÄÅÁøªÂ¢ô-ÁßëÂ≠¶‰∏äÁΩë-Ê¢ØÂ≠ê&lt;/p&gt;&lt;hr&gt;&lt;p&gt;ÁßëÂ≠¶‰∏äÁΩë-ÁøªÂ¢ô„ÄÅÂÖçË¥πÁøªÂ¢ô„ÄÅÂÖçË¥πÁßëÂ≠¶‰∏äÁΩë„ÄÅËΩØ‰ª∂„ÄÅVPN„ÄÅ‰∏ÄÈîÆÁøªÂ¢ôÊµèËßàÂô®Ôºåvps‰∏ÄÈîÆÊê≠Âª∫ÁøªÂ¢ôÊúçÂä°Âô®ËÑöÊú¨/ÊïôÁ®ãÔºåÂÖçË¥πshadowsocks/ss/ssr/v2ray/goflywayË¥¶Âè∑/ËäÇÁÇπÔºåÂÖçË¥πËá™Áî±‰∏äÁΩë„ÄÅfanqiang„ÄÅÁøªÂ¢ôÊ¢ØÂ≠êÔºåÁîµËÑë„ÄÅÊâãÊú∫„ÄÅiOS„ÄÅÂÆâÂçì„ÄÅwindows„ÄÅMac„ÄÅLinux„ÄÅË∑ØÁî±Âô®ÁøªÂ¢ô„ÄÅyoutubeËßÜÈ¢ë‰∏ãËΩΩ„ÄÅyoutubeÊ≤πÁÆ°ÈïúÂÉè/ÂÖçÁøªÂ¢ôÁΩëÁ´ô„ÄÅÁæéÂå∫apple idÂÖ±‰∫´Ë¥¶Âè∑&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Alvin9999/new-pac/wiki"&gt;https://github.com/Alvin9999/new-pac/wiki&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Âåó‰∫¨Êó∂Èó¥2025Âπ¥09Êúà08Êó•09ÁÇπ04ÂàÜÊõ¥Êñ∞„ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lllyasviel/stable-diffusion-webui-forge</title>
      <link>https://github.com/lllyasviel/stable-diffusion-webui-forge</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion WebUI Forge&lt;/h1&gt; 
&lt;p&gt;Stable Diffusion WebUI Forge is a platform on top of &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Stable Diffusion WebUI&lt;/a&gt; (based on &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;) to make development easier, optimize resource management, speed up inference, and study experimental features.&lt;/p&gt; 
&lt;p&gt;The name "Forge" is inspired from "Minecraft Forge". This project is aimed at becoming SD WebUI's Forge.&lt;/p&gt; 
&lt;p&gt;Forge is currently based on SD-WebUI 1.10.1 at &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/commit/82a973c04367123ae98bd9abdf80d9eda9b910e2"&gt;this commit&lt;/a&gt;. (Because original SD-WebUI is almost static now, Forge will sync with original WebUI every 90 days, or when important fixes.)&lt;/p&gt; 
&lt;p&gt;News are moved to this link: &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/raw/main/NEWS.md"&gt;Click here to see the News section&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Quick List&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/853"&gt;Gradio 4 UI Must Read (TLDR: You need to use RIGHT MOUSE BUTTON to move canvas!)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/981"&gt;Flux Tutorial (BitsandBytes Models, NF4, "GPU Weight", "Offload Location", "Offload Method", etc)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1050"&gt;Flux Tutorial 2 (Seperated Full Models, GGUF, Technically Correct Comparison between GGUF and NF4, etc)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1754"&gt;Forge Extension List and Extension Replacement List (Temporary)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1038"&gt;How to make LoRAs more precise on low-bit models; How to Skip" Patching LoRAs"; How to only load LoRA one time rather than each generation; How to report LoRAs that do not work&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1181"&gt;Report Flux Performance Problems (TLDR: DO NOT set "GPU Weight" too high! Lower "GPU Weight" solves 99% problems!)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1474"&gt;How to solve "Connection errored out" / "Press anykey to continue ..." / etc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1224#discussioncomment-10384104"&gt;(Save Flux BitsandBytes UNet/Checkpoint)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/854"&gt;LayerDiffuse Transparent Image Editing&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/932"&gt;Tell us what is missing in ControlNet Integrated&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/1286"&gt;(Policy) Soft Advertisement Removal Policy&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(Flux BNB NF4 / GGUF Q8_0/Q5_0/Q5_1/Q4_0/Q4_1 are all natively supported with GPU weight slider and Quene/Async Swap toggle and swap location toggle. All Flux BNB NF4 / GGUF Q8_0/Q5_0/Q4_0 have LoRA support.)&lt;/p&gt; 
&lt;h1&gt;Installing Forge&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Just use this one-click installation package (with git and python included).&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z"&gt;&amp;gt;&amp;gt;&amp;gt; Click Here to Download One-Click Package (CUDA 12.1 + Pytorch 2.3.1) &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Some other CUDA/Torch Versions:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch231.7z"&gt;Forge with CUDA 12.1 + Pytorch 2.3.1&lt;/a&gt; &amp;lt;- &lt;strong&gt;Recommended&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu124_torch24.7z"&gt;Forge with CUDA 12.4 + Pytorch 2.4&lt;/a&gt; &amp;lt;- &lt;strong&gt;Fastest&lt;/strong&gt;, but MSVC may be broken, xformers may not work&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/releases/download/latest/webui_forge_cu121_torch21.7z"&gt;Forge with CUDA 12.1 + Pytorch 2.1&lt;/a&gt; &amp;lt;- the previously used old environments&lt;/p&gt; 
&lt;p&gt;After you download, you uncompress, use &lt;code&gt;update.bat&lt;/code&gt; to update, and use &lt;code&gt;run.bat&lt;/code&gt; to run.&lt;/p&gt; 
&lt;p&gt;Note that running &lt;code&gt;update.bat&lt;/code&gt; is important, otherwise you may be using a previous version with potential bugs unfixed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/stable-diffusion-webui-forge/assets/19834515/c49bd60d-82bd-4086-9859-88d472582b94" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Advanced Install&lt;/h3&gt; 
&lt;p&gt;If you are proficient in Git and you want to install Forge as another branch of SD-WebUI, please see &lt;a href="https://github.com/continue-revolution/sd-webui-animatediff/raw/forge/master/docs/how-to-use.md#you-have-a1111-and-you-know-git"&gt;here&lt;/a&gt;. In this way, you can reuse all SD checkpoints and all extensions you installed previously in your OG SD-WebUI, but you should know what you are doing.&lt;/p&gt; 
&lt;p&gt;If you know what you are doing, you can also install Forge using same method as SD-WebUI. (Install Git, Python, Git Clone the forge repo &lt;code&gt;https://github.com/lllyasviel/stable-diffusion-webui-forge.git&lt;/code&gt; and then run webui-user.bat).&lt;/p&gt; 
&lt;h3&gt;Previous Versions&lt;/h3&gt; 
&lt;p&gt;You can download previous versions &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/discussions/849"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Forge Status&lt;/h1&gt; 
&lt;p&gt;Based on manual test one-by-one:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Last Test&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Basic Diffusion&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Memory Management System&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LoRAs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Preprocessors&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All ControlNets&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All IP-Adapters&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Instant-IDs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Reference-only Methods&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;All Integrated Extensions&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Popular Extensions (Adetailer, etc)&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gradio 4 UIs&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gradio 4 Forge Canvas&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LoRA/Checkpoint Selection UI for Gradio 4&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Photopea/OpenposeEditor/etc for ControlNet&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Wacom 128 level touch pressure support for Canvas&lt;/td&gt; 
   &lt;td&gt;Normal&lt;/td&gt; 
   &lt;td&gt;2024 July 15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Microsoft Surface touch pressure support for Canvas&lt;/td&gt; 
   &lt;td&gt;Broken, pending fix&lt;/td&gt; 
   &lt;td&gt;2024 July 29&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ControlNets (Union)&lt;/td&gt; 
   &lt;td&gt;Not implemented yet, pending implementation&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ControlNets (Flux)&lt;/td&gt; 
   &lt;td&gt;Not implemented yet, pending implementation&lt;/td&gt; 
   &lt;td&gt;2024 Aug 26&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API endpoints (txt2img, img2img, etc)&lt;/td&gt; 
   &lt;td&gt;Normal, but pending improved Flux support&lt;/td&gt; 
   &lt;td&gt;2024 Aug 29&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OFT LoRAs&lt;/td&gt; 
   &lt;td&gt;Broken, pending fix&lt;/td&gt; 
   &lt;td&gt;2024 Sep 9&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Feel free to open issue if anything is broken and I will take a look every several days. If I do not update this "Forge Status" then it means I cannot reproduce any problem. In that case, fresh re-install should help most.&lt;/p&gt; 
&lt;h1&gt;UnetPatcher&lt;/h1&gt; 
&lt;p&gt;Below are self-supported &lt;strong&gt;single file&lt;/strong&gt; of all codes to implement FreeU V2.&lt;/p&gt; 
&lt;p&gt;See also &lt;code&gt;extension-builtin/sd_forge_freeu/scripts/forge_freeu.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch
import gradio as gr

from modules import scripts


def Fourier_filter(x, threshold, scale):
    # FFT
    x_freq = torch.fft.fftn(x.float(), dim=(-2, -1))
    x_freq = torch.fft.fftshift(x_freq, dim=(-2, -1))

    B, C, H, W = x_freq.shape
    mask = torch.ones((B, C, H, W), device=x.device)

    crow, ccol = H // 2, W // 2
    mask[..., crow - threshold:crow + threshold, ccol - threshold:ccol + threshold] = scale
    x_freq = x_freq * mask

    # IFFT
    x_freq = torch.fft.ifftshift(x_freq, dim=(-2, -1))
    x_filtered = torch.fft.ifftn(x_freq, dim=(-2, -1)).real

    return x_filtered.to(x.dtype)


def patch_freeu_v2(unet_patcher, b1, b2, s1, s2):
    model_channels = unet_patcher.model.diffusion_model.config["model_channels"]
    scale_dict = {model_channels * 4: (b1, s1), model_channels * 2: (b2, s2)}
    on_cpu_devices = {}

    def output_block_patch(h, hsp, transformer_options):
        scale = scale_dict.get(h.shape[1], None)
        if scale is not None:
            hidden_mean = h.mean(1).unsqueeze(1)
            B = hidden_mean.shape[0]
            hidden_max, _ = torch.max(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_min, _ = torch.min(hidden_mean.view(B, -1), dim=-1, keepdim=True)
            hidden_mean = (hidden_mean - hidden_min.unsqueeze(2).unsqueeze(3)) / (hidden_max - hidden_min).unsqueeze(2).unsqueeze(3)

            h[:, :h.shape[1] // 2] = h[:, :h.shape[1] // 2] * ((scale[0] - 1) * hidden_mean + 1)

            if hsp.device not in on_cpu_devices:
                try:
                    hsp = Fourier_filter(hsp, threshold=1, scale=scale[1])
                except:
                    print("Device", hsp.device, "does not support the torch.fft.")
                    on_cpu_devices[hsp.device] = True
                    hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)
            else:
                hsp = Fourier_filter(hsp.cpu(), threshold=1, scale=scale[1]).to(hsp.device)

        return h, hsp

    m = unet_patcher.clone()
    m.set_model_output_block_patch(output_block_patch)
    return m


class FreeUForForge(scripts.Script):
    sorting_priority = 12  # It will be the 12th item on UI.

    def title(self):
        return "FreeU Integrated"

    def show(self, is_img2img):
        # make this extension visible in both txt2img and img2img tab.
        return scripts.AlwaysVisible

    def ui(self, *args, **kwargs):
        with gr.Accordion(open=False, label=self.title()):
            freeu_enabled = gr.Checkbox(label='Enabled', value=False)
            freeu_b1 = gr.Slider(label='B1', minimum=0, maximum=2, step=0.01, value=1.01)
            freeu_b2 = gr.Slider(label='B2', minimum=0, maximum=2, step=0.01, value=1.02)
            freeu_s1 = gr.Slider(label='S1', minimum=0, maximum=4, step=0.01, value=0.99)
            freeu_s2 = gr.Slider(label='S2', minimum=0, maximum=4, step=0.01, value=0.95)

        return freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2

    def process_before_every_sampling(self, p, *script_args, **kwargs):
        # This will be called before every sampling.
        # If you use highres fix, this will be called twice.

        freeu_enabled, freeu_b1, freeu_b2, freeu_s1, freeu_s2 = script_args

        if not freeu_enabled:
            return

        unet = p.sd_model.forge_objects.unet

        unet = patch_freeu_v2(unet, freeu_b1, freeu_b2, freeu_s1, freeu_s2)

        p.sd_model.forge_objects.unet = unet

        # Below codes will add some logs to the texts below the image outputs on UI.
        # The extra_generation_params does not influence results.
        p.extra_generation_params.update(dict(
            freeu_enabled=freeu_enabled,
            freeu_b1=freeu_b1,
            freeu_b2=freeu_b2,
            freeu_s1=freeu_s1,
            freeu_s2=freeu_s2,
        ))

        return
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See also &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge/raw/main/backend/nn/unet.py"&gt;Forge's Unet Implementation&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Under Construction&lt;/h1&gt; 
&lt;p&gt;WebUI Forge is now under some constructions, and docs / UI / functionality may change with updates.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/TensorRT-Model-Optimizer</title>
      <link>https://github.com/NVIDIA/TensorRT-Model-Optimizer</link>
      <description>&lt;p&gt;A unified library of state-of-the-art model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/docs/source/assets/model-optimizer-banner.png" alt="Banner image" /&gt;&lt;/p&gt; 
 &lt;h1&gt;NVIDIA TensorRT Model Optimizer&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer"&gt;&lt;img src="https://img.shields.io/badge/Documentation-latest-brightgreen.svg?style=flat" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/nvidia-modelopt/"&gt;&lt;img src="https://img.shields.io/pypi/v/nvidia-modelopt?label=Release" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/146"&gt;Roadmap&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;The &lt;strong&gt;NVIDIA TensorRT Model Optimizer&lt;/strong&gt; (referred to as &lt;strong&gt;Model Optimizer&lt;/strong&gt;, or &lt;strong&gt;ModelOpt&lt;/strong&gt;) is a library comprising state-of-the-art model optimization &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/#techniques"&gt;techniques&lt;/a&gt; including quantization, distillation, pruning, speculative decoding and sparsity to accelerate models.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;[Input]&lt;/strong&gt; Model Optimizer currently supports inputs of a &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt;, &lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt; or &lt;a href="https://github.com/onnx/onnx"&gt;ONNX&lt;/a&gt; model.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;[Optimize]&lt;/strong&gt; Model Optimizer provides Python APIs for users to easily compose the above model optimization techniques and export an optimized quantized checkpoint. Model Optimizer is also integrated with &lt;a href="https://github.com/NVIDIA-NeMo/NeMo"&gt;NVIDIA NeMo&lt;/a&gt;, &lt;a href="https://github.com/NVIDIA/Megatron-LM"&gt;Megatron-LM&lt;/a&gt; and &lt;a href="https://github.com/huggingface/accelerate"&gt;Hugging Face Accelerate&lt;/a&gt; for training required inference optimization techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;[Export for deployment]&lt;/strong&gt; Seamlessly integrated within the NVIDIA AI software ecosystem, the quantized checkpoint generated from Model Optimizer is ready for deployment in downstream inference frameworks like &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;, &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/quantization"&gt;TensorRT-LLM&lt;/a&gt;, &lt;a href="https://github.com/NVIDIA/TensorRT"&gt;TensorRT&lt;/a&gt;, or &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/08/29] &lt;a href="https://developer.nvidia.com/blog/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-training/"&gt;Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/08/01] &lt;a href="https://developer.nvidia.com/blog/optimizing-llms-for-performance-and-accuracy-with-post-training-quantization/"&gt;Optimizing LLMs for Performance and Accuracy with Post-Training Quantization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/06/24] &lt;a href="https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/"&gt;Introducing NVFP4 for Efficient and Accurate Low-Precision Inference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/05/14] &lt;a href="https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/"&gt;NVIDIA TensorRT Unlocks FP4 Image Generation for NVIDIA Blackwell GeForce RTX 50 Series GPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/04/21] &lt;a href="https://developer.nvidia.com/blog/optimizing-transformer-based-diffusion-models-for-video-generation-with-nvidia-tensorrt/"&gt;Adobe optimized deployment using TensorRT-Model-Optimizer + TensorRT leading to a 60% reduction in diffusion latency, a 40% reduction in total cost of ownership&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/04/05] &lt;a href="https://developer.nvidia.com/blog/nvidia-accelerates-inference-on-meta-llama-4-scout-and-maverick/"&gt;NVIDIA Accelerates Inference on Meta Llama 4 Scout and Maverick&lt;/a&gt;. Check out how to quantize Llama4 for deployment acceleration &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_ptq/README.md#llama-4"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/03/18] &lt;a href="https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/"&gt;World's Fastest DeepSeek-R1 Inference with Blackwell FP4 &amp;amp; Increasing Image Generation Efficiency on Blackwell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/02/25] Model Optimizer quantized NVFP4 models available on Hugging Face for download: &lt;a href="https://huggingface.co/nvidia/DeepSeek-R1-FP4"&gt;DeepSeek-R1-FP4&lt;/a&gt;, &lt;a href="https://huggingface.co/nvidia/Llama-3.3-70B-Instruct-FP4"&gt;Llama-3.3-70B-Instruct-FP4&lt;/a&gt;, &lt;a href="https://huggingface.co/nvidia/Llama-3.1-405B-Instruct-FP4"&gt;Llama-3.1-405B-Instruct-FP4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/01/28] Model Optimizer has added support for NVFP4. Check out an example of NVFP4 PTQ &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_ptq/README.md#model-quantization-and-trt-llm-conversion"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01/28] Model Optimizer is now open source!&lt;/li&gt; 
 &lt;li&gt;[2024/10/23] Model Optimizer quantized FP8 Llama-3.1 Instruct models available on Hugging Face for download: &lt;a href="https://huggingface.co/nvidia/Llama-3.1-8B-Instruct-FP8"&gt;8B&lt;/a&gt;, &lt;a href="https://huggingface.co/nvidia/Llama-3.1-70B-Instruct-FP8"&gt;70B&lt;/a&gt;, &lt;a href="https://huggingface.co/nvidia/Llama-3.1-405B-Instruct-FP8"&gt;405B&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2024/09/10] &lt;a href="https://developer.nvidia.com/blog/post-training-quantization-of-llms-with-nvidia-nemo-and-nvidia-tensorrt-model-optimizer/"&gt;Post-Training Quantization of LLMs with NVIDIA NeMo and TensorRT Model Optimizer&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details close&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2024/08/28] &lt;a href="https://developer.nvidia.com/blog/boosting-llama-3-1-405b-performance-by-up-to-44-with-nvidia-tensorrt-model-optimizer-on-nvidia-h200-gpus/"&gt;Boosting Llama 3.1 405B Performance up to 44% with TensorRT Model Optimizer on NVIDIA H200 GPUs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/08/28] &lt;a href="https://developer.nvidia.com/blog/low-latency-inference-chapter-1-up-to-1-9x-higher-llama-3-1-performance-with-medusa-on-nvidia-hgx-h200-with-nvlink-switch/"&gt;Up to 1.9X Higher Llama 3.1 Performance with Medusa&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/08/15] New features in recent releases: &lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/tree/main/examples/diffusers/cache_diffusion"&gt;Cache Diffusion&lt;/a&gt;, &lt;a href="https://docs.nvidia.com/nemo-framework/user-guide/24.09/sft_peft/qlora.html"&gt;QLoRA workflow with NVIDIA NeMo&lt;/a&gt;, and more. Check out &lt;a href="https://developer.nvidia.com/blog/nvidia-tensorrt-model-optimizer-v0-15-boosts-inference-performance-and-expands-model-support/"&gt;our blog&lt;/a&gt; for details.&lt;/li&gt; 
  &lt;li&gt;[2024/06/03] Model Optimizer now has an experimental feature to deploy to vLLM as part of our effort to support popular deployment frameworks. Check out the workflow &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_ptq/README.md#deploy-fp8-quantized-model-using-vllm"&gt;here&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/05/08] &lt;a href="https://developer.nvidia.com/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/"&gt;Announcement: Model Optimizer Now Formally Available to Further Accelerate GenAI Inference Performance&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/03/27] &lt;a href="https://developer.nvidia.com/blog/nvidia-h200-tensor-core-gpus-and-nvidia-tensorrt-llm-set-mlperf-llm-inference-records/"&gt;Model Optimizer supercharges TensorRT-LLM to set MLPerf LLM inference records&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/03/18] &lt;a href="https://www.nvidia.com/en-us/on-demand/session/gtc24-s63213/"&gt;GTC Session: Optimize Generative AI Inference with Quantization in TensorRT-LLM and TensorRT&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/03/07] &lt;a href="https://developer.nvidia.com/blog/tensorrt-accelerates-stable-diffusion-nearly-2x-faster-with-8-bit-post-training-quantization/"&gt;Model Optimizer's 8-bit Post-Training Quantization enables TensorRT to accelerate Stable Diffusion to nearly 2x faster&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;[2024/02/01] &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docs/source/blogs/quantization-in-TRT-LLM.md"&gt;Speed up inference with Model Optimizer quantization techniques in TRT-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;To install stable release packages for Model Optimizer with &lt;code&gt;pip&lt;/code&gt; from &lt;a href="https://pypi.org/project/nvidia-modelopt/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nvidia-modelopt[all]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install from source in editable mode with all development dependencies or to test the latest changes, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the Model Optimizer repository
git clone https://github.com/NVIDIA/TensorRT-Model-Optimizer.git
cd TensorRT-Model-Optimizer

pip install -e .[dev]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/getting_started/2_installation.html"&gt;installation guide&lt;/a&gt; for more fine-grained control on installed dependencies or view our pre-made &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/docker/README.md"&gt;dockerfiles&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Techniques&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Technique&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Post Training Quantization&lt;/td&gt; 
    &lt;td align="center"&gt;Compress model size by 2x-4x, speeding up inference while preserving model quality!&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_ptq/"&gt;LLMs&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/diffusers/"&gt;diffusers&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/vlm_ptq/"&gt;VLMs&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/onnx_ptq/"&gt;onnx&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/windows/"&gt;windows&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/1_quantization.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Quantization Aware Training&lt;/td&gt; 
    &lt;td align="center"&gt;Refine accuracy even further with a few training steps!&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_qat#nemo-qatqad-simplified-flow-example"&gt;NeMo&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_qat/"&gt;Hugging Face&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/1_quantization.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Pruning&lt;/td&gt; 
    &lt;td align="center"&gt;Reduce your model size and accelerate inference by removing unnecessary weights!&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/pruning/"&gt;PyTorch&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/3_pruning.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Distillation&lt;/td&gt; 
    &lt;td align="center"&gt;Reduce deployment model size by teaching small models to behave like larger models!&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_distill#knowledge-distillation-kd-for-nvidia-nemo-models"&gt;NeMo&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_distill/"&gt;Hugging Face&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/4_distillation.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Speculative Decoding&lt;/td&gt; 
    &lt;td align="center"&gt;Train draft modules to predict extra tokens during inference!&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/speculative_decoding#mlm-example"&gt;Megatron&lt;/a&gt;] [&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/speculative_decoding/"&gt;Hugging Face&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/5_speculative_decoding.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Sparsity&lt;/td&gt; 
    &lt;td align="center"&gt;Efficiently compress your model by storing only its non-zero parameter values and their locations&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_sparsity/"&gt;PyTorch&lt;/a&gt;]&lt;/td&gt; 
    &lt;td align="center"&gt;[&lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/guides/6_sparsity.html"&gt;docs&lt;/a&gt;]&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Pre-Quantized Checkpoints&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ready-to-deploy checkpoints [&lt;a href="https://huggingface.co/collections/nvidia/model-optimizer-66aa84f7966b3150262481a4"&gt;ü§ó Hugging Face - Nvidia TensorRT Model Optimizer Collection&lt;/a&gt;]&lt;/li&gt; 
 &lt;li&gt;Deployable on &lt;a href="https://github.com/NVIDIA/TensorRT-LLM"&gt;TensorRT-LLM&lt;/a&gt;, &lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt; and &lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;More models coming soon!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìÖ &lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/146"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üéØ &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/benchmark.md"&gt;Benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://nvidia.github.io/TensorRT-Model-Optimizer/reference/0_changelog.html"&gt;Release Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/new?template=1_bug_report.md"&gt;File a bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/new?template=2_feature_request.md"&gt;File a Feature Request&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Type&lt;/th&gt; 
   &lt;th&gt;Support Matrix&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Quantization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_ptq/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Diffusers Quantization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/diffusers/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VLM Quantization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/vlm_ptq/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ONNX Quantization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/onnx_ptq/README.md#onnx-export-supported-llm-models"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows Quantization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/windows/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quantization Aware Training&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_qat/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pruning&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/pruning/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Distillation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/llm_distill/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Speculative Decoding&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/examples/speculative_decoding/README.md#support-matrix"&gt;View Support Matrix&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Model Optimizer is now open source! We welcome any feedback, feature requests and PRs. Please read our &lt;a href="https://raw.githubusercontent.com/NVIDIA/TensorRT-Model-Optimizer/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; guidelines for details on how to contribute to this project.&lt;/p&gt; 
&lt;h3&gt;Top Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=NVIDIA/TensorRT-Model-Optimizer" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Happy optimizing!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>infinition/Bjorn</title>
      <link>https://github.com/infinition/Bjorn</link>
      <description>&lt;p&gt;Bjorn is a powerful network scanning and offensive security tool for the Raspberry Pi with a 2.13-inch e-Paper HAT. It discovers network targets, identifies open ports, exposed services, and potential vulnerabilities. Bjorn can perform brute force attacks, file stealing, host zombification, and supports custom attack scripts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/user-attachments/assets/c5eb4cc1-0c3d-497d-9422-1614651a84ab" alt="thumbnail_IMG_0546" width="33" /&gt; Bjorn&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?logo=python&amp;amp;logoColor=fff" alt="Python" /&gt; &lt;img src="https://img.shields.io/badge/Status-Development-blue.svg?sanitize=true" alt="Status" /&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.reddit.com/r/Bjorn_CyberViking"&gt;&lt;img src="https://img.shields.io/badge/Reddit-Bjorn__CyberViking-orange?style=for-the-badge&amp;amp;logo=reddit" alt="Reddit" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/B3ZH9taVfT"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?style=for-the-badge&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/c5eb4cc1-0c3d-497d-9422-1614651a84ab" alt="thumbnail_IMG_0546" width="150" /&gt; &lt;img src="https://github.com/user-attachments/assets/1b490f07-f28e-4418-8d41-14f1492890c6" alt="bjorn_epd-removebg-preview" width="150" /&gt; &lt;/p&gt; 
&lt;p&gt;Bjorn is a&amp;nbsp;¬´&amp;nbsp;Tamagotchi like&amp;nbsp;¬ª sophisticated, autonomous network scanning, vulnerability assessment, and offensive security tool designed to run on a Raspberry Pi equipped with a 2.13-inch e-Paper HAT. This document provides a detailed explanation of the project.&lt;/p&gt; 
&lt;h2&gt;üìö Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-usage-example"&gt;Usage Example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ Introduction&lt;/h2&gt; 
&lt;p&gt;Bjorn is a powerful tool designed to perform comprehensive network scanning, vulnerability assessment, and data ex-filtration. Its modular design and extensive configuration options allow for flexible and targeted operations. By combining different actions and orchestrating them intelligently, Bjorn can provide valuable insights into network security and help identify and mitigate potential risks.&lt;/p&gt; 
&lt;p&gt;The e-Paper HAT display and web interface make it easy to monitor and interact with Bjorn, providing real-time updates and status information. With its extensible architecture and customizable actions, Bjorn can be adapted to suit a wide range of security testing and monitoring needs.&lt;/p&gt; 
&lt;h2&gt;üåü Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Network Scanning&lt;/strong&gt;: Identifies live hosts and open ports on the network.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vulnerability Assessment&lt;/strong&gt;: Performs vulnerability scans using Nmap and other tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System Attacks&lt;/strong&gt;: Conducts brute-force attacks on various services (FTP, SSH, SMB, RDP, Telnet, SQL).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Stealing&lt;/strong&gt;: Extracts data from vulnerable services.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User Interface&lt;/strong&gt;: Real-time display on the e-Paper HAT and web interface for monitoring and interaction.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/infinition/Bjorn/assets/37984399/bcad830d-77d6-4f3e-833d-473eadd33921" alt="Bjorn Display" /&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h2&gt;üìå Prerequisites&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites for RPI zero W (32bits)&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3980ec5f-a8fc-4848-ab25-4356e0529639" alt="image" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Raspberry Pi OS installed. 
  &lt;ul&gt; 
   &lt;li&gt;Stable: 
    &lt;ul&gt; 
     &lt;li&gt;System: 32-bit&lt;/li&gt; 
     &lt;li&gt;Kernel version: 6.6&lt;/li&gt; 
     &lt;li&gt;Debian version: 12 (bookworm) '2024-10-22-raspios-bookworm-armhf-lite'&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Username and hostname set to &lt;code&gt;bjorn&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;2.13-inch e-Paper HAT connected to GPIO pins.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Prerequisites for RPI zero W2 (64bits)&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/e8d276be-4cb2-474d-a74d-b5b6704d22f5" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;I did not develop Bjorn for the raspberry pi zero w2 64bits, but several feedbacks have attested that the installation worked perfectly.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Raspberry Pi OS installed. 
  &lt;ul&gt; 
   &lt;li&gt;Stable: 
    &lt;ul&gt; 
     &lt;li&gt;System: 64-bit&lt;/li&gt; 
     &lt;li&gt;Kernel version: 6.6&lt;/li&gt; 
     &lt;li&gt;Debian version: 12 (bookworm) '2024-10-22-raspios-bookworm-arm64-lite'&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Username and hostname set to &lt;code&gt;bjorn&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;2.13-inch e-Paper HAT connected to GPIO pins.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;At the moment the paper screen v2 v4 have been tested and implemented. I juste hope the V1 &amp;amp; V3 will work the same.&lt;/p&gt; 
&lt;h3&gt;üî® Installation&lt;/h3&gt; 
&lt;p&gt;The fastest way to install Bjorn is using the automatic installation script :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and run the installer
wget https://raw.githubusercontent.com/infinition/Bjorn/refs/heads/main/install_bjorn.sh
sudo chmod +x install_bjorn.sh &amp;amp;&amp;amp; sudo ./install_bjorn.sh
# Choose the choice 1 for automatic installation. It may take a while as a lot of packages and modules will be installed. You must reboot at the end.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For &lt;strong&gt;detailed information&lt;/strong&gt; about &lt;strong&gt;installation&lt;/strong&gt; process go to &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/INSTALL.md"&gt;Install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ö° Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Need help ? You struggle to find Bjorn's IP after the installation ?&lt;/strong&gt; Use my Bjorn Detector &amp;amp; SSH Launcher :&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/infinition/bjorn-detector"&gt;https://github.com/infinition/bjorn-detector&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/182f82f0-5c3a-48a9-a75e-37b9cfa2263a" alt="ezgif-1-a310f5fe8f" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hmm, You still need help ?&lt;/strong&gt; For &lt;strong&gt;detailed information&lt;/strong&gt; about &lt;strong&gt;troubleshooting&lt;/strong&gt; go to &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick Installation&lt;/strong&gt;: you can use the fastest way to install &lt;strong&gt;Bjorn&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/#-getting-started"&gt;Getting Started&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üí° Usage Example&lt;/h2&gt; 
&lt;p&gt;Here's a demonstration of how Bjorn autonomously hunts through your network like a Viking raider (fake demo for illustration):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Reconnaissance Phase
[NetworkScanner] Discovering alive hosts...
[+] Host found: 192.168.1.100
    ‚îú‚îÄ‚îÄ Ports: 22,80,445,3306
    ‚îî‚îÄ‚îÄ MAC: 00:11:22:33:44:55

# Attack Sequence 
[NmapVulnScanner] Found vulnerabilities on 192.168.1.100
    ‚îú‚îÄ‚îÄ MySQL 5.5 &amp;lt; 5.7 - User Enumeration
    ‚îî‚îÄ‚îÄ SMB - EternalBlue Candidate

[SSHBruteforce] Cracking credentials...
[+] Success! user:password123
[StealFilesSSH] Extracting sensitive data...

# Automated Data Exfiltration
[SQLBruteforce] Database accessed!
[StealDataSQL] Dumping tables...
[SMBBruteforce] Share accessible
[+] Found config files, credentials, backups...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is just a demo output - actual results will vary based on your network and target configuration.&lt;/p&gt; 
&lt;p&gt;All discovered data is automatically organized in the data/output/ directory, viewable through both the e-Paper display (as indicators) and web interface. Bjorn works tirelessly, expanding its network knowledge base and growing stronger with each discovery.&lt;/p&gt; 
&lt;p&gt;No constant monitoring needed - just deploy and let Bjorn do what it does best: hunt for vulnerabilities.&lt;/p&gt; 
&lt;p&gt;üîß Expand Bjorn's Arsenal! Bjorn is designed to be a community-driven weapon forge. Create and share your own attack modules!&lt;/p&gt; 
&lt;p&gt;‚ö†Ô∏è &lt;strong&gt;For educational and authorized testing purposes only&lt;/strong&gt; ‚ö†Ô∏è&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;The project welcomes contributions in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;New attack modules.&lt;/li&gt; 
 &lt;li&gt;Bug fixes.&lt;/li&gt; 
 &lt;li&gt;Documentation.&lt;/li&gt; 
 &lt;li&gt;Feature improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For &lt;strong&gt;detailed information&lt;/strong&gt; about &lt;strong&gt;contributing&lt;/strong&gt; process go to &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/CONTRIBUTING.md"&gt;Contributing Docs&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/CODE_OF_CONDUCT.md"&gt;Code Of Conduct&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/DEVELOPMENT.md"&gt;Development Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üì´ Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Report Issues&lt;/strong&gt;: Via GitHub.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Follow ethical guidelines.&lt;/li&gt; 
   &lt;li&gt;Document reproduction steps.&lt;/li&gt; 
   &lt;li&gt;Provide logs and context.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;: &lt;strong&gt;infinition&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href="https://github.com/infinition/Bjorn"&gt;infinition/Bjorn&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üå† Stargazers&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#infinition/bjorn&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=infinition/bjorn&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;2024 - Bjorn is distributed under the MIT License. For more details, please refer to the &lt;a href="https://raw.githubusercontent.com/infinition/Bjorn/main/LICENSE"&gt;LICENSE&lt;/a&gt; file included in this repository.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PacktPublishing/LLM-Engineers-Handbook</title>
      <link>https://github.com/PacktPublishing/LLM-Engineers-Handbook</link>
      <description>&lt;p&gt;The LLM's practical guide: From the fundamentals to deploying advanced LLM and RAG apps to AWS using LLMOps best practices&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;üë∑ LLM Engineer's Handbook&lt;/h1&gt; 
 &lt;p class="tagline"&gt;Official repository of the &lt;a href="https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/"&gt;LLM Engineer's Handbook&lt;/a&gt; by &lt;a href="https://github.com/iusztinpaul"&gt;Paul Iusztin&lt;/a&gt; and &lt;a href="https://github.com/mlabonne"&gt;Maxime Labonne&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/"&gt; &lt;img src="https://raw.githubusercontent.com/PacktPublishing/LLM-Engineers-Handbook/main/images/cover_plus.png" alt="Book cover" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Find the book on &lt;a href="https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/"&gt;Amazon&lt;/a&gt; or &lt;a href="https://www.packtpub.com/en-us/product/llm-engineers-handbook-9781836200062"&gt;Packt&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üåü Features&lt;/h2&gt; 
&lt;p&gt;The goal of this book is to create your own end-to-end LLM-based system using best practices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìù Data collection &amp;amp; generation&lt;/li&gt; 
 &lt;li&gt;üîÑ LLM training pipeline&lt;/li&gt; 
 &lt;li&gt;üìä Simple RAG system&lt;/li&gt; 
 &lt;li&gt;üöÄ Production-ready AWS deployment&lt;/li&gt; 
 &lt;li&gt;üîç Comprehensive monitoring&lt;/li&gt; 
 &lt;li&gt;üß™ Testing and evaluation framework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can download and use the final trained model on &lt;a href="https://huggingface.co/mlabonne/TwinLlama-3.1-8B-DPO"&gt;Hugging Face&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The code in this GitHub repository is actively maintained and may contain updates not reflected in the book. &lt;strong&gt;Always refer to this repository for the latest version of the code.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üîó Dependencies&lt;/h2&gt; 
&lt;h3&gt;Local dependencies&lt;/h3&gt; 
&lt;p&gt;To install and run the project locally, you need the following dependencies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Installation Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pyenv&lt;/td&gt; 
   &lt;td&gt;‚â•2.3.36&lt;/td&gt; 
   &lt;td&gt;Multiple Python versions (optional)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/pyenv/pyenv?tab=readme-ov-file#installation"&gt;Install Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;3.11&lt;/td&gt; 
   &lt;td&gt;Runtime environment&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.python.org/downloads/"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Poetry&lt;/td&gt; 
   &lt;td&gt;&amp;gt;= 1.8.3 and &amp;lt; 2.0&lt;/td&gt; 
   &lt;td&gt;Package management&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://python-poetry.org/docs/#installation"&gt;Install Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docker&lt;/td&gt; 
   &lt;td&gt;‚â•27.1.1&lt;/td&gt; 
   &lt;td&gt;Containerization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Install Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS CLI&lt;/td&gt; 
   &lt;td&gt;‚â•2.15.42&lt;/td&gt; 
   &lt;td&gt;Cloud management&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html"&gt;Install Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git&lt;/td&gt; 
   &lt;td&gt;‚â•2.44.0&lt;/td&gt; 
   &lt;td&gt;Version control&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://git-scm.com/downloads"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Cloud services&lt;/h3&gt; 
&lt;p&gt;The code also uses and depends on the following cloud services. For now, you don't have to do anything. We will guide you in the installation and deployment sections on how to use them:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.com/"&gt;HuggingFace&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Model registry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/site/products/opik/?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_campaign=opik"&gt;Comet ML&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Experiment tracker&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.comet.com/site/products/opik/?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_campaign=opik"&gt;Opik&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Prompt monitoring&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.zenml.io/"&gt;ZenML&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Orchestrator and artifacts layer&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://aws.amazon.com/"&gt;AWS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Compute and storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.mongodb.com/"&gt;MongoDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;NoSQL database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://qdrant.tech/"&gt;Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/features/actions"&gt;GitHub Actions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI/CD pipeline&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;In the &lt;a href="https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/"&gt;LLM Engineer's Handbook&lt;/a&gt;, Chapter 2 will walk you through each tool. Chapters 10 and 11 provide step-by-step guides on how to set up everything you need.&lt;/p&gt; 
&lt;h2&gt;üóÇÔ∏è Project Structure&lt;/h2&gt; 
&lt;p&gt;Here is the directory overview:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;.
‚îú‚îÄ‚îÄ code_snippets/       # Standalone example code
‚îú‚îÄ‚îÄ configs/             # Pipeline configuration files
‚îú‚îÄ‚îÄ llm_engineering/     # Core project package
‚îÇ   ‚îú‚îÄ‚îÄ application/    
‚îÇ   ‚îú‚îÄ‚îÄ domain/         
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/ 
‚îÇ   ‚îú‚îÄ‚îÄ model/         
‚îú‚îÄ‚îÄ pipelines/           # ML pipeline definitions
‚îú‚îÄ‚îÄ steps/               # Pipeline components
‚îú‚îÄ‚îÄ tests/               # Test examples
‚îú‚îÄ‚îÄ tools/               # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ run.py
‚îÇ   ‚îú‚îÄ‚îÄ ml_service.py
‚îÇ   ‚îú‚îÄ‚îÄ rag.py
‚îÇ   ‚îú‚îÄ‚îÄ data_warehouse.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;llm_engineering/&lt;/code&gt; is the main Python package implementing LLM and RAG functionality. It follows Domain-Driven Design (DDD) principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;domain/&lt;/code&gt;: Core business entities and structures&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;application/&lt;/code&gt;: Business logic, crawlers, and RAG implementation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;model/&lt;/code&gt;: LLM training and inference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;infrastructure/&lt;/code&gt;: External service integrations (AWS, Qdrant, MongoDB, FastAPI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The code logic and imports flow as follows: &lt;code&gt;infrastructure&lt;/code&gt; ‚Üí &lt;code&gt;model&lt;/code&gt; ‚Üí &lt;code&gt;application&lt;/code&gt; ‚Üí &lt;code&gt;domain&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pipelines/&lt;/code&gt;: Contains the ZenML ML pipelines, which serve as the entry point for all the ML pipelines. Coordinates the data processing and model training stages of the ML lifecycle.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;steps/&lt;/code&gt;: Contains individual ZenML steps, which are reusable components for building and customizing ZenML pipelines. Steps perform specific tasks (e.g., data loading, preprocessing) and can be combined within the ML pipelines.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;tests/&lt;/code&gt;: Covers a few sample tests used as examples within the CI pipeline.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;tools/&lt;/code&gt;: Utility scripts used to call the ZenML pipelines and inference code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;run.py&lt;/code&gt;: Entry point script to run ZenML pipelines.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ml_service.py&lt;/code&gt;: Starts the REST API inference server.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rag.py&lt;/code&gt;: Demonstrates usage of the RAG retrieval module.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_warehouse.py&lt;/code&gt;: Used to export or import data from the MongoDB data warehouse through JSON files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;configs/&lt;/code&gt;: ZenML YAML configuration files to control the execution of pipelines and steps.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;code_snippets/&lt;/code&gt;: Independent code examples that can be executed independently.&lt;/p&gt; 
&lt;h2&gt;üíª Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you are experiencing issues while installing and running the repository, consider checking the &lt;a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook/issues"&gt;Issues&lt;/a&gt; GitHub section for other people who solved similar problems or directly asking us for help.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;p&gt;Start by cloning the repository and navigating to the project directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/PacktPublishing/LLM-Engineers-Handbook.git
cd LLM-Engineers-Handbook 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, we have to prepare your Python environment and its adjacent dependencies.&lt;/p&gt; 
&lt;h3&gt;2. Set Up Python Environment&lt;/h3&gt; 
&lt;p&gt;The project requires Python 3.11. You can either use your global Python installation or set up a project-specific version using pyenv.&lt;/p&gt; 
&lt;h4&gt;Option A: Using Global Python (if version 3.11 is installed)&lt;/h4&gt; 
&lt;p&gt;Verify your Python version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python --version  # Should show Python 3.11.x
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option B: Using pyenv (recommended)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Verify pyenv installation:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pyenv --version   # Should show pyenv 2.3.36 or later
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install Python 3.11.8:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pyenv install 3.11.8
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Verify the installation:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python --version  # Should show Python 3.11.8
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Confirm Python version in the project directory:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python --version
# Output: Python 3.11.8
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br /&gt; The project includes a &lt;code&gt;.python-version&lt;/code&gt; file that automatically sets the correct Python version when you're in the project directory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;3. Install Dependencies&lt;/h3&gt; 
&lt;p&gt;The project uses Poetry for dependency management.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Verify Poetry installation:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry --version  # Should show Poetry version 1.8.3 or later
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up the project environment and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry env use 3.11
poetry install --without aws
poetry run pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configure Poetry to use Python 3.11&lt;/li&gt; 
 &lt;li&gt;Install project dependencies (excluding AWS-specific packages)&lt;/li&gt; 
 &lt;li&gt;Set up pre-commit hooks for code verification&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Activate the Environment&lt;/h3&gt; 
&lt;p&gt;As our task manager, we run all the scripts using &lt;a href="https://poethepoet.natn.io/index.html"&gt;Poe the Poet&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start a Poetry shell:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run project commands using Poe the Poet:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Troubleshooting Poe the Poet Installation&lt;/summary&gt; 
 &lt;h3&gt;Alternative Command Execution&lt;/h3&gt; 
 &lt;p&gt;If you're experiencing issues with &lt;code&gt;poethepoet&lt;/code&gt;, you can still run the project commands directly through Poetry. Here's how:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Look up the command definition in &lt;code&gt;pyproject.toml&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Use &lt;code&gt;poetry run&lt;/code&gt; with the underlying command&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;Example:&lt;/h4&gt; 
 &lt;p&gt;Instead of:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe local-infrastructure-up
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Use the direct command from pyproject.toml:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;poetry run &amp;lt;actual-command-from-pyproject-toml&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: All project commands are defined in the [tool.poe.tasks] section of pyproject.toml&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Now, let's configure our local project with all the necessary credentials and tokens to run the code locally.&lt;/p&gt; 
&lt;h3&gt;5. Local Development Setup&lt;/h3&gt; 
&lt;p&gt;After you have installed all the dependencies, you must create and fill a&amp;nbsp;&lt;code&gt;.env&lt;/code&gt; file with your credentials to appropriately interact with other services and run the project. Setting your sensitive credentials in a &lt;code&gt;.env&lt;/code&gt; file is a good security practice, as this file won't be committed to GitHub or shared with anyone else.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;First, copy our example by running the following:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env # The file must be at your repository's root!
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Now, let's understand how to fill in all the essential variables within the &lt;code&gt;.env&lt;/code&gt; file to get you started. The following are the mandatory settings we must complete when working locally:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;OpenAI&lt;/h4&gt; 
&lt;p&gt;To authenticate to OpenAI's API, you must fill out the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; env var with an authentication token.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;OPENAI_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí Check out this &lt;a href="https://platform.openai.com/docs/quickstart"&gt;tutorial&lt;/a&gt; to learn how to provide one from OpenAI.&lt;/p&gt; 
&lt;h4&gt;Hugging Face&lt;/h4&gt; 
&lt;p&gt;To authenticate to Hugging Face, you must fill out the &lt;code&gt;HUGGINGFACE_ACCESS_TOKEN&lt;/code&gt; env var with an authentication token.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;HUGGINGFACE_ACCESS_TOKEN=your_token_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí Check out this &lt;a href="https://huggingface.co/docs/hub/en/security-tokens"&gt;tutorial&lt;/a&gt; to learn how to provide one from Hugging Face.&lt;/p&gt; 
&lt;h4&gt;Comet ML &amp;amp; Opik&lt;/h4&gt; 
&lt;p&gt;To authenticate to Comet ML (required only during training) and Opik, you must fill out the &lt;code&gt;COMET_API_KEY&lt;/code&gt; env var with your authentication token.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;COMET_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí Check out this &lt;a href="https://www.comet.com/docs/opik/?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_campaign=opik"&gt;tutorial&lt;/a&gt; to learn how to get started with Opik. You can also access Opik's dashboard using üîó&lt;a href="https://www.comet.com/opik?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_content=opik"&gt;this link&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;6. Deployment Setup&lt;/h3&gt; 
&lt;p&gt;When deploying the project to the cloud, we must set additional settings for Mongo, Qdrant, and AWS. If you are just working locally, the default values of these env vars will work out of the box. Detailed deployment instructions are available in Chapter 11 of the &lt;a href="https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/"&gt;LLM Engineer's Handbook&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;MongoDB&lt;/h4&gt; 
&lt;p&gt;We must change the &lt;code&gt;DATABASE_HOST&lt;/code&gt; env var with the URL pointing to your cloud MongoDB cluster.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;DATABASE_HOST=your_mongodb_url
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí Check out this &lt;a href="https://www.mongodb.com/resources/products/fundamentals/mongodb-cluster-setup"&gt;tutorial&lt;/a&gt; to learn how to create and host a MongoDB cluster for free.&lt;/p&gt; 
&lt;h4&gt;Qdrant&lt;/h4&gt; 
&lt;p&gt;Change &lt;code&gt;USE_QDRANT_CLOUD&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;, &lt;code&gt;QDRANT_CLOUD_URL&lt;/code&gt; with the URL point to your cloud Qdrant cluster, and &lt;code&gt;QDRANT_APIKEY&lt;/code&gt; with its API key.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;USE_QDRANT_CLOUD=true
QDRANT_CLOUD_URL=your_qdrant_cloud_url
QDRANT_APIKEY=your_qdrant_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí Check out this &lt;a href="https://qdrant.tech/documentation/cloud/create-cluster/"&gt;tutorial&lt;/a&gt; to learn how to create a Qdrant cluster for free&lt;/p&gt; 
&lt;h4&gt;AWS&lt;/h4&gt; 
&lt;p&gt;For your AWS set-up to work correctly, you need the AWS CLI installed on your local machine and properly configured with an admin user (or a user with enough permissions to create new SageMaker, ECR, and S3 resources; using an admin user will make everything more straightforward).&lt;/p&gt; 
&lt;p&gt;Chapter 2 provides step-by-step instructions on how to install the AWS CLI, create an admin user on AWS, and get an access key to set up the &lt;code&gt;AWS_ACCESS_KEY&lt;/code&gt; and &lt;code&gt;AWS_SECRET_KEY&lt;/code&gt; environment variables. If you already have an AWS admin user in place, you have to configure the following env vars in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AWS_REGION=eu-central-1 # Change it with your AWS region.
AWS_ACCESS_KEY=your_aws_access_key
AWS_SECRET_KEY=your_aws_secret_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;AWS credentials are typically stored in &lt;code&gt;~/.aws/credentials&lt;/code&gt;. You can view this file directly using &lt;code&gt;cat&lt;/code&gt; or similar commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat ~/.aws/credentials
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Additional configuration options are available in &lt;a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook/raw/main/llm_engineering/settings.py"&gt;settings.py&lt;/a&gt;. Any variable in the &lt;code&gt;Settings&lt;/code&gt; class can be configured through the &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üèóÔ∏è Infrastructure&lt;/h2&gt; 
&lt;h3&gt;Local infrastructure (for testing and development)&lt;/h3&gt; 
&lt;p&gt;When running the project locally, we host a MongoDB and Qdrant database using Docker. Also, a testing ZenML server is made available through their Python package.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] You need Docker installed (&amp;gt;= v27.1.1)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For ease of use, you can start the whole local development infrastructure with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe local-infrastructure-up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also, you can stop the ZenML server and all the Docker containers using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe local-infrastructure-down
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;br /&gt; When running on MacOS, before starting the server, export the following environment variable: &lt;code&gt;export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES&lt;/code&gt; Otherwise, the connection between the local server and pipeline will break. üîó More details in &lt;a href="https://github.com/zenml-io/zenml/issues/2369"&gt;this issue&lt;/a&gt;. This is done by default when using Poe the Poet.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Start the inference real-time RESTful API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-inference-ml-service
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The LLM microservice, called by the RESTful API, will work only after deploying the LLM to AWS SageMaker.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ZenML&lt;/h4&gt; 
&lt;p&gt;Dashboard URL: &lt;code&gt;localhost:8237&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Default credentials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;username&lt;/code&gt;: default&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;password&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚Üí Find out more about using and setting up &lt;a href="https://docs.zenml.io/"&gt;ZenML&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Qdrant&lt;/h4&gt; 
&lt;p&gt;REST API URL: &lt;code&gt;localhost:6333&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Dashboard URL: &lt;code&gt;localhost:6333/dashboard&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;‚Üí Find out more about using and setting up &lt;a href="https://qdrant.tech/documentation/quick-start/"&gt;Qdrant with Docker&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;MongoDB&lt;/h4&gt; 
&lt;p&gt;Database URI: &lt;code&gt;mongodb://llm_engineering:llm_engineering@127.0.0.1:27017&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Database name: &lt;code&gt;twin&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Default credentials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;username&lt;/code&gt;: llm_engineering&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;password&lt;/code&gt;: llm_engineering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚Üí Find out more about using and setting up &lt;a href="https://www.mongodb.com/docs/manual/tutorial/install-mongodb-community-with-docker"&gt;MongoDB with Docker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can search your MongoDB collections using your &lt;strong&gt;IDEs MongoDB plugin&lt;/strong&gt; (which you have to install separately), where you have to use the database URI to connect to the MongoDB database hosted within the Docker container: &lt;code&gt;mongodb://llm_engineering:llm_engineering@127.0.0.1:27017&lt;/code&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Everything related to training or running the LLMs (e.g., training, evaluation, inference) can only be run if you set up AWS SageMaker, as explained in the next section on cloud infrastructure.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Cloud infrastructure (for production)&lt;/h3&gt; 
&lt;p&gt;Here we will quickly present how to deploy the project to AWS and other serverless services. We won't go into the details (as everything is presented in the book) but only point out the main steps you have to go through.&lt;/p&gt; 
&lt;p&gt;First, reinstall your Python dependencies with the AWS group:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install --with aws
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AWS SageMaker&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Chapter 10 provides step-by-step instructions in the section "Implementing the LLM microservice using AWS SageMaker".&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;By this point, we expect you to have AWS CLI installed and your AWS CLI and project's env vars (within the &lt;code&gt;.env&lt;/code&gt; file) properly configured with an AWS admin user.&lt;/p&gt; 
&lt;p&gt;To ensure best practices, we must create a new AWS user restricted to creating and deleting only resources related to AWS SageMaker. Create it by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe create-sagemaker-role
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will create a &lt;code&gt;sagemaker_user_credentials.json&lt;/code&gt; file at the root of your repository with your new &lt;code&gt;AWS_ACCESS_KEY&lt;/code&gt; and &lt;code&gt;AWS_SECRET_KEY&lt;/code&gt; values. &lt;strong&gt;But before replacing your new AWS credentials, also run the following command to create the execution role (to create it using your admin credentials).&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To create the IAM execution role used by AWS SageMaker to access other AWS resources on our behalf, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe create-sagemaker-execution-role
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will create a &lt;code&gt;sagemaker_execution_role.json&lt;/code&gt; file at the root of your repository with your new &lt;code&gt;AWS_ARN_ROLE&lt;/code&gt; value. Add it to your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;Once you've updated the &lt;code&gt;AWS_ACCESS_KEY&lt;/code&gt;, &lt;code&gt;AWS_SECRET_KEY&lt;/code&gt;, and &lt;code&gt;AWS_ARN_ROLE&lt;/code&gt; values in your &lt;code&gt;.env&lt;/code&gt; file, you can use AWS SageMaker. &lt;strong&gt;Note that this step is crucial to complete the AWS setup.&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Training&lt;/h4&gt; 
&lt;p&gt;We start the training pipeline through ZenML by running the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-training-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start the training code using the configs from &lt;code&gt;configs/training.yaml&lt;/code&gt; directly in SageMaker. You can visualize the results in Comet ML's dashboard.&lt;/p&gt; 
&lt;p&gt;We start the evaluation pipeline through ZenML by running the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-evaluation-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start the evaluation code using the configs from &lt;code&gt;configs/evaluating.yaml&lt;/code&gt; directly in SageMaker. You can visualize the results in &lt;code&gt;*-results&lt;/code&gt; datasets saved to your Hugging Face profile.&lt;/p&gt; 
&lt;h4&gt;Inference&lt;/h4&gt; 
&lt;p&gt;To create an AWS SageMaker Inference Endpoint, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe deploy-inference-endpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To test it out, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe test-sagemaker-endpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To delete it, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe delete-inference-endpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AWS: ML pipelines, artifacts, and containers&lt;/h4&gt; 
&lt;p&gt;The ML pipelines, artifacts, and containers are deployed to AWS by leveraging ZenML's deployment features. Thus, you must create an account with ZenML Cloud and follow their guide on deploying a ZenML stack to AWS. Otherwise, we provide step-by-step instructions in &lt;strong&gt;Chapter 11&lt;/strong&gt;, section &lt;strong&gt;Deploying the LLM Twin's pipelines to the cloud&lt;/strong&gt; on what you must do.&lt;/p&gt; 
&lt;h4&gt;Qdrant &amp;amp; MongoDB&lt;/h4&gt; 
&lt;p&gt;We leverage Qdrant's and MongoDB's serverless options when deploying the project. Thus, you can either follow &lt;a href="https://qdrant.tech/documentation/cloud/create-cluster/"&gt;Qdrant's&lt;/a&gt; and &lt;a href="https://www.mongodb.com/resources/products/fundamentals/mongodb-cluster-setup"&gt;MongoDB's&lt;/a&gt; tutorials on how to create a freemium cluster for each or go through &lt;strong&gt;Chapter 11&lt;/strong&gt;, section &lt;strong&gt;Deploying the LLM Twin's pipelines to the cloud&lt;/strong&gt; and follow our step-by-step instructions.&lt;/p&gt; 
&lt;h4&gt;GitHub Actions&lt;/h4&gt; 
&lt;p&gt;We use GitHub Actions to implement our CI/CD pipelines. To implement your own, you have to fork our repository and set the following env vars as Actions secrets in your forked repository:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AWS_ECR_NAME&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, we provide instructions on how to set everything up in &lt;strong&gt;Chapter 11&lt;/strong&gt;, section &lt;strong&gt;Adding LLMOps to the LLM Twin&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Comet ML &amp;amp; Opik&lt;/h4&gt; 
&lt;p&gt;You can visualize the results on their self-hosted dashboards if you create a Comet account and correctly set the &lt;code&gt;COMET_API_KEY&lt;/code&gt; env var. As Opik is powered by Comet, you don't have to set up anything else along Comet:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_campaign=opik"&gt;Comet ML (for experiment tracking)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/opik?utm_source=llm_handbook&amp;amp;utm_medium=github&amp;amp;utm_campaign=opik"&gt;Opik (for prompt monitoring)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí∞ Running the Project Costs&lt;/h3&gt; 
&lt;p&gt;We will mostly stick to free tiers for all the services except for AWS and OpenAI's API, which are both pay-as-you-go services. The cost of running the project once, with our default values, will be roughly ~$25 (most of it comes from using AWS SageMaker for training and inference).&lt;/p&gt; 
&lt;h2&gt;‚ö° Pipelines&lt;/h2&gt; 
&lt;p&gt;All the ML pipelines will be orchestrated behind the scenes by &lt;a href="https://www.zenml.io/"&gt;ZenML&lt;/a&gt;. A few exceptions exist when running utility scrips, such as exporting or importing from the data warehouse.&lt;/p&gt; 
&lt;p&gt;The ZenML pipelines are the entry point for most processes throughout this project. They are under the &lt;code&gt;pipelines/&lt;/code&gt; folder. Thus, when you want to understand or debug a workflow, starting with the ZenML pipeline is the best approach.&lt;/p&gt; 
&lt;p&gt;To see the pipelines running and their results:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;go to your ZenML dashboard&lt;/li&gt; 
 &lt;li&gt;go to the &lt;code&gt;Pipelines&lt;/code&gt; section&lt;/li&gt; 
 &lt;li&gt;click on a specific pipeline (e.g., &lt;code&gt;feature_engineering&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;click on a specific run (e.g., &lt;code&gt;feature_engineering_run_2024_06_20_18_40_24&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;click on a specific step or artifact of the DAG to find more details about it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now, let's explore all the pipelines you can run. From data collection to training, we will present them in their natural order to go through the LLM project end-to-end.&lt;/p&gt; 
&lt;h3&gt;Data pipelines&lt;/h3&gt; 
&lt;p&gt;Run the data collection ETL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-digital-data-etl
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] You must have Chrome (or another Chromium-based browser) installed on your system for LinkedIn and Medium crawlers to work (which use Selenium under the hood). Based on your Chrome version, the Chromedriver will be automatically installed to enable Selenium support. Another option is to run everything using our Docker image if you don't want to install Chrome. For example, to run all the pipelines combined you can run &lt;code&gt;poetry poe run-docker-end-to-end-data-pipeline&lt;/code&gt;. Note that the command can be tweaked to support any other pipeline.&lt;/p&gt; 
 &lt;p&gt;If, for any other reason, you don't have a Chromium-based browser installed and don't want to use Docker, you have two other options to bypass this Selenium issue:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comment out all the code related to Selenium, Chrome and all the links that use Selenium to crawl them (e.g., Medium), such as the &lt;code&gt;chromedriver_autoinstaller.install()&lt;/code&gt; command from &lt;a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook/raw/main/llm_engineering/application/crawlers/base.py"&gt;application.crawlers.base&lt;/a&gt; and other static calls that check for Chrome drivers and Selenium.&lt;/li&gt; 
  &lt;li&gt;Install Google Chrome using your CLI in environments such as GitHub Codespaces or other cloud VMs using the same command as in our &lt;a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook/raw/main/Dockerfile#L10"&gt;Docker file&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To add additional links to collect from, go to &lt;code&gt;configs/digital_data_etl_[author_name].yaml&lt;/code&gt; and add them to the &lt;code&gt;links&lt;/code&gt; field. Also, you can create a completely new file and specify it at run time, like this: &lt;code&gt;python -m llm_engineering.interfaces.orchestrator.run --run-etl --etl-config-filename configs/digital_data_etl_[your_name].yaml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Run the feature engineering pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-feature-engineering-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the instruct dataset:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-generate-instruct-datasets-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the preference dataset:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-generate-preference-datasets-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run all of the above compressed into a single pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-end-to-end-data-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Utility pipelines&lt;/h3&gt; 
&lt;p&gt;Export the data from the data warehouse to JSON files:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-export-data-warehouse-to-json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Import data to the data warehouse from JSON files (by default, it imports the data from the &lt;code&gt;data/data_warehouse_raw_data&lt;/code&gt; directory):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-import-data-warehouse-from-json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Export ZenML artifacts to JSON:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-export-artifact-to-json-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will export the following ZenML artifacts to the &lt;code&gt;output&lt;/code&gt; folder as JSON files (it will take their latest version):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;cleaned_documents.json&lt;/li&gt; 
 &lt;li&gt;instruct_datasets.json&lt;/li&gt; 
 &lt;li&gt;preference_datasets.json&lt;/li&gt; 
 &lt;li&gt;raw_documents.json&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can configure what artifacts to export by tweaking the &lt;code&gt;configs/export_artifact_to_json.yaml&lt;/code&gt; configuration file.&lt;/p&gt; 
&lt;h3&gt;Training pipelines&lt;/h3&gt; 
&lt;p&gt;Run the training pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-training-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the evaluation pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-evaluation-pipeline
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] For this to work, make sure you properly configured AWS SageMaker as described in &lt;a href="https://raw.githubusercontent.com/PacktPublishing/LLM-Engineers-Handbook/main/#set-up-cloud-infrastructure-for-production"&gt;Set up cloud infrastructure (for production)&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Inference pipelines&lt;/h3&gt; 
&lt;p&gt;Call the RAG retrieval module with a test query:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe call-rag-retrieval-module
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start the inference real-time RESTful API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe run-inference-ml-service
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call the inference real-time RESTful API with a test query:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe call-inference-ml-service
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Remember that you can monitor the prompt traces on &lt;a href="https://www.comet.com/opik"&gt;Opik&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] For the inference service to work, you must have the LLM microservice deployed to AWS SageMaker, as explained in the setup cloud infrastructure section.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Linting &amp;amp; formatting (QA)&lt;/h3&gt; 
&lt;p&gt;Check or fix your linting issues:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe lint-check
poetry poe lint-fix
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check or fix your formatting issues:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe format-check
poetry poe format-fix
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check the code for leaked credentials:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe gitleaks-check
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tests&lt;/h3&gt; 
&lt;p&gt;Run all the tests using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry poe test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üèÉ Run project&lt;/h2&gt; 
&lt;p&gt;Based on the setup and usage steps described above, assuming the local and cloud infrastructure works and the &lt;code&gt;.env&lt;/code&gt; is filled as expected, follow the next steps to run the LLM system end-to-end:&lt;/p&gt; 
&lt;h3&gt;Data&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Collect data: &lt;code&gt;poetry poe run-digital-data-etl&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Compute features: &lt;code&gt;poetry poe run-feature-engineering-pipeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Compute instruct dataset: &lt;code&gt;poetry poe run-generate-instruct-datasets-pipeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Compute preference alignment dataset: &lt;code&gt;poetry poe run-generate-preference-datasets-pipeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Training&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] From now on, for these steps to work, you need to properly set up AWS SageMaker, such as running &lt;code&gt;poetry install --with aws&lt;/code&gt; and filling in the AWS-related environment variables and configs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;SFT fine-tuning Llamma 3.1: &lt;code&gt;poetry poe run-training-pipeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For DPO, go to &lt;code&gt;configs/training.yaml&lt;/code&gt;, change &lt;code&gt;finetuning_type&lt;/code&gt; to &lt;code&gt;dpo&lt;/code&gt;, and run &lt;code&gt;poetry poe run-training-pipeline&lt;/code&gt; again&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Evaluate fine-tuned models: &lt;code&gt;poetry poe run-evaluation-pipeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Inference&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] From now on, for these steps to work, you need to properly set up AWS SageMaker, such as running &lt;code&gt;poetry install --with aws&lt;/code&gt; and filling in the AWS-related environment variables and configs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="8"&gt; 
 &lt;li&gt; &lt;p&gt;Call only the RAG retrieval module: &lt;code&gt;poetry poe call-rag-retrieval-module&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy the LLM Twin microservice to SageMaker: &lt;code&gt;poetry poe deploy-inference-endpoint&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Test the LLM Twin microservice: &lt;code&gt;poetry poe test-sagemaker-endpoint&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start end-to-end RAG server: &lt;code&gt;poetry poe run-inference-ml-service&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Test RAG server: &lt;code&gt;poetry poe call-inference-ml-service&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This course is an open-source project released under the MIT license. Thus, as long you distribute our LICENSE and acknowledge our work, you can safely clone or fork this project and use it as a source of inspiration for whatever you want (e.g., university projects, college degree projects, personal projects, etc.).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wasi-master/13ft</title>
      <link>https://github.com/wasi-master/13ft</link>
      <description>&lt;p&gt;My own custom 12ft.io replacement&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;13 Feet Ladder&lt;/h1&gt; 
&lt;p&gt;A site similar to &lt;a href="https://12ft.io"&gt;12ft.io&lt;/a&gt; but is self hosted and works with websites that 12ft.io doesn't work with.&lt;/p&gt; 
&lt;h2&gt;What is this?&lt;/h2&gt; 
&lt;p&gt;This is a simple self hosted server that has a simple but powerful interface to block ads, paywalls, and other nonsense. Specially for sites like medium, new york times which have paid articles that you normally cannot read. Now I do want you to support the creators you benefit from but if you just wanna see one single article and move on with your day then this might be helpful&lt;/p&gt; 
&lt;h2&gt;How does it work?&lt;/h2&gt; 
&lt;p&gt;It pretends to be GoogleBot (Google's web crawler) and gets the same content that google will get. Google gets the whole page so that the content of the article can be indexed properly and this takes advantage of that.&lt;/p&gt; 
&lt;h2&gt;How do I use it?&lt;/h2&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;docker&lt;/li&gt; 
 &lt;li&gt;Docker Compose (available as &lt;code&gt;docker compose&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;First, clone the repo to your machine then run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/wasi-master/13ft.git
cd 13ft
docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The image is also available from &lt;a href="https://hub.docker.com/r/wasimaster/13ft" title="docker pull wasimaster/13ft"&gt;DockerHub&lt;/a&gt; or &lt;a href="https://github.com/wasi-master/13ft/pkgs/container/13ft" title="docker pull ghcr.io/wasi-master/13ft:0.2.3"&gt;ghcr.io&lt;/a&gt; so the command &lt;code&gt;docker pull wasimaster/13ft&lt;/code&gt; also works.&lt;/p&gt; 
&lt;h3&gt;Standard Python script&lt;/h3&gt; 
&lt;p&gt;First, make sure you have &lt;a href="https://python.org"&gt;python&lt;/a&gt; installed on your machine. Next, clone the git repo. Then go to a terminal (&lt;code&gt;Command Prompt&lt;/code&gt; on Windows, &lt;code&gt;Terminal&lt;/code&gt; on Mac) and run the following command:&lt;/p&gt; 
&lt;p&gt;From the git cloned directory on your computer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd app/
python -m pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If that doesn't work retry but replace &lt;code&gt;python&lt;/code&gt; with &lt;code&gt;py&lt;/code&gt;, then try &lt;code&gt;python3&lt;/code&gt;, then try &lt;code&gt;py3&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Then run &lt;code&gt;portable.py&lt;/code&gt;, click &lt;a href="https://realpython.com/run-python-scripts/"&gt;this link&lt;/a&gt; for a tutorial on how to run python scripts.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python portable.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open the link shown in the terminal in the browser and you'll be able to use this&lt;/p&gt; 
&lt;h3&gt;Installation using venv and running under specific bind address / port&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 -m venv venv
source venv/bin/activate
python -m pip install -r requirements.txt
FLASK_APP=app/portable.py flask run --host=127.0.0.1 --port=9982
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using as a Bookmarklet in Chrome:&lt;/h2&gt; 
&lt;p&gt;You can create a bookmarklet that performs the URL transformation by writing a small JavaScript snippet. Below is the JavaScript code for your bookmarklet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;javascript:(function(){window.location.href='https://13ft.wasimaster.me/'+encodeURIComponent(window.location.href);})();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can replace &lt;a href="https://13ft.wasimaster.me"&gt;https://13ft.wasimaster.me&lt;/a&gt; with your own 13ft instance if desired.&lt;/p&gt; 
&lt;p&gt;Steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open Bookmarks Manager:&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Click on the three dots (menu) in the top-right corner of Chrome. Go to Bookmarks &amp;gt; Bookmark manager, or simply press Ctrl+Shift+O on Windows/Linux or Cmd+Option+B on Mac. Create a New Bookmark:&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the Bookmark Manager, click the three-dot menu in the top-right corner of the window and select Add new bookmark. Enter Bookmark Details:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Name: Enter a name for your bookmarklet, such as "13ft-ize". This name will show as a bookmark title in the bookmarks bar&lt;/li&gt; 
   &lt;li&gt;URL: Paste the JavaScript code provided above into the URL field.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Click Save.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Using the Bookmarklet:&lt;/p&gt; 
&lt;p&gt;Navigate to the page whose URL you want to use 13ft on.&lt;/p&gt; 
&lt;p&gt;Click on the bookmarklet you saved in your bookmarks bar. The browser will redirect you to the 13ft version of the URL using your service.&lt;/p&gt; 
&lt;p&gt;To show Bookmarks in Chrome, click the icon with three horizontal bars in the top right corner to open options. 2. In options, hover over "Bookmarks" to display a second menu where you can click the "Show bookmarks bar" text to toggle the bar on or off.&lt;/p&gt; 
&lt;p&gt;Instructions courtesy of &lt;a href="https://github.com/barakplasma"&gt;@barakplasma&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Customizing listening host and port, Systemd / Reverse-proxy example&lt;/h2&gt; 
&lt;h3&gt;Systemd Service&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;/lib/systemd/system/13ft.service
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;[Unit]
Description=13ft Flask Service
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
Restart=on-failure
RestartSec=10
User=www-data
Group=www-data
Environment=APP_PATH=/var/www/paywall-break
Environment=FLASK_APP=app/portable.py

ExecStart=/bin/bash -c "cd ${APP_PATH};${APP_PATH}/venv/bin/flask run --host=127.0.0.1 --port=22113"

# Make sure stderr/stdout is captured in the systemd journal.
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reverse Proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;VirtualHost *:22114&amp;gt;
    ErrorLog ${APACHE_LOG_DIR}/13ft-error.log
    CustomLog ${APACHE_LOG_DIR}/13ft-access.log combined

    ProxyRequests Off

    SSLEngine on
    SSLCertificateFile      /etc/ssl/certs/ssl-cert-snakeoil.pem
    SSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key
    Header always set Strict-Transport-Security "max-age=63072000"
    SSLProtocol             all -SSLv3 -TLSv1 -TLSv1.1

    SSLHonorCipherOrder     off
    SSLSessionTickets       off

    Protocols h2 http/1.1

    &amp;lt;Proxy *&amp;gt;
        Order deny,allow
        Allow from all
    &amp;lt;/Proxy&amp;gt;


    ProxyPass / http://127.0.0.1:22113/
    ProxyPassReverse / http://127.0.0.1:22113/


&amp;lt;/VirtualHost&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;h3&gt;Step 1&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wasi-master/13ft/main/screenshots/step-1.png" alt="step 1 screenshot" /&gt; Go to the website at the url shown in the console&lt;/p&gt; 
&lt;h3&gt;Step 2&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wasi-master/13ft/main/screenshots/step-2.png" alt="step 2 screenshot" /&gt; Click on the input box&lt;/p&gt; 
&lt;h3&gt;Step 3&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wasi-master/13ft/main/screenshots/step-3.png" alt="step 3 screenshot" /&gt; Paste your desired url&lt;/p&gt; 
&lt;h3&gt;Step 4&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wasi-master/13ft/main/screenshots/step-4.gif" alt="step 4 screenshot" /&gt; Voil√† you now have bypassed the paywall and ads&lt;/p&gt; 
&lt;h3&gt;Alternative method&lt;/h3&gt; 
&lt;p&gt;You can also append the url at the end of the link and it will also work. (e.g if your server is running at &lt;code&gt;http://127.0.0.1:5000&lt;/code&gt; then you can go to &lt;code&gt;http://127.0.0.1:5000/https://example.com&lt;/code&gt; and it will read out the contents of &lt;code&gt;https://example.com&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;This feature was implemented by &lt;a href="https://github.com/atcasanova"&gt;@atcasanova&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>awslabs/agent-squad</title>
      <link>https://github.com/awslabs/agent-squad</link>
      <description>&lt;p&gt;Flexible and powerful framework for managing multiple AI agents and handling complex conversations&lt;/p&gt;&lt;hr&gt;&lt;h2 align="center"&gt;Agent Squad&lt;/h2&gt; 
&lt;p align="center"&gt;Flexible, lightweight open-source framework for orchestrating multiple AI agents to handle complex conversations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt;üì¢ New Name Alert:&lt;/strong&gt; Multi-Agent Orchestrator is now &lt;strong&gt;Agent Squad!&lt;/strong&gt; üéâ&lt;br /&gt; Same powerful functionalities, new catchy name. Embrace the squad! &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/awslabs/agent-squad"&gt;&lt;img alt="GitHub Repo" src="https://img.shields.io/badge/GitHub-Repo-green.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/agent-squad"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/agent-squad.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/agent-squad/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/agent-squad.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- GitHub Stats --&gt; &lt;img src="https://img.shields.io/github/stars/awslabs/agent-squad?style=social" alt="GitHub stars" /&gt; &lt;img src="https://img.shields.io/github/forks/awslabs/agent-squad?style=social" alt="GitHub forks" /&gt; &lt;img src="https://img.shields.io/github/watchers/awslabs/agent-squad?style=social" alt="GitHub watchers" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Repository Info --&gt; &lt;img src="https://img.shields.io/github/last-commit/awslabs/agent-squad" alt="Last Commit" /&gt; &lt;img src="https://img.shields.io/github/issues/awslabs/agent-squad" alt="Issues" /&gt; &lt;img src="https://img.shields.io/github/issues-pr/awslabs/agent-squad" alt="Pull Requests" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://awslabs.github.io/agent-squad/" style="display: inline-block; background-color: #0066cc; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 15px; transition: background-color 0.3s;"&gt; üìö Explore Full Documentation &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üîñ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß† &lt;strong&gt;Intelligent intent classification&lt;/strong&gt; ‚Äî Dynamically route queries to the most suitable agent based on context and content.&lt;/li&gt; 
 &lt;li&gt;üî§ &lt;strong&gt;Dual language support&lt;/strong&gt; ‚Äî Fully implemented in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;üåä &lt;strong&gt;Flexible agent responses&lt;/strong&gt; ‚Äî Support for both streaming and non-streaming responses from different agents.&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Context management&lt;/strong&gt; ‚Äî Maintain and utilize conversation context across multiple agents for coherent interactions.&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Extensible architecture&lt;/strong&gt; ‚Äî Easily integrate new agents or customize existing ones to fit your specific needs.&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Universal deployment&lt;/strong&gt; ‚Äî Run anywhere - from AWS Lambda to your local environment or any cloud platform.&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;Pre-built agents and classifiers&lt;/strong&gt; ‚Äî A variety of ready-to-use agents and multiple classifier implementations available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's the Agent Squad ‚ùì&lt;/h2&gt; 
&lt;p&gt;The Agent Squad is a flexible framework for managing multiple AI agents and handling complex conversations. It intelligently routes queries and maintains context across interactions.&lt;/p&gt; 
&lt;p&gt;The system offers pre-built components for quick deployment, while also allowing easy integration of custom agents and conversation messages storage solutions.&lt;/p&gt; 
&lt;p&gt;This adaptability makes it suitable for a wide range of applications, from simple chatbots to sophisticated AI systems, accommodating diverse requirements and scaling efficiently.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è High-level architecture flow diagram&lt;/h2&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/flow.jpg" alt="High-level architecture flow diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The process begins with user input, which is analyzed by a Classifier.&lt;/li&gt; 
 &lt;li&gt;The Classifier leverages both Agents' Characteristics and Agents' Conversation history to select the most appropriate agent for the task.&lt;/li&gt; 
 &lt;li&gt;Once an agent is selected, it processes the user input.&lt;/li&gt; 
 &lt;li&gt;The orchestrator then saves the conversation, updating the Agents' Conversation history, before delivering the response back to the user.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/new.png" alt="" /&gt; Introducing SupervisorAgent: Agents Coordination&lt;/h2&gt; 
&lt;p&gt;The Agent Squad now includes a powerful new SupervisorAgent that enables sophisticated team coordination between multiple specialized agents. This new component implements a "agent-as-tools" architecture, allowing a lead agent to coordinate a team of specialized agents in parallel, maintaining context and delivering coherent responses.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/flow-supervisor.jpg" alt="SupervisorAgent flow diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Key capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Team Coordination&lt;/strong&gt; - Coordinate multiple specialized agents working together on complex tasks&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Parallel Processing&lt;/strong&gt; - Execute multiple agent queries simultaneously&lt;/li&gt; 
 &lt;li&gt;üß† &lt;strong&gt;Smart Context Management&lt;/strong&gt; - Maintain conversation history across all team members&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Dynamic Delegation&lt;/strong&gt; - Intelligently distribute subtasks to appropriate team members&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Compatibility&lt;/strong&gt; - Works with all agent types (Bedrock, Anthropic, Lex, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The SupervisorAgent can be used in two powerful ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Direct Usage&lt;/strong&gt; - Call it directly when you need dedicated team coordination for specific tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classifier Integration&lt;/strong&gt; - Add it as an agent within the classifier to build complex hierarchical systems with multiple specialized teams&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here are just a few examples where this agent can be used:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Customer Support Teams with specialized sub-teams&lt;/li&gt; 
 &lt;li&gt;AI Movie Production Studios&lt;/li&gt; 
 &lt;li&gt;Travel Planning Services&lt;/li&gt; 
 &lt;li&gt;Product Development Teams&lt;/li&gt; 
 &lt;li&gt;Healthcare Coordination Systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://awslabs.github.io/agent-squad/agents/built-in/supervisor-agent"&gt;Learn more about SupervisorAgent ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üí¨ Demo App&lt;/h2&gt; 
&lt;p&gt;In the screen recording below, we demonstrate an extended version of the demo app that uses 6 specialized agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Travel Agent&lt;/strong&gt;: Powered by an Amazon Lex Bot&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Weather Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with a tool to query the open-meteo API&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Restaurant Agent&lt;/strong&gt;: Implemented as an Amazon Bedrock Agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Math Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with two tools for executing mathematical operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tech Agent&lt;/strong&gt;: A Bedrock LLM Agent designed to answer questions on technical topics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Health Agent&lt;/strong&gt;: A Bedrock LLM Agent focused on addressing health-related queries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Watch as the system seamlessly switches context between diverse topics, from booking flights to checking weather, solving math problems, and providing health information. Notice how the appropriate agent is selected for each query, maintaining coherence even with brief follow-up inputs.&lt;/p&gt; 
&lt;p&gt;The demo highlights the system's ability to handle complex, multi-turn conversations while preserving context and leveraging specialized agents across various domains.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/demo-app.gif?raw=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;üéØ Examples &amp;amp; Quick Start&lt;/h2&gt; 
&lt;p&gt;Get hands-on experience with the Agent Squad through our diverse set of examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demo Applications&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/python"&gt;Streamlit Global Demo&lt;/a&gt;: A single Streamlit application showcasing multiple demos, including: 
    &lt;ul&gt; 
     &lt;li&gt;AI Movie Production Studio&lt;/li&gt; 
     &lt;li&gt;AI Travel Planner&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://awslabs.github.io/agent-squad/cookbook/examples/chat-demo-app/"&gt;Chat Demo App&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Explore multiple specialized agents handling various domains like travel, weather, math, and health&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://awslabs.github.io/agent-squad/cookbook/examples/ecommerce-support-simulator/"&gt;E-commerce Support Simulator&lt;/a&gt;: Experience AI-powered customer support with: 
    &lt;ul&gt; 
     &lt;li&gt;Automated response generation for common queries&lt;/li&gt; 
     &lt;li&gt;Intelligent routing of complex issues to human support&lt;/li&gt; 
     &lt;li&gt;Real-time chat and email-style communication&lt;/li&gt; 
     &lt;li&gt;Human-in-the-loop interactions for complex cases&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sample Projects&lt;/strong&gt;: Explore our example implementations in the &lt;code&gt;examples&lt;/code&gt; folder: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/chat-demo-app"&gt;&lt;code&gt;chat-demo-app&lt;/code&gt;&lt;/a&gt;: Web-based chat interface with multiple specialized agents&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/ecommerce-support-simulator"&gt;&lt;code&gt;ecommerce-support-simulator&lt;/code&gt;&lt;/a&gt;: AI-powered customer support system&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/chat-chainlit-app"&gt;&lt;code&gt;chat-chainlit-app&lt;/code&gt;&lt;/a&gt;: Chat application built with Chainlit&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/fast-api-streaming"&gt;&lt;code&gt;fast-api-streaming&lt;/code&gt;&lt;/a&gt;: FastAPI implementation with streaming support&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/text-2-structured-output"&gt;&lt;code&gt;text-2-structured-output&lt;/code&gt;&lt;/a&gt;: Natural Language to Structured Data&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/bedrock-inline-agents"&gt;&lt;code&gt;bedrock-inline-agents&lt;/code&gt;&lt;/a&gt;: Bedrock Inline Agents sample&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/bedrock-prompt-routing"&gt;&lt;code&gt;bedrock-prompt-routing&lt;/code&gt;&lt;/a&gt;: Bedrock Prompt Routing sample code&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples are available in both Python and TypeScript. Check out our &lt;a href="https://awslabs.github.io/agent-squad/"&gt;documentation&lt;/a&gt; for comprehensive guides on setting up and using the Agent Squad framework!&lt;/p&gt; 
&lt;h2&gt;üìö Deep Dives: Stories, Blogs &amp;amp; Podcasts&lt;/h2&gt; 
&lt;p&gt;Discover creative implementations and diverse applications of the Agent Squad:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2lCi8jEKydhDm8eE8QFIQ5K23pF/from-bonjour-to-boarding-pass-multilingual-ai-chatbot-for-flight-reservations"&gt;From 'Bonjour' to 'Boarding Pass': Multilingual AI Chatbot for Flight Reservations&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build a multilingual chatbot using the Agent Squad framework. The article explains how to use an &lt;strong&gt;Amazon Lex&lt;/strong&gt; bot as an agent, along with 2 other new agents to make it work in many languages with just a few lines of code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2lq6cYYwTYGc7S3Zmz28xZoQNQj/beyond-auto-replies-building-an-ai-powered-e-commerce-support-system"&gt;Beyond Auto-Replies: Building an AI-Powered E-commerce Support system&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI-driven multi-agent system for automated e-commerce customer email support. It covers the architecture and setup of specialized AI agents using the Agent Squad framework, integrating automated processing with human-in-the-loop oversight. The guide explores email ingestion, intelligent routing, automated response generation, and human verification, providing a comprehensive approach to balancing AI efficiency with human expertise in customer support.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2mt7CFG7xg4yw6GRHwH9akhg0oD/speak-up-ai-voicing-your-agents-with-amazon-connect-lex-and-bedrock"&gt;Speak Up, AI: Voicing Your Agents with Amazon Connect, Lex, and Bedrock&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI customer call center. It covers the architecture and setup of specialized AI agents using the Agent Squad framework interacting with voice via &lt;strong&gt;Amazon Connect&lt;/strong&gt; and &lt;strong&gt;Amazon Lex&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2pTsHrYPqvAbJBl9ht1XxPOSPjR/unlock-bedrock-invokeinlineagent-api-s-hidden-potential-with-agent-squad"&gt;Unlock Bedrock InvokeInlineAgent API's Hidden Potential&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Learn how to scale &lt;strong&gt;Amazon Bedrock Agents&lt;/strong&gt; beyond knowledge base limitations using the Agent Squad framework and &lt;strong&gt;InvokeInlineAgent API&lt;/strong&gt;. This article demonstrates dynamic agent creation and knowledge base selection for enterprise-scale AI applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2phMjQ0bqWMg4PBwejBs1uf4YQE/supercharging-amazon-bedrock-flows-with-aws-agent-squad"&gt;Supercharging Amazon Bedrock Flows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Learn how to enhance &lt;strong&gt;Amazon Bedrock Flows&lt;/strong&gt; with conversation memory and multi-flow orchestration using the Agent Squad framework. This guide shows how to overcome Bedrock Flows' limitations to build more sophisticated AI workflows with persistent memory and intelligent routing between flows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéôÔ∏è Podcast Discussions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üá´üá∑ Podcast (French)&lt;/strong&gt;: L'orchestrateur multi-agents : Un orchestrateur open source pour vos agents IA&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Platforms&lt;/strong&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://podcasts.apple.com/be/podcast/lorchestrateur-multi-agents/id1452118442?i=1000684332612"&gt;Apple Podcasts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://open.spotify.com/episode/4RdMazSRhZUyW2pniG91Vf"&gt;Spotify&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üá¨üáß Podcast (English)&lt;/strong&gt;: An Orchestrator for Your AI Agents&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Platforms&lt;/strong&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://podcasts.apple.com/us/podcast/an-orchestrator-for-your-ai-agents/id1574162669?i=1000677039579"&gt;Apple Podcasts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://open.spotify.com/episode/2a9DBGZn2lVqVMBLWGipHU"&gt;Spotify&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;TypeScript Version&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üîÑ &lt;code&gt;multi-agent-orchestrator&lt;/code&gt; becomes &lt;code&gt;agent-squad&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install agent-squad
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;p&gt;The following example demonstrates how to use the Agent Squad with two different types of agents: a Bedrock LLM Agent with Converse API support and a Lex Bot Agent. This showcases the flexibility of the system in integrating various AI services.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AgentSquad, BedrockLLMAgent, LexBotAgent } from "agent-squad";

const orchestrator = new AgentSquad();

// Add a Bedrock LLM Agent with Converse API support
orchestrator.addAgent(
  new BedrockLLMAgent({
      name: "Tech Agent",
      description:
        "Specializes in technology areas including software development, hardware, AI, cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs related to technology products and services.",
      streaming: true
  })
);

// Add a Lex Bot Agent for handling travel-related queries
orchestrator.addAgent(
  new LexBotAgent({
    name: "Travel Agent",
    description: "Helps users book and manage their flight reservations",
    botId: process.env.LEX_BOT_ID,
    botAliasId: process.env.LEX_BOT_ALIAS_ID,
    localeId: "en_US",
  })
);

// Example usage
const response = await orchestrator.routeRequest(
  "I want to book a flight",
  'user123',
  'session456'
);

// Handle the response (streaming or non-streaming)
if (response.streaming == true) {
    console.log("\n** RESPONSE STREAMING ** \n");
    // Send metadata immediately
    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);
    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);
    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);
    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);
    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);
    console.log(
      `&amp;gt; Additional Parameters:`,
      response.metadata.additionalParams
    );
    console.log(`\n&amp;gt; Response: `);

    // Stream the content
    for await (const chunk of response.output) {
      if (typeof chunk === "string") {
        process.stdout.write(chunk);
      } else {
        console.error("Received unexpected chunk type:", typeof chunk);
      }
    }

} else {
    // Handle non-streaming response (AgentProcessingResult)
    console.log("\n** RESPONSE ** \n");
    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);
    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);
    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);
    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);
    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);
    console.log(
      `&amp;gt; Additional Parameters:`,
      response.metadata.additionalParams
    );
    console.log(`\n&amp;gt; Response: ${response.output}`);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python Version&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üîÑ &lt;code&gt;multi-agent-orchestrator&lt;/code&gt; becomes &lt;code&gt;agent-squad&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Optional: Set up a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
pip install agent-squad[aws]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Default Usage&lt;/h4&gt; 
&lt;p&gt;Here's an equivalent Python example demonstrating the use of the Agent Squad with a Bedrock LLM Agent and a Lex Bot Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
import asyncio
from agent_squad.orchestrator import AgentSquad
from agent_squad.agents import BedrockLLMAgent, BedrockLLMAgentOptions, AgentStreamResponse

orchestrator = AgentSquad()

tech_agent = BedrockLLMAgent(BedrockLLMAgentOptions(
  name="Tech Agent",
  streaming=True,
  description="Specializes in technology areas including software development, hardware, AI, \
  cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs \
  related to technology products and services.",
  model_id="anthropic.claude-3-sonnet-20240229-v1:0",
))
orchestrator.add_agent(tech_agent)


health_agent = BedrockLLMAgent(BedrockLLMAgentOptions(
  name="Health Agent",
  streaming=True,
  description="Specializes in health and well being",
))
orchestrator.add_agent(health_agent)

async def main():
    # Example usage
    response = await orchestrator.route_request(
        "What is AWS Lambda?",
        'user123',
        'session456',
        {},
        True
    )

    # Handle the response (streaming or non-streaming)
    if response.streaming:
        print("\n** RESPONSE STREAMING ** \n")
        # Send metadata immediately
        print(f"&amp;gt; Agent ID: {response.metadata.agent_id}")
        print(f"&amp;gt; Agent Name: {response.metadata.agent_name}")
        print(f"&amp;gt; User Input: {response.metadata.user_input}")
        print(f"&amp;gt; User ID: {response.metadata.user_id}")
        print(f"&amp;gt; Session ID: {response.metadata.session_id}")
        print(f"&amp;gt; Additional Parameters: {response.metadata.additional_params}")
        print("\n&amp;gt; Response: ")

        # Stream the content
        async for chunk in response.output:
            async for chunk in response.output:
              if isinstance(chunk, AgentStreamResponse):
                  print(chunk.text, end='', flush=True)
              else:
                  print(f"Received unexpected chunk type: {type(chunk)}", file=sys.stderr)

    else:
        # Handle non-streaming response (AgentProcessingResult)
        print("\n** RESPONSE ** \n")
        print(f"&amp;gt; Agent ID: {response.metadata.agent_id}")
        print(f"&amp;gt; Agent Name: {response.metadata.agent_name}")
        print(f"&amp;gt; User Input: {response.metadata.user_input}")
        print(f"&amp;gt; User ID: {response.metadata.user_id}")
        print(f"&amp;gt; Session ID: {response.metadata.session_id}")
        print(f"&amp;gt; Additional Parameters: {response.metadata.additional_params}")
        print(f"\n&amp;gt; Response: {response.output.content}")

if __name__ == "__main__":
  asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These examples showcase:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The use of a Bedrock LLM Agent with Converse API support, allowing for multi-turn conversations.&lt;/li&gt; 
 &lt;li&gt;Integration of a Lex Bot Agent for specialized tasks (in this case, travel-related queries).&lt;/li&gt; 
 &lt;li&gt;The orchestrator's ability to route requests to the most appropriate agent based on the input.&lt;/li&gt; 
 &lt;li&gt;Handling of both streaming and non-streaming responses from different types of agents.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Modular Installation Options&lt;/h3&gt; 
&lt;p&gt;The Agent Squad is designed with a modular architecture, allowing you to install only the components you need while ensuring you always get the core functionality.&lt;/p&gt; 
&lt;h4&gt;Installation Options&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;1. AWS Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; pip install "agent-squad[aws]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes core orchestration functionality with comprehensive AWS service integrations (&lt;code&gt;BedrockLLMAgent&lt;/code&gt;, &lt;code&gt;AmazonBedrockAgent&lt;/code&gt;, &lt;code&gt;LambdaAgent&lt;/code&gt;, etc.)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Anthropic Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[anthropic]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;3. OpenAI Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[openai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Adds OpenAI's GPT models for agents and classification, along with core packages.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. Full Installation&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes all optional dependencies for maximum flexibility.&lt;/p&gt; 
&lt;h3&gt;üôå &lt;strong&gt;We Want to Hear From You!&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Have something to share, discuss, or brainstorm? We‚Äôd love to connect with you and hear about your journey with the &lt;strong&gt;Agent Squad framework&lt;/strong&gt;. Here‚Äôs how you can get involved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üôå Show &amp;amp; Tell&lt;/strong&gt;: Got a success story, cool project, or creative implementation? Share it with us in the &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/show-and-tell"&gt;&lt;strong&gt;Show and Tell&lt;/strong&gt;&lt;/a&gt; section. Your work might inspire the entire community! üéâ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí¨ General Discussion&lt;/strong&gt;: Have questions, feedback, or suggestions? Join the conversation in our &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/general"&gt;&lt;strong&gt;General Discussions&lt;/strong&gt;&lt;/a&gt; section. It‚Äôs the perfect place to connect with other users and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí° Ideas&lt;/strong&gt;: Thinking of a new feature or improvement? Share your thoughts in the &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/ideas"&gt;&lt;strong&gt;Ideas&lt;/strong&gt;&lt;/a&gt; section. We‚Äôre always open to exploring innovative ways to make the orchestrator even better!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Let‚Äôs collaborate, learn from each other, and build something incredible together! üöÄ&lt;/p&gt; 
&lt;h2&gt;üìù Pull Request Guidelines&lt;/h2&gt; 
&lt;h3&gt;Issue-First Policy&lt;/h3&gt; 
&lt;p&gt;This repository follows an &lt;strong&gt;Issue-First&lt;/strong&gt; policy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Every pull request must be linked to an existing issue&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;If there isn't an issue for the changes you want to make, please create one first&lt;/li&gt; 
 &lt;li&gt;Use the issue to discuss proposed changes before investing time in implementation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to Link Pull Requests to Issues&lt;/h3&gt; 
&lt;p&gt;When creating a pull request, you must link it to an issue using one of these methods:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Include a reference in the PR description using keywords:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Fixes #123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Resolves #123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Closes #123&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Manually link the PR to an issue through GitHub's UI:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On the right sidebar of your PR, click "Development" and then "Link an issue"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Automated Enforcement&lt;/h3&gt; 
&lt;p&gt;We use GitHub Actions to automatically verify that each PR is linked to an issue. PRs without linked issues will not pass required checks and cannot be merged.&lt;/p&gt; 
&lt;p&gt;This policy helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Maintain clear documentation of changes and their purposes&lt;/li&gt; 
 &lt;li&gt;Ensure community discussion before implementation&lt;/li&gt; 
 &lt;li&gt;Keep a structured development process&lt;/li&gt; 
 &lt;li&gt;Make project history more traceable and understandable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;‚ö†Ô∏è Note: Our project has been renamed from &lt;strong&gt;Multi-Agent Orchestrator&lt;/strong&gt; to &lt;strong&gt;Agent Squad&lt;/strong&gt;. Please use the new name in your contributions and discussions.&lt;/p&gt; 
&lt;p&gt;‚ö†Ô∏è We value your contributions! Before submitting changes, please start a discussion by opening an issue to share your proposal.&lt;/p&gt; 
&lt;p&gt;Once your proposal is approved, here are the next steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;üìö Review our &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° Create a &lt;a href="https://github.com/awslabs/agent-squad/issues"&gt;GitHub Issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî® Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;‚úÖ Follow existing project structure and include documentation for new features.&lt;/p&gt; 
&lt;p&gt;üåü &lt;strong&gt;Stay Updated&lt;/strong&gt;: Star the repository to be notified about new features, improvements, and exciting developments in the Agent Squad framework!&lt;/p&gt; 
&lt;h1&gt;Authors&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/corneliucroitoru/"&gt;Corneliu Croitoru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/anthonybernabeu/"&gt;Anthony Bernabeu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üë• Contributors&lt;/h1&gt; 
&lt;p&gt;Big shout out to our awesome contributors! Thank you for making this project better! üåü ‚≠ê üöÄ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/awslabs/agent-squad/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=awslabs/agent-squad&amp;amp;max=2000" alt="contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for guidelines on how to propose bugfixes and improvements.&lt;/p&gt; 
&lt;h2&gt;üìÑ LICENSE&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 licence - see the &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üìÑ Font License&lt;/h2&gt; 
&lt;p&gt;This project uses the JetBrainsMono NF font, licensed under the SIL Open Font License 1.1. For full license details, see &lt;a href="https://github.com/JetBrains/JetBrainsMono/raw/master/OFL.txt"&gt;FONT-LICENSE.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cinnamon/kotaemon</title>
      <link>https://github.com/Cinnamon/kotaemon</link>
      <description>&lt;p&gt;An open-source RAG-based tool for chatting with your documents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;kotaemon&lt;/h1&gt; 
 &lt;p&gt;An open-source clean &amp;amp; customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png" alt="Preview" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11607" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11607" alt="Cinnamon%2Fkotaemon | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/spaces/cin-model/kotaemon"&gt;Live Demo #1&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;Live Demo #2&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/online_install/"&gt;Online Install&lt;/a&gt; | &lt;a href="https://colab.research.google.com/drive/1eTfieec_UOowNizTJA1NjawBJH9y_1nn"&gt;Colab Notebook (Local RAG)&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/development/"&gt;Developer Guide&lt;/a&gt; | &lt;a href="https://github.com/Cinnamon/kotaemon/issues"&gt;Feedback&lt;/a&gt; | &lt;a href="mailto:kotaemon.support@cinnamon.is"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/downloads/release/python-31013/"&gt;&lt;img src="https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true" alt="Python 3.10+" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docker_pull-kotaemon:latest-brightgreen" alt="docker pull ghcr.io/cinnamon/kotaemon:latest" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/Cinnamon/kotaemon/total.svg?label=downloads&amp;amp;color=blue" alt="download" /&gt; &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" /&gt;&lt;/a&gt; &lt;a href="https://hellogithub.com/en/repository/d3141471a0244d5798bc654982b263eb" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=d3141471a0244d5798bc654982b263eb&amp;amp;claim_uid=RLiD9UZ1rEHNaMf&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- start-intro --&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;This project serves as a functional RAG UI for both end users who want to do QA on their documents and developers who want to build their own RAG pipeline. &lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;+----------------------------------------------------------------------------+
| End users: Those who use apps built with `kotaemon`.                       |
| (You use an app like the one in the demo above)                            |
|     +----------------------------------------------------------------+     |
|     | Developers: Those who built with `kotaemon`.                   |     |
|     | (You have `import kotaemon` somewhere in your project)         |     |
|     |     +----------------------------------------------------+     |     |
|     |     | Contributors: Those who make `kotaemon` better.    |     |     |
|     |     | (You make PR to this repo)                         |     |     |
|     |     +----------------------------------------------------+     |     |
|     +----------------------------------------------------------------+     |
+----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;For end users&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Clean &amp;amp; Minimalistic UI&lt;/strong&gt;: A user-friendly interface for RAG-based QA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support for Various LLMs&lt;/strong&gt;: Compatible with LLM API providers (OpenAI, AzureOpenAI, Cohere, etc.) and local LLMs (via &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llama-cpp-python&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Installation&lt;/strong&gt;: Simple scripts to get you started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For developers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework for RAG Pipelines&lt;/strong&gt;: Tools to build your own RAG-based document QA pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable UI&lt;/strong&gt;: See your RAG pipeline in action with the provided UI, built with &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio &lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradio Theme&lt;/strong&gt;: If you use Gradio for development, check out our theme here: &lt;a href="https://github.com/lone17/kotaemon-gradio-theme"&gt;kotaemon-gradio-theme&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Host your own document QA (RAG) web-UI&lt;/strong&gt;: Support multi-user login, organize your files in private/public collections, collaborate and share your favorite chat with others.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Organize your LLM &amp;amp; Embedding models&lt;/strong&gt;: Support both local LLMs &amp;amp; popular API providers (OpenAI, Azure, Ollama, Groq).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid RAG pipeline&lt;/strong&gt;: Sane default RAG pipeline with hybrid (full-text &amp;amp; vector) retriever and re-ranking to ensure best retrieval quality.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-modal QA support&lt;/strong&gt;: Perform Question Answering on multiple documents with figures and tables support. Support multi-modal document parsing (selectable options on UI).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced citations with document preview&lt;/strong&gt;: By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the &lt;em&gt;in-browser PDF viewer&lt;/em&gt; with highlights. Warning when retrieval pipeline return low relevant articles.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support complex reasoning methods&lt;/strong&gt;: Use question decomposition to answer your complex/multi-hop question. Support agent-based reasoning with &lt;code&gt;ReAct&lt;/code&gt;, &lt;code&gt;ReWOO&lt;/code&gt; and other agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configurable settings UI&lt;/strong&gt;: You can adjust most important aspects of retrieval &amp;amp; generation process on the UI (incl. prompts).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Being built on Gradio, you are free to customize or add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp;amp; retrieval. &lt;code&gt;GraphRAG&lt;/code&gt; indexing pipeline is provided as an example.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png" alt="Preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you are not a developer and just want to use the app, please check out our easy-to-follow &lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt;. Download the &lt;code&gt;.zip&lt;/code&gt; file from the &lt;a href="https://github.com/Cinnamon/kotaemon/releases/latest"&gt;latest release&lt;/a&gt; to get all the newest features and bug fixes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;System requirements&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; &amp;gt;= 3.10&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;: optional, if you &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/#with-docker-recommended"&gt;install with Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.unstructured.io/open-source/installation/full-installation#full-installation"&gt;Unstructured&lt;/a&gt; if you want to process files other than &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.mhtml&lt;/code&gt;, and &lt;code&gt;.xlsx&lt;/code&gt; documents. Installation steps differ depending on your operating system. Please visit the link and follow the specific instructions provided there.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;With Docker (recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;We support both &lt;code&gt;lite&lt;/code&gt; &amp;amp; &lt;code&gt;full&lt;/code&gt; version of Docker images. With &lt;code&gt;full&lt;/code&gt; version, the extra packages of &lt;code&gt;unstructured&lt;/code&gt; will be installed, which can support additional file types (&lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, ...) but the cost is larger docker image size. For most users, the &lt;code&gt;lite&lt;/code&gt; image should work well in most cases.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
ghcr.io/cinnamon/kotaemon:main-full
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version with bundled &lt;strong&gt;Ollama&lt;/strong&gt; for &lt;em&gt;local / private RAG&lt;/em&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# change image name to
docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-ollama
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;lite&lt;/code&gt; version.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; # change image name to
 docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We currently support and test two platforms: &lt;code&gt;linux/amd64&lt;/code&gt; and &lt;code&gt;linux/arm64&lt;/code&gt; (for newer Mac). You can specify the platform by passing &lt;code&gt;--platform&lt;/code&gt; in the &lt;code&gt;docker run&lt;/code&gt; command. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# To run docker with platform linux/arm64
docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
--platform linux/arm64 \
ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once everything is set up correctly, you can go to &lt;code&gt;http://localhost:7860/&lt;/code&gt; to access the WebUI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry"&gt;GHCR&lt;/a&gt; to store docker images, all images can be found &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon"&gt;here.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Without Docker&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone and install required packages on a fresh python environment.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# optional (setup env)
conda create -n kotaemon python=3.10
conda activate kotaemon

# clone this repo
git clone https://github.com/Cinnamon/kotaemon
cd kotaemon

pip install -e "libs/kotaemon[all]"
pip install -e "libs/ktem"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root of this project. Use &lt;code&gt;.env.example&lt;/code&gt; as a template&lt;/p&gt; &lt;p&gt;The &lt;code&gt;.env&lt;/code&gt; file is there to serve use cases where users want to pre-config the models before starting up the app (e.g. deploy the app on HF hub). The file will only be used to populate the db once upon the first run, it will no longer be used in consequent runs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) To enable in-browser &lt;code&gt;PDF_JS&lt;/code&gt; viewer, download &lt;a href="https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip"&gt;PDF_JS_DIST&lt;/a&gt; then extract it to &lt;code&gt;libs/ktem/ktem/assets/prebuilt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png" alt="pdf-setup" width="300" /&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt; &lt;p&gt;Start the web server:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;python app.py
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The app will be automatically launched in your browser.&lt;/li&gt; 
   &lt;li&gt;Default username and password are both &lt;code&gt;admin&lt;/code&gt;. You can set up additional users directly through the UI.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png" alt="Chat tab" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Check the &lt;code&gt;Resources&lt;/code&gt; tab and &lt;code&gt;LLMs and Embeddings&lt;/code&gt; and ensure that your &lt;code&gt;api_key&lt;/code&gt; value is set correctly from your &lt;code&gt;.env&lt;/code&gt; file. If it is not set, you can set it there.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Setup GraphRAG&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Official MS GraphRAG indexing only works with OpenAI or Ollama API. We recommend most users to use NanoGraphRAG implementation for straightforward integration with Kotaemon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup Nano GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install nano-GraphRAG: &lt;code&gt;pip install nano-graphrag&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;nano-graphrag&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_NANO_GRAPHRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from NanoGraphRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup LIGHTRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install LightRAG: &lt;code&gt;pip install git+https://github.com/HKUDS/LightRAG.git&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LightRAG&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_LIGHTRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from LightRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup MS GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Non-Docker Installation&lt;/strong&gt;: If you are not using Docker, install GraphRAG with the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip install "graphrag&amp;lt;=0.3.6" future
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Setting Up API KEY&lt;/strong&gt;: To use the GraphRAG retriever feature, ensure you set the &lt;code&gt;GRAPHRAG_API_KEY&lt;/code&gt; environment variable. You can do this directly in your environment or by adding it to a &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Local Models and Custom Settings&lt;/strong&gt;: If you want to use GraphRAG with local models (like &lt;code&gt;Ollama&lt;/code&gt;) or customize the default LLM and other configurations, set the &lt;code&gt;USE_CUSTOMIZED_GRAPHRAG_SETTING&lt;/code&gt; environment variable to true. Then, adjust your settings in the &lt;code&gt;settings.yaml.example&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Setup Local Models (for local/private RAG)&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/local_model.md"&gt;Local model setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Setup multimodal document parsing (OCR, table parsing, figure extraction)&lt;/h3&gt; 
&lt;p&gt;These options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence"&gt;Azure Document Intelligence (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/"&gt;Adobe PDF Extract (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DS4SD/docling"&gt;Docling (local, open-source)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;To use Docling, first install required dependencies: &lt;code&gt;pip install docling&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Select corresponding loaders in &lt;code&gt;Settings -&amp;gt; Retrieval Settings -&amp;gt; File loader&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Customize your application&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;By default, all application data is stored in the &lt;code&gt;./ktem_app_data&lt;/code&gt; folder. You can back up or copy this folder to transfer your installation to a new machine.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For advanced users or specific use cases, you can customize these files:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file contains the configuration of your application. You can use the example &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/flowsettings.py"&gt;here&lt;/a&gt; as the starting point.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Notable settings&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# setup your preferred document store (with full-text search capabilities)
KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)

# setup your preferred vectorstore (for vector-based search)
KH_VECTORSTORE=(ChromaDB | LanceDB | InMemory | Milvus | Qdrant)

# Enable / disable multimodal QA
KH_REASONINGS_USE_MULTIMODAL=True

# Setup your new reasoning pipeline or modify existing one.
KH_REASONINGS = [
    "ktem.reasoning.simple.FullQAPipeline",
    "ktem.reasoning.simple.FullDecomposeQAPipeline",
    "ktem.reasoning.react.ReactAgentPipeline",
    "ktem.reasoning.rewoo.RewooAgentPipeline",
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file provides another way to configure your models and credentials.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Configure model via the .env file&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Alternatively, you can configure the models via the &lt;code&gt;.env&lt;/code&gt; file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don't see it, you can create one.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Currently, the following providers are supported:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;.env&lt;/code&gt; file, set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; variable with your OpenAI API key in order to enable access to OpenAI's models. There are other variables that can be modified, please feel free to edit them to fit your case. Otherwise, the default parameter should work for most people.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=&amp;lt;your OpenAI API key here&amp;gt;
OPENAI_CHAT_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For OpenAI models via Azure platform, you need to provide your Azure endpoint and API key. Your might also need to provide your developments' name for the chat model and the embedding model depending on how you set up Azure development.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local Models&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;ollama&lt;/code&gt; OpenAI compatible server:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/ollama/ollama"&gt;ollama&lt;/a&gt; and start the application.&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Pull your model, for example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.1:8b
ollama pull nomic-embed-text
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Set the model names on web UI and make it as default:&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png" alt="Models" /&gt;&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;GGUF&lt;/code&gt; with &lt;code&gt;llama-cpp-python&lt;/code&gt;&lt;/p&gt; &lt;p&gt;You can search and download a LLM to be ran locally from the &lt;a href="https://huggingface.co/models"&gt;Hugging Face Hub&lt;/a&gt;. Currently, these model formats are supported:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;GGUF&lt;/p&gt; &lt;p&gt;You should choose a model whose size is less than your device's memory and should leave about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available, then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to give better generation but also take more processing time.&lt;/p&gt; &lt;p&gt;Here are some recommendations and their size in memory:&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true"&gt;Qwen1.5-1.8B-Chat-GGUF&lt;/a&gt;: around 2 GB&lt;/p&gt; &lt;p&gt;Add a new LlamaCpp model with the provided model name on the web UI.&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;   
&lt;h3&gt;Adding your own RAG pipeline&lt;/h3&gt; 
&lt;h4&gt;Custom Reasoning Pipeline&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check the default pipeline implementation in &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/libs/ktem/ktem/reasoning/simple.py"&gt;here&lt;/a&gt;. You can make quick adjustment to how the default QA pipeline work.&lt;/li&gt; 
 &lt;li&gt;Add new &lt;code&gt;.py&lt;/code&gt; implementation in &lt;code&gt;libs/ktem/ktem/reasoning/&lt;/code&gt; and later include it in &lt;code&gt;flowssettings&lt;/code&gt; to enable it on the UI.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Custom Indexing Pipeline&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check sample implementation in &lt;code&gt;libs/ktem/ktem/index/file/graph&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;(more instruction WIP).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- end-intro --&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite this project as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{kotaemon2024,
    title = {Kotaemon - An open-source RAG-based tool for chatting with any content.},
    author = {The Kotaemon Team},
    year = {2024},
    howpublished = {\url{https://github.com/Cinnamon/kotaemon}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#Cinnamon/kotaemon&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Since our project is actively being developed, we greatly value your feedback and contributions. Please see our &lt;a href="https://github.com/Cinnamon/kotaemon/raw/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started. Thank you to all our contributors!&lt;/p&gt; 
&lt;a href="https://github.com/Cinnamon/kotaemon/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Cinnamon/kotaemon" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.2 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>