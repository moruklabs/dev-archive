<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Fri, 14 Nov 2025 01:44:41 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;ğŸ¯ å‘Šåˆ«ä¿¡æ¯è¿‡è½½ï¼ŒAI åŠ©ä½ çœ‹æ‡‚æ–°é—»èµ„è®¯çƒ­ç‚¹ï¼Œç®€å•çš„èˆ†æƒ…ç›‘æ§åˆ†æ - å¤šå¹³å°çƒ­ç‚¹èšåˆ+åŸºäº MCP çš„AIåˆ†æå·¥å…·ã€‚ç›‘æ§35ä¸ªå¹³å°ï¼ˆæŠ–éŸ³ã€çŸ¥ä¹ã€Bç«™ã€åå°”è¡—è§é—»ã€è´¢è”ç¤¾ç­‰ï¼‰ï¼Œæ™ºèƒ½ç­›é€‰+è‡ªåŠ¨æ¨é€+AIå¯¹è¯åˆ†æï¼ˆç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»ï¼šè¶‹åŠ¿è¿½è¸ªã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ£€ç´¢ç­‰13ç§å·¥å…·ï¼‰ã€‚æ”¯æŒä¼ä¸šå¾®ä¿¡/é£ä¹¦/é’‰é’‰/Telegram/é‚®ä»¶/ntfyæ¨é€ï¼Œ30ç§’ç½‘é¡µéƒ¨ç½²ï¼Œ1åˆ†é’Ÿæ‰‹æœºé€šçŸ¥ï¼Œæ— éœ€ç¼–ç¨‹ã€‚æ”¯æŒDockeréƒ¨ç½²â­ è®©ç®—æ³•ä¸ºä½ æœåŠ¡ï¼Œç”¨AIç†è§£çƒ­ç‚¹&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="trendradar"&gt; 
 &lt;a href="https://github.com/sansan0/TrendRadar" title="TrendRadar"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner.jpg" alt="TrendRadar Banner" width="50%" /&gt; &lt;/a&gt; 
 &lt;p&gt;ğŸš€ æœ€å¿«&lt;strong&gt;30ç§’&lt;/strong&gt;éƒ¨ç½²çš„çƒ­ç‚¹åŠ©æ‰‹ â€”â€” å‘Šåˆ«æ— æ•ˆåˆ·å±ï¼Œåªçœ‹çœŸæ­£å…³å¿ƒçš„æ–°é—»èµ„è®¯&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14726" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14726" alt="sansan0%2FTrendRadar | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=yellow" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/version-v3.0.5-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/MCP-v1.0.1-green.svg?sanitize=true" alt="MCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://work.weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ä¼ä¸šå¾®ä¿¡é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://telegram.org/"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="Telegramé€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/%E9%92%89%E9%92%89-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="dingtalké€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://www.feishu.cn/"&gt;&lt;img src="https://img.shields.io/badge/%E9%A3%9E%E4%B9%A6-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é£ä¹¦é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/Email-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é‚®ä»¶é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://github.com/binwiederhier/ntfy"&gt;&lt;img src="https://img.shields.io/badge/ntfy-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ntfyé€šçŸ¥" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Actions-%E8%87%AA%E5%8A%A8%E5%8C%96-2088FF?style=flat-square&amp;amp;logo=github-actions&amp;amp;logoColor=white" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://sansan0.github.io/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Pages-%E9%83%A8%E7%BD%B2-4285F4?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Pages" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/wantcat/trendradar"&gt;&lt;img src="https://img.shields.io/badge/Docker-%E9%83%A8%E7%BD%B2-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io/"&gt;&lt;img src="https://img.shields.io/badge/MCP-AI%E5%88%86%E6%9E%90%E6%94%AF%E6%8C%81-FF6B6B?style=flat-square&amp;amp;logo=ai&amp;amp;logoColor=white" alt="MCP Support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä»¥è½»é‡ï¼Œæ˜“éƒ¨ç½²ä¸ºç›®æ ‡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ“‘ å¿«é€Ÿå¯¼èˆª&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"&gt;ğŸ¯ æ ¸å¿ƒåŠŸèƒ½&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Dockeréƒ¨ç½²&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E9%83%A8%E7%BD%B2"&gt;ğŸ¤– AIåˆ†æä¸“åŒº&lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-mcp-%E5%AE%A2%E6%88%B7%E7%AB%AF"&gt;ğŸ”Œ MCPå®¢æˆ·ç«¯&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;â“ ç­”ç–‘ä¸å¸¸è§é—®é¢˜&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3"&gt;â­ é¡¹ç›®ç›¸å…³&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;è€å¿ƒåé¦ˆ bug&lt;/strong&gt; çš„è´¡çŒ®è€…ï¼Œä½ ä»¬çš„æ¯ä¸€æ¡åé¦ˆè®©é¡¹ç›®æ›´åŠ å®Œå–„ğŸ˜‰;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;ä¸ºé¡¹ç›®ç‚¹ star&lt;/strong&gt; çš„è§‚ä¼—ä»¬ï¼Œ&lt;strong&gt;fork&lt;/strong&gt; ä½ æ‰€æ¬²ä¹Ÿï¼Œ&lt;strong&gt;star&lt;/strong&gt; æˆ‘æ‰€æ¬²ä¹Ÿï¼Œä¸¤è€…å¾—å…¼ğŸ˜æ˜¯å¯¹å¼€æºç²¾ç¥æœ€å¥½çš„æ”¯æŒ;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;å…³æ³¨&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;å…¬ä¼—å·&lt;/a&gt;&lt;/strong&gt; çš„è¯»è€…ä»¬ï¼Œä½ ä»¬çš„ç•™è¨€ã€ç‚¹èµã€åˆ†äº«å’Œæ¨èç­‰ç§¯æäº’åŠ¨è®©å†…å®¹æ›´æœ‰æ¸©åº¦ğŸ˜ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»æŸ¥çœ‹&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt; (å½“å‰ &lt;strong&gt;ğŸ”¥59ğŸ”¥&lt;/strong&gt; ä½)&lt;/summary&gt; 
 &lt;h3&gt;æ•°æ®æ”¯æŒ&lt;/h3&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä½¿ç”¨äº† &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; é¡¹ç›®æä¾›çš„ API æ¥å£è·å–å¤šå¹³å°æ•°æ®&lt;/p&gt; 
 &lt;h3&gt;æ¨å¹¿åŠ©åŠ›&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹å¹³å°å’Œä¸ªäººçš„æ¨è(æŒ‰æ—¶é—´æ’åˆ—)&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA"&gt;å°ä¼—è½¯ä»¶&lt;/a&gt; - å¼€æºè½¯ä»¶æ¨èå¹³å°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://linux.do/"&gt;LinuxDo ç¤¾åŒº&lt;/a&gt; - æŠ€æœ¯çˆ±å¥½è€…çš„èšé›†åœ°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ruanyf/weekly"&gt;é˜®ä¸€å³°å‘¨åˆŠ&lt;/a&gt; - æŠ€æœ¯åœˆæœ‰å½±å“åŠ›çš„å‘¨åˆŠ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;è§‚ä¼—æ”¯æŒ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢&lt;strong&gt;ç»™äºˆèµ„é‡‘æ”¯æŒ&lt;/strong&gt; çš„æœ‹å‹ä»¬,ä½ ä»¬çš„æ…·æ…¨å·²åŒ–èº«ä¸ºé”®ç›˜æ—çš„é›¶é£Ÿé¥®æ–™,é™ªä¼´ç€é¡¹ç›®çš„æ¯ä¸€æ¬¡è¿­ä»£&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;ç‚¹èµäºº&lt;/th&gt; 
    &lt;th align="center"&gt;é‡‘é¢&lt;/th&gt; 
    &lt;th align="center"&gt;æ—¥æœŸ&lt;/th&gt; 
    &lt;th align="center"&gt;å¤‡æ³¨&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å‡¯&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;å¯¹*.&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;Thanks for your TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;s*y&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**ç¿”&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;å¥½é¡¹ç›®ï¼Œç›¸è§æ¨æ™šï¼Œæ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*éŸ¦&lt;/td&gt; 
    &lt;td align="center"&gt;9.9&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadarè¶…èµï¼Œè¯·è€å¸ˆå–å’–å•¡~&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;h*p&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸­å›½å¼€æºåŠ›é‡ï¼ŒåŠ æ²¹ï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;c*r&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;a*n&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;ã€‚*c&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºåˆ†äº«&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.11&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸»&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*äº†&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.09&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.08&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ç‚¹&lt;/td&gt; 
    &lt;td align="center"&gt;8.80&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;å¼€å‘ä¸æ˜“ï¼Œæ”¯æŒä¸€ä¸‹ã€‚&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Q*Q&lt;/td&gt; 
    &lt;td align="center"&gt;6.66&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;C*e&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.05&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Peter Fan&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.29&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.27&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æº&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®¸&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.23&lt;/td&gt; 
    &lt;td align="center"&gt;è€å¸ˆ å°ç™½ä¸€æšï¼Œæ‘¸äº†å‡ å¤©äº†è¿˜æ²¡æ•´èµ·æ¥ï¼Œæ±‚æ•™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Eason&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.22&lt;/td&gt; 
    &lt;td align="center"&gt;è¿˜æ²¡æ•´æ˜ç™½ï¼Œä½†ä½ åœ¨åšå¥½äº‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¾&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.18&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¿—&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ˜€&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ°&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å•¸&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*çºª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*d&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;è°¢è°¢ä½ çš„å·¥å…·ï¼Œå¾ˆå¥½ç©...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*H&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;é‚£*O&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*åœ†&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*g&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Ocean&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.12&lt;/td&gt; 
    &lt;td align="center"&gt;...çœŸçš„å¤ªæ£’äº†ï¼ï¼ï¼å°ç™½çº§åˆ«ä¹Ÿèƒ½ç›´æ¥ç”¨...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**åŸ¹&lt;/td&gt; 
    &lt;td align="center"&gt;5.2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.2&lt;/td&gt; 
    &lt;td align="center"&gt;github-yzyf1312:å¼€æºä¸‡å²&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¤¿&lt;/td&gt; 
    &lt;td align="center"&gt;3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.23&lt;/td&gt; 
    &lt;td align="center"&gt;åŠ æ²¹ï¼Œå¾ˆä¸é”™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.21&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;E*f&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;z*u&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ˜Š&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å·&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;T*T&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å®¶&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*X&lt;/td&gt; 
    &lt;td align="center"&gt;1.11&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.3&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é£™&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.31&lt;/td&gt; 
    &lt;td align="center"&gt;æ¥è‡ªè€ç«¥è°¢è°¢&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸‹&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸‹åˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸Šåˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;S*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.05&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¾ &lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.04&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;x*x&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.03&lt;/td&gt; 
    &lt;td align="center"&gt;trendRadar å¥½é¡¹ç›® ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è¿œ&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é‚ª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¢¦&lt;/td&gt; 
    &lt;td align="center"&gt;0.1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**é¾™&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.29&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;âœ¨ æ ¸å¿ƒåŠŸèƒ½&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;å…¨ç½‘çƒ­ç‚¹èšåˆ&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;çŸ¥ä¹&lt;/li&gt; 
 &lt;li&gt;æŠ–éŸ³&lt;/li&gt; 
 &lt;li&gt;bilibili çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;åå°”è¡—è§é—»&lt;/li&gt; 
 &lt;li&gt;è´´å§&lt;/li&gt; 
 &lt;li&gt;ç™¾åº¦çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;è´¢è”ç¤¾çƒ­é—¨&lt;/li&gt; 
 &lt;li&gt;æ¾æ¹ƒæ–°é—»&lt;/li&gt; 
 &lt;li&gt;å‡¤å‡°ç½‘&lt;/li&gt; 
 &lt;li&gt;ä»Šæ—¥å¤´æ¡&lt;/li&gt; 
 &lt;li&gt;å¾®åš&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;é»˜è®¤ç›‘æ§ 11 ä¸ªä¸»æµå¹³å°ï¼Œä¹Ÿå¯è‡ªè¡Œå¢åŠ é¢å¤–çš„å¹³å°&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ è‡ªå®šä¹‰ç›‘æ§å¹³å°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®çš„èµ„è®¯æ•°æ®æ¥æºäº &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; ï¼Œä½ å¯ä»¥ç‚¹å‡»&lt;a href="https://newsnow.busiyi.world/"&gt;ç½‘ç«™&lt;/a&gt;ï¼Œç‚¹å‡»[æ›´å¤š]ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰ä½ æƒ³è¦çš„å¹³å°ã€‚&lt;/p&gt; 
 &lt;p&gt;å…·ä½“æ·»åŠ å¯è®¿é—® &lt;a href="https://github.com/ourongxing/newsnow/tree/main/server/sources"&gt;é¡¹ç›®æºä»£ç &lt;/a&gt;ï¼Œæ ¹æ®é‡Œé¢çš„æ–‡ä»¶åï¼Œåœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ä¸­ä¿®æ”¹ &lt;code&gt;platforms&lt;/code&gt; é…ç½®ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;platforms:
  - id: "toutiao"
    name: "ä»Šæ—¥å¤´æ¡"
  - id: "baidu"  
    name: "ç™¾åº¦çƒ­æœ"
  - id: "wallstreetcn-hot"
    name: "åå°”è¡—è§é—»"
  # æ·»åŠ æ›´å¤šå¹³å°...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å¦‚æœä¸ä¼šçœ‹çš„è¯ï¼Œå°±ç›´æ¥å¤åˆ¶ä»–äººæ•´ç†å¥½çš„éƒ¨åˆ†&lt;a href="https://github.com/sansan0/TrendRadar/issues/95"&gt;å¹³å°é…ç½®&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;æ™ºèƒ½æ¨é€ç­–ç•¥&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ä¸‰ç§æ¨é€æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ¨¡å¼&lt;/th&gt; 
   &lt;th&gt;é€‚ç”¨äººç¾¤&lt;/th&gt; 
   &lt;th&gt;æ¨é€æ—¶æœº&lt;/th&gt; 
   &lt;th&gt;æ˜¾ç¤ºå†…å®¹&lt;/th&gt; 
   &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“æ—¥æ±‡æ€»&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“‹ ä¼ä¸šç®¡ç†è€…/æ™®é€šç”¨æˆ·&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
   &lt;td&gt;å½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
   &lt;td&gt;æ—¥æŠ¥æ€»ç»“&lt;br /&gt;å…¨é¢äº†è§£å½“æ—¥çƒ­ç‚¹è¶‹åŠ¿&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“å‰æ¦œå•&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“° è‡ªåª’ä½“äºº/å†…å®¹åˆ›ä½œè€…&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
   &lt;td&gt;å½“å‰æ¦œå•åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
   &lt;td&gt;å®æ—¶çƒ­ç‚¹è¿½è¸ª&lt;br /&gt;äº†è§£å½“å‰æœ€ç«çš„å†…å®¹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å¢é‡ç›‘æ§&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;incremental&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“ˆ æŠ•èµ„è€…/äº¤æ˜“å‘˜&lt;/td&gt; 
   &lt;td&gt;æœ‰æ–°å¢æ‰æ¨é€&lt;/td&gt; 
   &lt;td&gt;æ–°å‡ºç°çš„åŒ¹é…é¢‘ç‡è¯æ–°é—»&lt;/td&gt; 
   &lt;td&gt;é¿å…é‡å¤ä¿¡æ¯å¹²æ‰°&lt;br /&gt;é«˜é¢‘ç›‘æ§åœºæ™¯&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;é™„åŠ åŠŸèƒ½ - æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;ï¼ˆå¯é€‰ï¼‰ï¼š&lt;/p&gt; 
&lt;p&gt;æ­¤åŠŸèƒ½ç‹¬ç«‹äºä¸Šè¿°ä¸‰ç§æ¨é€æ¨¡å¼,å¯ä¸ä»»æ„æ¨¡å¼æ­é…ä½¿ç”¨:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´çª—å£é™åˆ¶&lt;/strong&gt;: è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼ˆå¦‚ 09:00-18:00 æˆ– 20:00-22:00ï¼‰,åªåœ¨æŒ‡å®šæ—¶é—´å†…æ¨é€&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡æ§åˆ¶&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;çª—å£å†…å¤šæ¬¡æ¨é€: æ—¶é—´çª—å£å†…æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€&lt;/li&gt; 
   &lt;li&gt;æ¯å¤©ä»…æ¨é€ä¸€æ¬¡: æ—¶é—´çª—å£å†…åªæ¨é€ä¸€æ¬¡ï¼ˆé€‚åˆå½“æ—¥æ±‡æ€»æˆ–å½“å‰æ¦œå•æ¨¡å¼ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;å·¥ä½œæ—¶é—´æ¨é€: åªåœ¨å·¥ä½œæ—¥ 09:00-18:00 æ¥æ”¶æ¶ˆæ¯&lt;/li&gt; 
   &lt;li&gt;æ™šé—´æ±‡æ€»æ¨é€: å¸Œæœ›åœ¨æ™šä¸Šå›ºå®šæ—¶é—´ï¼ˆå¦‚ 20:00-22:00ï¼‰æ”¶åˆ°æ±‡æ€»&lt;/li&gt; 
   &lt;li&gt;é¿å…æ‰“æ‰°: é˜²æ­¢éå·¥ä½œæ—¶é—´æ”¶åˆ°æ¨é€é€šçŸ¥&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æç¤º: æ­¤åŠŸèƒ½é»˜è®¤å…³é—­,éœ€åœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; ä¸­æ‰‹åŠ¨å¯ç”¨ &lt;code&gt;push_window.enabled&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;ç²¾å‡†å†…å®¹ç­›é€‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;è®¾ç½®ä¸ªäººå…³é”®è¯ï¼ˆå¦‚ï¼šAIã€æ¯”äºšè¿ªã€æ•™è‚²æ”¿ç­–ï¼‰ï¼Œåªæ¨é€ç›¸å…³çƒ­ç‚¹ï¼Œè¿‡æ»¤æ— å…³ä¿¡æ¯&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ”¯æŒæ™®é€šè¯ã€å¿…é¡»è¯(+)ã€è¿‡æ»¤è¯(!)ä¸‰ç§è¯­æ³•ï¼Œè§ã€frequency_words.txt é…ç½®æ•™ç¨‹ã€‘&lt;/li&gt; 
 &lt;li&gt;è¯ç»„åŒ–ç®¡ç†ï¼Œç‹¬ç«‹ç»Ÿè®¡ä¸åŒä¸»é¢˜çƒ­ç‚¹&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¹Ÿå¯ä»¥ä¸åšç­›é€‰ï¼Œå®Œæ•´çš„æ¨é€æ‰€æœ‰çƒ­ç‚¹ï¼Œå…·ä½“è§ã€å†å²æ›´æ–°ã€‘ä¸­çš„ v2.0.1&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ frequency_words.txt é…ç½®æ•™ç¨‹&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;åœ¨ &lt;code&gt;frequency_words.txt&lt;/code&gt; æ–‡ä»¶ä¸­é…ç½®ç›‘æ§çš„å…³é”®è¯ï¼Œæ”¯æŒä¸‰ç§è¯­æ³•å’Œè¯ç»„åŠŸèƒ½ã€‚&lt;/p&gt; 
 &lt;p&gt;å…³é”®è¯è¶Šé å‰ï¼Œæ–°é—»çš„ä¼˜å…ˆçº§è¶Šé«˜ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å…³æ³¨åº¦è°ƒæ•´å…³é”®è¯é¡ºåº&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;è¯­æ³•ç±»å‹&lt;/th&gt; 
    &lt;th&gt;ç¬¦å·&lt;/th&gt; 
    &lt;th&gt;ä½œç”¨&lt;/th&gt; 
    &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
    &lt;th&gt;åŒ¹é…é€»è¾‘&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ™®é€šè¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;æ— &lt;/td&gt; 
    &lt;td&gt;åŸºç¡€åŒ¹é…&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;åä¸º&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ…å«ä»»æ„ä¸€ä¸ªå³å¯&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;é™å®šèŒƒå›´&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+æ‰‹æœº&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¿…é¡»åŒæ—¶åŒ…å«&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ’é™¤å¹²æ‰°&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!å¹¿å‘Š&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ…å«åˆ™ç›´æ¥æ’é™¤&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;ğŸ“‹ åŸºç¡€è¯­æ³•è¯´æ˜&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;æ™®é€šå…³é”®è¯&lt;/strong&gt; - åŸºç¡€åŒ¹é…&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; æ–°é—»æ ‡é¢˜åŒ…å«å…¶ä¸­&lt;strong&gt;ä»»æ„ä¸€ä¸ªè¯&lt;/strong&gt;å°±ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h4&gt;2. &lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt; &lt;code&gt;+è¯æ±‡&lt;/code&gt; - é™å®šèŒƒå›´&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ‰‹æœº
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; å¿…é¡»åŒæ—¶åŒ…å«æ™®é€šè¯&lt;strong&gt;å’Œ&lt;/strong&gt;å¿…é¡»è¯æ‰ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h4&gt;3. &lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt; &lt;code&gt;!è¯æ±‡&lt;/code&gt; - æ’é™¤å¹²æ‰°&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;è‹¹æœ
åä¸º
!æ°´æœ
!ä»·æ ¼
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; åŒ…å«è¿‡æ»¤è¯çš„æ–°é—»ä¼šè¢«&lt;strong&gt;ç›´æ¥æ’é™¤&lt;/strong&gt;ï¼Œå³ä½¿åŒ…å«å…³é”®è¯&lt;/p&gt; 
 &lt;h3&gt;ğŸ”— è¯ç»„åŠŸèƒ½ - ç©ºè¡Œåˆ†éš”çš„é‡è¦ä½œç”¨&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒè§„åˆ™ï¼š&lt;/strong&gt; ç”¨&lt;strong&gt;ç©ºè¡Œ&lt;/strong&gt;åˆ†éš”ä¸åŒçš„è¯ç»„ï¼Œæ¯ä¸ªè¯ç»„ç‹¬ç«‹ç»Ÿè®¡&lt;/p&gt; 
 &lt;h4&gt;ç¤ºä¾‹é…ç½®ï¼š&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;iPhone
åä¸º
OPPO
+å‘å¸ƒ

Aè‚¡
ä¸Šè¯
æ·±è¯
+æ¶¨è·Œ
!é¢„æµ‹

ä¸–ç•Œæ¯
æ¬§æ´²æ¯
äºšæ´²æ¯
+æ¯”èµ›
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;è¯ç»„è§£é‡ŠåŠåŒ¹é…æ•ˆæœï¼š&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬1ç»„ - æ‰‹æœºæ–°å“ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šiPhoneã€åä¸ºã€OPPO&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šå‘å¸ƒ&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå¿…é¡»åŒ…å«æ‰‹æœºå“ç‰Œåï¼ŒåŒæ—¶åŒ…å«"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "iPhone 15æ­£å¼å‘å¸ƒå”®ä»·å…¬å¸ƒ" â† æœ‰"iPhone"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "åä¸ºMate60ç³»åˆ—å‘å¸ƒä¼šç›´æ’­" â† æœ‰"åä¸º"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "OPPO Find X7å‘å¸ƒæ—¶é—´ç¡®å®š" â† æœ‰"OPPO"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âŒ "iPhoneé”€é‡åˆ›æ–°é«˜" â† æœ‰"iPhone"ä½†ç¼ºå°‘"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬2ç»„ - è‚¡å¸‚è¡Œæƒ…ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šAè‚¡ã€ä¸Šè¯ã€æ·±è¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¶¨è·Œ&lt;/li&gt; 
  &lt;li&gt;è¿‡æ»¤è¯ï¼šé¢„æµ‹&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šåŒ…å«è‚¡å¸‚ç›¸å…³è¯ï¼ŒåŒæ—¶åŒ…å«"æ¶¨è·Œ"ï¼Œä½†æ’é™¤åŒ…å«"é¢„æµ‹"çš„å†…å®¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "Aè‚¡ä»Šæ—¥å¤§å¹…æ¶¨è·Œåˆ†æ" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âœ… "ä¸Šè¯æŒ‡æ•°æ¶¨è·ŒåŸå› è§£è¯»" â† æœ‰"ä¸Šè¯"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âŒ "ä¸“å®¶é¢„æµ‹Aè‚¡æ¶¨è·Œè¶‹åŠ¿" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"ä½†åŒ…å«"é¢„æµ‹"&lt;/li&gt; 
  &lt;li&gt;âŒ "Aè‚¡æˆäº¤é‡åˆ›æ–°é«˜" â† æœ‰"Aè‚¡"ä½†ç¼ºå°‘"æ¶¨è·Œ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬3ç»„ - è¶³çƒèµ›äº‹ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šä¸–ç•Œæ¯ã€æ¬§æ´²æ¯ã€äºšæ´²æ¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¯”èµ›&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå¿…é¡»åŒ…å«æ¯èµ›åç§°ï¼ŒåŒæ—¶åŒ…å«"æ¯”èµ›"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "ä¸–ç•Œæ¯å°ç»„èµ›æ¯”èµ›ç»“æœ" â† æœ‰"ä¸–ç•Œæ¯"+"æ¯”èµ›"&lt;/li&gt; 
  &lt;li&gt;âœ… "æ¬§æ´²æ¯å†³èµ›æ¯”èµ›æ—¶é—´" â† æœ‰"æ¬§æ´²æ¯"+"æ¯”èµ›"&lt;/li&gt; 
  &lt;li&gt;âŒ "ä¸–ç•Œæ¯é—¨ç¥¨å¼€å”®" â† æœ‰"ä¸–ç•Œæ¯"ä½†ç¼ºå°‘"æ¯”èµ›"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ğŸ¯ é…ç½®æŠ€å·§&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;ä»å®½åˆ°ä¸¥çš„é…ç½®ç­–ç•¥&lt;/strong&gt;&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# ç¬¬ä¸€æ­¥ï¼šå…ˆç”¨å®½æ³›å…³é”®è¯æµ‹è¯•
äººå·¥æ™ºèƒ½
AI
ChatGPT

# ç¬¬äºŒæ­¥ï¼šå‘ç°è¯¯åŒ¹é…åï¼ŒåŠ å…¥å¿…é¡»è¯é™å®š
äººå·¥æ™ºèƒ½  
AI
ChatGPT
+æŠ€æœ¯

# ç¬¬ä¸‰æ­¥ï¼šå‘ç°å¹²æ‰°å†…å®¹åï¼ŒåŠ å…¥è¿‡æ»¤è¯
äººå·¥æ™ºèƒ½
AI  
ChatGPT
+æŠ€æœ¯
!å¹¿å‘Š
!åŸ¹è®­
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2. &lt;strong&gt;é¿å…è¿‡åº¦å¤æ‚&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;âŒ &lt;strong&gt;ä¸æ¨èï¼š&lt;/strong&gt; ä¸€ä¸ªè¯ç»„åŒ…å«å¤ªå¤šè¯æ±‡&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
ä¸‰æ˜Ÿ
vivo
ä¸€åŠ 
é­…æ—
+æ‰‹æœº
+å‘å¸ƒ
+é”€é‡
!å‡è´§
!ç»´ä¿®
!äºŒæ‰‹
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;âœ… &lt;strong&gt;æ¨èï¼š&lt;/strong&gt; æ‹†åˆ†æˆå¤šä¸ªç²¾ç¡®çš„è¯ç»„&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ–°å“

è‹¹æœ
ä¸‰æ˜Ÿ  
+å‘å¸ƒ

æ‰‹æœº
é”€é‡
+å¸‚åœº
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;çƒ­ç‚¹è¶‹åŠ¿åˆ†æ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;å®æ—¶è¿½è¸ªæ–°é—»çƒ­åº¦å˜åŒ–ï¼Œè®©ä½ ä¸ä»…çŸ¥é“"ä»€ä¹ˆåœ¨çƒ­æœ"ï¼Œæ›´äº†è§£"çƒ­ç‚¹å¦‚ä½•æ¼”å˜"&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´è½´è¿½è¸ª&lt;/strong&gt;ï¼šè®°å½•æ¯æ¡æ–°é—»ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„å®Œæ•´æ—¶é—´è·¨åº¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;çƒ­åº¦å˜åŒ–&lt;/strong&gt;ï¼šç»Ÿè®¡æ–°é—»åœ¨ä¸åŒæ—¶é—´æ®µçš„æ’åå˜åŒ–å’Œå‡ºç°é¢‘æ¬¡&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–°å¢æ£€æµ‹&lt;/strong&gt;ï¼šå®æ—¶è¯†åˆ«æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜ï¼Œç”¨ğŸ†•æ ‡è®°ç¬¬ä¸€æ—¶é—´æé†’&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŒç»­æ€§åˆ†æ&lt;/strong&gt;ï¼šåŒºåˆ†ä¸€æ¬¡æ€§çƒ­ç‚¹è¯é¢˜å’ŒæŒç»­å‘é…µçš„æ·±åº¦æ–°é—»&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è·¨å¹³å°å¯¹æ¯”&lt;/strong&gt;ï¼šåŒä¸€æ–°é—»åœ¨ä¸åŒå¹³å°çš„æ’åè¡¨ç°ï¼Œçœ‹å‡ºåª’ä½“å…³æ³¨åº¦å·®å¼‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸å†é”™è¿‡é‡è¦æ–°é—»çš„å®Œæ•´å‘å±•è¿‡ç¨‹ï¼Œä»è¯é¢˜èŒèŠ½åˆ°é«˜å³°çƒ­è®®ï¼Œå…¨ç¨‹æŒæ¡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ æ¨é€æ ¼å¼è¯´æ˜&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡&lt;/p&gt; 
 &lt;p&gt;ğŸ”¥ [1/3] AI ChatGPT : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ç™¾åº¦çƒ­æœ] ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;] - 09æ—¶15åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[ä»Šæ—¥å¤´æ¡] AIèŠ¯ç‰‡æ¦‚å¿µè‚¡æš´æ¶¨ [&lt;strong&gt;3&lt;/strong&gt;] - [08æ—¶30åˆ† ~ 10æ—¶45åˆ†] (3æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“ˆ [2/3] æ¯”äºšè¿ª ç‰¹æ–¯æ‹‰ : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[å¾®åš] ğŸ†• æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;] - 10æ—¶20åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[æŠ–éŸ³] ç‰¹æ–¯æ‹‰é™ä»·ä¿ƒé”€ [&lt;strong&gt;4&lt;/strong&gt;] - [07æ—¶45åˆ† ~ 09æ—¶15åˆ†] (2æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“Œ [3/3] Aè‚¡ è‚¡å¸‚ : 1 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;[åå°”è¡—è§é—»] Aè‚¡åˆç›˜ç‚¹è¯„åˆ†æ [&lt;strong&gt;5&lt;/strong&gt;] - [11æ—¶30åˆ† ~ 12æ—¶00åˆ†] (2æ¬¡)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± 2 æ¡)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ç™¾åº¦çƒ­æœ&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;å¾®åš&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ›´æ–°æ—¶é—´ï¼š2025-01-15 12:30:15&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;æ¶ˆæ¯æ ¼å¼è¯´æ˜&lt;/strong&gt;&lt;/h2&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ ¼å¼å…ƒç´ &lt;/th&gt; 
    &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
    &lt;th&gt;å«ä¹‰&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ”¥ğŸ“ˆğŸ“Œ&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥ [1/3] AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;çƒ­åº¦ç­‰çº§&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥é«˜çƒ­åº¦(â‰¥10æ¡) ğŸ“ˆä¸­çƒ­åº¦(5-9æ¡) ğŸ“Œæ™®é€šçƒ­åº¦(&amp;lt;5æ¡)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[åºå·/æ€»æ•°]&lt;/td&gt; 
    &lt;td&gt;[1/3]&lt;/td&gt; 
    &lt;td&gt;æ’åºä½ç½®&lt;/td&gt; 
    &lt;td&gt;å½“å‰è¯ç»„åœ¨æ‰€æœ‰åŒ¹é…è¯ç»„ä¸­çš„æ’å&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;é¢‘ç‡è¯ç»„&lt;/td&gt; 
    &lt;td&gt;AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;å…³é”®è¯ç»„&lt;/td&gt; 
    &lt;td&gt;é…ç½®æ–‡ä»¶ä¸­çš„è¯ç»„ï¼Œæ ‡é¢˜å¿…é¡»åŒ…å«å…¶ä¸­è¯æ±‡&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;: N æ¡&lt;/td&gt; 
    &lt;td&gt;: 2 æ¡&lt;/td&gt; 
    &lt;td&gt;åŒ¹é…æ•°é‡&lt;/td&gt; 
    &lt;td&gt;è¯¥è¯ç»„åŒ¹é…çš„æ–°é—»æ€»æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[å¹³å°å]&lt;/td&gt; 
    &lt;td&gt;[ç™¾åº¦çƒ­æœ]&lt;/td&gt; 
    &lt;td&gt;æ¥æºå¹³å°&lt;/td&gt; 
    &lt;td&gt;æ–°é—»æ‰€å±çš„å¹³å°åç§°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ†•&lt;/td&gt; 
    &lt;td&gt;ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ&lt;/td&gt; 
    &lt;td&gt;æ–°å¢æ ‡è®°&lt;/td&gt; 
    &lt;td&gt;æœ¬è½®æŠ“å–ä¸­é¦–æ¬¡å‡ºç°çš„çƒ­ç‚¹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[&lt;strong&gt;æ•°å­—&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;[&lt;strong&gt;1&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;é«˜æ’å&lt;/td&gt; 
    &lt;td&gt;æ’åâ‰¤é˜ˆå€¼çš„çƒ­æœï¼Œçº¢è‰²åŠ ç²—æ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ•°å­—]&lt;/td&gt; 
    &lt;td&gt;[7]&lt;/td&gt; 
    &lt;td&gt;æ™®é€šæ’å&lt;/td&gt; 
    &lt;td&gt;æ’å&amp;gt;é˜ˆå€¼çš„çƒ­æœï¼Œæ™®é€šæ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;- æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;- 09æ—¶15åˆ†&lt;/td&gt; 
    &lt;td&gt;é¦–æ¬¡æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;è¯¥æ–°é—»é¦–æ¬¡è¢«å‘ç°çš„æ—¶é—´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ—¶é—´~æ—¶é—´]&lt;/td&gt; 
    &lt;td&gt;[08æ—¶30åˆ† ~ 10æ—¶45åˆ†]&lt;/td&gt; 
    &lt;td&gt;æŒç»­æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„æ—¶é—´èŒƒå›´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;(Næ¬¡)&lt;/td&gt; 
    &lt;td&gt;(3æ¬¡)&lt;/td&gt; 
    &lt;td&gt;å‡ºç°é¢‘ç‡&lt;/td&gt; 
    &lt;td&gt;åœ¨ç›‘æ§æœŸé—´å‡ºç°çš„æ€»æ¬¡æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ–°å¢åŒºåŸŸ&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ†• &lt;strong&gt;æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;æ–°è¯é¢˜æ±‡æ€»&lt;/td&gt; 
    &lt;td&gt;å•ç‹¬å±•ç¤ºæœ¬è½®æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;ä¸ªæ€§åŒ–çƒ­ç‚¹ç®—æ³•&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä¸å†è¢«å„ä¸ªå¹³å°çš„ç®—æ³•ç‰µç€èµ°ï¼ŒTrendRadar ä¼šé‡æ–°æ•´ç†å…¨ç½‘çƒ­æœï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;çœ‹é‡æ’åé«˜çš„æ–°é—»&lt;/strong&gt;ï¼ˆå 60%ï¼‰ï¼šå„å¹³å°å‰å‡ åçš„æ–°é—»ä¼˜å…ˆæ˜¾ç¤º&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…³æ³¨æŒç»­å‡ºç°çš„è¯é¢˜&lt;/strong&gt;ï¼ˆå 30%ï¼‰ï¼šåå¤å‡ºç°çš„æ–°é—»æ›´é‡è¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è€ƒè™‘æ’åè´¨é‡&lt;/strong&gt;ï¼ˆå 10%ï¼‰ï¼šä¸ä»…å¤šæ¬¡å‡ºç°ï¼Œè¿˜ç»å¸¸æ’åœ¨å‰åˆ—&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æŠŠåˆ†æ•£åœ¨å„ä¸ªå¹³å°çš„çƒ­æœåˆå¹¶èµ·æ¥ï¼ŒæŒ‰ç…§ä½ å…³å¿ƒçš„çƒ­åº¦é‡æ–°æ’åºï¼Œè¿™ä¸‰ä¸ªæ¯”ä¾‹å¯ä»¥é€‰æ‹©é€‚åˆè‡ªå·±çš„åœºæ™¯è¿›è¡Œè°ƒæ•´&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ çƒ­ç‚¹æƒé‡è°ƒæ•´&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;å½“å‰é»˜è®¤çš„é…ç½®æ˜¯å¹³è¡¡æ€§é…ç½®&lt;/p&gt; 
 &lt;h3&gt;ä¸¤ä¸ªæ ¸å¿ƒåœºæ™¯&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½å®æ—¶çƒ­ç‚¹å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.8    # ä¸»è¦çœ‹æ’å
  frequency_weight: 0.1  # ä¸å¤ªåœ¨ä¹æŒç»­æ€§
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šè‡ªåª’ä½“åšä¸»ã€è¥é”€äººå‘˜ã€æƒ³å¿«é€Ÿäº†è§£å½“ä¸‹æœ€ç«è¯é¢˜çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½æ·±åº¦è¯é¢˜å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.4    # é€‚åº¦çœ‹æ’å
  frequency_weight: 0.5  # é‡è§†å½“å¤©å†…çš„æŒç»­çƒ­åº¦
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šæŠ•èµ„è€…ã€ç ”ç©¶äººå‘˜ã€æ–°é—»å·¥ä½œè€…ã€éœ€è¦æ·±åº¦åˆ†æè¶‹åŠ¿çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;h3&gt;è°ƒæ•´çš„æ–¹æ³•&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ä¸‰ä¸ªæ•°å­—åŠ èµ·æ¥å¿…é¡»ç­‰äº 1.0&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å“ªä¸ªé‡è¦å°±è°ƒå¤§å“ªä¸ª&lt;/strong&gt;ï¼šåœ¨ä¹æ’åå°±è°ƒå¤§ rank_weightï¼Œåœ¨ä¹æŒç»­æ€§å°±è°ƒå¤§ frequency_weight&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å»ºè®®æ¯æ¬¡åªè°ƒ 0.1-0.2&lt;/strong&gt;ï¼Œè§‚å¯Ÿæ•ˆæœ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ ¸å¿ƒæ€è·¯ï¼šè¿½æ±‚é€Ÿåº¦å’Œæ—¶æ•ˆæ€§çš„ç”¨æˆ·æé«˜æ’åæƒé‡ï¼Œè¿½æ±‚æ·±åº¦å’Œç¨³å®šæ€§çš„ç”¨æˆ·æé«˜é¢‘æ¬¡æƒé‡ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šæ¸ é“å®æ—¶æ¨é€&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒ&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;(+ å¾®ä¿¡æ¨é€æ–¹æ¡ˆ)ã€&lt;strong&gt;é£ä¹¦&lt;/strong&gt;ã€&lt;strong&gt;é’‰é’‰&lt;/strong&gt;ã€&lt;strong&gt;Telegram&lt;/strong&gt;ã€&lt;strong&gt;é‚®ä»¶&lt;/strong&gt;ã€&lt;strong&gt;ntfy&lt;/strong&gt;ï¼Œæ¶ˆæ¯ç›´è¾¾æ‰‹æœºå’Œé‚®ç®±&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šç«¯é€‚é…&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;ï¼šè‡ªåŠ¨ç”Ÿæˆç²¾ç¾ç½‘é¡µæŠ¥å‘Šï¼ŒPC/ç§»åŠ¨ç«¯é€‚é…&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dockeréƒ¨ç½²&lt;/strong&gt;ï¼šæ”¯æŒå¤šæ¶æ„å®¹å™¨åŒ–è¿è¡Œ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®æŒä¹…åŒ–&lt;/strong&gt;ï¼šHTML/TXTå¤šæ ¼å¼å†å²è®°å½•ä¿å­˜&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;AI æ™ºèƒ½åˆ†æï¼ˆv3.0.0 æ–°å¢ï¼‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åŸºäº MCP (Model Context Protocol) åè®®çš„ AI å¯¹è¯åˆ†æç³»ç»Ÿï¼Œè®©ä½ ç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»æ•°æ®&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å¯¹è¯å¼æŸ¥è¯¢&lt;/strong&gt;ï¼šç”¨è‡ªç„¶è¯­è¨€æé—®ï¼Œå¦‚"æŸ¥è¯¢æ˜¨å¤©çŸ¥ä¹çš„çƒ­ç‚¹"ã€"åˆ†ææ¯”ç‰¹å¸æœ€è¿‘çš„çƒ­åº¦è¶‹åŠ¿"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;13 ç§åˆ†æå·¥å…·&lt;/strong&gt;ï¼šæ¶µç›–åŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€è¶‹åŠ¿åˆ†æã€æ•°æ®æ´å¯Ÿã€æƒ…æ„Ÿåˆ†æç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒ&lt;/strong&gt;ï¼šCherry Studioï¼ˆGUI é…ç½®ï¼‰ã€Claude Desktopã€Cursorã€Cline ç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ·±åº¦åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;è¯é¢˜è¶‹åŠ¿è¿½è¸ªï¼ˆçƒ­åº¦å˜åŒ–ã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
   &lt;li&gt;è·¨å¹³å°æ•°æ®å¯¹æ¯”ï¼ˆæ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
   &lt;li&gt;æ™ºèƒ½æ‘˜è¦ç”Ÿæˆã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€å†å²å…³è”æ£€ç´¢&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å‘Šåˆ«æ‰‹åŠ¨ç¿»é˜…æ•°æ®æ–‡ä»¶ï¼ŒAI åŠ©æ‰‹å¸®ä½ ç§’æ‡‚æ–°é—»èƒŒåçš„æ•…äº‹&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;é›¶æŠ€æœ¯é—¨æ§›éƒ¨ç½²&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GitHub ä¸€é”® Fork å³å¯ä½¿ç”¨ï¼Œæ— éœ€ç¼–ç¨‹åŸºç¡€ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;30ç§’éƒ¨ç½²ï¼š GitHub Pagesï¼ˆç½‘é¡µæµè§ˆï¼‰æ”¯æŒä¸€é”®ä¿å­˜æˆå›¾ç‰‡ï¼Œéšæ—¶åˆ†äº«ç»™ä»–äºº&lt;/p&gt; 
 &lt;p&gt;1åˆ†é’Ÿéƒ¨ç½²ï¼š ä¼ä¸šå¾®ä¿¡ï¼ˆæ‰‹æœºé€šçŸ¥ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æç¤ºï¼š&lt;/strong&gt; æƒ³è¦&lt;strong&gt;å®æ—¶æ›´æ–°&lt;/strong&gt;çš„ç½‘é¡µç‰ˆï¼Ÿfork åï¼Œè¿›å…¥ä½ çš„ä»“åº“ Settings â†’ Pagesï¼Œå¯ç”¨ GitHub Pagesã€‚&lt;a href="https://sansan0.github.io/TrendRadar/"&gt;æ•ˆæœé¢„è§ˆ&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;å‡å°‘ APP ä¾èµ–&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä»"è¢«ç®—æ³•æ¨èç»‘æ¶"å˜æˆ"ä¸»åŠ¨è·å–è‡ªå·±æƒ³è¦çš„ä¿¡æ¯"&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤ï¼š&lt;/strong&gt; æŠ•èµ„è€…ã€è‡ªåª’ä½“äººã€ä¼ä¸šå…¬å…³ã€å…³å¿ƒæ—¶äº‹çš„æ™®é€šç”¨æˆ·&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å…¸å‹åœºæ™¯ï¼š&lt;/strong&gt; è‚¡å¸‚æŠ•èµ„ç›‘æ§ã€å“ç‰Œèˆ†æƒ…è¿½è¸ªã€è¡Œä¸šåŠ¨æ€å…³æ³¨ã€ç”Ÿæ´»èµ„è®¯è·å–&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Github Pages æ•ˆæœ(æ‰‹æœºç«¯é€‚é…ã€é‚®ç®±æ¨é€æ•ˆæœ)&lt;/th&gt; 
   &lt;th align="center"&gt;é£ä¹¦æ¨é€æ•ˆæœ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/github-pages.png" alt="Github Pagesæ•ˆæœ" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/feishu.jpg" alt="é£ä¹¦æ¨é€æ•ˆæœ" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šä¸è¦é€šè¿‡ &lt;strong&gt;Sync fork&lt;/strong&gt; æ›´æ–°æœ¬é¡¹ç›®, å»ºè®®æŸ¥çœ‹ã€å†å²æ›´æ–°ã€‘ï¼Œæ˜ç¡®å…·ä½“çš„ã€å‡çº§æ–¹å¼ã€‘å’Œã€åŠŸèƒ½å†…å®¹ã€‘&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å°ç‰ˆæœ¬æ›´æ–°&lt;/strong&gt;ï¼šä» v2.x å‡çº§åˆ° v2.y, ç”¨æœ¬é¡¹ç›®çš„ &lt;code&gt;main.py&lt;/code&gt; ä»£ç æ›¿æ¢ä½  fork ä»“åº“ä¸­çš„å¯¹åº”æ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§ç‰ˆæœ¬å‡çº§&lt;/strong&gt;ï¼šä» v1.x å‡çº§åˆ° v2.y, å»ºè®®åˆ é™¤ç°æœ‰ fork åé‡æ–° forkï¼Œè¿™æ ·æ›´çœåŠ›ä¸”é¿å…é…ç½®å†²çª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/11/12 - v3.0.5&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¿®å¤é‚®ä»¶å‘é€ SSL/TLS ç«¯å£é…ç½®é€»è¾‘é”™è¯¯&lt;/li&gt; 
 &lt;li&gt;ä¼˜åŒ–é‚®ç®±æœåŠ¡å•†ï¼ˆQQ/163/126ï¼‰é»˜è®¤ä½¿ç”¨ 465 ç«¯å£ï¼ˆSSLï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–°å¢ Docker ç¯å¢ƒå˜é‡æ”¯æŒ&lt;/strong&gt;ï¼šæ ¸å¿ƒé…ç½®é¡¹ï¼ˆ&lt;code&gt;enable_crawler&lt;/code&gt;ã€&lt;code&gt;report_mode&lt;/code&gt;ã€&lt;code&gt;push_window&lt;/code&gt; ç­‰ï¼‰æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œè§£å†³ NAS ç”¨æˆ·ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸ç”Ÿæ•ˆçš„é—®é¢˜ï¼ˆè¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Docker éƒ¨ç½²&lt;/a&gt; ç« èŠ‚ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/26 - mcp-v1.0.1&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¿®å¤æ—¥æœŸæŸ¥è¯¢å‚æ•°ä¼ é€’é”™è¯¯&lt;/li&gt; 
 &lt;li&gt;ç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„æ—¶é—´å‚æ•°æ ¼å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ å†å²æ›´æ–°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;2025/10/31 - v3.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é£ä¹¦å› æ¨é€å†…å®¹è¿‡é•¿è€Œäº§ç”Ÿçš„é”™è¯¯ï¼Œå®ç°äº†åˆ†æ‰¹æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/23 - v3.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ‰©å¤§ ntfy é”™è¯¯ä¿¡æ¯æ˜¾ç¤ºèŒƒå›´&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/21 - v3.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/20 - v3.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§æ›´æ–° - AI åˆ†æåŠŸèƒ½ä¸Šçº¿&lt;/strong&gt; ğŸ¤–&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ–°å¢åŸºäº MCP (Model Context Protocol) çš„ AI åˆ†ææœåŠ¡å™¨&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒ13ç§æ™ºèƒ½åˆ†æå·¥å…·ï¼šåŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€é«˜çº§åˆ†æã€ç³»ç»Ÿç®¡ç†&lt;/li&gt; 
    &lt;li&gt;è‡ªç„¶è¯­è¨€äº¤äº’ï¼šé€šè¿‡å¯¹è¯æ–¹å¼æŸ¥è¯¢å’Œåˆ†ææ–°é—»æ•°æ®&lt;/li&gt; 
    &lt;li&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒï¼šClaude Desktopã€Cherry Studioã€Cursorã€Cline ç­‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¯é¢˜è¶‹åŠ¿åˆ†æï¼ˆçƒ­åº¦è¿½è¸ªã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ•°æ®æ´å¯Ÿï¼ˆå¹³å°å¯¹æ¯”ã€æ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
    &lt;li&gt;æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ&lt;/li&gt; 
    &lt;li&gt;å†å²ç›¸å…³æ–°é—»æ£€ç´¢ã€å¤šæ¨¡å¼æœç´¢&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™æ˜¯ç‹¬ç«‹çš„ AI åˆ†æåŠŸèƒ½ï¼Œä¸å½±å“ç°æœ‰çš„æ¨é€åŠŸèƒ½&lt;/li&gt; 
    &lt;li&gt;å¯é€‰æ‹©æ€§ä½¿ç”¨ï¼Œæ— éœ€å‡çº§ç°æœ‰éƒ¨ç½²&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/15 - v2.4.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜ + 1&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤æ¨é€æ—¶é—´çª—å£åˆ¤æ–­é—®é¢˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ã€å°ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/10 - v2.4.3&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ &lt;a href="https://github.com/sansan0/TrendRadar/issues/98"&gt;nidaye996&lt;/a&gt; å‘ç°çš„ä½“éªŒé—®é¢˜&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡æ„"é™é»˜æ¨é€æ¨¡å¼"å‘½åä¸º"æ¨é€æ—¶é—´çª—å£æ§åˆ¶"ï¼Œæå‡åŠŸèƒ½ç†è§£åº¦&lt;/li&gt; 
    &lt;li&gt;æ˜ç¡®æ¨é€æ—¶é—´çª—å£ä½œä¸ºå¯é€‰é™„åŠ åŠŸèƒ½ï¼Œå¯ä¸ä¸‰ç§æ¨é€æ¨¡å¼æ­é…ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;æ”¹è¿›æ³¨é‡Šå’Œæ–‡æ¡£æè¿°ï¼Œä½¿åŠŸèƒ½å®šä½æ›´åŠ æ¸…æ™°&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™ä¸ªä»…ä»…æ˜¯é‡æ„ï¼Œå¯ä»¥ä¸ç”¨å‡çº§&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/8 - v2.4.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤é…ç½®æ–‡ä»¶ç¼ºå¤±é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¼˜åŒ– ntfy æ¨é€æ•ˆæœ&lt;/li&gt; 
    &lt;li&gt;å¢åŠ  github page å›¾ç‰‡åˆ†æ®µå¯¼å‡ºåŠŸèƒ½&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/2 - v2.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ–°å¢ ntfy æ¨é€é€šçŸ¥&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒ ntfy.sh å…¬å…±æœåŠ¡å’Œè‡ªæ‰˜ç®¡æœåŠ¡å™¨&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é€‚åˆè¿½æ±‚éšç§çš„ç”¨æˆ·ï¼ˆæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/li&gt; 
    &lt;li&gt;è·¨å¹³å°æ¨é€ï¼ˆiOSã€Androidã€Desktopã€Webï¼‰&lt;/li&gt; 
    &lt;li&gt;æ— éœ€æ³¨å†Œè´¦å·ï¼ˆå…¬å…±æœåŠ¡å™¨ï¼‰&lt;/li&gt; 
    &lt;li&gt;å¼€æºå…è´¹ï¼ˆMIT åè®®ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/26 - v2.3.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®æ­£äº†é‚®ä»¶é€šçŸ¥é…ç½®æ£€æŸ¥è¢«é—æ¼çš„é—®é¢˜ï¼ˆ&lt;a href="https://github.com/sansan0/TrendRadar/issues/88"&gt;#88&lt;/a&gt;ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³äº†å³ä½¿æ­£ç¡®é…ç½®é‚®ä»¶é€šçŸ¥ï¼Œç³»ç»Ÿä»æç¤º"æœªé…ç½®ä»»ä½•webhook"çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/22 - v2.3.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ–°å¢é‚®ä»¶æ¨é€åŠŸèƒ½&lt;/strong&gt;ï¼Œæ”¯æŒå°†çƒ­ç‚¹æ–°é—»æŠ¥å‘Šå‘é€åˆ°é‚®ç®±&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ™ºèƒ½ SMTP è¯†åˆ«&lt;/strong&gt;ï¼šè‡ªåŠ¨è¯†åˆ« Gmailã€QQé‚®ç®±ã€Outlookã€ç½‘æ˜“é‚®ç®±ç­‰ 10+ ç§é‚®ç®±æœåŠ¡å•†é…ç½®&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HTML ç²¾ç¾æ ¼å¼&lt;/strong&gt;ï¼šé‚®ä»¶å†…å®¹é‡‡ç”¨ä¸ç½‘é¡µç‰ˆç›¸åŒçš„ HTML æ ¼å¼ï¼Œæ’ç‰ˆç²¾ç¾ï¼Œç§»åŠ¨ç«¯é€‚é…&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ‰¹é‡å‘é€æ”¯æŒ&lt;/strong&gt;ï¼šæ”¯æŒå¤šä¸ªæ”¶ä»¶äººï¼Œç”¨é€—å·åˆ†éš”å³å¯åŒæ—¶å‘é€ç»™å¤šäºº&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰ SMTP&lt;/strong&gt;ï¼šå¯è‡ªå®šä¹‰ SMTP æœåŠ¡å™¨å’Œç«¯å£&lt;/li&gt; 
  &lt;li&gt;ä¿®å¤Dockeræ„å»ºç½‘ç»œè¿æ¥é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šé€‚åˆéœ€è¦é‚®ä»¶å½’æ¡£ã€å›¢é˜Ÿåˆ†äº«ã€å®šæ—¶æŠ¥å‘Šçš„ç”¨æˆ·&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒé‚®ç®±ï¼šGmailã€QQé‚®ç®±ã€Outlook/Hotmailã€163/126é‚®ç®±ã€æ–°æµªé‚®ç®±ã€æœç‹é‚®ç®±ç­‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ­¤æ¬¡æ›´æ–°çš„å†…å®¹æ¯”è¾ƒå¤šï¼Œå¦‚æœæƒ³å‡çº§ï¼Œå»ºè®®é‡‡ç”¨ã€å¤§ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/17 - v2.2.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢ä¸€é”®ä¿å­˜æ–°é—»å›¾ç‰‡åŠŸèƒ½ï¼Œè®©ä½ è½»æ¾åˆ†äº«å…³æ³¨çš„çƒ­ç‚¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šå½“ä½ æŒ‰ç…§æ•™ç¨‹å¼€å¯äº†ç½‘é¡µç‰ˆåŠŸèƒ½å(GitHub Pages)&lt;/li&gt; 
  &lt;li&gt;ä½¿ç”¨æ–¹æ³•ï¼šç”¨æ‰‹æœºæˆ–ç”µè„‘æ‰“å¼€è¯¥ç½‘é¡µé“¾æ¥ï¼Œç‚¹å‡»é¡µé¢é¡¶éƒ¨çš„"ä¿å­˜ä¸ºå›¾ç‰‡"æŒ‰é’®&lt;/li&gt; 
  &lt;li&gt;å®é™…æ•ˆæœï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å°†å½“å‰çš„æ–°é—»æŠ¥å‘Šåˆ¶ä½œæˆä¸€å¼ ç²¾ç¾å›¾ç‰‡ï¼Œä¿å­˜åˆ°ä½ çš„æ‰‹æœºç›¸å†Œæˆ–ç”µè„‘æ¡Œé¢&lt;/li&gt; 
  &lt;li&gt;åˆ†äº«ä¾¿åˆ©ï¼šä½ å¯ä»¥ç›´æ¥æŠŠè¿™å¼ å›¾ç‰‡å‘ç»™æœ‹å‹ã€å‘åˆ°æœ‹å‹åœˆï¼Œæˆ–åˆ†äº«åˆ°å·¥ä½œç¾¤ï¼Œè®©åˆ«äººä¹Ÿèƒ½çœ‹åˆ°ä½ å‘ç°çš„é‡è¦èµ„è®¯&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/13 - v2.1.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é’‰é’‰çš„æ¨é€å®¹é‡é™åˆ¶å¯¼è‡´çš„æ–°é—»æ¨é€å¤±è´¥é—®é¢˜(é‡‡ç”¨åˆ†æ‰¹æ¨é€)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/04 - v2.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤dockeråœ¨æŸäº›æ¶æ„ä¸­æ— æ³•æ­£å¸¸è¿è¡Œçš„é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;æ­£å¼å‘å¸ƒå®˜æ–¹ Docker é•œåƒ wantcat/trendradarï¼Œæ”¯æŒå¤šæ¶æ„&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ– Docker éƒ¨ç½²æµç¨‹ï¼Œæ— éœ€æœ¬åœ°æ„å»ºå³å¯å¿«é€Ÿä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/30 - v2.1.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒæ”¹è¿›&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é€»è¾‘ä¼˜åŒ–&lt;/strong&gt;ï¼šä»"æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€"æ”¹ä¸º"æ—¶é—´çª—å£å†…å¯æ§æ¨é€"&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;ï¼šå¯è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼Œé¿å…éå·¥ä½œæ—¶é—´æ‰“æ‰°&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡å¯é€‰&lt;/strong&gt;ï¼šæ—¶é—´æ®µå†…æ”¯æŒå•æ¬¡æ¨é€æˆ–å¤šæ¬¡æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬åŠŸèƒ½é»˜è®¤å…³é—­ï¼Œéœ€æ‰‹åŠ¨åœ¨ config.yaml ä¸­å¼€å¯æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/li&gt; 
  &lt;li&gt;å‡çº§éœ€åŒæ—¶æ›´æ–° main.py å’Œ config.yaml ä¸¤ä¸ªæ–‡ä»¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/27 - v2.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬æ¬¡ç‰ˆæœ¬ä¸æ˜¯åŠŸèƒ½ä¿®å¤ï¼Œè€Œæ˜¯é‡è¦æé†’&lt;/li&gt; 
  &lt;li&gt;è¯·åŠ¡å¿…å¦¥å–„ä¿ç®¡å¥½ webhooksï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ ä»¥ fork çš„æ–¹å¼å°†æœ¬é¡¹ç›®éƒ¨ç½²åœ¨ GitHub ä¸Šï¼Œè¯·å°† webhooks å¡«å…¥ GitHub Secretï¼Œè€Œé config.yaml&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ å·²ç»æš´éœ²äº† webhooks æˆ–å°†å…¶å¡«å…¥äº† config.yamlï¼Œå»ºè®®åˆ é™¤åé‡æ–°ç”Ÿæˆ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/06 - v2.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¼˜åŒ– github page çš„ç½‘é¡µç‰ˆæ•ˆæœï¼Œæ–¹ä¾¿ç§»åŠ¨ç«¯ä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/28 - v2.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é‡æ„ä»£ç &lt;/li&gt; 
  &lt;li&gt;è§£å†³ç‰ˆæœ¬å·å®¹æ˜“è¢«é—æ¼ä¿®æ”¹çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/27 - v2.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;docker çš„ shell è„šæœ¬çš„æ¢è¡Œç¬¦ä¸º CRLF å¯¼è‡´çš„æ‰§è¡Œå¼‚å¸¸é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå¯¼è‡´æ–°é—»å‘é€ä¹Ÿä¸ºç©ºçš„é€»è¾‘é—®é¢˜&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤åï¼Œå½“ä½ é€‰æ‹© frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå°†&lt;strong&gt;æ¨é€æ‰€æœ‰æ–°é—»&lt;/strong&gt;ï¼Œä½†å—é™äºæ¶ˆæ¯æ¨é€å¤§å°é™åˆ¶ï¼Œè¯·åšå¦‚ä¸‹è°ƒæ•´ 
   &lt;ul&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸€ï¼šå…³é—­æ‰‹æœºæ¨é€ï¼Œåªé€‰æ‹© Github Pages å¸ƒç½®(è¿™æ˜¯èƒ½è·å¾—æœ€å®Œæ•´ä¿¡æ¯çš„æ–¹æ¡ˆï¼Œå°†æŠŠæ‰€æœ‰å¹³å°çš„çƒ­ç‚¹æŒ‰ç…§ä½ &lt;strong&gt;è‡ªå®šä¹‰çš„çƒ­æœç®—æ³•&lt;/strong&gt;è¿›è¡Œé‡æ–°æ’åº)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆäºŒï¼šå‡å°‘æ¨é€å¹³å°ï¼Œä¼˜å…ˆé€‰æ‹©&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;æˆ–&lt;strong&gt;Telegram&lt;/strong&gt;ï¼Œè¿™ä¸¤ä¸ªæ¨é€æˆ‘åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½(å› ä¸ºåˆ†æ‰¹æ¨é€å½±å“æ¨é€ä½“éªŒï¼Œä¸”åªæœ‰è¿™ä¸¤ä¸ªå¹³å°åªç»™ä¸€ç‚¹ç‚¹æ¨é€å®¹é‡ï¼Œæ‰€ä»¥æ‰ä¸å¾—å·²åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½ï¼Œä½†è‡³å°‘èƒ½ä¿è¯è·å¾—çš„ä¿¡æ¯å®Œæ•´)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸‰ï¼šå¯ä¸æ–¹æ¡ˆäºŒç»“åˆï¼Œæ¨¡å¼é€‰æ‹© current æˆ– incremental å¯æœ‰æ•ˆå‡å°‘ä¸€æ¬¡æ€§æ¨é€çš„å†…å®¹&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/17 - v2.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§é‡æ„&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é…ç½®ç®¡ç†é‡æ„ï¼šæ‰€æœ‰é…ç½®ç°åœ¨é€šè¿‡ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ç®¡ç†ï¼ˆmain.py æˆ‘ä¾æ—§æ²¡æ‹†åˆ†ï¼Œæ–¹ä¾¿ä½ ä»¬å¤åˆ¶å‡çº§ï¼‰&lt;/li&gt; 
  &lt;li&gt;è¿è¡Œæ¨¡å¼å‡çº§ï¼šæ”¯æŒä¸‰ç§æ¨¡å¼ - &lt;code&gt;daily&lt;/code&gt;ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰ã€&lt;code&gt;current&lt;/code&gt;ï¼ˆå½“å‰æ¦œå•ï¼‰ã€&lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰&lt;/li&gt; 
  &lt;li&gt;Docker æ”¯æŒï¼šå®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒå®¹å™¨åŒ–è¿è¡Œ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - ä¸»é…ç½®æ–‡ä»¶ï¼ˆåº”ç”¨è®¾ç½®ã€çˆ¬è™«é…ç½®ã€é€šçŸ¥é…ç½®ã€å¹³å°é…ç½®ç­‰ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆç›‘æ§è¯æ±‡è®¾ç½®ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/09 - v1.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;åŠŸèƒ½æ–°å¢&lt;/strong&gt;ï¼šå¢åŠ å¢é‡æ¨é€(åœ¨ main.py å¤´éƒ¨é…ç½® FOCUS_NEW_ONLY)ï¼Œè¯¥å¼€å…³åªå…³å¿ƒæ–°è¯é¢˜è€ŒéæŒç»­çƒ­åº¦ï¼Œåªåœ¨æœ‰æ–°å†…å®¹æ—¶æ‰å‘é€šçŸ¥ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;: æŸäº›æƒ…å†µä¸‹ï¼Œç”±äºæ–°é—»æœ¬èº«å«æœ‰ç‰¹æ®Šç¬¦å·å¯¼è‡´çš„å¶å‘æ€§æ’ç‰ˆå¼‚å¸¸ã€‚&lt;/p&gt; 
 &lt;h3&gt;2025/06/23 - v1.3.0&lt;/h3&gt; 
 &lt;p&gt;ä¼ä¸šå¾®ä¿¡ å’Œ Telegram çš„æ¨é€æ¶ˆæ¯æœ‰é•¿åº¦é™åˆ¶ï¼Œå¯¹æ­¤æˆ‘é‡‡ç”¨å°†æ¶ˆæ¯æ‹†åˆ†æ¨é€çš„æ–¹å¼ã€‚å¼€å‘æ–‡æ¡£è¯¦è§&lt;a href="https://developer.work.weixin.qq.com/document/path/91770"&gt;ä¼ä¸šå¾®ä¿¡&lt;/a&gt; å’Œ &lt;a href="https://core.telegram.org/bots/api"&gt;Telegram&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/21 - v1.2.1&lt;/h3&gt; 
 &lt;p&gt;åœ¨æœ¬ç‰ˆæœ¬ä¹‹å‰çš„æ—§ç‰ˆæœ¬ï¼Œä¸ä»… main.py éœ€è¦å¤åˆ¶æ›¿æ¢ï¼Œ crawler.yml ä¹Ÿéœ€è¦ä½ å¤åˆ¶æ›¿æ¢ &lt;a href="https://github.com/sansan0/TrendRadar/raw/master/.github/workflows/crawler.yml"&gt;https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/19 - v1.2.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ claude research æ•´ç†çš„å„å¹³å° api ,è®©æˆ‘å¿«é€Ÿå®Œæˆå„å¹³å°é€‚é…ï¼ˆè™½ç„¶ä»£ç æ›´å¤šå†—ä½™äº†~&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ”¯æŒ telegram ï¼Œä¼ä¸šå¾®ä¿¡ï¼Œé’‰é’‰æ¨é€æ¸ é“, æ”¯æŒå¤šæ¸ é“é…ç½®å’ŒåŒæ—¶æ¨é€&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/18 - v1.1.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;200 starâ­&lt;/strong&gt; äº†, ç»§ç»­ç»™å¤§ä¼™å„¿åŠ©å…´~è¿‘æœŸï¼Œåœ¨æˆ‘çš„"æ€‚æ¿"ä¸‹ï¼ŒæŒºå¤šäººåœ¨æˆ‘å…¬ä¼—å·ç‚¹èµåˆ†äº«æ¨èåŠ©åŠ›äº†æˆ‘ï¼Œæˆ‘éƒ½åœ¨åå°çœ‹è§äº†å…·ä½“è´¦å·çš„é¼“åŠ±æ•°æ®ï¼Œå¾ˆå¤šéƒ½æˆäº†å¤©ä½¿è½®è€ç²‰ï¼ˆæˆ‘ç©å…¬ä¼—å·æ‰ä¸€ä¸ªå¤šæœˆï¼Œè™½ç„¶æ³¨å†Œæ˜¯ä¸ƒå…«å¹´å‰çš„äº‹äº†å“ˆå“ˆï¼Œå±äºä¸Šè½¦æ—©ï¼Œå‘è½¦æ™šï¼‰ï¼Œä½†å› ä¸ºä½ ä»¬æ²¡æœ‰ç•™è¨€æˆ–ç§ä¿¡æˆ‘ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæ— æ³•ä¸€ä¸€å›åº”å¹¶æ„Ÿè°¢æ”¯æŒï¼Œåœ¨æ­¤ä¸€å¹¶è°¢è°¢ï¼&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é‡è¦çš„æ›´æ–°ï¼ŒåŠ äº†æƒé‡ï¼Œä½ ç°åœ¨çœ‹åˆ°çš„æ–°é—»éƒ½æ˜¯æœ€çƒ­ç‚¹æœ€æœ‰å…³æ³¨åº¦çš„å‡ºç°åœ¨æœ€ä¸Šé¢&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°æ–‡æ¡£ä½¿ç”¨ï¼Œå› ä¸ºè¿‘æœŸæ›´æ–°äº†å¾ˆå¤šåŠŸèƒ½ï¼Œè€Œä¸”ä¹‹å‰çš„ä½¿ç”¨æ–‡æ¡£æˆ‘å·æ‡’å†™çš„ç®€å•ï¼ˆè§ä¸‹é¢çš„ âš™ï¸ frequency_words.txt é…ç½®å®Œæ•´æ•™ç¨‹ï¼‰&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/16 - v1.0.0&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¢åŠ äº†ä¸€ä¸ªé¡¹ç›®æ–°ç‰ˆæœ¬æ›´æ–°æç¤ºï¼Œé»˜è®¤æ‰“å¼€ï¼Œå¦‚è¦å…³æ‰ï¼Œå¯ä»¥åœ¨ main.py ä¸­æŠŠ "FEISHU_SHOW_VERSION_UPDATE": True ä¸­çš„ True æ”¹æˆ False å³å¯&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/13+14&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å»æ‰äº†å…¼å®¹ä»£ç ï¼Œä¹‹å‰ fork çš„åŒå­¦ï¼Œç›´æ¥å¤åˆ¶ä»£ç ä¼šåœ¨å½“å¤©æ˜¾ç¤ºå¼‚å¸¸ï¼ˆç¬¬äºŒå¤©ä¼šæ¢å¤æ­£å¸¸ï¼‰&lt;/li&gt; 
  &lt;li&gt;feishu å’Œ html åº•éƒ¨å¢åŠ ä¸€ä¸ªæ–°å¢æ–°é—»æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/09&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;100 starâ­&lt;/strong&gt; äº†ï¼Œå†™ä¸ªå°åŠŸèƒ½ç»™å¤§ä¼™å„¿åŠ©åŠ©å…´ frequency_words.txt æ–‡ä»¶å¢åŠ äº†ä¸€ä¸ªã€å¿…é¡»è¯ã€‘åŠŸèƒ½ï¼Œä½¿ç”¨ + å·&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¿…é¡»è¯è¯­æ³•å¦‚ä¸‹ï¼š&lt;br /&gt; å”åƒ§æˆ–è€…çŒªå…«æˆ’å¿…é¡»åœ¨æ ‡é¢˜é‡ŒåŒæ—¶å‡ºç°ï¼Œæ‰ä¼šæ”¶å½•åˆ°æ¨é€æ–°é—»ä¸­&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
+çŒªå…«æˆ’
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;è¿‡æ»¤è¯çš„ä¼˜å…ˆçº§æ›´é«˜ï¼š&lt;br /&gt; å¦‚æœæ ‡é¢˜ä¸­è¿‡æ»¤è¯åŒ¹é…åˆ°å”åƒ§å¿µç»ï¼Œé‚£ä¹ˆå³ä½¿å¿…é¡»è¯é‡Œæœ‰å”åƒ§ï¼Œä¹Ÿä¸æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
!å”åƒ§å¿µç»
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;2025/06/02&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ç½‘é¡µ&lt;/strong&gt;å’Œ&lt;strong&gt;é£ä¹¦æ¶ˆæ¯&lt;/strong&gt;æ”¯æŒæ‰‹æœºç›´æ¥è·³è½¬è¯¦æƒ…æ–°é—»&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ–æ˜¾ç¤ºæ•ˆæœ + 1&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/05/26&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é£ä¹¦æ¶ˆæ¯æ˜¾ç¤ºæ•ˆæœä¼˜åŒ–&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å‰&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/before.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å‰" width="400" /&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/after.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å" width="400" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;é…ç½®å®Œæˆåï¼Œæ–°é—»æ•°æ®ä¸€å°æ—¶åæ‰ä¼šæ›´æ–°ï¼Œå¦‚æƒ³åŠ å¿«ï¼Œå¯å‚ç…§ã€ç¬¬4æ­¥ã€‘æ‰‹åŠ¨æµ‹è¯•é…ç½®æ•ˆæœ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fork æœ¬é¡¹ç›®&lt;/strong&gt;åˆ°ä½ çš„ GitHub è´¦æˆ·&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ç‚¹å‡»æœ¬é¡µé¢å³ä¸Šè§’çš„"Fork"æŒ‰é’®&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¾ç½® GitHub Secretsï¼ˆé€‰æ‹©ä½ éœ€è¦çš„å¹³å°ï¼‰&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;åœ¨ä½  Fork åçš„ä»“åº“ä¸­ï¼Œè¿›å…¥ &lt;code&gt;Settings&lt;/code&gt; &amp;gt; &lt;code&gt;Secrets and variables&lt;/code&gt; &amp;gt; &lt;code&gt;Actions&lt;/code&gt; &amp;gt; &lt;code&gt;New repository secret&lt;/code&gt;ï¼Œç„¶åæ ¹æ®éœ€è¦é…ç½®ä»¥ä¸‹ä»»ä¸€æˆ–å¤šä¸ªé€šçŸ¥å¹³å°ï¼š&lt;/p&gt; &lt;p&gt;å¯ä»¥åŒæ—¶é…ç½®å¤šä¸ªå¹³å°ï¼Œç³»ç»Ÿä¼šå‘æ‰€æœ‰é…ç½®çš„å¹³å°å‘é€é€šçŸ¥ã€‚&lt;/p&gt; &lt;p&gt;æ•ˆæœç±»ä¼¼ä¸‹å›¾ï¼Œä¸€ä¸ª name å¯¹åº”ä¸€ä¸ª secretï¼Œä¿å­˜å®Œå°±è¡Œï¼Œä½ é‡æ–°ç¼–è¾‘çœ‹ä¸åˆ° secret æ˜¯æ­£å¸¸æƒ…å†µã€‚&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/secrets.png" alt="GitHub Secrets" /&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ ä¼ä¸šå¾®ä¿¡æœºå™¨äºº&lt;/strong&gt;ï¼ˆé…ç½®æœ€ç®€å•æœ€è¿…é€Ÿï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„ä¼ä¸šå¾®ä¿¡æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;æ‰‹æœºç«¯è®¾ç½®ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;æ‰“å¼€ä¼ä¸šå¾®ä¿¡ App â†’ è¿›å…¥ç›®æ ‡å†…éƒ¨ç¾¤èŠ&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»å³ä¸Šè§’"â€¦"æŒ‰é’® â†’ é€‰æ‹©"æ¶ˆæ¯æ¨é€"&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»"æ·»åŠ " â†’ åç§°è¾“å…¥"TrendRadar"&lt;/li&gt; 
    &lt;li&gt;å¤åˆ¶ Webhook åœ°å€ï¼Œç‚¹å‡»ä¿å­˜ï¼Œå¤åˆ¶çš„å†…å®¹é…ç½®åˆ°ä¸Šæ–¹çš„ GitHub Secret ä¸­&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;PC ç«¯è®¾ç½®æµç¨‹ç±»ä¼¼&lt;/h4&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é£ä¹¦æœºå™¨äºº&lt;/strong&gt;ï¼ˆæ¶ˆæ¯æ˜¾ç¤ºæœ€å‹å¥½ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„é£ä¹¦æœºå™¨äºº Webhook åœ°å€(è¯¥é“¾æ¥å¼€å¤´ç±»ä¼¼ &lt;a href="https://www.feishu.cn/flow/api/trigger-webhook/"&gt;https://www.feishu.cn/flow/api/trigger-webhook/&lt;/a&gt;********)&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;æœ‰ä¸¤ä¸ªæ–¹æ¡ˆï¼Œ&lt;strong&gt;æ–¹æ¡ˆä¸€&lt;/strong&gt;é…ç½®ç®€å•ï¼Œ&lt;strong&gt;æ–¹æ¡ˆäºŒ&lt;/strong&gt;é…ç½®å¤æ‚(ä½†æ˜¯ç¨³å®šæ¨é€)&lt;/p&gt; 
   &lt;p&gt;å…¶ä¸­æ–¹æ¡ˆä¸€ï¼Œç”± &lt;strong&gt;ziventian&lt;/strong&gt;å‘ç°å¹¶æä¾›å»ºè®®ï¼Œåœ¨è¿™é‡Œæ„Ÿè°¢ä»–ï¼Œé»˜è®¤æ˜¯ä¸ªäººæ¨é€ï¼Œä¹Ÿå¯ä»¥é…ç½®ç¾¤ç»„æ¨é€æ“ä½œ&lt;a href="https://github.com/sansan0/TrendRadar/issues/97"&gt;#97&lt;/a&gt; ï¼Œ&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆä¸€ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;å¯¹éƒ¨åˆ†äººå­˜åœ¨é¢å¤–æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥"ç³»ç»Ÿé”™è¯¯"ã€‚éœ€è¦æ‰‹æœºç«¯æœç´¢ä¸‹æœºå™¨äººï¼Œç„¶åå¼€å¯é£ä¹¦æœºå™¨äººåº”ç”¨(è¯¥å»ºè®®æ¥è‡ªäºç½‘å‹ï¼Œå¯å‚è€ƒ)&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-command"&gt;https://botbuilder.feishu.cn/home/my-command&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººæŒ‡ä»¤"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©è§¦å‘å™¨"ï¼Œå¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="6"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "é€šè¿‡å®˜æ–¹æœºå™¨äººå‘æ¶ˆæ¯"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="9"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 4 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆäºŒï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-app"&gt;https://botbuilder.feishu.cn/home/my-app&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººåº”ç”¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;è¿›å…¥åˆ›å»ºçš„åº”ç”¨åï¼Œç‚¹å‡»"æµç¨‹æ¶‰åŠ" &amp;gt; "åˆ›å»ºæµç¨‹" &amp;gt; "é€‰æ‹©è§¦å‘å™¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;å¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="7"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "å‘é€é£ä¹¦æ¶ˆæ¯"ï¼Œå‹¾é€‰ "ç¾¤æ¶ˆæ¯"ï¼Œç„¶åç‚¹å‡»ä¸‹é¢çš„è¾“å…¥æ¡†ï¼Œç‚¹å‡»"æˆ‘ç®¡ç†çš„ç¾¤ç»„"ï¼ˆå¦‚æœæ²¡æœ‰ç¾¤ç»„ï¼Œä½ å¯ä»¥åœ¨é£ä¹¦ app ä¸Šåˆ›å»ºç¾¤ç»„ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="10"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 5 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é’‰é’‰æœºå™¨äºº&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„é’‰é’‰æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äººï¼ˆä»… PC ç«¯æ”¯æŒï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰“å¼€é’‰é’‰ PC å®¢æˆ·ç«¯ï¼Œè¿›å…¥ç›®æ ‡ç¾¤èŠ&lt;/li&gt; 
      &lt;li&gt;ç‚¹å‡»ç¾¤è®¾ç½®å›¾æ ‡ï¼ˆâš™ï¸ï¼‰â†’ å¾€ä¸‹ç¿»æ‰¾åˆ°"æœºå™¨äºº"ç‚¹å¼€&lt;/li&gt; 
      &lt;li&gt;é€‰æ‹©"æ·»åŠ æœºå™¨äºº" â†’ "è‡ªå®šä¹‰"&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å®‰å…¨è®¾ç½®&lt;/strong&gt;ï¼š 
       &lt;ul&gt; 
        &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰å…³é”®è¯&lt;/strong&gt;ï¼šè®¾ç½® "çƒ­ç‚¹"&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å®Œæˆè®¾ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å‹¾é€‰æœåŠ¡æ¡æ¬¾åè®® â†’ ç‚¹å‡»"å®Œæˆ"&lt;/li&gt; 
      &lt;li&gt;å¤åˆ¶è·å¾—çš„ Webhook URL&lt;/li&gt; 
      &lt;li&gt;å°† URL é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šç§»åŠ¨ç«¯åªèƒ½æ¥æ”¶æ¶ˆæ¯ï¼Œæ— æ³•åˆ›å»ºæ–°æœºå™¨äººã€‚&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ Telegram Bot&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt; - ä½ çš„ Telegram Bot Token&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt; - ä½ çš„ Telegram Chat ID&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;åœ¨ Telegram ä¸­æœç´¢ &lt;code&gt;@BotFather&lt;/code&gt;ï¼ˆå¤§å°å†™æ³¨æ„ï¼Œæœ‰è“è‰²å¾½ç« å‹¾å‹¾ï¼Œæœ‰ç±»ä¼¼ 37849827 monthly usersï¼Œè¿™ä¸ªæ‰æ˜¯å®˜æ–¹çš„ï¼Œæœ‰ä¸€äº›ä»¿å®˜æ–¹çš„è´¦å·æ³¨æ„è¾¨åˆ«ï¼‰&lt;/li&gt; 
      &lt;li&gt;å‘é€ &lt;code&gt;/newbot&lt;/code&gt; å‘½ä»¤åˆ›å»ºæ–°æœºå™¨äºº&lt;/li&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°ï¼ˆå¿…é¡»ä»¥"bot"ç»“å°¾ï¼Œå¾ˆå®¹æ˜“é‡åˆ°é‡å¤åå­—ï¼Œæ‰€ä»¥ä½ è¦ç»å°½è„‘æ±æƒ³ä¸åŒçš„åå­—ï¼‰&lt;/li&gt; 
      &lt;li&gt;è·å– Bot Tokenï¼ˆæ ¼å¼å¦‚ï¼š&lt;code&gt;123456789:AAHfiqksKZ8WmR2zSjiQ7_v4TMAKdiHm9T0&lt;/code&gt;ï¼‰&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è·å– Chat ID&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•ä¸€ï¼šé€šè¿‡å®˜æ–¹ API è·å–&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å…ˆå‘ä½ çš„æœºå™¨äººå‘é€ä¸€æ¡æ¶ˆæ¯&lt;/li&gt; 
      &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;https://api.telegram.org/bot&amp;lt;ä½ çš„Bot Token&amp;gt;/getUpdates&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;åœ¨è¿”å›çš„ JSON ä¸­æ‰¾åˆ° &lt;code&gt;"chat":{"id":æ•°å­—}&lt;/code&gt; ä¸­çš„æ•°å­—&lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•äºŒï¼šä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æœç´¢ &lt;code&gt;@userinfobot&lt;/code&gt; å¹¶å‘é€ &lt;code&gt;/start&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;è·å–ä½ çš„ç”¨æˆ· ID ä½œä¸º Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®åˆ° GitHub&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 1 æ­¥è·å¾—çš„ Bot Token&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 2 æ­¥è·å¾—çš„ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é‚®ä»¶æ¨é€&lt;/strong&gt;ï¼ˆæ”¯æŒæ‰€æœ‰ä¸»æµé‚®ç®±ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ³¨æ„äº‹é¡¹ï¼šä¸ºé˜²æ­¢é‚®ä»¶ç¾¤å‘åŠŸèƒ½è¢«&lt;strong&gt;æ»¥ç”¨&lt;/strong&gt;ï¼Œå½“å‰çš„ç¾¤å‘æ˜¯æ‰€æœ‰æ”¶ä»¶äººéƒ½èƒ½çœ‹åˆ°å½¼æ­¤çš„é‚®ç®±åœ°å€ï¼Œé€‚åˆç†Ÿäººé—´äº¤æµèµ„è®¯ã€‚&lt;/li&gt; 
    &lt;li&gt;ä»…ä¾›å‚è€ƒï¼šè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼Œé‚®ç®±æ–¹é¢å¹¶æ²¡æœ‰ä¸€ä¸€éªŒè¯ï¼Œæ˜¯æŒ‰ç…§ SMTP çš„æ ‡å‡†é…ç½®çš„&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_FROM&lt;/code&gt; - å‘ä»¶äººé‚®ç®±åœ°å€&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; - é‚®ç®±å¯†ç æˆ–æˆæƒç &lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_TO&lt;/code&gt; - æ”¶ä»¶äººé‚®ç®±åœ°å€ï¼ˆå¤šä¸ªæ”¶ä»¶äººç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰ä¹Ÿå¯ä»¥å’Œ EMAIL_FROM ä¸€æ ·ï¼Œè‡ªå·±å‘é€ç»™è‡ªå·±&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt; - SMTPæœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt; - SMTPç«¯å£ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é‚®ç®±è®¾ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;QQé‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½• QQé‚®ç®±ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ è´¦æˆ·&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ POP3/SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆæˆæƒç ï¼ˆ16ä½å­—æ¯ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç ï¼Œè€Œé QQ å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;Gmailï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;å¼€å¯ä¸¤æ­¥éªŒè¯&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆåº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™åº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;163/126é‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½•ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ POP3/SMTP/IMAP&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;è®¾ç½®å®¢æˆ·ç«¯æˆæƒç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;é«˜çº§é…ç½®&lt;/strong&gt;ï¼š å¦‚æœè‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼Œå¯æ‰‹åŠ¨é…ç½® SMTPï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ï¼šå¦‚ smtp.gmail.com&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ï¼šå¦‚ 587ï¼ˆTLSï¼‰æˆ– 465ï¼ˆSSLï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;å¤šæ”¶ä»¶äººè®¾ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;EMAIL_TO="&lt;a href="mailto:user1@example.com"&gt;user1@example.com&lt;/a&gt;,&lt;a href="mailto:user2@example.com"&gt;user2@example.com&lt;/a&gt;,&lt;a href="mailto:user3@example.com"&gt;user3@example.com&lt;/a&gt;"&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ ntfy æ¨é€&lt;/strong&gt;ï¼ˆå¼€æºå…è´¹ï¼Œæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;æ–¹å¼ä¸€ï¼šå…è´¹ä½¿ç”¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰ ğŸ†“&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… æ— éœ€æ³¨å†Œè´¦å·ï¼Œç«‹å³ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;âœ… æ¯å¤© 250 æ¡æ¶ˆæ¯ï¼ˆè¶³å¤Ÿ 90% ç”¨æˆ·ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… Topic åç§°å³"å¯†ç "ï¼ˆéœ€é€‰æ‹©ä¸æ˜“çŒœæµ‹çš„åç§°ï¼‰&lt;/li&gt; 
    &lt;li&gt;âš ï¸ æ¶ˆæ¯æœªåŠ å¯†ï¼Œä¸é€‚åˆæ•æ„Ÿä¿¡æ¯, ä½†é€‚åˆæˆ‘ä»¬è¿™ä¸ªé¡¹ç›®çš„ä¸æ•æ„Ÿä¿¡æ¯&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;å¿«é€Ÿå¼€å§‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä¸‹è½½ ntfy åº”ç”¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Androidï¼š&lt;a href="https://play.google.com/store/apps/details?id=io.heckel.ntfy"&gt;Google Play&lt;/a&gt; / &lt;a href="https://f-droid.org/en/packages/io.heckel.ntfy/"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;iOSï¼š&lt;a href="https://apps.apple.com/us/app/ntfy/id1625396347"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;æ¡Œé¢ï¼šè®¿é—® &lt;a href="https://ntfy.sh"&gt;ntfy.sh&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¢é˜…ä¸»é¢˜&lt;/strong&gt;ï¼ˆé€‰æ‹©ä¸€ä¸ªéš¾çŒœçš„åç§°ï¼‰ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code&gt;å»ºè®®æ ¼å¼ï¼štrendradar-{ä½ çš„åå­—ç¼©å†™}-{éšæœºæ•°å­—}

ä¸èƒ½ä½¿ç”¨ä¸­æ–‡

âœ… å¥½ä¾‹å­ï¼štrendradar-zs-8492
âŒ åä¾‹å­ï¼šnewsã€alertsï¼ˆå¤ªå®¹æ˜“è¢«çŒœåˆ°ï¼‰
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® GitHub Secret&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOPIC&lt;/code&gt;ï¼šå¡«å†™ä½ åˆšæ‰è®¢é˜…çš„ä¸»é¢˜åç§°&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_SERVER_URL&lt;/code&gt;ï¼šç•™ç©ºï¼ˆé»˜è®¤ä½¿ç”¨ ntfy.shï¼‰&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOKEN&lt;/code&gt;ï¼šç•™ç©º&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æµ‹è¯•&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -d "æµ‹è¯•æ¶ˆæ¯" ntfy.sh/ä½ çš„ä¸»é¢˜åç§°
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;h3&gt;æ–¹å¼äºŒï¼šè‡ªæ‰˜ç®¡ï¼ˆå®Œå…¨éšç§æ§åˆ¶ï¼‰ ğŸ”’&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤&lt;/strong&gt;ï¼šæœ‰æœåŠ¡å™¨ã€è¿½æ±‚å®Œå…¨éšç§ã€æŠ€æœ¯èƒ½åŠ›å¼º&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… å®Œå…¨å¼€æºï¼ˆApache 2.0 + GPLv2ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… æ•°æ®å®Œå…¨è‡ªä¸»æ§åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… æ— ä»»ä½•é™åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… é›¶è´¹ç”¨&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ä¸€é”®éƒ¨ç½²&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name ntfy \
  -p 80:80 \
  -v /var/cache/ntfy:/var/cache/ntfy \
  binwiederhier/ntfy \
  serve --cache-file /var/cache/ntfy/cache.db
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;é…ç½® TrendRadar&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;NTFY_SERVER_URL: https://ntfy.yourdomain.com
NTFY_TOPIC: trendradar-alerts  # è‡ªæ‰˜ç®¡å¯ç”¨ç®€å•åç§°
NTFY_TOKEN: tk_your_token  # å¯é€‰ï¼šå¯ç”¨è®¿é—®æ§åˆ¶
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;åœ¨åº”ç”¨ä¸­è®¢é˜…&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç‚¹å‡»"Use another server"&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä½ çš„æœåŠ¡å™¨åœ°å€&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä¸»é¢˜åç§°&lt;/li&gt; 
    &lt;li&gt;ï¼ˆå¯é€‰ï¼‰è¾“å…¥ç™»å½•å‡­æ®&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é—®é¢˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q1: å…è´¹ç‰ˆå¤Ÿç”¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;æ¯å¤© 250 æ¡æ¶ˆæ¯å¯¹å¤§å¤šæ•°ç”¨æˆ·è¶³å¤Ÿã€‚æŒ‰ 30 åˆ†é’ŸæŠ“å–ä¸€æ¬¡è®¡ç®—ï¼Œæ¯å¤©çº¦ 48 æ¬¡æ¨é€ï¼Œå®Œå…¨å¤Ÿç”¨ã€‚&lt;/p&gt; 
   &lt;/details&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q2: Topic åç§°çœŸçš„å®‰å…¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;å¦‚æœä½ é€‰æ‹©éšæœºçš„ã€è¶³å¤Ÿé•¿çš„åç§°ï¼ˆå¦‚ &lt;code&gt;trendradar-zs-8492-news&lt;/code&gt;ï¼‰ï¼Œæš´åŠ›ç ´è§£å‡ ä¹ä¸å¯èƒ½ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ntfy æœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶ï¼ˆ1 ç§’ 1 æ¬¡è¯·æ±‚ï¼‰&lt;/li&gt; 
     &lt;li&gt;64 ä¸ªå­—ç¬¦é€‰æ‹©ï¼ˆA-Z, a-z, 0-9, _, -ï¼‰&lt;/li&gt; 
     &lt;li&gt;10 ä½éšæœºå­—ç¬¦ä¸²æœ‰ 64^10 ç§å¯èƒ½æ€§ï¼ˆéœ€è¦æ•°å¹´æ‰èƒ½ç ´è§£ï¼‰&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/details&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;æ¨èé€‰æ‹©ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;ç”¨æˆ·ç±»å‹&lt;/th&gt; 
      &lt;th&gt;æ¨èæ–¹æ¡ˆ&lt;/th&gt; 
      &lt;th&gt;ç†ç”±&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æ™®é€šç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸€ï¼ˆå…è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;ç®€å•å¿«é€Ÿï¼Œå¤Ÿç”¨&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æŠ€æœ¯ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼äºŒï¼ˆè‡ªæ‰˜ç®¡ï¼‰&lt;/td&gt; 
      &lt;td&gt;å®Œå…¨æ§åˆ¶ï¼Œæ— é™åˆ¶&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;é«˜é¢‘ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸‰ï¼ˆä»˜è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;è¿™ä¸ªè‡ªå·±å»å®˜ç½‘çœ‹å§&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;p&gt;&lt;strong&gt;ç›¸å…³é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/"&gt;ntfy å®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/install/"&gt;è‡ªæ‰˜ç®¡æ•™ç¨‹&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/binwiederhier/ntfy"&gt;GitHub ä»“åº“&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®è¯´æ˜ï¼š&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;æ¨é€è®¾ç½®&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;config/config.yaml&lt;/a&gt; ä¸­é…ç½®æ¨é€æ¨¡å¼å’Œé€šçŸ¥é€‰é¡¹&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;å…³é”®è¯è®¾ç½®&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;config/frequency_words.txt&lt;/a&gt; ä¸­æ·»åŠ ä½ å…³å¿ƒçš„å…³é”®è¯&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡è°ƒæ•´&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/.github/workflows/crawler.yml"&gt;.github/workflows/crawler.yml&lt;/a&gt; è¯·è°¨æ…è°ƒæ•´ï¼Œåˆ«è´ªå¿ƒ&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šå»ºè®®åªè°ƒæ•´æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜çš„é…ç½®é¡¹ï¼Œå…¶ä»–é€‰é¡¹ä¸»è¦ä¾›ä½œè€…å¼€å‘æ—¶æµ‹è¯•ä½¿ç”¨&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ‰‹åŠ¨æµ‹è¯•æ–°é—»æ¨é€&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;æˆ‘è¿™é‡Œæ˜¯æ‹¿æˆ‘çš„é¡¹ç›®ä¸¾ä¾‹ï¼Œä½ è¦å»ä½ &lt;strong&gt;fork&lt;/strong&gt;çš„é¡¹ç›®åšæµ‹è¯•&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;è¿›å…¥ Actions&lt;/strong&gt;ï¼š&lt;a href="https://github.com/sansan0/TrendRadar/actions"&gt;https://github.com/sansan0/TrendRadar/actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;æ‰¾åˆ° "Hot News Crawler" çš„ç‚¹è¿›å»ï¼Œå¦‚æœçœ‹ä¸åˆ°è¯¥å­—æ ·ï¼Œé‚£ä¹ˆå‚ç…§&lt;a href="https://github.com/sansan0/TrendRadar/issues/109"&gt;#109&lt;/a&gt;è§£å†³&lt;/li&gt; 
   &lt;li&gt;ç‚¹å‡» "Run workflow" æŒ‰é’®è¿è¡Œï¼Œç­‰å¾… 1 åˆ†é’Ÿå·¦å³æ•°æ®åˆ°ä½ æ‰‹æœºä¸Š&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ³ Docker éƒ¨ç½²&lt;/h2&gt; 
&lt;h4&gt;æ–¹å¼ä¸€ï¼šå¿«é€Ÿä½“éªŒï¼ˆä¸€è¡Œå‘½ä»¤ï¼‰&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Linux/macOS ç³»ç»Ÿï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºé…ç½®ç›®å½•å¹¶ä¸‹è½½é…ç½®æ–‡ä»¶
mkdir -p config output
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æˆ–è€…&lt;strong&gt;æ‰‹åŠ¨åˆ›å»º&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;åœ¨å½“å‰ç›®å½•åˆ›å»º &lt;code&gt;config&lt;/code&gt; æ–‡ä»¶å¤¹&lt;/li&gt; 
 &lt;li&gt;ä¸‹è½½é…ç½®æ–‡ä»¶ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;è®¿é—® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml&lt;/a&gt; â†’ å³é”®"å¦å­˜ä¸º" â†’ ä¿å­˜åˆ° &lt;code&gt;config\config.yaml&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;è®¿é—® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt&lt;/a&gt; â†’ å³é”®"å¦å­˜ä¸º" â†’ ä¿å­˜åˆ° &lt;code&gt;config\frequency_words.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;å®Œæˆåçš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;å½“å‰ç›®å½•/
â””â”€â”€ config/
    â”œâ”€â”€ config.yaml
    â””â”€â”€ frequency_words.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name trend-radar \
  -v ./config:/app/config:ro \
  -v ./output:/app/output \
  -e FEISHU_WEBHOOK_URL="ä½ çš„é£ä¹¦webhook" \
  -e DINGTALK_WEBHOOK_URL="ä½ çš„é’‰é’‰webhook" \
  -e WEWORK_WEBHOOK_URL="ä½ çš„ä¼ä¸šå¾®ä¿¡webhook" \
  -e TELEGRAM_BOT_TOKEN="ä½ çš„telegram_bot_token" \
  -e TELEGRAM_CHAT_ID="ä½ çš„telegram_chat_id" \
  -e EMAIL_FROM="ä½ çš„å‘ä»¶é‚®ç®±" \
  -e EMAIL_PASSWORD="ä½ çš„é‚®ç®±å¯†ç æˆ–æˆæƒç " \
  -e EMAIL_TO="æ”¶ä»¶äººé‚®ç®±" \
  -e CRON_SCHEDULE="*/30 * * * *" \
  -e RUN_MODE="cron" \
  -e IMMEDIATE_RUN="true" \
  wantcat/trendradar:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æ–¹å¼äºŒï¼šä½¿ç”¨ docker-composeï¼ˆæ¨èï¼‰&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;åˆ›å»ºé¡¹ç›®ç›®å½•å’Œé…ç½®&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p trendradar/{config,docker}
cd trendradar

# ä¸‹è½½é…ç½®æ–‡ä»¶æ¨¡æ¿
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/

# ä¸‹è½½ docker-compose é…ç½®
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/.env
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;å®Œæˆåçš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;å½“å‰ç›®å½•/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ frequency_words.txt
â””â”€â”€ docker/
    â”œâ”€â”€ .env
    â””â”€â”€ docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - åº”ç”¨ä¸»é…ç½®ï¼ˆæŠ¥å‘Šæ¨¡å¼ã€æ¨é€è®¾ç½®ç­‰ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆè®¾ç½®ä½ å…³å¿ƒçš„çƒ­ç‚¹è¯æ±‡ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - ç¯å¢ƒå˜é‡é…ç½®ï¼ˆwebhook URLs å’Œå®šæ—¶ä»»åŠ¡ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;âš™ï¸ ç¯å¢ƒå˜é‡è¦†ç›–æœºåˆ¶ï¼ˆv3.0.5+ï¼‰&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;å¦‚æœä½ åœ¨ NAS æˆ–å…¶ä»– Docker ç¯å¢ƒä¸­é‡åˆ°&lt;strong&gt;ä¿®æ”¹ &lt;code&gt;config.yaml&lt;/code&gt; åé…ç½®ä¸ç”Ÿæ•ˆ&lt;/strong&gt;çš„é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ç›´æ¥è¦†ç›–é…ç½®ï¼š&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;ç¯å¢ƒå˜é‡&lt;/th&gt; 
     &lt;th&gt;å¯¹åº”é…ç½®&lt;/th&gt; 
     &lt;th&gt;ç¤ºä¾‹å€¼&lt;/th&gt; 
     &lt;th&gt;è¯´æ˜&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;ENABLE_CRAWLER&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;crawler.enable_crawler&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ˜¯å¦å¯ç”¨çˆ¬è™«&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;ENABLE_NOTIFICATION&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.enable_notification&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ˜¯å¦å¯ç”¨é€šçŸ¥&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;REPORT_MODE&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;report.mode&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;daily&lt;/code&gt; / &lt;code&gt;incremental&lt;/code&gt; / &lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æŠ¥å‘Šæ¨¡å¼&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_ENABLED&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.enabled&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€æ—¶é—´çª—å£å¼€å…³&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_START&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.time_range.start&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;08:00&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€å¼€å§‹æ—¶é—´&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_END&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.time_range.end&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;22:00&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€ç»“æŸæ—¶é—´&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.webhooks.feishu_url&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;https://...&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;é£ä¹¦ Webhook&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;p&gt;&lt;strong&gt;é…ç½®ä¼˜å…ˆçº§&lt;/strong&gt;ï¼šç¯å¢ƒå˜é‡ &amp;gt; config.yaml&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ–¹æ³•&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä¿®æ”¹ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶å¡«å†™éœ€è¦çš„é…ç½®&lt;/li&gt; 
   &lt;li&gt;æˆ–åœ¨ NAS/ç¾¤æ™– Docker ç®¡ç†ç•Œé¢çš„"ç¯å¢ƒå˜é‡"ä¸­ç›´æ¥æ·»åŠ &lt;/li&gt; 
   &lt;li&gt;é‡å¯å®¹å™¨åç”Ÿæ•ˆï¼š&lt;code&gt;docker-compose restart&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨æœåŠ¡&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æ‹‰å–æœ€æ–°é•œåƒå¹¶å¯åŠ¨
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŸ¥çœ‹è¿è¡ŒçŠ¶æ€&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹æ—¥å¿—
docker logs -f trend-radar

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps | grep trend-radar
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;æ–¹å¼ä¸‰ï¼šæœ¬åœ°æ„å»ºï¼ˆå¼€å‘è€…é€‰é¡¹ï¼‰&lt;/h4&gt; 
&lt;p&gt;å¦‚æœéœ€è¦è‡ªå®šä¹‰ä¿®æ”¹ä»£ç æˆ–æ„å»ºè‡ªå·±çš„é•œåƒï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å…‹éš†é¡¹ç›®
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar

# ä¿®æ”¹é…ç½®æ–‡ä»¶
vim config/config.yaml
vim config/frequency_words.txt

# ä½¿ç”¨æ„å»ºç‰ˆæœ¬çš„ docker-compose
cd docker
cp docker-compose-build.yml docker-compose.yml

# æ„å»ºå¹¶å¯åŠ¨
docker-compose build
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;é•œåƒæ›´æ–°&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ–¹å¼ä¸€ï¼šæ‰‹åŠ¨æ›´æ–°
docker pull wantcat/trendradar:latest
docker-compose down
docker-compose up -d

# æ–¹å¼äºŒï¼šä½¿ç”¨ docker-compose æ›´æ–°
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æœåŠ¡ç®¡ç†å‘½ä»¤&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
docker exec -it trend-radar python manage.py status

# æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡çˆ¬è™«
docker exec -it trend-radar python manage.py run

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker exec -it trend-radar python manage.py logs

# æ˜¾ç¤ºå½“å‰é…ç½®
docker exec -it trend-radar python manage.py config

# æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
docker exec -it trend-radar python manage.py files

# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
docker exec -it trend-radar python manage.py help

# é‡å¯å®¹å™¨
docker restart trend-radar

# åœæ­¢å®¹å™¨
docker stop trend-radar

# åˆ é™¤å®¹å™¨ï¼ˆä¿ç•™æ•°æ®ï¼‰
docker rm trend-radar
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æ•°æ®æŒä¹…åŒ–&lt;/h4&gt; 
&lt;p&gt;ç”Ÿæˆçš„æŠ¥å‘Šå’Œæ•°æ®é»˜è®¤ä¿å­˜åœ¨ &lt;code&gt;./output&lt;/code&gt; ç›®å½•ä¸‹ï¼Œå³ä½¿å®¹å™¨é‡å¯æˆ–åˆ é™¤ï¼Œæ•°æ®ä¹Ÿä¼šä¿ç•™ã€‚&lt;/p&gt; 
&lt;h4&gt;æ•…éšœæ’æŸ¥&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker inspect trend-radar

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs --tail 100 trend-radar

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker exec -it trend-radar /bin/bash

# éªŒè¯é…ç½®æ–‡ä»¶
docker exec -it trend-radar ls -la /app/config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ¤– AI æ™ºèƒ½åˆ†æéƒ¨ç½²&lt;/h2&gt; 
&lt;p&gt;TrendRadar v3.0.0 æ–°å¢äº†åŸºäº &lt;strong&gt;MCP (Model Context Protocol)&lt;/strong&gt; çš„ AI åˆ†æåŠŸèƒ½ï¼Œè®©ä½ å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€ä¸æ–°é—»æ•°æ®å¯¹è¯ï¼Œè¿›è¡Œæ·±åº¦åˆ†æã€‚ä½¿ç”¨ &lt;strong&gt;AI åŠŸèƒ½&lt;/strong&gt; çš„æœ€ä½³å‰ææ˜¯å·²ä½¿ç”¨æœ¬é¡¹ç›®è‡³å°‘è¿è¡Œä¸€å¤©(ç§¯ç´¯æ–°é—»æ•°æ®)&lt;/p&gt; 
&lt;h3&gt;1. å¿«é€Ÿéƒ¨ç½²&lt;/h3&gt; 
&lt;p&gt;Cherry Studio æä¾› GUI é…ç½®ç•Œé¢ï¼Œ 5 åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²ï¼Œ å¤æ‚çš„éƒ¨åˆ†æ˜¯ä¸€é”®å®‰è£…çš„ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å›¾æ–‡éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼šç°å·²æ›´æ–°åˆ°æˆ‘çš„&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;å…¬ä¼—å·&lt;/a&gt;ï¼Œå›å¤ "mcp" å³å¯&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. å­¦ä¹ ä¸ AI å¯¹è¯çš„å§¿åŠ¿&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†å¯¹è¯æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-MCP-FAQ.md"&gt;README-MCP-FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æé—®æ•ˆæœ&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å®é™…ä¸å»ºè®®ä¸€æ¬¡æ€§é—®å¤šä¸ªé—®é¢˜ã€‚å¦‚æœä½ é€‰æ‹©çš„ ai æ¨¡å‹è¿ä¸‹å›¾çš„æŒ‰é¡ºåºè°ƒç”¨éƒ½æ— æ³•åšåˆ°ï¼Œå»ºè®®æ¢ä¸€ä¸ªã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/ai2.png" alt="mcp ä½¿ç”¨æ•ˆæœå›¾2" width="600" /&gt; 
&lt;h2&gt;ğŸ”Œ MCP å®¢æˆ·ç«¯&lt;/h2&gt; 
&lt;p&gt;TrendRadar MCP æœåŠ¡æ”¯æŒæ ‡å‡†çš„ Model Context Protocol (MCP) åè®®ï¼Œå¯ä»¥æ¥å…¥å„ç§æ”¯æŒ MCP çš„ AI å®¢æˆ·ç«¯è¿›è¡Œæ™ºèƒ½åˆ†æã€‚&lt;/p&gt; 
&lt;h3&gt;æ”¯æŒçš„å®¢æˆ·ç«¯&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°† &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; æ›¿æ¢ä¸ºä½ çš„é¡¹ç›®å®é™…è·¯å¾„&lt;/li&gt; 
 &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åŒåæ–œæ ï¼š&lt;code&gt;C:\\Users\\YourName\\TrendRadar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ä¿å­˜åè®°å¾—é‡å¯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Claude Desktop&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;é…ç½®æ–‡ä»¶æ–¹å¼&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ Claude Desktop çš„ MCP é…ç½®æ–‡ä»¶ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;ï¼š &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Mac&lt;/strong&gt;ï¼š &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ],
      "env": {},
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Cursor&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;æ–¹å¼ä¸€ï¼šHTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® Cursor&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;é¡¹ç›®çº§é…ç½®&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://localhost:3333/mcp",
      "description": "TrendRadar æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;å…¨å±€é…ç½®&lt;/strong&gt;ï¼š åœ¨ç”¨æˆ·ç›®å½•åˆ›å»º &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;ï¼ˆåŒæ ·å†…å®¹ï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿å­˜é…ç½®æ–‡ä»¶åé‡å¯ Cursor&lt;/li&gt; 
    &lt;li&gt;åœ¨èŠå¤©ç•Œé¢çš„ "Available Tools" ä¸­æŸ¥çœ‹å·²è¿æ¥çš„å·¥å…·&lt;/li&gt; 
    &lt;li&gt;å¼€å§‹ä½¿ç”¨ï¼š&lt;code&gt;æœç´¢ä»Šå¤©çš„"AI"ç›¸å…³æ–°é—»&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;æ–¹å¼äºŒï¼šSTDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ VSCode (Cline/Continue)&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;Cline é…ç½®&lt;/h4&gt; 
 &lt;p&gt;åœ¨ Cline çš„ MCP è®¾ç½®ä¸­æ·»åŠ ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "url": "http://localhost:3333/mcp",
    "type": "streamableHttp",
    "autoApprove": [],
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "command": "uv",
    "args": [
      "--directory",
      "/path/to/TrendRadar",
      "run",
      "python",
      "-m",
      "mcp_server.server"
    ],
    "type": "stdio",
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Continue é…ç½®&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ &lt;code&gt;~/.continue/config.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "experimental": {
    "modelContextProtocolServers": [
      {
        "transport": {
          "type": "stdio",
          "command": "uv",
          "args": [
            "--directory",
            "/path/to/TrendRadar",
            "run",
            "python",
            "-m",
            "mcp_server.server"
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;åˆ†ææœ€è¿‘7å¤©"ç‰¹æ–¯æ‹‰"çš„çƒ­åº¦å˜åŒ–è¶‹åŠ¿
ç”Ÿæˆä»Šå¤©çš„çƒ­ç‚¹æ‘˜è¦æŠ¥å‘Š
æœç´¢"æ¯”ç‰¹å¸"ç›¸å…³æ–°é—»å¹¶åˆ†ææƒ…æ„Ÿå€¾å‘
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Claude Code CLI&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼é…ç½®&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. å¯åŠ¨ HTTP æœåŠ¡
# Windows: start-http.bat
# Mac/Linux: ./start-http.sh

# 2. æ·»åŠ  MCP æœåŠ¡å™¨
claude mcp add --transport http trendradar http://localhost:3333/mcp

# 3. éªŒè¯è¿æ¥ï¼ˆç¡®ä¿æœåŠ¡å·²å¯åŠ¨ï¼‰
claude mcp list
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥è¯¢æ–°é—»
claude "æœç´¢ä»Šå¤©çŸ¥ä¹çš„çƒ­ç‚¹æ–°é—»ï¼Œå‰10æ¡"

# è¶‹åŠ¿åˆ†æ
claude "åˆ†æ'äººå·¥æ™ºèƒ½'è¿™ä¸ªè¯é¢˜æœ€è¿‘ä¸€å‘¨çš„çƒ­åº¦è¶‹åŠ¿"

# æ•°æ®å¯¹æ¯”
claude "å¯¹æ¯”çŸ¥ä¹å’Œå¾®åšå¹³å°å¯¹'æ¯”ç‰¹å¸'çš„å…³æ³¨åº¦"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ MCP Inspector&lt;/b&gt;ï¼ˆè°ƒè¯•å·¥å…·ï¼‰&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;MCP Inspector æ˜¯å®˜æ–¹è°ƒè¯•å·¥å…·ï¼Œç”¨äºæµ‹è¯• MCP è¿æ¥ï¼š&lt;/p&gt; 
 &lt;h4&gt;ä½¿ç”¨æ­¥éª¤&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ TrendRadar HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ MCP Inspector&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åœ¨æµè§ˆå™¨ä¸­è¿æ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æµ‹è¯• "Ping Server" åŠŸèƒ½éªŒè¯è¿æ¥&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥ "List Tools" æ˜¯å¦è¿”å› 13 ä¸ªå·¥å…·ï¼š 
     &lt;ul&gt; 
      &lt;li&gt;åŸºç¡€æŸ¥è¯¢ï¼šget_latest_news, get_news_by_date, get_trending_topics&lt;/li&gt; 
      &lt;li&gt;æ™ºèƒ½æ£€ç´¢ï¼šsearch_news, search_related_news_history&lt;/li&gt; 
      &lt;li&gt;é«˜çº§åˆ†æï¼šanalyze_topic_trend, analyze_data_insights, analyze_sentiment, find_similar_news, generate_summary_report&lt;/li&gt; 
      &lt;li&gt;ç³»ç»Ÿç®¡ç†ï¼šget_current_config, get_system_status, trigger_crawl&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ å…¶ä»–æ”¯æŒ MCP çš„å®¢æˆ·ç«¯&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ä»»ä½•æ”¯æŒ Model Context Protocol çš„å®¢æˆ·ç«¯éƒ½å¯ä»¥è¿æ¥ TrendRadarï¼š&lt;/p&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;æœåŠ¡åœ°å€&lt;/strong&gt;ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "url": "http://localhost:3333/mcp",
  "type": "http",
  "description": "æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;STDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "command": "uv",
  "args": [
    "--directory",
    "/path/to/TrendRadar",
    "run",
    "python",
    "-m",
    "mcp_server.server"
  ],
  "type": "stdio"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›¿æ¢ &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ä¸ºå®é™…é¡¹ç›®è·¯å¾„&lt;/li&gt; 
  &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åæ–œæ è½¬ä¹‰ï¼š&lt;code&gt;C:\\Users\\...&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;ç¡®ä¿å·²å®Œæˆé¡¹ç›®ä¾èµ–å®‰è£…ï¼ˆè¿è¡Œè¿‡ setup è„šæœ¬ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;â˜•é—®é¢˜ç­”ç–‘ä¸1å…ƒç‚¹èµ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¿ƒæ„åˆ°å°±è¡Œï¼Œæ”¶åˆ°çš„&lt;strong&gt;ç‚¹èµ&lt;/strong&gt;ç”¨äºæé«˜å¼€å‘è€…å¼€æºçš„ç§¯ææ€§ã€‚&lt;strong&gt;ç‚¹èµ&lt;/strong&gt;å·²æ”¶å½•äº&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;ï¼šé€‚åˆé’ˆå¯¹æ€§å¼ºçš„è§£ç­”ã€‚æé—®æ—¶è¯·æä¾›å®Œæ•´ä¿¡æ¯ï¼ˆæˆªå›¾ã€é”™è¯¯æ—¥å¿—ã€ç³»ç»Ÿç¯å¢ƒç­‰ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…¬ä¼—å·äº¤æµ&lt;/strong&gt;ï¼šé€‚åˆå¿«é€Ÿå’¨è¯¢ã€‚å»ºè®®ä¼˜å…ˆåœ¨ç›¸å…³æ–‡ç« ä¸‹çš„å…¬å…±ç•™è¨€åŒºäº¤æµï¼Œå¦‚ç§ä¿¡ï¼Œè¯·æ–‡æ˜ç¤¼è²Œç”¨è¯­ğŸ˜‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;å…¬ä¼—å·å…³æ³¨&lt;/th&gt; 
   &lt;th align="center"&gt;å¾®ä¿¡ç‚¹èµ&lt;/th&gt; 
   &lt;th align="center"&gt;æ”¯ä»˜å®ç‚¹èµ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/weixin.png" width="300" title="ç¡…åŸºèŒ¶æ°´é—´" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG" width="300" title="å¾®ä¿¡æ”¯ä»˜" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG" width="300" title="æ”¯ä»˜å®æ”¯ä»˜" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;å¸¸è§é—®é¢˜&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q1: HTTP æœåŠ¡æ— æ³•å¯åŠ¨ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;æ£€æŸ¥æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;ç¡®è®¤ç«¯å£ 3333 æœªè¢«å ç”¨ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
netstat -ano | findstr :3333

# Mac/Linux
lsof -i :3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æ£€æŸ¥é¡¹ç›®ä¾èµ–æ˜¯å¦å®‰è£…ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# é‡æ–°è¿è¡Œå®‰è£…è„šæœ¬
# Windows: setup-windows.bat æˆ–è€… setup-windows-en.bat
# Mac/Linux: ./setup-mac.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å°è¯•è‡ªå®šä¹‰ç«¯å£:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 33333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q2: å®¢æˆ·ç«¯æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆ&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ UV è·¯å¾„æ­£ç¡®ï¼ˆè¿è¡Œ &lt;code&gt;which uv&lt;/code&gt; æˆ– &lt;code&gt;where uv&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤é¡¹ç›®è·¯å¾„æ­£ç¡®ä¸”æ— ä¸­æ–‡å­—ç¬¦&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å®¢æˆ·ç«¯é”™è¯¯æ—¥å¿—&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤æœåŠ¡å·²å¯åŠ¨ï¼ˆè®¿é—® &lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é˜²ç«å¢™è®¾ç½®&lt;/li&gt; 
    &lt;li&gt;å°è¯•ä½¿ç”¨ 127.0.0.1 æ›¿ä»£ localhost&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€šç”¨æ£€æŸ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡å¯å®¢æˆ·ç«¯åº”ç”¨&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ MCP æœåŠ¡æ—¥å¿—&lt;/li&gt; 
    &lt;li&gt;ä½¿ç”¨ MCP Inspector æµ‹è¯•è¿æ¥&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q3: å·¥å…·è°ƒç”¨å¤±è´¥æˆ–è¿”å›é”™è¯¯ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;å¯èƒ½åŸå› &lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä¸å­˜åœ¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤å·²è¿è¡Œè¿‡çˆ¬è™«ï¼ˆæœ‰ output ç›®å½•æ•°æ®ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥æŸ¥è¯¢æ—¥æœŸèŒƒå›´æ˜¯å¦æœ‰æ•°æ®&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ output ç›®å½•çš„å¯ç”¨æ—¥æœŸ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å‚æ•°é”™è¯¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ£€æŸ¥æ—¥æœŸæ ¼å¼ï¼š&lt;code&gt;YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤å¹³å° ID æ­£ç¡®ï¼š&lt;code&gt;zhihu&lt;/code&gt;, &lt;code&gt;weibo&lt;/code&gt; ç­‰&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å·¥å…·æ–‡æ¡£ä¸­çš„å‚æ•°è¯´æ˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®é—®é¢˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/config.yaml&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/frequency_words.txt&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;é¡¹ç›®ç›¸å…³&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;4 ç¯‡æ–‡ç« &lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/KYEPfTPVzZNWFclZh4am_g"&gt;å¯åœ¨è¯¥æ–‡ç« ä¸‹æ–¹ç•™è¨€ï¼Œæ–¹ä¾¿é¡¹ç›®ä½œè€…ç”¨æ‰‹æœºç­”ç–‘&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/jzn0vLiQFX408opcfpPPxQ"&gt;2ä¸ªæœˆç ´ 1000 starï¼Œæˆ‘çš„GitHubé¡¹ç›®æ¨å¹¿å®æˆ˜ç»éªŒ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/C8evK-U7onG1sTTdwdW2zg"&gt;github fork è¿è¡Œæœ¬é¡¹ç›®çš„æ³¨æ„äº‹é¡¹ &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/8ghyfDAtQZjLrnWTQabYOQ"&gt;åŸºäºæœ¬é¡¹ç›®ï¼Œå¦‚ä½•å¼€å±•å…¬ä¼—å·æˆ–è€…æ–°é—»èµ„è®¯ç±»æ–‡ç« å†™ä½œ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;AI å¼€å‘&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;å¦‚æœä½ æœ‰å°ä¼—éœ€æ±‚ï¼Œå®Œå…¨å¯ä»¥åŸºäºæˆ‘çš„é¡¹ç›®è‡ªè¡Œå¼€å‘ï¼Œé›¶ç¼–ç¨‹åŸºç¡€çš„ä¹Ÿå¯ä»¥è¯•è¯•&lt;/li&gt; 
 &lt;li&gt;æˆ‘æ‰€æœ‰çš„å¼€æºé¡¹ç›®æˆ–å¤šæˆ–å°‘éƒ½ä½¿ç”¨äº†è‡ªå·±å†™çš„&lt;strong&gt;AIè¾…åŠ©è½¯ä»¶&lt;/strong&gt;æ¥æå‡å¼€å‘æ•ˆç‡ï¼Œè¿™æ¬¾å·¥å…·å·²å¼€æº&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼šè¿…é€Ÿç­›é€‰é¡¹ç›®ä»£ç å–‚ç»™AIï¼Œä½ åªéœ€è¦è¡¥å……ä¸ªäººéœ€æ±‚å³å¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®åœ°å€&lt;/strong&gt;ï¼š&lt;a href="https://github.com/sansan0/ai-code-context-helper"&gt;https://github.com/sansan0/ai-code-context-helper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å…¶ä½™é¡¹ç›®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ“ æ¯›ä¸»å¸­è¶³è¿¹åœ°å›¾ - äº¤äº’å¼åŠ¨æ€å±•ç¤º1893-1976å¹´å®Œæ•´è½¨è¿¹ã€‚æ¬¢è¿è¯¸ä½åŒå¿—è´¡çŒ®æ•°æ®&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/mao-map"&gt;https://github.com/sansan0/mao-map&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å“”å“©å“”å“©(bilibili)è¯„è®ºåŒºæ•°æ®å¯è§†åŒ–åˆ†æè½¯ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/bilibili-comment-analyzer"&gt;https://github.com/sansan0/bilibili-comment-analyzer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ å¾®ä¿¡æ¨é€é€šçŸ¥æ–¹æ¡ˆ&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ç”±äºè¯¥æ–¹æ¡ˆæ˜¯åŸºäºä¼ä¸šå¾®ä¿¡çš„æ’ä»¶æœºåˆ¶ï¼Œæ¨é€æ ·å¼ä¹Ÿååˆ†ä¸åŒï¼Œæ‰€ä»¥ç›¸å…³å®ç°æˆ‘æš‚æ—¶ä¸å‡†å¤‡çº³å…¥å½“å‰é¡¹ç›®&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;fork è¿™ä½å…„å°çš„é¡¹ç›® &lt;a href="https://github.com/jayzqj/TrendRadar"&gt;https://github.com/jayzqj/TrendRadar&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;å®Œæˆä¸Šæ–¹çš„ä¼ä¸šå¾®ä¿¡æ¨é€è®¾ç½®&lt;/li&gt; 
  &lt;li&gt;æŒ‰ç…§ä¸‹é¢å›¾ç‰‡æ“ä½œ&lt;/li&gt; 
  &lt;li&gt;é…ç½®å¥½åï¼Œæ‰‹æœºä¸Šçš„ä¼ä¸šå¾®ä¿¡ app åˆ é™¤æ‰ä¹Ÿæ²¡äº‹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/wework.png" title="github" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;æœ¬é¡¹ç›®æµç¨‹å›¾&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[ğŸ‘¤ ç”¨æˆ·å¼€å§‹] --&amp;gt; B{ğŸš€ é€‰æ‹©éƒ¨ç½²æ–¹å¼}
    
    B --&amp;gt;|äº‘ç«¯éƒ¨ç½²| C1[ğŸ´ Fork é¡¹ç›®åˆ° GitHub]
    B --&amp;gt;|æœ¬åœ°éƒ¨ç½²| C2[ğŸ³ Docker éƒ¨ç½²]
    
    C1 --&amp;gt; D[âš™ï¸ é…ç½®é€šçŸ¥æ¸ é“&amp;lt;br/&amp;gt;å¯åŒæ—¶é…ç½®å¤šä¸ª]
    C2 --&amp;gt; D
    
    D --&amp;gt; E[é€‰æ‹©é€šçŸ¥æ–¹å¼ï¼š&amp;lt;br/&amp;gt;ğŸ“±ä¼ä¸šå¾®ä¿¡ ğŸ’¬é£ä¹¦ ğŸ””é’‰é’‰&amp;lt;br/&amp;gt;ğŸ“ŸTelegram ğŸ“§é‚®ä»¶]
    
    E --&amp;gt; F[ğŸ”‘ å¡«å†™é€šçŸ¥å‚æ•°&amp;lt;br/&amp;gt;GitHub Secrets æˆ–ç¯å¢ƒå˜é‡]
    
    F --&amp;gt; G[ğŸ“ é…ç½®å…³é”®è¯&amp;lt;br/&amp;gt;config/frequency_words.txt&amp;lt;br/&amp;gt;æ™®é€šè¯/å¿…é¡»è¯+/è¿‡æ»¤è¯!]
    
    G --&amp;gt; H[ğŸ¯ é€‰æ‹©è¿è¡Œæ¨¡å¼&amp;lt;br/&amp;gt;config/config.yaml]
    
    H --&amp;gt; H1[ğŸ“‹ daily - å½“æ—¥æ±‡æ€»&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æ‰€æœ‰åŒ¹é…æ–°é—»]
    H --&amp;gt; H2[ğŸ“° current - å½“å‰æ¦œå•&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æœ€æ–°æ¦œå•]
    H --&amp;gt; H3[ğŸ“ˆ incremental - å¢é‡ç›‘æ§&amp;lt;br/&amp;gt;ä»…æ¨é€æ–°å¢å†…å®¹]
    
    H1 --&amp;gt; I[å¯é€‰ï¼šæ¨é€æ—¶é—´çª—å£æ§åˆ¶&amp;lt;br/&amp;gt;â° é™åˆ¶æ¨é€æ—¶é—´èŒƒå›´]
    H2 --&amp;gt; I
    H3 --&amp;gt; I
    
    I --&amp;gt; J[âœ… é…ç½®å®Œæˆ]
    
    J --&amp;gt; K[ğŸ¤– ç³»ç»Ÿè‡ªåŠ¨è¿è¡Œ]
    
    K --&amp;gt; L[ğŸ•·ï¸ çˆ¬å–11+å¹³å°çƒ­ç‚¹]
    L --&amp;gt; M[ğŸ” å…³é”®è¯ç­›é€‰]
    M --&amp;gt; N[âš–ï¸ æƒé‡ç®—æ³•æ’åº&amp;lt;br/&amp;gt;æ’å60% + é¢‘æ¬¡30% + çƒ­åº¦10%]
    N --&amp;gt; O[ğŸ“Š ç”ŸæˆæŠ¥å‘Š&amp;lt;br/&amp;gt;HTMLç½‘é¡µ + æ¨é€æ¶ˆæ¯]
    O --&amp;gt; P[ğŸ“± å¤šæ¸ é“æ¨é€é€šçŸ¥]
    
    P --&amp;gt; Q[ğŸ‰ æŒç»­æ¥æ”¶ç²¾å‡†æ¨é€&amp;lt;br/&amp;gt;å‘Šåˆ«ä¿¡æ¯è¿‡è½½]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style F fill:#fff9c4
    style G fill:#e8f5e9
    style H fill:#e0f2f1
    style I fill:#fce4ec
    style O fill:#e1bee7
    style Q fill:#c8e6c9
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#sansan0/TrendRadar&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sansan0/TrendRadar&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#trendradar"&gt;ğŸ” å›åˆ°é¡¶éƒ¨&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AtsushiSakai/PythonRobotics</title>
      <link>https://github.com/AtsushiSakai/PythonRobotics</link>
      <description>&lt;p&gt;Python sample codes and textbook for robotics algorithms.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true" align="right" width="300" alt="header pic" /&gt; 
&lt;h1&gt;PythonRobotics&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg?sanitize=true" alt="GitHub_Action_Linux_CI" /&gt; &lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg?sanitize=true" alt="GitHub_Action_MacOS_CI" /&gt; &lt;img src="https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg?sanitize=true" alt="GitHub_Action_Windows_CI" /&gt; &lt;a href="https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics"&gt;&lt;img src="https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true" alt="Build status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Python codes and &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;textbook&lt;/a&gt; for robotics algorithm.&lt;/p&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#what-is-this"&gt;What is this?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#how-to-use"&gt;How to use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#localization"&gt;Localization&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#extended-kalman-filter-localization"&gt;Extended Kalman Filter localization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#particle-filter-localization"&gt;Particle filter localization&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#histogram-filter-localization"&gt;Histogram filter localization&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#mapping"&gt;Mapping&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#gaussian-grid-map"&gt;Gaussian grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#ray-casting-grid-map"&gt;Ray casting grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lidar-to-grid-map"&gt;Lidar to grid map&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#k-means-object-clustering"&gt;k-means object clustering&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rectangle-fitting"&gt;Rectangle fitting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#slam"&gt;SLAM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#iterative-closest-point-icp-matching"&gt;Iterative Closest Point (ICP) Matching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#fastslam-10"&gt;FastSLAM 1.0&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#path-planning"&gt;Path Planning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#dynamic-window-approach"&gt;Dynamic Window Approach&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#grid-based-search"&gt;Grid based search&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#dijkstra-algorithm"&gt;Dijkstra algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#a-algorithm"&gt;A* algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#d-algorithm"&gt;D* algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#d-lite-algorithm"&gt;D* Lite algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#potential-field-algorithm"&gt;Potential Field algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#grid-based-coverage-path-planning"&gt;Grid based coverage path planning&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#particle-swarm-optimization-pso"&gt;Particle Swarm Optimization (PSO)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#state-lattice-planning"&gt;State Lattice Planning&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#biased-polar-sampling"&gt;Biased polar sampling&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lane-sampling"&gt;Lane sampling&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#probabilistic-road-map-prm-planning"&gt;Probabilistic Road-Map (PRM) planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rapidly-exploring-random-trees-rrt"&gt;Rapidly-Exploring Random Trees (RRT)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rrt"&gt;RRT*&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rrt-with-reeds-shepp-path"&gt;RRT* with reeds-shepp path&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lqr-rrt"&gt;LQR-RRT*&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#quintic-polynomials-planning"&gt;Quintic polynomials planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#reeds-shepp-planning"&gt;Reeds Shepp planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#lqr-based-path-planning"&gt;LQR based path planning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#optimal-trajectory-in-a-frenet-frame"&gt;Optimal Trajectory in a Frenet Frame&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#path-tracking"&gt;Path Tracking&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#move-to-a-pose-control"&gt;move to a pose control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#stanley-control"&gt;Stanley control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rear-wheel-feedback-control"&gt;Rear wheel feedback control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#linearquadratic-regulator-lqr-speed-and-steering-control"&gt;Linearâ€“quadratic regulator (LQR) speed and steering control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#model-predictive-speed-and-steering-control"&gt;Model predictive speed and steering control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#nonlinear-model-predictive-control-with-c-gmres"&gt;Nonlinear Model predictive control with C-GMRES&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#arm-navigation"&gt;Arm Navigation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#n-joint-arm-to-point-control"&gt;N joint arm to point control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#arm-navigation-with-obstacle-avoidance"&gt;Arm navigation with obstacle avoidance&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#aerial-navigation"&gt;Aerial Navigation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#drone-3d-trajectory-following"&gt;drone 3d trajectory following&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#rocket-powered-landing"&gt;rocket powered landing&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#bipedal"&gt;Bipedal&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#bipedal-planner-with-inverted-pendulum"&gt;bipedal planner with inverted pendulum&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#use-case"&gt;Use-case&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#citing"&gt;Citing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#sponsors"&gt;Sponsors&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#JetBrains"&gt;JetBrains&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#1password"&gt;1Password&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AtsushiSakai/PythonRobotics/master/#authors"&gt;Authors&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;What is PythonRobotics?&lt;/h1&gt; 
&lt;p&gt;PythonRobotics is a Python code collection and a &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;textbook&lt;/a&gt; of robotics algorithms.&lt;/p&gt; 
&lt;p&gt;Features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Easy to read for understanding each algorithm's basic idea.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Widely used and practical algorithms are selected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Minimum dependency.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See this documentation&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/0_getting_started/1_what_is_python_robotics.html"&gt;Getting Started â€” PythonRobotics documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or this Youtube video:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uMeRnNoJAfU"&gt;PythonRobotics project audio overview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;or this paper for more details:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1808.10703"&gt;[1808.10703] PythonRobotics: a Python code collection of robotics algorithms&lt;/a&gt; (&lt;a href="https://github.com/AtsushiSakai/PythonRoboticsPaper/raw/master/python_robotics.bib"&gt;BibTeX&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Requirements to run the code&lt;/h1&gt; 
&lt;p&gt;For running each sample code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.python.org/"&gt;Python 3.13.x&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://numpy.org/"&gt;NumPy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://scipy.org/"&gt;SciPy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.cvxpy.org/"&gt;cvxpy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pytest.org/"&gt;pytest&lt;/a&gt; (for unit tests)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pypi.org/project/pytest-xdist/"&gt;pytest-xdist&lt;/a&gt; (for parallel unit tests)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://mypy-lang.org/"&gt;mypy&lt;/a&gt; (for type check)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.sphinx-doc.org/"&gt;sphinx&lt;/a&gt; (for document generation)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pypi.org/project/pycodestyle/"&gt;pycodestyle&lt;/a&gt; (for code style check)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Documentation (Textbook)&lt;/h1&gt; 
&lt;p&gt;This README only shows some examples of this project.&lt;/p&gt; 
&lt;p&gt;If you are interested in other examples or mathematical backgrounds of each algorithm,&lt;/p&gt; 
&lt;p&gt;You can check the full documentation (textbook) online: &lt;a href="https://atsushisakai.github.io/PythonRobotics/index.html"&gt;Welcome to PythonRoboticsâ€™s documentation! â€” PythonRobotics documentation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;All animation gifs are stored here: &lt;a href="https://github.com/AtsushiSakai/PythonRoboticsGifs"&gt;AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;How to use&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone this repo.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;git clone https://github.com/AtsushiSakai/PythonRobotics.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the required libraries.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;using conda :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;conda env create -f requirements/environment.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;using pip :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-terminal"&gt;pip install -r requirements/requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;Execute python script in each directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add star to this repo if you like it &lt;span&gt;ğŸ˜ƒ&lt;/span&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Localization&lt;/h1&gt; 
&lt;h2&gt;Extended Kalman Filter localization&lt;/h2&gt; 
&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif" width="640" alt="EKF pic" /&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/2_localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Particle filter localization&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a sensor fusion localization with Particle Filter(PF).&lt;/p&gt; 
&lt;p&gt;The blue line is true trajectory, the black line is dead reckoning trajectory,&lt;/p&gt; 
&lt;p&gt;and the red line is an estimated trajectory with PF.&lt;/p&gt; 
&lt;p&gt;It is assumed that the robot can measure a distance from landmarks (RFID).&lt;/p&gt; 
&lt;p&gt;These measurements are used for PF localization.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Histogram filter localization&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a 2D localization example with Histogram filter.&lt;/p&gt; 
&lt;p&gt;The red cross is true position, black points are RFID positions.&lt;/p&gt; 
&lt;p&gt;The blue grid shows a position probability of histogram filter.&lt;/p&gt; 
&lt;p&gt;In this simulation, x,y are unknown, yaw is known.&lt;/p&gt; 
&lt;p&gt;The filter integrates speed input and range observations from RFID for localization.&lt;/p&gt; 
&lt;p&gt;Initial position is not needed.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Mapping&lt;/h1&gt; 
&lt;h2&gt;Gaussian grid map&lt;/h2&gt; 
&lt;p&gt;This is a 2D Gaussian grid mapping example.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Ray casting grid map&lt;/h2&gt; 
&lt;p&gt;This is a 2D ray casting grid mapping example.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Lidar to grid map&lt;/h2&gt; 
&lt;p&gt;This example shows how to convert a 2D range measurement to a grid map.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;k-means object clustering&lt;/h2&gt; 
&lt;p&gt;This is a 2D object clustering with k-means algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Rectangle fitting&lt;/h2&gt; 
&lt;p&gt;This is a 2D rectangle fitting for vehicle detection.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h1&gt;SLAM&lt;/h1&gt; 
&lt;p&gt;Simultaneous Localization and Mapping(SLAM) examples&lt;/p&gt; 
&lt;h2&gt;Iterative Closest Point (ICP) Matching&lt;/h2&gt; 
&lt;p&gt;This is a 2D ICP matching example with singular value decomposition.&lt;/p&gt; 
&lt;p&gt;It can calculate a rotation matrix, and a translation vector between points and points.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf"&gt;Introduction to Mobile Robotics: Iterative Closest Point Algorithm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FastSLAM 1.0&lt;/h2&gt; 
&lt;p&gt;This is a feature based SLAM example using FastSLAM 1.0.&lt;/p&gt; 
&lt;p&gt;The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.&lt;/p&gt; 
&lt;p&gt;The red points are particles of FastSLAM.&lt;/p&gt; 
&lt;p&gt;Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.probabilistic-robotics.org/"&gt;PROBABILISTIC ROBOTICS&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm"&gt;SLAM simulations by Tim Bailey&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Path Planning&lt;/h1&gt; 
&lt;h2&gt;Dynamic Window Approach&lt;/h2&gt; 
&lt;p&gt;This is a 2D navigation sample code with Dynamic Window Approach.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf"&gt;The Dynamic Window Approach to Collision Avoidance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;h2&gt;Grid based search&lt;/h2&gt; 
&lt;h3&gt;Dijkstra algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with Dijkstra's algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt; 
&lt;h3&gt;A* algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with A star algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, cyan points are searched nodes.&lt;/p&gt; 
&lt;p&gt;Its heuristic is 2D Euclid distance.&lt;/p&gt; 
&lt;h3&gt;D* algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based the shortest path planning with D star algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif" alt="figure at master Â· nirnayroy/intelligentrobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;The animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/D*"&gt;D* Algorithm Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;D* Lite algorithm&lt;/h3&gt; 
&lt;p&gt;This algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif" alt="D* Lite" /&gt;&lt;/p&gt; 
&lt;p&gt;The animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.&lt;/p&gt; 
&lt;p&gt;Refs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://idm-lab.org/bib/abstracts/papers/aaai02b.pdf"&gt;D* Lite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf"&gt;Improved Fast Replanning for Robot Navigation in Unknown Terrain&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Potential Field algorithm&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based path planning with Potential Field algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif" alt="PotentialField" /&gt;&lt;/p&gt; 
&lt;p&gt;In the animation, the blue heat map shows potential value on each grid.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf"&gt;Robotic Motion Planning:Potential Functions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Grid based coverage path planning&lt;/h3&gt; 
&lt;p&gt;This is a 2D grid based coverage path planning simulation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif" alt="PotentialField" /&gt;&lt;/p&gt; 
&lt;h3&gt;Particle Swarm Optimization (PSO)&lt;/h3&gt; 
&lt;p&gt;This is a 2D path planning simulation using the Particle Swarm Optimization algorithm.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ParticleSwarmOptimization/animation.gif" alt="PSO" /&gt;&lt;/p&gt; 
&lt;p&gt;PSO is a metaheuristic optimization algorithm inspired by bird flocking behavior. In path planning, particles explore the search space to find collision-free paths while avoiding obstacles.&lt;/p&gt; 
&lt;p&gt;The animation shows particles (blue dots) converging towards the optimal path (yellow line) from start (green area) to goal (red star).&lt;/p&gt; 
&lt;p&gt;References&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization"&gt;Particle swarm optimization - Wikipedia&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://ieeexplore.ieee.org/document/488968"&gt;Kennedy, J.; Eberhart, R. (1995). "Particle Swarm Optimization"&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;State Lattice Planning&lt;/h2&gt; 
&lt;p&gt;This script is a path planning code with state lattice planning.&lt;/p&gt; 
&lt;p&gt;This code uses the model predictive trajectory generator to solve boundary problem.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://journals.sagepub.com/doi/pdf/10.1177/0278364906075328"&gt;Optimal rough terrain trajectory generation for wheeled mobile robots&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.cs.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf"&gt;State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Biased polar sampling&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;h3&gt;Lane sampling&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;h2&gt;Probabilistic Road-Map (PRM) planning&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif" alt="PRM" /&gt;&lt;/p&gt; 
&lt;p&gt;This PRM planner uses Dijkstra method for graph search.&lt;/p&gt; 
&lt;p&gt;In the animation, blue points are sampled points,&lt;/p&gt; 
&lt;p&gt;Cyan crosses means searched points with Dijkstra method,&lt;/p&gt; 
&lt;p&gt;The red line is the final path of PRM.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Probabilistic_roadmap"&gt;Probabilistic roadmap - Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ã€€ã€€&lt;/p&gt; 
&lt;h2&gt;Rapidly-Exploring Random Trees (RRT)&lt;/h2&gt; 
&lt;h3&gt;RRT*&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;This is a path planning code with RRT*&lt;/p&gt; 
&lt;p&gt;Black circles are obstacles, green line is a searched tree, red crosses are start and goal positions.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://arxiv.org/abs/1005.0416"&gt;Incremental Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;amp;type=pdf&amp;amp;doi=bddbc99f97173430aa49a0ada53ab5bade5902fa"&gt;Sampling-based Algorithms for Optimal Motion Planning&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RRT* with reeds-shepp path&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif" alt="Robotics/animation.gif at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;Path planning for a car robot with RRT* and reeds shepp path planner.&lt;/p&gt; 
&lt;h3&gt;LQR-RRT*&lt;/h3&gt; 
&lt;p&gt;This is a path planning simulation with LQR-RRT*.&lt;/p&gt; 
&lt;p&gt;A double integrator motion model is used for LQR local planner.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif" alt="LQR_RRT" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://lis.csail.mit.edu/pubs/perez-icra12.pdf"&gt;LQR-RRT*: Optimal Sampling-Based Motion Planning with Automatically Derived Extension Heuristics&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/MahanFathi/LQR-RRTstar"&gt;MahanFathi/LQR-RRTstar: LQR-RRT* method is used for random motion planning of a simple pendulum in its phase plot&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quintic polynomials planning&lt;/h2&gt; 
&lt;p&gt;Motion planning with quintic polynomials.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;It can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ieeexplore.ieee.org/document/637936/"&gt;Local Path Planning And Motion Control For Agv In Positioning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reeds Shepp planning&lt;/h2&gt; 
&lt;p&gt;A sample code with Reeds Shepp path planning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true" alt="RSPlanning" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://planning.cs.uiuc.edu/node822.html"&gt;15.3.2 Reeds-Shepp Curves&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf"&gt;optimal paths for a car that goes both forwards and backwards&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ghliu/pyReedsShepp"&gt;ghliu/pyReedsShepp: Implementation of Reeds Shepp curve.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;LQR based path planning&lt;/h2&gt; 
&lt;p&gt;A sample code using LQR based path planning for double integrator model.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true" alt="RSPlanning" /&gt;&lt;/p&gt; 
&lt;h2&gt;Optimal Trajectory in a Frenet Frame&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;This is optimal trajectory generation in a Frenet Frame.&lt;/p&gt; 
&lt;p&gt;The cyan line is the target course and black crosses are obstacles.&lt;/p&gt; 
&lt;p&gt;The red line is the predicted path.&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf"&gt;Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Cj6tAQe7UCY"&gt;Optimal trajectory generation for dynamic street scenarios in a Frenet Frame&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Path Tracking&lt;/h1&gt; 
&lt;h2&gt;move to a pose control&lt;/h2&gt; 
&lt;p&gt;This is a simulation of moving to a pose control&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Control/move_to_pose/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://link.springer.com/book/10.1007/978-3-642-20144-8"&gt;P. I. Corke, "Robotics, Vision and Control" | SpringerLink p102&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stanley control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with Stanley steering control and PID speed control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif" alt="2" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://robots.stanford.edu/papers/thrun.stanley05.pdf"&gt;Stanley: The robot that won the DARPA grand challenge&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf"&gt;Automatic Steering Methods for Autonomous Automobile Path Tracking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Rear wheel feedback control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with rear wheel feedback steering control and PID speed control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif" alt="PythonRobotics/figure_1.png at master Â· AtsushiSakai/PythonRobotics" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1604.07446"&gt;A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Linearâ€“quadratic regulator (LQR) speed and steering control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with LQR speed and steering control.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ieeexplore.ieee.org/document/5940562/"&gt;Towards fully autonomous driving: Systems and algorithms - IEEE Conference Publication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model predictive speed and steering control&lt;/h2&gt; 
&lt;p&gt;Path tracking simulation with iterative linear model predictive speed and steering control.&lt;/p&gt; 
&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif" width="640" alt="MPC pic" /&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/6_path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html"&gt;documentation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://grauonline.de/wordpress/?page_id=3244"&gt;Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Nonlinear Model predictive control with C-GMRES&lt;/h2&gt; 
&lt;p&gt;A motion planning and path tracking simulation with NMPC of C-GMRES&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/6_path_tracking/cgmres_nmpc/cgmres_nmpc.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Arm Navigation&lt;/h1&gt; 
&lt;h2&gt;N joint arm to point control&lt;/h2&gt; 
&lt;p&gt;N joint arm to a point control simulation.&lt;/p&gt; 
&lt;p&gt;This is an interactive simulation.&lt;/p&gt; 
&lt;p&gt;You can set the goal position of the end effector with left-click on the plotting area.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;In this simulation N = 10, however, you can change it.&lt;/p&gt; 
&lt;h2&gt;Arm navigation with obstacle avoidance&lt;/h2&gt; 
&lt;p&gt;Arm navigation with obstacle avoidance simulation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h1&gt;Aerial Navigation&lt;/h1&gt; 
&lt;h2&gt;drone 3d trajectory following&lt;/h2&gt; 
&lt;p&gt;This is a 3d trajectory following simulation for a quadrotor.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h2&gt;rocket powered landing&lt;/h2&gt; 
&lt;p&gt;This is a 3d trajectory generation simulation for a rocket powered landing.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;p&gt;Reference&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/8_aerial_navigation/rocket_powered_landing/rocket_powered_landing.html"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Bipedal&lt;/h1&gt; 
&lt;h2&gt;bipedal planner with inverted pendulum&lt;/h2&gt; 
&lt;p&gt;This is a bipedal planner for modifying footsteps for an inverted pendulum.&lt;/p&gt; 
&lt;p&gt;You can set the footsteps, and the planner will modify those automatically.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif" alt="3" /&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;MIT&lt;/p&gt; 
&lt;h1&gt;Use-case&lt;/h1&gt; 
&lt;p&gt;If this project helps your robotics project, please let me know with creating an issue.&lt;/p&gt; 
&lt;p&gt;Your robot's video, which is using PythonRobotics, is very welcome!!&lt;/p&gt; 
&lt;p&gt;This is a list of user's comment and references:&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/raw/master/users_comments.md"&gt;users_comments&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contribution&lt;/h1&gt; 
&lt;p&gt;Any contribution is welcome!!&lt;/p&gt; 
&lt;p&gt;Please check this document:&lt;a href="https://atsushisakai.github.io/PythonRobotics/modules/0_getting_started/3_how_to_contribute.html"&gt;How To Contribute â€” PythonRobotics documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Citing&lt;/h1&gt; 
&lt;p&gt;If you use this project's code for your academic work, we encourage you to cite &lt;a href="https://arxiv.org/abs/1808.10703"&gt;our papers&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.&lt;/p&gt; 
&lt;h1&gt;&lt;a id="support"&gt;&lt;/a&gt;Supporting this project&lt;/h1&gt; 
&lt;p&gt;If you or your company would like to support this project, please consider:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/sponsors/AtsushiSakai"&gt;Sponsor @AtsushiSakai on GitHub Sponsors&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.patreon.com/myenigma"&gt;Become a backer or sponsor on Patreon&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.paypal.com/paypalme/myenigmapay/"&gt;One-time donation via PayPal&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you would like to support us in some other way, please contact with creating an issue.&lt;/p&gt; 
&lt;h2&gt;&lt;a id="sponsors"&gt;&lt;/a&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;&lt;a id="JetBrains"&gt;&lt;/a&gt;&lt;a href="https://www.jetbrains.com/"&gt;JetBrains&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;They are providing a free license of their IDEs for this OSS development.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/1Password/for-open-source"&gt;1Password&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;They are providing a free license of their 1Password team license for this OSS project.&lt;/p&gt; 
&lt;h1&gt;Authors&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors"&gt;Contributors to AtsushiSakai/PythonRobotics&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>localstack/localstack</title>
      <link>https://github.com/localstack/localstack</link>
      <description>&lt;p&gt;ğŸ’» A fully functional local AWS cloud stack. Develop and test your cloud &amp; Serverless apps offline&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;span&gt;âš¡&lt;/span&gt; We are thrilled to announce the release of &lt;a href="https://blog.localstack.cloud/localstack-for-aws-release-v-4-9-0/"&gt;LocalStack 4.9&lt;/a&gt; &lt;span&gt;âš¡&lt;/span&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/localstack/localstack/main/docs/localstack-readme-banner.svg?sanitize=true" alt="LocalStack - The Leading Platform for Local Cloud Development" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/localstack/localstack/actions/workflows/aws-main.yml?query=branch%3Amain"&gt;&lt;img alt="GitHub Actions" src="https://github.com/localstack/localstack/actions/workflows/aws-main.yml/badge.svg?branch=main" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/localstack/localstack?branch=main"&gt;&lt;img alt="Coverage Status" src="https://coveralls.io/repos/github/localstack/localstack/badge.svg?branch=main" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/localstack/"&gt;&lt;img alt="PyPI Version" src="https://img.shields.io/pypi/v/localstack?color=blue" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/localstack/localstack"&gt;&lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/localstack/localstack" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/localstack"&gt;&lt;img alt="PyPi downloads" src="https://static.pepy.tech/badge/localstack" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#backers"&gt;&lt;img alt="Backers on Open Collective" src="https://opencollective.com/localstack/backers/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#sponsors"&gt;&lt;img alt="Sponsors on Open Collective" src="https://opencollective.com/localstack/sponsors/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://img.shields.io/pypi/l/localstack.svg"&gt;&lt;img alt="PyPI License" src="https://img.shields.io/pypi/l/localstack.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/ruff"&gt;&lt;img alt="Ruff" src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/localstack.cloud"&gt;&lt;img alt="Bluesky" src="https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; LocalStack is a cloud software development framework to develop and test your AWS applications locally. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#overview"&gt;Overview&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#install"&gt;Install&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#quickstart"&gt;Quickstart&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#running"&gt;Run&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#usage"&gt;Usage&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#releases"&gt;Releases&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/#contributing"&gt;Contributing&lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.localstack.cloud" target="_blank"&gt;ğŸ“– Docs&lt;/a&gt; â€¢ &lt;a href="https://app.localstack.cloud" target="_blank"&gt;ğŸ’» Pro version&lt;/a&gt; â€¢ &lt;a href="https://docs.localstack.cloud/references/coverage/" target="_blank"&gt;â˜‘ï¸ LocalStack coverage&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://localstack.cloud"&gt;LocalStack&lt;/a&gt; is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.&lt;/p&gt; 
&lt;p&gt;LocalStack supports a growing number of AWS services, like AWS Lambda, S3, DynamoDB, Kinesis, SQS, SNS, and many more! The &lt;a href="https://localstack.cloud/pricing"&gt;Pro version of LocalStack&lt;/a&gt; supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our &lt;a href="https://docs.localstack.cloud/user-guide/aws/feature-coverage/"&gt;â˜‘ï¸ Feature Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;LocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack's &lt;a href="https://docs.localstack.cloud/user-guide/"&gt;User Guides&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;The quickest way to get started with LocalStack is by using the LocalStack CLI. It enables you to start and manage the LocalStack Docker container directly through your command line. Ensure that your machine has a functional &lt;a href="https://docs.docker.com/get-docker/"&gt;&lt;code&gt;docker&lt;/code&gt; environment&lt;/a&gt; installed before proceeding.&lt;/p&gt; 
&lt;h3&gt;Brew (macOS or Linux with Homebrew)&lt;/h3&gt; 
&lt;p&gt;Install the LocalStack CLI through our &lt;a href="https://github.com/localstack/homebrew-tap"&gt;official LocalStack Brew Tap&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install localstack/tap/localstack-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary download (macOS, Linux, Windows)&lt;/h3&gt; 
&lt;p&gt;If Brew is not installed on your machine, you can download the pre-built LocalStack CLI binary directly:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit &lt;a href="https://github.com/localstack/localstack-cli/releases/latest"&gt;localstack/localstack-cli&lt;/a&gt; and download the latest release for your platform.&lt;/li&gt; 
 &lt;li&gt;Extract the downloaded archive to a directory included in your &lt;code&gt;PATH&lt;/code&gt; variable: 
  &lt;ul&gt; 
   &lt;li&gt;For macOS/Linux, use the command: &lt;code&gt;sudo tar xvzf ~/Downloads/localstack-cli-*-darwin-*-onefile.tar.gz -C /usr/local/bin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;PyPI (macOS, Linux, Windows)&lt;/h3&gt; 
&lt;p&gt;LocalStack is developed using Python. To install the LocalStack CLI using &lt;code&gt;pip&lt;/code&gt;, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m pip install localstack
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;localstack-cli&lt;/code&gt; installation enables you to run the Docker image containing the LocalStack runtime. To interact with the local AWS services, you need to install the &lt;code&gt;awslocal&lt;/code&gt; CLI separately. For installation guidelines, refer to the &lt;a href="https://docs.localstack.cloud/user-guide/integrations/aws-cli/#localstack-aws-cli-awslocal"&gt;&lt;code&gt;awslocal&lt;/code&gt; documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Do not use &lt;code&gt;sudo&lt;/code&gt; or run as &lt;code&gt;root&lt;/code&gt; user. LocalStack must be installed and started entirely under a local non-root user. If you have problems with permissions in macOS High Sierra, install with &lt;code&gt;pip install --user localstack&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Start LocalStack inside a Docker container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; % localstack start -d

     __                     _______ __             __
    / /   ____  _________ _/ / ___// /_____ ______/ /__
   / /   / __ \/ ___/ __ `/ /\__ \/ __/ __ `/ ___/ //_/
  / /___/ /_/ / /__/ /_/ / /___/ / /_/ /_/ / /__/ ,&amp;lt;
 /_____/\____/\___/\__,_/_//____/\__/\__,_/\___/_/|_|

- LocalStack CLI: 4.9.0
- Profile: default
- App: https://app.localstack.cloud

[17:00:15] starting LocalStack in Docker mode ğŸ³               localstack.py:512
           preparing environment                               bootstrap.py:1322
           configuring container                               bootstrap.py:1330
           starting container                                  bootstrap.py:1340
[17:00:16] detaching                                           bootstrap.py:1344
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can query the status of respective services on LocalStack by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;% localstack status services
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Service                  â”ƒ Status      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ acm                      â”‚ âœ” available â”‚
â”‚ apigateway               â”‚ âœ” available â”‚
â”‚ cloudformation           â”‚ âœ” available â”‚
â”‚ cloudwatch               â”‚ âœ” available â”‚
â”‚ config                   â”‚ âœ” available â”‚
â”‚ dynamodb                 â”‚ âœ” available â”‚
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use SQS, a fully managed distributed message queuing service, on LocalStack, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;% awslocal sqs create-queue --queue-name sample-queue
{
    "QueueUrl": "http://sqs.us-east-1.localhost.localstack.cloud:4566/000000000000/sample-queue"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Learn more about &lt;a href="https://docs.localstack.cloud/references/coverage/"&gt;LocalStack AWS services&lt;/a&gt; and using them with LocalStack's &lt;code&gt;awslocal&lt;/code&gt; CLI.&lt;/p&gt; 
&lt;h2&gt;Running&lt;/h2&gt; 
&lt;p&gt;You can run LocalStack through the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#localstack-cli"&gt;LocalStack CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#docker-compose"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/installation/#helm"&gt;Helm&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To start using LocalStack, check out our &lt;a href="https://docs.localstack.cloud"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/references/configuration/"&gt;LocalStack Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/ci/"&gt;LocalStack in CI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/integrations/"&gt;LocalStack Integrations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/"&gt;LocalStack Tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/references/"&gt;Understanding LocalStack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/getting-started/faq/"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use LocalStack with a graphical user interface, you can use the following UI clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://app.localstack.cloud"&gt;LocalStack Web Application&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/localstack-desktop/"&gt;LocalStack Desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.localstack.cloud/user-guide/tools/localstack-docker-extension/"&gt;LocalStack Docker Extension&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://github.com/localstack/localstack/releases"&gt;GitHub releases&lt;/a&gt; to see the complete list of changes for each release. For extended release notes, please refer to the &lt;a href="https://docs.localstack.cloud/references/changelog/"&gt;changelog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you are interested in contributing to LocalStack:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start by reading our &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/development-environment-setup/README.md"&gt;development environment setup guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Navigate our codebase and &lt;a href="https://github.com/localstack/localstack/issues"&gt;open issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are thankful for all the contributions and feedback we receive.&lt;/p&gt; 
&lt;h2&gt;Get in touch&lt;/h2&gt; 
&lt;p&gt;Get in touch with the LocalStack Team to report ğŸ &lt;a href="https://github.com/localstack/localstack/issues/new/choose"&gt;issues&lt;/a&gt;, upvote ğŸ‘ &lt;a href="https://github.com/localstack/localstack/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+"&gt;feature requests&lt;/a&gt;, ğŸ™‹ğŸ½ ask &lt;a href="https://docs.localstack.cloud/getting-started/help-and-support/"&gt;support questions&lt;/a&gt;, or ğŸ—£ï¸ discuss local cloud development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localstack.cloud/slack/"&gt;LocalStack Slack Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/localstack/localstack/issues"&gt;LocalStack GitHub Issue tracker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;We are thankful to all the people who have contributed to this project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/localstack/localstack/graphs/contributors"&gt;&lt;img src="https://opencollective.com/localstack/contributors.svg?width=890" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Backers&lt;/h3&gt; 
&lt;p&gt;We are also grateful to all our backers who have donated to the project. You can become a backer on &lt;a href="https://opencollective.com/localstack#backer"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/localstack#backers" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/backers.svg?width=890" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Sponsors&lt;/h3&gt; 
&lt;p&gt;You can also support this project by becoming a sponsor on &lt;a href="https://opencollective.com/localstack#sponsor"&gt;Open Collective&lt;/a&gt;. Your logo will show up here along with a link to your website.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/localstack/sponsor/0/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/0/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/1/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/1/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/2/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/2/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/3/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/3/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/4/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/4/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/5/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/5/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/6/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/6/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/7/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/7/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/8/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/8/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/localstack/sponsor/9/website" target="_blank"&gt;&lt;img src="https://opencollective.com/localstack/sponsor/9/avatar.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2017-2025 LocalStack maintainers and contributors.&lt;/p&gt; 
&lt;p&gt;Copyright (c) 2016 Atlassian and others.&lt;/p&gt; 
&lt;p&gt;This version of LocalStack is released under the Apache License, Version 2.0 (see &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/LICENSE.txt"&gt;LICENSE&lt;/a&gt;). By downloading and using this software you agree to the &lt;a href="https://raw.githubusercontent.com/localstack/localstack/main/docs/end_user_license_agreement"&gt;End-User License Agreement (EULA)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser based workflows with AI&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; ğŸ‰ Automate Browser-based workflows using LLMs and Computer Vision ğŸ‰ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. âš ï¸&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;ğŸ” 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ğŸ” Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ” Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;ğŸ“• docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;â€‚ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;â€‚ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒŸ åŠ å…¥å®˜æ–¹äº¤æµç¾¤&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;height=200&amp;amp;section=header&amp;amp;text=æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµQQç¾¤ï¼&amp;amp;fontSize=40&amp;amp;fontAlignY=35&amp;amp;desc=æ‰«æä¸‹æ–¹äºŒç»´ç åŠ å…¥ç¾¤èŠ&amp;amp;descAlignY=55" alt="æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµQQç¾¤ï¼" style="width:60%; max-width:900px; display:block; margin:0 auto;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/QQ_Light_Horizenal.png" alt="BettaFish æŠ€æœ¯äº¤æµç¾¤äºŒç»´ç " style="width:60%; max-width:360px; display:block; margin:20px auto 0;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;âš¡ é¡¹ç›®æ¦‚è¿°&lt;/h2&gt; 
&lt;p&gt;â€œ&lt;strong&gt;å¾®èˆ†&lt;/strong&gt;â€ æ˜¯ä¸€ä¸ªä»0å®ç°çš„åˆ›æ–°å‹ å¤šæ™ºèƒ½ä½“ èˆ†æƒ…åˆ†æç³»ç»Ÿï¼Œå¸®åŠ©å¤§å®¶ç ´é™¤ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ã€‚ç”¨æˆ·åªéœ€åƒèŠå¤©ä¸€æ ·æå‡ºåˆ†æéœ€æ±‚ï¼Œæ™ºèƒ½ä½“å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ å›½å†…å¤–30+ä¸»æµç¤¾åª’ ä¸ æ•°ç™¾ä¸‡æ¡å¤§ä¼—è¯„è®ºã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â€œå¾®èˆ†â€è°éŸ³â€œå¾®é±¼â€ï¼ŒBettaFishæ˜¯ä¸€ç§ä½“å‹å¾ˆå°ä½†éå¸¸å¥½æ–—ã€æ¼‚äº®çš„é±¼ï¼Œå®ƒè±¡å¾ç€â€œå°è€Œå¼ºå¤§ï¼Œä¸ç•æŒ‘æˆ˜â€&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œç”Ÿæˆçš„ç ”ç©¶æŠ¥å‘Šï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œä¸€æ¬¡å®Œæ•´è¿è¡Œçš„è§†é¢‘ï¼š&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;è§†é¢‘-æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ä¸ä»…ä»…ä½“ç°åœ¨æŠ¥å‘Šè´¨é‡ä¸Šï¼Œç›¸æ¯”åŒç±»äº§å“ï¼Œæˆ‘ä»¬æ‹¥æœ‰ğŸš€å…­å¤§ä¼˜åŠ¿ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIé©±åŠ¨çš„å…¨åŸŸç›‘æ§&lt;/strong&gt;ï¼šAIçˆ¬è™«é›†ç¾¤7x24å°æ—¶ä¸é—´æ–­ä½œä¸šï¼Œå…¨é¢è¦†ç›–å¾®åšã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ç­‰10+å›½å†…å¤–å…³é”®ç¤¾åª’ã€‚ä¸ä»…å®æ—¶æ•è·çƒ­ç‚¹å†…å®¹ï¼Œæ›´èƒ½ä¸‹é’»è‡³æµ·é‡ç”¨æˆ·è¯„è®ºï¼Œè®©æ‚¨å¬åˆ°æœ€çœŸå®ã€æœ€å¹¿æ³›çš„å¤§ä¼—å£°éŸ³ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è¶…è¶ŠLLMçš„å¤åˆåˆ†æå¼•æ“&lt;/strong&gt;ï¼šæˆ‘ä»¬ä¸ä»…ä¾èµ–è®¾è®¡çš„5ç±»ä¸“ä¸šAgentï¼Œæ›´èåˆäº†å¾®è°ƒæ¨¡å‹ã€ç»Ÿè®¡æ¨¡å‹ç­‰ä¸­é—´ä»¶ã€‚é€šè¿‡å¤šæ¨¡å‹ååŒå·¥ä½œï¼Œç¡®ä¿äº†åˆ†æç»“æœçš„æ·±åº¦ã€å‡†åº¦ä¸å¤šç»´è§†è§’ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›&lt;/strong&gt;ï¼šçªç ´å›¾æ–‡é™åˆ¶ï¼Œèƒ½æ·±åº¦è§£ææŠ–éŸ³ã€å¿«æ‰‹ç­‰çŸ­è§†é¢‘å†…å®¹ï¼Œå¹¶ç²¾å‡†æå–ç°ä»£æœç´¢å¼•æ“ä¸­çš„å¤©æ°”ã€æ—¥å†ã€è‚¡ç¥¨ç­‰ç»“æ„åŒ–å¤šæ¨¡æ€ä¿¡æ¯å¡ç‰‡ï¼Œè®©æ‚¨å…¨é¢æŒæ¡èˆ†æƒ…åŠ¨æ€ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agentâ€œè®ºå›â€åä½œæœºåˆ¶&lt;/strong&gt;ï¼šä¸ºä¸åŒAgentèµ‹äºˆç‹¬ç‰¹çš„å·¥å…·é›†ä¸æ€ç»´æ¨¡å¼ï¼Œå¼•å…¥è¾©è®ºä¸»æŒäººæ¨¡å‹ï¼Œé€šè¿‡â€œè®ºå›â€æœºåˆ¶è¿›è¡Œé“¾å¼æ€ç»´ç¢°æ’ä¸è¾©è®ºã€‚è¿™ä¸ä»…é¿å…äº†å•ä¸€æ¨¡å‹çš„æ€ç»´å±€é™ä¸äº¤æµå¯¼è‡´çš„åŒè´¨åŒ–ï¼Œæ›´å‚¬ç”Ÿå‡ºæ›´é«˜è´¨é‡çš„é›†ä½“æ™ºèƒ½ä¸å†³ç­–æ”¯æŒã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å…¬ç§åŸŸæ•°æ®æ— ç¼èåˆ&lt;/strong&gt;ï¼šå¹³å°ä¸ä»…åˆ†æå…¬å¼€èˆ†æƒ…ï¼Œè¿˜æä¾›é«˜å®‰å…¨æ€§çš„æ¥å£ï¼Œæ”¯æŒæ‚¨å°†å†…éƒ¨ä¸šåŠ¡æ•°æ®åº“ä¸èˆ†æƒ…æ•°æ®æ— ç¼é›†æˆã€‚æ‰“é€šæ•°æ®å£å’ï¼Œä¸ºå‚ç›´ä¸šåŠ¡æä¾›â€œå¤–éƒ¨è¶‹åŠ¿+å†…éƒ¨æ´å¯Ÿâ€çš„å¼ºå¤§åˆ†æèƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è½»é‡åŒ–ä¸é«˜æ‰©å±•æ€§æ¡†æ¶&lt;/strong&gt;ï¼šåŸºäºçº¯Pythonæ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°è½»é‡åŒ–ã€ä¸€é”®å¼éƒ¨ç½²ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œå¼€å‘è€…å¯è½»æ¾é›†æˆè‡ªå®šä¹‰æ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘ï¼Œå®ç°å¹³å°çš„å¿«é€Ÿæ‰©å±•ä¸æ·±åº¦å®šåˆ¶ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;å§‹äºèˆ†æƒ…ï¼Œè€Œä¸æ­¢äºèˆ†æƒ…&lt;/strong&gt;ã€‚â€œå¾®èˆ†â€çš„ç›®æ ‡ï¼Œæ˜¯æˆä¸ºé©±åŠ¨ä¸€åˆ‡ä¸šåŠ¡åœºæ™¯çš„ç®€æ´é€šç”¨çš„æ•°æ®åˆ†æå¼•æ“ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸¾ä¸ªä¾‹å­. ä½ åªéœ€ç®€å•ä¿®æ”¹Agentå·¥å…·é›†çš„apiå‚æ•°ä¸promptï¼Œå°±å¯ä»¥æŠŠä»–å˜æˆä¸€ä¸ªé‡‘èé¢†åŸŸçš„å¸‚åœºåˆ†æç³»ç»Ÿ&lt;/p&gt; 
 &lt;p&gt;é™„ä¸€ä¸ªæ¯”è¾ƒæ´»è·ƒçš„Lç«™é¡¹ç›®è®¨è®ºå¸–ï¼š&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;æŸ¥çœ‹Lç«™ä½¬å‹åšçš„æµ‹è¯„ &lt;a href="https://linux.do/t/topic/1148040"&gt;å¼€æºé¡¹ç›®(å¾®èˆ†)ä¸manus|minimax|ChatGPTå¯¹æ¯”&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;å‘Šåˆ«ä¼ ç»Ÿçš„æ•°æ®çœ‹æ¿ï¼Œåœ¨â€œå¾®èˆ†â€ï¼Œä¸€åˆ‡ç”±ä¸€ä¸ªç®€å•çš„é—®é¢˜å¼€å§‹ï¼Œæ‚¨åªéœ€åƒå¯¹è¯ä¸€æ ·ï¼Œæå‡ºæ‚¨çš„åˆ†æéœ€æ±‚&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸª„ èµåŠ©å•†&lt;/h2&gt; 
&lt;p&gt;LLMæ¨¡å‹APIèµåŠ©ï¼š&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;(ç‚¹å¼€â–¶æœ‰èµåŠ©LLMç®—åŠ›ç¦åˆ©)ç¼–ç¨‹æ‹¼è½¦codecodex.aiï¼›ç¼–ç¨‹ç®—åŠ›VibeCodingAPI.aiï¼š&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ‰€ç½—é—¨åšå®¢LionCC.aiå·²æ›´æ–°ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿ - LionCC API éƒ¨ç½²é…ç½®å®Œå…¨æŒ‡å—ã€‹æ­£åœ¨äºŒå¼€ä¼˜åŒ–ä¸€é”®éƒ¨ç½²å’Œäº‘æœåŠ¡å™¨è°ƒç”¨æ–¹æ¡ˆã€‚&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiç‹®å­ç®—åŠ›å¹³å°å·²ç»é€‚é…ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿã€‹æ‰€æœ‰LLMæ¨¡å‹å«claude codeå’Œopenai codexå’Œgemini cliç¼–ç¨‹å¼€å‘ä¸‰å·¨å¤´ç®—åŠ›ã€‚é¢åº¦ä»·æ ¼ï¼Œåªè¦ä¸€æ¯”ä¸€ï¼ˆ100å…ƒç­‰äº100ç¾åˆ€é¢åº¦ï¼‰&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiç‹®å­ç¼–ç¨‹æ‹¼è½¦ç³»ç»Ÿï¼Œå·²å®ç°æ— IPé—¨æ§›ç»•è¿‡claude codeå’Œopenai codexå°é”ï¼ŒæŒ‰å®˜æ–¹éƒ¨ç½²æ•™ç¨‹ååˆ‡æ¢BASE_URLè°ƒç”¨åœ°å€å’ŒToken keyè°ƒç”¨å¯†é’¥å³å¯ä½¿ç”¨æœ€å¼ºç¼–ç¨‹æ¨¡å‹ã€‚&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ‰€ç½—é—¨LionCCèµåŠ©BettaFish å¾®èˆ†ç¦åˆ©ï¼šæ‰“å¼€codecodex.aiç‹®å­ç¼–ç¨‹é¢‘é“æ‰«ç åŠ å…¥å¾®ä¿¡ç¤¾ç¾¤ï¼Œæ³¨å†ŒVibeCodingapi.aiç‹®å­ç®—åŠ›ï¼Œç»Ÿä¸€é€20åˆ€APIé¢åº¦ï¼ˆä»…é™å‰ä¸€åƒåï¼‰&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;æŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šå…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§åœ¨çº¿AIåº”ç”¨ï¼š&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIæ˜¯ä¸€ä¸ªæŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šæœ€æ–°ã€æœ€å…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§å¼€ç®±å³ç”¨çš„åœ¨çº¿AIåº”ç”¨ã€‚ 
&lt;/details&gt; 
&lt;h2&gt;ğŸ—ï¸ ç³»ç»Ÿæ¶æ„&lt;/h2&gt; 
&lt;h3&gt;æ•´ä½“æ¶æ„å›¾&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ç§æœ‰æ•°æ®åº“æŒ–æ˜ï¼šç§æœ‰èˆ†æƒ…æ•°æ®åº“æ·±åº¦åˆ†æAIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; å¤šæ¨¡æ€å†…å®¹åˆ†æï¼šå…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; ç²¾å‡†ä¿¡æ¯æœç´¢ï¼šå…·å¤‡å›½å†…å¤–ç½‘é¡µæœç´¢èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆï¼šå†…ç½®æ¨¡æ¿çš„å¤šè½®æŠ¥å‘Šç”ŸæˆAIä»£ç†&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ä¸€æ¬¡å®Œæ•´åˆ†ææµç¨‹&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ­¥éª¤&lt;/th&gt; 
   &lt;th&gt;é˜¶æ®µåç§°&lt;/th&gt; 
   &lt;th&gt;ä¸»è¦æ“ä½œ&lt;/th&gt; 
   &lt;th&gt;å‚ä¸ç»„ä»¶&lt;/th&gt; 
   &lt;th&gt;å¾ªç¯ç‰¹æ€§&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;ç”¨æˆ·æé—®&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨æ¥æ”¶æŸ¥è¯¢&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;å¹¶è¡Œå¯åŠ¨&lt;/td&gt; 
   &lt;td&gt;ä¸‰ä¸ªAgentåŒæ—¶å¼€å§‹å·¥ä½œ&lt;/td&gt; 
   &lt;td&gt;Query Agentã€Media Agentã€Insight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;åˆæ­¥åˆ†æ&lt;/td&gt; 
   &lt;td&gt;å„Agentä½¿ç”¨ä¸“å±å·¥å…·è¿›è¡Œæ¦‚è§ˆæœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + ä¸“å±å·¥å…·é›†&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;ç­–ç•¥åˆ¶å®š&lt;/td&gt; 
   &lt;td&gt;åŸºäºåˆæ­¥ç»“æœåˆ¶å®šåˆ†å—ç ”ç©¶ç­–ç•¥&lt;/td&gt; 
   &lt;td&gt;å„Agentå†…éƒ¨å†³ç­–æ¨¡å—&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¾ªç¯é˜¶æ®µ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;è®ºå›åä½œ + æ·±åº¦ç ”ç©¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + æ‰€æœ‰Agent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¤šè½®å¾ªç¯&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;æ·±åº¦ç ”ç©¶&lt;/td&gt; 
   &lt;td&gt;å„AgentåŸºäºè®ºå›ä¸»æŒäººå¼•å¯¼è¿›è¡Œä¸“é¡¹æœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + åæ€æœºåˆ¶ + è®ºå›å¼•å¯¼&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;è®ºå›åä½œ&lt;/td&gt; 
   &lt;td&gt;ForumEngineç›‘æ§Agentå‘è¨€å¹¶ç”Ÿæˆä¸»æŒäººæ€»ç»“&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLMä¸»æŒäºº&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;äº¤æµèåˆ&lt;/td&gt; 
   &lt;td&gt;å„Agentæ ¹æ®è®¨è®ºè°ƒæ•´ç ”ç©¶æ–¹å‘&lt;/td&gt; 
   &lt;td&gt;å„Agent + forum_readerå·¥å…·&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ç»“æœæ•´åˆ&lt;/td&gt; 
   &lt;td&gt;Report Agentæ”¶é›†æ‰€æœ‰åˆ†æç»“æœå’Œè®ºå›å†…å®¹&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;æŠ¥å‘Šç”Ÿæˆ&lt;/td&gt; 
   &lt;td&gt;åŠ¨æ€é€‰æ‹©æ¨¡æ¿å’Œæ ·å¼ï¼Œå¤šè½®ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š&lt;/td&gt; 
   &lt;td&gt;Report Agent + æ¨¡æ¿å¼•æ“&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;é¡¹ç›®ä»£ç ç»“æ„æ ‘&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
â”œâ”€â”€ QueryEngine/                   # å›½å†…å¤–æ–°é—»å¹¿åº¦æœç´¢Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ MediaEngine/                   # å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ tools/                     # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ ...                        # å…¶ä»–æ¨¡å—
â”œâ”€â”€ InsightEngine/                 # ç§æœ‰æ•°æ®åº“æŒ–æ˜Agent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£å°è£…
â”‚   â”‚   â””â”€â”€ base.py                # ç»Ÿä¸€çš„ OpenAI å…¼å®¹å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ nodes/                     # å¤„ç†èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ base_node.py           # åŸºç¡€èŠ‚ç‚¹ç±»
â”‚   â”‚   â”œâ”€â”€ formatting_node.py     # æ ¼å¼åŒ–èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ report_structure_node.py # æŠ¥å‘Šç»“æ„èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ search_node.py         # æœç´¢èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ summary_node.py        # æ€»ç»“èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                     # æ•°æ®åº“æŸ¥è¯¢å’Œåˆ†æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ keyword_optimizer.py   # Qwenå…³é”®è¯ä¼˜åŒ–ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ search.py              # æ•°æ®åº“æ“ä½œå·¥å…·é›†
â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py  # æƒ…æ„Ÿåˆ†æé›†æˆå·¥å…·
â”‚   â”œâ”€â”€ state/                     # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ state.py               # AgentçŠ¶æ€å®šä¹‰
â”‚   â”œâ”€â”€ prompts/                   # æç¤ºè¯æ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ prompts.py             # å„ç±»æç¤ºè¯
â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚       â””â”€â”€ text_processing.py     # æ–‡æœ¬å¤„ç†å·¥å…·
â”œâ”€â”€ ReportEngine/                  # å¤šè½®æŠ¥å‘Šç”ŸæˆAgent
â”‚   â”œâ”€â”€ agent.py                   # Agentä¸»é€»è¾‘
â”‚   â”œâ”€â”€ llms/                      # LLMæ¥å£
â”‚   â”œâ”€â”€ nodes/                     # æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ template_selection.py  # æ¨¡æ¿é€‰æ‹©èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ html_generation.py     # HTMLç”ŸæˆèŠ‚ç‚¹
â”‚   â”œâ”€â”€ report_template/           # æŠ¥å‘Šæ¨¡æ¿åº“
â”‚   â”‚   â”œâ”€â”€ ç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†æ.md
â”‚   â”‚   â”œâ”€â”€ å•†ä¸šå“ç‰Œèˆ†æƒ…ç›‘æµ‹.md
â”‚   â”‚   â””â”€â”€ ...                    # æ›´å¤šæ¨¡æ¿
â”‚   â””â”€â”€ flask_interface.py         # Flask APIæ¥å£
â”œâ”€â”€ ForumEngine/                   # è®ºå›å¼•æ“ç®€æ˜“å®ç°
â”‚   â”œâ”€â”€ monitor.py                 # æ—¥å¿—ç›‘æ§å’Œè®ºå›ç®¡ç†
â”‚   â””â”€â”€ llm_host.py                # è®ºå›ä¸»æŒäººLLMæ¨¡å—
â”œâ”€â”€ MindSpider/                    # å¾®åšçˆ¬è™«ç³»ç»Ÿ
â”‚   â”œâ”€â”€ main.py                    # çˆ¬è™«ä¸»ç¨‹åº
â”‚   â”œâ”€â”€ config.py                  # çˆ¬è™«é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ BroadTopicExtraction/      # è¯é¢˜æå–æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ database_manager.py    # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ get_today_news.py      # ä»Šæ—¥æ–°é—»è·å–
â”‚   â”‚   â”œâ”€â”€ main.py                # è¯é¢˜æå–ä¸»ç¨‹åº
â”‚   â”‚   â””â”€â”€ topic_extractor.py     # è¯é¢˜æå–å™¨
â”‚   â”œâ”€â”€ DeepSentimentCrawling/     # æ·±åº¦èˆ†æƒ…çˆ¬å–
â”‚   â”‚   â”œâ”€â”€ keyword_manager.py     # å…³é”®è¯ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ main.py                # æ·±åº¦çˆ¬å–ä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ MediaCrawler/          # åª’ä½“çˆ¬è™«æ ¸å¿ƒ
â”‚   â”‚   â””â”€â”€ platform_crawler.py    # å¹³å°çˆ¬è™«ç®¡ç†
â”‚   â””â”€â”€ schema/                    # æ•°æ®åº“ç»“æ„
â”‚       â”œâ”€â”€ db_manager.py          # æ•°æ®åº“ç®¡ç†å™¨
â”‚       â”œâ”€â”€ init_database.py       # æ•°æ®åº“åˆå§‹åŒ–
â”‚       â””â”€â”€ mindspider_tables.sql  # æ•°æ®åº“è¡¨ç»“æ„
â”œâ”€â”€ SentimentAnalysisModel/        # æƒ…æ„Ÿåˆ†ææ¨¡å‹é›†åˆ
â”‚   â”œâ”€â”€ WeiboSentiment_Finetuned/  # å¾®è°ƒBERT/GPT-2æ¨¡å‹
â”‚   â”œâ”€â”€ WeiboMultilingualSentiment/# å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ WeiboSentiment_SmallQwen/  # å°å‚æ•°Qwen3å¾®è°ƒ
â”‚   â””â”€â”€ WeiboSentiment_MachineLearning/ # ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•
â”œâ”€â”€ SingleEngineApp/               # å•ç‹¬Agentçš„Streamlitåº”ç”¨
â”‚   â”œâ”€â”€ query_engine_streamlit_app.py
â”‚   â”œâ”€â”€ media_engine_streamlit_app.py
â”‚   â””â”€â”€ insight_engine_streamlit_app.py
â”œâ”€â”€ templates/                     # Flaskæ¨¡æ¿
â”‚   â””â”€â”€ index.html                 # ä¸»ç•Œé¢å‰ç«¯
â”œâ”€â”€ static/                        # é™æ€èµ„æº
â”œâ”€â”€ logs/                          # è¿è¡Œæ—¥å¿—ç›®å½•
â”œâ”€â”€ final_reports/                 # æœ€ç»ˆç”Ÿæˆçš„HTMLæŠ¥å‘Šæ–‡ä»¶
â”œâ”€â”€ utils/                         # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ forum_reader.py            # Agenté—´è®ºå›é€šä¿¡
â”‚   â””â”€â”€ retry_helper.py            # ç½‘ç»œè¯·æ±‚é‡è¯•æœºåˆ¶å·¥å…·
â”œâ”€â”€ app.py                         # Flaskä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                      # å…¨å±€é…ç½®æ–‡ä»¶
â””â”€â”€ requirements.txt               # Pythonä¾èµ–åŒ…æ¸…å•
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆDockerï¼‰&lt;/h2&gt; 
&lt;h3&gt;1. å¯åŠ¨é¡¹ç›®&lt;/h3&gt; 
&lt;p&gt;å¤åˆ¶ä¸€ä»½ &lt;code&gt;.env.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;.env&lt;/code&gt; ï¼Œå¹¶æŒ‰éœ€é…ç½® &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡&lt;/p&gt; 
&lt;p&gt;æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åœ¨åå°å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨ï¼šé•œåƒæ‹‰å–é€Ÿåº¦æ…¢&lt;/strong&gt;ï¼Œåœ¨åŸ &lt;code&gt;docker-compose.yml&lt;/code&gt; æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å·²ç»é€šè¿‡&lt;strong&gt;æ³¨é‡Š&lt;/strong&gt;çš„æ–¹å¼æä¾›äº†å¤‡ç”¨é•œåƒåœ°å€ä¾›æ‚¨æ›¿æ¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. é…ç½®è¯´æ˜&lt;/h3&gt; 
&lt;h4&gt;æ•°æ®åº“é…ç½®ï¼ˆPostgreSQLï¼‰&lt;/h4&gt; 
&lt;p&gt;è¯·æŒ‰ç…§ä»¥ä¸‹å‚æ•°é…ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œä¹Ÿæ”¯æŒMysqlå¯è‡ªè¡Œä¿®æ”¹ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;é…ç½®é¡¹&lt;/th&gt; 
   &lt;th align="left"&gt;å¡«å†™å€¼&lt;/th&gt; 
   &lt;th align="left"&gt;è¯´æ˜&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“æœåŠ¡åç§° (å¯¹åº” &lt;code&gt;docker-compose.yml&lt;/code&gt; ä¸­çš„æœåŠ¡å)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;é»˜è®¤ PostgreSQL ç«¯å£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“ç”¨æˆ·å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“å¯†ç &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“åç§°&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;å…¶ä»–&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ä¿æŒé»˜è®¤&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“è¿æ¥æ± ç­‰å…¶ä»–å‚æ•°è¯·ä¿æŒé»˜è®¤è®¾ç½®ã€‚&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;å¤§æ¨¡å‹é…ç½®&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æˆ‘ä»¬æ‰€æœ‰ LLM è°ƒç”¨ä½¿ç”¨ OpenAI çš„ API æ¥å£æ ‡å‡†&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;åœ¨å®Œæˆæ•°æ®åº“é…ç½®åï¼Œè¯·æ­£å¸¸é…ç½®&lt;strong&gt;æ‰€æœ‰å¤§æ¨¡å‹ç›¸å…³çš„å‚æ•°&lt;/strong&gt;ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿè¿æ¥åˆ°æ‚¨é€‰æ‹©çš„å¤§æ¨¡å‹æœåŠ¡ã€‚&lt;/p&gt; 
&lt;p&gt;å®Œæˆä¸Šè¿°æ‰€æœ‰é…ç½®å¹¶ä¿å­˜åï¼Œç³»ç»Ÿå³å¯æ­£å¸¸è¿è¡Œã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ”§ æºç å¯åŠ¨æŒ‡å—&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¦‚æœä½ æ˜¯åˆæ¬¡å­¦ä¹ ä¸€ä¸ªAgentç³»ç»Ÿçš„æ­å»ºï¼Œå¯ä»¥ä»ä¸€ä¸ªéå¸¸ç®€å•çš„demoå¼€å§‹ï¼š&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ç¯å¢ƒè¦æ±‚&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ“ä½œç³»ç»Ÿ&lt;/strong&gt;: Windowsã€Linuxã€MacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pythonç‰ˆæœ¬&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: Anacondaæˆ–Miniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®åº“&lt;/strong&gt;: PostgreSQLï¼ˆæ¨èï¼‰æˆ–MySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å†…å­˜&lt;/strong&gt;: å»ºè®®2GBä»¥ä¸Š&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. åˆ›å»ºç¯å¢ƒ&lt;/h3&gt; 
&lt;h4&gt;å¦‚æœä½¿ç”¨Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºcondaç¯å¢ƒ
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;å¦‚æœä½¿ç”¨uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºuvç¯å¢ƒ
uv venv --python 3.11 # åˆ›å»º3.11ç¯å¢ƒ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. å®‰è£…ä¾èµ–åŒ…&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åŸºç¡€ä¾èµ–å®‰è£…
pip install -r requirements.txt

# uvç‰ˆæœ¬å‘½ä»¤ï¼ˆæ›´å¿«é€Ÿå®‰è£…ï¼‰
uv pip install -r requirements.txt
# å¦‚æœä¸æƒ³ä½¿ç”¨æœ¬åœ°æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆç®—åŠ›éœ€æ±‚å¾ˆå°ï¼Œé»˜è®¤å®‰è£…cpuç‰ˆæœ¬ï¼‰ï¼Œå¯ä»¥å°†è¯¥æ–‡ä»¶ä¸­çš„â€œæœºå™¨å­¦ä¹ â€éƒ¨åˆ†æ³¨é‡Šæ‰å†æ‰§è¡ŒæŒ‡ä»¤
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. å®‰è£…Playwrightæµè§ˆå™¨é©±åŠ¨&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å®‰è£…æµè§ˆå™¨é©±åŠ¨ï¼ˆç”¨äºçˆ¬è™«åŠŸèƒ½ï¼‰
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. é…ç½®LLMä¸æ•°æ®åº“&lt;/h3&gt; 
&lt;p&gt;å¤åˆ¶ä¸€ä»½é¡¹ç›®æ ¹ç›®å½• &lt;code&gt;.env.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ç¼–è¾‘ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥ï¼ˆæ‚¨ä¹Ÿå¯ä»¥é€‰æ‹©è‡ªå·±çš„æ¨¡å‹ã€æœç´¢ä»£ç†ï¼Œè¯¦æƒ…è§æ ¹ç›®å½•.env.exampleæ–‡ä»¶å†…æˆ–æ ¹ç›®å½•config.pyä¸­çš„è¯´æ˜ï¼‰ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== æ•°æ®åº“é…ç½® ======================
# æ•°æ®åº“ä¸»æœºï¼Œä¾‹å¦‚localhost æˆ– 127.0.0.1
DB_HOST=your_db_host
# æ•°æ®åº“ç«¯å£å·ï¼Œé»˜è®¤ä¸º3306
DB_PORT=3306
# æ•°æ®åº“ç”¨æˆ·å
DB_USER=your_db_user
# æ•°æ®åº“å¯†ç 
DB_PASSWORD=your_db_password
# æ•°æ®åº“åç§°
DB_NAME=your_db_name
# æ•°æ®åº“å­—ç¬¦é›†ï¼Œæ¨èutf8mb4ï¼Œå…¼å®¹emoji
DB_CHARSET=utf8mb4
# æ•°æ®åº“ç±»å‹postgresqlæˆ–mysql
DB_DIALECT=postgresql
# æ•°æ®åº“ä¸éœ€è¦åˆå§‹åŒ–ï¼Œæ‰§è¡Œapp.pyæ—¶ä¼šè‡ªåŠ¨æ£€æµ‹

# ====================== LLMé…ç½® ======================
# æ‚¨å¯ä»¥æ›´æ”¹æ¯ä¸ªéƒ¨åˆ†LLMä½¿ç”¨çš„APIï¼Œåªè¦å…¼å®¹OpenAIè¯·æ±‚æ ¼å¼éƒ½å¯ä»¥

# Insight Agent
INSIGHT_ENGINE_API_KEY=
# Insight Agent LLMæ¥å£BaseUrlï¼Œå¯è‡ªå®šä¹‰å‚å•†API
INSIGHT_ENGINE_BASE_URL=
# Insight Agent LLMæ¨¡å‹åç§°ï¼Œå¦‚kimi-k2-0711-preview
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ¨èLLM APIä¾›åº”å•†ï¼š&lt;a href="https://aihubmix.com/?aff=8Ds9"&gt;æ¨ç†æ—¶ä»£&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;5. å¯åŠ¨ç³»ç»Ÿ&lt;/h3&gt; 
&lt;h4&gt;5.1 å®Œæ•´ç³»ç»Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»condaç¯å¢ƒ
conda activate your_conda_name

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ç‰ˆæœ¬å¯åŠ¨å‘½ä»¤&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»uvç¯å¢ƒ
.venv\Scripts\activate

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨1ï¼šä¸€æ¬¡è¿è¡Œç»ˆæ­¢åï¼Œstreamlit appå¯èƒ½ç»“æŸå¼‚å¸¸ä»ç„¶å ç”¨ç«¯å£ï¼Œæ­¤æ—¶æœç´¢å ç”¨ç«¯å£çš„è¿›ç¨‹killæ‰å³å¯&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨2ï¼šæ•°æ®çˆ¬å–éœ€è¦å•ç‹¬æ“ä½œï¼Œè§5.3æŒ‡å¼•&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨3ï¼šå¦‚æœæœåŠ¡å™¨è¿œç¨‹éƒ¨ç½²å‡ºç°é¡µé¢æ˜¾ç¤ºé—®é¢˜ï¼Œè§&lt;a href="https://github.com/666ghj/BettaFish/pull/45"&gt;PR#45&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;è®¿é—® &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; å³å¯ä½¿ç”¨å®Œæ•´ç³»ç»Ÿ&lt;/p&gt; 
&lt;h4&gt;5.2 å•ç‹¬å¯åŠ¨æŸä¸ªAgent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å¯åŠ¨QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# å¯åŠ¨MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# å¯åŠ¨InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5.3 çˆ¬è™«ç³»ç»Ÿå•ç‹¬ä½¿ç”¨&lt;/h4&gt; 
&lt;p&gt;è¿™éƒ¨åˆ†æœ‰è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpiderä½¿ç”¨è¯´æ˜&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider è¿è¡Œç¤ºä¾‹&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# è¿›å…¥çˆ¬è™«ç›®å½•
cd MindSpider

# é¡¹ç›®åˆå§‹åŒ–
python main.py --setup

# è¿è¡Œè¯é¢˜æå–ï¼ˆè·å–çƒ­ç‚¹æ–°é—»å’Œå…³é”®è¯ï¼‰
python main.py --broad-topic

# è¿è¡Œå®Œæ•´çˆ¬è™«æµç¨‹
python main.py --complete --date 2024-01-20

# ä»…è¿è¡Œè¯é¢˜æå–
python main.py --broad-topic --date 2024-01-20

# ä»…è¿è¡Œæ·±åº¦çˆ¬å–
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;âš™ï¸ é«˜çº§é…ç½®ï¼ˆå·²è¿‡æ—¶ï¼Œå·²ç»ç»Ÿä¸€ä¸ºé¡¹ç›®æ ¹ç›®å½•.envæ–‡ä»¶ç®¡ç†ï¼Œå…¶ä»–å­agentè‡ªåŠ¨ç»§æ‰¿æ ¹ç›®å½•é…ç½®ï¼‰&lt;/h2&gt; 
&lt;h3&gt;ä¿®æ”¹å…³é”®å‚æ•°&lt;/h3&gt; 
&lt;h4&gt;Agenté…ç½®å‚æ•°&lt;/h4&gt; 
&lt;p&gt;æ¯ä¸ªAgentéƒ½æœ‰ä¸“é—¨çš„é…ç½®æ–‡ä»¶ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œä¸‹é¢æ˜¯éƒ¨åˆ†ç¤ºä¾‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # åæ€è½®æ¬¡
    max_search_results = 15       # æœ€å¤§æœç´¢ç»“æœæ•°
    max_content_length = 8000     # æœ€å¤§å†…å®¹é•¿åº¦
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ç»¼åˆæœç´¢é™åˆ¶
    web_search_limit = 15           # ç½‘é¡µæœç´¢é™åˆ¶
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # å…¨å±€æœç´¢é™åˆ¶
    default_get_comments_limit = 500             # è¯„è®ºè·å–é™åˆ¶
    max_search_results_for_llm = 50              # ä¼ ç»™LLMçš„æœ€å¤§ç»“æœæ•°
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æƒ…æ„Ÿåˆ†ææ¨¡å‹é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # å¯é€‰: 'bert', 'multilingual', 'qwen'ç­‰
    'confidence_threshold': 0.8,      # ç½®ä¿¡åº¦é˜ˆå€¼
    'batch_size': 32,                 # æ‰¹å¤„ç†å¤§å°
    'max_sequence_length': 512,       # æœ€å¤§åºåˆ—é•¿åº¦
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥ä¸åŒçš„LLMæ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒä»»æ„openAIè°ƒç”¨æ ¼å¼çš„LLMæä¾›å•†ï¼Œåªéœ€è¦åœ¨/config.pyä¸­å¡«å†™å¯¹åº”çš„KEYã€BASE_URLã€MODEL_NAMEå³å¯ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä»€ä¹ˆæ˜¯openAIè°ƒç”¨æ ¼å¼ï¼Ÿä¸‹é¢æä¾›ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "æ¨ç†æ¨¡å‹ä¼šç»™å¸‚åœºå¸¦æ¥å“ªäº›æ–°çš„æœºä¼š"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;æ›´æ”¹æƒ…æ„Ÿåˆ†ææ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;ç³»ç»Ÿé›†æˆäº†å¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•ï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š&lt;/p&gt; 
&lt;h4&gt;1. å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. å°å‚æ•°Qwen3å¾®è°ƒ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "è¿™æ¬¡æ´»åŠ¨åŠå¾—å¾ˆæˆåŠŸ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. åŸºäºBERTçš„å¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ä½¿ç”¨BERTä¸­æ–‡æ¨¡å‹
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "è¿™ä¸ªäº§å“çœŸçš„å¾ˆä¸é”™"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAå¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "æœåŠ¡æ€åº¦éœ€è¦æ”¹è¿›"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“&lt;/h3&gt; 
&lt;h4&gt;1. ä¿®æ”¹æ•°æ®åº“è¿æ¥é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ä¸­æ·»åŠ æ‚¨çš„ä¸šåŠ¡æ•°æ®åº“é…ç½®
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. åˆ›å»ºè‡ªå®šä¹‰æ•°æ®è®¿é—®å·¥å…·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“æŸ¥è¯¢å·¥å…·"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """æŸ¥è¯¢ä¸šåŠ¡æ•°æ®"""
        # å®ç°æ‚¨çš„ä¸šåŠ¡é€»è¾‘
        pass
    
    def get_customer_feedback(self, product_id: str):
        """è·å–å®¢æˆ·åé¦ˆæ•°æ®"""
        # å®ç°å®¢æˆ·åé¦ˆæŸ¥è¯¢é€»è¾‘
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. é›†æˆåˆ°InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ä¸­é›†æˆè‡ªå®šä¹‰å·¥å…·
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... å…¶ä»–åˆå§‹åŒ–ä»£ç 
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """æ‰§è¡Œè‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®æœç´¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿&lt;/h3&gt; 
&lt;h4&gt;1. åœ¨Webç•Œé¢ä¸­ä¸Šä¼ &lt;/h4&gt; 
&lt;p&gt;ç³»ç»Ÿæ”¯æŒä¸Šä¼ è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶ï¼ˆ.mdæˆ–.txtæ ¼å¼ï¼‰ï¼Œå¯åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶é€‰æ‹©ä½¿ç”¨ã€‚&lt;/p&gt; 
&lt;h4&gt;2. åˆ›å»ºæ¨¡æ¿æ–‡ä»¶&lt;/h4&gt; 
&lt;p&gt;åœ¨ &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡æ¿ï¼Œæˆ‘ä»¬çš„Agentä¼šè‡ªè¡Œé€‰ç”¨æœ€åˆé€‚çš„æ¨¡æ¿ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ è´¡çŒ®æŒ‡å—&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯·é˜…è¯»ä»¥ä¸‹è´¡çŒ®æŒ‡å—ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¦– ä¸‹ä¸€æ­¥å¼€å‘è®¡åˆ’&lt;/h2&gt; 
&lt;p&gt;ç°åœ¨ç³»ç»Ÿåªå®Œæˆäº†"ä¸‰æ¿æ–§"ä¸­çš„å‰ä¸¤æ­¥ï¼Œå³ï¼šè¾“å…¥è¦æ±‚-&amp;gt;è¯¦ç»†åˆ†æï¼Œè¿˜ç¼ºå°‘ä¸€æ­¥é¢„æµ‹ï¼Œç›´æ¥å°†ä»–ç»§ç»­äº¤ç»™LLMæ˜¯ä¸å…·æœ‰è¯´æœåŠ›çš„ã€‚&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ç›®å‰æˆ‘ä»¬ç»è¿‡å¾ˆé•¿ä¸€æ®µæ—¶é—´çš„çˆ¬å–æ”¶é›†ï¼Œæ‹¥æœ‰äº†å¤§é‡å…¨ç½‘è¯é¢˜çƒ­åº¦éšæ—¶é—´ã€çˆ†ç‚¹ç­‰çš„å˜åŒ–è¶‹åŠ¿çƒ­åº¦æ•°æ®ï¼Œå·²ç»å…·å¤‡äº†å¯ä»¥å¼€å‘é¢„æµ‹æ¨¡å‹çš„æ¡ä»¶ã€‚æˆ‘ä»¬å›¢é˜Ÿå°†è¿ç”¨æ—¶åºæ¨¡å‹ã€å›¾ç¥ç»ç½‘ç»œã€å¤šæ¨¡æ€èåˆç­‰é¢„æµ‹æ¨¡å‹æŠ€æœ¯å‚¨å¤‡äºæ­¤ï¼Œå®ç°çœŸæ­£åŸºäºæ•°æ®é©±åŠ¨çš„èˆ†æƒ…é¢„æµ‹åŠŸèƒ½ã€‚&lt;/p&gt; 
&lt;h2&gt;âš ï¸ å…è´£å£°æ˜&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;é‡è¦æé†’ï¼šæœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆè§„æ€§å£°æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®ä¸­çš„æ‰€æœ‰ä»£ç ã€å·¥å…·å’ŒåŠŸèƒ½å‡ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•å•†ä¸šç”¨é€”æˆ–ç›ˆåˆ©æ€§æ´»åŠ¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•è¿æ³•ã€è¿è§„æˆ–ä¾µçŠ¯ä»–äººæƒç›Šçš„è¡Œä¸º&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;çˆ¬è™«åŠŸèƒ½å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®ä¸­çš„çˆ¬è™«åŠŸèƒ½ä»…ç”¨äºæŠ€æœ¯å­¦ä¹ å’Œç ”ç©¶ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›®æ ‡ç½‘ç«™çš„robots.txtåè®®å’Œä½¿ç”¨æ¡æ¬¾&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸å¾—è¿›è¡Œæ¶æ„çˆ¬å–æˆ–æ•°æ®æ»¥ç”¨&lt;/li&gt; 
   &lt;li&gt;å› ä½¿ç”¨çˆ¬è™«åŠŸèƒ½äº§ç”Ÿçš„ä»»ä½•æ³•å¾‹åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä½¿ç”¨å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®æ¶‰åŠçš„æ•°æ®åˆ†æåŠŸèƒ½ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†åˆ†æç»“æœç”¨äºå•†ä¸šå†³ç­–æˆ–ç›ˆåˆ©ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿æ‰€åˆ†ææ•°æ®çš„åˆæ³•æ€§å’Œåˆè§„æ€§&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŠ€æœ¯å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®æŒ‰"ç°çŠ¶"æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯&lt;/li&gt; 
   &lt;li&gt;ä½œè€…ä¸å¯¹ä½¿ç”¨æœ¬é¡¹ç›®é€ æˆçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”è‡ªè¡Œè¯„ä¼°é¡¹ç›®çš„é€‚ç”¨æ€§å’Œé£é™©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è´£ä»»é™åˆ¶&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰åº”å……åˆ†äº†è§£ç›¸å…³æ³•å¾‹æ³•è§„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿å…¶ä½¿ç”¨è¡Œä¸ºç¬¦åˆå½“åœ°æ³•å¾‹æ³•è§„è¦æ±‚&lt;/li&gt; 
   &lt;li&gt;å› è¿åæ³•å¾‹æ³•è§„ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;è¯·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰ä»”ç»†é˜…è¯»å¹¶ç†è§£ä¸Šè¿°å…è´£å£°æ˜ã€‚ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²åŒæ„å¹¶æ¥å—ä¸Šè¿°æ‰€æœ‰æ¡æ¬¾ã€‚&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®é‡‡ç”¨ &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0è®¸å¯è¯&lt;/a&gt;ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…LICENSEæ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ‰ æ”¯æŒä¸è”ç³»&lt;/h2&gt; 
&lt;h3&gt;è·å–å¸®åŠ©&lt;/h3&gt; 
&lt;p&gt;å¸¸è§é—®é¢˜è§£ç­”ï¼š&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®ä¸»é¡µ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHubä»“åº“&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é—®é¢˜åé¦ˆ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;Issuesé¡µé¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;åŠŸèƒ½å»ºè®®&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;Discussionsé¡µé¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;è”ç³»æ–¹å¼&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“§ &lt;strong&gt;é‚®ç®±&lt;/strong&gt;ï¼š&lt;a href="mailto:hangjiang@bupt.edu.cn"&gt;hangjiang@bupt.edu.cn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å•†åŠ¡åˆä½œ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼ä¸šå®šåˆ¶å¼€å‘&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§æ•°æ®æœåŠ¡&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å­¦æœ¯åˆä½œ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŠ€æœ¯åŸ¹è®­&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ è´¡çŒ®è€…&lt;/h2&gt; 
&lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è´¡çŒ®è€…ä»¬ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; Â· &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; Â· &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-â¤ï¸-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; ğŸŒ Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;PortuguÃªs&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;ä¸­æ–‡&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.&lt;/p&gt; 
&lt;p&gt;You can use Cognee in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.cognee.ai/getting-started/installation"&gt;Self-host Cognee Open Source&lt;/a&gt;, which stores all data locally by default.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.cognee.ai/"&gt;Connect to Cognee Cloud&lt;/a&gt;, and get the same OSS stack on managed infrastructure for easier development and productionization.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cognee Open Source (self-hosted):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data â€” including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cognee Cloud (managed):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hosted web UI dashboard&lt;/li&gt; 
 &lt;li&gt;Automatic version updates&lt;/li&gt; 
 &lt;li&gt;Resource usage analytics&lt;/li&gt; 
 &lt;li&gt;GDPR compliant, enterprise-grade security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Letâ€™s try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        print(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>kvcache-ai/ktransformers</title>
      <link>https://github.com/kvcache-ai/ktransformers</link>
      <description>&lt;p&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="KTransformers" src="https://github.com/user-attachments/assets/d5a2492f-a415-4456-af99-4ab102f13f8b" width="50%" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; 
 &lt;h3&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference/Fine-tune Optimizations&lt;/h3&gt; 
 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-overview"&gt;ğŸ¯ Overview&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-kernel---high-performance-inference-kernels"&gt;ğŸš€ kt-kernel&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-sft---fine-tuning-framework"&gt;ğŸ“ KT-SFT&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-citation"&gt;ğŸ”¥ Citation&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;ğŸ’¬ Discussion&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/issues/1582"&gt;ğŸš€ Roadmap(2025Q4)&lt;/a&gt; &lt;/strong&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ¯ Overview&lt;/h2&gt; 
&lt;p&gt;KTransformers is a research project focused on efficient inference and fine-tuning of large language models through CPU-GPU heterogeneous computing. The project has evolved into &lt;strong&gt;two core modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ”¥ Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 6, 2025&lt;/strong&gt;: Support Kimi-K2-Thinking inference (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2-Thinking.md"&gt;Tutorial&lt;/a&gt;) and fine-tune (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SFT_Installation_Guide_KimiK2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 4, 2025&lt;/strong&gt;: KTransformers Fine-Tuning Ã— LLaMA-Factory Integration. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/KTransformers-Fine-Tuning_User-Guide.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 27, 2025&lt;/strong&gt;: Support Ascend NPU. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/zh/DeepseekR1_V3_tutorial_zh_for_Ascend_NPU.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 10, 2025&lt;/strong&gt;: Integrating into SGLang. (&lt;a href="https://github.com/sgl-project/sglang/issues/11425"&gt;Roadmap&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2025-10-22-KTransformers/"&gt;Blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 11, 2025&lt;/strong&gt;: Support Qwen3-Next. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Qwen3-Next.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 05, 2025&lt;/strong&gt;: Support Kimi-K2-0905. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 26, 2025&lt;/strong&gt;: Support SmallThinker and GLM4-MoE. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SmallThinker_and_Glm4moe.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 11, 2025&lt;/strong&gt;: Support Kimi-K2. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 30, 2025&lt;/strong&gt;: Support 3-layer (GPU-CPU-Disk) &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/prefix_cache.md"&gt;prefix cache&lt;/a&gt; reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;May 14, 2025&lt;/strong&gt;: Support Intel Arc GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/xpu.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 29, 2025&lt;/strong&gt;: Support AMX-Int8ã€ AMX-BF16 and Qwen3MoE (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/AMX.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 9, 2025&lt;/strong&gt;: Experimental support for LLaMA 4 models (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/llama4.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 2, 2025&lt;/strong&gt;: Support Multi-concurrency. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/balance-serve.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 15, 2025&lt;/strong&gt;: Support ROCm on AMD GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/ROCm.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 5, 2025&lt;/strong&gt;: Support unsloth 1.58/2.51 bits weights and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;IQ1_S/FP8 hybrid&lt;/a&gt; weights. Support 139K &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022--v023-longer-context--fp8-kernel"&gt;Longer Context&lt;/a&gt; for DeepSeek-V3 and R1 in 24GB VRAM.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 25, 2025&lt;/strong&gt;: Support &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;FP8 GPU kernel&lt;/a&gt; for DeepSeek-V3 and R1; &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022-longer-context"&gt;Longer Context&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 15, 2025&lt;/strong&gt;: Longer Context (from 4K to 8K for 24GB VRAM) &amp;amp; Slightly Faster Speed ï¼ˆ+15%, up to 16 Tokens/s), update &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;docs&lt;/a&gt; and &lt;a href="https://kvcache-ai.github.io/ktransformers/"&gt;online books&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 10, 2025&lt;/strong&gt;: Support Deepseek-R1 and V3 on single (24GB VRAM)/multi gpu and 382G DRAM, up to 3~28x speedup. For detailed show case and reproduction tutorial, see &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 28, 2024&lt;/strong&gt;: Decrease DeepseekV2's required VRAM from 21G to 11G.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 15, 2024&lt;/strong&gt;: Update detailed &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/injection_tutorial.md"&gt;tutorial&lt;/a&gt; for injection and multi-GPU.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 14, 2024&lt;/strong&gt;: Support llamfile as linear backend.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 12, 2024&lt;/strong&gt;: Support multiple GPU; Support new model: mixtral 8*7B and 8*22B; Support q2k, q3k, q5k dequant on gpu.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 9, 2024&lt;/strong&gt;: Support windows native.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“¦ Core Modules&lt;/h2&gt; 
&lt;h3&gt;ğŸš€ &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; - High-Performance Inference Kernels&lt;/h3&gt; 
&lt;p&gt;CPU-optimized kernel operations for heterogeneous LLM inference.&lt;/p&gt; 
&lt;img width="1049" height="593" alt="image" src="https://github.com/user-attachments/assets/68f423da-3f55-4025-bdc9-9ceaa554f00b" /&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AMX/AVX Acceleration&lt;/strong&gt;: Intel AMX and AVX512/AVX2 optimized kernels for INT4/INT8 quantized inference&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MoE Optimization&lt;/strong&gt;: Efficient Mixture-of-Experts inference with NUMA-aware memory management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quantization Support&lt;/strong&gt;: CPU-side INT4/INT8 quantized weights, GPU-side GPTQ support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Integration&lt;/strong&gt;: Clean Python API for SGLang and other frameworks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd kt-kernel
pip install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU-GPU hybrid inference for large MoE models&lt;/li&gt; 
 &lt;li&gt;Integration with SGLang for production serving&lt;/li&gt; 
 &lt;li&gt;Heterogeneous expert placement (hot experts on GPU, cold experts on CPU)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Hardware Configuration&lt;/th&gt; 
   &lt;th&gt;Total Throughput&lt;/th&gt; 
   &lt;th&gt;Output Throughput&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1-0528 (FP8)&lt;/td&gt; 
   &lt;td&gt;8Ã—L20 GPU + Xeon Gold 6454S&lt;/td&gt; 
   &lt;td&gt;227.85 tokens/s&lt;/td&gt; 
   &lt;td&gt;87.58 tokens/s (8-way concurrency)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;ğŸ‘‰ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/README.md"&gt;Full Documentation â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ“ &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt; - Fine-Tuning Framework&lt;/h3&gt; 
&lt;p&gt;KTransformers Ã— LLaMA-Factory integration for ultra-large MoE model fine-tuning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/assets/image-20251011010558909.png" alt="image-20251011010558909" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Resource Efficient&lt;/strong&gt;: Fine-tune 671B DeepSeek-V3 with just &lt;strong&gt;70GB GPU memory&lt;/strong&gt; + 1.3TB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LoRA Support&lt;/strong&gt;: Full LoRA fine-tuning with heterogeneous acceleration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLaMA-Factory Integration&lt;/strong&gt;: Seamless integration with popular fine-tuning framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Ready&lt;/strong&gt;: Chat, batch inference, and metrics evaluation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Configuration&lt;/th&gt; 
   &lt;th&gt;Throughput&lt;/th&gt; 
   &lt;th&gt;GPU Memory&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V3 (671B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~40 tokens/s&lt;/td&gt; 
   &lt;td&gt;70GB (multi-GPU)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V2-Lite (14B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~530 tokens/s&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd KT-SFT
# Install environment following KT-SFT/README.md
USE_KT=1 llamafactory-cli train examples/train_lora/deepseek3_lora_sft_kt.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ğŸ‘‰ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/README.md"&gt;Full Documentation â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”¥ Citation&lt;/h2&gt; 
&lt;p&gt;If you use KTransformers in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{10.1145/3731569.3764843,
  title = {KTransformers: Unleashing the Full Potential of CPU/GPU Hybrid Inference for MoE Models},
  author = {Chen, Hongtao and Xie, Weiyu and Zhang, Boxin and Tang, Jingqi and Wang, Jiahao and Dong, Jianwei and Chen, Shaoyuan and Yuan, Ziwei and Lin, Chen and Qiu, Chengyu and Zhu, Yuening and Ou, Qingliang and Liao, Jiaqi and Chen, Xianglin and Ai, Zhiyuan and Wu, Yongwei and Zhang, Mingxing},
  booktitle = {Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
  year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ‘¥ Contributors &amp;amp; Team&lt;/h2&gt; 
&lt;p&gt;Developed and maintained by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://madsys.cs.tsinghua.edu.cn/"&gt;MADSys Lab&lt;/a&gt; @ Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://approaching.ai/"&gt;Approaching.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community contributors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We welcome contributions! Please feel free to submit issues and pull requests.&lt;/p&gt; 
&lt;h2&gt;ğŸ’¬ Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;Ask questions and share ideas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Group&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/WeChatGroup.png"&gt;archive/WeChatGroup.png&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ KT original Code&lt;/h2&gt; 
&lt;p&gt;The original integrated KTransformers framework has been archived to the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/"&gt;&lt;code&gt;archive/&lt;/code&gt;&lt;/a&gt; directory for reference. The project now focuses on the two core modules above for better modularity and maintainability.&lt;/p&gt; 
&lt;p&gt;For the original documentation with full quick-start guides and examples, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README.md"&gt;archive/README.md&lt;/a&gt; (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README_ZH.md"&gt;archive/README_ZH.md&lt;/a&gt; (ä¸­æ–‡)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;Open-source AI agents for penetration testing&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¦‰ Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developerâ€‘first&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Autoâ€‘fix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¯ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ† Enterprise Platform&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ˆ Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§  Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš™ï¸ CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”Œ Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo â†’&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ› ï¸ Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¯ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ•¸ï¸ Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’» Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Default Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Black-Box Web application assessment
strix --target https://your-app.com

# Grey-Box Security Assesment
strix --target https://your-app.com --instruction "Perform authenticated testing using the following credentials user:pass"

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ¤– Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flagâ€”perfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”„ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;âš™ï¸ Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://openai.com/api/"&gt;OpenAI's GPT-5&lt;/a&gt; (&lt;code&gt;openai/gpt-5&lt;/code&gt;) and &lt;a href="https://claude.com/platform/api"&gt;Anthropic's Claude Sonnet 4.5&lt;/a&gt; (&lt;code&gt;anthropic/claude-sonnet-4-5&lt;/code&gt;) work best with Strix, but we support many &lt;a href="https://docs.litellm.ai/docs/providers"&gt;other options&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a â­ on GitHub!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test apps you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>coleam00/ottomator-agents</title>
      <link>https://github.com/coleam00/ottomator-agents</link>
      <description>&lt;p&gt;All the open source AI Agents hosted on the oTTomator Live Agent Studio platform!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What is the Live Agent Studio?&lt;/h1&gt; 
&lt;p&gt;The &lt;a href="https://studio.ottomator.ai"&gt;Live Agent Studio&lt;/a&gt; is a community-driven platform developed by &lt;a href="https://ottomator.ai"&gt;oTTomator&lt;/a&gt; for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.&lt;/p&gt; 
&lt;p&gt;The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that youâ€™ll want to use the agents just for the sake of what they can do for you!&lt;/p&gt; 
&lt;p&gt;This platform is still in beta â€“ expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medinâ€™s YouTube channel!&lt;/p&gt; 
&lt;h1&gt;What is this Repository for?&lt;/h1&gt; 
&lt;p&gt;This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!&lt;/p&gt; 
&lt;h2&gt;Tokens&lt;/h2&gt; 
&lt;p&gt;Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/pricing"&gt;Purchase Tokens&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Future Plans&lt;/h2&gt; 
&lt;p&gt;As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, itâ€™ll be featured through agents on the platform. Itâ€™s a tall order, but we have big plans for the oTTomator community, and weâ€™re confident we can grow to accomplish this!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I want to build an agent to showcase in the Live Agent Studio! How do I do that?&lt;/h3&gt; 
&lt;p&gt;Head on over here to learn how to build an agent for the platform:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://studio.ottomator.ai/guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-n8n-agent~"&gt;the sample n8n agent&lt;/a&gt; for a starting point of building an n8n agent for the Live Agent Studio, and &lt;a href="https://raw.githubusercontent.com/coleam00/ottomator-agents/main/~sample-python-agent~"&gt;the sample Python agent&lt;/a&gt; for Python.&lt;/p&gt; 
&lt;h3&gt;How many tokens does it cost to use an agent?&lt;/h3&gt; 
&lt;p&gt;Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.&lt;/p&gt; 
&lt;h3&gt;Where can I go to talk about all these agents and get help implementing them myself?&lt;/h3&gt; 
&lt;p&gt;Head on over to our Think Tank community and feel free to make a post!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://thinktank.ottomator.ai"&gt;Think Tank Community&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Â© 2024 Live Agent Studio. All rights reserved.&lt;br /&gt; Created by oTTomator&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>droidrun/droidrun</title>
      <link>https://github.com/droidrun/droidrun</link>
      <description>&lt;p&gt;Automate your mobile devices with natural language commands - an LLM agnostic mobile Agent ğŸ¤–&lt;/p&gt;&lt;hr&gt;&lt;picture align="center"&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./static/droidrun-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="./static/droidrun.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/droidrun/droidrun/main/static/droidrun.png" width="full" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-%F0%9F%93%95-0D9373?style=for-the-badge" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://cloud.droidrun.ai/sign-in?waitlist=true"&gt;&lt;img src="https://img.shields.io/badge/Cloud-%E2%98%81%EF%B8%8F-0D9373?style=for-the-badge" alt="Cloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/droidrun/droidrun/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/droidrun/droidrun?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/droidrun.ai-white" alt="droidrun.ai" /&gt;&lt;/a&gt; &lt;a href="https://x.com/droid_run"&gt;&lt;img src="https://img.shields.io/twitter/follow/droid_run?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZZbKEZZkwK"&gt;&lt;img src="https://img.shields.io/discord/1360219330318696488?color=white&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai/benchmark"&gt;&lt;img src="https://img.shields.io/badge/Benchmark-91.4%EF%B9%AA-white" alt="Benchmark" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1753948032207" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" /&gt; 
  &lt;a href="https://www.producthunt.com/products/droidrun-framework-for-mobile-agent?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-droidrun" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" alt="Droidrun - Give AI native control of physical &amp;amp; virtual phones. | Product Hunt" style="width: 200px; height: 54px;" width="200" height="54" /&gt;&lt;/a&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://zdoc.app/de/droidrun/droidrun"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/droidrun/droidrun"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/droidrun/droidrun"&gt;franÃ§ais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/droidrun/droidrun"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/droidrun/droidrun"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/droidrun/droidrun"&gt;PortuguÃªs&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/droidrun/droidrun"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/droidrun/droidrun"&gt;ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;DroidRun is a powerful framework for controlling Android and iOS devices through LLM agents. It allows you to automate device interactions using natural language commands. &lt;a href="https://droidrun.ai/benchmark"&gt;Checkout our benchmark results&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Droidrun?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤– Control Android and iOS devices with natural language commands&lt;/li&gt; 
 &lt;li&gt;ğŸ”€ Supports multiple LLM providers (OpenAI, Anthropic, Gemini, Ollama, DeepSeek)&lt;/li&gt; 
 &lt;li&gt;ğŸ§  Planning capabilities for complex multi-step tasks&lt;/li&gt; 
 &lt;li&gt;ğŸ’» Easy to use CLI with enhanced debugging features&lt;/li&gt; 
 &lt;li&gt;ğŸ Extendable Python API for custom automations&lt;/li&gt; 
 &lt;li&gt;ğŸ“¸ Screenshot analysis for visual understanding of the device&lt;/li&gt; 
 &lt;li&gt;ğŸ«† Execution tracing with Arize Phoenix&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'droidrun[google,anthropic,openai,deepseek,ollama,dev]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ Quickstart&lt;/h2&gt; 
&lt;p&gt;Read on how to get droidrun up and running within seconds in &lt;a href="https://docs.droidrun.ai/v3/quickstart"&gt;our docs&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4WT7FXJah2I"&gt;&lt;img src="https://img.youtube.com/vi/4WT7FXJah2I/0.jpg" alt="Quickstart Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ¬ Demo Videos&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accommodation booking&lt;/strong&gt;: Let Droidrun search for an apartment for you&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/VUpCyq1PSXw"&gt;&lt;img src="https://img.youtube.com/vi/VUpCyq1PSXw/0.jpg" alt="Droidrun Accommodation Booking Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Trend Hunter&lt;/strong&gt;: Let Droidrun hunt down trending posts&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/7V8S2f8PnkQ"&gt;&lt;img src="https://img.youtube.com/vi/7V8S2f8PnkQ/0.jpg" alt="Droidrun Trend Hunter Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streak Saver&lt;/strong&gt;: Let Droidrun save your streak on your favorite language learning app&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/B5q2B467HKw"&gt;&lt;img src="https://img.youtube.com/vi/B5q2B467HKw/0.jpg" alt="Droidrun Streak Saver Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ’¡ Example Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automated UI testing of mobile applications&lt;/li&gt; 
 &lt;li&gt;Creating guided workflows for non-technical users&lt;/li&gt; 
 &lt;li&gt;Automating repetitive tasks on mobile devices&lt;/li&gt; 
 &lt;li&gt;Remote assistance for less technical users&lt;/li&gt; 
 &lt;li&gt;Exploring mobile UI with natural language commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; 
&lt;h2&gt;Security Checks&lt;/h2&gt; 
&lt;p&gt;To ensure the security of the codebase, we have integrated security checks using &lt;code&gt;bandit&lt;/code&gt; and &lt;code&gt;safety&lt;/code&gt;. These tools help identify potential security issues in the code and dependencies.&lt;/p&gt; 
&lt;h3&gt;Running Security Checks&lt;/h3&gt; 
&lt;p&gt;Before submitting any code, please run the following security checks:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bandit&lt;/strong&gt;: A tool to find common security issues in Python code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;bandit -r droidrun
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safety&lt;/strong&gt;: A tool to check your installed dependencies for known security vulnerabilities.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;safety scan
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>GeeeekExplorer/nano-vllm</title>
      <link>https://github.com/GeeeekExplorer/nano-vllm</link>
      <description>&lt;p&gt;Nano vLLM&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="300" src="https://raw.githubusercontent.com/GeeeekExplorer/nano-vllm/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15323" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Nano-vLLM&lt;/h1&gt; 
&lt;p&gt;A lightweight vLLM implementation built from scratch.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Fast offline inference&lt;/strong&gt; - Comparable inference speeds to vLLM&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Readable codebase&lt;/strong&gt; - Clean implementation in ~ 1,200 lines of Python code&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Optimization Suite&lt;/strong&gt; - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Download&lt;/h2&gt; 
&lt;p&gt;To download the model weights manually, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;example.py&lt;/code&gt; for usage. The API mirrors vLLM's interface with minor differences in the &lt;code&gt;LLM.generate&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;bench.py&lt;/code&gt; for benchmark.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: RTX 4070 Laptop (8GB)&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Results:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Inference Engine&lt;/th&gt; 
   &lt;th&gt;Output Tokens&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Throughput (tokens/s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;98.37&lt;/td&gt; 
   &lt;td&gt;1361.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nano-vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;93.41&lt;/td&gt; 
   &lt;td&gt;1434.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#GeeeekExplorer/nano-vllm&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thinking-machines-lab/tinker-cookbook</title>
      <link>https://github.com/thinking-machines-lab/tinker-cookbook</link>
      <description>&lt;p&gt;Post-training with Tinker&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Tinker Cookbook&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/assets/tinker-cover.png" width="60%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;We provide two libraries for the broader community to customize their language models: &lt;code&gt;tinker&lt;/code&gt; and &lt;code&gt;tinker-cookbook&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tinker&lt;/code&gt; is a training SDK for researchers and developers to fine-tune language models. You send API requests to us and we handle the complexities of distributed training.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tinker-cookbook&lt;/code&gt; includes realistic examples of fine-tuning language models. It builds on the Tinker API and provides common abstractions to fine-tune language models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign up for Tinker through the &lt;a href="https://thinkingmachines.ai/tinker"&gt;waitlist&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Once you have access, create an API key from the &lt;a href="https://tinker-console.thinkingmachines.ai"&gt;console&lt;/a&gt; and export it as environment variable &lt;code&gt;TINKER_API_KEY&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install tinker python client via &lt;code&gt;pip install tinker&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;We recommend installing &lt;code&gt;tinker-cookbook&lt;/code&gt; in a virtual env either with &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;uv&lt;/code&gt;. For running most examples, you can install via &lt;code&gt;pip install -e .&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Tinker&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://tinker-docs.thinkingmachines.ai/training-sampling"&gt;docs&lt;/a&gt; to start from basics. Here we introduce a few Tinker primitives - the basic components to fine-tune LLMs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;service_client = tinker.ServiceClient()
training_client = service_client.create_lora_training_client(
  base_model="meta-llama/Llama-3.2-1B", rank=32,
)
training_client.forward_backward(...)
training_client.optim_step(...)
training_client.save_state(...)
training_client.load_state(...)

sampling_client = training_client.save_weights_and_get_sampling_client(name="my_model")
sampling_client.sample(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_loop.py"&gt;tinker_cookbook/recipes/sl_loop.py&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_loop.py"&gt;tinker_cookbook/recipes/rl_loop.py&lt;/a&gt; for minimal examples of using these primitives to fine-tune LLMs.&lt;/p&gt; 
&lt;p&gt;To download the weights of any model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;rest_client = service_client.create_rest_client()
future = rest_client.download_checkpoint_archive_from_tinker_path(sampling_client.model_path)
with open(f"model-checkpoint.tar.gz", "wb") as f:
    f.write(future.result())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tinker Cookbook&lt;/h3&gt; 
&lt;p&gt;Besides these primitives, we also offer &lt;strong&gt;Tinker Cookbook&lt;/strong&gt; (a.k.a. this repo), a library of a wide range of abstractions to help you customize training environments. &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/sl_basic.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/rl_basic.py&lt;/code&gt;&lt;/a&gt; contain minimal examples to configure supervised learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;We also include a wide range of more sophisticated examples in the &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/"&gt;&lt;code&gt;tinker_cookbook/recipes/&lt;/code&gt;&lt;/a&gt; folder:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/chat_sl/"&gt;Chat supervised learning&lt;/a&gt;&lt;/strong&gt;: supervised fine-tuning on conversational datasets like Tulu3.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/math_rl/"&gt;Math reasoning&lt;/a&gt;&lt;/strong&gt;: improve LLM reasoning capability by rewarding it for answering math questions correctly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/preference/"&gt;Preference learning&lt;/a&gt;&lt;/strong&gt;: showcase a three-stage RLHF pipeline: 1) supervised fine-tuning, 2) learning a reward model, 3) RL against the reward model.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/tool_use/"&gt;Tool use&lt;/a&gt;&lt;/strong&gt;: train LLMs to better use retrieval tools to answer questions more accurately.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/prompt_distillation/"&gt;Prompt distillation&lt;/a&gt;&lt;/strong&gt;: internalize long and complex instructions into LLMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/multiplayer_rl/"&gt;Multi-Agent&lt;/a&gt;&lt;/strong&gt;: optimize LLMs to play against another LLM or themselves.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These examples are located in each subfolder, and their &lt;code&gt;README.md&lt;/code&gt; files will walk you through the key implementation details, the commands to run them, and the expected performance.&lt;/p&gt; 
&lt;h3&gt;Import our utilities&lt;/h3&gt; 
&lt;p&gt;Tinker cookbook includes several utilities. Here's a quick overview:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/renderers.py"&gt;&lt;code&gt;renderers&lt;/code&gt;&lt;/a&gt; converts tokens from/to structured chat message objects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/hyperparam_utils.py"&gt;&lt;code&gt;hyperparam_utils&lt;/code&gt;&lt;/a&gt; helps calculate hyperparameters suitable for LoRAs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/evaluators.py"&gt;&lt;code&gt;evaluation&lt;/code&gt;&lt;/a&gt; provides abstractions for evaluating Tinker models and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/inspect_evaluators.py"&gt;&lt;code&gt;inspect_evaluation&lt;/code&gt;&lt;/a&gt; shows how to integrate with InspectAI to make evaluating on standard benchmarks easy.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is built in the spirit of open science and collaborative development. We believe that the best tools emerge through community involvement and shared learning.&lt;/p&gt; 
&lt;p&gt;We welcome PR contributions after our private beta is over. If you have any feedback, please email us at &lt;a href="mailto:tinker@thinkingmachines.ai"&gt;tinker@thinkingmachines.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Tinker for your research, please cite it as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Thinking Machines Lab, 2025. Tinker. https://thinkingmachines.ai/tinker/.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use this BibTeX citation:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{tml2025tinker,
  author = {Thinking Machines Lab},
  title = {Tinker},
  year = {2025},
  url = {https://thinkingmachines.ai/tinker/},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>lzhoang2801/OpCore-Simplify</title>
      <link>https://github.com/lzhoang2801/OpCore-Simplify</link>
      <description>&lt;p&gt;A tool designed to simplify the creation of OpenCore EFI&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;OpCore Simplify&lt;/h3&gt; 
 &lt;p align="center"&gt; A specialized tool that streamlines &lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCore&lt;/a&gt; EFI creation by automating the essential setup process and providing standardized configurations. Designed to reduce manual effort while ensuring accuracy in your Hackintosh journey. &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-features"&gt;Features&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-how-to-use"&gt;How To Use&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contributing"&gt;Contributing&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-license"&gt;License&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-credits"&gt;Credits&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contact"&gt;Contact&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15410" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15410" alt="lzhoang2801%2FOpCore-Simplify | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] &lt;strong&gt;DO NOT TRUST ANY HACKINTOSH INFORMATION FROM AI/LLM SOURCES&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;They often provide incorrect information about Hackintosh. Always rely on official sources like the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt; and the Hackintosh community for accurate information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;OUTDATED SECTIONS IN DORTANIA GUIDE&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While the Dortania Guide is a valuable resource, some sections may be outdated. Always:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Verify information with the Hackintosh community&lt;/li&gt; 
  &lt;li&gt;Test configurations yourself&lt;/li&gt; 
  &lt;li&gt;Prefer reading documentation directly from the GitHub repositories of bootloaders and kexts you plan to use&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If the installation process is successful using OpCore Simplify, please confirm it at &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/discussions/23"&gt;Successful Hackintosh Setup with OpCore Simplify&lt;/a&gt;. This will greatly assist others in the community.&lt;/p&gt; 
 &lt;p&gt;OpCore Simplify is the ONLY tool that builds OpenCore EFI based on your complete hardware configuration, not just predefined options. This fundamental difference sets us apart from other tools in the Hackintosh community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] While OpCore Simplify significantly reduces setup time, the Hackintosh journey still requires:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Understanding basic concepts from the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Testing and troubleshooting during the installation process&lt;/li&gt; 
  &lt;li&gt;Patience and persistence in resolving any issues that arise&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Our tool doesn't eliminate these steps, but it ensures you start with a solid foundation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;âœ¨ &lt;strong&gt;Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comprehensive Hardware and macOS Support&lt;/strong&gt;&lt;br /&gt; Fully supports modern hardware. Use &lt;code&gt;Compatibility Checker&lt;/code&gt; to check supported/unsupported devices and macOS version supported.&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Supported&lt;/strong&gt;&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel: Nehalem and Westmere (1st Gen) â†’ Arrow Lake (15th Gen/Core Ultra Series 2) &lt;br /&gt; AMD: Ryzen and Threadripper with &lt;a href="https://github.com/AMD-OSX/AMD_Vanilla"&gt;AMD Vanilla&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel iGPU: Iron Lake (1st Gen) â†’ Ice Lake (10th Gen) &lt;br /&gt; AMD APU: The entire Vega Raven ASIC family (Ryzen 1xxx â†’ 5xxx, 7x30 series) &lt;br /&gt; AMD dGPU: Navi 23, Navi 22, Navi 21 generations, and older series &lt;br /&gt; NVIDIA: Kepler, Pascal, Maxwell, Fermi, Tesla generations&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;macOS High Sierra â†’ macOS Tahoe&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ACPI Patches and Kexts&lt;/strong&gt;&lt;br /&gt; Automatically detects and adds ACPI patches and kexts based on hardware configuration.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrated with &lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; for common patches (e.g., FakeEC, FixHPET, PLUG, RTCAWAC).&lt;/li&gt; 
   &lt;li&gt;Includes custom patches: 
    &lt;ul&gt; 
     &lt;li&gt;Prevent kernel panics by directing the first CPU entry to an active CPU, disabling the UNC0 device, and creating a new RTC device for HEDT systems.&lt;/li&gt; 
     &lt;li&gt;Disable unsupported or unused PCI devices, such as the GPU (using Optimus and Bumblebee methods or adding the disable-gpu property), Wi-Fi card, and NVMe storage controller.&lt;/li&gt; 
     &lt;li&gt;Fix sleep state values in _PRW methods (GPRW, UPRW, HP special) to prevent immediate wake.&lt;/li&gt; 
     &lt;li&gt;Add devices including ALS0, BUS0, MCHC, PMCR, PNLF, RMNE, IMEI, USBX, XOSI, along with a Surface Patch.&lt;/li&gt; 
     &lt;li&gt;Enable ALSD and GPI0 devices.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Updates&lt;/strong&gt;&lt;br /&gt; Automatically checks for and updates OpenCorePkg and kexts from &lt;a href="https://dortania.github.io/builds/"&gt;Dortania Builds&lt;/a&gt; and GitHub releases before each EFI build.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;EFI Configuration&lt;/strong&gt;&lt;br /&gt; Apply additional customization based on both widely used sources and personal experience.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Spoof GPU IDs for certain AMD GPUs not recognized in macOS.&lt;/li&gt; 
   &lt;li&gt;Use CpuTopologyRebuild kext for Intel CPUs with P-cores and E-cores to enhance performance.&lt;/li&gt; 
   &lt;li&gt;Disable System Integrity Protection (SIP).&lt;/li&gt; 
   &lt;li&gt;Spoof CPU IDs for Intel Pentium, Celeron, Core, and Xeon processors.&lt;/li&gt; 
   &lt;li&gt;Add custom CPU names for AMD CPUs, as well as Intel Pentium, Celeron, Xeon, and Core lines from the Rocket Lake (11th) generation and newer.&lt;/li&gt; 
   &lt;li&gt;Add a patch to allow booting macOS with unsupported SMBIOS.&lt;/li&gt; 
   &lt;li&gt;Add NVRAM entries to bypass checking the internal Bluetooth controller.&lt;/li&gt; 
   &lt;li&gt;Properly configure ResizeAppleGpuBars based on specific Resizable BAR information.&lt;/li&gt; 
   &lt;li&gt;Allow flexible iGPU configuration between headless and driving a display when a supported discrete GPU is present.&lt;/li&gt; 
   &lt;li&gt;Force Intel GPUs into VESA mode with HDMI and DVI connectors to simplify installation process.&lt;/li&gt; 
   &lt;li&gt;Provide configuration required for using OpenCore Legacy Patcher.&lt;/li&gt; 
   &lt;li&gt;Add built-in device property for network devices (fix 'Could not communicate with the server' when using iServices) and storage controllers (fix internal drives shown as external).&lt;/li&gt; 
   &lt;li&gt;Prioritize SMBIOS optimized for both power management and performance.&lt;/li&gt; 
   &lt;li&gt;Re-enable CPU power management on legacy Intel CPUs in macOS Ventura 13 and newer.&lt;/li&gt; 
   &lt;li&gt;Apply WiFi profiles for itlwm kext to enable auto WiFi connections at boot time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;and more...&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy Customization&lt;/strong&gt;&lt;br /&gt; In addition to the default settings applied, users can easily make further customizations if desired.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Custom ACPI patches, kexts, and SMBIOS adjustments (&lt;strong&gt;not recommended&lt;/strong&gt;).&lt;/li&gt; 
   &lt;li&gt;Force load kexts on unsupported macOS versions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸš€ &lt;strong&gt;How To Use&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click &lt;strong&gt;Code&lt;/strong&gt; â†’ &lt;strong&gt;Download ZIP&lt;/strong&gt;, or download directly via this &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/archive/refs/heads/main.zip"&gt;link&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Extract the downloaded ZIP file to your desired location.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/mcE7OSX.png" alt="Download OpCore Simplify" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Running OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On &lt;strong&gt;Windows&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.bat&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;macOS&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.command&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/vTr1V9D.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting hardware report&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On Windows, there will be an option for &lt;code&gt;E. Export hardware report&lt;/code&gt;. It's recommended to use this for the best results with your hardware configuration and BIOS at the time of building.&lt;/li&gt; 
   &lt;li&gt;Alternatively, use &lt;a href="https://github.com/lzhoang2801/Hardware-Sniffer"&gt;&lt;strong&gt;Hardware Sniffer&lt;/strong&gt;&lt;/a&gt; to create a &lt;code&gt;Report.json&lt;/code&gt; and ACPI dump for configuration manully.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MbRmIGJ.png" alt="Selecting hardware report" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/SbL6N6v.png" alt="Loading ACPI Tables" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/kuDGMmp.png" alt="Compatibility Checker" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting macOS Version and Customizing OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;By default, the latest compatible macOS version will be selected for your hardware.&lt;/li&gt; 
   &lt;li&gt;OpCore Simplify will automatically apply essential ACPI patches and kexts.&lt;/li&gt; 
   &lt;li&gt;You can manually review and customize these settings as needed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/TSk9ejy.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Building OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Once you've customized all options, select &lt;strong&gt;Build OpenCore EFI&lt;/strong&gt; to generate your EFI.&lt;/li&gt; 
   &lt;li&gt;The tool will automatically download the necessary bootloader and kexts, which may take a few minutes.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/71TkJkD.png" alt="WiFi Profile Extractor" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/Mcm20EQ.png" alt="Choosing Codec Layout ID" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/deyj5de.png" alt="Building OpenCore EFI" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;USB Mapping&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;After building your EFI, follow the steps for mapping USB ports.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MIPigPF.png" alt="Results" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create USB and Install macOS&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use &lt;a href="https://github.com/corpnewt/UnPlugged"&gt;&lt;strong&gt;UnPlugged&lt;/strong&gt;&lt;/a&gt; on Windows to create a USB macOS installer, or follow &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/installer-guide/mac-install.html"&gt;this guide&lt;/a&gt; for macOS.&lt;/li&gt; 
   &lt;li&gt;For troubleshooting, refer to the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/troubleshooting/troubleshooting.html"&gt;OpenCore Troubleshooting Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;After a successful installation, if OpenCore Legacy Patcher is required, simply apply root patches to activate the missing features (such as modern Broadcom Wi-Fi card and graphics acceleration).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For AMD GPUs, after applying root patches from OpenCore Legacy Patcher, you need to remove the boot argument &lt;code&gt;-radvesa&lt;/code&gt;/&lt;code&gt;-amd_no_dgpu_accel&lt;/code&gt; for graphics acceleration to work.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ¤ &lt;strong&gt;Contributing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Contributions are &lt;strong&gt;highly appreciated&lt;/strong&gt;! If you have ideas to improve this project, feel free to fork the repo and create a pull request, or open an issue with the "enhancement" tag.&lt;/p&gt; 
&lt;p&gt;Don't forget to â­ star the project! Thank you for your support! ğŸŒŸ&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ &lt;strong&gt;License&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Distributed under the BSD 3-Clause License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;ğŸ™Œ &lt;strong&gt;Credits&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCorePkg&lt;/a&gt; and &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/raw/main/Scripts/datasets/kext_data.py"&gt;kexts&lt;/a&gt; â€“ The backbone of this project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; â€“ SSDT patching utilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“ &lt;strong&gt;Contact&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hoang Hong Quan&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Facebook &lt;a href="https://facebook.com/macforce2601"&gt;@macforce2601&lt;/a&gt; &amp;nbsp;Â·&amp;nbsp; Telegram &lt;a href="https://t.me/lzhoang2601"&gt;@lzhoang2601&lt;/a&gt; &amp;nbsp;Â·&amp;nbsp; Email: &lt;a href="mailto:lzhoang2601@gmail.com"&gt;lzhoang2601@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸŒŸ &lt;strong&gt;Star History&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#lzhoang2801/OpCore-Simplify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=lzhoang2801/OpCore-Simplify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/call-center-ai</title>
      <link>https://github.com/microsoft/call-center-ai</link>
      <description>&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Call Center AI&lt;/h1&gt; 
&lt;p&gt;AI-powered call center solution with Azure and OpenAI GPT.&lt;/p&gt; 
&lt;!-- github.com badges --&gt; 
&lt;p&gt;&lt;a href="https://github.com/clemlesne/call-center-ai/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/clemlesne/call-center-ai" alt="Last release date" /&gt;&lt;/a&gt; &lt;a href="https://github.com/clemlesne/call-center-ai/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/clemlesne/call-center-ai" alt="Project license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- GitHub Codespaces badge --&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in GitHub Codespaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!&lt;/p&gt; 
&lt;p&gt;Insurance, IT support, customer service, and more. The bot can be customized in few hours (really) to fit your needs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ask the bot to call a phone number
data='{
  "bot_company": "Contoso",
  "bot_name": "AmÃ©lie",
  "phone_number": "+11234567890",
  "task": "Help the customer with their digital workplace. Assistant is working for the IT support department. The objective is to help the customer with their issue and gather information in the claim.",
  "agent_phone_number": "+33612345678",
  "claim": [
    {
      "name": "hardware_info",
      "type": "text"
    },
    {
      "name": "first_seen",
      "type": "datetime"
    },
    {
      "name": "building_location",
      "type": "text"
    }
  ]
}'

curl \
  --header 'Content-Type: application/json' \
  --request POST \
  --url https://xxx/call \
  --data $data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhanced communication and user experience&lt;/strong&gt;: Integrates inbound and outbound calls with a dedicated phone number, supports multiple languages and voice tones, and allows users to provide or receive information via SMS. Conversations are &lt;strong&gt;streamed in real-time&lt;/strong&gt; to avoid delays, can be &lt;strong&gt;resumed after disconnections&lt;/strong&gt;, and are &lt;strong&gt;stored for future reference&lt;/strong&gt;. This ensures an &lt;strong&gt;improved customer experience&lt;/strong&gt;, enabling 24/7 communication and handling of low to medium complexity calls, all in a more accessible and user-friendly manner.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced intelligence and data management&lt;/strong&gt;: Leverages &lt;strong&gt;gpt-4.1&lt;/strong&gt; and &lt;strong&gt;gpt-4.1-nano&lt;/strong&gt; (known for higher performance and a 10â€“15x cost premium) to achieve nuanced comprehension. It can discuss &lt;strong&gt;private and sensitive data&lt;/strong&gt;, including customer-specific information, while following &lt;strong&gt;retrieval-augmented generation (RAG)&lt;/strong&gt; best practices to ensure secure and compliant handling of internal documents. The system understands domain-specific terms, follows a structured claim schema, generates automated to-do lists, filters inappropriate content, and detects jailbreak attempts. Historical conversations and past interactions can also be used to &lt;strong&gt;fine-tune the LLM&lt;/strong&gt;, improving accuracy and personalization over time. Redis caching further enhances efficiency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Customization, oversight, and scalability&lt;/strong&gt;: Offers &lt;strong&gt;customizable prompts&lt;/strong&gt;, feature flags for controlled experimentation, human agent fallback, and call recording for quality assurance. Integrates Application Insights for monitoring and tracing, provides publicly accessible claim data, and plans future enhancements such as automated callbacks and IVR-like workflows. It also enables the creation of a &lt;strong&gt;brand-specific custom voice&lt;/strong&gt;, allowing the assistantâ€™s voice to reflect the companyâ€™s identity and improve brand consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cloud-native deployment and resource management&lt;/strong&gt;: Deployed on &lt;strong&gt;Azure&lt;/strong&gt; with a containerized, serverless architecture for low maintenance and elastic scaling. This approach optimizes costs based on usage, ensuring flexibility and affordability over time. Seamless integration with &lt;strong&gt;Azure Communication Services&lt;/strong&gt;, &lt;strong&gt;Cognitive Services&lt;/strong&gt;, and &lt;strong&gt;OpenAI resources&lt;/strong&gt; provides a secure environment suitable for rapid iteration, continuous improvement, and accommodating variable workloads in the call center.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Demo&lt;/h3&gt; 
&lt;p&gt;A French demo is avaialble on YouTube. Do not hesitate to watch the demo in x1.5 speed to get a quick overview of the project. Voice is hesitant on purpose to show the bot can handle it. All the infrastructure is deployed on Azure, mostly in serverless mode. Provisionning of the LLM resources can be done to reduce the latency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtube.com/watch?v=i_qhNdUUxSI"&gt;&lt;img src="https://img.youtube.com/vi/i_qhNdUUxSI/maxresdefault.jpg" alt="French demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Main interactions shown in the demo:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;User calls the call center&lt;/li&gt; 
 &lt;li&gt;The bot answers and the conversation starts&lt;/li&gt; 
 &lt;li&gt;The bot stores conversation, claim and todo list in the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Extract of the data stored during the call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "claim": {
    "incident_description": "Collision avec un autre vÃ©hicule, voiture dans le fossÃ©, pas de blessÃ©s",
    "incident_location": "Nationale 17",
    "involved_parties": "Dujardin, Madame LesnÃ©",
    "policy_number": "DEC1748"
  },
  "messages": [
    {
      "created_at": "2024-12-10T15:51:04.566727Z",
      "action": "talk",
      "content": "Non, je pense que c'est pas mal. Vous avez rÃ©pondu Ã  mes questions et lÃ  j'attends la dÃ©paneuse. Merci beaucoup.",
      "persona": "human",
      "style": "none",
      "tool_calls": []
    },
    {
      "created_at": "2024-12-10T15:51:06.040451Z",
      "action": "talk",
      "content": "Je suis ravi d'avoir pu vous aider! Si vous avez besoin de quoi que ce soit d'autre, n'hÃ©sitez pas Ã  nous contacter. Je vous souhaite une bonne journÃ©e et j'espÃ¨re que tout se passera bien avec la dÃ©panneuse. Au revoir!",
      "persona": "assistant",
      "style": "none",
      "tool_calls": []
    }
  ],
  "next": {
    "action": "case_closed",
    "justification": "The customer has provided all necessary information for the insurance claim, and a reminder has been set for a follow-up call. The customer is satisfied with the assistance provided and is waiting for the tow truck. The case can be closed for now."
  },
  "reminders": [
    {
      "created_at": "2024-12-10T15:50:09.507903Z",
      "description": "Rappeler le client pour faire le point sur l'accident et l'avancement du dossier.",
      "due_date_time": "2024-12-11T14:30:00",
      "owner": "assistant",
      "title": "Rappel client sur l'accident"
    }
  ],
  "synthesis": {
    "long": "During our call, you reported an accident involving your vehicle on the Nationale 17. You mentioned that there were no injuries, but both your car and the other vehicle ended up in a ditch. The other party involved is named Dujardin, and your vehicle is a 4x4 Ford. I have updated your claim with these details, including the license plates: yours is U837GE and the other vehicle's is GA837IA. A reminder has been set for a follow-up call tomorrow at 14:30 to discuss the progress of your claim. If you need further assistance, please feel free to reach out.",
    "satisfaction": "high",
    "short": "the accident on Nationale 17",
    "improvement_suggestions": "To improve the customer experience, it would be beneficial to ensure that the call connection is stable to avoid interruptions. Additionally, providing a clear step-by-step guide on what information is needed for the claim could help streamline the process and reduce any confusion for the customer."
  }
  ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;User report after the call&lt;/h3&gt; 
&lt;p&gt;A report is available at &lt;code&gt;https://[your_domain]/report/[phone_number]&lt;/code&gt; (like &lt;code&gt;http://localhost:8080/report/%2B133658471534&lt;/code&gt;). It shows the conversation history, claim data and reminders.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/call-center-ai/main/docs/user_report.png" alt="User report" /&gt;&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;High level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: System diagram (C4 model)
---
graph
  user(["User"])
  agent(["Agent"])

  app["Call Center AI"]

  app -- Transfer to --&amp;gt; agent
  app -. Send voice .-&amp;gt; user
  user -- Call --&amp;gt; app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Component level architecture&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;---
title: Claim AI component diagram (C4 model)
---
graph LR
  agent(["Agent"])
  user(["User"])

  subgraph "Claim AI"
    ada["Embedding&amp;lt;br&amp;gt;(ADA)"]
    app["App&amp;lt;br&amp;gt;(Container App)"]
    communication_services["Call &amp;amp; SMS gateway&amp;lt;br&amp;gt;(Communication Services)"]
    db[("Conversations and claims&amp;lt;br&amp;gt;(Cosmos DB)")]
    eventgrid["Broker&amp;lt;br&amp;gt;(Event Grid)"]
    gpt["LLM&amp;lt;br&amp;gt;(gpt-4.1, gpt-4.1-nano)"]
    queues[("Queues&amp;lt;br&amp;gt;(Azure Storage)")]
    redis[("Cache&amp;lt;br&amp;gt;(Redis)")]
    search[("RAG&amp;lt;br&amp;gt;(AI Search)")]
    sounds[("Sounds&amp;lt;br&amp;gt;(Azure Storage)")]
    sst["Speech-to-text&amp;lt;br&amp;gt;(Cognitive Services)"]
    translation["Translation&amp;lt;br&amp;gt;(Cognitive Services)"]
    tts["Text-to-speech&amp;lt;br&amp;gt;(Cognitive Services)"]
  end

  app -- Translate static TTS --&amp;gt; translation
  app -- Sezarch RAG data --&amp;gt; search
  app -- Generate completion --&amp;gt; gpt
  gpt -. Answer with completion .-&amp;gt; app
  app -- Generate voice --&amp;gt; tts
  tts -. Answer with voice .-&amp;gt; app
  app -- Get cached data --&amp;gt; redis
  app -- Save conversation --&amp;gt; db
  app -- Transform voice --&amp;gt; sst
  sst -. Answer with text .-&amp;gt; app
  app &amp;lt;-. Exchange audio .-&amp;gt; communication_services
  app -. Watch .-&amp;gt; queues

  communication_services -- Load sound --&amp;gt; sounds
  communication_services -- Notifies --&amp;gt; eventgrid
  communication_services -- Transfer to --&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; agent
  communication_services &amp;lt;-. Exchange audio .-&amp;gt; user

  eventgrid -- Push to --&amp;gt; queues

  search -- Generate embeddings --&amp;gt; ada

  user -- Call --&amp;gt; communication_services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This project is a proof of concept. It is not intended to be used in production. This demonstrates how can be combined Azure Communication Services, Azure Cognitive Services and Azure OpenAI to build an automated call center solution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/microsoft/call-center-ai?quickstart=1"&gt;Prefer using GitHub Codespaces for a quick start.&lt;/a&gt; The environment will setup automatically with all the required tools.&lt;/p&gt; 
&lt;p&gt;In macOS, with &lt;a href="https://brew.sh"&gt;Homebrew&lt;/a&gt;, simply type &lt;code&gt;make brew&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For other systems, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/cli/azure/install-azure-cli"&gt;Azure CLI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.twilio.com/docs/twilio-cli/getting-started/install"&gt;Twilio CLI&lt;/a&gt; (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mikefarah/yq?tab=readme-ov-file#install"&gt;yq&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Bash compatible shell, like &lt;code&gt;bash&lt;/code&gt; or &lt;code&gt;zsh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Make, &lt;code&gt;apt install make&lt;/code&gt; (Ubuntu), &lt;code&gt;yum install make&lt;/code&gt; (CentOS), &lt;code&gt;brew install make&lt;/code&gt; (macOS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, Azure resources are needed:&lt;/p&gt; 
&lt;h4&gt;1. &lt;a href="https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal"&gt;Create a new resource group&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prefer to use lowercase and no special characters other than dashes (e.g. &lt;code&gt;ccai-customer-a&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/create-communication-resource?tabs=linux&amp;amp;pivots=platform-azp"&gt;Create a Communication Services resource&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Same name as the resource group&lt;/li&gt; 
 &lt;li&gt;Enable system managed identity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;3. &lt;a href="https://learn.microsoft.com/en-us/azure/communication-services/quickstarts/telephony/get-phone-number?tabs=linux&amp;amp;pivots=platform-azp-new"&gt;Buy a phone number&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;From the Communication Services resource&lt;/li&gt; 
 &lt;li&gt;Allow inbound and outbound communication&lt;/li&gt; 
 &lt;li&gt;Enable voice (required) and SMS (optional) capabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now that the prerequisites are configured (local + Azure), the deployment can be done.&lt;/p&gt; 
&lt;h3&gt;Remote (on Azure)&lt;/h3&gt; 
&lt;p&gt;A pre-built container image is available on GitHub Actions, it will be used to deploy the solution on Azure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Latest version from a branch: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:main&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Specific tag: &lt;code&gt;ghcr.io/clemlesne/call-center-ai:0.1.0&lt;/code&gt; (recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Create the light config file&lt;/h4&gt; 
&lt;p&gt;Fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-remote-example.yaml"&gt;&lt;code&gt;config-remote-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;. It will be used by install scripts (incl. Makefile and Bicep) to configure the Azure resources.&lt;/p&gt; 
&lt;h4&gt;2. Connect to your Azure environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;az login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Run deployment automation&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Specify the release version under the &lt;code&gt;image_version&lt;/code&gt; parameter (default is &lt;code&gt;main&lt;/code&gt;). For example, &lt;code&gt;image_version=16.0.0&lt;/code&gt; or &lt;code&gt;image_version=sha-7ca2c0c&lt;/code&gt;. This will ensure any future project breaking changes won't affect your deployment.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the deployment to finish.&lt;/p&gt; 
&lt;h4&gt;4. Get the logs&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make logs name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local (on your machine)&lt;/h3&gt; 
&lt;h4&gt;1. Prerequisites&lt;/h4&gt; 
&lt;p&gt;If you skiped the &lt;code&gt;make brew&lt;/code&gt; command from the first install section, make sure you have the following installed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rust-lang.org"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, run &lt;code&gt;make install&lt;/code&gt; to setup Python environment.&lt;/p&gt; 
&lt;h4&gt;2. Create the full config file&lt;/h4&gt; 
&lt;p&gt;If the application is already deployed on Azure, you can run &lt;code&gt;make name=my-rg-name sync-local-config&lt;/code&gt; to copy the configuration from remote to your local machine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] To use a Service Principal to authenticate to Azure, you can also add the following in a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;AZURE_CLIENT_ID=xxx
AZURE_CLIENT_SECRET=xxx
AZURE_TENANT_ID=xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If the solution is not running online, fill the template from the example at &lt;a href="https://raw.githubusercontent.com/microsoft/call-center-ai/main/config-local-example.yaml"&gt;&lt;code&gt;config-local-example.yaml&lt;/code&gt;&lt;/a&gt;. The file should be placed at the root of the project under the name &lt;code&gt;config.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;3. Run the deployment automation&lt;/h4&gt; 
&lt;p&gt;Execute if the solution is not yet deployed on Azure.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make deploy-bicep deploy-post name=my-rg-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;This will deploy the Azure resources without the API server, allowing you to test the bot locally&lt;/li&gt; 
 &lt;li&gt;Wait for the deployment to finish&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;4. Connect to Azure Dev tunnels&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Tunnel requires to be run in a separate terminal, because it needs to be running all the time&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;# Log in once
devtunnel login

# Start the tunnel
make tunnel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Iterate quickly with the code&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To override a specific configuration value, you can use environment variables. For example, to override the &lt;code&gt;llm.fast.endpoint&lt;/code&gt; value, you can use the &lt;code&gt;LLM__FAST__ENDPOINT&lt;/code&gt; variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-dotenv"&gt;LLM__FAST__ENDPOINT=https://xxx.openai.azure.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Also, &lt;code&gt;local.py&lt;/code&gt; script is available to test the application without the need of a phone call (= without Communication Services). Run the script with:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m tests.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Code is automatically reloaded on file changes, no need to restart the server&lt;/li&gt; 
 &lt;li&gt;The API server is available at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Advanced usage&lt;/h2&gt; 
&lt;h3&gt;Enable call recording&lt;/h3&gt; 
&lt;p&gt;Call recording is disabled by default. To enable it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a new container in the Azure Storage account (i.e. &lt;code&gt;recordings&lt;/code&gt;), it is already done if you deployed the solution on Azure&lt;/li&gt; 
 &lt;li&gt;Update the feature flag &lt;code&gt;recording_enabled&lt;/code&gt; in App Configuration to &lt;code&gt;true&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Add my custom training data with AI Search&lt;/h3&gt; 
&lt;p&gt;Training data is stored on AI Search to be retrieved by the bot, on demand.&lt;/p&gt; 
&lt;p&gt;Required index schema:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Field Name&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;Type&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Retrievable&lt;/th&gt; 
   &lt;th&gt;Searchable&lt;/th&gt; 
   &lt;th&gt;Dimensions&lt;/th&gt; 
   &lt;th&gt;Vectorizer&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;answer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;context&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;created_at&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;document_synthesis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;file_path&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;id&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;question&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Edm.String&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vectors&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Collection(Edm.Single)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;1536&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;OpenAI ADA&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Software to fill the index is included &lt;a href="https://github.com/clemlesne/rag-index"&gt;on Synthetic RAG Index&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h3&gt;Customize the languages&lt;/h3&gt; 
&lt;p&gt;The bot can be used in multiple languages. It can understand the language the user chose.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts#supported-languages"&gt;list of supported languages&lt;/a&gt; for the Text-to-Speech service.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: fr-FR-DeniseNeural
        - pronunciations_en: ["Chinese", "ZH", "China"]
          short_code: zh-CN
          voice: zh-CN-XiaoqiuNeural
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you built and deployed an &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-neural-voice"&gt;Azure Speech Custom Neural Voice (CNV)&lt;/a&gt;, add field &lt;code&gt;custom_voice_endpoint_id&lt;/code&gt; on the language configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    lang:
      default_short_code: fr-FR
      availables:
        - pronunciations_en: ["French", "FR", "France"]
          short_code: fr-FR
          voice: xxx
          custom_voice_endpoint_id: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the moderation levels&lt;/h3&gt; 
&lt;p&gt;Levels are defined for each category of Content Safety. The higher the score, the more strict the moderation is, from 0 to 7. Moderation is applied on all bot data, including the web page and the conversation. Configure them in Azure OpenAI Content Filters.&lt;/p&gt; 
&lt;h3&gt;Customize the claim data schema&lt;/h3&gt; 
&lt;p&gt;Customization of the data schema is fully supported. You can add or remove fields as needed, depending on the requirements.&lt;/p&gt; 
&lt;p&gt;By default, the schema of composed of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;caller_email&lt;/code&gt; (&lt;code&gt;email&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_name&lt;/code&gt; (&lt;code&gt;text&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;caller_phone&lt;/code&gt; (&lt;code&gt;phone_number&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Values are validated to ensure the data format commit to your schema. They can be either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;datetime&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;email&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;phone_number&lt;/code&gt; (&lt;code&gt;E164&lt;/code&gt; format)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;text&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Finally, an optional description can be provided. The description must be short and meaningful, it will be passed to the LLM.&lt;/p&gt; 
&lt;p&gt;Default schema, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  default_initiate:
    claim:
      - name: additional_notes
        type: text
        # description: xxx
      - name: device_info
        type: text
        # description: xxx
      - name: incident_datetime
        type: datetime
        # description: xxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Claim schema can be customized for each call, by adding the &lt;code&gt;claim&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the call objective&lt;/h3&gt; 
&lt;p&gt;The objective is a description of what the bot will do during the call. It is used to give a context to the LLM. It should be short, meaningful, and written in English.&lt;/p&gt; 
&lt;p&gt;This solution is priviledged instead of overriding the LLM prompt.&lt;/p&gt; 
&lt;p&gt;Default task, for inbound calls, is defined in the configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
conversation:
  initiate:
    task: |
      Help the customer with their insurance claim. Assistant requires data from the customer to fill the claim. The latest claim data will be given. Assistant role is not over until all the relevant data is gathered.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Task can be customized for each call, by adding the &lt;code&gt;task&lt;/code&gt; field in the &lt;code&gt;POST /call&lt;/code&gt; API call.&lt;/p&gt; 
&lt;h3&gt;Customize the conversation&lt;/h3&gt; 
&lt;p&gt;Conversation options are represented as features. They can be configured from App Configuration, without the need to redeploy or restart the application. Once a feature is updated, a delay of 60 secs is needed to make the change effective.&lt;/p&gt; 
&lt;p&gt;By default, values are refreshed every 60 seconds. Refresh is not sync across all instances, so it can take up to 60 seconds to see the change on all users. Update this in the &lt;code&gt;app_configuration.ttl_sec&lt;/code&gt; field.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_hard_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before aborting the answer with an error message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;answer_soft_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Time waiting the LLM before sending a waiting message.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;callback_timeout_hour&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for a callback in hours. Set 0 to disable.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;phone_silence_timeout_sec&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amount of silence in secs to trigger a warning message from the assistant.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_retry_max&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;TThe maximum number of retries for voice recognition. Minimum of 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recognition_stt_complete_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The timeout for STT completion in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;recording_enabled&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether call recording is enabled.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;slow_llm_for_chat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether to use the slow LLM for chat.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;bool&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_cutoff_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The cutoff timeout for voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;250&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_silence_timeout_ms&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Silence to trigger voice activity detection in milliseconds.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;500&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vad_threshold&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The threshold for voice activity detection. Between 0.1 and 1.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;float&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;0.5&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Use Twilio for SMS&lt;/h3&gt; 
&lt;p&gt;To use Twilio for SMS, you need to create an account and get the following information:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Account SID&lt;/li&gt; 
 &lt;li&gt;Auth Token&lt;/li&gt; 
 &lt;li&gt;Phone number&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then, add the following in the &lt;code&gt;config.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
sms:
  mode: twilio
  twilio:
    account_sid: xxx
    auth_token: xxx
    phone_number: "+33612345678"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customize the prompts&lt;/h3&gt; 
&lt;p&gt;Note that prompt examples contains &lt;code&gt;{xxx}&lt;/code&gt; placeholders. These placeholders are replaced by the bot with the corresponding data. For example, &lt;code&gt;{bot_name}&lt;/code&gt; is internally replaced by the bot name. Be sure to write all the TTS prompts in English. This language is used as a pivot language for the conversation translation. All texts are referenced as lists, so user can have a different experience each time they call, thus making the conversation more engaging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yaml
prompts:
  tts:
    hello_tpl:
      - : |
        Hello, I'm {bot_name}, from {bot_company}! I'm an IT support specialist.

        Here's how I work: when I'm working, you'll hear a little music; then, at the beep, it's your turn to speak. You can speak to me naturally, I'll understand.

        What's your problem?
      - : |
        Hi, I'm {bot_name} from {bot_company}. I'm here to help.

        You'll hear music, then a beep. Speak naturally, I'll understand.

        What's the issue?
  llm:
    default_system_tpl: |
      Assistant is called {bot_name} and is in a call center for the company {bot_company} as an expert with 20 years of experience in IT service.

      # Context
      Today is {date}. Customer is calling from {phone_number}. Call center number is {bot_phone_number}.
    chat_system_tpl: |
      # Objective
      Provide internal IT support to employees. Assistant requires data from the employee to provide IT support. The assistant's role is not over until the issue is resolved or the request is fulfilled.

      # Rules
      - Answers in {default_lang}, even if the customer speaks another language
      - Cannot talk about any topic other than IT support
      - Is polite, helpful, and professional
      - Rephrase the employee's questions as statements and answer them
      - Use additional context to enhance the conversation with useful details
      - When the employee says a word and then spells out letters, this means that the word is written in the way the employee spelled it (e.g. "I work in Paris PARIS", "My name is John JOHN", "My email is Clemence CLEMENCE at gmail GMAIL dot com COM")
      - You work for {bot_company}, not someone else

      # Required employee data to be gathered by the assistant
      - Department
      - Description of the IT issue or request
      - Employee name
      - Location

      # General process to follow
      1. Gather information to know the employee's identity (e.g. name, department)
      2. Gather details about the IT issue or request to understand the situation (e.g. description, location)
      3. Provide initial troubleshooting steps or solutions
      4. Gather additional information if needed (e.g. error messages, screenshots)
      5. Be proactive and create reminders for follow-up or further assistance

      # Support status
      {claim}

      # Reminders
      {reminders}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optimize response delay&lt;/h3&gt; 
&lt;p&gt;The delay mainly come from two things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Voice in and voice out are processed by Azure AI Speech, both are implemented in streaming mode but voice is not directly streamed to the LLM&lt;/li&gt; 
 &lt;li&gt;The LLM, more specifically the delay between API call and first sentence infered, can be long (as the sentences are sent one by one once they are made avalable), even longer if it hallucinate and returns empty answers (it happens regularly, and the applicatoipn retries the call)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;From now, the only impactful thing you can do is the LLM part. This can be acheieve by a PTU on Azure or using a less smart model like &lt;code&gt;gpt-4.1-nano&lt;/code&gt; (selected by default on the latest versions). With a PTU on Azure OpenAI, you can divide by 2 the latency in some case.&lt;/p&gt; 
&lt;p&gt;The application is natively connected to Azure Application Insights, so you can monitor the response time and see where the time is spent. This is a great start to identify the bottlenecks.&lt;/p&gt; 
&lt;p&gt;Feel free to raise an issue or propose a PR if you have any idea to optimize the response delay.&lt;/p&gt; 
&lt;h3&gt;Improving conversation quality through model fine-tuning&lt;/h3&gt; 
&lt;p&gt;Enhance the LLMâ€™s accuracy and domain adaptation by integrating historical data from human-run call centers. Before proceeding, ensure compliance with data privacy regulations, internal security standards, and &lt;a href="https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai?view=azureml-api-2"&gt;Responsible AI principles&lt;/a&gt;. Consider the following steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aggregate authentic data sources: Collect voice recordings, call transcripts, and chat logs from previous human-managed interactions to provide the LLM with realistic training material.&lt;/li&gt; 
 &lt;li&gt;Preprocess and anonymize data: &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/overview"&gt;Remove sensitive information (AI Language Personally Identifiable Information detection)&lt;/a&gt;, including personal identifiers or confidential details, to preserve user privacy, meet compliance, and align with Responsible AI guidelines.&lt;/li&gt; 
 &lt;li&gt;Perform iterative fine-tuning: Continuously &lt;a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/fine-tuning-overview"&gt;refine the modelâ€™s using the curated dataset (AI Foundry Fine-tuning)&lt;/a&gt;, allowing it to learn industry-specific terminology, preferred conversation styles, and problem-resolution approaches.&lt;/li&gt; 
 &lt;li&gt;Validate improvements: Test the updated model against sample scenarios and measure key performance indicators (e.g. user satisfaction, call duration, resolution rate) to confirm that adjustments have led to meaningful enhancements.&lt;/li&gt; 
 &lt;li&gt;Monitor, iterate, and A/B test: Regularly reassess the modelâ€™s performance, integrate newly gathered data, and apply further fine-tuning as needed. Leverage &lt;a href="https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-experimentation"&gt;built-in feature configurations to A/B test (App Configuration Experimentation)&lt;/a&gt; different versions of the model, ensuring responsible, data-driven decisions and continuous optimization over time.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Monitoring the application&lt;/h3&gt; 
&lt;p&gt;Application send traces and metrics to Azure Application Insights. You can monitor the application from the Azure portal, or by using the API.&lt;/p&gt; 
&lt;p&gt;This includes application behavior, database queries, and external service calls. Plus, LLM metrics (latency, token usage, prompts content, raw response) from &lt;a href="https://github.com/traceloop/openllmetry"&gt;OpenLLMetry&lt;/a&gt;, following the &lt;a href="https://opentelemetry.io/docs/specs/semconv/gen-ai/openai/#openai-spans"&gt;semantic sonventions for OpenAI operations&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally custom metrics (viewable in Application Insights &amp;gt; Metrics) are published, notably:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.droped&lt;/code&gt;, number of times the echo cancellation dropped the voice completely.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.aec.missed&lt;/code&gt;, number of times the echo cancellation failed to remove the echo in time.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;call.answer.latency&lt;/code&gt;, time between the end of the user voice and the start of the bot voice.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;h3&gt;What will this cost?&lt;/h3&gt; 
&lt;p&gt;For a monthly usage of 1000 calls of 10 minutes each. Costs are estimated for 2024-12-10, in USD. Prices are subject to change.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For production usage, it is recommended to upgrade to SKUs with vNET integration and private endpoints. This can increase notably the costs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This totalizes $720.07 /month, $0.12 /hour, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Audio Streaming&lt;/td&gt; 
   &lt;td&gt;$0.004 /minute&lt;/td&gt; 
   &lt;td&gt;$40&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.15 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$35.25&lt;/td&gt; 
   &lt;td&gt;8k tokens for conversation history, 3750 tokens for RAG, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1-nano global&lt;/td&gt; 
   &lt;td&gt;$0.60 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$1.4&lt;/td&gt; 
   &lt;td&gt;400 tokens for each response incl tools, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$2.50 /1M input tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;4k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;gpt-4.1 global&lt;/td&gt; 
   &lt;td&gt;$10 /1M output tokens&lt;/td&gt; 
   &lt;td&gt;$10&lt;/td&gt; 
   &lt;td&gt;1k tokens for each conversation, to get insights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$2.08&lt;/td&gt; 
   &lt;td&gt;1 search or 400 tokens for each message, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/"&gt;Azure Container Apps&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless vCPU&lt;/td&gt; 
   &lt;td&gt;$0.000024 /sec&lt;/td&gt; 
   &lt;td&gt;$128.56&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 1 vCPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Serverless memory (average of 2 replicas)&lt;/td&gt; 
   &lt;td&gt;$0.000003 /sec&lt;/td&gt; 
   &lt;td&gt;$32.14&lt;/td&gt; 
   &lt;td&gt;Avg of 2 replicas with 2GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/search/"&gt;Azure AI Search&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;$73.73 /month&lt;/td&gt; 
   &lt;td&gt;$73.73&lt;/td&gt; 
   &lt;td&gt;Has 15GB of storage /index, should be upgraded for big datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/"&gt;Azure AI Speech&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Speech-to-text real-time&lt;/td&gt; 
   &lt;td&gt;$1 /hour&lt;/td&gt; 
   &lt;td&gt;$83.33&lt;/td&gt; 
   &lt;td&gt;Each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Text-to-speech standard&lt;/td&gt; 
   &lt;td&gt;$15 /1M characters&lt;/td&gt; 
   &lt;td&gt;$69.23&lt;/td&gt; 
   &lt;td&gt;300 tokens for each response, 1.3 tokens /word in English, each participant talk every 15s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cosmos-db/autoscale-provisioned/"&gt;Azure Cosmos DB&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Multi-region write RU/s /region&lt;/td&gt; 
   &lt;td&gt;$11.68 /100 RU/s&lt;/td&gt; 
   &lt;td&gt;$233.6&lt;/td&gt; 
   &lt;td&gt;Avg of 1k RU/s on 2 regions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Transactional storage&lt;/td&gt; 
   &lt;td&gt;$0.25 /GB&lt;/td&gt; 
   &lt;td&gt;$0.5&lt;/td&gt; 
   &lt;td&gt;2GB of storage, should be upgraded if more history is needed&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Not included upper:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Azure Monitor costs shouldn't be considered as optional as monitoring is a key part of maintaining a business-critical application and high-quality service for users.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional costs totalizing $343.02 /month, with the following breakdown:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/communication-services/"&gt;Azure Communication Services&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;West Europe&lt;/td&gt; 
   &lt;td&gt;Call recording&lt;/td&gt; 
   &lt;td&gt;$0.002 /minute&lt;/td&gt; 
   &lt;td&gt;$20&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"&gt;Azure OpenAI&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;text-embedding-3-large&lt;/td&gt; 
   &lt;td&gt;$0.00013 /1k tokens&lt;/td&gt; 
   &lt;td&gt;$0.52&lt;/td&gt; 
   &lt;td&gt;10k PDF pages with 400 tokens each, for indexing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://azure.microsoft.com/en-us/pricing/details/monitor/"&gt;Azure Monitor&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Region&lt;/th&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Cost&lt;/th&gt; 
   &lt;th&gt;Total (monthly $)&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sweden Central&lt;/td&gt; 
   &lt;td&gt;Basic logs ingestion&lt;/td&gt; 
   &lt;td&gt;$0.645 /GB&lt;/td&gt; 
   &lt;td&gt;$322.5&lt;/td&gt; 
   &lt;td&gt;500GB of logs &lt;a href="https://learn.microsoft.com/en-us/azure/azure-monitor/app/opentelemetry-configuration?tabs=python#enable-sampling"&gt;with sampling enabled&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;What would it require to make it production ready?&lt;/h3&gt; 
&lt;p&gt;Quality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Unit and integration tests for persistence layer&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Complete unit and integration tests coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reliability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Reproductible builds&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Traces and telemetry&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Operation runbooks for common issues&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Proper dashboarding in Azure Application Insights (deployed with the IaC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Maintainability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automated and required static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Decouple assistant from the insights in a separate service&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Peer review to limit the bus factor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Resiliency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infrastructure as Code (IaC)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Multi-region deployment&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Reproductible performance tests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Security:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CI builds attestations&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; CodeQL static code checks&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GitOps for deployments&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Private networking&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Production SKUs allowing vNET integration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Red team exercises&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Responsible AI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Harmful content detection&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Grounding detection with Content Safety&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Social impact assessment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why no LLM framework is used?&lt;/h3&gt; 
&lt;p&gt;At the time of development, no LLM framework was available to handle all of these features: streaming capability with multi-tools, backup models on availability issue, callbacks mechanisms in the triggered tools. So, OpenAI SDK is used directly and some algorithms are implemented to handle reliability.&lt;/p&gt; 
&lt;h2&gt;Related content&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For a simple sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, local deployment only, &lt;a href="https://github.com/Azure-Samples/aisearch-openai-rag-audio"&gt;see VoiceRAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For an easier-to-use sample with Azure OpenAI &lt;code&gt;gpt-4o-realtime&lt;/code&gt;, deployed on Azure, &lt;a href="https://github.com/Azure-Samples/realtime-call-center-accelerator"&gt;see Realtime Call Center Solution Accelerator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>airweave-ai/airweave</title>
      <link>https://github.com/airweave-ai/airweave</link>
      <description>&lt;p&gt;Context retrieval for AI agents across apps and databases&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="frontend/public/logo-airweave-darkbg.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="frontend/public/logo-airweave-lightbg.svg" /&gt; 
  &lt;img width="837" alt="airweave-lettermark" style="padding-bottom: 12px;" src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/public/logo-airweave-darkbg.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;h1&gt;Context Retrieval for AI Agents across Apps &amp;amp; Databases&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg?sanitize=true" alt="Ruff" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg?sanitize=true" alt="ESLint" /&gt;&lt;/a&gt; &lt;a href="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml"&gt;&lt;img src="https://github.com/airweave-ai/airweave/actions/workflows/test-public-api.yml/badge.svg?sanitize=true" alt="System Tests" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/airweave-sdk"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/airweave-sdk?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GRAY&amp;amp;right_color=BRIGHTGREEN&amp;amp;left_text=downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/gDuebsWGkn"&gt;&lt;img src="https://img.shields.io/discord/1323415085011701870?label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div style="padding-top: 16px;"&gt; 
  &lt;a href="https://trendshift.io/repositories/13748" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13748" alt="airweave-ai%2Fairweave | Trendshift" style="width: 250px; height: 55px; margin-right: 24px;" width="250" height="55" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
  &lt;a href="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app" target="_blank"&gt;&lt;img src="https://www.ycombinator.com/launches/NX7-airweave-let-agents-search-any-app/upvote_embed.svg?sanitize=true" alt="Launch YC: Airweave - Let Agents Search Any App" style="margin-left: 12px;" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;â­ &lt;strong&gt;Help us reach more developers and grow the Airweave community. Star this repo!&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Airweave?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.airweave.ai/"&gt;Airweave&lt;/a&gt; is a fully open-source context retrieval layer for AI agents across apps and databases. It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.&lt;/p&gt; 
&lt;p&gt;The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving. You can find our documentation &lt;a href="https://docs.airweave.ai/welcome"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;ğŸ“º Check out a quick demo of Airweave below:&lt;/p&gt; 
&lt;p&gt;
 &lt;video width="100%" src="https://github.com/user-attachments/assets/995e4a36-3f88-4d8e-b401-6ca43db0c7bf" controls&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/airweave-ai/airweave/tree/main/examples"&gt;&lt;strong&gt;ğŸ”— Example notebooks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#airweave"&gt;Airweave&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-supported-integrations"&gt;ğŸ”Œ Supported Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-usage"&gt;ğŸ’» Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#frontend"&gt;Frontend&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#api"&gt;API&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-sdks"&gt;ğŸ“¦ SDKs&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#typescriptjavascript"&gt;TypeScript/JavaScript&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-key-features"&gt;ğŸ”‘ Key Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-tech-stack"&gt;ğŸ”§ Technology Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-contributing"&gt;ğŸ‘¥ Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/#-connect"&gt;ğŸ”— Connect&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Managed Service: &lt;a href="https://app.airweave.ai/"&gt;Airweave Cloud&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;Self-hosted:&lt;/h3&gt; 
&lt;p&gt;Make sure docker and docker-compose are installed, then...&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Access the dashboard at &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ”Œ Supported Integrations&lt;/h2&gt; 
&lt;!-- START_APP_GRID --&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/airtable.svg?sanitize=true" alt="Airtable" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/asana.svg?sanitize=true" alt="Asana" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/attio.svg?sanitize=true" alt="Attio" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/bitbucket.svg?sanitize=true" alt="Bitbucket" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/box.svg?sanitize=true" alt="Box" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/clickup.svg?sanitize=true" alt="ClickUp" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/confluence.svg?sanitize=true" alt="Confluence" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/ctti.svg?sanitize=true" alt="CTTI" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/dropbox.svg?sanitize=true" alt="Dropbox" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/excel.svg?sanitize=true" alt="Excel" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/github.svg?sanitize=true" alt="Github" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gitlab.svg?sanitize=true" alt="Gitlab" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/gmail.svg?sanitize=true" alt="Gmail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_calendar.svg?sanitize=true" alt="Google Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_docs.svg?sanitize=true" alt="Google Docs" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_drive.svg?sanitize=true" alt="Google Drive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/google_slides.svg?sanitize=true" alt="Google Slides" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/hubspot.svg?sanitize=true" alt="Hubspot" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/jira.svg?sanitize=true" alt="Jira" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/linear.svg?sanitize=true" alt="Linear" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/monday.svg?sanitize=true" alt="Monday" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/notion.svg?sanitize=true" alt="Notion" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onedrive.svg?sanitize=true" alt="Onedrive" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/onenote.svg?sanitize=true" alt="OneNote" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_calendar.svg?sanitize=true" alt="Outlook Calendar" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/outlook_mail.svg?sanitize=true" alt="Outlook Mail" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/postgresql.svg?sanitize=true" alt="Postgresql" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/salesforce.svg?sanitize=true" alt="Salesforce" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/sharepoint.svg?sanitize=true" alt="Sharepoint" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/slack.svg?sanitize=true" alt="Slack" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/stripe.svg?sanitize=true" alt="Stripe" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/teams.svg?sanitize=true" alt="Teams" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/todoist.svg?sanitize=true" alt="Todoist" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/trello.svg?sanitize=true" alt="Trello" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/word.svg?sanitize=true" alt="Word" width="50" height="50" style="margin: 8px;" /&gt; &lt;img src="https://raw.githubusercontent.com/airweave-ai/airweave/main/frontend/src/components/icons/apps/zendesk.svg?sanitize=true" alt="Zendesk" width="50" height="50" style="margin: 8px;" /&gt; &lt;/p&gt; 
&lt;!-- END_APP_GRID --&gt; 
&lt;h2&gt;ğŸ’» Usage&lt;/h2&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Access the UI at &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Connect sources, configure syncs, and query data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swagger docs: &lt;code&gt;http://localhost:8001/docs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create connections, trigger syncs, and search data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ SDKs&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install airweave-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from airweave import AirweaveSDK

# Initialize client
client = AirweaveSDK(
    api_key="YOUR_API_KEY",
    base_url="http://localhost:8001"
)

# Create a collection
collection = client.collections.create(name="My Collection")

# Add a source connection
source = client.source_connections.create(
    name="My Stripe Connection",
    short_name="stripe",
    readable_collection_id=collection.readable_id,
    authentication={
        "credentials": {"api_key": "your_stripe_api_key"}
    }
)

# Semantic search (default)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="Find recent failed payments"
)

# Hybrid search (semantic + keyword)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="customer invoices Q4 2024",
    search_type="hybrid"
)

# With query expansion and reranking
results = client.collections.search(
    readable_id=collection.readable_id,
    query="technical documentation",
    enable_query_expansion=True,
    enable_reranking=True,
    top_k=20
)

# Search with recency bias (prioritize recent results)
results = client.collections.search(
    readable_id=collection.readable_id,
    query="critical bugs",
    recency_bias=0.8,  # 0.0 to 1.0, higher = more recent
    limit=10
)

# Get AI-generated answer instead of raw results
answer = client.collections.search(
    readable_id=collection.readable_id,
    query="What are our customer refund policies?",
    response_type="completion",
    enable_reranking=True
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @airweave/sdk
# or
yarn add @airweave/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AirweaveSDKClient, AirweaveSDKEnvironment } from "@airweave/sdk";

// Initialize client
const client = new AirweaveSDKClient({
    apiKey: "YOUR_API_KEY",
    environment: AirweaveSDKEnvironment.Local
});

// Create a collection
const collection = await client.collections.create({
    name: "My Collection"
});

// Add a source connection
const source = await client.sourceConnections.create({
    name: "My Stripe Connection",
    shortName: "stripe",
    readableCollectionId: collection.readableId,
    authentication: {
        credentials: { apiKey: "your_stripe_api_key" }
    }
});

// Semantic search (default)
const results = await client.collections.search(
    collection.readableId,
    { query: "Find recent failed payments" }
);

// Hybrid search (semantic + keyword)
const hybridResults = await client.collections.search(
    collection.readableId,
    {
        query: "customer invoices Q4 2024",
        searchType: "hybrid"
    }
);

// With query expansion and reranking
const advancedResults = await client.collections.search(
    collection.readableId,
    {
        query: "technical documentation",
        enableQueryExpansion: true,
        enableReranking: true,
        topK: 20
    }
);

// Search with recency bias (prioritize recent results)
const recentResults = await client.collections.search(
    collection.readableId,
    {
        query: "critical bugs",
        recencyBias: 0.8,  // 0.0 to 1.0, higher = more recent
        limit: 10
    }
);

// Get AI-generated answer instead of raw results
const answer = await client.collections.search(
    collection.readableId,
    {
        query: "What are our customer refund policies?",
        responseType: "completion",
        enableReranking: true
    }
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ”‘ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data synchronization&lt;/strong&gt; from 30+ sources with minimal config&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Entity extraction&lt;/strong&gt; and transformation pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-tenant&lt;/strong&gt; architecture with OAuth2&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental updates&lt;/strong&gt; using content hashing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic search&lt;/strong&gt; for agent queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versioning&lt;/strong&gt; for data changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”§ Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React/TypeScript with ShadCN&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: FastAPI (Python)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL (metadata), Qdrant (vectors)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt;: Temporal (workflow orchestration), Redis (pub/sub)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker Compose (dev), Kubernetes (prod)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please check &lt;a href="https://github.com/airweave-ai/airweave/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;Airweave is released under the &lt;a href="https://raw.githubusercontent.com/airweave-ai/airweave/main/LICENSE"&gt;MIT&lt;/a&gt; license.&lt;/p&gt; 
&lt;h2&gt;ğŸ”— Connect&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.com/invite/484HY9Ehxt"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Get help and discuss features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/airweave-ai/airweave/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://x.com/airweave_ai"&gt;Twitter&lt;/a&gt;&lt;/strong&gt; - Follow for updates&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google/adk-python</title>
      <link>https://github.com/google/adk-python</link>
      <description>&lt;p&gt;An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-python/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/google-adk/"&gt;&lt;img src="https://img.shields.io/pypi/v/google-adk" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/google/adk-python/actions/workflows/python-unit-tests.yml"&gt;&lt;img src="https://github.com/google/adk-python/actions/workflows/python-unit-tests.yml/badge.svg?sanitize=true" alt="Python Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/agentdevelopmentkit/"&gt;&lt;img src="https://img.shields.io/badge/Reddit-r%2Fagentdevelopmentkit-FF4500?style=flat&amp;amp;logo=reddit&amp;amp;logoColor=white" alt="r/agentdevelopmentkit" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/google/adk-python"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt;  
&lt;h2 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/agent-development-kit.png" width="256" /&gt; &lt;/h2&gt; 
&lt;h3 align="center"&gt; An open-source, code-first Python framework for building, evaluating, and deploying sophisticated AI agents with flexibility and control. &lt;/h3&gt; 
&lt;h3 align="center"&gt; Important Links: &lt;a href="https://google.github.io/adk-docs/"&gt;Docs&lt;/a&gt;, &lt;a href="https://github.com/google/adk-samples"&gt;Samples&lt;/a&gt;, &lt;a href="https://github.com/google/adk-java"&gt;Java ADK&lt;/a&gt;, &lt;a href="https://github.com/google/adk-go"&gt;Go ADK&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/google/adk-web"&gt;ADK Web&lt;/a&gt;. &lt;/h3&gt;  
&lt;p&gt;Agent Development Kit (ADK) is a flexible and modular framework that applies software development principles to AI agent creation. It is designed to simplify building, deploying, and orchestrating agent workflows, from simple tasks to complex systems. While optimized for Gemini, ADK is model-agnostic, deployment-agnostic, and compatible with other frameworks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”¥ What's new&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Custom Service Registration&lt;/strong&gt;: Add a service registry to provide a generic way to register custom service implementations to be used in FastAPI server. See &lt;a href="https://github.com/google/adk-python/discussions/3175#discussioncomment-14745120"&gt;short instruction&lt;/a&gt;. (&lt;a href="https://github.com/google/adk-python/commit/391628fcdc7b950c6835f64ae3ccab197163c990"&gt;391628f&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rewind&lt;/strong&gt;: Add the ability to rewind a session to before a previous invocation (&lt;a href="https://github.com/google/adk-python/commit/9dce06f9b00259ec42241df4f6638955e783a9d1"&gt;9dce06f&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New CodeExecutor&lt;/strong&gt;: Introduces a new AgentEngineSandboxCodeExecutor class that supports executing agent-generated code using the Vertex AI Code Execution Sandbox API (&lt;a href="https://github.com/google/adk-python/commit/ee39a891106316b790621795b5cc529e89815a98"&gt;ee39a89&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rich Tool Ecosystem&lt;/strong&gt;: Utilize pre-built tools, custom functions, OpenAPI specs, MCP tools or integrate existing tools to give agents diverse capabilities, all for tight integration with the Google ecosystem.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Code-First Development&lt;/strong&gt;: Define agent logic, tools, and orchestration directly in Python for ultimate flexibility, testability, and versioning.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agent Config&lt;/strong&gt;: Build agents without code. Check out the &lt;a href="https://google.github.io/adk-docs/agents/config/"&gt;Agent Config&lt;/a&gt; feature.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Confirmation&lt;/strong&gt;: A &lt;a href="https://google.github.io/adk-docs/tools/confirmation/"&gt;tool confirmation flow(HITL)&lt;/a&gt; that can guard tool execution with explicit confirmation and custom input.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modular Multi-Agent Systems&lt;/strong&gt;: Design scalable applications by composing multiple specialized agents into flexible hierarchies.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy Anywhere&lt;/strong&gt;: Easily containerize and deploy agents on Cloud Run or scale seamlessly with Vertex AI Agent Engine.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Installation&lt;/h2&gt; 
&lt;h3&gt;Stable Release (Recommended)&lt;/h3&gt; 
&lt;p&gt;You can install the latest stable version of ADK using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install google-adk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The release cadence is roughly bi-weekly.&lt;/p&gt; 
&lt;p&gt;This version is recommended for most users as it represents the most recent official release.&lt;/p&gt; 
&lt;h3&gt;Development Version&lt;/h3&gt; 
&lt;p&gt;Bug fixes and new features are merged into the main branch on GitHub first. If you need access to changes that haven't been included in an official PyPI release yet, you can install directly from the main branch:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/google/adk-python.git@main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: The development version is built directly from the latest code commits. While it includes the newest fixes and features, it may also contain experimental changes or bugs not present in the stable release. Use it primarily for testing upcoming changes or accessing critical fixes before they are officially released.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤– Agent2Agent (A2A) Protocol and ADK Integration&lt;/h2&gt; 
&lt;p&gt;For remote agent-to-agent communication, ADK integrates with the &lt;a href="https://github.com/google-a2a/A2A/"&gt;A2A protocol&lt;/a&gt;. See this &lt;a href="https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents"&gt;example&lt;/a&gt; for how they can work together.&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;p&gt;Explore the full documentation for detailed guides on building, evaluating, and deploying agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://google.github.io/adk-docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ Feature Highlight&lt;/h2&gt; 
&lt;h3&gt;Define a single agent:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google.adk.agents import Agent
from google.adk.tools import google_search

root_agent = Agent(
    name="search_assistant",
    model="gemini-2.5-flash", # Or your preferred Gemini model
    instruction="You are a helpful assistant. Answer user questions using Google Search when needed.",
    description="An assistant that can search the web.",
    tools=[google_search]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Define a multi-agent system:&lt;/h3&gt; 
&lt;p&gt;Define a multi-agent system with coordinator agent, greeter agent, and task execution agent. Then ADK engine and the model will guide the agents works together to accomplish the task.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from google.adk.agents import LlmAgent, BaseAgent

# Define individual agents
greeter = LlmAgent(name="greeter", model="gemini-2.5-flash", ...)
task_executor = LlmAgent(name="task_executor", model="gemini-2.5-flash", ...)

# Create parent agent and assign children via sub_agents
coordinator = LlmAgent(
    name="Coordinator",
    model="gemini-2.5-flash",
    description="I coordinate greetings and tasks.",
    sub_agents=[ # Assign sub_agents here
        greeter,
        task_executor
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development UI&lt;/h3&gt; 
&lt;p&gt;A built-in development UI to help you test, evaluate, debug, and showcase your agent(s).&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/google/adk-python/main/assets/adk-web-dev-ui-function-call.png" /&gt; 
&lt;h3&gt;Evaluate Agents&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;adk eval \
    samples_for_testing/hello_world \
    samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://google.github.io/adk-docs/contributing-guide/"&gt;General contribution guideline and flow&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Then if you want to contribute code, please read &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/CONTRIBUTING.md"&gt;Code Contributing Guidelines&lt;/a&gt; to get started.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community Repo&lt;/h2&gt; 
&lt;p&gt;We have &lt;a href="https://github.com/google/adk-python-community"&gt;adk-python-community repo&lt;/a&gt;that is home to a growing ecosystem of community-contributed tools, third-party service integrations, and deployment scripts that extend the core capabilities of the ADK.&lt;/p&gt; 
&lt;h2&gt;Vibe Coding&lt;/h2&gt; 
&lt;p&gt;If you are to develop agent via vibe coding the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/llms.txt"&gt;llms.txt&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/llms-full.txt"&gt;llms-full.txt&lt;/a&gt; can be used as context to LLM. While the former one is a summarized one and the later one has the full information in case your LLM has big enough context window.&lt;/p&gt; 
&lt;h2&gt;Community Events&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Completed] ADK's 1st community meeting on Wednesday, October 15, 2025. Remember to &lt;a href="https://groups.google.com/g/adk-community"&gt;join our group&lt;/a&gt; to get access to the &lt;a href="https://drive.google.com/file/d/1rpXDq5NSH8-MyMeYI6_5pZ3Lhn0X9BQf/view"&gt;recording&lt;/a&gt;, and &lt;a href="https://docs.google.com/presentation/d/1_b8LG4xaiadbUUDzyNiapSFyxanc9ZgFdw7JQ6zmZ9Q/edit?slide=id.g384e60cdaca_0_658&amp;amp;resourcekey=0-tjFFv0VBQhpXBPCkZr0NOg#slide=id.g384e60cdaca_0_658"&gt;deck&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/google/adk-python/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Happy Agent Building!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/ä¸­æ–‡-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="ä¸­æ–‡" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸš€ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;âš¡ Fast command-line workflow&lt;br /&gt;ğŸ”§ Developer-friendly interface&lt;br /&gt;ğŸ“Š Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸ¨ Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;ğŸ–±ï¸ Intuitive drag-and-drop&lt;br /&gt;ğŸ“± Responsive design&lt;br /&gt;ğŸ¯ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;ğŸ¬ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;ğŸ¯ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/â–¶ï¸_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;ğŸ“° News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;ğŸ—ï¸ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;ğŸ“Š Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;ğŸ’¡ Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;ğŸ¬ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“° News&lt;/h2&gt; 
&lt;p&gt;ğŸ‰ &lt;strong&gt;[2025-10] ğŸ‰ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ† &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ğŸ¥‡ &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;ğŸ”¬ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸš€ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸ¨ &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;âš™ï¸ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“Š Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;â‘  ğŸ§  Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;â‘¡ ğŸ’¼ State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;â€”rather than base model capabilityâ€”drives this performance gap.&lt;/p&gt; 
&lt;h3&gt;â‘¢ ğŸ”¬ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;â‘£ ğŸ¤– LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“„ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¬ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;â±ï¸ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”„ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["ğŸ“„ Research Papers&amp;lt;br/&amp;gt;ğŸ’¬ Text Prompts&amp;lt;br/&amp;gt;ğŸŒ URLs &amp;amp; Document&amp;lt;br/&amp;gt;ğŸ“ Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["ğŸ§  DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["ğŸš€ Algorithm Implementation &amp;lt;br/&amp;gt;ğŸ¨ Frontend Development &amp;lt;br/&amp;gt;âš™ï¸ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;ğŸ¯ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;ğŸ§¬ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ğŸª„ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;âš¡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;ğŸ’ &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;ğŸ”® &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ”§ &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ” &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¤– &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“„ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“š Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§¬ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”§ Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;ğŸ“¡ &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ”§ &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ’¡ &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ” brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‚ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“¥ github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‹ file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš¡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ§¬ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“š code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;ğŸ”§ &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ¯ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âœï¸ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš™ï¸ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“Š get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ›ï¸ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ğŸŒŸ &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ğŸ’¡ &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; ğŸ“„ Research Papers â€¢ ğŸ’¬ Natural Language â€¢ ğŸŒ URLs â€¢ ğŸ“‹ Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ¯ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making â€¢ Workflow Coordination â€¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“ &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“„ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ“‹ &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis â€¢ Code Requirements Parsing â€¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ” &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“š &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ§¬ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation â€¢ Testing â€¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; âš¡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; ğŸ“¦ Complete Codebase â€¢ ğŸ§ª Test Suite â€¢ ğŸ“š Documentation â€¢ ğŸš€ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ”„ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;ğŸ¯ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;ğŸ§  Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;ğŸ” Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;âš¡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸš€ Install DeepCode package directly
pip install deepcode-hku

# ğŸ”‘ Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‚ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;ğŸ”¥ &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# ğŸ”§ Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;ğŸ &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ğŸªŸ &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ğŸ” &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸŒ Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš¡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸŒ Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“„ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’¡ Examples&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ“„ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ–¼ï¸ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;ğŸ†• &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸ“„ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“Š &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/ğŸš€_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/ğŸ›ï¸_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/â­_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ğŸ“„ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>yichuan-w/LEANN</title>
      <link>https://github.com/yichuan-w/LEANN</link>
      <description>&lt;p&gt;RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/logo-text.png" alt="LEANN Logo" width="400" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue.svg?sanitize=true" alt="Python Versions" /&gt; &lt;img src="https://github.com/yichuan-w/LEANN/actions/workflows/build-and-publish.yml/badge.svg?sanitize=true" alt="CI Status" /&gt; &lt;img src="https://img.shields.io/badge/Platform-Ubuntu%20%26%20Arch%20%26%20WSL%20%7C%20macOS%20(ARM64%2FIntel)-lightgrey" alt="Platform" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="MIT License" /&gt; &lt;img src="https://img.shields.io/badge/MCP-Native%20Integration-blue" alt="MCP Integration" /&gt; &lt;a href="https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ckd2f6w1-OX08~NN4gkWhh10PRVBj1Q"&gt; &lt;img src="https://img.shields.io/badge/Slack-Join-4A154B?logo=slack&amp;amp;logoColor=white" alt="Join Slack" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/wechat_user_group.JPG" title="Join WeChat group"&gt; &lt;img src="https://img.shields.io/badge/WeChat-Join-2DC100?logo=wechat&amp;amp;logoColor=white" alt="Join WeChat group" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2 align="center" tabindex="-1" class="heading-element" dir="auto"&gt; The smallest vector index in the world. RAG Everything with LEANN! &lt;/h2&gt; 
&lt;p&gt;LEANN is an innovative vector database that democratizes personal AI. Transform your laptop into a powerful RAG system that can index and search through millions of documents while using &lt;strong&gt;97% less storage&lt;/strong&gt; than traditional solutions &lt;strong&gt;without accuracy loss&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;LEANN achieves this through &lt;em&gt;graph-based selective recomputation&lt;/em&gt; with &lt;em&gt;high-degree preserving pruning&lt;/em&gt;, computing embeddings on-demand instead of storing them all. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#%EF%B8%8F-architecture--how-it-works"&gt;Illustration Fig â†’&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2506.08276"&gt;Paper â†’&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ready to RAG Everything?&lt;/strong&gt; Transform your laptop into a personal AI assistant that can semantic search your &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-personal-data-manager-process-any-documents-pdf-txt-md"&gt;file system&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-your-personal-email-secretary-rag-on-apple-mail"&gt;emails&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-time-machine-for-the-web-rag-your-entire-browser-history"&gt;browser history&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;chat history&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-wechat-detective-unlock-your-golden-memories"&gt;WeChat&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-imessage-history-your-personal-conversation-archive"&gt;iMessage&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;agent memory&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-chatgpt-chat-history-your-personal-ai-conversation-archive"&gt;ChatGPT&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-chat-history-your-personal-ai-conversation-archive"&gt;Claude&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;live data&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;Slack&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#mcp-integration-rag-on-live-data-from-any-platform"&gt;Twitter&lt;/a&gt;), &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-claude-code-integration-transform-your-development-workflow"&gt;codebase&lt;/a&gt;&lt;/strong&gt;* , or external knowledge bases (i.e., 60M documents) - all on your laptop, with zero cloud costs and complete privacy.&lt;/p&gt; 
&lt;p&gt;* Claude Code only supports basic &lt;code&gt;grep&lt;/code&gt;-style keyword search. &lt;strong&gt;LEANN&lt;/strong&gt; is a drop-in &lt;strong&gt;semantic search MCP service fully compatible with Claude Code&lt;/strong&gt;, unlocking intelligent retrieval without changing your workflow. ğŸ”¥ Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;the easy setup â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why LEANN?&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/effects.png" alt="LEANN vs Traditional Vector DB Storage Comparison" width="70%" /&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;The numbers speak for themselves:&lt;/strong&gt; Index 60 million text chunks in just 6GB instead of 201GB. From emails to browser history, everything fits on your laptop. &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/#-storage-comparison"&gt;See detailed benchmarks for different applications below â†“&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ğŸ”’ &lt;strong&gt;Privacy:&lt;/strong&gt; Your data never leaves your laptop. No OpenAI, no cloud, no "terms of service".&lt;/p&gt; 
&lt;p&gt;ğŸª¶ &lt;strong&gt;Lightweight:&lt;/strong&gt; Graph-based recomputation eliminates heavy embedding storage, while smart graph pruning and CSR format minimize graph storage overhead. Always less storage, less memory usage!&lt;/p&gt; 
&lt;p&gt;ğŸ“¦ &lt;strong&gt;Portable:&lt;/strong&gt; Transfer your entire knowledge base between devices (even with others) with minimal cost - your personal AI memory travels with you.&lt;/p&gt; 
&lt;p&gt;ğŸ“ˆ &lt;strong&gt;Scalability:&lt;/strong&gt; Handle messy personal data that would crash traditional vector DBs, easily managing your growing personalized data and agent generated memory!&lt;/p&gt; 
&lt;p&gt;âœ¨ &lt;strong&gt;No Accuracy Loss:&lt;/strong&gt; Maintain the same search quality as heavyweight solutions while using 97% less storage.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ Prerequisites: Install uv&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.astral.sh/uv/getting-started/installation/#installation-methods"&gt;Install uv&lt;/a&gt; first if you don't have it. Typically, you can install it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸš€ Quick Install&lt;/h3&gt; 
&lt;p&gt;Clone the repository to access all examples and try amazing applications,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and install LEANN from &lt;a href="https://pypi.org/project/leann/"&gt;PyPI&lt;/a&gt; to run them immediately:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv
source .venv/bin/activate
uv pip install leann
&lt;/code&gt;&lt;/pre&gt; 
&lt;!--
&gt; Low-resource? See "Low-resource setups" in the [Configuration Guide](docs/configuration-guide.md#low-resource-setups). --&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;strong&gt;ğŸ”§ Build from Source (Recommended for development)&lt;/strong&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: DiskANN requires MacOS 13.3 or later.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install libomp boost protobuf zeromq pkgconf
uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Ubuntu/Debian):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Note: On Ubuntu 20.04, you may need to build a newer Abseil and pin Protobuf (e.g., v3.20.x) for building DiskANN. See &lt;a href="https://github.com/yichuan-w/LEANN/issues/30"&gt;Issue #30&lt;/a&gt; for a step-by-step note.&lt;/p&gt; 
 &lt;p&gt;You can manually install &lt;a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html"&gt;Intel oneAPI MKL&lt;/a&gt; instead of &lt;code&gt;libmkl-full-dev&lt;/code&gt; for DiskANN. You can also use &lt;code&gt;libopenblas-dev&lt;/code&gt; for building HNSW only, by removing &lt;code&gt;--extra diskann&lt;/code&gt; in the command below.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y \
  libomp-dev libboost-all-dev protobuf-compiler libzmq3-dev \
  pkg-config libabsl-dev libaio-dev libprotobuf-dev \
  libmkl-full-dev

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Arch Linux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo pacman -Syu &amp;amp;&amp;amp; sudo pacman -S --needed base-devel cmake pkgconf git gcc \
  boost boost-libs protobuf abseil-cpp libaio zeromq

# For MKL in DiskANN
sudo pacman -S --needed base-devel git
git clone https://aur.archlinux.org/paru-bin.git
cd paru-bin &amp;amp;&amp;amp; makepkg -si
paru -S intel-oneapi-mkl intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (RHEL / CentOS Stream / Oracle / Rocky / AlmaLinux):&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/yichuan-w/LEANN/issues/50"&gt;Issue #50&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo dnf groupinstall -y "Development Tools"
sudo dnf install -y libomp-devel boost-devel protobuf-compiler protobuf-devel \
  abseil-cpp-devel libaio-devel zeromq-devel pkgconf-pkg-config

# For MKL in DiskANN
sudo dnf install -y intel-oneapi-mkl intel-oneapi-mkl-devel \
  intel-oneapi-openmp || sudo dnf install -y intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Our declarative API makes RAG as easy as writing a config file.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/demo.ipynb"&gt;demo.ipynb&lt;/a&gt; or &lt;a href="https://colab.research.google.com/github/yichuan-w/LEANN/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from leann import LeannBuilder, LeannSearcher, LeannChat
from pathlib import Path
INDEX_PATH = str(Path("./").resolve() / "demo.leann")

# Build an index
builder = LeannBuilder(backend_name="hnsw")
builder.add_text("LEANN saves 97% storage compared to traditional vector databases.")
builder.add_text("Tung Tung Tung Sahur calledâ€”they need their bananaâ€‘crocodile hybrid back")
builder.build_index(INDEX_PATH)

# Search
searcher = LeannSearcher(INDEX_PATH)
results = searcher.search("fantastical AI-generated creatures", top_k=1)

# Chat with your data
chat = LeannChat(INDEX_PATH, llm_config={"type": "hf", "model": "Qwen/Qwen3-0.6B"})
response = chat.ask("How much storage does LEANN save?", top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;RAG on Everything!&lt;/h2&gt; 
&lt;p&gt;LEANN supports RAG on various data sources including documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;), Apple Mail, Google Search History, WeChat, ChatGPT conversations, Claude conversations, iMessage conversations, and &lt;strong&gt;live data from any platform through MCP (Model Context Protocol) servers&lt;/strong&gt; - including Slack, Twitter, and more.&lt;/p&gt; 
&lt;h3&gt;Generation Model Setup&lt;/h3&gt; 
&lt;h4&gt;LLM Backend&lt;/h4&gt; 
&lt;p&gt;LEANN supports many LLM providers for text generation (HuggingFace, Ollama, and Any OpenAI compatible API).&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ”‘ OpenAI API Setup (Default)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Set your OpenAI API key as an environment variable:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag when using the CLI. You can also specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ› ï¸ Supported LLM &amp;amp; Embedding Providers (via OpenAI Compatibility)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Thanks to the widespread adoption of the OpenAI API format, LEANN is compatible out-of-the-box with a vast array of LLM and embedding providers. Simply set the &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; and &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; environment variables to connect to your preferred service.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export OPENAI_API_KEY="xxx"
export OPENAI_BASE_URL="http://localhost:1234/v1" # base url of the provider
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To use OpenAI compatible endpoint with the CLI interface:&lt;/p&gt; 
 &lt;p&gt;If you are using it for text generation, make sure to use &lt;code&gt;--llm openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--llm-model &amp;lt;model-name&amp;gt;&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;p&gt;If you are using it for embedding, set the &lt;code&gt;--embedding-mode openai&lt;/code&gt; flag and specify the model name with &lt;code&gt;--embedding-model &amp;lt;MODEL&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;Below is a list of base URLs for common providers to get you started.&lt;/p&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ Local Inference Engines (Recommended for full privacy)&lt;/h3&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Sample Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:11434/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:1234/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:8080/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SGLang&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:30000/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;LiteLLM&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;http://localhost:4000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;â˜ï¸ Cloud Providers&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;ğŸš¨ A Note on Privacy:&lt;/strong&gt; Before choosing a cloud provider, carefully review their privacy and data retention policies. Depending on their terms, your data may be used for their own purposes, including but not limited to human reviews and model training, which can lead to serious consequences if not handled properly.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Provider&lt;/th&gt; 
    &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://openrouter.ai/api/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Gemini&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://generativelanguage.googleapis.com/v1beta/openai/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;x.AI (Grok)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.x.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Groq AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.groq.com/openai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.deepseek.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;SiliconFlow&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.siliconflow.cn/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Zhipu (BigModel)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://open.bigmodel.cn/api/paas/v4/&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Mistral AI&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;https://api.mistral.ai/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;If your provider isn't on this list, don't worry! Check their documentation for an OpenAI-compatible endpointâ€”chances are, it's OpenAI Compatible too!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ”§ Ollama Setup (Recommended for full privacy)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;First, &lt;a href="https://ollama.com/download/mac"&gt;download Ollama for macOS&lt;/a&gt;.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service manually
ollama serve &amp;amp;

# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;â­ Flexible Configuration&lt;/h2&gt; 
&lt;p&gt;LEANN provides flexible parameters for embedding models, search strategies, and data processing to fit your specific needs.&lt;/p&gt; 
&lt;p&gt;ğŸ“š &lt;strong&gt;Need configuration best practices?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/configuration-guide.md"&gt;Configuration Guide&lt;/a&gt; for detailed optimization tips, model selection advice, and solutions to common issues like slow embeddings or poor search quality.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Common Parameters (Available in All Examples)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;All RAG examples share these common parameters. &lt;strong&gt;Interactive mode&lt;/strong&gt; is available in all examples - simply run without &lt;code&gt;--query&lt;/code&gt; to start a continuous Q&amp;amp;A session where you can ask multiple questions. Type 'quit' to exit.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Core Parameters (General preprocessing for all examples)
--index-dir DIR              # Directory to store the index (default: current directory)
--query "YOUR QUESTION"      # Single query mode. Omit for interactive chat (type 'quit' to exit), and now you can play with your index interactively
--max-items N                # Limit data preprocessing (default: -1, process all data)
--force-rebuild              # Force rebuild index even if it exists

# Embedding Parameters
--embedding-model MODEL      # e.g., facebook/contriever, text-embedding-3-small, mlx-community/Qwen3-Embedding-0.6B-8bit or nomic-embed-text
--embedding-mode MODE        # sentence-transformers, openai, mlx, or ollama

# LLM Parameters (Text generation models)
--llm TYPE                   # LLM backend: openai, ollama, or hf (default: openai)
--llm-model MODEL            # Model name (default: gpt-4o) e.g., gpt-4o-mini, llama3.2:1b, Qwen/Qwen2.5-1.5B-Instruct
--thinking-budget LEVEL      # Thinking budget for reasoning models: low/medium/high (supported by o3, o3-mini, GPT-Oss:20b, and other reasoning models)

# Search Parameters
--top-k N                    # Number of results to retrieve (default: 20)
--search-complexity N        # Search complexity for graph traversal (default: 32)

# Chunking Parameters
--chunk-size N               # Size of text chunks (default varies by source: 256 for most, 192 for WeChat)
--chunk-overlap N            # Overlap between chunks (default varies: 25-128 depending on source)

# Index Building Parameters
--backend-name NAME          # Backend to use: hnsw or diskann (default: hnsw)
--graph-degree N             # Graph degree for index construction (default: 32)
--build-complexity N         # Build complexity for index construction (default: 64)
--compact / --no-compact     # Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
--recompute / --no-recompute # Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ“„ Personal Data Manager: Process Any Documents (&lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.md&lt;/code&gt;)!&lt;/h3&gt; 
&lt;p&gt;Ask questions directly about your personal PDFs, documents, and any directory containing your files!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/paper_clear.gif" alt="LEANN Document Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;The example below asks a question about summarizing our paper (uses default data in &lt;code&gt;data/&lt;/code&gt;, which is a directory with diverse data sources: two papers, Pride and Prejudice, and a Technical report about LLM in Huawei in Chinese), and this is the &lt;strong&gt;easiest example&lt;/strong&gt; to run here:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate # Don't forget to activate the virtual environment
python -m apps.document_rag --query "What are the main techniques LEANN explores?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Document-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--data-dir DIR           # Directory containing documents to process (default: data)
--file-types .ext .ext   # Filter by specific file types (optional - all LlamaIndex supported types if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Process all documents with larger chunks for academic papers
python -m apps.document_rag --data-dir "~/Documents/Papers" --chunk-size 1024

# Filter only markdown and Python files with smaller chunks
python -m apps.document_rag --data-dir "./docs" --chunk-size 256 --file-types .md .py

# Enable AST-aware chunking for code files
python -m apps.document_rag --enable-code-chunking --data-dir "./my_project"

# Or use the specialized code RAG for better code understanding
python -m apps.code_rag --repo-dir "./my_codebase" --query "How does authentication work?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ“§ Your Personal Email Secretary: RAG on Apple Mail!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The examples below currently support macOS only. Windows support coming soon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/mail_clear.gif" alt="LEANN Email Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Before running the example below, you need to grant full disk access to your terminal/VS Code in System Preferences â†’ Privacy &amp;amp; Security â†’ Full Disk Access.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.email_rag --query "What's the food I ordered by DoorDash or Uber Eats mostly?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;780K email chunks â†’ 78MB storage.&lt;/strong&gt; Finally, search your email like you search Google.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Email-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--mail-path PATH         # Path to specific mail directory (auto-detects if omitted)
--include-html          # Include HTML content in processing (useful for newsletters)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search work emails from a specific account
python -m apps.email_rag --mail-path "~/Library/Mail/V10/WORK_ACCOUNT"

# Find all receipts and order confirmations (includes HTML)
python -m apps.email_rag --query "receipt order confirmation invoice" --include-html
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Find emails from my boss about deadlines"&lt;/li&gt; 
  &lt;li&gt;"What did John say about the project timeline?"&lt;/li&gt; 
  &lt;li&gt;"Show me emails about travel expenses"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ” Time Machine for the Web: RAG Your Entire Chrome Browser History!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/google_clear.gif" alt="LEANN Browser History Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.browser_rag --query "Tell me my browser history about machine learning?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;38K browser entries â†’ 6MB storage.&lt;/strong&gt; Your browser history becomes your personal search engine.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Browser-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--chrome-profile PATH    # Path to Chrome profile directory (auto-detects if omitted)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search academic research from your browsing history
python -m apps.browser_rag --query "arxiv papers machine learning transformer architecture"

# Track competitor analysis across work profile
python -m apps.browser_rag --chrome-profile "~/Library/Application Support/Google/Chrome/Work Profile" --max-items 5000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: How to find your Chrome profile&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The default Chrome profile path is configured for a typical macOS setup. If you need to find your specific Chrome profile:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Open Terminal&lt;/li&gt; 
  &lt;li&gt;Run: &lt;code&gt;ls ~/Library/Application\ Support/Google/Chrome/&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Look for folders like "Default", "Profile 1", "Profile 2", etc.&lt;/li&gt; 
  &lt;li&gt;Use the full path as your &lt;code&gt;--chrome-profile&lt;/code&gt; argument&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Common Chrome profile locations:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS: &lt;code&gt;~/Library/Application Support/Google/Chrome/Default&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Linux: &lt;code&gt;~/.config/google-chrome/Default&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¬ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What websites did I visit about machine learning?"&lt;/li&gt; 
  &lt;li&gt;"Find my search history about programming"&lt;/li&gt; 
  &lt;li&gt;"What YouTube videos did I watch recently?"&lt;/li&gt; 
  &lt;li&gt;"Show me websites I visited about travel planning"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ’¬ WeChat Detective: Unlock Your Golden Memories!&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/videos/wechat_clear.gif" alt="LEANN WeChat Search Demo" width="600" /&gt; &lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.wechat_rag --query "Show me all group chats about weekend plans"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;400K messages â†’ 64MB storage&lt;/strong&gt; Search years of chat history in any language.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ”§ Click to expand: Installation Requirements&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;First, you need to install the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI"&gt;WeChat exporter&lt;/a&gt;,&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install sunnyyoung/repo/wechattweak-cli
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;or install it manually (if you have issues with Homebrew):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo packages/wechat-exporter/wechattweak-cli install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Troubleshooting:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Installation issues&lt;/strong&gt;: Check the &lt;a href="https://github.com/sunnyyoung/WeChatTweak-CLI/issues/41"&gt;WeChatTweak-CLI issues page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Export errors&lt;/strong&gt;: If you encounter the error below, try restarting WeChat &lt;pre&gt;&lt;code class="language-bash"&gt;Failed to export WeChat data. Please ensure WeChat is running and WeChatTweak is installed.
Failed to find or export WeChat data. Exiting.
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: WeChat-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-dir DIR         # Directory to store exported WeChat data (default: wechat_export_direct)
--force-export          # Force re-export even if data exists
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Search for travel plans discussed in group chats
python -m apps.wechat_rag --query "travel plans" --max-items 10000

# Re-export and search recent chats (useful after new messages)
python -m apps.wechat_rag --force-export --query "work schedule"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¬ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once the index is built, you can ask questions like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"æˆ‘æƒ³ä¹°é­”æœ¯å¸ˆçº¦ç¿°é€Šçš„çƒè¡£ï¼Œç»™æˆ‘ä¸€äº›å¯¹åº”èŠå¤©è®°å½•?" (Chinese: Show me chat records about buying Magic Johnson's jersey)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ¤– ChatGPT Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your ChatGPT conversations into a searchable knowledge base! Search through all your ChatGPT discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.chatgpt_rag --export-path chatgpt_export.html --query "How do I create a list in Python?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your ChatGPT discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: How to Export ChatGPT Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Sign in to ChatGPT&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click your profile icon&lt;/strong&gt; in the top right corner&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; â†’ &lt;strong&gt;Data Controls&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Click "Export"&lt;/strong&gt; under Export Data&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Confirm the export&lt;/strong&gt; request&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download the ZIP file&lt;/strong&gt; from the email link (expires in 24 hours)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Extract or use directly&lt;/strong&gt; with LEANN&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.html&lt;/code&gt; files from ChatGPT exports&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives from ChatGPT&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: ChatGPT-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to ChatGPT export file (.html/.zip) or directory (default: ./chatgpt_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with HTML export
python -m apps.chatgpt_rag --export-path conversations.html

# Process ZIP archive from ChatGPT
python -m apps.chatgpt_rag --export-path chatgpt_export.zip

# Search with specific query
python -m apps.chatgpt_rag --export-path chatgpt_data.html --query "Python programming help"

# Process individual messages for fine-grained search
python -m apps.chatgpt_rag --separate-messages --export-path chatgpt_export.html

# Process directory containing multiple exports
python -m apps.chatgpt_rag --export-path ./chatgpt_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¡ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your ChatGPT conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask ChatGPT about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about web development frameworks"&lt;/li&gt; 
  &lt;li&gt;"What coding advice did ChatGPT give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about debugging techniques"&lt;/li&gt; 
  &lt;li&gt;"Find ChatGPT's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ¤– Claude Chat History: Your Personal AI Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your Claude conversations into a searchable knowledge base! Search through all your Claude discussions about coding, research, brainstorming, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.claude_rag --export-path claude_export.json --query "What did I ask about Python dictionaries?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your AI conversation history.&lt;/strong&gt; Never lose track of valuable insights from your Claude discussions again.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: How to Export Claude Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Step-by-step export process:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Open Claude&lt;/strong&gt; in your browser&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Navigate to Settings&lt;/strong&gt; (look for gear icon or settings menu)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Find Export/Download&lt;/strong&gt; options in your account settings&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Download conversation data&lt;/strong&gt; (usually in JSON format)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Place the file&lt;/strong&gt; in your project directory&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;em&gt;Note: Claude export methods may vary depending on the interface you're using. Check Claude's help documentation for the most current export instructions.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.json&lt;/code&gt; files (recommended)&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;.zip&lt;/code&gt; archives containing JSON data&lt;/li&gt; 
  &lt;li&gt;Directories with multiple export files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Claude-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--export-path PATH           # Path to Claude export file (.json/.zip) or directory (default: ./claude_export)
--separate-messages         # Process each message separately instead of concatenated conversations
--chunk-size N              # Text chunk size (default: 512)
--chunk-overlap N           # Overlap between chunks (default: 128)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage with JSON export
python -m apps.claude_rag --export-path my_claude_conversations.json

# Process ZIP archive from Claude
python -m apps.claude_rag --export-path claude_export.zip

# Search with specific query
python -m apps.claude_rag --export-path claude_data.json --query "machine learning advice"

# Process individual messages for fine-grained search
python -m apps.claude_rag --separate-messages --export-path claude_export.json

# Process directory containing multiple exports
python -m apps.claude_rag --export-path ./claude_exports/ --max-items 1000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¡ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your Claude conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did I ask Claude about Python programming?"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about machine learning algorithms"&lt;/li&gt; 
  &lt;li&gt;"Find discussions about software architecture patterns"&lt;/li&gt; 
  &lt;li&gt;"What debugging advice did Claude give me?"&lt;/li&gt; 
  &lt;li&gt;"Search for conversations about data structures"&lt;/li&gt; 
  &lt;li&gt;"Find Claude's recommendations for learning resources"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸ’¬ iMessage History: Your Personal Conversation Archive!&lt;/h3&gt; 
&lt;p&gt;Transform your iMessage conversations into a searchable knowledge base! Search through all your text messages, group chats, and conversations with friends, family, and colleagues.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m apps.imessage_rag --query "What did we discuss about the weekend plans?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unlock your message history.&lt;/strong&gt; Never lose track of important conversations, shared links, or memorable moments from your iMessage history.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: How to Access iMessage Data&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;iMessage data location:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;iMessage conversations are stored in a SQLite database on your Mac at:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;~/Library/Messages/chat.db
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important setup requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Grant Full Disk Access&lt;/strong&gt; to your terminal or IDE:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Open &lt;strong&gt;System Preferences&lt;/strong&gt; â†’ &lt;strong&gt;Security &amp;amp; Privacy&lt;/strong&gt; â†’ &lt;strong&gt;Privacy&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Select &lt;strong&gt;Full Disk Access&lt;/strong&gt; from the left sidebar&lt;/li&gt; 
    &lt;li&gt;Click the &lt;strong&gt;+&lt;/strong&gt; button and add your terminal app (Terminal, iTerm2) or IDE (VS Code, etc.)&lt;/li&gt; 
    &lt;li&gt;Restart your terminal/IDE after granting access&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternative: Use a backup database&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;If you have Time Machine backups or manual copies of the database&lt;/li&gt; 
    &lt;li&gt;Use &lt;code&gt;--db-path&lt;/code&gt; to specify a custom location&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Supported formats:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Direct access to &lt;code&gt;~/Library/Messages/chat.db&lt;/code&gt; (default)&lt;/li&gt; 
  &lt;li&gt;Custom database path with &lt;code&gt;--db-path&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Works with backup copies of the database&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: iMessage-Specific Arguments&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h4&gt;Parameters&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;--db-path PATH                    # Path to chat.db file (default: ~/Library/Messages/chat.db)
--concatenate-conversations       # Group messages by conversation (default: True)
--no-concatenate-conversations    # Process each message individually
--chunk-size N                    # Text chunk size (default: 1000)
--chunk-overlap N                 # Overlap between chunks (default: 200)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Example Commands&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Basic usage (requires Full Disk Access)
python -m apps.imessage_rag

# Search with specific query
python -m apps.imessage_rag --query "family dinner plans"

# Use custom database path
python -m apps.imessage_rag --db-path /path/to/backup/chat.db

# Process individual messages instead of conversations
python -m apps.imessage_rag --no-concatenate-conversations

# Limit processing for testing
python -m apps.imessage_rag --max-items 100 --query "weekend"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¡ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Once your iMessage conversations are indexed, you can search with queries like:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did we discuss about vacation plans?"&lt;/li&gt; 
  &lt;li&gt;"Find messages about restaurant recommendations"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations with John about the project"&lt;/li&gt; 
  &lt;li&gt;"Search for shared links about technology"&lt;/li&gt; 
  &lt;li&gt;"Find group chat discussions about weekend events"&lt;/li&gt; 
  &lt;li&gt;"What did mom say about the family gathering?"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;MCP Integration: RAG on Live Data from Any Platform&lt;/h3&gt; 
&lt;p&gt;Connect to live data sources through the Model Context Protocol (MCP). LEANN now supports real-time RAG on platforms like Slack, Twitter, and more through standardized MCP servers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Live Data Access&lt;/strong&gt;: Fetch real-time data without manual exports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standardized Protocol&lt;/strong&gt;: Use any MCP-compatible server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Extension&lt;/strong&gt;: Add new platforms with minimal code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure Access&lt;/strong&gt;: MCP servers handle authentication&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ’¬ Slack Messages: Search Your Team Conversations&lt;/h4&gt; 
&lt;p&gt;Transform your Slack workspace into a searchable knowledge base! Find discussions, decisions, and shared knowledge across all your channels.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test MCP server connection
python -m apps.slack_rag --mcp-server "slack-mcp-server" --test-connection

# Index and search Slack messages
python -m apps.slack_rag \
  --mcp-server "slack-mcp-server" \
  --workspace-name "my-team" \
  --channels general dev-team random \
  --query "What did we decide about the product launch?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ“– Comprehensive Setup Guide&lt;/strong&gt;: For detailed setup instructions, troubleshooting common issues (like "users cache is not ready yet"), and advanced configuration options, see our &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/slack-setup-guide.md"&gt;&lt;strong&gt;Slack Setup Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install a Slack MCP server (e.g., &lt;code&gt;npm install -g slack-mcp-server&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Create a Slack App and get API credentials (see detailed guide above)&lt;/li&gt; 
 &lt;li&gt;Set environment variables: &lt;pre&gt;&lt;code class="language-bash"&gt;export SLACK_BOT_TOKEN="xoxb-your-bot-token"
export SLACK_APP_TOKEN="xapp-your-app-token"  # Optional
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Test connection with &lt;code&gt;--test-connection&lt;/code&gt; flag&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Arguments:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--mcp-server&lt;/code&gt;: Command to start the Slack MCP server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--workspace-name&lt;/code&gt;: Slack workspace name for organization&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--channels&lt;/code&gt;: Specific channels to index (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--concatenate-conversations&lt;/code&gt;: Group messages by channel (default: true)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-messages-per-channel&lt;/code&gt;: Limit messages per channel (default: 100)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-retries&lt;/code&gt;: Maximum retries for cache sync issues (default: 5)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--retry-delay&lt;/code&gt;: Initial delay between retries in seconds (default: 2.0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ¦ Twitter Bookmarks: Your Personal Tweet Library&lt;/h4&gt; 
&lt;p&gt;Search through your Twitter bookmarks! Find that perfect article, thread, or insight you saved for later.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Test MCP server connection
python -m apps.twitter_rag --mcp-server "twitter-mcp-server" --test-connection

# Index and search Twitter bookmarks
python -m apps.twitter_rag \
  --mcp-server "twitter-mcp-server" \
  --max-bookmarks 1000 \
  --query "What AI articles did I bookmark about machine learning?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Setup Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install a Twitter MCP server (e.g., &lt;code&gt;npm install -g twitter-mcp-server&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Get Twitter API credentials: 
  &lt;ul&gt; 
   &lt;li&gt;Apply for a Twitter Developer Account at &lt;a href="https://developer.twitter.com"&gt;developer.twitter.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Create a new app in the Twitter Developer Portal&lt;/li&gt; 
   &lt;li&gt;Generate API keys and access tokens with "Read" permissions&lt;/li&gt; 
   &lt;li&gt;For bookmarks access, you may need Twitter API v2 with appropriate scopes&lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export TWITTER_API_KEY="your-api-key"
export TWITTER_API_SECRET="your-api-secret"
export TWITTER_ACCESS_TOKEN="your-access-token"
export TWITTER_ACCESS_TOKEN_SECRET="your-access-token-secret"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Test connection with &lt;code&gt;--test-connection&lt;/code&gt; flag&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Arguments:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--mcp-server&lt;/code&gt;: Command to start the Twitter MCP server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--username&lt;/code&gt;: Filter bookmarks by username (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--max-bookmarks&lt;/code&gt;: Maximum bookmarks to fetch (default: 1000)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-tweet-content&lt;/code&gt;: Exclude tweet content, only metadata&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-metadata&lt;/code&gt;: Exclude engagement metadata&lt;/li&gt; 
&lt;/ul&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ’¡ Click to expand: Example queries you can try&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Slack Queries:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What did the team discuss about the project deadline?"&lt;/li&gt; 
  &lt;li&gt;"Find messages about the new feature launch"&lt;/li&gt; 
  &lt;li&gt;"Show me conversations about budget planning"&lt;/li&gt; 
  &lt;li&gt;"What decisions were made in the dev-team channel?"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Twitter Queries:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"What AI articles did I bookmark last month?"&lt;/li&gt; 
  &lt;li&gt;"Find tweets about machine learning techniques"&lt;/li&gt; 
  &lt;li&gt;"Show me bookmarked threads about startup advice"&lt;/li&gt; 
  &lt;li&gt;"What Python tutorials did I save?"&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;strong&gt;ğŸ”§ Using MCP with CLI Commands&lt;/strong&gt;&lt;/summary&gt; 
&lt;p&gt;&lt;strong&gt;Want to use MCP data with regular LEANN CLI?&lt;/strong&gt; You can combine MCP apps with CLI commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Step 1: Use MCP app to fetch and index data
python -m apps.slack_rag --mcp-server "slack-mcp-server" --workspace-name "my-team"

# Step 2: The data is now indexed and available via CLI
leann search slack_messages "project deadline"
leann ask slack_messages "What decisions were made about the product launch?"

# Same for Twitter bookmarks
python -m apps.twitter_rag --mcp-server "twitter-mcp-server"
leann search twitter_bookmarks "machine learning articles"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;MCP vs Manual Export:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MCP&lt;/strong&gt;: Live data, automatic updates, requires server setup&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual Export&lt;/strong&gt;: One-time setup, works offline, requires manual data export&lt;/li&gt; 
&lt;/ul&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ”§ Adding New MCP Platforms&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Want to add support for other platforms? LEANN's MCP integration is designed for easy extension:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Find or create an MCP server&lt;/strong&gt; for your platform&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Create a reader class&lt;/strong&gt; following the pattern in &lt;code&gt;apps/slack_data/slack_mcp_reader.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Create a RAG application&lt;/strong&gt; following the pattern in &lt;code&gt;apps/slack_rag.py&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Test and contribute&lt;/strong&gt; back to the community!&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;Popular MCP servers to explore:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitHub repositories and issues&lt;/li&gt; 
  &lt;li&gt;Discord messages&lt;/li&gt; 
  &lt;li&gt;Notion pages&lt;/li&gt; 
  &lt;li&gt;Google Drive documents&lt;/li&gt; 
  &lt;li&gt;And many more in the MCP ecosystem!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ğŸš€ Claude Code Integration: Transform Your Development Workflow!&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ASTâ€‘Aware Code Chunking&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;LEANN features intelligent code chunking that preserves semantic boundaries (functions, classes, methods) for Python, Java, C#, and TypeScript, improving code understanding compared to text-based chunking.&lt;/p&gt; 
 &lt;p&gt;ğŸ“– Read the &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/ast_chunking_guide.md"&gt;AST Chunking Guide â†’&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;The future of code assistance is here.&lt;/strong&gt; Transform your development workflow with LEANN's native MCP integration for Claude Code. Index your entire codebase and get intelligent code assistance directly in your IDE.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Semantic code search&lt;/strong&gt; across your entire project, fully local index and lightweight&lt;/li&gt; 
 &lt;li&gt;ğŸ§  &lt;strong&gt;AST-aware chunking&lt;/strong&gt; preserves code structure (functions, classes)&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Context-aware assistance&lt;/strong&gt; for debugging and development&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Zero-config setup&lt;/strong&gt; with automatic language detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install LEANN globally for MCP integration
uv tool install leann-core --with leann
claude mcp add --scope user leann-server -- leann_mcp
# Setup is automatic - just start using Claude Code!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try our fully agentic pipeline with auto query rewriting, semantic search planning, and more:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/mcp_leann.png" alt="LEANN MCP Integration" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”¥ Ready to supercharge your coding?&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/packages/leann-mcp/README.md"&gt;Complete Setup Guide â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Command Line Interface&lt;/h2&gt; 
&lt;p&gt;LEANN includes a powerful CLI for document processing and search. Perfect for quick document indexing and interactive chat.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;If you followed the Quick Start, &lt;code&gt;leann&lt;/code&gt; is already installed in your virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To make it globally available:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the LEANN CLI globally using uv tool
uv tool install leann-core --with leann


# Now you can use leann from anywhere without activating venv
leann --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Global installation is required for Claude Code integration. The &lt;code&gt;leann_mcp&lt;/code&gt; server depends on the globally available &lt;code&gt;leann&lt;/code&gt; command.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# build from a specific directory, and my_docs is the index name(Here you can also build from multiple dict or multiple files)
leann build my-docs --docs ./your_documents

# Search your documents
leann search my-docs "machine learning concepts"

# Interactive chat with your documents
leann ask my-docs --interactive

# Ask a single question (non-interactive)
leann ask my-docs "Where are prompts configured?"

# List all your indexes
leann list

# Remove an index
leann remove my-docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key CLI features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Auto-detects document formats (PDF, TXT, MD, DOCX, PPTX + code files)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§  AST-aware chunking&lt;/strong&gt; for Python, Java, C#, TypeScript files&lt;/li&gt; 
 &lt;li&gt;Smart text chunking with overlap for all other content&lt;/li&gt; 
 &lt;li&gt;Multiple LLM providers (Ollama, OpenAI, HuggingFace)&lt;/li&gt; 
 &lt;li&gt;Organized index storage in &lt;code&gt;.leann/indexes/&lt;/code&gt; (project-local)&lt;/li&gt; 
 &lt;li&gt;Support for advanced search parameters&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‹ Click to expand: Complete CLI Reference&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;You can use &lt;code&gt;leann --help&lt;/code&gt;, or &lt;code&gt;leann build --help&lt;/code&gt;, &lt;code&gt;leann search --help&lt;/code&gt;, &lt;code&gt;leann ask --help&lt;/code&gt;, &lt;code&gt;leann list --help&lt;/code&gt;, &lt;code&gt;leann remove --help&lt;/code&gt; to get the complete CLI reference.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Build Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann build INDEX_NAME --docs DIRECTORY|FILE [DIRECTORY|FILE ...] [OPTIONS]

Options:
  --backend {hnsw,diskann}     Backend to use (default: hnsw)
  --embedding-model MODEL      Embedding model (default: facebook/contriever)
  --graph-degree N             Graph degree (default: 32)
  --complexity N               Build complexity (default: 64)
  --force                      Force rebuild existing index
  --compact / --no-compact     Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
  --recompute / --no-recompute Enable recomputation (default: true)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Search Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann search INDEX_NAME QUERY [OPTIONS]

Options:
  --top-k N                     Number of results (default: 5)
  --complexity N                Search complexity (default: 64)
  --recompute / --no-recompute  Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
  --pruning-strategy {global,local,proportional}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Ask Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann ask INDEX_NAME [OPTIONS]

Options:
  --llm {ollama,openai,hf}    LLM provider (default: ollama)
  --model MODEL               Model name (default: qwen3:8b)
  --interactive              Interactive chat mode
  --top-k N                  Retrieval count (default: 20)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;List Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann list

# Lists all indexes across all projects with status indicators:
# âœ… - Index is complete and ready to use
# âŒ - Index is incomplete or corrupted
# ğŸ“ - CLI-created index (in .leann/indexes/)
# ğŸ“„ - App-created index (*.leann.meta.json files)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Remove Command:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;leann remove INDEX_NAME [OPTIONS]

Options:
  --force, -f    Force removal without confirmation

# Smart removal: automatically finds and safely removes indexes
# - Shows all matching indexes across projects
# - Requires confirmation for cross-project removal
# - Interactive selection when multiple matches found
# - Supports both CLI and app-created indexes
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸš€ Advanced Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ¯ Metadata Filtering&lt;/h3&gt; 
&lt;p&gt;LEANN supports a simple metadata filtering system to enable sophisticated use cases like document filtering by date/type, code search by file extension, and content management based on custom criteria.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Add metadata during indexing
builder.add_text(
    "def authenticate_user(token): ...",
    metadata={"file_extension": ".py", "lines_of_code": 25}
)

# Search with filters
results = searcher.search(
    query="authentication function",
    metadata_filters={
        "file_extension": {"==": ".py"},
        "lines_of_code": {"&amp;lt;": 100}
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Supported operators&lt;/strong&gt;: &lt;code&gt;==&lt;/code&gt;, &lt;code&gt;!=&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;in&lt;/code&gt;, &lt;code&gt;not_in&lt;/code&gt;, &lt;code&gt;contains&lt;/code&gt;, &lt;code&gt;starts_with&lt;/code&gt;, &lt;code&gt;ends_with&lt;/code&gt;, &lt;code&gt;is_true&lt;/code&gt;, &lt;code&gt;is_false&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ğŸ“– &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/metadata_filtering.md"&gt;Complete Metadata filtering guide â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ” Grep Search&lt;/h3&gt; 
&lt;p&gt;For exact text matching instead of semantic search, use the &lt;code&gt;use_grep&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Exact text search
results = searcher.search("bananaâ€‘crocodile", use_grep=True, top_k=1)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use cases&lt;/strong&gt;: Finding specific code patterns, error messages, function names, or exact phrases where semantic similarity isn't needed.&lt;/p&gt; 
&lt;p&gt;ğŸ“– &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/grep_search.md"&gt;Complete grep search guide â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture &amp;amp; How It Works&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yichuan-w/LEANN/main/assets/arch.png" alt="LEANN Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The magic:&lt;/strong&gt; Most vector DBs store every single embedding (expensive). LEANN stores a pruned graph structure (cheap) and recomputes embeddings only when needed (fast).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Core techniques:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graph-based selective recomputation:&lt;/strong&gt; Only compute embeddings for nodes in the search path&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High-degree preserving pruning:&lt;/strong&gt; Keep important "hub" nodes while removing redundant connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic batching:&lt;/strong&gt; Efficiently batch embedding computations for GPU utilization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Two-level search:&lt;/strong&gt; Smart graph traversal that prioritizes promising nodes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Backends:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HNSW&lt;/strong&gt; (default): Ideal for most datasets with maximum storage savings through full recomputation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DiskANN&lt;/strong&gt;: Advanced option with superior search performance, using PQ-based graph traversal with real-time reranking for the best speed-accuracy trade-off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/diskann_vs_hnsw_speed_comparison.py"&gt;DiskANN vs HNSW Performance Comparison â†’&lt;/a&gt;&lt;/strong&gt; - Compare search performance between both backends&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/benchmarks/compare_faiss_vs_leann.py"&gt;Simple Example: Compare LEANN vs FAISS â†’&lt;/a&gt;&lt;/strong&gt; - See storage savings in action&lt;/p&gt; 
&lt;h3&gt;ğŸ“Š Storage Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;DPR (2.1M)&lt;/th&gt; 
   &lt;th&gt;Wiki (60M)&lt;/th&gt; 
   &lt;th&gt;Chat (400K)&lt;/th&gt; 
   &lt;th&gt;Email (780K)&lt;/th&gt; 
   &lt;th&gt;Browser (38K)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional vector database (e.g., FAISS)&lt;/td&gt; 
   &lt;td&gt;3.8 GB&lt;/td&gt; 
   &lt;td&gt;201 GB&lt;/td&gt; 
   &lt;td&gt;1.8 GB&lt;/td&gt; 
   &lt;td&gt;2.4 GB&lt;/td&gt; 
   &lt;td&gt;130 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LEANN&lt;/td&gt; 
   &lt;td&gt;324 MB&lt;/td&gt; 
   &lt;td&gt;6 GB&lt;/td&gt; 
   &lt;td&gt;64 MB&lt;/td&gt; 
   &lt;td&gt;79 MB&lt;/td&gt; 
   &lt;td&gt;6.4 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Savings&lt;/td&gt; 
   &lt;td&gt;91%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;97%&lt;/td&gt; 
   &lt;td&gt;95%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Reproduce Our Results&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run benchmarks/run_evaluation.py    # Will auto-download evaluation data and run benchmarks
uv run benchmarks/run_evaluation.py benchmarks/data/indices/rpj_wiki/rpj_wiki --num-queries 2000    # After downloading data, you can run the benchmark with our biggest index
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The evaluation script downloads data automatically on first run. The last three results were tested with partial personal data, and you can reproduce them with your own data!&lt;/p&gt; 
&lt;h2&gt;ğŸ”¬ Paper&lt;/h2&gt; 
&lt;p&gt;If you find Leann useful, please cite:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2506.08276"&gt;LEANN: A Low-Storage Vector Index&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{wang2025leannlowstoragevectorindex,
      title={LEANN: A Low-Storage Vector Index},
      author={Yichuan Wang and Shu Liu and Zhifei Li and Yongji Wu and Ziming Mao and Yilong Zhao and Xiao Yan and Zhiying Xu and Yang Zhou and Ion Stoica and Sewon Min and Matei Zaharia and Joseph E. Gonzalez},
      year={2025},
      eprint={2506.08276},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2506.08276},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;âœ¨ &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/features.md"&gt;Detailed Features â†’&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;ğŸ¤ &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING â†’&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;â“ &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/faq.md"&gt;FAQ â†’&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;ğŸ“ˆ &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/docs/roadmap.md"&gt;Roadmap â†’&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/yichuan-w/LEANN/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Core Contributors: &lt;a href="https://yichuan-w.github.io/"&gt;Yichuan Wang&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/andylizf"&gt;Zhifei Li&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Active Contributors: &lt;a href="https://github.com/gabriel-dehan"&gt;Gabriel Dehan&lt;/a&gt;, &lt;a href="https://github.com/ASuresh0524"&gt;Aakash Suresh&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We welcome more contributors! Feel free to open issues or submit PRs.&lt;/p&gt; 
&lt;p&gt;This work is done at &lt;a href="https://sky.cs.berkeley.edu/"&gt;&lt;strong&gt;Berkeley Sky Computing Lab&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#yichuan-w/LEANN&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yichuan-w/LEANN&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;â­ Star us on GitHub if Leann is useful for your research or applications!&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Made with â¤ï¸ by the Leann team &lt;/p&gt; 
&lt;h2&gt;ğŸ¤– Explore LEANN with AI&lt;/h2&gt; 
&lt;p&gt;LEANN is indexed on &lt;a href="https://deepwiki.com/yichuan-w/LEANN"&gt;DeepWiki&lt;/a&gt;, so you can ask questions to LLMs using Deep Research to explore the codebase and get help to add new features.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>