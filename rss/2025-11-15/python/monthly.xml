<rss version="2.0">
  <channel>
    <title>GitHub Python Monthly Trending</title>
    <description>Monthly Trending of Python in GitHub</description>
    <pubDate>Fri, 14 Nov 2025 01:52:56 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;Open-source AI agents for penetration testing&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¦‰ Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developerâ€‘first&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Autoâ€‘fix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¯ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;ğŸ† Enterprise Platform&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ˆ Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§  Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš™ï¸ CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”Œ Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo â†’&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ› ï¸ Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ¯ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ•¸ï¸ Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’» Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Default Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Black-Box Web application assessment
strix --target https://your-app.com

# Grey-Box Security Assesment
strix --target https://your-app.com --instruction "Perform authenticated testing using the following credentials user:pass"

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ¤– Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flagâ€”perfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ”„ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;âš™ï¸ Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://openai.com/api/"&gt;OpenAI's GPT-5&lt;/a&gt; (&lt;code&gt;openai/gpt-5&lt;/code&gt;) and &lt;a href="https://claude.com/platform/api"&gt;Anthropic's Claude Sonnet 4.5&lt;/a&gt; (&lt;code&gt;anthropic/claude-sonnet-4-5&lt;/code&gt;) work best with Strix, but we support many &lt;a href="https://docs.litellm.ai/docs/providers"&gt;other options&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a â­ on GitHub!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test apps you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightningâš¡&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;âš¡ Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! ğŸ’¤&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ğŸ¤–&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. ğŸ¯&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ğŸ¤—&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;âš¡ Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest nightly build (cutting-edge features), you can install from Test PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;âš¡ Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker âœ• Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš¡ Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; â€” A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; â€” A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš¡ Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;âš¡ CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="tests summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UI Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml/badge.svg?sanitize=true" alt="UI Tests" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml/badge.svg?sanitize=true" alt="compat summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;âš¡ Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;âš¡ Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;âš¡ Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;âš¡ Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;âš¡ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yeongpin/cursor-free-vip</title>
      <link>https://github.com/yeongpin/cursor-free-vip</link>
      <description>&lt;p&gt;[Support 0.49.x]ï¼ˆReset Cursor AI MachineID &amp; Bypass Higher Token Limitï¼‰ Cursor Ai ï¼Œè‡ªåŠ¨é‡ç½®æœºå™¨ID ï¼Œ å…è´¹å‡çº§ä½¿ç”¨ProåŠŸèƒ½: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="http://go.warp.dev/cursor-free-vip"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="http://go.warp.dev/cursor-free-vip"&gt;Warp, built for coding with multiple agents.&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="http://go.warp.dev/cursor-free-vip"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;â¤ Cursor Free VIP&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/logo.png" alt="Cursor Pro Logo" width="200" style="border-radius: 6px;" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;&lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg?sanitize=true" alt="License: CC BY-NC-ND 4.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/stargazers"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/yeongpin" target="_blank"&gt;&lt;img alt="Buy Me a Coffee" src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/yeongpin/cursor-free-vip"&gt;&lt;img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/13425" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13425" alt="yeongpin%2Fcursor-free-vip | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;h4&gt;Support Latest 0.49.x Version | æ”¯æŒæœ€æ–° 0.49.x ç‰ˆæœ¬&lt;/h4&gt; 
 &lt;p&gt;This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project. This tool will not generate any fake email accounts and OAuth access.&lt;/p&gt; 
 &lt;p&gt;Supports Windows, macOS and Linux.&lt;/p&gt; 
 &lt;p&gt;For optimal performance, run with privileges and always stay up to date.&lt;/p&gt; 
 &lt;p&gt;é€™æ˜¯ä¸€æ¬¾ç”¨æ–¼å­¸ç¿’å’Œç ”ç©¶çš„å·¥å…·ï¼Œç›®å‰ repo æ²’æœ‰é•åä»»ä½•æ³•å¾‹ã€‚è«‹æ”¯æŒåŸä½œè€…ã€‚ é€™æ¬¾å·¥å…·ä¸æœƒç”Ÿæˆä»»ä½•å‡çš„é›»å­éƒµä»¶å¸³æˆ¶å’Œ OAuth è¨ªå•ã€‚&lt;/p&gt; 
 &lt;p&gt;æ”¯æŒ Windowsã€macOS å’Œ Linuxã€‚&lt;/p&gt; 
 &lt;p&gt;å°æ–¼æœ€ä½³æ€§èƒ½ï¼Œè«‹ä»¥ç®¡ç†å“¡èº«ä»½é‹è¡Œä¸¦å§‹çµ‚ä¿æŒæœ€æ–°ã€‚&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/product_2025-04-16_10-40-21.png" alt="new" width="800" style="border-radius: 6px;" /&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ”„ Change Log | æ›´æ–°æ—¥å¿—&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/CHANGELOG.md"&gt;Watch Change Log | æŸ¥çœ‹æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Features | åŠŸèƒ½ç‰¹é»&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Support Windows macOS and Linux systems&lt;br /&gt;æ”¯æŒ Windowsã€macOS å’Œ Linux ç³»çµ±&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reset Cursor's configuration&lt;br /&gt;é‡ç½® Cursor çš„é…ç½®&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-language support (English, ç®€ä½“ä¸­æ–‡, ç¹é«”ä¸­æ–‡, Vietnamese)&lt;br /&gt;å¤šèªè¨€æ”¯æŒï¼ˆè‹±æ–‡ã€ç®€ä½“ä¸­æ–‡ã€ç¹é«”ä¸­æ–‡ã€è¶Šå—èªï¼‰&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’» System Support | ç³»çµ±æ”¯æŒ&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Supported&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;x64, x86&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;Intel, Apple Silicon&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;x64, x86, ARM64&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ‘€ How to use | å¦‚ä½•ä½¿ç”¨&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;â­ Auto Run Script | è…³æœ¬è‡ªå‹•åŒ–é‹è¡Œ&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;&lt;strong&gt;Linux/macOS&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Archlinux&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;Install via &lt;a href="https://aur.archlinux.org/packages/cursor-free-vip-git"&gt;AUR&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;yay -S cursor-free-vip-git
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;If you want to stop the script, please press Ctrl+C&lt;br /&gt;è¦åœæ­¢è…³æœ¬ï¼Œè«‹æŒ‰ Ctrl+C&lt;/p&gt; 
&lt;h2&gt;â— Note | æ³¨æ„äº‹é …&lt;/h2&gt; 
&lt;p&gt;ğŸ“ Config | æ–‡ä»¶é…ç½® &lt;code&gt;Win / Macos / Linux Path | è·¯å¾‘ [Documents/.cursor-free-vip/config.ini]&lt;/code&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;â­ Config | æ–‡ä»¶é…ç½®&lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;[Chrome]
# Default Google Chrome Path | é»˜èªGoogle Chrome éŠè¦½å™¨è·¯å¾‘
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | ç­‰å¾…äººæ©Ÿé©—è­‰æ™‚é–“
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | ç­‰å¾…äººæ©Ÿé©—è­‰éš¨æ©Ÿæ™‚é–“ï¼ˆå¿…é ˆæ˜¯ 1-3 æˆ–è€… 1,3 é€™æ¨£çš„çµ„åˆï¼‰
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | å­˜å„²è·¯å¾‘
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLiteè·¯å¾‘
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | æ©Ÿå™¨IDè·¯å¾‘
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | æœ€å°éš¨æ©Ÿæ™‚é–“
min_random_time = 0.1
# Max Random Time | æœ€å¤§éš¨æ©Ÿæ™‚é–“
max_random_time = 0.8
# Page Load Wait | é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
page_load_wait = 0.1-0.8
# Input Wait | è¼¸å…¥ç­‰å¾…æ™‚é–“
input_wait = 0.3-0.8
# Submit Wait | æäº¤ç­‰å¾…æ™‚é–“
submit_wait = 0.5-1.5
# Verification Code Input | é©—è­‰ç¢¼è¼¸å…¥ç­‰å¾…æ™‚é–“
verification_code_input = 0.1-0.3
# Verification Success Wait | é©—è­‰æˆåŠŸç­‰å¾…æ™‚é–“
verification_success_wait = 2-3
# Verification Retry Wait | é©—è­‰é‡è©¦ç­‰å¾…æ™‚é–“
verification_retry_wait = 2-3
# Email Check Initial Wait | éƒµä»¶æª¢æŸ¥åˆå§‹ç­‰å¾…æ™‚é–“
email_check_initial_wait = 4-6
# Email Refresh Wait | éƒµä»¶åˆ·æ–°ç­‰å¾…æ™‚é–“
email_refresh_wait = 2-4
# Settings Page Load Wait | è¨­ç½®é é¢åŠ è¼‰ç­‰å¾…æ™‚é–“
settings_page_load_wait = 1-2
# Failed Retry Time | å¤±æ•—é‡è©¦æ™‚é–“
failed_retry_time = 0.5-1
# Retry Interval | é‡è©¦é–“éš”
retry_interval = 8-12
# Max Timeout | æœ€å¤§è¶…æ™‚æ™‚é–“
max_timeout = 160

[Utils]
# Check Update | æª¢æŸ¥æ›´æ–°
check_update = True
# Show Account Info | é¡¯ç¤ºè³¬è™Ÿä¿¡æ¯
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | å•“ç”¨ TempMailPlusï¼ˆä»»ä½•è½‰ç™¼åˆ°TempMailPlusçš„éƒµä»¶éƒ½æ”¯æŒç²å–é©—è­‰ç¢¼ï¼Œä¾‹å¦‚cloudflareéƒµä»¶Catch-allï¼‰
enabled = false
# TempMailPlus Email | TempMailPlus é›»å­éƒµä»¶
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pinç¢¼
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use administrator privileges to run the script &lt;br /&gt;è«‹ä½¿ç”¨ç®¡ç†å“¡èº«ä»½é‹è¡Œè…³æœ¬&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Confirm that Cursor is closed before running the script &lt;br /&gt;è«‹ç¢ºä¿åœ¨é‹è¡Œè…³æœ¬å‰å·²ç¶“é—œé–‰ Cursor&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;This tool is only for learning and research purposes &lt;br /&gt;æ­¤å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Please comply with the relevant software usage terms when using this tool &lt;br /&gt;ä½¿ç”¨æœ¬å·¥å…·æ™‚è«‹éµå®ˆç›¸é—œè»Ÿä»¶ä½¿ç”¨æ¢æ¬¾&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš¨ Common Issues | å¸¸è¦‹å•é¡Œ&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;å¦‚æœé‡åˆ°æ¬Šé™å•é¡Œï¼Œè«‹ç¢ºä¿ï¼š&lt;/th&gt; 
   &lt;th align="center"&gt;æ­¤è…³æœ¬ä»¥ç®¡ç†å“¡èº«ä»½é‹è¡Œ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;If you encounter permission issues, please ensure:&lt;/td&gt; 
   &lt;td align="center"&gt;This script is run with administrator privileges&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Error 'User is not authorized'&lt;/td&gt; 
   &lt;td align="center"&gt;This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ¤© Contribution | è²¢ç»&lt;/h2&gt; 
&lt;p&gt;æ­¡è¿æäº¤ Issue å’Œ Pull Requestï¼&lt;/p&gt; 
&lt;a href="https://github.com/yeongpin/cursor-free-vip/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;amp;preview=true&amp;amp;max=&amp;amp;columns=" /&gt; &lt;/a&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h2&gt;ğŸ“© Disclaimer | å…è²¬è²æ˜&lt;/h2&gt; 
&lt;p&gt;æœ¬å·¥å…·åƒ…ä¾›å­¸ç¿’å’Œç ”ç©¶ä½¿ç”¨ï¼Œä½¿ç”¨æœ¬å·¥å…·æ‰€ç”¢ç”Ÿçš„ä»»ä½•å¾Œæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ“”ã€‚ &lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne by the user.&lt;/p&gt; 
&lt;h2&gt;ğŸ’° Buy Me a Coffee | è«‹æˆ‘å–æ¯å’–å•¡&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/provi-code.jpg" alt="buy_me_a_coffee" width="280" /&gt;&lt;br /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/paypal.png" alt="buy_me_a_coffee" width="280" /&gt;&lt;br /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;â­ Star History | æ˜Ÿæ˜Ÿæ•¸&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#yeongpin/cursor-free-vip&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“ License | æˆæ¬Š&lt;/h2&gt; 
&lt;p&gt;æœ¬é …ç›®æ¡ç”¨ &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;CC BY-NC-ND 4.0&lt;/a&gt; æˆæ¬Šã€‚ Please refer to the &lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PaddlePaddle/PaddleOCR</title>
      <link>https://github.com/PaddlePaddle/PaddleOCR</link>
      <description>&lt;p&gt;Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/Banner.png" alt="PaddleOCR Banner" /&gt; &lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_cn.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_tcn.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ja.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ko.md"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_fr.md"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ru.md"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_es.md"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ar.md"&gt;Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- icon --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/forks/PaddlePaddle/PaddleOCR.svg?sanitize=true" alt="forks" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2507.05595"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR_3.0-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2510.14528"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-Technical%20Report-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projectsproject/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/network/dependents"&gt;&lt;img src="https://img.shields.io/badge/Used%20by-6k%2B%20repositories-blue" alt="Used by" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/paddleocr/"&gt;&lt;img src="https://img.shields.io/pypi/v/paddleocr" alt="PyPI version" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/python-3.8~3.12-aff.svg?sanitize=true" alt="python" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true" alt="os" /&gt; &lt;img src="https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg?sanitize=true" alt="hardware" /&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache_2.0-green" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://www.paddleocr.com"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR-_Offiical_Website-1927BA?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAMAAADDpiTIAAAABlBMVEU2P+X///+1KuUwAAAHKklEQVR42u3dS5bjOAwEwALvf2fMavZum6IAImI7b2yYSqU+1Zb//gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADKCR/+fzly7rD92yVg69xh8zeLwOa5w+ZvFYHtc4ft3ykB++cOm79PAp6YO2z/Ngl4ZO5l+9+yT4QAvLqS748VF33Ylzdvzpl72f6z53YIGJ6SZdPeNHcIwOycaADdLgCSIgAIgCOAACAAykIAEAAEAAFAABCAT+WQuQVgeBqXhXQIQAAYegowLQBpbg3gZGFyAC6vgBQAMREA2/YfDPxyaDQNyTNz+3Zwn5J4ZG7PB2h0kHhi7plPCImmJwkPzO0RMa3OET0i5uGlzHFze0xcu0vE2Dq3J4U2vEPgSaHbFzPNDQAAAAAAAMBNovdw+cP/ny+uaf7w/+eYADy8kE+F4Offdjn6zZXhAXgiA78G4MNNsmnu1Xr7b3mbOL8T5Ja5bw/A35EC2LiWpzt1y9jRugBy30fLg3NvHPvnuZcC2NsCUXA/aRmA89V07Fwgt37uH8deCmBr6N44pP4UgaUATpdA7v/cMbIB8okliY65/SW5HhJ1ehPmM+8edwXgpbu4R88FayR32Y/P7oZZbOx13/Zr//ZHx27bAPnkFoyewYlbAhD3TvBobr95gaUAtr1EdNx1lgI4OcTTuR3z6+FZMEDRcu9ZCuDgGCdyGxMa4EgBRMvcjrkM7NgBZw5c0TwAUWUhZwRXA2xaya65Xa3jO2qYZ8bu2AD5w38tG5V8aZpoGN6Tz0bOfa9bceyWAciTO0jWyO1Tc5cLwJmF/JfPnXVyu3/slgHIg1n79O2O5fZv+1cHV7sC2HYqmUdHysNzX3sVkMcjUK5Gc+dMs28E5bGtm0V3gloBOP9vgZv+4sYn3RUaYFMCol5uN77g6lUApc8pWs69Zn7snS9Z9Q8G0S0AUTVUUTG3A54R1KSvo/diLAv5fKzynZeN6xogC75u93+AtBTA47OlAFSv6qY/vp3DAjD8iv2ZdFYJwKynMhTK1rInPfzaxW81LnvSgFP9KxrATaCLA3DxHpbFX31ZyNm5XRZyXG5bNkAWfP0rcrsUwOgC6NIAzgBcBiqAWwPgLrAGuGBP6jr2sifdfiJ6QQM4Bbw4AK4B3129ZSFn53ZZyA/GyFty27IBFMDFAXAG8PbyLQv5xULGPRl0K3h2AbwcgCZPhs+LD1zLnjS6AN4NwMU/DVFh7LyhASreTbvqrxdr/J4XT4Swz4FrTS+AGJ7bNbwAYkxuWzZAVljHrJfbjb9wviYXwFO/FJ8Vli4vaICsEMFyBbA3tmtsAUS0zG1c/bj4YwsZH2/+Whd0+1Nb+S7IE2sfPw4RL0XmsR8Nqvz7qFngmPHF34EqjP15AAofAkosZKPC/K6FVoeP02Ehi540NG6AK/4pYP3cLgVwXwHkDQ1QcSGb/uF4WwCmfX8u/+4vgLINcMUlQIfcLgXwXAF0+BGkpQDuuJx7/hwgpu//cWVuO3wxJOz/z8297vgYBwaIO3O7Kn+c194578ltywbIgu8fl+Z2lS+APvnLjnOv8hsgSqxjgwL4Ln9LAezaj98tgPzy7ZcC+GQzxrWxXQpgx370dm6/H7v6jaBoso5dY1swAFlwHWvfBf5pxVa93fCtdx64+1dsgCy4joWvAfPX9VoKYMs6Zse9/8Mlvv7LILlhAfKFFdsSutJXAdFkL3qlADJPrXFcXAC5KYaH586jO9mtAch9S3T0GQJ726ZWAE49kjP3rlDJuetdaL/1zeqZY9c7CRz7s0wCUPxienQBnAuAAtAAlxaAAAxfyBQABSAACkAAFIAAKAABUAACMEkKwL170oh7V8ueNLoAjgTAXWAN4BRwcABcA2oABTA4AApAAyiAwQFQABpAAQwOgALQADMWUgCuEmNyu15fSIY3gFPAiwPgFFADKIDBAVAAGkABCIACmBqAUAAaQAHMDUCMWkgBuMWw3K43F5LhDeAU8OIAuAmkARTA4AAoAA2gAARAAUwNgLvAGkABDA6Au8AaoKOJuV0vLSTDG8Ap4MUBcBNIAyiAwQFQABpAAQwOgALQAApAABTA1AC4C6wBOhqb23V+IRneAE4BLw6Aa0ANoAAGB0ABaAAFMDgACkADKAABUABTA+AusAboKATAQs4trjV+IYcfuJYCcA6gAATAQk69dFkKQANYyLkFcLIBFIDLQAVwawDsSRrAEWBwAJwCagAFMDgACkADKIDBAVAAGkABCIACmBoAzwXWAApgcADsSRrg0iNACoACEADXgAIwdCFTACykALgGFIAfl0kBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPBv/gN+IH8U6YveYgAAAABJRU5ErkJggg==&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;PaddleOCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.paddlepaddle.org.cn/en"&gt;&lt;img src="https://img.shields.io/badge/PaddlePaddle-3.0-orange" alt="Framework" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Recognition%20Accuracy-%F0%9F%8F%86-green" alt="Accuracy" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Support_Languages-100+-brightgreen" alt="Multi-Language" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Handwriting-%E2%9C%93-success" alt="Handwriting" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red" alt="Hardware" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;PaddleOCR MCP Server&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR 3.0 Technical Report is now available. See details at: &lt;a href="https://arxiv.org/abs/2507.05595"&gt;PaddleOCR 3.0 Technical Report&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR-VL Technical Report is now available. See details at &lt;a href="https://arxiv.org/abs/2510.14528"&gt;PaddleOCR-VL Technical Report&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The Beta version of the PaddleOCR official website is now live, offering a more convenient online experience and large-scale PDF file parsing, as well as free API and MCP services. For more details, please visit the &lt;a href="https://www.paddleocr.com"&gt;PaddleOCR official website&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;PaddleOCR&lt;/strong&gt; converts documents and images into &lt;strong&gt;structured, AI-friendly data&lt;/strong&gt; (like JSON and Markdown) with &lt;strong&gt;industry-leading accuracy&lt;/strong&gt;â€”powering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over &lt;strong&gt;60,000 stars&lt;/strong&gt; and deep integration into leading projects like &lt;strong&gt;MinerU, RAGFlow, pathway and cherry-studio&lt;/strong&gt;, PaddleOCR has become the &lt;strong&gt;premier solution&lt;/strong&gt; for developers building intelligent document applications in the &lt;strong&gt;AI era&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;PaddleOCR 3.0 Core Features&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/application/detail/98365"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;The SOTA and resource-efficient model tailored for document parsing&lt;/strong&gt;, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5 â€” Universal Scene Text Recognition&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;Single model supports five text types&lt;/strong&gt; (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with &lt;strong&gt;13% accuracy improvement&lt;/strong&gt;. Solves multilingual mixed document recognition challenges.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3 â€” Complex Document Parsing&lt;/strong&gt;&lt;br /&gt; Intelligently converts complex PDFs and document images into &lt;strong&gt;Markdown and JSON files that preserve original structure&lt;/strong&gt;. &lt;strong&gt;Outperforms&lt;/strong&gt; numerous commercial solutions in public benchmarks. &lt;strong&gt;Perfectly maintains document layout and hierarchical structure&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4 â€” Intelligent Information Extraction&lt;/strong&gt;&lt;br /&gt; Natively integrates ERNIE 4.5 to &lt;strong&gt;precisely extract key information&lt;/strong&gt; from massive documents, with 15% accuracy improvement over previous generation. Makes documents "&lt;strong&gt;understand&lt;/strong&gt;" your questions and provide accurate answers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg" alt="PaddleOCR Architecture" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Special Note&lt;/strong&gt;: PaddleOCR 3.x introduces several significant interface changes. &lt;strong&gt;Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x&lt;/strong&gt;. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html"&gt;This document&lt;/a&gt; explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.&lt;/p&gt; 
&lt;h2&gt;ğŸ“£ Recent updates&lt;/h2&gt; 
&lt;h3&gt;ğŸ”¥ğŸ”¥ 2025.10.16: PaddleOCR 3.3.0 released, includes:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Released PaddleOCR-VL:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Introduction&lt;/strong&gt;:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;PaddleOCR-VL&lt;/strong&gt; is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. &lt;strong&gt;This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption&lt;/strong&gt;. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on &lt;a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL"&gt;HuggingFace&lt;/a&gt;. Everyone is welcome to download and use it! More introduction infomation can be found in &lt;a href="https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html"&gt;PaddleOCR-VL&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Compact yet Powerful VLM Architecture&lt;/strong&gt;: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the modelâ€™s recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;SOTA Performance on Document Parsing&lt;/strong&gt;: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multilingual Support&lt;/strong&gt;: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Released PP-OCRv5 Multilingual Recognition Model:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.21: Release of PaddleOCR 3.2.0&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Significant Model Additions:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. &lt;strong&gt;The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deployment Capability Upgrades:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Benchmark Support:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/pipeline_usage/instructions/benchmark.en.md"&gt;Here's&lt;/a&gt; how to set up and use the benchmark feature.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Resolved the issue of failed log saving during model training.&lt;/li&gt; 
    &lt;li&gt;Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.&lt;/li&gt; 
    &lt;li&gt;Fixed inconsistencies in switch behaviors (e.g., &lt;code&gt;use_chart_parsing&lt;/code&gt;) in the PP-StructureV3 configuration files compared to other pipelines.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other Enhancements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/installation.en.md"&gt;installation guide&lt;/a&gt; for the corresponding PaddlePaddle framework versions.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;PP-OCR series models now support returning single-character coordinates.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.&lt;/li&gt; 
    &lt;li&gt;Added support for chart-to-table conversion via the PP-Chart2Table module.&lt;/li&gt; 
    &lt;li&gt;Optimized documentation descriptions to improve usability.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.15: PaddleOCR 3.1.1 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added the missing methods &lt;code&gt;save_vector&lt;/code&gt;, &lt;code&gt;save_visual_info_list&lt;/code&gt;, &lt;code&gt;load_vector&lt;/code&gt;, and &lt;code&gt;load_visual_info_list&lt;/code&gt; in the &lt;code&gt;PP-ChatOCRv4&lt;/code&gt; class.&lt;/li&gt; 
    &lt;li&gt;Added the missing parameters &lt;code&gt;glossary&lt;/code&gt; and &lt;code&gt;llm_request_interval&lt;/code&gt; to the &lt;code&gt;translate&lt;/code&gt; method in the &lt;code&gt;PPDocTranslation&lt;/code&gt; class.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added a demo to the MCP documentation.&lt;/li&gt; 
    &lt;li&gt;Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.&lt;/li&gt; 
    &lt;li&gt;Fixed errors and omissions in the production line document translation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Changed the MCP server dependency to use the pure Python library &lt;code&gt;puremagic&lt;/code&gt; instead of &lt;code&gt;python-magic&lt;/code&gt; to reduce installation issues.&lt;/li&gt; 
    &lt;li&gt;Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.29: PaddleOCR 3.1.0 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Models and Pipelines:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Added PP-OCRv5 Multilingual Text Recognition Model&lt;/strong&gt;, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. &lt;strong&gt;Average accuracy improved by over 30%.&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Upgraded the &lt;strong&gt;PP-Chart2Table model&lt;/strong&gt; in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) &lt;strong&gt;increased by 9.36 percentage points (71.24% -&amp;gt; 80.60%).&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Newly launched &lt;strong&gt;document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5&lt;/strong&gt;, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MCP server:&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;Details&lt;/a&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Supports both OCR and PP-StructureV3 pipelines.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.&lt;/li&gt; 
    &lt;li&gt;Supports invoking local services via stdio and remote services via Streamable HTTP.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Optimization:&lt;/strong&gt; Improved the descriptions in some user guides for a smoother reading experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.26: PaddleOCR 3.0.3 Released&lt;/strong&gt;&lt;/summary&gt; - Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.19: PaddleOCR 3.0.2 Released&lt;/strong&gt;&lt;/summary&gt; - **New Features:** 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;The default download source has been changed from &lt;code&gt;BOS&lt;/code&gt; to &lt;code&gt;HuggingFace&lt;/code&gt;. Users can also change the environment variable &lt;code&gt;PADDLE_PDX_MODEL_SOURCE&lt;/code&gt; to &lt;code&gt;BOS&lt;/code&gt; to set the model download source back to Baidu Object Storage (BOS).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added service invocation examples for six languagesâ€”C++, Java, Go, C#, Node.js, and PHPâ€”for pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added Android example for PP-OCRv5. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html"&gt;Details&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.&lt;/li&gt; 
    &lt;li&gt;Resolved an issue where &lt;code&gt;export_paddlex_config_to_yaml&lt;/code&gt; would not function correctly in certain cases.&lt;/li&gt; 
    &lt;li&gt;Corrected the discrepancy between the actual behavior of &lt;code&gt;save_path&lt;/code&gt; and its documentation description.&lt;/li&gt; 
    &lt;li&gt;Fixed potential multithreading errors when using MKL-DNN in basic service deployment.&lt;/li&gt; 
    &lt;li&gt;Corrected channel order errors in image preprocessing for the Latex-OCR model.&lt;/li&gt; 
    &lt;li&gt;Fixed channel order errors in saving visualized images within the text recognition module.&lt;/li&gt; 
    &lt;li&gt;Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.&lt;/li&gt; 
    &lt;li&gt;Fixed an overflow issue in the calculation of &lt;code&gt;overlap_ratio&lt;/code&gt; under extremely special circumstances in the PP-StructureV3 pipeline.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the description of the &lt;code&gt;enable_mkldnn&lt;/code&gt; parameter in the documentation to accurately reflect the program's actual behavior.&lt;/li&gt; 
    &lt;li&gt;Fixed errors in the documentation regarding the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;ocr_version&lt;/code&gt; parameters.&lt;/li&gt; 
    &lt;li&gt;Added instructions for exporting pipeline configuration files via CLI.&lt;/li&gt; 
    &lt;li&gt;Fixed missing columns in the performance data table for PP-OCRv5.&lt;/li&gt; 
    &lt;li&gt;Refined benchmark metrics for PP-StructureV3 across different configurations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;History Log&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;2025.06.05: &lt;strong&gt;PaddleOCR 3.0.1 Released&lt;/strong&gt;, includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Optimisation of certain models and model configurations:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter &lt;code&gt;limit_side_len&lt;/code&gt; in the configuration has been changed from 736 to 64.&lt;/li&gt; 
    &lt;li&gt;Added a new text line orientation classification model &lt;code&gt;PP-LCNet_x1_0_textline_ori&lt;/code&gt; with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.&lt;/li&gt; 
    &lt;li&gt;Optimized the text line orientation classification model &lt;code&gt;PP-LCNet_x0_25_textline_ori&lt;/code&gt;, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimizations and fixes for some issues in version 3.0.0, &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;details&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ğŸ”¥ğŸ”¥2025.05.20: Official Release of &lt;strong&gt;PaddleOCR v3.0&lt;/strong&gt;, including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5&lt;/strong&gt;: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ğŸŒ Single-model support for &lt;strong&gt;five&lt;/strong&gt; text types - Seamlessly process &lt;strong&gt;Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English&lt;/strong&gt; and &lt;strong&gt;Japanese&lt;/strong&gt; within a single model.&lt;/li&gt; 
    &lt;li&gt;âœï¸ Improved &lt;strong&gt;handwriting recognition&lt;/strong&gt;: Significantly better at complex cursive scripts and non-standard handwriting.&lt;/li&gt; 
    &lt;li&gt;ğŸ¯ &lt;strong&gt;13-point accuracy gain&lt;/strong&gt; over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3&lt;/strong&gt;: General-Purpose Document Parsing â€“ Unleash SOTA Images/PDFs Parsing for Real-World Scenarios!&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ğŸ§® &lt;strong&gt;High-Accuracy multi-scene PDF parsing&lt;/strong&gt;, leading both open- and closed-source solutions on the OmniDocBench benchmark.&lt;/li&gt; 
    &lt;li&gt;ğŸ§  Specialized capabilities include &lt;strong&gt;seal recognition&lt;/strong&gt;, &lt;strong&gt;chart-to-table conversion&lt;/strong&gt;, &lt;strong&gt;table recognition with nested formulas/images&lt;/strong&gt;, &lt;strong&gt;vertical text document parsing&lt;/strong&gt;, and &lt;strong&gt;complex table structure analysis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4&lt;/strong&gt;: Intelligent Document Understanding â€“ Extract Key Information, not just text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ğŸ”¥ &lt;strong&gt;15-point accuracy gain&lt;/strong&gt; in key-information extraction on PDF/PNG/JPG files over the previous generation.&lt;/li&gt; 
    &lt;li&gt;ğŸ’» Native support for &lt;strong&gt;ERNIE 4.5&lt;/strong&gt;, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.&lt;/li&gt; 
    &lt;li&gt;ğŸ¤ Integrated &lt;a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2"&gt;PP-DocBee2&lt;/a&gt;, enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;History Log&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;âš¡ Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Run online demo&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install PaddlePaddle refer to &lt;a href="https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html"&gt;Installation Guide&lt;/a&gt;, after then, install the PaddleOCR toolkit.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting from version 3.2.0, in addition to the &lt;code&gt;all&lt;/code&gt; dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dependency Group Name&lt;/th&gt; 
   &lt;th&gt;Corresponding Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doc-parser&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3, PaddleOCR-VL&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ie&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Complete functionality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Run inference by CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run PP-OCRv5 inference
paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  

# Run PP-StructureV3 inference
paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False

# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference
paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k é©¾é©¶å®¤å‡†ä¹˜äººæ•° --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False 

# Run PaddleOCR-VL inference
paddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png

# Get more information about "paddleocr ocr"
paddleocr ocr --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Run inference by API&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;4.1 PP-OCRv5 Example&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initialize PaddleOCR instance
from paddleocr import PaddleOCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False)

# Run OCR inference on a sample image 
result = ocr.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png")

# Visualize the results and save the JSON results
for res in result:
    res.print()
    res.save_to_img("output")
    res.save_to_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.2 PP-StructureV3 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from paddleocr import PPStructureV3

pipeline = PPStructureV3(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

# For Image
output = pipeline.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png",
)

# Visualize the results and save the JSON results
for res in output:
    res.print() 
    res.save_to_json(save_path="output") 
    res.save_to_markdown(save_path="output")           
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.3 PP-ChatOCRv4 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PPChatOCRv4Doc

chat_bot_config = {
    "module_name": "chat_bot",
    "model_name": "ernie-3.5-8k",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "openai",
    "api_key": "api_key",  # your api_key
}

retriever_config = {
    "module_name": "retriever",
    "model_name": "embedding-v1",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "qianfan",
    "api_key": "api_key",  # your api_key
}

pipeline = PPChatOCRv4Doc(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

visual_predict_res = pipeline.visual_predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
    use_common_ocr=True,
    use_seal_recognition=True,
    use_table_recognition=True,
)

mllm_predict_info = None
use_mllm = False
# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.
if use_mllm:
    mllm_chat_bot_config = {
        "module_name": "chat_bot",
        "model_name": "PP-DocBee",
        "base_url": "http://127.0.0.1:8080/",  # your local mllm service url
        "api_type": "openai",
        "api_key": "api_key",  # your api_key
    }

    mllm_predict_res = pipeline.mllm_pred(
        input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
        key_list=["é©¾é©¶å®¤å‡†ä¹˜äººæ•°"],
        mllm_chat_bot_config=mllm_chat_bot_config,
    )
    mllm_predict_info = mllm_predict_res["mllm_res"]

visual_info_list = []
for res in visual_predict_res:
    visual_info_list.append(res["visual_info"])
    layout_parsing_result = res["layout_parsing_result"]

vector_info = pipeline.build_vector(
    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config
)
chat_result = pipeline.chat(
    key_list=["é©¾é©¶å®¤å‡†ä¹˜äººæ•°"],
    visual_info=visual_info_list,
    vector_info=vector_info,
    mllm_predict_info=mllm_predict_info,
    chat_bot_config=chat_bot_config,
    retriever_config=retriever_config,
)
print(chat_result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.4 PaddleOCR-VL Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PaddleOCRVL

pipeline = PaddleOCRVL()
output = pipeline.predict("https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png")
for res in output:
    res.print()
    res.save_to_json(save_path="output")
    res.save_to_markdown(save_path="output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. Chinese Heterogeneous AI Accelerators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html"&gt;Huawei Ascend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html"&gt;KUNLUNXIN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ§© More Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert models to ONNX format: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html"&gt;Obtaining ONNX Models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html"&gt;High-Performance Inference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using multi-GPU and multi-process: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html"&gt;Parallel Inference for Pipelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate PaddleOCR into applications written in C++, C#, Java, etc.: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html"&gt;Serving&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;â›°ï¸ Advanced Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html"&gt;PP-OCRv5 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html"&gt;PP-StructureV3 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html"&gt;PP-ChatOCRv4 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html"&gt;PaddleOCR-VL Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”„ Quick Overview of Execution Results&lt;/h2&gt; 
&lt;h3&gt;PP-OCRv5&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-OCRv5_demo.gif" alt="PP-OCRv5 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;PP-StructureV3&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PP-StructureV3_demo.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;PaddleOCR-VL&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/PaddleOCR-VL_demo.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;âœ¨ Stay Tuned&lt;/h2&gt; 
&lt;p&gt;â­ &lt;strong&gt;Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!&lt;/strong&gt; â­&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="1200" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif" alt="Star-Project" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Community&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;PaddlePaddle WeChat official account&lt;/th&gt; 
    &lt;th align="center"&gt;Join the tech discussion group&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg" width="150" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg" width="150" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ˜ƒ Awesome Projects Leveraging PaddleOCR&lt;/h2&gt; 
&lt;p&gt;PaddleOCR wouldn't be where it is today without its incredible community! ğŸ’— A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR â€” whether we've named you or not. Your support fuels our fire!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Project Name&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow"&gt;&lt;img src="https://img.shields.io/github/stars/infiniflow/ragflow" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;RAG engine based on deep document understanding.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/pathwaycom/pathway"&gt;pathway&lt;/a&gt; &lt;a href="https://github.com/pathwaycom/pathway"&gt;&lt;img src="https://img.shields.io/github/stars/pathwaycom/pathway" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Multi-type Document to Markdown Conversion Tool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;Umi-OCR&lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;&lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Free, Open-source, Batch Offline OCR Software.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/CherryHQ/cherry-studio"&gt;cherry-studio&lt;/a&gt; &lt;a href="https://github.com/CherryHQ/cherry-studio"&gt;&lt;img src="https://img.shields.io/github/stars/CherryHQ/cherry-studio" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A desktop client that supports for multiple LLM providers.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;OmniParser&lt;/a&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/OmniParser" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;QAnything&lt;/a&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;&lt;img src="https://img.shields.io/github/stars/netease-youdao/QAnything" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Question and Answer based on Anything.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt; &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;Dango-Translator&lt;/a&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;&lt;img src="https://img.shields.io/github/stars/PantsuDango/Dango-Translator" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Recognize text on the screen, translate it and show the translation results in real time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;Learn more projects&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;More projects based on PaddleOCR&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Contributors&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&amp;amp;max=400&amp;amp;columns=20" width="800" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒŸ Star&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="800" src="https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&amp;amp;type=Date" alt="Star-history" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is released under the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ“ Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{cui2025paddleocr30technicalreport,
      title={PaddleOCR 3.0 Technical Report}, 
      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2507.05595},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.05595}, 
}

@misc{cui2025paddleocrvlboostingmultilingualdocument,
      title={PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model}, 
      author={Cheng Cui and Ting Sun and Suyin Liang and Tingquan Gao and Zelun Zhang and Jiaxuan Liu and Xueqing Wang and Changda Zhou and Hongen Liu and Manhui Lin and Yue Zhang and Yubo Zhang and Handong Zheng and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2510.14528},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.14528}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>huggingface/lerobot</title>
      <link>https://github.com/huggingface/lerobot</link>
      <description>&lt;p&gt;ğŸ¤— LeRobot: Making AI for Robotics more accessible with end-to-end learning&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="LeRobot, Hugging Face Robotics Library" src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/lerobot-logo-thumbnail.png" width="100%" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/huggingface/lerobot/actions/workflows/nightly.yml?query=branch%3Amain"&gt;&lt;img src="https://github.com/huggingface/lerobot/actions/workflows/nightly.yml/badge.svg?branch=main" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/lerobot" alt="Python versions" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/lerobot/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/lerobot/"&gt;&lt;img src="https://img.shields.io/pypi/status/lerobot" alt="Status" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/lerobot/"&gt;&lt;img src="https://img.shields.io/pypi/v/lerobot" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/lerobot/raw/main/CODE_OF_CONDUCT.md"&gt;&lt;img src="https://img.shields.io/badge/Contributor%20Covenant-v2.1-ff69b4.svg?sanitize=true" alt="Contributor Covenant" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/s3KuuzsPFb"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/C5P34WJ68S?style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- [![Coverage](https://codecov.io/gh/huggingface/lerobot/branch/main/graph/badge.svg?token=TODO)](https://codecov.io/gh/huggingface/lerobot) --&gt; 
&lt;/div&gt; 
&lt;h2 align="center"&gt; &lt;p&gt;&lt;a href="https://huggingface.co/docs/lerobot/hope_jr"&gt; Build Your Own HopeJR Robot!&lt;/a&gt;&lt;/p&gt; &lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/hope_jr/hopejr.png" alt="HopeJR robot" title="HopeJR robot" width="60%" /&gt; 
 &lt;p&gt;&lt;strong&gt;Meet HopeJR â€“ A humanoid robot arm and hand for dexterous manipulation!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Control it with exoskeletons and gloves for precise hand movements.&lt;/p&gt; 
 &lt;p&gt;Perfect for advanced manipulation tasks! ğŸ¤–&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/docs/lerobot/hope_jr"&gt; See the full HopeJR tutorial here.&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2 align="center"&gt; &lt;p&gt;&lt;a href="https://huggingface.co/docs/lerobot/so101"&gt; Build Your Own SO-101 Robot!&lt;/a&gt;&lt;/p&gt; &lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101.webp" alt="SO-101 follower arm" title="SO-101 follower arm" width="90%" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/so101/so101-leader.webp" alt="SO-101 leader arm" title="SO-101 leader arm" width="90%" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;Meet the updated SO100, the SO-101 â€“ Just â‚¬114 per arm!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Train it in minutes with a few simple moves on your laptop.&lt;/p&gt; 
 &lt;p&gt;Then sit back and watch your creation act autonomously! ğŸ¤¯&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/docs/lerobot/so101"&gt; See the full SO-101 tutorial here.&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Want to take it to the next level? Make your SO-101 mobile by building LeKiwi!&lt;/p&gt; 
 &lt;p&gt;Check out the &lt;a href="https://huggingface.co/docs/lerobot/lekiwi"&gt;LeKiwi tutorial&lt;/a&gt; and bring your robot to life on wheels.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/lekiwi/kiwi.webp" alt="LeKiwi mobile robot" title="LeKiwi mobile robot" width="50%" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3 align="center"&gt; &lt;p&gt;LeRobot: State-of-the-art AI for real-world robotics&lt;/p&gt; &lt;/h3&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ¤— LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot already provides a set of pretrained models, datasets with human collected demonstrations, and simulation environments to get started without assembling a robot. In the coming weeks, the plan is to add more and more support for real-world robotics on the most affordable and capable robots out there.&lt;/p&gt; 
&lt;p&gt;ğŸ¤— LeRobot hosts pretrained models and datasets on this Hugging Face community page: &lt;a href="https://huggingface.co/lerobot"&gt;huggingface.co/lerobot&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Examples of pretrained models on simulation environments&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/aloha_act.gif" width="100%" alt="ACT policy on ALOHA env" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/simxarm_tdmpc.gif" width="100%" alt="TDMPC policy on SimXArm env" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/huggingface/lerobot/main/media/gym/pusht_diffusion.gif" width="100%" alt="Diffusion policy on PushT env" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;ACT policy on ALOHA env&lt;/td&gt; 
   &lt;td align="center"&gt;TDMPC policy on SimXArm env&lt;/td&gt; 
   &lt;td align="center"&gt;Diffusion policy on PushT env&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;LeRobot works with Python 3.10+ and PyTorch 2.2+.&lt;/p&gt; 
&lt;h3&gt;Environment Setup&lt;/h3&gt; 
&lt;p&gt;Create a virtual environment with Python 3.10 and activate it, e.g. with &lt;a href="https://conda-forge.org/download/"&gt;&lt;code&gt;miniforge&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -y -n lerobot python=3.10
conda activate lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using &lt;code&gt;conda&lt;/code&gt;, install &lt;code&gt;ffmpeg&lt;/code&gt; in your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install ffmpeg -c conda-forge
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; This usually installs &lt;code&gt;ffmpeg 7.X&lt;/code&gt; for your platform compiled with the &lt;code&gt;libsvtav1&lt;/code&gt; encoder. If &lt;code&gt;libsvtav1&lt;/code&gt; is not supported (check supported encoders with &lt;code&gt;ffmpeg -encoders&lt;/code&gt;), you can:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;em&gt;[On any platform]&lt;/em&gt; Explicitly install &lt;code&gt;ffmpeg 7.X&lt;/code&gt; using:&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;conda install ffmpeg=7.1.1 -c conda-forge
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;em&gt;[On Linux only]&lt;/em&gt; Install &lt;a href="https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu#GettheDependencies"&gt;ffmpeg build dependencies&lt;/a&gt; and &lt;a href="https://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu#libsvtav1"&gt;compile ffmpeg from source with libsvtav1&lt;/a&gt;, and make sure you use the corresponding ffmpeg binary to your install with &lt;code&gt;which ffmpeg&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install LeRobot ğŸ¤—&lt;/h3&gt; 
&lt;h4&gt;From Source&lt;/h4&gt; 
&lt;p&gt;First, clone the repository and navigate into the directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/huggingface/lerobot.git
cd lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, install the library in editable mode. This is useful if you plan to contribute to the code.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you encounter build errors, you may need to install additional dependencies (&lt;code&gt;cmake&lt;/code&gt;, &lt;code&gt;build-essential&lt;/code&gt;, and &lt;code&gt;ffmpeg libs&lt;/code&gt;). On Linux, run: &lt;code&gt;sudo apt-get install cmake build-essential python3-dev pkg-config libavformat-dev libavcodec-dev libavdevice-dev libavutil-dev libswscale-dev libswresample-dev libavfilter-dev&lt;/code&gt;. For other systems, see: &lt;a href="https://pyav.org/docs/develop/overview/installation.html#bring-your-own-ffmpeg"&gt;Compiling PyAV&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For simulations, ğŸ¤— LeRobot comes with gymnasium environments that can be installed as extras:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/gym-aloha"&gt;aloha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/gym-xarm"&gt;xarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/gym-pusht"&gt;pusht&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For instance, to install ğŸ¤— LeRobot with aloha and pusht, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e ".[aloha, pusht]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installation from PyPI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Core Library:&lt;/strong&gt; Install the base package with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install lerobot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;This installs only the default dependencies.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Extra Features:&lt;/strong&gt; To install additional functionality, use one of the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'lerobot[all]'          # All available features
pip install 'lerobot[aloha,pusht]'  # Specific features (Aloha &amp;amp; Pusht)
pip install 'lerobot[feetech]'      # Feetech motor support
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Replace &lt;code&gt;[...]&lt;/code&gt; with your desired features.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Available Tags:&lt;/strong&gt; For a full list of optional dependencies, see: &lt;a href="https://pypi.org/project/lerobot/"&gt;https://pypi.org/project/lerobot/&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For lerobot 0.4.0, if you want to install pi tags, you will have to do: &lt;code&gt;pip install "lerobot[pi]@git+https://github.com/huggingface/lerobot.git"&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;This will be solved in the next patch release&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Weights &amp;amp; Biases&lt;/h3&gt; 
&lt;p&gt;To use &lt;a href="https://docs.wandb.ai/quickstart"&gt;Weights and Biases&lt;/a&gt; for experiment tracking, log in with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wandb login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note: you will also need to enable WandB in the configuration. See below.)&lt;/p&gt; 
&lt;h3&gt;Visualize datasets&lt;/h3&gt; 
&lt;p&gt;Check out &lt;a href="https://github.com/huggingface/lerobot/raw/main/examples/dataset/load_lerobot_dataset.py"&gt;example 1&lt;/a&gt; that illustrates how to use our dataset class which automatically downloads data from the Hugging Face hub.&lt;/p&gt; 
&lt;p&gt;You can also locally visualize episodes from a dataset on the hub by executing our script from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lerobot-dataset-viz \
    --repo-id lerobot/pusht \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or from a dataset in a local folder with the &lt;code&gt;root&lt;/code&gt; option and the &lt;code&gt;--mode local&lt;/code&gt; (in the following case the dataset will be searched for in &lt;code&gt;./my_local_data_dir/lerobot/pusht&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lerobot-dataset-viz \
    --repo-id lerobot/pusht \
    --root ./my_local_data_dir \
    --mode local \
    --episode-index 0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will open &lt;code&gt;rerun.io&lt;/code&gt; and display the camera streams, robot states and actions, like this:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144"&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/4681518/328035972-fd46b787-b532-47e2-bb6f-fd536a55a7ed.mov?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20240505T172924Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-Signature=d680b26c532eeaf80740f08af3320d22ad0b8a4e4da1bcc4f33142c15b509eda&amp;amp;X-Amz-SignedHeaders=host&amp;amp;actor_id=24889239&amp;amp;key_id=0&amp;amp;repo_id=748713144&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our script can also visualize datasets stored on a distant server. See &lt;code&gt;lerobot-dataset-viz --help&lt;/code&gt; for more instructions.&lt;/p&gt; 
&lt;h3&gt;The &lt;code&gt;LeRobotDataset&lt;/code&gt; format&lt;/h3&gt; 
&lt;p&gt;A dataset in &lt;code&gt;LeRobotDataset&lt;/code&gt; format is very simple to use. It can be loaded from a repository on the Hugging Face hub or a local folder simply with e.g. &lt;code&gt;dataset = LeRobotDataset("lerobot/aloha_static_coffee")&lt;/code&gt; and can be indexed into like any Hugging Face and PyTorch dataset. For instance &lt;code&gt;dataset[0]&lt;/code&gt; will retrieve a single temporal frame from the dataset containing observation(s) and an action as PyTorch tensors ready to be fed to a model.&lt;/p&gt; 
&lt;p&gt;A specificity of &lt;code&gt;LeRobotDataset&lt;/code&gt; is that, rather than retrieving a single frame by its index, we can retrieve several frames based on their temporal relationship with the indexed frame, by setting &lt;code&gt;delta_timestamps&lt;/code&gt; to a list of relative times with respect to the indexed frame. For example, with &lt;code&gt;delta_timestamps = {"observation.image": [-1, -0.5, -0.2, 0]}&lt;/code&gt; one can retrieve, for a given index, 4 frames: 3 "previous" frames 1 second, 0.5 seconds, and 0.2 seconds before the indexed frame, and the indexed frame itself (corresponding to the 0 entry). See example &lt;a href="https://github.com/huggingface/lerobot/raw/main/examples/dataset/load_lerobot_dataset.py"&gt;1_load_lerobot_dataset.py&lt;/a&gt; for more details on &lt;code&gt;delta_timestamps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Under the hood, the &lt;code&gt;LeRobotDataset&lt;/code&gt; format makes use of several ways to serialize data which can be useful to understand if you plan to work more closely with this format. We tried to make a flexible yet simple dataset format that would cover most type of features and specificities present in reinforcement learning and robotics, in simulation and in real-world, with a focus on cameras and robot states but easily extended to other types of sensory inputs as long as they can be represented by a tensor.&lt;/p&gt; 
&lt;p&gt;Here are the important details and internal structure organization of a typical &lt;code&gt;LeRobotDataset&lt;/code&gt; instantiated with &lt;code&gt;dataset = LeRobotDataset("lerobot/aloha_static_coffee")&lt;/code&gt;. The exact features will change from dataset to dataset but not the main aspects:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;dataset attributes:
  â”œ hf_dataset: a Hugging Face dataset (backed by Arrow/parquet). Typical features example:
  â”‚  â”œ observation.images.cam_high (VideoFrame):
  â”‚  â”‚   VideoFrame = {'path': path to a mp4 video, 'timestamp' (float32): timestamp in the video}
  â”‚  â”œ observation.state (list of float32): position of an arm joints (for instance)
  â”‚  ... (more observations)
  â”‚  â”œ action (list of float32): goal position of an arm joints (for instance)
  â”‚  â”œ episode_index (int64): index of the episode for this sample
  â”‚  â”œ frame_index (int64): index of the frame for this sample in the episode ; starts at 0 for each episode
  â”‚  â”œ timestamp (float32): timestamp in the episode
  â”‚  â”œ next.done (bool): indicates the end of an episode ; True for the last frame in each episode
  â”‚  â”” index (int64): general index in the whole dataset
  â”œ meta: a LeRobotDatasetMetadata object containing:
  â”‚  â”œ info: a dictionary of metadata on the dataset
  â”‚  â”‚  â”œ codebase_version (str): this is to keep track of the codebase version the dataset was created with
  â”‚  â”‚  â”œ fps (int): frame per second the dataset is recorded/synchronized to
  â”‚  â”‚  â”œ features (dict): all features contained in the dataset with their shapes and types
  â”‚  â”‚  â”œ total_episodes (int): total number of episodes in the dataset
  â”‚  â”‚  â”œ total_frames (int): total number of frames in the dataset
  â”‚  â”‚  â”œ robot_type (str): robot type used for recording
  â”‚  â”‚  â”œ data_path (str): formattable string for the parquet files
  â”‚  â”‚  â”” video_path (str): formattable string for the video files (if using videos)
  â”‚  â”œ episodes: a DataFrame containing episode metadata with columns:
  â”‚  â”‚  â”œ episode_index (int): index of the episode
  â”‚  â”‚  â”œ tasks (list): list of tasks for this episode
  â”‚  â”‚  â”œ length (int): number of frames in this episode
  â”‚  â”‚  â”œ dataset_from_index (int): start index of this episode in the dataset
  â”‚  â”‚  â”” dataset_to_index (int): end index of this episode in the dataset
  â”‚  â”œ stats: a dictionary of statistics (max, mean, min, std) for each feature in the dataset, for instance
  â”‚  â”‚  â”œ observation.images.front_cam: {'max': tensor with same number of dimensions (e.g. `(c, 1, 1)` for images, `(c,)` for states), etc.}
  â”‚  â”‚  â”” ...
  â”‚  â”” tasks: a DataFrame containing task information with task names as index and task_index as values
  â”œ root (Path): local directory where the dataset is stored
  â”œ image_transforms (Callable): optional image transformations to apply to visual modalities
  â”” delta_timestamps (dict): optional delta timestamps for temporal queries
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A &lt;code&gt;LeRobotDataset&lt;/code&gt; is serialised using several widespread file formats for each of its parts, namely:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;hf_dataset stored using Hugging Face datasets library serialization to parquet&lt;/li&gt; 
 &lt;li&gt;videos are stored in mp4 format to save space&lt;/li&gt; 
 &lt;li&gt;metadata are stored in plain json/jsonl files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Dataset can be uploaded/downloaded from the HuggingFace hub seamlessly. To work on a local dataset, you can specify its location with the &lt;code&gt;root&lt;/code&gt; argument if it's not in the default &lt;code&gt;~/.cache/huggingface/lerobot&lt;/code&gt; location.&lt;/p&gt; 
&lt;h4&gt;Reproduce state-of-the-art (SOTA)&lt;/h4&gt; 
&lt;p&gt;We provide some pretrained policies on our &lt;a href="https://huggingface.co/lerobot"&gt;hub page&lt;/a&gt; that can achieve state-of-the-art performances. You can reproduce their training by loading the config from their run. Simply running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lerobot-train --config_path=lerobot/diffusion_pusht
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;reproduces SOTA results for Diffusion Policy on the PushT task.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;If you would like to contribute to ğŸ¤— LeRobot, please check out our &lt;a href="https://github.com/huggingface/lerobot/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Add a pretrained policy&lt;/h3&gt; 
&lt;p&gt;Once you have trained a policy you may upload it to the Hugging Face hub using a hub id that looks like &lt;code&gt;${hf_user}/${repo_name}&lt;/code&gt; (e.g. &lt;a href="https://huggingface.co/lerobot/diffusion_pusht"&gt;lerobot/diffusion_pusht&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You first need to find the checkpoint folder located inside your experiment directory (e.g. &lt;code&gt;outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500&lt;/code&gt;). Within that there is a &lt;code&gt;pretrained_model&lt;/code&gt; directory which should contain:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;config.json&lt;/code&gt;: A serialized version of the policy configuration (following the policy's dataclass config).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;model.safetensors&lt;/code&gt;: A set of &lt;code&gt;torch.nn.Module&lt;/code&gt; parameters, saved in &lt;a href="https://huggingface.co/docs/safetensors/index"&gt;Hugging Face Safetensors&lt;/a&gt; format.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;train_config.json&lt;/code&gt;: A consolidated configuration containing all parameters used for training. The policy configuration should match &lt;code&gt;config.json&lt;/code&gt; exactly. This is useful for anyone who wants to evaluate your policy or for reproducibility.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To upload these to the hub, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli upload ${hf_user}/${repo_name} path/to/pretrained_model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/huggingface/lerobot/raw/main/src/lerobot/scripts/lerobot_eval.py"&gt;lerobot_eval.py&lt;/a&gt; for an example of how other people may use your policy.&lt;/p&gt; 
&lt;h3&gt;Acknowledgment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The LeRobot team ğŸ¤— for building SmolVLA &lt;a href="https://arxiv.org/abs/2506.01844"&gt;Paper&lt;/a&gt;, &lt;a href="https://huggingface.co/blog/smolvla"&gt;Blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Tony Zhao, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from &lt;a href="https://tonyzhaozh.github.io/aloha"&gt;ALOHA&lt;/a&gt; and &lt;a href="https://mobile-aloha.github.io"&gt;Mobile ALOHA&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from &lt;a href="https://diffusion-policy.cs.columbia.edu"&gt;Diffusion Policy&lt;/a&gt; and &lt;a href="https://umi-gripper.github.io"&gt;UMI Gripper&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from &lt;a href="https://github.com/nicklashansen/tdmpc"&gt;TDMPC&lt;/a&gt; and &lt;a href="https://www.yunhaifeng.com/FOWM"&gt;FOWM&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to Antonio Loquercio and Ashish Kumar for their early support.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://sjlee.cc/"&gt;Seungjae (Jay) Lee&lt;/a&gt;, &lt;a href="https://mahis.life/"&gt;Mahi Shafiullah&lt;/a&gt; and colleagues for open sourcing &lt;a href="https://sjlee.cc/vq-bet/"&gt;VQ-BeT&lt;/a&gt; policy and helping us adapt the codebase to our repository. The policy is adapted from &lt;a href="https://github.com/jayLEE0301/vq_bet_official"&gt;VQ-BeT repo&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you want, you can cite this work with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{cadene2024lerobot,
    author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Palma, Steven and Kooijmans, Pepijn and Aractingi, Michel and Shukor, Mustafa and Aubakirova, Dana and Russi, Martino and Capuano, Francesco and Pascal, Caroline and Choghari, Jade and Moss, Jess and Wolf, Thomas},
    title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch},
    howpublished = "\url{https://github.com/huggingface/lerobot}",
    year = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#huggingface/lerobot&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=huggingface/lerobot&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>allenai/olmocr</title>
      <link>https://github.com/allenai/olmocr</link>
      <description>&lt;p&gt;Toolkit for linearizing PDFs for LLM datasets/training&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img width="350" alt="olmocr-2-full@2x" src="https://github.com/user-attachments/assets/24f1b596-4059-46f1-8130-5d72dcc0b02e" /&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/allenai/OLMo/raw/main/LICENSE"&gt; &lt;img alt="GitHub License" src="https://img.shields.io/github/license/allenai/OLMo" /&gt; &lt;/a&gt; &lt;a href="https://github.com/allenai/olmocr/releases"&gt; &lt;img alt="GitHub release" src="https://img.shields.io/github/release/allenai/olmocr.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://arxiv.org/abs/2502.18443"&gt; &lt;img alt="Tech Report v1" src="https://img.shields.io/badge/Paper_v1-olmOCR-blue" /&gt; &lt;/a&gt; &lt;a href="https://arxiv.org/abs/2510.19817"&gt; &lt;img alt="Tech Report v2" src="https://img.shields.io/badge/Paper_v2-olmOCR-blue" /&gt; &lt;/a&gt; &lt;a href="https://olmocr.allenai.org"&gt; &lt;img alt="Demo" src="https://img.shields.io/badge/Ai2-Demo-F0529C" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/sZq3jTNVNG"&gt; &lt;img alt="Discord" src="https://img.shields.io/badge/Discord%20-%20blue?style=flat&amp;amp;logo=discord&amp;amp;label=Ai2&amp;amp;color=%235B65E9" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;A toolkit for converting PDFs and other image-based document formats into clean, readable, plain text format.&lt;/p&gt; 
&lt;p&gt;Try the online demo: &lt;a href="https://olmocr.allenai.org/"&gt;https://olmocr.allenai.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert PDF, PNG, and JPEG based documents into clean Markdown&lt;/li&gt; 
 &lt;li&gt;Support for equations, tables, handwriting, and complex formatting&lt;/li&gt; 
 &lt;li&gt;Automatically removes headers and footers&lt;/li&gt; 
 &lt;li&gt;Convert into text with a natural reading order, even in the presence of figures, multi-column layouts, and insets&lt;/li&gt; 
 &lt;li&gt;Efficient, less than $200 USD per million pages converted&lt;/li&gt; 
 &lt;li&gt;(Based on a 7B parameter VLM, so it requires a GPU)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;News&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 21, 2025 - v0.4.0 - &lt;a href="https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8"&gt;New model release&lt;/a&gt;, boosts olmOCR-bench score by ~4 points using synthetic data and introduces RL training.&lt;/li&gt; 
 &lt;li&gt;August 13, 2025 - v0.3.0 - &lt;a href="https://huggingface.co/allenai/olmOCR-7B-0825-FP8"&gt;New model release&lt;/a&gt;, fixes auto-rotation detection, and hallucinations on blank documents.&lt;/li&gt; 
 &lt;li&gt;July 24, 2025 - v0.2.1 - &lt;a href="https://huggingface.co/allenai/olmOCR-7B-0725-FP8"&gt;New model release&lt;/a&gt;, scores 3 points higher on &lt;a href="https://github.com/allenai/olmocr/tree/main/olmocr/bench"&gt;olmOCR-Bench&lt;/a&gt;, also runs significantly faster because it's default FP8, and needs much fewer retries per document.&lt;/li&gt; 
 &lt;li&gt;July 23, 2025 - v0.2.0 - New cleaned up &lt;a href="https://github.com/allenai/olmocr/tree/main/olmocr/train"&gt;trainer code&lt;/a&gt;, makes it much simpler to train olmOCR models yourself.&lt;/li&gt; 
 &lt;li&gt;June 17, 2025 - v0.1.75 - Switch from sglang to vllm based inference pipeline, updated docker image to CUDA 12.8.&lt;/li&gt; 
 &lt;li&gt;May 23, 2025 - v0.1.70 - Official docker support and images are now available! &lt;a href="https://raw.githubusercontent.com/allenai/olmocr/main/#using-docker"&gt;See Docker usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 19, 2025 - v0.1.68 - &lt;a href="https://github.com/allenai/olmocr/tree/main/olmocr/bench"&gt;olmOCR-Bench&lt;/a&gt; launch, scoring 77.4. Launch includes 2 point performance boost in olmOCR pipeline due to bug fixes with prompts.&lt;/li&gt; 
 &lt;li&gt;Mar 17, 2025 - v0.1.60 - Performance improvements due to better temperature selection in sampling.&lt;/li&gt; 
 &lt;li&gt;Feb 25, 2025 - v0.1.58 - Initial public launch and demo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/allenai/olmocr/tree/main/olmocr/bench"&gt;&lt;strong&gt;olmOCR-Bench&lt;/strong&gt;&lt;/a&gt;: We also ship a comprehensive benchmark suite covering over 7,000 test cases across 1,400 documents to help measure performance of OCR systems.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;ArXiv&lt;/th&gt; 
   &lt;th&gt;Old&lt;br /&gt;scans&lt;br /&gt;math&lt;/th&gt; 
   &lt;th&gt;Tables&lt;/th&gt; 
   &lt;th&gt;Old&lt;br /&gt;scans&lt;/th&gt; 
   &lt;th&gt;Headers&lt;br /&gt;&amp;amp;&lt;br /&gt;footers&lt;/th&gt; 
   &lt;th&gt;Multi&lt;br /&gt;column&lt;/th&gt; 
   &lt;th&gt;Long&lt;br /&gt;tiny&lt;br /&gt;text&lt;/th&gt; 
   &lt;th&gt;Base&lt;/th&gt; 
   &lt;th&gt;Overall&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral OCR API&lt;/td&gt; 
   &lt;td&gt;77.2&lt;/td&gt; 
   &lt;td&gt;67.5&lt;/td&gt; 
   &lt;td&gt;60.6&lt;/td&gt; 
   &lt;td&gt;29.3&lt;/td&gt; 
   &lt;td&gt;93.6&lt;/td&gt; 
   &lt;td&gt;71.3&lt;/td&gt; 
   &lt;td&gt;77.1&lt;/td&gt; 
   &lt;td&gt;99.4&lt;/td&gt; 
   &lt;td&gt;72.0Â±1.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Marker 1.10.1&lt;/td&gt; 
   &lt;td&gt;83.8&lt;/td&gt; 
   &lt;td&gt;66.8&lt;/td&gt; 
   &lt;td&gt;72.9&lt;/td&gt; 
   &lt;td&gt;33.5&lt;/td&gt; 
   &lt;td&gt;86.6&lt;/td&gt; 
   &lt;td&gt;80.0&lt;/td&gt; 
   &lt;td&gt;85.7&lt;/td&gt; 
   &lt;td&gt;99.3&lt;/td&gt; 
   &lt;td&gt;76.1Â±1.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinerU 2.5.4*&lt;/td&gt; 
   &lt;td&gt;76.6&lt;/td&gt; 
   &lt;td&gt;54.6&lt;/td&gt; 
   &lt;td&gt;84.9&lt;/td&gt; 
   &lt;td&gt;33.7&lt;/td&gt; 
   &lt;td&gt;96.6&lt;/td&gt; 
   &lt;td&gt;78.2&lt;/td&gt; 
   &lt;td&gt;83.5&lt;/td&gt; 
   &lt;td&gt;93.7&lt;/td&gt; 
   &lt;td&gt;75.2Â±1.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-OCR&lt;/td&gt; 
   &lt;td&gt;77.2&lt;/td&gt; 
   &lt;td&gt;73.6&lt;/td&gt; 
   &lt;td&gt;80.2&lt;/td&gt; 
   &lt;td&gt;33.3&lt;/td&gt; 
   &lt;td&gt;96.1&lt;/td&gt; 
   &lt;td&gt;66.4&lt;/td&gt; 
   &lt;td&gt;79.4&lt;/td&gt; 
   &lt;td&gt;99.8&lt;/td&gt; 
   &lt;td&gt;75.7Â±1.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nanonets-OCR2-3B&lt;/td&gt; 
   &lt;td&gt;75.4&lt;/td&gt; 
   &lt;td&gt;46.1&lt;/td&gt; 
   &lt;td&gt;86.8&lt;/td&gt; 
   &lt;td&gt;40.9&lt;/td&gt; 
   &lt;td&gt;32.1&lt;/td&gt; 
   &lt;td&gt;81.9&lt;/td&gt; 
   &lt;td&gt;93.0&lt;/td&gt; 
   &lt;td&gt;99.6&lt;/td&gt; 
   &lt;td&gt;69.5Â±1.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PaddleOCR-VL*&lt;/td&gt; 
   &lt;td&gt;85.7&lt;/td&gt; 
   &lt;td&gt;71.0&lt;/td&gt; 
   &lt;td&gt;84.1&lt;/td&gt; 
   &lt;td&gt;37.8&lt;/td&gt; 
   &lt;td&gt;97.0&lt;/td&gt; 
   &lt;td&gt;79.9&lt;/td&gt; 
   &lt;td&gt;85.7&lt;/td&gt; 
   &lt;td&gt;98.5&lt;/td&gt; 
   &lt;td&gt;80.0Â±1.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Infinity-Parser 7B*&lt;/td&gt; 
   &lt;td&gt;84.4&lt;/td&gt; 
   &lt;td&gt;83.8&lt;/td&gt; 
   &lt;td&gt;85.0&lt;/td&gt; 
   &lt;td&gt;47.9&lt;/td&gt; 
   &lt;td&gt;88.7&lt;/td&gt; 
   &lt;td&gt;84.2&lt;/td&gt; 
   &lt;td&gt;86.4&lt;/td&gt; 
   &lt;td&gt;99.8&lt;/td&gt; 
   &lt;td&gt;82.5Â±?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chandra OCR 0.1.0*&lt;/td&gt; 
   &lt;td&gt;82.2&lt;/td&gt; 
   &lt;td&gt;80.3&lt;/td&gt; 
   &lt;td&gt;88.0&lt;/td&gt; 
   &lt;td&gt;50.4&lt;/td&gt; 
   &lt;td&gt;90.8&lt;/td&gt; 
   &lt;td&gt;81.2&lt;/td&gt; 
   &lt;td&gt;92.3&lt;/td&gt; 
   &lt;td&gt;99.9&lt;/td&gt; 
   &lt;td&gt;83.1Â±0.9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="10"&gt;
    &lt;hr /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;olmOCR v0.4.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;83.0&lt;/td&gt; 
   &lt;td&gt;82.3&lt;/td&gt; 
   &lt;td&gt;84.9&lt;/td&gt; 
   &lt;td&gt;47.7&lt;/td&gt; 
   &lt;td&gt;96.1&lt;/td&gt; 
   &lt;td&gt;83.7&lt;/td&gt; 
   &lt;td&gt;81.9&lt;/td&gt; 
   &lt;td&gt;99.7&lt;/td&gt; 
   &lt;td&gt;82.4Â±1.1&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Recent NVIDIA GPU (tested on RTX 4090, L40S, A100, H100) with at least 15 GB of GPU RAM&lt;/li&gt; 
 &lt;li&gt;30GB of free disk space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You will need to install poppler-utils and additional fonts for rendering PDF images.&lt;/p&gt; 
&lt;p&gt;Install dependencies (Ubuntu/Debian)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get update
sudo apt-get install poppler-utils ttf-mscorefonts-installer msttcorefonts fonts-crosextra-caladea fonts-crosextra-carlito gsfonts lcdf-typetools
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set up a conda environment and install olmocr. The requirements for running olmOCR are difficult to install in an existing python environment, so please do make a clean python environment to install into.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n olmocr python=3.11
conda activate olmocr

# For CPU-only operations, ex running the benchmark
pip install olmocr[bench]

# For actually converting the files with your own GPU
pip install olmocr[gpu]  --extra-index-url https://download.pytorch.org/whl/cu128

# Recommended: Install flash infer for faster inference on GPU
pip install https://download.pytorch.org/whl/cu128/flashinfer/flashinfer_python-0.2.5%2Bcu128torch2.7-cp38-abi3-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Usage Example&lt;/h3&gt; 
&lt;p&gt;For quick testing, try the &lt;a href="https://olmocr.allen.ai/"&gt;web demo&lt;/a&gt;. To run locally, a GPU is required, as inference is powered by &lt;a href="https://github.com/sgl-project/sglang"&gt;sglang&lt;/a&gt; under the hood.&lt;/p&gt; 
&lt;p&gt;Convert a Single PDF:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download a sample PDF
curl -o olmocr-sample.pdf https://olmocr.allenai.org/papers/olmocr_3pg_sample.pdf

# Convert it to markdown
python -m olmocr.pipeline ./localworkspace --markdown --pdfs olmocr-sample.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Convert an Image file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline ./localworkspace --markdown --pdfs random_page.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Convert Multiple PDFs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline ./localworkspace --markdown --pdfs tests/gnarly_pdfs/*.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the addition of the &lt;code&gt;--markdown&lt;/code&gt; flag, results will be stored as markdown files inside of &lt;code&gt;./localworkspace/markdown/&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Viewing Results&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;./localworkspace/&lt;/code&gt; workspace folder will then have both &lt;a href="https://github.com/allenai/dolma"&gt;Dolma&lt;/a&gt; and markdown files (if using &lt;code&gt;--markdown&lt;/code&gt;).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat localworkspace/markdown/olmocr-sample.md 
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using an Inference Provider or External Server&lt;/h3&gt; 
&lt;p&gt;If you have a vLLM server already running elsewhere (or any inference platform implementing the OpenAI API), you can point olmOCR to use it instead of spawning a local instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use external vLLM server instead of local one
python -m olmocr.pipeline ./localworkspace --server http://remote-server:8000/v1 --markdown --pdfs tests/gnarly_pdfs/*.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The served model name should be &lt;code&gt;olmocr&lt;/code&gt;. An example vLLM launch command would be:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve allenai/olmOCR-2-7B-1025-FP8 --served-model-name olmocr --max-model-len 16384
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Verified External Providers&lt;/h4&gt; 
&lt;p&gt;We have tested &lt;code&gt;olmOCR-2-7B-1025-FP8&lt;/code&gt; on these external model providers and confirmed that they work&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;$/1M Input tokens&lt;/th&gt; 
   &lt;th&gt;$/1M Output tokens&lt;/th&gt; 
   &lt;th&gt;Example Command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ai2endpoints.cirrascale.ai/models/overview"&gt;Cirrascale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;$0.07&lt;/td&gt; 
   &lt;td&gt;$0.15&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python -m olmocr.pipeline ./localworkspace1 --server https://ai2endpoints.cirrascale.ai/api --api_key sk-XXXXXXX --model olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://deepinfra.com/"&gt;DeepInfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;$0.09&lt;/td&gt; 
   &lt;td&gt;$0.19&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python -m olmocr.pipeline ./localworkspace1 --server https://api.deepinfra.com/v1/openai --api_key DfXXXXXXX --model allenai/olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.saas.parasail.io/serverless?name=olmocr-7b-1025-fp8"&gt;Parasail&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;$0.10&lt;/td&gt; 
   &lt;td&gt;$0.20&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python -m olmocr.pipeline ./localworkspace1 --server https://api.parasail.io/v1 --api_key psk-XXXXX --model allenai/olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Notes on arguments&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--server&lt;/code&gt;: Defines the OpenAI-compatible endpoint: ex &lt;code&gt;https://api.deepinfra.com/v1/openai&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--api_key&lt;/code&gt;: Your API key, bassed in via Authorization Bearer HTTP header&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--pages_per_group&lt;/code&gt;: You may want a smaller number of pages per group as many external provides have lower concurrent request limits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--model&lt;/code&gt;: The model identifier, ex. &lt;code&gt;allenai/olmOCR-2-7B-1025&lt;/code&gt;, different providers have different names, and if you run locally, you can use &lt;code&gt;olmocr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Other arguments work the same as with local inference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multi-node / Cluster Usage&lt;/h3&gt; 
&lt;p&gt;If you want to convert millions of PDFs, using multiple nodes running in parallel, then olmOCR supports reading your PDFs from AWS S3, and coordinating work using an AWS S3 output bucket.&lt;/p&gt; 
&lt;p&gt;For example, you can start this command on your first worker node, and it will set up a simple work queue in your AWS bucket and start converting PDFs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace --pdfs s3://my_s3_bucket/jakep/gnarly_pdfs/*.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now on any subsequent nodes, just run this and they will start grabbing items from the same workspace queue.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are at Ai2 and want to linearize millions of PDFs efficiently using &lt;a href="https://www.beaker.org"&gt;beaker&lt;/a&gt;, just add the &lt;code&gt;--beaker&lt;/code&gt; flag. This will prepare the workspace on your local machine, and then launch N GPU workers in the cluster to start converting PDFs.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace --pdfs s3://my_s3_bucket/jakep/gnarly_pdfs/*.pdf --beaker --beaker_gpus 4
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;p&gt;Pull the Docker image.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull alleninstituteforai/olmocr:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the container interactively:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --gpus all --name olmocr_container alleninstituteforai/olmocr:latest /bin/bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to access your local files inside the container, use volume mounting:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --gpus all \
  -v /path/to/your/local/files:/local_files \
  --name olmocr_container \
  alleninstituteforai/olmocr:latest /bin/bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All dependencies are already installed. Once youâ€™re inside the container, you can run olmOCR commands. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -o olmocr-sample.pdf https://olmocr.allenai.org/papers/olmocr_3pg_sample.pdf

python -m olmocr.pipeline ./localworkspace --markdown --pdfs olmocr-sample.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can also visit our Docker repository on &lt;a href="https://hub.docker.com/r/alleninstituteforai/olmocr"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Full documentation for the pipeline&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m olmocr.pipeline --help
usage: pipeline.py [-h] [--pdfs [PDFS ...]] [--model MODEL] [--workspace_profile WORKSPACE_PROFILE] [--pdf_profile PDF_PROFILE] [--pages_per_group PAGES_PER_GROUP] [--max_page_retries MAX_PAGE_RETRIES] [--max_page_error_rate MAX_PAGE_ERROR_RATE] [--workers WORKERS]
                   [--apply_filter] [--stats] [--markdown] [--target_longest_image_dim TARGET_LONGEST_IMAGE_DIM] [--target_anchor_text_len TARGET_ANCHOR_TEXT_LEN] [--guided_decoding] [--gpu-memory-utilization GPU_MEMORY_UTILIZATION] [--max_model_len MAX_MODEL_LEN]
                   [--tensor-parallel-size TENSOR_PARALLEL_SIZE] [--data-parallel-size DATA_PARALLEL_SIZE] [--port PORT] [--server SERVER] [--beaker] [--beaker_workspace BEAKER_WORKSPACE] [--beaker_cluster BEAKER_CLUSTER] [--beaker_gpus BEAKER_GPUS] [--beaker_priority BEAKER_PRIORITY]
                   workspace

Manager for running millions of PDFs through a batch inference pipeline

positional arguments:
  workspace             The filesystem path where work will be stored, can be a local folder, or an s3 path if coordinating work with many workers, s3://bucket/prefix/

options:
  -h, --help            show this help message and exit
  --pdfs [PDFS ...]     Path to add pdfs stored in s3 to the workspace, can be a glob path s3://bucket/prefix/*.pdf or path to file containing list of pdf paths
  --model MODEL         Path where the model is located, allenai/olmOCR-7B-0725-FP8 is the default, can be local, s3, or hugging face.
  --workspace_profile WORKSPACE_PROFILE
                        S3 configuration profile for accessing the workspace
  --pdf_profile PDF_PROFILE
                        S3 configuration profile for accessing the raw pdf documents
  --pages_per_group PAGES_PER_GROUP
                        Aiming for this many pdf pages per work item group
  --max_page_retries MAX_PAGE_RETRIES
                        Max number of times we will retry rendering a page
  --max_page_error_rate MAX_PAGE_ERROR_RATE
                        Rate of allowable failed pages in a document, 1/250 by default
  --workers WORKERS     Number of workers to run at a time
  --apply_filter        Apply basic filtering to English pdfs which are not forms, and not likely seo spam
  --stats               Instead of running any job, reports some statistics about the current workspace
  --markdown            Also write natural text to markdown files preserving the folder structure of the input pdfs
  --target_longest_image_dim TARGET_LONGEST_IMAGE_DIM
                        Dimension on longest side to use for rendering the pdf pages
  --target_anchor_text_len TARGET_ANCHOR_TEXT_LEN
                        Maximum amount of anchor text to use (characters), not used for new models
  --guided_decoding     Enable guided decoding for model YAML type outputs

VLLM arguments:
  --gpu-memory-utilization GPU_MEMORY_UTILIZATION
                        Fraction of VRAM vLLM may pre-allocate for KV-cache (passed through to vllm serve).
  --max_model_len MAX_MODEL_LEN
                        Upper bound (tokens) vLLM will allocate KV-cache for, lower if VLLM won't start
  --tensor-parallel-size TENSOR_PARALLEL_SIZE, -tp TENSOR_PARALLEL_SIZE
                        Tensor parallel size for vLLM
  --data-parallel-size DATA_PARALLEL_SIZE, -dp DATA_PARALLEL_SIZE
                        Data parallel size for vLLM
  --port PORT           Port to use for the VLLM server
  --server SERVER       URL of external vLLM (or other compatible provider)
                        server (e.g., http://hostname:port). If provided,
                        skips spawning local vLLM instance

beaker/cluster execution:
  --beaker              Submit this job to beaker instead of running locally
  --beaker_workspace BEAKER_WORKSPACE
                        Beaker workspace to submit to
  --beaker_cluster BEAKER_CLUSTER
                        Beaker clusters you want to run on
  --beaker_gpus BEAKER_GPUS
                        Number of gpu replicas to run
  --beaker_priority BEAKER_PRIORITY
                        Beaker priority level for the job
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Code overview&lt;/h2&gt; 
&lt;p&gt;There are some nice reusable pieces of the code that may be useful for your own projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A prompting strategy to get really good natural text parsing using ChatGPT 4o - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/data/buildsilver.py"&gt;buildsilver.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Basic filtering by language and SEO spam removal - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/filter/filter.py"&gt;filter.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SFT Finetuning code for Qwen2.5-VL - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/train/train.py"&gt;train.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GRPO RL Trainer - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/train/grpo_train.py"&gt;grpo_train.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Synthetic data generation - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/bench/synth/mine_html_templates.py"&gt;mine_html_templates.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Processing millions of PDFs through a finetuned model using VLLM - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/pipeline.py"&gt;pipeline.py&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Viewing &lt;a href="https://github.com/allenai/dolma"&gt;Dolma docs&lt;/a&gt; created from PDFs - &lt;a href="https://github.com/allenai/olmocr/raw/main/olmocr/viewer/dolmaviewer.py"&gt;dolmaviewer.py&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Team&lt;/h2&gt; 
&lt;!-- start team --&gt; 
&lt;p&gt;&lt;strong&gt;olmOCR&lt;/strong&gt; is developed and maintained by the AllenNLP team, backed by &lt;a href="https://allenai.org/"&gt;the Allen Institute for Artificial Intelligence (AI2)&lt;/a&gt;. AI2 is a non-profit institute with the mission to contribute to humanity through high-impact AI research and engineering. To learn more about who specifically contributed to this codebase, see &lt;a href="https://github.com/allenai/olmocr/graphs/contributors"&gt;our contributors&lt;/a&gt; page.&lt;/p&gt; 
&lt;!-- end team --&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;!-- start license --&gt; 
&lt;p&gt;&lt;strong&gt;olmOCR&lt;/strong&gt; is licensed under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache 2.0&lt;/a&gt;. A full copy of the license can be found &lt;a href="https://github.com/allenai/olmocr/raw/main/LICENSE"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- end license --&gt; 
&lt;h2&gt;Citing&lt;/h2&gt; 
&lt;p&gt;For olmOCR v1 and OlmOCR-bench:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{olmocrbench,
      title={{olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models}},
      author={Jake Poznanski and Jon Borchardt and Jason Dunkelberger and Regan Huff and Daniel Lin and Aman Rangapur and Christopher Wilhelm and Kyle Lo and Luca Soldaini},
      year={2025},
      eprint={2502.18443},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.18443},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For olmOCR v2 Unit Testing Rewards with RL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{olmocr2,
      title={olmOCR 2: Unit Test Rewards for Document OCR}, 
      author={Jake Poznanski and Luca Soldaini and Kyle Lo},
      year={2025},
      eprint={2510.19817},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.19817}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/deepagents</title>
      <link>https://github.com/langchain-ai/deepagents</link>
      <description>&lt;p&gt;Deepagents is an agent harness built on langchain and langgraph. Deep agents are equipped with a planning tool, a filesystem backend, and the ability to spawn subagents - making them well-equipped to handle complex agentic tasks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ§ ğŸ¤–Deep Agents&lt;/h1&gt; 
&lt;p&gt;Using an LLM to call tools in a loop is the simplest form of an agent. This architecture, however, can yield agents that are â€œshallowâ€ and fail to plan and act over longer, more complex tasks.&lt;/p&gt; 
&lt;p&gt;Applications like â€œDeep Researchâ€, "Manus", and â€œClaude Codeâ€ have gotten around this limitation by implementing a combination of four things: a &lt;strong&gt;planning tool&lt;/strong&gt;, &lt;strong&gt;sub agents&lt;/strong&gt;, access to a &lt;strong&gt;file system&lt;/strong&gt;, and a &lt;strong&gt;detailed prompt&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/langchain-ai/deepagents/master/deep_agents.png" alt="deep agent" width="600" /&gt; 
&lt;p&gt;&lt;code&gt;deepagents&lt;/code&gt; is a Python package that implements these in a general purpose way so that you can easily create a Deep Agent for your application. For a full overview and quickstart of &lt;code&gt;deepagents&lt;/code&gt;, the best resource is our &lt;a href="https://docs.langchain.com/oss/python/deepagents/overview"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Acknowledgements: This project was primarily inspired by Claude Code, and initially was largely an attempt to see what made Claude Code general purpose, and make it even more so.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# pip
pip install deepagents

# uv
uv add deepagents

# poetry
poetry add deepagents
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;(To run the example below, you will need to &lt;code&gt;pip install tavily-python&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Make sure to set &lt;code&gt;TAVILY_API_KEY&lt;/code&gt; in your environment. You can generate one &lt;a href="https://www.tavily.com/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# Web search tool
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )


# System prompt to steer the agent to be an expert researcher
research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.

You have access to an internet search tool as your primary means of gathering information.

## `internet_search`

Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.
"""

# Create the deep agent
agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_instructions,
)

# Invoke the agent
result = agent.invoke({"messages": [{"role": "user", "content": "What is langgraph?"}]})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/langchain-ai/deepagents/master/examples/research/research_agent.py"&gt;examples/research/research_agent.py&lt;/a&gt; for a more complex example.&lt;/p&gt; 
&lt;p&gt;The agent created with &lt;code&gt;create_deep_agent&lt;/code&gt; is just a LangGraph graph - so you can interact with it (streaming, human-in-the-loop, memory, studio) in the same way you would any LangGraph agent.&lt;/p&gt; 
&lt;h2&gt;Core Capabilities&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Planning &amp;amp; Task Decomposition&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Deep Agents include a built-in &lt;code&gt;write_todos&lt;/code&gt; tool that enables agents to break down complex tasks into discrete steps, track progress, and adapt plans as new information emerges.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Context Management&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;File system tools (&lt;code&gt;ls&lt;/code&gt;, &lt;code&gt;read_file&lt;/code&gt;, &lt;code&gt;write_file&lt;/code&gt;, &lt;code&gt;edit_file&lt;/code&gt;, &lt;code&gt;glob&lt;/code&gt;, &lt;code&gt;grep&lt;/code&gt;) allow agents to offload large context to memory, preventing context window overflow and enabling work with variable-length tool results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Subagent Spawning&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;A built-in &lt;code&gt;task&lt;/code&gt; tool enables agents to spawn specialized subagents for context isolation. This keeps the main agentâ€™s context clean while still going deep on specific subtasks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Long-term Memory&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend agents with persistent memory across threads using LangGraphâ€™s Store. Agents can save and retrieve information from previous conversations.&lt;/p&gt; 
&lt;h2&gt;Customizing Deep Agents&lt;/h2&gt; 
&lt;p&gt;There are several parameters you can pass to &lt;code&gt;create_deep_agent&lt;/code&gt; to create your own custom deep agent.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;model&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;By default, &lt;code&gt;deepagents&lt;/code&gt; uses &lt;code&gt;"claude-sonnet-4-5-20250929"&lt;/code&gt;. You can customize this by passing any &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;LangChain model object&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.chat_models import init_chat_model
from deepagents import create_deep_agent

model = init_chat_model("openai:gpt-4o")
agent = create_deep_agent(
    model=model,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;system_prompt&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Deep Agents come with a built-in system prompt. This is relatively detailed prompt that is heavily based on and inspired by &lt;a href="https://github.com/kn1026/cc/raw/main/claudecode.md"&gt;attempts&lt;/a&gt; to &lt;a href="https://github.com/asgeirtj/system_prompts_leaks/raw/main/Anthropic/claude-code.md"&gt;replicate&lt;/a&gt; Claude Code's system prompt. It was made more general purpose than Claude Code's system prompt. The default prompt contains detailed instructions for how to use the built-in planning tool, file system tools, and sub agents.&lt;/p&gt; 
&lt;p&gt;Each deep agent tailored to a use case should include a custom system prompt specific to that use case as well. The importance of prompting for creating a successful deep agent cannot be overstated.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepagents import create_deep_agent

research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.
"""

agent = create_deep_agent(
    system_prompt=research_instructions,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;tools&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Just like with tool-calling agents, you can provide a deep agent with a set of tools that it has access to.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

agent = create_deep_agent(
    tools=[internet_search]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;middleware&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;create_deep_agent&lt;/code&gt; is implemented with middleware that can be customized. You can provide additional middleware to extend functionality, add tools, or implement custom hooks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from deepagents import create_deep_agent
from langchain.agents.middleware import AgentMiddleware

@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

@tool
def get_temperature(city: str) -&amp;gt; str:
    """Get the temperature in a city."""
    return f"The temperature in {city} is 70 degrees Fahrenheit."

class WeatherMiddleware(AgentMiddleware):
  tools = [get_weather, get_temperature]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[WeatherMiddleware()]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;subagents&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;A main feature of Deep Agents is their ability to spawn subagents. You can specify custom subagents that your agent can hand off work to in the subagents parameter. Sub agents are useful for context quarantine (to help not pollute the overall context of the main agent) as well as custom instructions.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;subagents&lt;/code&gt; should be a list of dictionaries, where each dictionary follow this schema:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class SubAgent(TypedDict):
    name: str
    description: str
    prompt: str
    tools: Sequence[BaseTool | Callable | dict[str, Any]]
    model: NotRequired[str | BaseChatModel]
    middleware: NotRequired[list[AgentMiddleware]]
    interrupt_on: NotRequired[dict[str, bool | InterruptOnConfig]]

class CompiledSubAgent(TypedDict):
    name: str
    description: str
    runnable: Runnable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;SubAgent fields:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: This is the name of the subagent, and how the main agent will call the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;description&lt;/strong&gt;: This is the description of the subagent that is shown to the main agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;prompt&lt;/strong&gt;: This is the prompt used for the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;tools&lt;/strong&gt;: This is the list of tools that the subagent has access to.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;model&lt;/strong&gt;: Optional model name or model instance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;middleware&lt;/strong&gt; Additional middleware to attach to the subagent. See &lt;a href="https://docs.langchain.com/oss/python/langchain/middleware"&gt;here&lt;/a&gt; for an introduction into middleware and how it works with create_agent.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;interrupt_on&lt;/strong&gt; A custom interrupt config that specifies human-in-the-loop interactions for your tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;CompiledSubAgent fields:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt;: This is the name of the subagent, and how the main agent will call the subagent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;description&lt;/strong&gt;: This is the description of the subagent that is shown to the main agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;runnable&lt;/strong&gt;: A pre-built LangGraph graph/agent that will be used as the subagent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using SubAgent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

research_subagent = {
    "name": "research-agent",
    "description": "Used to research more in depth questions",
    "system_prompt": "You are a great researcher",
    "tools": [internet_search],
    "model": "openai:gpt-4o",  # Optional override, defaults to main agent model
}
subagents = [research_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    subagents=subagents
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using CustomSubAgent&lt;/h4&gt; 
&lt;p&gt;For more complex use cases, you can provide your own pre-built LangGraph graph as a subagent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a custom agent graph
custom_graph = create_agent(
    model=your_model,
    tools=specialized_tools,
    prompt="You are a specialized agent for data analysis..."
)

# Use it as a custom subagent
custom_subagent = CompiledSubAgent(
    name="data-analyzer",
    description="Specialized agent for complex data analysis tasks",
    runnable=custom_graph
)

subagents = [custom_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[internet_search],
    system_prompt=research_instructions,
    subagents=subagents
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;interrupt_on&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;A common reality for agents is that some tool operations may be sensitive and require human approval before execution. Deep Agents supports human-in-the-loop workflows through LangGraphâ€™s interrupt capabilities. You can configure which tools require approval using a checkpointer.&lt;/p&gt; 
&lt;p&gt;These tool configs are passed to our prebuilt &lt;a href="https://docs.langchain.com/oss/python/langchain/middleware#human-in-the-loop"&gt;HITL middleware&lt;/a&gt; so that the agent pauses execution and waits for feedback from the user before executing configured tools.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from deepagents import create_deep_agent

@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[get_weather],
    interrupt_on={
        "get_weather": {
            "allowed_decisions": ["approve", "edit", "reject"]
        },
    }
)

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Deep Agents Middleware&lt;/h2&gt; 
&lt;p&gt;Deep Agents are built with a modular middleware architecture. As a reminder, Deep Agents have access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A planning tool&lt;/li&gt; 
 &lt;li&gt;A filesystem for storing context and long-term memories&lt;/li&gt; 
 &lt;li&gt;The ability to spawn subagents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each of these features is implemented as separate middleware. When you create a deep agent with &lt;code&gt;create_deep_agent&lt;/code&gt;, we automatically attach &lt;strong&gt;TodoListMiddleware&lt;/strong&gt;, &lt;strong&gt;FilesystemMiddleware&lt;/strong&gt; and &lt;strong&gt;SubAgentMiddleware&lt;/strong&gt; to your agent.&lt;/p&gt; 
&lt;p&gt;Middleware is a composable concept, and you can choose to add as many or as few middleware to an agent depending on your use case. That means that you can also use any of the aforementioned middleware independently!&lt;/p&gt; 
&lt;h3&gt;TodoListMiddleware&lt;/h3&gt; 
&lt;p&gt;Planning is integral to solving complex problems. If youâ€™ve used claude code recently, youâ€™ll notice how it writes out a To-Do list before tackling complex, multi-part tasks. Youâ€™ll also notice how it can adapt and update this To-Do list on the fly as more information comes in.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TodoListMiddleware&lt;/strong&gt; provides your agent with a tool specifically for updating this To-Do list. Before, and while it executes a multi-part task, the agent is prompted to use the write_todos tool to keep track of what its doing, and what still needs to be done.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.agents import create_agent
from langchain.agents.middleware import TodoListMiddleware

# TodoListMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    # Custom planning instructions can be added via middleware
    middleware=[
        TodoListMiddleware(
            system_prompt="Use the write_todos tool to..."  # Optional: Custom addition to the system prompt
        ),
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FilesystemMiddleware&lt;/h3&gt; 
&lt;p&gt;Context engineering is one of the main challenges in building effective agents. This can be particularly hard when using tools that can return variable length results (ex. web_search, rag), as long ToolResults can quickly fill up your context window. &lt;strong&gt;FilesystemMiddleware&lt;/strong&gt; provides four tools to your agent to interact with both short-term and long-term memory.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ls&lt;/strong&gt;: List the files in your filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;read_file&lt;/strong&gt;: Read an entire file, or a certain number of lines from a file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;write_file&lt;/strong&gt;: Write a new file to your filesystem&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;edit_file&lt;/strong&gt;: Edit an existing file in your filesystem&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain.agents import create_agent
from deepagents.middleware.filesystem import FilesystemMiddleware


# FilesystemMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        FilesystemMiddleware(
            backend=..., # Optional: customize storage backend
            system_prompt="Write to the filesystem when...",  # Optional custom system prompt override
            custom_tool_descriptions={
                "ls": "Use the ls tool when...",
                "read_file": "Use the read_file tool to..."
            }  # Optional: Custom descriptions for filesystem tools
        ),
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;SubAgentMiddleware&lt;/h3&gt; 
&lt;p&gt;Handing off tasks to subagents is a great way to isolate context, keeping the context window of the main (supervisor) agent clean while still going deep on a task. The subagents middleware allows you supply subagents through a task tool.&lt;/p&gt; 
&lt;p&gt;A subagent is defined with a name, description, system prompt, and tools. You can also provide a subagent with a custom model, or with additional middleware. This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from langchain_core.tools import tool
from langchain.agents import create_agent
from deepagents.middleware.subagents import SubAgentMiddleware


@tool
def get_weather(city: str) -&amp;gt; str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_agent(
    model="claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[
                {
                    "name": "weather",
                    "description": "This subagent can get weather in cities.",
                    "system_prompt": "Use the get_weather tool to get the weather in a city.",
                    "tools": [get_weather],
                    "model": "gpt-4.1",
                    "middleware": [],
                }
            ],
        )
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Create a custom LangGraph graph
def create_weather_graph():
    workflow = StateGraph(...)
    # Build your custom graph
    return workflow.compile()

weather_graph = create_weather_graph()

# Wrap it in a CompiledSubAgent
weather_subagent = CompiledSubAgent(
    name="weather",
    description="This subagent can get weather in cities.",
    runnable=weather_graph
)

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[weather_subagent],
        )
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Sync vs Async&lt;/h2&gt; 
&lt;p&gt;Prior versions of deepagents separated sync and async agent factories.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;async_create_deep_agent&lt;/code&gt; has been folded in to &lt;code&gt;create_deep_agent&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;You should use &lt;code&gt;create_deep_agent&lt;/code&gt; as the factory for both sync and async agents&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;MCP&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;deepagents&lt;/code&gt; library can be ran with MCP tools. This can be achieved by using the &lt;a href="https://github.com/langchain-ai/langchain-mcp-adapters"&gt;Langchain MCP Adapter library&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You will want to use &lt;code&gt;from deepagents import async_create_deep_agent&lt;/code&gt; to use the async version of &lt;code&gt;deepagents&lt;/code&gt;, since MCP tools are async&lt;/p&gt; 
&lt;p&gt;(To run the example below, will need to &lt;code&gt;pip install langchain-mcp-adapters&lt;/code&gt;)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from deepagents import create_deep_agent

async def main():
    # Collect MCP tools
    mcp_client = MultiServerMCPClient(...)
    mcp_tools = await mcp_client.get_tools()

    # Create agent
    agent = create_deep_agent(tools=mcp_tools, ....)

    # Stream the agent
    async for chunk in agent.astream(
        {"messages": [{"role": "user", "content": "what is langgraph?"}]},
        stream_mode="values"
    ):
        if "messages" in chunk:
            chunk["messages"][-1].pretty_print()

asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>volcengine/MineContext</title>
      <link>https://github.com/volcengine/MineContext</link>
      <description>&lt;p&gt;MineContext is your proactive context-aware AI partnerï¼ˆContext-Engineering+ChatGPT Pulseï¼‰&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="MineContext" src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/MineContext-Banner.svg?sanitize=true" width="100%" height="auto" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;MineContext: Create with Context, Clarity from Chaos&lt;/h3&gt; 
 &lt;p&gt;An open-source, proactive context-aware AI partner, dedicated to bringing clarity and efficiency to your work, study and creation.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/README_zh.md"&gt;ä¸­æ–‡&lt;/a&gt; / English&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://bytedance.larkoffice.com/wiki/Hn6ewRnAwiSro7kkH6Sc1DMFnng"&gt;Community Best Practice&lt;/a&gt; Â· &lt;a href="https://github.com/volcengine/MineContext/issues"&gt;Report Issues&lt;/a&gt; Â· &lt;a href="https://bytedance.larkoffice.com/share/base/form/shrcnPAjJtlufuhBZGegll41NOh"&gt;Feedback&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/volcengine/MineContext/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/volcengine/MineContext?color=369eff&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/volcengine/MineContext"&gt;&lt;img src="https://img.shields.io/github/stars/volcengine/MineContext?labelColor&amp;amp;style=flat-square&amp;amp;color=ffcb47" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/volcengine/MineContext/issues"&gt;&lt;img src="https://img.shields.io/github/issues/volcengine/MineContext?labelColor=black&amp;amp;style=flat-square&amp;amp;color=ff80eb" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/volcengine/MineContext/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/volcengine/MineContext?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/volcengine/MineContext/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/volcengine/MineContext/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/volcengine/MineContext?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://bytedance.larkoffice.com/wiki/Hg6VwrxnTiXtWUkgHexcFTqrnpg"&gt;&lt;img src="https://img.shields.io/badge/WeChat-%E5%BE%AE%E4%BF%A1-4cb55e?labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15157" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15157" alt="volcengine%2FMineContext | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;ğŸ‘‹ Join our &lt;a href="https://bytedance.larkoffice.com/wiki/Hg6VwrxnTiXtWUkgHexcFTqrnpg"&gt;WeChat / Lark / Red Note Group&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;ğŸŒ Join our &lt;a href="https://discord.gg/tGj7RQ3nUR"&gt;Discord Group&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/volcengine/MineContext/releases/download/0.1.4/MineContext-0.1.4.dmg"&gt;ğŸ–¥ï¸ Download for Mac&lt;/a&gt; Â· &lt;a href="https://github.com/volcengine/MineContext/releases/download/0.1.4/MineContext-0.1.4-setup.exe"&gt;ğŸ’» Download for Windows&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Table of Contents&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-what-is-minecontext"&gt;ğŸ‘‹ğŸ» What is MineContext&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-privacy-protection"&gt;ğŸ” Privacy Protection&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#local-first"&gt;Local-First&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#local-ai-model"&gt;Local AI model&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-quick-start"&gt;ğŸ Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#1-installation"&gt;1. Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#2-disable-the-quarantine-attribute"&gt;2. Disable the quarantine attribute&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#3-enter-your-api-key"&gt;3. Enter Your API Key&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#4-start-recording"&gt;4. Start Recording&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#5-forget-it"&gt;5. Forget it&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#6-backend-debugging"&gt;6. Backend Debugging&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-contribution-guide"&gt;ğŸƒ Contribution Guide&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-frontend-architecture"&gt;ğŸ¨ Frontend Architecture&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#core-tech-stack"&gt;Core Tech Stack&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#core-architecture"&gt;Core Architecture&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-frontend-usage"&gt;ğŸ’» Frontend Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#build-backend"&gt;Build Backend&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#development-and-debugging"&gt;Development and Debugging&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#application-packaging"&gt;Application Packaging&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#%EF%B8%8F-backend-architecture"&gt;ğŸ—ï¸ Backend Architecture&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#core-architecture-components"&gt;Core Architecture Components&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#layer-responsibilities"&gt;Layer Responsibilities&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-backend-usage"&gt;ğŸš€ Backend Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#running-the-server"&gt;Running the Server&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-the-philosophy-behind-the-name"&gt;ğŸ’ The Philosophy Behind the Name&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-target-user"&gt;ğŸ¯ Target User&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-context-source"&gt;ğŸ”Œ Context-Source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-comparison-with-familiar-application"&gt;ğŸ†š Comparison with Familiar Application&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#minecontext-vs-chatgpt-pulse"&gt;MineContext vs ChatGPT Pulse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#minecontext-vs-dayflow"&gt;MineContext vs Dayflow&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-community"&gt;ğŸ‘¥ Community&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#community-and-support"&gt;Community and Support&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/volcengine/MineContext/main/#-license"&gt;ğŸ“ƒ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h1&gt;ğŸ‘‹ğŸ» What is MineContext&lt;/h1&gt; 
&lt;p&gt;MineContext is a proactive context-aware AI partner. By utilizing screenshots and content comprehension (with future support for multi-source multimodal information including documents, images, videos, code, and external application data), it can see and understand the user's digital world context. Based on an underlying contextual engineering framework, it actively delivers high-quality information such as insights, daily/weekly summaries, to-do lists, and activity records.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/feature.gif" alt="feature.gif" /&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸš€ Key Features&lt;/h1&gt; 
&lt;p&gt;MineContext focuses on four key features: effortless collection, intelligent resurfacing, proactive delivery, and a context engineering architecture.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;ğŸ“¥ Effortless Collection Capable of gathering and processing massive amounts of context. Designed storage management enables extensive collection without adding mental burden.&lt;/li&gt; 
 &lt;li&gt;ğŸš€ Proactive Delivery Delivers key information and insights proactively in daily use. It extracts summarized content from your contextâ€”such as daily/weekly summaries, tips, and todosâ€”and pushes them directly to your homepage.&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ Intelligent Resurfacing Surfaces relevant and useful context intelligently during creation. Ensures assisted creativity without overwhelming you with information.&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ Context Engineering Architecture Supports the complete lifecycle of multimodal, multi-source dataâ€”from capture, processing, and storage to management, retrieval, and consumptionâ€”enabling the generation of six types of intelligent context.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;ğŸ” Privacy Protection&lt;/h1&gt; 
&lt;h2&gt;Local-First&lt;/h2&gt; 
&lt;p&gt;MineContext places a high priority on user privacy. By default, all data is stored locally in the following path to ensure your privacy and security.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;~/Library/Application Support/MineContext/Data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Local AI model&lt;/h2&gt; 
&lt;p&gt;In addition, we support custom model services based on the OpenAI API protocol. You can use fully local models in MineContext, ensuring that any data does not leave your local environment.&lt;/p&gt; 
&lt;h1&gt;ğŸ Quick Start&lt;/h1&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;Click &lt;a href="https://github.com/volcengine/MineContext/releases"&gt;Github Latest Release&lt;/a&gt; to Download&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/Download-App.gif" alt="Download APP" /&gt;&lt;/p&gt; 
&lt;h2&gt;2. Disable the quarantine attribute&lt;/h2&gt; 
&lt;p&gt;Enter the following command in the terminal to disable the quarantine attribute before running the application.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo xattr -d com.apple.quarantine "/Applications/MineContext.app"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/Quarantine.gif" alt="Quarantine" /&gt;&lt;/p&gt; 
&lt;h2&gt;3. Enter Your API Key&lt;/h2&gt; 
&lt;p&gt;After the application launches, please follow the prompts to enter your API key. (Note: On the first run, the application needs to install the backend environment, which may take about two minutes).&lt;/p&gt; 
&lt;p&gt;We currently support services from Doubao, OpenAI, and custom models. This includes any &lt;strong&gt;local models&lt;/strong&gt; or &lt;strong&gt;third-party model&lt;/strong&gt; services that are compatible with the OpenAI API format.&lt;/p&gt; 
&lt;p&gt;We recommend using &lt;a href="https://lmstudio.ai/"&gt;LMStudio&lt;/a&gt; to run local models. It provides a simple interface and powerful features to help you quickly deploy and manage them.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Considering both cost and performance, we recommend using the Doubao model.&lt;/strong&gt; The Doubao API Key can be generated in the &lt;a href="https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey"&gt;API Management Interface&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After obtaining the Doubao API Key, you need to activate two models in the &lt;a href="https://console.volcengine.com/ark/region:ark+cn-beijing/model"&gt;Model Activation Management Interface&lt;/a&gt;: the Visual Language Model and the Embedding Model.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Visual Language Model: Doubao-Seed-1.6-flash &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/doubao-vlm-model.png" alt="doubao-vlm-model" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Embedding Model: Doubao-embedding-large &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/doubao-emb-model.png" alt="doubao-emb-model" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following is the filling process after obtaining the API Key:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/Enter-API-Key.gif" alt="Enter API Key" /&gt;&lt;/p&gt; 
&lt;h2&gt;4. Start Recording&lt;/h2&gt; 
&lt;p&gt;Enter [Screen Monitor] to enable the system permissions for screen sharing. After completing the setup, you need to restart the application for the changes to take effect. &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/Enable-Permissions.gif" alt="Enable-Permissions" /&gt;&lt;/p&gt; 
&lt;p&gt;After restarting the application, please first set your screen sharing area in [Settings], then click [Start Recording] to begin taking screenshots. &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/Screen-Settings.gif" alt="Screen-Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;5. Forget it&lt;/h2&gt; 
&lt;p&gt;After starting the recording, your context will gradually be collected. It will take some time to generate value. So, forget about it and focus on other tasks with peace of mind. MineContext will generate to-dos, prompts, summaries, and activities for you in the background. Of course, you can also engage in proactive Q&amp;amp;A through [Chat with AI].&lt;/p&gt; 
&lt;h2&gt;6. Backend Debugging&lt;/h2&gt; 
&lt;p&gt;MineContext supports backend debugging, which can be accessed at &lt;code&gt;http://localhost:1733&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;1.View Token Consumption and Usage &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/backend-web-1.png" alt="åå°è°ƒè¯•1" /&gt;&lt;/p&gt; 
&lt;p&gt;2.Configure Interval for Automated Tasks &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/backend-web-2.png" alt="åå°è°ƒè¯•2" /&gt;&lt;/p&gt; 
&lt;p&gt;3.Adjust System Prompt for Automated Tasks &lt;img src="https://raw.githubusercontent.com/volcengine/MineContext/main/src/backend-web-3.png" alt="åå°è°ƒè¯•3" /&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸƒ Contribution Guide&lt;/h1&gt; 
&lt;h2&gt;ğŸ¨ Frontend Architecture&lt;/h2&gt; 
&lt;p&gt;The MineContext frontend is a cross-platform desktop application built with Electron, React, and TypeScript, providing a modular, maintainable, and high-performance foundation for desktop development.&lt;/p&gt; 
&lt;h3&gt;Core Tech Stack&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Technology&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Electron&lt;/td&gt; 
   &lt;td&gt;Allows for the development of cross-platform desktop applications using web technologies.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;React&lt;/td&gt; 
   &lt;td&gt;A component-based UI library for building dynamic user interfaces.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;Provides static type checking to enhance code maintainability.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vite&lt;/td&gt; 
   &lt;td&gt;A modern frontend build tool optimized for Electron.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tailwind CSS&lt;/td&gt; 
   &lt;td&gt;A utility-first CSS framework for rapid and consistent UI styling.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pnpm&lt;/td&gt; 
   &lt;td&gt;A fast and efficient package manager suitable for monorepo projects.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core Architecture&lt;/h3&gt; 
&lt;p&gt;The project follows a standard Electron architectural design, clearly separating the code for the main process, preload scripts, and renderer process to ensure security and maintainability.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;frontend/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main/     # Electron main process (window management, lifecycle, IPC)
â”‚ â”œâ”€â”€ preload/  # Preload script, securely bridging Node APIs and the renderer process
â”‚ â””â”€â”€ renderer/ # React frontend interface (renderer process)
â”‚
â”œâ”€â”€ packages/
â”‚ â””â”€â”€ shared/   # Common utilities, IPC channels, logging, and constant definitions
â”‚
â”œâ”€â”€ build/      # Build resources (icons, platform configurations)
â”œâ”€â”€ dist/       # Build artifacts generated by electron-builder
â”œâ”€â”€ externals/  # External dependencies (Python scripts, binaries, etc.)
â”œâ”€â”€ resources/  # Static assets (icons, templates, images)
â””â”€â”€ scripts/    # Development and build helper scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Process (&lt;code&gt;src/main/&lt;/code&gt;) is responsible for:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Managing application windows&lt;/li&gt; 
   &lt;li&gt;Handling lifecycle events (startup, quit, activate)&lt;/li&gt; 
   &lt;li&gt;Establishing secure IPC communication&lt;/li&gt; 
   &lt;li&gt;Integrating with backend services (Python and system APIs)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preload Script (&lt;code&gt;src/preload/&lt;/code&gt;) is responsible for:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Securely exposing Node.js APIs to the renderer process&lt;/li&gt; 
   &lt;li&gt;Handling IPC communication with the main process&lt;/li&gt; 
   &lt;li&gt;Implementing cross-process resource access&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Renderer Process (&lt;code&gt;src/renderer/&lt;/code&gt;) is responsible for:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Implementing the user interface with React&lt;/li&gt; 
   &lt;li&gt;Managing global state with Jotai and Redux&lt;/li&gt; 
   &lt;li&gt;Utilizing an efficient styling system based on Tailwind CSS&lt;/li&gt; 
   &lt;li&gt;Implementing dynamic loading and performance optimization mechanisms&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build and Packaging are responsible for:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;electron-vite.config.ts&lt;/code&gt; â€” Configures the build logic for both the main and renderer processes (aliases, plugins, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;electron-builder.yml&lt;/code&gt; â€” Defines packaging and distribution configurations for Windows, macOS, and Linux.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ’» Frontend Usage&lt;/h2&gt; 
&lt;h3&gt;Build Backend&lt;/h3&gt; 
&lt;p&gt;Before starting frontend development, you need to build the backend first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
source .venv/bin/activate
./build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install Dependencies&lt;/h3&gt; 
&lt;p&gt;Due to package version issues, using a domestic PyPI mirror is not currently supported. Please run the following command to ensure you are using the original PyPI source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip config unset global.index-url
cd frontend
pnpm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development and Debugging&lt;/h3&gt; 
&lt;p&gt;During local development, it is normal for the screen capture area selection to be slow. Please wait, as this issue does not exist in the packaged application.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Application Packaging&lt;/h3&gt; 
&lt;p&gt;To build APP for macOS:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm build:mac
# Data Path
# ï½/Library/Application\ Support/MineContext
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The executable files generated by the packaging process will be stored in the &lt;code&gt;MineContext/frontend/dist&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;ğŸ—ï¸ Backend Architecture&lt;/h2&gt; 
&lt;p&gt;MineContext adopts a modular, layered architecture design with clear separation of concerns and well-defined responsibilities for each component.&lt;/p&gt; 
&lt;h3&gt;Core Architecture Components&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;opencontext/
â”œâ”€â”€ server/             # Web server and API layer
â”œâ”€â”€ managers/           # Business logic managers
â”œâ”€â”€ context_capture/    # Context acquisition modules
â”œâ”€â”€ context_processing/ # Context processing pipeline
â”œâ”€â”€ context_consumption/# Context consumption and generation
â”œâ”€â”€ storage/            # Multi-backend storage layer
â”œâ”€â”€ llm/               # LLM integration layer
â”œâ”€â”€ tools/             # Tool system
â””â”€â”€ monitoring/        # System monitoring
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Layer Responsibilities&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Server Layer&lt;/strong&gt; (&lt;code&gt;server/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;FastAPI-based RESTful API&lt;/li&gt; 
   &lt;li&gt;WebSocket support for real-time communication&lt;/li&gt; 
   &lt;li&gt;Static file serving and template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Manager Layer&lt;/strong&gt; (&lt;code&gt;managers/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CaptureManager&lt;/code&gt;: Manages all context capture sources&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ProcessorManager&lt;/code&gt;: Coordinates context processing pipeline&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ConsumptionManager&lt;/code&gt;: Handles context consumption and generation&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;EventManager&lt;/code&gt;: Event-driven system coordination&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Context Capture Layer&lt;/strong&gt; (&lt;code&gt;context_capture/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Screenshot monitoring&lt;/li&gt; 
   &lt;li&gt;Document monitoring&lt;/li&gt; 
   &lt;li&gt;Extensible capture interface for future sources&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Processing Layer&lt;/strong&gt; (&lt;code&gt;context_processing/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Document chunking strategies&lt;/li&gt; 
   &lt;li&gt;Entity extraction and normalization&lt;/li&gt; 
   &lt;li&gt;Context merging and deduplication&lt;/li&gt; 
   &lt;li&gt;Multi-modal content processing (text, images)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Storage Layer&lt;/strong&gt; (&lt;code&gt;storage/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multi-backend support (SQLite, ChromaDB)&lt;/li&gt; 
   &lt;li&gt;Vector storage for similarity search&lt;/li&gt; 
   &lt;li&gt;Unified storage interface&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Integration&lt;/strong&gt; (&lt;code&gt;llm/&lt;/code&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Support for multiple LLM providers (OpenAI, Doubao)&lt;/li&gt; 
   &lt;li&gt;VLM (Vision-Language Model) integration&lt;/li&gt; 
   &lt;li&gt;Embedding generation services&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸš€ Backend Usage&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;We recommend using &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; for fast and reliable package management:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone https://github.com/volcengine/MineContext.git
cd MineContext

# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Sync dependencies (automatically creates virtual environment)
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Configuration&lt;/strong&gt; (&lt;code&gt;config/config.yaml&lt;/code&gt;):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;server:
  host: 127.0.0.1
  port: 8765
  debug: false

embedding_model:
  provider: doubao # options: openai, doubao
  api_key: your-api-key
  model: doubao-embedding-large-text-240915

vlm_model:
  provider: doubao # options: openai, doubao
  api_key: your-api-key
  model: doubao-seed-1-6-flash-250828

capture:
  enabled: true
  screenshot:
    enabled: true # enable screenshot capture
    capture_interval: 5 # capture interval in seconds
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt Templates&lt;/strong&gt; (&lt;code&gt;config/prompts_*.yaml&lt;/code&gt;): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;prompts_en.yaml&lt;/code&gt;: English prompt templates&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;prompts_zh.yaml&lt;/code&gt;: Chinese prompt templates&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Running the Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with default configuration
uv run opencontext start

# Start with custom config
uv run opencontext start --config /path/to/config.yaml

# Start with custom port (useful for avoiding conflicts)
uv run opencontext start --port 1733
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--config&lt;/code&gt;: Path to configuration file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--host&lt;/code&gt;: Host address (default: from config or &lt;code&gt;localhost&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--port&lt;/code&gt;: Port number (default: from config or &lt;code&gt;1733&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Priority&lt;/strong&gt;: Command-line arguments &amp;gt; Config file &amp;gt; Default values&lt;/p&gt; 
&lt;p&gt;Alternatively, you can activate the virtual environment manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -e .
opencontext start --port 1733
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;ğŸ’ The Philosophy Behind the Name&lt;/h1&gt; 
&lt;p&gt;The naming of MineContext also reflects the team's ingenuity. It signifies both "my context" and "mining context." It draws inspiration from the core philosophy of Minecraftâ€”openness, creativity, and exploration.&lt;/p&gt; 
&lt;p&gt;If vast amounts of context are like scattered "blocks," then MineContext provides a "world" where you can freely build, combine, and create. Users can reimagine and create new content based on the collected massive context and generate high-quality information.&lt;/p&gt; 
&lt;h1&gt;ğŸ¯ Target User&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Target User Category&lt;/th&gt; 
   &lt;th&gt;Specific Roles/Identities&lt;/th&gt; 
   &lt;th&gt;Core Needs/Pain Points&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Workers&lt;/td&gt; 
   &lt;td&gt;Researchers, Analysts&lt;/td&gt; 
   &lt;td&gt;Navigating vast amounts of information, improving information processing and analysis efficiency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Content Creators&lt;/td&gt; 
   &lt;td&gt;Writers, Bloggers&lt;/td&gt; 
   &lt;td&gt;Craving endless inspiration, optimizing content creation workflows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Lifelong Learners&lt;/td&gt; 
   &lt;td&gt;Students, Researchers&lt;/td&gt; 
   &lt;td&gt;Building systematic knowledge systems, efficiently managing and connecting learning materials&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Project Managers&lt;/td&gt; 
   &lt;td&gt;Product Managers, Project Managers&lt;/td&gt; 
   &lt;td&gt;Integrating multi-source information and data, ensuring project alignment and decision-making efficiency&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;ğŸ”Œ Context-Source&lt;/h1&gt; 
&lt;p&gt;We will prioritize the expansion of Context Sources according to the following plan, and we warmly welcome everyone to actively contribute code to our efforts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;P0: Digital life and public information loop (PC screen capture and link upload)&lt;/li&gt; 
 &lt;li&gt;P1: Personal text context loop (file upload, file tracking)&lt;/li&gt; 
 &lt;li&gt;P2: AI and common office context loop (MCP, meeting notes)&lt;/li&gt; 
 &lt;li&gt;P3: High-quality information acquisition loop (DeepResearch and RSS)&lt;/li&gt; 
 &lt;li&gt;P4: Personal deep context loop (WeChat, QQ chat data acquisition, mobile screenshots)&lt;/li&gt; 
 &lt;li&gt;P5: Physical world context loop (smart wearable synchronization, smart glasses synchronization)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Context Capture Capability&lt;/th&gt; 
   &lt;th align="left"&gt;Context Source&lt;/th&gt; 
   &lt;th align="left"&gt;Priority&lt;/th&gt; 
   &lt;th align="left"&gt;Completion Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Screen Screenshot&lt;/td&gt; 
   &lt;td align="left"&gt;User PC Information&lt;/td&gt; 
   &lt;td align="left"&gt;P0&lt;/td&gt; 
   &lt;td align="left"&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Note Editing&lt;/td&gt; 
   &lt;td align="left"&gt;Application Internal Creation Information&lt;/td&gt; 
   &lt;td align="left"&gt;P0&lt;/td&gt; 
   &lt;td align="left"&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Link Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Internet Information&lt;/td&gt; 
   &lt;td align="left"&gt;P0&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Structured Documents&lt;/td&gt; 
   &lt;td align="left"&gt;P1&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Unstructured Documents&lt;/td&gt; 
   &lt;td align="left"&gt;P1&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Images&lt;/td&gt; 
   &lt;td align="left"&gt;P1&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Audio&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Video&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;File Upload&lt;/td&gt; 
   &lt;td align="left"&gt;Code&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Browser Extension&lt;/td&gt; 
   &lt;td align="left"&gt;AI Conversation Records&lt;/td&gt; 
   &lt;td align="left"&gt;P2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Browser Extension&lt;/td&gt; 
   &lt;td align="left"&gt;Refined Internet Information&lt;/td&gt; 
   &lt;td align="left"&gt;P5&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Meeting Records&lt;/td&gt; 
   &lt;td align="left"&gt;Meeting Information&lt;/td&gt; 
   &lt;td align="left"&gt;P2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RSS&lt;/td&gt; 
   &lt;td align="left"&gt;Consultation Information&lt;/td&gt; 
   &lt;td align="left"&gt;P3&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Deep Research&lt;/td&gt; 
   &lt;td align="left"&gt;High-Quality Research Analysis&lt;/td&gt; 
   &lt;td align="left"&gt;P3&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Payment Records&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Research Papers&lt;/td&gt; 
   &lt;td align="left"&gt;P3&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;News&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Emails&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Notion&lt;/td&gt; 
   &lt;td align="left"&gt;P2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Obsidian&lt;/td&gt; 
   &lt;td align="left"&gt;P2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Slack&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Jira&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Figma&lt;/td&gt; 
   &lt;td align="left"&gt;P2&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Linear&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Application MCP/API&lt;/td&gt; 
   &lt;td align="left"&gt;Todoist&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Memory Bank Migration Import&lt;/td&gt; 
   &lt;td align="left"&gt;User Memory&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;WeChat Data Capture&lt;/td&gt; 
   &lt;td align="left"&gt;WeChat Chat History&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;QQ Data Capture&lt;/td&gt; 
   &lt;td align="left"&gt;QQ Chat History&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Mobile Screenshot Monitor&lt;/td&gt; 
   &lt;td align="left"&gt;User Mobile End Information&lt;/td&gt; 
   &lt;td align="left"&gt;P4&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Smart Glasses Data Sync&lt;/td&gt; 
   &lt;td align="left"&gt;Physical World Interaction Records&lt;/td&gt; 
   &lt;td align="left"&gt;P5&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Smart Bracelet Data Sync&lt;/td&gt; 
   &lt;td align="left"&gt;Physiological Data&lt;/td&gt; 
   &lt;td align="left"&gt;P5&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;ğŸ†š Comparison with Familiar Application&lt;/h1&gt; 
&lt;h2&gt;MineContext vs ChatGPT Pulse&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ–¥ï¸ Comprehensive Digital Context: MineContext captures your entire digital workflow by reading from screen screenshots, providing a rich, visual context of your daily activities and applications. ChatGPT Pulse, in contrast, is limited to the context of a single text-based conversation.&lt;/li&gt; 
 &lt;li&gt;ğŸ”’ Local-First Data &amp;amp; Privacy: Your data is processed and stored entirely on your local device, ensuring complete privacy and security without relying on cloud servers. ChatGPT Pulse requires data to be sent to and stored on OpenAI's servers.&lt;/li&gt; 
 &lt;li&gt;ğŸš€ Proactive &amp;amp; Diverse Insights: MineContext delivers a wider variety of intelligent, auto-generated contentâ€”including daily summaries, actionable todos, and activity reportsâ€”not just simple tips. ChatGPT Pulse primarily offers reactive assistance within the chat interface.&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ Open Source &amp;amp; Customizable: As an open-source project, MineContext allows developers to freely inspect, modify, and build upon the codebase for complete customization. ChatGPT Pulse is a closed, proprietary product with no option for modification.&lt;/li&gt; 
 &lt;li&gt;ğŸ’° Cost-Effective API Usage: MineContext avoids the need for a costly $200/month Pro subscription by allowing you to use your own API key, giving you full control over your spending. ChatGPT Pulse's advanced features are locked behind its expensive premium tier.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MineContext vs Dayflow&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¡ Richer, Proactive Insights: MineContext delivers a more diverse range of automated, intelligent contentâ€”including concise summaries, actionable todos, and contextual tipsâ€”going beyond basic activity tracking. DayFlow primarily focuses on logging user activity.&lt;/li&gt; 
 &lt;li&gt;ğŸ§  Context-Aware Q&amp;amp;A &amp;amp; Creation: MineContext enables you to ask questions and generate new content based on your captured context, unlocking wider application scenarios like content drafting and project planning. DayFlow is limited to passive activity recording and review.&lt;/li&gt; 
 &lt;li&gt;âœ¨ Superior Activity Generation &amp;amp; Experience: MineContext produces activity records with greater clarity and detail, featuring a more intuitive and interactive dashboard for a seamless user experience. DayFlow's activity logs are more basic with limited interactivity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h1&gt;ğŸ‘¥ Community&lt;/h1&gt; 
&lt;h2&gt;Community and Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/volcengine/MineContext/issues"&gt;GitHub Issues&lt;/a&gt;: Errors and issues encountered while using MineContext.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="mailto:minecontext@bytedance.com"&gt;Email Support&lt;/a&gt;: Feedback and questions about using MineContext.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bytedance.larkoffice.com/wiki/Hg6VwrxnTiXtWUkgHexcFTqrnpg"&gt;WeChat Group&lt;/a&gt;: Discuss SwanLab usage and share the latest AI technologies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#volcengine/MineContext&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=volcengine/MineContext&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸ“ƒ License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the Apache 2.0 License.&lt;/p&gt; 
&lt;!-- link --&gt;</description>
    </item>
    
    <item>
      <title>lzhoang2801/OpCore-Simplify</title>
      <link>https://github.com/lzhoang2801/OpCore-Simplify</link>
      <description>&lt;p&gt;A tool designed to simplify the creation of OpenCore EFI&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;OpCore Simplify&lt;/h3&gt; 
 &lt;p align="center"&gt; A specialized tool that streamlines &lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCore&lt;/a&gt; EFI creation by automating the essential setup process and providing standardized configurations. Designed to reduce manual effort while ensuring accuracy in your Hackintosh journey. &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-features"&gt;Features&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-how-to-use"&gt;How To Use&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contributing"&gt;Contributing&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-license"&gt;License&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-credits"&gt;Credits&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/lzhoang2801/OpCore-Simplify/main/#-contact"&gt;Contact&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15410" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15410" alt="lzhoang2801%2FOpCore-Simplify | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] &lt;strong&gt;DO NOT TRUST ANY HACKINTOSH INFORMATION FROM AI/LLM SOURCES&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;They often provide incorrect information about Hackintosh. Always rely on official sources like the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt; and the Hackintosh community for accurate information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;OUTDATED SECTIONS IN DORTANIA GUIDE&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;While the Dortania Guide is a valuable resource, some sections may be outdated. Always:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Verify information with the Hackintosh community&lt;/li&gt; 
  &lt;li&gt;Test configurations yourself&lt;/li&gt; 
  &lt;li&gt;Prefer reading documentation directly from the GitHub repositories of bootloaders and kexts you plan to use&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If the installation process is successful using OpCore Simplify, please confirm it at &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/discussions/23"&gt;Successful Hackintosh Setup with OpCore Simplify&lt;/a&gt;. This will greatly assist others in the community.&lt;/p&gt; 
 &lt;p&gt;OpCore Simplify is the ONLY tool that builds OpenCore EFI based on your complete hardware configuration, not just predefined options. This fundamental difference sets us apart from other tools in the Hackintosh community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] While OpCore Simplify significantly reduces setup time, the Hackintosh journey still requires:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Understanding basic concepts from the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/"&gt;Dortania Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Testing and troubleshooting during the installation process&lt;/li&gt; 
  &lt;li&gt;Patience and persistence in resolving any issues that arise&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Our tool doesn't eliminate these steps, but it ensures you start with a solid foundation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;âœ¨ &lt;strong&gt;Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Comprehensive Hardware and macOS Support&lt;/strong&gt;&lt;br /&gt; Fully supports modern hardware. Use &lt;code&gt;Compatibility Checker&lt;/code&gt; to check supported/unsupported devices and macOS version supported.&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Supported&lt;/strong&gt;&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel: Nehalem and Westmere (1st Gen) â†’ Arrow Lake (15th Gen/Core Ultra Series 2) &lt;br /&gt; AMD: Ryzen and Threadripper with &lt;a href="https://github.com/AMD-OSX/AMD_Vanilla"&gt;AMD Vanilla&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Intel iGPU: Iron Lake (1st Gen) â†’ Ice Lake (10th Gen) &lt;br /&gt; AMD APU: The entire Vega Raven ASIC family (Ryzen 1xxx â†’ 5xxx, 7x30 series) &lt;br /&gt; AMD dGPU: Navi 23, Navi 22, Navi 21 generations, and older series &lt;br /&gt; NVIDIA: Kepler, Pascal, Maxwell, Fermi, Tesla generations&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;macOS&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;macOS High Sierra â†’ macOS Tahoe&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ACPI Patches and Kexts&lt;/strong&gt;&lt;br /&gt; Automatically detects and adds ACPI patches and kexts based on hardware configuration.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrated with &lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; for common patches (e.g., FakeEC, FixHPET, PLUG, RTCAWAC).&lt;/li&gt; 
   &lt;li&gt;Includes custom patches: 
    &lt;ul&gt; 
     &lt;li&gt;Prevent kernel panics by directing the first CPU entry to an active CPU, disabling the UNC0 device, and creating a new RTC device for HEDT systems.&lt;/li&gt; 
     &lt;li&gt;Disable unsupported or unused PCI devices, such as the GPU (using Optimus and Bumblebee methods or adding the disable-gpu property), Wi-Fi card, and NVMe storage controller.&lt;/li&gt; 
     &lt;li&gt;Fix sleep state values in _PRW methods (GPRW, UPRW, HP special) to prevent immediate wake.&lt;/li&gt; 
     &lt;li&gt;Add devices including ALS0, BUS0, MCHC, PMCR, PNLF, RMNE, IMEI, USBX, XOSI, along with a Surface Patch.&lt;/li&gt; 
     &lt;li&gt;Enable ALSD and GPI0 devices.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Updates&lt;/strong&gt;&lt;br /&gt; Automatically checks for and updates OpenCorePkg and kexts from &lt;a href="https://dortania.github.io/builds/"&gt;Dortania Builds&lt;/a&gt; and GitHub releases before each EFI build.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;EFI Configuration&lt;/strong&gt;&lt;br /&gt; Apply additional customization based on both widely used sources and personal experience.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Spoof GPU IDs for certain AMD GPUs not recognized in macOS.&lt;/li&gt; 
   &lt;li&gt;Use CpuTopologyRebuild kext for Intel CPUs with P-cores and E-cores to enhance performance.&lt;/li&gt; 
   &lt;li&gt;Disable System Integrity Protection (SIP).&lt;/li&gt; 
   &lt;li&gt;Spoof CPU IDs for Intel Pentium, Celeron, Core, and Xeon processors.&lt;/li&gt; 
   &lt;li&gt;Add custom CPU names for AMD CPUs, as well as Intel Pentium, Celeron, Xeon, and Core lines from the Rocket Lake (11th) generation and newer.&lt;/li&gt; 
   &lt;li&gt;Add a patch to allow booting macOS with unsupported SMBIOS.&lt;/li&gt; 
   &lt;li&gt;Add NVRAM entries to bypass checking the internal Bluetooth controller.&lt;/li&gt; 
   &lt;li&gt;Properly configure ResizeAppleGpuBars based on specific Resizable BAR information.&lt;/li&gt; 
   &lt;li&gt;Allow flexible iGPU configuration between headless and driving a display when a supported discrete GPU is present.&lt;/li&gt; 
   &lt;li&gt;Force Intel GPUs into VESA mode with HDMI and DVI connectors to simplify installation process.&lt;/li&gt; 
   &lt;li&gt;Provide configuration required for using OpenCore Legacy Patcher.&lt;/li&gt; 
   &lt;li&gt;Add built-in device property for network devices (fix 'Could not communicate with the server' when using iServices) and storage controllers (fix internal drives shown as external).&lt;/li&gt; 
   &lt;li&gt;Prioritize SMBIOS optimized for both power management and performance.&lt;/li&gt; 
   &lt;li&gt;Re-enable CPU power management on legacy Intel CPUs in macOS Ventura 13 and newer.&lt;/li&gt; 
   &lt;li&gt;Apply WiFi profiles for itlwm kext to enable auto WiFi connections at boot time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;and more...&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy Customization&lt;/strong&gt;&lt;br /&gt; In addition to the default settings applied, users can easily make further customizations if desired.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Custom ACPI patches, kexts, and SMBIOS adjustments (&lt;strong&gt;not recommended&lt;/strong&gt;).&lt;/li&gt; 
   &lt;li&gt;Force load kexts on unsupported macOS versions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸš€ &lt;strong&gt;How To Use&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click &lt;strong&gt;Code&lt;/strong&gt; â†’ &lt;strong&gt;Download ZIP&lt;/strong&gt;, or download directly via this &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/archive/refs/heads/main.zip"&gt;link&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Extract the downloaded ZIP file to your desired location.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/mcE7OSX.png" alt="Download OpCore Simplify" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Running OpCore Simplify&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On &lt;strong&gt;Windows&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.bat&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;On &lt;strong&gt;macOS&lt;/strong&gt;, run &lt;code&gt;OpCore-Simplify.command&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/vTr1V9D.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting hardware report&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On Windows, there will be an option for &lt;code&gt;E. Export hardware report&lt;/code&gt;. It's recommended to use this for the best results with your hardware configuration and BIOS at the time of building.&lt;/li&gt; 
   &lt;li&gt;Alternatively, use &lt;a href="https://github.com/lzhoang2801/Hardware-Sniffer"&gt;&lt;strong&gt;Hardware Sniffer&lt;/strong&gt;&lt;/a&gt; to create a &lt;code&gt;Report.json&lt;/code&gt; and ACPI dump for configuration manully.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MbRmIGJ.png" alt="Selecting hardware report" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/SbL6N6v.png" alt="Loading ACPI Tables" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/kuDGMmp.png" alt="Compatibility Checker" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Selecting macOS Version and Customizing OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;By default, the latest compatible macOS version will be selected for your hardware.&lt;/li&gt; 
   &lt;li&gt;OpCore Simplify will automatically apply essential ACPI patches and kexts.&lt;/li&gt; 
   &lt;li&gt;You can manually review and customize these settings as needed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/TSk9ejy.png" alt="OpCore Simplify Menu" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Building OpenCore EFI&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Once you've customized all options, select &lt;strong&gt;Build OpenCore EFI&lt;/strong&gt; to generate your EFI.&lt;/li&gt; 
   &lt;li&gt;The tool will automatically download the necessary bootloader and kexts, which may take a few minutes.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/71TkJkD.png" alt="WiFi Profile Extractor" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/Mcm20EQ.png" alt="Choosing Codec Layout ID" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/deyj5de.png" alt="Building OpenCore EFI" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;USB Mapping&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;After building your EFI, follow the steps for mapping USB ports.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://i.imgur.com/MIPigPF.png" alt="Results" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create USB and Install macOS&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use &lt;a href="https://github.com/corpnewt/UnPlugged"&gt;&lt;strong&gt;UnPlugged&lt;/strong&gt;&lt;/a&gt; on Windows to create a USB macOS installer, or follow &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/installer-guide/mac-install.html"&gt;this guide&lt;/a&gt; for macOS.&lt;/li&gt; 
   &lt;li&gt;For troubleshooting, refer to the &lt;a href="https://dortania.github.io/OpenCore-Install-Guide/troubleshooting/troubleshooting.html"&gt;OpenCore Troubleshooting Guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;After a successful installation, if OpenCore Legacy Patcher is required, simply apply root patches to activate the missing features (such as modern Broadcom Wi-Fi card and graphics acceleration).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For AMD GPUs, after applying root patches from OpenCore Legacy Patcher, you need to remove the boot argument &lt;code&gt;-radvesa&lt;/code&gt;/&lt;code&gt;-amd_no_dgpu_accel&lt;/code&gt; for graphics acceleration to work.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ¤ &lt;strong&gt;Contributing&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Contributions are &lt;strong&gt;highly appreciated&lt;/strong&gt;! If you have ideas to improve this project, feel free to fork the repo and create a pull request, or open an issue with the "enhancement" tag.&lt;/p&gt; 
&lt;p&gt;Don't forget to â­ star the project! Thank you for your support! ğŸŒŸ&lt;/p&gt; 
&lt;h2&gt;ğŸ“œ &lt;strong&gt;License&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Distributed under the BSD 3-Clause License. See &lt;code&gt;LICENSE&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;ğŸ™Œ &lt;strong&gt;Credits&lt;/strong&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acidanthera/OpenCorePkg"&gt;OpenCorePkg&lt;/a&gt; and &lt;a href="https://github.com/lzhoang2801/OpCore-Simplify/raw/main/Scripts/datasets/kext_data.py"&gt;kexts&lt;/a&gt; â€“ The backbone of this project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/corpnewt/SSDTTime"&gt;SSDTTime&lt;/a&gt; â€“ SSDT patching utilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“ &lt;strong&gt;Contact&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Hoang Hong Quan&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Facebook &lt;a href="https://facebook.com/macforce2601"&gt;@macforce2601&lt;/a&gt; &amp;nbsp;Â·&amp;nbsp; Telegram &lt;a href="https://t.me/lzhoang2601"&gt;@lzhoang2601&lt;/a&gt; &amp;nbsp;Â·&amp;nbsp; Email: &lt;a href="mailto:lzhoang2601@gmail.com"&gt;lzhoang2601@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸŒŸ &lt;strong&gt;Star History&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#lzhoang2801/OpCore-Simplify&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=lzhoang2801/OpCore-Simplify&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tinygrad/tinygrad</title>
      <link>https://github.com/tinygrad/tinygrad</link>
      <description>&lt;p&gt;You like pytorch? You like micrograd? You love tinygrad! â¤ï¸&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/logo_tiny_light.svg" /&gt; 
  &lt;img alt="tiny corp logo" src="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs/logo_tiny_dark.svg?sanitize=true" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;tinygrad: For something between &lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt; and &lt;a href="https://github.com/karpathy/micrograd"&gt;karpathy/micrograd&lt;/a&gt;. Maintained by &lt;a href="https://tinygrad.org"&gt;tiny corp&lt;/a&gt;.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad"&gt;Homepage&lt;/a&gt; | &lt;a href="https://docs.tinygrad.org/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://discord.gg/ZjZadyC7PK"&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/tinygrad/tinygrad" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tinygrad/tinygrad/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tinygrad/tinygrad/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZjZadyC7PK"&gt;&lt;img src="https://img.shields.io/discord/1068976834382925865" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;tinygrad is an end-to-end deep learning stack:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor library&lt;/strong&gt; with autograd&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;IR and compiler&lt;/strong&gt; that fuse and lower kernels&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JIT + graph execution&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;nn / optim / datasets&lt;/strong&gt; for real training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Itâ€™s inspired by PyTorch (ergonomics), JAX (functional transforms and IR-based AD), and TVM (scheduling and codegen), but stays intentionally tiny and hackable.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How tinygrad compares&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… Similar: eager &lt;code&gt;Tensor&lt;/code&gt; API, autograd, &lt;code&gt;optim&lt;/code&gt;, basic datasets and layers.&lt;/li&gt; 
 &lt;li&gt;âœ… You can write familiar training loops.&lt;/li&gt; 
 &lt;li&gt;ğŸ” Unlike PyTorch, the entire compiler and IR are visible and hackable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;JAX&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… IR-based autodiff over primitives (like JAXPR + XLA).&lt;/li&gt; 
 &lt;li&gt;âœ… Function-level JIT (&lt;code&gt;TinyJit&lt;/code&gt;) that captures and replays kernels.&lt;/li&gt; 
 &lt;li&gt;ğŸ” Fewer functional transforms (no full &lt;code&gt;vmap&lt;/code&gt;/&lt;code&gt;pmap&lt;/code&gt; yet), but far easier to read.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;TVM&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… Multiple lowering passes, scheduling, and BEAM search over kernels.&lt;/li&gt; 
 &lt;li&gt;âœ… Device â€œgraphsâ€ for batched execution.&lt;/li&gt; 
 &lt;li&gt;ğŸ” tinygrad also ships the &lt;strong&gt;front-end framework&lt;/strong&gt; (tensors, nn, optim), not just the compiler.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Laziness&lt;/h3&gt; 
&lt;p&gt;Try a matmul. See how, despite the style, it is fused into one kernel with the power of laziness.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;DEBUG=3 python3 -c "from tinygrad import Tensor;
N = 1024; a, b = Tensor.empty(N, N), Tensor.empty(N, N);
(a.reshape(N, 1, N) * b.T.reshape(1, N, N)).sum(axis=2).realize()"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And we can change &lt;code&gt;DEBUG&lt;/code&gt; to &lt;code&gt;4&lt;/code&gt; to see the generated code.&lt;/p&gt; 
&lt;h3&gt;Neural networks&lt;/h3&gt; 
&lt;p&gt;As it turns out, 90% of what you need for neural networks are a decent autograd/tensor library. Throw in an optimizer, a data loader, and some compute, and you have all you need.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tinygrad import Tensor, nn

class LinearNet:
  def __init__(self):
    self.l1 = Tensor.kaiming_uniform(784, 128)
    self.l2 = Tensor.kaiming_uniform(128, 10)
  def __call__(self, x:Tensor) -&amp;gt; Tensor:
    return x.flatten(1).dot(self.l1).relu().dot(self.l2)

model = LinearNet()
optim = nn.optim.Adam([model.l1, model.l2], lr=0.001)

x, y = Tensor.rand(4, 1, 28, 28), Tensor([2,4,3,7])  # replace with real mnist dataloader

with Tensor.train():
  for i in range(10):
    optim.zero_grad()
    loss = model(x).sparse_categorical_crossentropy(y).backward()
    optim.step()
    print(i, loss.item())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/examples/beautiful_mnist.py"&gt;examples/beautiful_mnist.py&lt;/a&gt; for the full version that gets 98% in ~5 seconds&lt;/p&gt; 
&lt;h2&gt;Accelerators&lt;/h2&gt; 
&lt;p&gt;tinygrad already supports numerous accelerators, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cl.py"&gt;OpenCL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cpu.py"&gt;CPU&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_metal.py"&gt;METAL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_cuda.py"&gt;CUDA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_amd.py"&gt;AMD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_nv.py"&gt;NV&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_qcom.py"&gt;QCOM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/runtime/ops_webgpu.py"&gt;WEBGPU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it is easy to add more! Your accelerator of choice only needs to support a total of ~25 low level ops.&lt;/p&gt; 
&lt;p&gt;To check default accelerator run: &lt;code&gt;python3 -c "from tinygrad import Device; print(Device.DEFAULT)"&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The current recommended way to install tinygrad is from source.&lt;/p&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/tinygrad/tinygrad.git
cd tinygrad
python3 -m pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Direct (master)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 -m pip install git+https://github.com/tinygrad/tinygrad.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation along with a quick start guide can be found on the &lt;a href="https://docs.tinygrad.org/"&gt;docs website&lt;/a&gt; built from the &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/docs"&gt;docs/&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Quick example comparing to PyTorch&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tinygrad import Tensor

x = Tensor.eye(3, requires_grad=True)
y = Tensor([[2.0,0,-2.0]], requires_grad=True)
z = y.matmul(x).sum()
z.backward()

print(x.grad.tolist())  # dz/dx
print(y.grad.tolist())  # dz/dy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The same thing but in PyTorch:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torch

x = torch.eye(3, requires_grad=True)
y = torch.tensor([[2.0,0,-2.0]], requires_grad=True)
z = y.matmul(x).sum()
z.backward()

print(x.grad.tolist())  # dz/dx
print(y.grad.tolist())  # dz/dy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;There has been a lot of interest in tinygrad lately. Following these guidelines will help your PR get accepted.&lt;/p&gt; 
&lt;p&gt;We'll start with what will get your PR closed with a pointer to this section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No code golf! While low line count is a guiding light of this project, anything that remotely looks like code golf will be closed. The true goal is reducing complexity and increasing readability, and deleting &lt;code&gt;\n&lt;/code&gt;s does nothing to help with that.&lt;/li&gt; 
 &lt;li&gt;All docs and whitespace changes will be closed unless you are a well-known contributor. The people writing the docs should be those who know the codebase the absolute best. People who have not demonstrated that shouldn't be messing with docs. Whitespace changes are both useless &lt;em&gt;and&lt;/em&gt; carry a risk of introducing bugs.&lt;/li&gt; 
 &lt;li&gt;Anything you claim is a "speedup" must be benchmarked. In general, the goal is simplicity, so even if your PR makes things marginally faster, you have to consider the tradeoff with maintainability and readability.&lt;/li&gt; 
 &lt;li&gt;In general, the code outside the core &lt;code&gt;tinygrad/&lt;/code&gt; folder is not well tested, so unless the current code there is broken, you shouldn't be changing it.&lt;/li&gt; 
 &lt;li&gt;If your PR looks "complex", is a big diff, or adds lots of lines, it won't be reviewed or merged. Consider breaking it up into smaller PRs that are individually clear wins. A common pattern I see is prerequisite refactors before adding new functionality. If you can (cleanly) refactor to the point that the feature is a 3 line change, this is great, and something easy for us to review.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now, what we want:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug fixes (with a regression test) are great! This library isn't 1.0 yet, so if you stumble upon a bug, fix it, write a test, and submit a PR, this is valuable work.&lt;/li&gt; 
 &lt;li&gt;Solving bounties! tinygrad &lt;a href="https://docs.google.com/spreadsheets/d/1WKHbT-7KOgjEawq5h5Ic1qUWzpfAzuD_J06N1JwOCGs/edit?usp=sharing"&gt;offers cash bounties&lt;/a&gt; for certain improvements to the library. All new code should be high quality and well tested.&lt;/li&gt; 
 &lt;li&gt;Features. However, if you are adding a feature, consider the line tradeoff. If it's 3 lines, there's less of a bar of usefulness it has to meet over something that's 30 or 300 lines. All features must have regression tests. In general with no other constraints, your feature's API should match torch or numpy.&lt;/li&gt; 
 &lt;li&gt;Refactors that are clear wins. In general, if your refactor isn't a clear win it will be closed. But some refactors are amazing! Think about readability in a deep core sense. A whitespace change or moving a few functions around is useless, but if you realize that two 100 line functions can actually use the same 110 line function with arguments while also improving readability, this is a big win. Refactors should pass &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/#process-replay-tests"&gt;process replay&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Tests/fuzzers. If you can add tests that are non brittle, they are welcome. We have some fuzzers in here too, and there's a plethora of bugs that can be found with them and by improving them. Finding bugs, even writing broken tests (that should pass) with &lt;code&gt;@unittest.expectedFailure&lt;/code&gt; is great. This is how we make progress.&lt;/li&gt; 
 &lt;li&gt;Dead code removal from core &lt;code&gt;tinygrad/&lt;/code&gt; folder. We don't care about the code in extra, but removing dead code from the core library is great. Less for new people to read and be confused by.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Running tests&lt;/h3&gt; 
&lt;p&gt;You should install the pre-commit hooks with &lt;code&gt;pre-commit install&lt;/code&gt;. This will run the linter, mypy, and a subset of the tests on every commit.&lt;/p&gt; 
&lt;p&gt;For more examples on how to run the full test suite please refer to the &lt;a href="https://raw.githubusercontent.com/tinygrad/tinygrad/master/.github/workflows/test.yml"&gt;CI workflow&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some examples of running tests locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 -m pip install -e '.[testing]'  # install extra deps for testing
python3 test/test_ops.py                # just the ops tests
python3 -m pytest test/                 # whole test suite
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Process replay tests&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/tinygrad/tinygrad/raw/master/test/external/process_replay/README.md"&gt;Process replay&lt;/a&gt; compares your PR's generated kernels against master. If your PR is a refactor or speedup without any expected behavior change, It should include [pr] in the pull request title.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Blaizzy/mlx-vlm</title>
      <link>https://github.com/Blaizzy/mlx-vlm</link>
      <description>&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/Blaizzy/mlx-vlm/actions/workflows/python-publish.yml"&gt;&lt;img src="https://github.com/Blaizzy/mlx-vlm/actions/workflows/python-publish.yml/badge.svg?sanitize=true" alt="Upload Python Package" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;MLX-VLM&lt;/h1&gt; 
&lt;p&gt;MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) and Omni Models (VLMs with audio and video support) on your Mac using MLX.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage"&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#command-line-interface-cli"&gt;Command Line Interface (CLI)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#chat-ui-with-gradio"&gt;Chat UI with Gradio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#python-script"&gt;Python Script&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#multi-image-chat-support"&gt;Multi-Image Chat Support&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#usage-examples"&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/#fine-tuning"&gt;Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The easiest way to get started is to install the &lt;code&gt;mlx-vlm&lt;/code&gt; package using pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install -U mlx-vlm
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command Line Interface (CLI)&lt;/h3&gt; 
&lt;p&gt;Generate output from a model using the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Text generation
mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt "Hello, how are you?"

# Image generation
mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --temperature 0.0 --image http://images.cocodataset.org/val2017/000000039769.jpg

# Audio generation (New)
mlx_vlm.generate --model mlx-community/gemma-3n-E2B-it-4bit --max-tokens 100 --prompt "Describe what you hear" --audio /path/to/audio.wav

# Multi-modal generation (Image + Audio)
mlx_vlm.generate --model mlx-community/gemma-3n-E2B-it-4bit --max-tokens 100 --prompt "Describe what you see and hear" --image /path/to/image.jpg --audio /path/to/audio.wav
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat UI with Gradio&lt;/h3&gt; 
&lt;p&gt;Launch a chat interface using Gradio:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mlx_vlm.chat_ui --model mlx-community/Qwen2-VL-2B-Instruct-4bit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python Script&lt;/h3&gt; 
&lt;p&gt;Here's an example of how to use MLX-VLM in a Python script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import mlx.core as mx
from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

# Load the model
model_path = "mlx-community/Qwen2-VL-2B-Instruct-4bit"
model, processor = load(model_path)
config = load_config(model_path)

# Prepare input
image = ["http://images.cocodataset.org/val2017/000000039769.jpg"]
# image = [Image.open("...")] can also be used with PIL.Image.Image objects
prompt = "Describe this image."

# Apply chat template
formatted_prompt = apply_chat_template(
    processor, config, prompt, num_images=len(image)
)

# Generate output
output = generate(model, processor, formatted_prompt, image, verbose=False)
print(output)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Audio Example&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

# Load model with audio support
model_path = "mlx-community/gemma-3n-E2B-it-4bit"
model, processor = load(model_path)
config = model.config

# Prepare audio input
audio = ["/path/to/audio1.wav", "/path/to/audio2.mp3"]
prompt = "Describe what you hear in these audio files."

# Apply chat template with audio
formatted_prompt = apply_chat_template(
    processor, config, prompt, num_audios=len(audio)
)

# Generate output with audio
output = generate(model, processor, formatted_prompt, audio=audio, verbose=False)
print(output)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multi-Modal Example (Image + Audio)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

# Load multi-modal model
model_path = "mlx-community/gemma-3n-E2B-it-4bit"
model, processor = load(model_path)
config = model.config

# Prepare inputs
image = ["/path/to/image.jpg"]
audio = ["/path/to/audio.wav"]
prompt = ""

# Apply chat template
formatted_prompt = apply_chat_template(
    processor, config, prompt,
    num_images=len(image),
    num_audios=len(audio)
)

# Generate output
output = generate(model, processor, formatted_prompt, image, audio=audio, verbose=False)
print(output)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server (FastAPI)&lt;/h3&gt; 
&lt;p&gt;Start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mlx_vlm.server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The server provides multiple endpoints for different use cases and supports dynamic model loading/unloading with caching (one model at a time).&lt;/p&gt; 
&lt;h4&gt;Available Endpoints&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;/generate&lt;/code&gt; - Main generation endpoint with support for images, audio, and text&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/chat&lt;/code&gt; - Chat-style interaction endpoint&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/responses&lt;/code&gt; - OpenAI-compatible endpoint&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/health&lt;/code&gt; - Check server status&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;/unload&lt;/code&gt; - Unload current model from memory&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Usage Examples&lt;/h4&gt; 
&lt;h5&gt;Text Generation&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/Qwen2-VL-2B-Instruct-4bit",
    "prompt": "Hello, how are you?",
    "stream": true,
    "max_tokens": 100
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Image Generation&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/Qwen2.5-VL-32B-Instruct-8bit",
    "image": ["/path/to/repo/examples/images/renewables_california.png"],
    "prompt": "This is today'\''s chart for energy demand in California. Can you provide an analysis of the chart and comment on the implications for renewable energy in California?",
    "system": "You are a helpful assistant.",
    "stream": true,
    "max_tokens": 1000
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Audio Support (New)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/gemma-3n-E2B-it-4bit",
    "audio": ["/path/to/audio1.wav", "https://example.com/audio2.mp3"],
    "prompt": "Describe what you hear in these audio files",
    "stream": true,
    "max_tokens": 500
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Multi-Modal (Image + Audio)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/gemma-3n-E2B-it-4bit",
    "image": ["/path/to/image.jpg"],
    "audio": ["/path/to/audio.wav"],
    "prompt": "",
    "max_tokens": 1000
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chat Endpoint&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/Qwen2-VL-2B-Instruct-4bit",
    "messages": [
      {
        "role": "user",
        "content": "What is in this image?",
        "images": ["/path/to/image.jpg"]
      }
    ],
    "max_tokens": 100
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;OpenAI-Compatible Endpoint&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -X POST "http://localhost:8000/responses" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/Qwen2-VL-2B-Instruct-4bit",
    "messages": [
      {
        "role": "user",
        "content": [
          {"type": "input_text", "text": "What is in this image?"},
          {"type": "input_image", "image": "/path/to/image.jpg"}
        ]
      }
    ],
    "max_tokens": 100
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Request Parameters&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;model&lt;/code&gt;: Model identifier (required)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;prompt&lt;/code&gt;: Text prompt for generation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;image&lt;/code&gt;: List of image URLs or local paths (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio&lt;/code&gt;: List of audio URLs or local paths (optional, new)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;system&lt;/code&gt;: System prompt (optional)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;messages&lt;/code&gt;: Chat messages for chat/OpenAI endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_tokens&lt;/code&gt;: Maximum tokens to generate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;temperature&lt;/code&gt;: Sampling temperature&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;top_p&lt;/code&gt;: Top-p sampling parameter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stream&lt;/code&gt;: Enable streaming responses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Multi-Image Chat Support&lt;/h2&gt; 
&lt;p&gt;MLX-VLM supports analyzing multiple images simultaneously with select models. This feature enables more complex visual reasoning tasks and comprehensive analysis across multiple images in a single conversation.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;Python Script&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

model_path = "mlx-community/Qwen2-VL-2B-Instruct-4bit"
model, processor = load(model_path)
config = model.config

images = ["path/to/image1.jpg", "path/to/image2.jpg"]
prompt = "Compare these two images."

formatted_prompt = apply_chat_template(
    processor, config, prompt, num_images=len(images)
)

output = generate(model, processor, formatted_prompt, images, verbose=False)
print(output)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Command Line&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mlx_vlm.generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt "Compare these images" --image path/to/image1.jpg path/to/image2.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Understanding&lt;/h2&gt; 
&lt;p&gt;MLX-VLM also supports video analysis such as captioning, summarization, and more, with select models.&lt;/p&gt; 
&lt;h3&gt;Supported Models&lt;/h3&gt; 
&lt;p&gt;The following models support video chat:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Qwen2-VL&lt;/li&gt; 
 &lt;li&gt;Qwen2.5-VL&lt;/li&gt; 
 &lt;li&gt;Idefics3&lt;/li&gt; 
 &lt;li&gt;LLaVA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;With more coming soon.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;Command Line&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mlx_vlm.video_generate --model mlx-community/Qwen2-VL-2B-Instruct-4bit --max-tokens 100 --prompt "Describe this video" --video path/to/video.mp4 --max-pixels 224 224 --fps 1.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These examples demonstrate how to use multiple images with MLX-VLM for more complex visual reasoning tasks.&lt;/p&gt; 
&lt;h1&gt;Fine-tuning&lt;/h1&gt; 
&lt;p&gt;MLX-VLM supports fine-tuning models with LoRA and QLoRA.&lt;/p&gt; 
&lt;h2&gt;LoRA &amp;amp; QLoRA&lt;/h2&gt; 
&lt;p&gt;To learn more about LoRA, please refer to the &lt;a href="https://raw.githubusercontent.com/Blaizzy/mlx-vlm/main/mlx_vlm/LORA.MD"&gt;LoRA.md&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fishaudio/fish-speech</title>
      <link>https://github.com/fishaudio/fish-speech</link>
      <description>&lt;p&gt;SOTA Open Source TTS&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Fish Speech&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; | &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/README.zh.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/README.pt-BR.md"&gt;Portuguese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/README.ja.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/README.ko.md"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/README.ar.md"&gt;Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.producthunt.com/products/fish-speech?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-fish-audio-s1" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=1023740&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1761164814710" alt="Fish Audio S1 - Expressive Voice Cloning and Text-to-Speech | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt;  &lt;a href="https://trendshift.io/repositories/7014" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/7014" alt="fishaudio%2Ffish-speech | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://count.getloli.com/get/@fish-speech?theme=asoul" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://discord.gg/Es5qTB9BcN"&gt; &lt;img alt="Discord" src="https://img.shields.io/discord/1214047546020728892?color=%23738ADB&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://hub.docker.com/r/fishaudio/fish-speech"&gt; &lt;img alt="Docker" src="https://img.shields.io/docker/pulls/fishaudio/fish-speech?style=flat-square&amp;amp;logo=docker" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://pd.qq.com/s/bwxia254o"&gt; &lt;img alt="QQ Channel" src="https://img.shields.io/badge/QQ-blue?logo=tencentqq" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://huggingface.co/spaces/TTS-AGI/TTS-Arena-V2"&gt; &lt;img alt="TTS-Arena2 Score" src="https://img.shields.io/badge/TTS_Arena2-Rank_%231-gold?style=flat-square&amp;amp;logo=trophy&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://huggingface.co/spaces/fishaudio/fish-speech-1"&gt; &lt;img alt="Huggingface" src="https://img.shields.io/badge/ğŸ¤—%20-space%20demo-yellow" /&gt; &lt;/a&gt; 
 &lt;a target="_blank" href="https://huggingface.co/fishaudio/openaudio-s1-mini"&gt; &lt;img alt="HuggingFace Model" src="https://img.shields.io/badge/ğŸ¤—%20-models-orange" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;License Notice&lt;/strong&gt;&lt;br /&gt; This codebase is released under &lt;strong&gt;Apache License&lt;/strong&gt; and all model weights are released under &lt;strong&gt;CC-BY-NC-SA-4.0 License&lt;/strong&gt;. Please refer to &lt;a href="https://raw.githubusercontent.com/fishaudio/fish-speech/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;Legal Disclaimer&lt;/strong&gt;&lt;br /&gt; We do not hold any responsibility for any illegal usage of the codebase. Please refer to your local laws about DMCA and other related laws.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Start Here&lt;/h2&gt; 
&lt;p&gt;Here are the official documents for Fish Speech, follow the instructions to get started easily.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://speech.fish.audio/install/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://speech.fish.audio/finetune/"&gt;Finetune&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://speech.fish.audio/inference/"&gt;Inference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://speech.fish.audio/examples"&gt;Samples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‰ Announcement&lt;/h2&gt; 
&lt;p&gt;We are excited to announce that we have rebranded to &lt;strong&gt;OpenAudio&lt;/strong&gt; â€” introducing a revolutionary new series of advanced Text-to-Speech models that builds upon the foundation of Fish-Speech.&lt;/p&gt; 
&lt;p&gt;We are proud to release &lt;strong&gt;OpenAudio-S1&lt;/strong&gt; as the first model in this series, delivering significant improvements in quality, performance, and capabilities.&lt;/p&gt; 
&lt;p&gt;OpenAudio-S1 comes in two versions: &lt;strong&gt;OpenAudio-S1&lt;/strong&gt; and &lt;strong&gt;OpenAudio-S1-mini&lt;/strong&gt;. Both models are now available on &lt;a href="https://fish.audio"&gt;Fish Audio Playground&lt;/a&gt; (for &lt;strong&gt;OpenAudio-S1&lt;/strong&gt;) and &lt;a href="https://huggingface.co/fishaudio/openaudio-s1-mini"&gt;Hugging Face&lt;/a&gt; (for &lt;strong&gt;OpenAudio-S1-mini&lt;/strong&gt;).&lt;/p&gt; 
&lt;p&gt;Visit the &lt;a href="https://openaudio.com/blogs/s1"&gt;OpenAudio website&lt;/a&gt; for blog &amp;amp; tech report.&lt;/p&gt; 
&lt;h2&gt;Highlights âœ¨&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Excellent TTS quality&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We use Seed TTS Eval Metrics to evaluate the model performance, and the results show that OpenAudio S1 achieves &lt;strong&gt;0.008 WER&lt;/strong&gt; and &lt;strong&gt;0.004 CER&lt;/strong&gt; on English text, which is significantly better than previous models. (English, auto eval, based on OpenAI gpt-4o-transcribe, speaker distance using Revai/pyannote-wespeaker-voxceleb-resnet34-LM)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Word Error Rate (WER)&lt;/th&gt; 
   &lt;th&gt;Character Error Rate (CER)&lt;/th&gt; 
   &lt;th&gt;Speaker Distance&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;S1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.008&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.004&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.332&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;S1-mini&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.011&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.005&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.380&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;strong&gt;Best Model in TTS-Arena2&lt;/strong&gt; ğŸ†&lt;/h3&gt; 
&lt;p&gt;OpenAudio S1 has achieved the &lt;strong&gt;#1 ranking&lt;/strong&gt; on &lt;a href="https://arena.speechcolab.org/"&gt;TTS-Arena2&lt;/a&gt;, the benchmark for text-to-speech evaluation:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/assets/Elo.jpg" alt="TTS-Arena2 Ranking" style="width: 75%;" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;Speech Control&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;OpenAudio S1 &lt;strong&gt;supports a variety of emotional, tone, and special markers&lt;/strong&gt; to enhance speech synthesis:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basic emotions&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;(angry) (sad) (excited) (surprised) (satisfied) (delighted) 
(scared) (worried) (upset) (nervous) (frustrated) (depressed)
(empathetic) (embarrassed) (disgusted) (moved) (proud) (relaxed)
(grateful) (confident) (interested) (curious) (confused) (joyful)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced emotions&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;(disdainful) (unhappy) (anxious) (hysterical) (indifferent) 
(impatient) (guilty) (scornful) (panicked) (furious) (reluctant)
(keen) (disapproving) (negative) (denying) (astonished) (serious)
(sarcastic) (conciliative) (comforting) (sincere) (sneering)
(hesitating) (yielding) (painful) (awkward) (amused)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tone markers&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;(in a hurry tone) (shouting) (screaming) (whispering) (soft tone)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Special audio effects&lt;/strong&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;(laughing) (chuckling) (sobbing) (crying loudly) (sighing) (panting)
(groaning) (crowd laughing) (background laughter) (audience laughing)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use Ha,ha,ha to control, there's many other cases waiting to be explored by yourself.&lt;/p&gt; 
&lt;p&gt;(Support for English, Chinese and Japanese now, and more languages is coming soon!)&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Two Type of Models&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Availability&lt;/th&gt; 
   &lt;th&gt;Features&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;S1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;4B parameters&lt;/td&gt; 
   &lt;td&gt;Avaliable on &lt;a href="https://fish.audio/"&gt;fish.audio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Full-featured flagship model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;S1-mini&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;0.5B parameters&lt;/td&gt; 
   &lt;td&gt;Avaliable on huggingface &lt;a href="https://huggingface.co/spaces/fishaudio/openaudio-s1-mini"&gt;hf space&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Distilled version with core capabilities&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Both S1 and S1-mini incorporate online Reinforcement Learning from Human Feedback (RLHF).&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zero-shot &amp;amp; Few-shot TTS:&lt;/strong&gt; Input a 10 to 30-second vocal sample to generate high-quality TTS output. &lt;strong&gt;For detailed guidelines, see &lt;a href="https://docs.fish.audio/resources/best-practices/voice-cloning"&gt;Voice Cloning Best Practices&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multilingual &amp;amp; Cross-lingual Support:&lt;/strong&gt; Simply copy and paste multilingual text into the input boxâ€”no need to worry about the language. Currently supports English, Japanese, Korean, Chinese, French, German, Arabic, and Spanish.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;No Phoneme Dependency:&lt;/strong&gt; The model has strong generalization capabilities and does not rely on phonemes for TTS. It can handle text in any language script.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Highly Accurate:&lt;/strong&gt; Achieves a low CER (Character Error Rate) of around 0.4% and WER (Word Error Rate) of around 0.8% for Seed-TTS Eval.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fast:&lt;/strong&gt; Accelerated by torch compile, the real-time factor is approximately 1:7 on an Nvidia RTX 4090 GPU.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WebUI Inference:&lt;/strong&gt; Features an easy-to-use, Gradio-based web UI compatible with Chrome, Firefox, Edge, and other browsers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy-Friendly:&lt;/strong&gt; Easily set up an inference server with native support for Linux and Windows (macOS support coming soon), minimizing performance loss.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;strong&gt;Media &amp;amp; Demos&lt;/strong&gt;&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;&lt;strong&gt;Social Media&lt;/strong&gt;&lt;/h3&gt; 
 &lt;a href="https://x.com/FishAudio/status/1929915992299450398" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/ğ•-Latest_Demo-black?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Latest Demo on X" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;strong&gt;Interactive Demos&lt;/strong&gt;&lt;/h3&gt; 
 &lt;a href="https://fish.audio" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Fish_Audio-Try_OpenAudio_S1-blue?style=for-the-badge" alt="Try OpenAudio S1" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.co/spaces/fishaudio/openaudio-s1-mini" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Hugging_Face-Try_S1_Mini-yellow?style=for-the-badge" alt="Try S1 Mini" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;strong&gt;Video Showcases&lt;/strong&gt;&lt;/h3&gt; 
 &lt;a href="https://www.youtube.com/watch?v=SYuPvd7m06A" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/fishaudio/fish-speech/main/docs/assets/Thumbnail.jpg" alt="OpenAudio S1 Video" style="width: 50%;" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/daniilrobnikov/vits2"&gt;VITS2 (daniilrobnikov)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fishaudio/Bert-VITS2"&gt;Bert-VITS2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innnky/gpt-vits"&gt;GPT VITS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b04901014/MQTTS"&gt;MQTTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch-labs/gpt-fast"&gt;GPT Fast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RVC-Boss/GPT-SoVITS"&gt;GPT-SoVITS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/QwenLM/Qwen3"&gt;Qwen3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tech Report (V1.4)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{fish-speech-v1.4,
      title={Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis},
      author={Shijia Liao and Yuxuan Wang and Tianyu Li and Yifan Cheng and Ruoyi Zhang and Rongzhi Zhou and Yijin Xing},
      year={2024},
      eprint={2411.01156},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2411.01156},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>DrewThomasson/ebook2audiobook</title>
      <link>https://github.com/DrewThomasson/ebook2audiobook</link>
      <description>&lt;p&gt;Generate audiobooks from e-books, voice cloning &amp; 1107+ languages!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ“š ebook2audiobook&lt;/h1&gt; 
&lt;p&gt;CPU/GPU Converter from eBooks to audiobooks with chapters and metadata&lt;br /&gt; using XTTSv2, Bark, Vits, Fairseq, YourTTS, Tacotron and more. Supports voice cloning and +1110 languages!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;This tool is intended for use with non-DRM, legally acquired eBooks only.&lt;/strong&gt; &lt;br /&gt; The authors are not responsible for any misuse of this software or any resulting legal consequences. &lt;br /&gt; Use this tool responsibly and in accordance with all applicable laws.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/63Tv3F65k6"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/63Tv3F65k6" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Thanks to support ebook2audiobook developers!&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/athomasson2"&gt;&lt;img src="https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&amp;amp;logo=ko-fi&amp;amp;logoColor=white" alt="Ko-Fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run locally&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;&lt;img src="https://img.shields.io/badge/Quick%20Start-blue?style=for-the-badge" alt="Quick Start" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml"&gt;&lt;img src="https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml/badge.svg?sanitize=true" alt="Docker Build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/releases/latest"&gt;&lt;img src="https://img.shields.io/badge/Download-Now-blue.svg?sanitize=true" alt="Download" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://github.com/DrewThomasson/ebook2audiobook"&gt; &lt;img src="https://img.shields.io/badge/Platform-mac%20|%20linux%20|%20windows-lightgrey" alt="Platform" /&gt; &lt;/a&gt;
&lt;a href="https://hub.docker.com/r/athomasson2/ebook2audiobook"&gt; &lt;img alt="Docker Pull Count" src="https://img.shields.io/docker/pulls/athomasson2/ebook2audiobook.svg?sanitize=true" /&gt; &lt;/a&gt; 
&lt;h3&gt;Run Remotely&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/ebook2audiobook"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/DrewThomasson/ebook2audiobook/blob/main/Notebooks/colab_ebook2audiobook.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Free Google Colab" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Rihcus/ebook2audiobookXTTS/raw/main/Notebooks/kaggle-ebook2audiobook.ipynb"&gt;&lt;img src="https://img.shields.io/badge/Kaggle-035a7d?style=flat&amp;amp;logo=kaggle&amp;amp;logoColor=white" alt="Kaggle" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;GUI Interface&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/demo_web_gui.gif" alt="demo_web_gui" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to see images of Web GUI&lt;/summary&gt; 
 &lt;img width="1728" alt="GUI Screen 1" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_1.png" /&gt; 
 &lt;img width="1728" alt="GUI Screen 2" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_2.png" /&gt; 
 &lt;img width="1728" alt="GUI Screen 3" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_3.png" /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;New Default Voice Demo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/750035dc-e355-46f1-9286-05c1d9e88cea"&gt;https://github.com/user-attachments/assets/750035dc-e355-46f1-9286-05c1d9e88cea&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;More Demos&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;ASMR Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/68eee9a1-6f71-4903-aacd-47397e47e422"&gt;https://github.com/user-attachments/assets/68eee9a1-6f71-4903-aacd-47397e47e422&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Rainy Day Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d25034d9-c77f-43a9-8f14-0d167172b080"&gt;https://github.com/user-attachments/assets/d25034d9-c77f-43a9-8f14-0d167172b080&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Scarlett Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b12009ee-ec0d-45ce-a1ef-b3a52b9f8693"&gt;https://github.com/user-attachments/assets/b12009ee-ec0d-45ce-a1ef-b3a52b9f8693&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;David Attenborough Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/81c4baad-117e-4db5-ac86-efc2b7fea921"&gt;https://github.com/user-attachments/assets/81c4baad-117e-4db5-ac86-efc2b7fea921&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/DrewThomasson/VoxNovel/raw/dc5197dff97252fa44c391dc0596902d71278a88/readme_files/example_in_app.jpeg" alt="Example" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;README.md&lt;/h2&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#-ebook2audiobook"&gt;ebook2audiobook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#gui-interface"&gt;GUI Interface&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#demos"&gt;Demos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#supported-languages"&gt;Supported Languages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#hardware-requirements"&gt;Minimum Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Run Locally&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Launching Gradio Web Interface&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#basic--usage"&gt;Basic Headless Usage&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#example-of-custom-model-zip-upload"&gt;Headless Custom XTTS Model Usage&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#help-command-output"&gt;Help command output&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#run-remotely"&gt;Run Remotely&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tuned-tts-models"&gt;Fine Tuned TTS models&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tuned-tts-collection"&gt;Collection of Fine-Tuned TTS Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tune-your-own-xttsv2-model"&gt;Train XTTSv2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-gpu-options"&gt;Docker&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-gpu-options"&gt;GPU options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#running-the-pre-built-docker-container"&gt;Docker Run&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#building-the-docker-container"&gt;Docker Build&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-compose"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-headless-guide"&gt;Docker headless guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-container-file-locations"&gt;Docker container file locations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#common-docker-issues"&gt;Common Docker issues&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#supported-ebook-formats"&gt;Supported eBook Formats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#output-formats"&gt;Output Formats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#updating-to-latest-version"&gt;Updating to Latest Version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#reverting-to-older-versions"&gt;Revert to older Version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#common-issues"&gt;Common Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#special-thanks"&gt;Special Thanks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“š Splits eBook into chapters for organized audio.&lt;/li&gt; 
 &lt;li&gt;ğŸ™ï¸ High-quality text-to-speech with &lt;a href="https://huggingface.co/coqui/XTTS-v2"&gt;Coqui XTTSv2&lt;/a&gt; and &lt;a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms"&gt;Fairseq&lt;/a&gt; (and more).&lt;/li&gt; 
 &lt;li&gt;ğŸ—£ï¸ Optional voice cloning with your own voice file.&lt;/li&gt; 
 &lt;li&gt;ğŸŒ Supports +1110 languages (English by default). &lt;a href="https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html"&gt;List of Supported languages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ–¥ï¸ Designed to run on 4GB RAM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Arabic (ar)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Chinese (zh)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;English (en)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Spanish (es)&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;French (fr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;German (de)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Italian (it)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Portuguese (pt)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Polish (pl)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Turkish (tr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Russian (ru)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Dutch (nl)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Czech (cs)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Japanese (ja)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Hindi (hi)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Bengali (bn)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Hungarian (hu)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Korean (ko)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Vietnamese (vi)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Swedish (sv)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Persian (fa)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Yoruba (yo)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Swahili (sw)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Indonesian (id)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Slovak (sk)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Croatian (hr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Tamil (ta)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Danish (da)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html"&gt;&lt;strong&gt;+1100 languages and dialects here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;4gb RAM minimum, 8GB recommended&lt;/li&gt; 
 &lt;li&gt;Virtualization enabled if running on windows (Docker only)&lt;/li&gt; 
 &lt;li&gt;CPU (intel, AMD, ARM), GPU (Nvidia, AMD*, Intel*) (Recommended), MPS (Apple Silicon CPU) *available very soon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Before to post an install or bug issue search carefully to the opened and closed issues TAB&lt;br /&gt; to be sure your issue does not exist already.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;strong&gt;Lacking of any standards structure like what is a chapter, paragraph, preface etc.&lt;br /&gt; you should first remove manually any text you don't want to be converted in audio.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installation Instructions&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone repo&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DrewThomasson/ebook2audiobook.git
cd ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Launching Gradio Web Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run ebook2audiobook&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh  # Run launch script
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mac Launcher&lt;/strong&gt;&lt;br /&gt; Double click &lt;code&gt;Mac Ebook2Audiobook Launcher.command&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd  # Run launch script or double click on it
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows Launcher&lt;/strong&gt;&lt;br /&gt; Double click &lt;code&gt;ebook2audiobook.cmd&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Manual Python Install&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# (for experts only!)
REQUIRED_PROGRAMS=("calibre" "ffmpeg" "nodejs" "mecab" "espeak-ng" "rust" "sox")
REQUIRED_PYTHON_VERSION="3.12"
pip install -r requirements.txt  # Install Python Requirements
python app.py  # Run Ebook2Audiobook
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open the Web App&lt;/strong&gt;: Click the URL provided in the terminal to access the web app and convert eBooks. &lt;code&gt;http://localhost:7860/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;For Public Link&lt;/strong&gt;: &lt;code&gt;python app.py --share&lt;/code&gt; (all OS) &lt;code&gt;./ebook2audiobook.sh --share&lt;/code&gt; (Linux/MacOS) &lt;code&gt;ebook2audiobook.cmd --share&lt;/code&gt; (Windows)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;If the script is stopped and run again, you need to refresh your gradio GUI interface&lt;br /&gt; to let the web page reconnect to the new connection socket.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --headless --ebook &amp;lt;path_to_ebook_file&amp;gt; \
    --voice [path_to_voice_file] --language [language_code]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --headless --ebook &amp;lt;path_to_ebook_file&amp;gt;
    --voice [path_to_voice_file] --language [language_code]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--ebook]&lt;/strong&gt;: Path to your eBook file&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--voice]&lt;/strong&gt;: Voice cloning file path (optional)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--language]&lt;/strong&gt;: Language code in ISO-639-3 (i.e.: ita for italian, eng for english, deu for german...).&lt;br /&gt; Default language is eng and --language is optional for default language set in ./lib/lang.py.&lt;br /&gt; The ISO-639-1 2 letters codes are also supported.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example of Custom Model Zip Upload&lt;/h3&gt; 
&lt;p&gt;(must be a .zip file containing the mandatory model files. Example for XTTSv2: config.json, model.pth, vocab.json and ref.wav)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --headless --ebook &amp;lt;ebook_file_path&amp;gt; \
    --voice &amp;lt;target_voice_file_path&amp;gt; --language &amp;lt;language&amp;gt; --custom_model &amp;lt;custom_model_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --headless --ebook &amp;lt;ebook_file_path&amp;gt; \
    --voice &amp;lt;target_voice_file_path&amp;gt; --language &amp;lt;language&amp;gt; --custom_model &amp;lt;custom_model_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&amp;lt;custom_model_path&amp;gt;&lt;/strong&gt;: Path to &lt;code&gt;model_name.zip&lt;/code&gt; file, which must contain (according to the tts engine) all the mandatory files&lt;br /&gt; (see ./lib/models.py).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For Detailed Guide with list of all Parameters to use&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --help
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --help
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Or for all OS&lt;/strong&gt; &lt;code&gt;python app.py --help &lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a id="help-command-output"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;usage: app.py [-h] [--session SESSION] [--share] [--headless] [--ebook EBOOK]
              [--ebooks_dir EBOOKS_DIR] [--language LANGUAGE] [--voice VOICE]
              [--device {cpu,gpu,mps}]
              [--tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}]
              [--custom_model CUSTOM_MODEL] [--fine_tuned FINE_TUNED]
              [--output_format OUTPUT_FORMAT] [--temperature TEMPERATURE]
              [--length_penalty LENGTH_PENALTY] [--num_beams NUM_BEAMS]
              [--repetition_penalty REPETITION_PENALTY] [--top_k TOP_K]
              [--top_p TOP_P] [--speed SPEED] [--enable_text_splitting]
              [--text_temp TEXT_TEMP] [--waveform_temp WAVEFORM_TEMP]
              [--output_dir OUTPUT_DIR] [--version]

Convert eBooks to Audiobooks using a Text-to-Speech model. You can either launch the Gradio interface or run the script in headless mode for direct conversion.

options:
  -h, --help            show this help message and exit
  --session SESSION     Session to resume the conversion in case of interruption, crash, 
                            or reuse of custom models and custom cloning voices.

**** The following options are for all modes:
  Optional

**** The following option are for gradio/gui mode only:
  Optional

  --share               Enable a public shareable Gradio link.

**** The following options are for --headless mode only:
  --headless            Run the script in headless mode
  --ebook EBOOK         Path to the ebook file for conversion. Cannot be used when --ebooks_dir is present.
  --ebooks_dir EBOOKS_DIR
                        Relative or absolute path of the directory containing the files to convert. 
                            Cannot be used when --ebook is present.
  --language LANGUAGE   Language of the e-book. Default language is set 
                            in ./lib/lang.py sed as default if not present. All compatible language codes are in ./lib/lang.py

optional parameters:
  --voice VOICE         (Optional) Path to the voice cloning file for TTS engine. 
                            Uses the default voice if not present.
  --device {cpu,gpu,mps}
                        (Optional) Pprocessor unit type for the conversion. 
                            Default is set in ./lib/conf.py if not present. Fall back to CPU if GPU not available.
  --tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}
                        (Optional) Preferred TTS engine (available are: ['XTTSv2', 'BARK', 'VITS', 'FAIRSEQ', 'TACOTRON2', 'YOURTTS', 'xtts', 'bark', 'vits', 'fairseq', 'tacotron', 'yourtts'].
                            Default depends on the selected language. The tts engine should be compatible with the chosen language
  --custom_model CUSTOM_MODEL
                        (Optional) Path to the custom model zip file cntaining mandatory model files. 
                            Please refer to ./lib/models.py
  --fine_tuned FINE_TUNED
                        (Optional) Fine tuned model path. Default is builtin model.
  --output_format OUTPUT_FORMAT
                        (Optional) Output audio format. Default is set in ./lib/conf.py
  --temperature TEMPERATURE
                        (xtts only, optional) Temperature for the model. 
                            Default to config.json model. Higher temperatures lead to more creative outputs.
  --length_penalty LENGTH_PENALTY
                        (xtts only, optional) A length penalty applied to the autoregressive decoder. 
                            Default to config.json model. Not applied to custom models.
  --num_beams NUM_BEAMS
                        (xtts only, optional) Controls how many alternative sequences the model explores. Must be equal or greater than length penalty. 
                            Default to config.json model.
  --repetition_penalty REPETITION_PENALTY
                        (xtts only, optional) A penalty that prevents the autoregressive decoder from repeating itself. 
                            Default to config.json model.
  --top_k TOP_K         (xtts only, optional) Top-k sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. 
                            Default to config.json model.
  --top_p TOP_P         (xtts only, optional) Top-p sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. Default to config.json model.
  --speed SPEED         (xtts only, optional) Speed factor for the speech generation. 
                            Default to config.json model.
  --enable_text_splitting
                        (xtts only, optional) Enable TTS text splitting. This option is known to not be very efficient. 
                            Default to config.json model.
  --text_temp TEXT_TEMP
                        (bark only, optional) Text Temperature for the model. 
                            Default to 0.85. Higher temperatures lead to more creative outputs.
  --waveform_temp WAVEFORM_TEMP
                        (bark only, optional) Waveform Temperature for the model. 
                            Default to 0.5. Higher temperatures lead to more creative outputs.
  --output_dir OUTPUT_DIR
                        (Optional) Path to the output directory. Default is set in ./lib/conf.py
  --version             Show the version of the script and exit

Example usage:    
Windows:
    Gradio/GUI:
    ebook2audiobook.cmd
    Headless mode:
    ebook2audiobook.cmd --headless --ebook '/path/to/file'
Linux/Mac:
    Gradio/GUI:
    ./ebook2audiobook.sh
    Headless mode:
    ./ebook2audiobook.sh --headless --ebook '/path/to/file'
    
Tip: to add of silence (1.4 seconds) into your text just use "###" or "[pause]".

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: in gradio/gui mode, to cancel a running conversion, just click on the [X] from the ebook upload component.&lt;/p&gt; 
&lt;p&gt;TIP: if it needs some more pauses, just add '###' or '[pause]' between the words you wish more pause. one [pause] equals to 1.4 seconds&lt;/p&gt; 
&lt;h4&gt;Docker GPU Options&lt;/h4&gt; 
&lt;p&gt;Available pre-build tags: &lt;code&gt;latest&lt;/code&gt; (CUDA 11.8)&lt;/p&gt; 
&lt;h4&gt;Edit: IF GPU isn't detected then you'll have to build the image -&amp;gt; &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#building-the-docker-container"&gt;Building the Docker Container&lt;/a&gt;&lt;/h4&gt; 
&lt;h4&gt;Running the pre-built Docker Container&lt;/h4&gt; 
&lt;p&gt;-Run with CPU only&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run --pull always --rm -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;-Run with GPU Speedup (NVIDIA compatible only)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run --pull always --rm --gpus all -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command will start the Gradio interface on port 7860.(localhost:7860)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For more options add the parameter &lt;code&gt;--help&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Building the Docker Container&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can build the docker image with the command:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker build -t athomasson2/ebook2audiobook .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Avalible Docker Build Arguments&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;--build-arg TORCH_VERSION=cuda118&lt;/code&gt; Available tags: [cuda121, cuda118, cuda128, rocm, xpu, cpu]&lt;/p&gt; 
&lt;p&gt;All CUDA version numbers should work, Ex: CUDA 11.6-&amp;gt; cuda116&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--build-arg SKIP_XTTS_TEST=true&lt;/code&gt; (Saves space by not baking XTTSv2 model into docker image)&lt;/p&gt; 
&lt;h2&gt;Docker container file locations&lt;/h2&gt; 
&lt;p&gt;All ebook2audiobooks will have the base dir of &lt;code&gt;/app/&lt;/code&gt; For example: &lt;code&gt;tmp&lt;/code&gt; = &lt;code&gt;/app/tmp&lt;/code&gt; &lt;code&gt;audiobooks&lt;/code&gt; = &lt;code&gt;/app/audiobooks&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Docker headless guide&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before you do run this you need to create a dir named "input-folder" in your current dir which will be linked, This is where you can put your input files for the docker image to see&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir input-folder &amp;amp;&amp;amp; mkdir Audiobooks
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the command below swap out &lt;strong&gt;YOUR_INPUT_FILE.TXT&lt;/strong&gt; with the name of your input file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --pull always --rm \
    -v $(pwd)/input-folder:/app/input_folder \
    -v $(pwd)/audiobooks:/app/audiobooks \
    athomasson2/ebook2audiobook \
    --headless --ebook /input_folder/YOUR_EBOOK_FILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;The output Audiobooks will be found in the Audiobook folder which will also be located in your local dir you ran this docker command in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;To get the help command for the other parameters this program has you can run this&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --pull always --rm athomasson2/ebook2audiobook --help

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That will output this &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#help-command-output"&gt;Help command output&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;p&gt;This project uses Docker Compose to run locally. You can enable or disable GPU support by setting either &lt;code&gt;*gpu-enabled&lt;/code&gt; or &lt;code&gt;*gpu-disabled&lt;/code&gt; in &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Steps to Run&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt; (if you haven't already): &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DrewThomasson/ebook2audiobook.git
cd ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set GPU Support (disabled by default)&lt;/strong&gt; To enable GPU support, modify &lt;code&gt;docker-compose.yml&lt;/code&gt; and change &lt;code&gt;*gpu-disabled&lt;/code&gt; to &lt;code&gt;*gpu-enabled&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start the service:&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker-compose up -d # To update add --build

# Podman
podman compose -f podman-compose.yml up -d # To update add --build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Access the service:&lt;/strong&gt; The service will be available at &lt;a href="http://localhost:7860"&gt;http://localhost:7860&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Common Docker Issues&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;My NVIDIA GPU isnt being detected?? -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/wiki/GPU-ISSUES"&gt;GPU ISSUES Wiki Page&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;python: can't open file '/home/user/app/app.py': [Errno 2] No such file or directory&lt;/code&gt; (Just remove all post arguments as I replaced the &lt;code&gt;CMD&lt;/code&gt; with &lt;code&gt;ENTRYPOINT&lt;/code&gt; in the &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/Dockerfile"&gt;Dockerfile&lt;/a&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Example: &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook app.py --script_mode full_docker&lt;/code&gt; - &amp;gt; corrected - &amp;gt; &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Arguments can be easily added like this now &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook --share&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Docker gets stuck downloading Fine-Tuned models. (This does not happen for every computer but some appear to run into this issue) Disabling the progress bar appears to fix the issue, as discussed &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/191"&gt;here in #191&lt;/a&gt; Example of adding this fix in the &lt;code&gt;docker run&lt;/code&gt; command&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-Dockerfile"&gt;docker run --pull always --rm --gpus all -e HF_HUB_DISABLE_PROGRESS_BARS=1 -e HF_HUB_ENABLE_HF_TRANSFER=0 \
    -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Fine Tuned TTS models&lt;/h2&gt; 
&lt;h4&gt;Fine Tune your own XTTSv2 model&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/xtts-finetune-webui-gpu"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/raw/v25/Notebooks/finetune/xtts/kaggle-xtts-finetune-webui-gradio-gui.ipynb"&gt;&lt;img src="https://img.shields.io/badge/Kaggle-035a7d?style=flat&amp;amp;logo=kaggle&amp;amp;logoColor=white" alt="Kaggle" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/DrewThomasson/ebook2audiobook/blob/v25/Notebooks/finetune/xtts/colab_xtts_finetune_webui.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;De-noise training data&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/DeepFilterNet2_no_limit"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Rikorose/DeepFilterNet"&gt;&lt;img src="https://img.shields.io/badge/DeepFilterNet-181717?logo=github" alt="GitHub Repo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Fine Tuned TTS Collection&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/drewThomasson/fineTunedTTSModels/tree/main"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Models-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For an XTTSv2 custom model a ref audio clip of the voice reference is mandatory:&lt;/p&gt; 
&lt;h2&gt;Supported eBook Formats&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.epub&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.mobi&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.chm&lt;/code&gt;, &lt;code&gt;.lit&lt;/code&gt;, &lt;code&gt;.pdb&lt;/code&gt;, &lt;code&gt;.fb2&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.cbr&lt;/code&gt;, &lt;code&gt;.cbz&lt;/code&gt;, &lt;code&gt;.prc&lt;/code&gt;, &lt;code&gt;.lrf&lt;/code&gt;, &lt;code&gt;.pml&lt;/code&gt;, &lt;code&gt;.snb&lt;/code&gt;, &lt;code&gt;.cbc&lt;/code&gt;, &lt;code&gt;.rb&lt;/code&gt;, &lt;code&gt;.tcr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Best results&lt;/strong&gt;: &lt;code&gt;.epub&lt;/code&gt; or &lt;code&gt;.mobi&lt;/code&gt; for automatic chapter detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Output Formats&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creates a &lt;code&gt;['m4b', 'm4a', 'mp4', 'webm', 'mov', 'mp3', 'flac', 'wav', 'ogg', 'aac']&lt;/code&gt; (set in ./lib/conf.py) file with metadata and chapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Updating to Latest Version&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git pull # Locally/Compose

docker pull athomasson2/ebook2audiobook:latest # For Pre-build docker images
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Reverting to older Versions&lt;/h2&gt; 
&lt;p&gt;Releases can be found -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/releases"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git checkout tags/VERSION_NUM # Locally/Compose -&amp;gt; Example: git checkout tags/v25.7.7

athomasson2/ebook2audiobook:VERSION_NUM # For Pre-build docker images -&amp;gt; Example: athomasson2/ebook2audiobook:v25.7.7
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Common Issues:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;My NVIDIA GPU isnt being detected?? -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/wiki/GPU-ISSUES"&gt;GPU ISSUES Wiki Page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CPU is slow (better on server smp CPU) while NVIDIA GPU can have almost real time conversion. &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/discussions/19#discussioncomment-10879846"&gt;Discussion about this&lt;/a&gt; For faster multilingual generation I would suggest my other &lt;a href="https://github.com/DrewThomasson/ebook2audiobookpiper-tts"&gt;project that uses piper-tts&lt;/a&gt; instead (It doesn't have zero-shot voice cloning though, and is Siri quality voices, but it is much faster on cpu).&lt;/li&gt; 
 &lt;li&gt;"I'm having dependency issues" - Just use the docker, its fully self contained and has a headless mode, add &lt;code&gt;--help&lt;/code&gt; parameter at the end of the docker run command for more information.&lt;/li&gt; 
 &lt;li&gt;"Im getting a truncated audio issue!" - PLEASE MAKE AN ISSUE OF THIS, we don't speak every language and need advise from users to fine tune the sentence splitting logic.ğŸ˜Š&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What we need help with! ğŸ™Œ&lt;/h2&gt; 
&lt;h2&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/32"&gt;Full list of things can be found here&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Any help from people speaking any of the supported languages to help us improve the models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Do you need to rent a GPU to boost service from us?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A poll is open here &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/discussions/889"&gt;https://github.com/DrewThomasson/ebook2audiobook/discussions/889&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Coqui TTS&lt;/strong&gt;: &lt;a href="https://github.com/idiap/coqui-ai-TTS"&gt;Coqui TTS GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Calibre&lt;/strong&gt;: &lt;a href="https://calibre-ebook.com"&gt;Calibre Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FFmpeg&lt;/strong&gt;: &lt;a href="https://ffmpeg.org"&gt;FFmpeg Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/8"&gt;@shakenbake15 for better chapter saving method&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>suitenumerique/docs</title>
      <link>https://github.com/suitenumerique/docs</link>
      <description>&lt;p&gt;A collaborative note taking, wiki and documentation platform that scales. Built with Django and React.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/suitenumerique/docs"&gt; &lt;img alt="Docs" src="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/assets/banner-docs.png" width="100%" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/suitenumerique/docs/stargazers/"&gt; &lt;img src="https://img.shields.io/github/stars/suitenumerique/docs" alt="" /&gt; &lt;/a&gt; &lt;a href="https://github.com/suitenumerique/docs/raw/main/CONTRIBUTING.md"&gt;&lt;img alt="PRs Welcome" src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=shields" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/suitenumerique/docs" /&gt; &lt;img alt="GitHub closed issues" src="https://img.shields.io/github/issues-closed/suitenumerique/docs" /&gt; &lt;a href="https://github.com/suitenumerique/docs/raw/main/LICENSE"&gt; &lt;img alt="MIT License" src="https://img.shields.io/github/license/suitenumerique/docs" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://matrix.to/#/#docs-official:matrix.org"&gt; Chat on Matrix &lt;/a&gt; - &lt;a href="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/"&gt; Documentation &lt;/a&gt; - &lt;a href="https://raw.githubusercontent.com/suitenumerique/docs/main/#getting-started-"&gt; Getting started &lt;/a&gt; - &lt;a href="mailto:docs@numerique.gouv.fr"&gt; Reach out &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;La Suite Docs : Collaborative Text Editing&lt;/h1&gt; 
&lt;p&gt;Docs, where your notes can become knowledge through live collaboration.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/assets/docs_live_collaboration_light.gif" width="100%" align="center" /&gt; 
&lt;h2&gt;Why use Docs â“&lt;/h2&gt; 
&lt;p&gt;Docs is a collaborative text editor designed to address common challenges in knowledge building and sharing.&lt;/p&gt; 
&lt;h3&gt;Write&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ˜Œ Get simple, accessible online editing for your team.&lt;/li&gt; 
 &lt;li&gt;ğŸ’… Create clean documents with beautiful formatting options.&lt;/li&gt; 
 &lt;li&gt;ğŸ–Œï¸ Focus on your content using either the in-line editor, or &lt;a href="https://www.markdownguide.org/basic-syntax/"&gt;the Markdown syntax&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ğŸ§± Quickly design your page thanks to the many block types, accessible from the &lt;code&gt;/&lt;/code&gt; slash commands, as well as keyboard shortcuts.&lt;/li&gt; 
 &lt;li&gt;ğŸ”Œ Write offline! Your edits will be synced once you're back online.&lt;/li&gt; 
 &lt;li&gt;âœ¨ Save time thanks to our AI actions, such as rephrasing, summarizing, fixing typos, translating, etc. You can even turn your selected text into a prompt!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Work together&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤ Enjoy live editing! See your team collaborate in real time.&lt;/li&gt; 
 &lt;li&gt;ğŸ”’ Keep your information secure thanks to granular access control. Only share with the right people.&lt;/li&gt; 
 &lt;li&gt;ğŸ“‘ Export your content in multiple formats (&lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;) with customizable templates.&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Turn your team's collaborative work into organized knowledge with Subpages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Self-host&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ Docs is easy to install on your own servers&lt;/h4&gt; 
&lt;p&gt;We use Kubernetes for our &lt;a href="https://docs.numerique.gouv.fr/"&gt;production instance&lt;/a&gt; but also support Docker Compose. The community contributed a couple other methods (Nix, YunoHost etc.) check out the &lt;a href="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/installation/README.md"&gt;docs&lt;/a&gt; to get detailed instructions and examples.&lt;/p&gt; 
&lt;h4&gt;ğŸŒ Known instances&lt;/h4&gt; 
&lt;p&gt;We hope to see many more, here is an incomplete list of public Docs instances. Feel free to make a PR to add ones that are not listed belowğŸ™&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Url&lt;/th&gt; 
   &lt;th&gt;Org&lt;/th&gt; 
   &lt;th&gt;Public&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.numerique.gouv.fr/"&gt;docs.numerique.gouv.fr&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DINUM&lt;/td&gt; 
   &lt;td&gt;French public agents working for the central administration and the extended public sphere. ProConnect is required to login in or sign up&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.suite.anct.gouv.fr/"&gt;docs.suite.anct.gouv.fr&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ANCT&lt;/td&gt; 
   &lt;td&gt;French public agents working for the territorial administration and the extended public sphere. ProConnect is required to login in or sign up&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://notes.demo.opendesk.eu"&gt;notes.demo.opendesk.eu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZenDiS&lt;/td&gt; 
   &lt;td&gt;Demo instance of OpenDesk. Request access to get credentials&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://notes.liiib.re/"&gt;notes.liiib.re&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;lasuite.coop&lt;/td&gt; 
   &lt;td&gt;Free and open demo to all. Content and accounts are reset after one month&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.federated.nexus/"&gt;docs.federated.nexus&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;federated.nexus&lt;/td&gt; 
   &lt;td&gt;Public instance, but you have to &lt;a href="https://federated.nexus/register/"&gt;sign up for a Federated Nexus account&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.demo.mosacloud.eu/"&gt;docs.demo.mosacloud.eu&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;mosa.cloud&lt;/td&gt; 
   &lt;td&gt;Demo instance of mosa.cloud, a dutch company providing services around La Suite apps.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;âš ï¸ Advanced features&lt;/h4&gt; 
&lt;p&gt;For some advanced features (ex: Export as PDF) Docs relies on XL packages from BlockNote. These are licenced under GPL and are not MIT compatible. You can perfectly use Docs without these packages by setting the environment variable &lt;code&gt;PUBLISH_AS_MIT&lt;/code&gt; to true. That way you'll build an image of the application without the features that are not MIT compatible. Read the &lt;a href="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/env.md"&gt;environment variables documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Getting started ğŸ”§&lt;/h2&gt; 
&lt;h3&gt;Test it&lt;/h3&gt; 
&lt;p&gt;You can test Docs on your browser by visiting this &lt;a href="https://impress-preprod.beta.numerique.gouv.fr/docs/6ee5aac4-4fb9-457d-95bf-bb56c2467713/"&gt;demo document&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run Docs locally&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ The methods described below for running Docs locally is &lt;strong&gt;for testing purposes only&lt;/strong&gt;. It is based on building Docs using &lt;a href="https://min.io/"&gt;Minio&lt;/a&gt; as an S3-compatible storage solution. Of course you can choose any S3-compatible storage solution.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Make sure you have a recent version of Docker and &lt;a href="https://docs.docker.com/compose/install"&gt;Docker Compose&lt;/a&gt; installed on your laptop, then type:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ docker -v

Docker version 20.10.2, build 2291f61

$ docker compose version

Docker Compose version v2.32.4
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ You may need to run the following commands with &lt;code&gt;sudo&lt;/code&gt;, but this can be avoided by adding your user to the local &lt;code&gt;docker&lt;/code&gt; group.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Project bootstrap&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The easiest way to start working on the project is to use &lt;a href="https://www.gnu.org/software/make/"&gt;GNU Make&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make bootstrap FLUSH_ARGS='--no-input'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command builds the &lt;code&gt;app-dev&lt;/code&gt; and &lt;code&gt;frontend-dev&lt;/code&gt; containers, installs dependencies, performs database migrations and compiles translations. It's a good idea to use this command each time you are pulling code from the project repository to avoid dependency-related or migration-related issues.&lt;/p&gt; 
&lt;p&gt;Your Docker services should now be up and running ğŸ‰&lt;/p&gt; 
&lt;p&gt;You can access the project by going to &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You will be prompted to log in. The default credentials are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;username: impress
password: impress
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ğŸ“ Note that if you need to run them afterwards, you can use the eponymous Make rule:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;âš ï¸ For the frontend developer, it is often better to run the frontend in development mode locally.&lt;/p&gt; 
&lt;p&gt;To do so, install the frontend dependencies with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make frontend-development-install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And run the frontend locally in development mode with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make run-frontend-development
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To start all the services, except the frontend container, you can use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make run-backend
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To execute frontend tests &amp;amp; linting only&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make frontend-test
$ make frontend-lint
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Adding content&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can create a basic demo site by running this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make demo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, you can check all available Make rules using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Django admin&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can access the Django admin site at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://localhost:8071/admin"&gt;http://localhost:8071/admin&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You first need to create a superuser account:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shellscript"&gt;$ make superuser
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Feedback ğŸ™‹â€â™‚ï¸ğŸ™‹â€â™€ï¸&lt;/h2&gt; 
&lt;p&gt;We'd love to hear your thoughts, and hear about your experiments, so come and say hi on &lt;a href="https://matrix.to/#/#docs-official:matrix.org"&gt;Matrix&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap ğŸ’¡&lt;/h2&gt; 
&lt;p&gt;Want to know where the project is headed? &lt;a href="https://github.com/orgs/numerique-gouv/projects/13/views/11"&gt;ğŸ—ºï¸ Checkout our roadmap&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License ğŸ“&lt;/h2&gt; 
&lt;p&gt;This work is released under the MIT License (see &lt;a href="https://github.com/suitenumerique/docs/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;While Docs is a public-driven initiative, our license choice is an invitation for private sector actors to use, sell and contribute to the project.&lt;/p&gt; 
&lt;h2&gt;Contributing ğŸ™Œ&lt;/h2&gt; 
&lt;p&gt;This project is intended to be community-driven, so please, do not hesitate to &lt;a href="https://matrix.to/#/#docs-official:matrix.org"&gt;get in touch&lt;/a&gt; if you have any question related to our implementation or design decisions.&lt;/p&gt; 
&lt;p&gt;You can help us with translations on &lt;a href="https://crowdin.com/project/lasuite-docs"&gt;Crowdin&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you intend to make pull requests, see &lt;a href="https://github.com/suitenumerique/docs/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Directory structure:&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;docs
â”œâ”€â”€ bin - executable scripts or binaries that are used for various tasks, such as setup scripts, utility scripts, or custom commands.
â”œâ”€â”€ crowdin - for crowdin translations, a tool or service that helps manage translations for the project.
â”œâ”€â”€ docker - Dockerfiles and related configuration files used to build Docker images for the project. These images can be used for development, testing, or production environments.
â”œâ”€â”€ docs - documentation for the project, including user guides, API documentation, and other helpful resources.
â”œâ”€â”€ env.d/development - environment-specific configuration files for the development environment. These files might include environment variables, configuration settings, or other setup files needed for development.
â”œâ”€â”€ gitlint - configuration files for `gitlint`, a tool that enforces commit message guidelines to ensure consistency and quality in commit messages.
â”œâ”€â”€ playground - experimental or temporary code, where developers can test new features or ideas without affecting the main codebase.
â””â”€â”€ src - main source code directory, containing the core application code, libraries, and modules of the project.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Credits â¤ï¸&lt;/h2&gt; 
&lt;h3&gt;Stack&lt;/h3&gt; 
&lt;p&gt;Docs is built on top of &lt;a href="https://www.django-rest-framework.org/"&gt;Django Rest Framework&lt;/a&gt;, &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt;, &lt;a href="https://www.blocknotejs.org/"&gt;BlockNote.js&lt;/a&gt;, &lt;a href="https://tiptap.dev/docs/hocuspocus/introduction"&gt;HocusPocus&lt;/a&gt; and &lt;a href="https://yjs.dev/"&gt;Yjs&lt;/a&gt;. We thank the contributors of all these projects for their awesome work!&lt;/p&gt; 
&lt;p&gt;We are proud sponsors of &lt;a href="https://www.blocknotejs.org/"&gt;BlockNotejs&lt;/a&gt; and &lt;a href="https://yjs.dev/"&gt;Yjs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Gov â¤ï¸ open source&lt;/h3&gt; 
&lt;p&gt;Docs is the result of a joint effort led by the French ğŸ‡«ğŸ‡·ğŸ¥– (&lt;a href="https://www.numerique.gouv.fr/dinum/"&gt;DINUM&lt;/a&gt;) and German ğŸ‡©ğŸ‡ªğŸ¥¨ governments (&lt;a href="https://zendis.de/"&gt;ZenDiS&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;We are always looking for new public partners (we are currently onboarding the Netherlands ğŸ‡³ğŸ‡±ğŸ§€), feel free to &lt;a href="mailto:docs@numerique.gouv.fr"&gt;reach out&lt;/a&gt; if you are interested in using or contributing to Docs.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/suitenumerique/docs/main/docs/assets/europe_opensource.png" width="50%" /&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>droidrun/droidrun</title>
      <link>https://github.com/droidrun/droidrun</link>
      <description>&lt;p&gt;Automate your mobile devices with natural language commands - an LLM agnostic mobile Agent ğŸ¤–&lt;/p&gt;&lt;hr&gt;&lt;picture align="center"&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="./static/droidrun-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="./static/droidrun.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/droidrun/droidrun/main/static/droidrun.png" width="full" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-%F0%9F%93%95-0D9373?style=for-the-badge" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://cloud.droidrun.ai/sign-in?waitlist=true"&gt;&lt;img src="https://img.shields.io/badge/Cloud-%E2%98%81%EF%B8%8F-0D9373?style=for-the-badge" alt="Cloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/droidrun/droidrun/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/droidrun/droidrun?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai"&gt;&lt;img src="https://img.shields.io/badge/droidrun.ai-white" alt="droidrun.ai" /&gt;&lt;/a&gt; &lt;a href="https://x.com/droid_run"&gt;&lt;img src="https://img.shields.io/twitter/follow/droid_run?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZZbKEZZkwK"&gt;&lt;img src="https://img.shields.io/discord/1360219330318696488?color=white&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://droidrun.ai/benchmark"&gt;&lt;img src="https://img.shields.io/badge/Benchmark-91.4%EF%B9%AA-white" alt="Benchmark" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1753948032207" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" /&gt; 
  &lt;a href="https://www.producthunt.com/products/droidrun-framework-for-mobile-agent?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_source=badge-droidrun" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=983810&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1753948125523" alt="Droidrun - Give AI native control of physical &amp;amp; virtual phones. | Product Hunt" style="width: 200px; height: 54px;" width="200" height="54" /&gt;&lt;/a&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://zdoc.app/de/droidrun/droidrun"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/droidrun/droidrun"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/droidrun/droidrun"&gt;franÃ§ais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/droidrun/droidrun"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/droidrun/droidrun"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/droidrun/droidrun"&gt;PortuguÃªs&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/droidrun/droidrun"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/droidrun/droidrun"&gt;ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;DroidRun is a powerful framework for controlling Android and iOS devices through LLM agents. It allows you to automate device interactions using natural language commands. &lt;a href="https://droidrun.ai/benchmark"&gt;Checkout our benchmark results&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Droidrun?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤– Control Android and iOS devices with natural language commands&lt;/li&gt; 
 &lt;li&gt;ğŸ”€ Supports multiple LLM providers (OpenAI, Anthropic, Gemini, Ollama, DeepSeek)&lt;/li&gt; 
 &lt;li&gt;ğŸ§  Planning capabilities for complex multi-step tasks&lt;/li&gt; 
 &lt;li&gt;ğŸ’» Easy to use CLI with enhanced debugging features&lt;/li&gt; 
 &lt;li&gt;ğŸ Extendable Python API for custom automations&lt;/li&gt; 
 &lt;li&gt;ğŸ“¸ Screenshot analysis for visual understanding of the device&lt;/li&gt; 
 &lt;li&gt;ğŸ«† Execution tracing with Arize Phoenix&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'droidrun[google,anthropic,openai,deepseek,ollama,dev]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ Quickstart&lt;/h2&gt; 
&lt;p&gt;Read on how to get droidrun up and running within seconds in &lt;a href="https://docs.droidrun.ai/v3/quickstart"&gt;our docs&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4WT7FXJah2I"&gt;&lt;img src="https://img.youtube.com/vi/4WT7FXJah2I/0.jpg" alt="Quickstart Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ¬ Demo Videos&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accommodation booking&lt;/strong&gt;: Let Droidrun search for an apartment for you&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/VUpCyq1PSXw"&gt;&lt;img src="https://img.youtube.com/vi/VUpCyq1PSXw/0.jpg" alt="Droidrun Accommodation Booking Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Trend Hunter&lt;/strong&gt;: Let Droidrun hunt down trending posts&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/7V8S2f8PnkQ"&gt;&lt;img src="https://img.youtube.com/vi/7V8S2f8PnkQ/0.jpg" alt="Droidrun Trend Hunter Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streak Saver&lt;/strong&gt;: Let Droidrun save your streak on your favorite language learning app&lt;/p&gt; &lt;p&gt;&lt;a href="https://youtu.be/B5q2B467HKw"&gt;&lt;img src="https://img.youtube.com/vi/B5q2B467HKw/0.jpg" alt="Droidrun Streak Saver Demo" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ’¡ Example Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Automated UI testing of mobile applications&lt;/li&gt; 
 &lt;li&gt;Creating guided workflows for non-technical users&lt;/li&gt; 
 &lt;li&gt;Automating repetitive tasks on mobile devices&lt;/li&gt; 
 &lt;li&gt;Remote assistance for less technical users&lt;/li&gt; 
 &lt;li&gt;Exploring mobile UI with natural language commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt; 
&lt;h2&gt;Security Checks&lt;/h2&gt; 
&lt;p&gt;To ensure the security of the codebase, we have integrated security checks using &lt;code&gt;bandit&lt;/code&gt; and &lt;code&gt;safety&lt;/code&gt;. These tools help identify potential security issues in the code and dependencies.&lt;/p&gt; 
&lt;h3&gt;Running Security Checks&lt;/h3&gt; 
&lt;p&gt;Before submitting any code, please run the following security checks:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bandit&lt;/strong&gt;: A tool to find common security issues in Python code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;bandit -r droidrun
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safety&lt;/strong&gt;: A tool to check your installed dependencies for known security vulnerabilities.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;safety scan
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>karpathy/nanoGPT</title>
      <link>https://github.com/karpathy/nanoGPT</link>
      <description>&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanoGPT&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/nanogpt.jpg" alt="nanoGPT" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Update Nov 2025&lt;/strong&gt; nanoGPT has a new and improved cousin called &lt;a href="https://github.com/karpathy/nanochat"&gt;nanochat&lt;/a&gt;. It is very likely you meant to use/find nanochat instead. nanoGPT (this repo) is now very old and deprecated but I will leave it up for posterity.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of &lt;a href="https://github.com/karpathy/minGPT"&gt;minGPT&lt;/a&gt; that prioritizes teeth over education. Still under active development, but currently the file &lt;code&gt;train.py&lt;/code&gt; reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: &lt;code&gt;train.py&lt;/code&gt; is a ~300-line boilerplate training loop and &lt;code&gt;model.py&lt;/code&gt; a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanoGPT/master/assets/gpt2_124M_loss.png" alt="repro124m" /&gt;&lt;/p&gt; 
&lt;p&gt;Because the code is so simple, it is very easy to hack to your needs, train new models from scratch, or finetune pretrained checkpoints (e.g. biggest one currently available as a starting point would be the GPT-2 1.3B model from OpenAI).&lt;/p&gt; 
&lt;h2&gt;install&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;pip install torch numpy transformers datasets tiktoken wandb tqdm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pytorch.org"&gt;pytorch&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://numpy.org/install/"&gt;numpy&lt;/a&gt; &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;transformers&lt;/code&gt; for huggingface transformers &amp;lt;3 (to load GPT-2 checkpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;datasets&lt;/code&gt; for huggingface datasets &amp;lt;3 (if you want to download + preprocess OpenWebText)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tiktoken&lt;/code&gt; for OpenAI's fast BPE code &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wandb&lt;/code&gt; for optional logging &amp;lt;3&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tqdm&lt;/code&gt; for progress bars &amp;lt;3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;quick start&lt;/h2&gt; 
&lt;p&gt;If you are not a deep learning professional and you just want to feel the magic and get your feet wet, the fastest way to get started is to train a character-level GPT on the works of Shakespeare. First, we download it as a single (1MB) file and turn it from raw text into one large stream of integers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/shakespeare_char/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; in that data directory. Now it is time to train your GPT. The size of it very much depends on the computational resources of your system:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I have a GPU&lt;/strong&gt;. Great, we can quickly train a baby GPT with the settings provided in the &lt;a href="https://raw.githubusercontent.com/karpathy/nanoGPT/master/config/train_shakespeare_char.py"&gt;config/train_shakespeare_char.py&lt;/a&gt; config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you peek inside it, you'll see that we're training a GPT with a context size of up to 256 characters, 384 feature channels, and it is a 6-layer Transformer with 6 heads in each layer. On one A100 GPU this training run takes about 3 minutes and the best validation loss is 1.4697. Based on the configuration, the model checkpoints are being written into the &lt;code&gt;--out_dir&lt;/code&gt; directory &lt;code&gt;out-shakespeare-char&lt;/code&gt;. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This generates a few samples, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;lol &lt;code&gt;Â¯\_(ãƒ„)_/Â¯&lt;/code&gt;. Not bad for a character-level model after 3 minutes of training on a GPU. Better results are quite likely obtainable by instead finetuning a pretrained GPT-2 model on this dataset (see finetuning section later).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I only have a macbook&lt;/strong&gt; (or other cheap computer). No worries, we can still train a GPT but we want to dial things down a notch. I recommend getting the bleeding edge PyTorch nightly (&lt;a href="https://pytorch.org/get-started/locally/"&gt;select it here&lt;/a&gt; when installing) as it is currently quite likely to make your code more efficient. But even without it, a simple train run could look as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here, since we are running on CPU instead of GPU we must set both &lt;code&gt;--device=cpu&lt;/code&gt; and also turn off PyTorch 2.0 compile with &lt;code&gt;--compile=False&lt;/code&gt;. Then when we evaluate we get a bit more noisy but faster estimate (&lt;code&gt;--eval_iters=20&lt;/code&gt;, down from 200), our context size is only 64 characters instead of 256, and the batch size only 12 examples per iteration, not 64. We'll also use a much smaller Transformer (4 layers, 4 heads, 128 embedding size), and decrease the number of iterations to 2000 (and correspondingly usually decay the learning rate to around max_iters with &lt;code&gt;--lr_decay_iters&lt;/code&gt;). Because our network is so small we also ease down on regularization (&lt;code&gt;--dropout=0.0&lt;/code&gt;). This still runs in about ~3 minutes, but gets us a loss of only 1.88 and therefore also worse samples, but it's still good fun:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py --out_dir=out-shakespeare-char --device=cpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generates samples like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Not bad for ~3 minutes on a CPU, for a hint of the right character gestalt. If you're willing to wait longer, feel free to tune the hyperparameters, increase the size of the network, the context length (&lt;code&gt;--block_size&lt;/code&gt;), the length of training, etc.&lt;/p&gt; 
&lt;p&gt;Finally, on Apple Silicon Macbooks and with a recent PyTorch version make sure to add &lt;code&gt;--device=mps&lt;/code&gt; (short for "Metal Performance Shaders"); PyTorch then uses the on-chip GPU that can &lt;em&gt;significantly&lt;/em&gt; accelerate training (2-3X) and allow you to use larger networks. See &lt;a href="https://github.com/karpathy/nanoGPT/issues/28"&gt;Issue 28&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h2&gt;reproducing GPT-2&lt;/h2&gt; 
&lt;p&gt;A more serious deep learning professional may be more interested in reproducing GPT-2 results. So here we go - we first tokenize the dataset, in this case the &lt;a href="https://openwebtext2.readthedocs.io/en/latest/"&gt;OpenWebText&lt;/a&gt;, an open reproduction of OpenAI's (private) WebText:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python data/openwebtext/prepare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This downloads and tokenizes the &lt;a href="https://huggingface.co/datasets/openwebtext"&gt;OpenWebText&lt;/a&gt; dataset. It will create a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt; which holds the GPT2 BPE token ids in one sequence, stored as raw uint16 bytes. Then we're ready to kick off training. To reproduce GPT-2 (124M) you'll want at least an 8X A100 40GB node and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will run for about 4 days using PyTorch Distributed Data Parallel (DDP) and go down to loss of ~2.85. Now, a GPT-2 model just evaluated on OWT gets a val loss of about 3.11, but if you finetune it it will come down to ~2.85 territory (due to an apparent domain gap), making the two models ~match.&lt;/p&gt; 
&lt;p&gt;If you're in a cluster environment and you are blessed with multiple GPU nodes you can make GPU go brrrr e.g. across 2 nodes like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Run on the first (master) node with example IP 123.456.123.456:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
# Run on the worker node:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is a good idea to benchmark your interconnect (e.g. iperf3). In particular, if you don't have Infiniband then also prepend &lt;code&gt;NCCL_IB_DISABLE=1&lt;/code&gt; to the above launches. Your multinode training will work, but most likely &lt;em&gt;crawl&lt;/em&gt;. By default checkpoints are periodically written to the &lt;code&gt;--out_dir&lt;/code&gt;. We can sample from the model by simply &lt;code&gt;python sample.py&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, to train on a single GPU simply run the &lt;code&gt;python train.py&lt;/code&gt; script. Have a look at all of its args, the script tries to be very readable, hackable and transparent. You'll most likely want to tune a number of those variables depending on your needs.&lt;/p&gt; 
&lt;h2&gt;baselines&lt;/h2&gt; 
&lt;p&gt;OpenAI GPT-2 checkpoints allow us to get some baselines in place for openwebtext. We can get the numbers as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and observe the following losses on train and val:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;model&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;train loss&lt;/th&gt; 
   &lt;th&gt;val loss&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2&lt;/td&gt; 
   &lt;td&gt;124M&lt;/td&gt; 
   &lt;td&gt;3.11&lt;/td&gt; 
   &lt;td&gt;3.12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-medium&lt;/td&gt; 
   &lt;td&gt;350M&lt;/td&gt; 
   &lt;td&gt;2.85&lt;/td&gt; 
   &lt;td&gt;2.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-large&lt;/td&gt; 
   &lt;td&gt;774M&lt;/td&gt; 
   &lt;td&gt;2.66&lt;/td&gt; 
   &lt;td&gt;2.67&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;gpt2-xl&lt;/td&gt; 
   &lt;td&gt;1558M&lt;/td&gt; 
   &lt;td&gt;2.56&lt;/td&gt; 
   &lt;td&gt;2.54&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;However, we have to note that GPT-2 was trained on (closed, never released) WebText, while OpenWebText is just a best-effort open reproduction of this dataset. This means there is a dataset domain gap. Indeed, taking the GPT-2 (124M) checkpoint and finetuning on OWT directly for a while reaches loss down to ~2.85. This then becomes the more appropriate baseline w.r.t. reproduction.&lt;/p&gt; 
&lt;h2&gt;finetuning&lt;/h2&gt; 
&lt;p&gt;Finetuning is no different than training, we just make sure to initialize from a pretrained model and train with a smaller learning rate. For an example of how to finetune a GPT on new text go to &lt;code&gt;data/shakespeare&lt;/code&gt; and run &lt;code&gt;prepare.py&lt;/code&gt; to download the tiny shakespeare dataset and render it into a &lt;code&gt;train.bin&lt;/code&gt; and &lt;code&gt;val.bin&lt;/code&gt;, using the OpenAI BPE tokenizer from GPT-2. Unlike OpenWebText this will run in seconds. Finetuning can take very little time, e.g. on a single GPU just a few minutes. Run an example finetuning like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python train.py config/finetune_shakespeare.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will load the config parameter overrides in &lt;code&gt;config/finetune_shakespeare.py&lt;/code&gt; (I didn't tune them much though). Basically, we initialize from a GPT2 checkpoint with &lt;code&gt;init_from&lt;/code&gt; and train as normal, except shorter and with a small learning rate. If you're running out of memory try decreasing the model size (they are &lt;code&gt;{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}&lt;/code&gt;) or possibly decreasing the &lt;code&gt;block_size&lt;/code&gt; (context length). The best checkpoint (lowest validation loss) will be in the &lt;code&gt;out_dir&lt;/code&gt; directory, e.g. in &lt;code&gt;out-shakespeare&lt;/code&gt; by default, per the config file. You can then run the code in &lt;code&gt;sample.py --out_dir=out-shakespeare&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Whoa there, GPT, entering some dark place over there. I didn't really tune the hyperparameters in the config too much, feel free to try!&lt;/p&gt; 
&lt;h2&gt;sampling / inference&lt;/h2&gt; 
&lt;p&gt;Use the script &lt;code&gt;sample.py&lt;/code&gt; to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. For example, here is a way to sample from the largest available &lt;code&gt;gpt2-xl&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python sample.py \
    --init_from=gpt2-xl \
    --start="What is the answer to life, the universe, and everything?" \
    --num_samples=5 --max_new_tokens=100
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to sample from a model you trained, use the &lt;code&gt;--out_dir&lt;/code&gt; to point the code appropriately. You can also prompt the model with some text from a file, e.g. &lt;code&gt;python sample.py --start=FILE:prompt.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;efficiency notes&lt;/h2&gt; 
&lt;p&gt;For simple model benchmarking and profiling, &lt;code&gt;bench.py&lt;/code&gt; might be useful. It's identical to what happens in the meat of the training loop of &lt;code&gt;train.py&lt;/code&gt;, but omits much of the other complexities.&lt;/p&gt; 
&lt;p&gt;Note that the code by default uses &lt;a href="https://pytorch.org/get-started/pytorch-2.0/"&gt;PyTorch 2.0&lt;/a&gt;. At the time of writing (Dec 29, 2022) this makes &lt;code&gt;torch.compile()&lt;/code&gt; available in the nightly release. The improvement from the one line of code is noticeable, e.g. cutting down iteration time from ~250ms / iter to 135ms / iter. Nice work PyTorch team!&lt;/p&gt; 
&lt;h2&gt;todos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Investigate and add FSDP instead of DDP&lt;/li&gt; 
 &lt;li&gt;Eval zero-shot perplexities on standard evals (e.g. LAMBADA? HELM? etc.)&lt;/li&gt; 
 &lt;li&gt;Finetune the finetuning script, I think the hyperparams are not great&lt;/li&gt; 
 &lt;li&gt;Schedule for linear batch size increase during training&lt;/li&gt; 
 &lt;li&gt;Incorporate other embeddings (rotary, alibi)&lt;/li&gt; 
 &lt;li&gt;Separate out the optim buffers from model params in checkpoints I think&lt;/li&gt; 
 &lt;li&gt;Additional logging around network health (e.g. gradient clip events, magnitudes)&lt;/li&gt; 
 &lt;li&gt;Few more investigations around better init etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;troubleshooting&lt;/h2&gt; 
&lt;p&gt;Note that by default this repo uses PyTorch 2.0 (i.e. &lt;code&gt;torch.compile&lt;/code&gt;). This is fairly new and experimental, and not yet available on all platforms (e.g. Windows). If you're running into related error messages try to disable this by adding &lt;code&gt;--compile=False&lt;/code&gt; flag. This will slow down the code but at least it will run.&lt;/p&gt; 
&lt;p&gt;For some context on this repository, GPT, and language modeling it might be helpful to watch my &lt;a href="https://karpathy.ai/zero-to-hero.html"&gt;Zero To Hero series&lt;/a&gt;. Specifically, the &lt;a href="https://www.youtube.com/watch?v=kCc8FmEb1nY"&gt;GPT video&lt;/a&gt; is popular if you have some prior language modeling context.&lt;/p&gt; 
&lt;p&gt;For more questions/discussions feel free to stop by &lt;strong&gt;#nanoGPT&lt;/strong&gt; on Discord:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/3zy8kqD9Cp"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;acknowledgements&lt;/h2&gt; 
&lt;p&gt;All nanoGPT experiments are powered by GPUs on &lt;a href="https://lambdalabs.com"&gt;Lambda labs&lt;/a&gt;, my favorite Cloud GPU provider. Thank you Lambda labs for sponsoring nanoGPT!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thinking-machines-lab/tinker-cookbook</title>
      <link>https://github.com/thinking-machines-lab/tinker-cookbook</link>
      <description>&lt;p&gt;Post-training with Tinker&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Tinker Cookbook&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/assets/tinker-cover.png" width="60%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;We provide two libraries for the broader community to customize their language models: &lt;code&gt;tinker&lt;/code&gt; and &lt;code&gt;tinker-cookbook&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tinker&lt;/code&gt; is a training SDK for researchers and developers to fine-tune language models. You send API requests to us and we handle the complexities of distributed training.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tinker-cookbook&lt;/code&gt; includes realistic examples of fine-tuning language models. It builds on the Tinker API and provides common abstractions to fine-tune language models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Sign up for Tinker through the &lt;a href="https://thinkingmachines.ai/tinker"&gt;waitlist&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Once you have access, create an API key from the &lt;a href="https://tinker-console.thinkingmachines.ai"&gt;console&lt;/a&gt; and export it as environment variable &lt;code&gt;TINKER_API_KEY&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install tinker python client via &lt;code&gt;pip install tinker&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;We recommend installing &lt;code&gt;tinker-cookbook&lt;/code&gt; in a virtual env either with &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;uv&lt;/code&gt;. For running most examples, you can install via &lt;code&gt;pip install -e .&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Tinker&lt;/h2&gt; 
&lt;p&gt;Refer to the &lt;a href="https://tinker-docs.thinkingmachines.ai/training-sampling"&gt;docs&lt;/a&gt; to start from basics. Here we introduce a few Tinker primitives - the basic components to fine-tune LLMs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;service_client = tinker.ServiceClient()
training_client = service_client.create_lora_training_client(
  base_model="meta-llama/Llama-3.2-1B", rank=32,
)
training_client.forward_backward(...)
training_client.optim_step(...)
training_client.save_state(...)
training_client.load_state(...)

sampling_client = training_client.save_weights_and_get_sampling_client(name="my_model")
sampling_client.sample(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_loop.py"&gt;tinker_cookbook/recipes/sl_loop.py&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_loop.py"&gt;tinker_cookbook/recipes/rl_loop.py&lt;/a&gt; for minimal examples of using these primitives to fine-tune LLMs.&lt;/p&gt; 
&lt;p&gt;To download the weights of any model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;rest_client = service_client.create_rest_client()
future = rest_client.download_checkpoint_archive_from_tinker_path(sampling_client.model_path)
with open(f"model-checkpoint.tar.gz", "wb") as f:
    f.write(future.result())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tinker Cookbook&lt;/h3&gt; 
&lt;p&gt;Besides these primitives, we also offer &lt;strong&gt;Tinker Cookbook&lt;/strong&gt; (a.k.a. this repo), a library of a wide range of abstractions to help you customize training environments. &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/sl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/sl_basic.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/rl_basic.py"&gt;&lt;code&gt;tinker_cookbook/recipes/rl_basic.py&lt;/code&gt;&lt;/a&gt; contain minimal examples to configure supervised learning and reinforcement learning.&lt;/p&gt; 
&lt;p&gt;We also include a wide range of more sophisticated examples in the &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/"&gt;&lt;code&gt;tinker_cookbook/recipes/&lt;/code&gt;&lt;/a&gt; folder:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/chat_sl/"&gt;Chat supervised learning&lt;/a&gt;&lt;/strong&gt;: supervised fine-tuning on conversational datasets like Tulu3.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/math_rl/"&gt;Math reasoning&lt;/a&gt;&lt;/strong&gt;: improve LLM reasoning capability by rewarding it for answering math questions correctly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/preference/"&gt;Preference learning&lt;/a&gt;&lt;/strong&gt;: showcase a three-stage RLHF pipeline: 1) supervised fine-tuning, 2) learning a reward model, 3) RL against the reward model.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/tool_use/"&gt;Tool use&lt;/a&gt;&lt;/strong&gt;: train LLMs to better use retrieval tools to answer questions more accurately.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/prompt_distillation/"&gt;Prompt distillation&lt;/a&gt;&lt;/strong&gt;: internalize long and complex instructions into LLMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/recipes/multiplayer_rl/"&gt;Multi-Agent&lt;/a&gt;&lt;/strong&gt;: optimize LLMs to play against another LLM or themselves.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These examples are located in each subfolder, and their &lt;code&gt;README.md&lt;/code&gt; files will walk you through the key implementation details, the commands to run them, and the expected performance.&lt;/p&gt; 
&lt;h3&gt;Import our utilities&lt;/h3&gt; 
&lt;p&gt;Tinker cookbook includes several utilities. Here's a quick overview:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/renderers.py"&gt;&lt;code&gt;renderers&lt;/code&gt;&lt;/a&gt; converts tokens from/to structured chat message objects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/hyperparam_utils.py"&gt;&lt;code&gt;hyperparam_utils&lt;/code&gt;&lt;/a&gt; helps calculate hyperparameters suitable for LoRAs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/evaluators.py"&gt;&lt;code&gt;evaluation&lt;/code&gt;&lt;/a&gt; provides abstractions for evaluating Tinker models and &lt;a href="https://raw.githubusercontent.com/thinking-machines-lab/tinker-cookbook/main/tinker_cookbook/eval/inspect_evaluators.py"&gt;&lt;code&gt;inspect_evaluation&lt;/code&gt;&lt;/a&gt; shows how to integrate with InspectAI to make evaluating on standard benchmarks easy.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is built in the spirit of open science and collaborative development. We believe that the best tools emerge through community involvement and shared learning.&lt;/p&gt; 
&lt;p&gt;We welcome PR contributions after our private beta is over. If you have any feedback, please email us at &lt;a href="mailto:tinker@thinkingmachines.ai"&gt;tinker@thinkingmachines.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use Tinker for your research, please cite it as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Thinking Machines Lab, 2025. Tinker. https://thinkingmachines.ai/tinker/.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use this BibTeX citation:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{tml2025tinker,
  author = {Thinking Machines Lab},
  title = {Tinker},
  year = {2025},
  url = {https://thinkingmachines.ai/tinker/},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>reflex-dev/reflex</title>
      <link>https://github.com/reflex-dev/reflex</link>
      <description>&lt;p&gt;ğŸ•¸ï¸ Web apps in pure Python ğŸ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex.svg?sanitize=true" alt="Reflex Logo" width="300px" /&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;&lt;strong&gt;âœ¨ Performant, customizable web apps in pure Python. Deploy in seconds. âœ¨&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/reflex"&gt;&lt;img src="https://badge.fury.io/py/reflex.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/reflex.svg?sanitize=true" alt="versions" /&gt; &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;&lt;img src="https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/reflex"&gt;&lt;img src="https://static.pepy.tech/badge/reflex" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;&lt;img src="https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/getreflex"&gt;&lt;img src="https://img.shields.io/twitter/follow/getreflex" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://github.com/reflex-dev/reflex/raw/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_cn/README.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_tw/README.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/tr/README.md"&gt;TÃ¼rkÃ§e&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/in/README.md"&gt;à¤¹à¤¿à¤‚à¤¦à¥€&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pt/pt_br/README.md"&gt;PortuguÃªs (Brasil)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/it/README.md"&gt;Italiano&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/es/README.md"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/kr/README.md"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/ja/README.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/de/README.md"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pe/README.md"&gt;Persian (Ù¾Ø§Ø±Ø³ÛŒ)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/vi/README.md"&gt;Tiáº¿ng Viá»‡t&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ğŸš€ &lt;strong&gt;Try &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt;&lt;/strong&gt; â€“ our AI-powered app builder that generates full-stack Reflex applications in seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;Reflex is a library to build full-stack web apps in pure Python.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pure Python&lt;/strong&gt; - Write your app's frontend and backend all in Python, no need to learn Javascript.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Flexibility&lt;/strong&gt; - Reflex is easy to get started with, but can also scale to complex apps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy Instantly&lt;/strong&gt; - After building, deploy your app with a &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start/"&gt;single command&lt;/a&gt; or host it on your own server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture"&gt;architecture page&lt;/a&gt; to learn how Reflex works under the hood.&lt;/p&gt; 
&lt;h2&gt;âš™ï¸ Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; We strongly recommend using a virtual environment to ensure the &lt;code&gt;reflex&lt;/code&gt; command is available in your PATH.&lt;/p&gt; 
&lt;h2&gt;ğŸ¥³ Create your first app&lt;/h2&gt; 
&lt;h3&gt;1. Create the project directory&lt;/h3&gt; 
&lt;p&gt;Replace &lt;code&gt;my_app_name&lt;/code&gt; with your project name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir my_app_name
cd my_app_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up a virtual environment&lt;/h3&gt; 
&lt;p&gt;Create and activate virtual environment&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows:
python -m venv .venv
.venv\Scripts\activate

# On macOS/Linux:
python3 -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Install Reflex&lt;/h3&gt; 
&lt;p&gt;Reflex is available as a pip package (Requires Python 3.10+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install reflex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Initialize the project&lt;/h3&gt; 
&lt;p&gt;This command initializes a template app in your new directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;reflex init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5. Run the app&lt;/h3&gt; 
&lt;p&gt;You can run this app in development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;reflex run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see your app running at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Reflex has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you installed Reflex without a virtual environment and the &lt;code&gt;reflex&lt;/code&gt; command is not found, you can run commands using: &lt;code&gt;python3 -m reflex init&lt;/code&gt; and &lt;code&gt;python3 -m reflex run&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ«§ Example App&lt;/h2&gt; 
&lt;p&gt;Let's go over an example: creating an image generation UI around &lt;a href="https://platform.openai.com/docs/guides/images/image-generation?context=node"&gt;DALLÂ·E&lt;/a&gt;. For simplicity, we just call the &lt;a href="https://platform.openai.com/docs/api-reference/authentication"&gt;OpenAI API&lt;/a&gt;, but you could replace this with an ML model run locally.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif" alt="A frontend wrapper for DALLÂ·E, shown in the process of generating an image." width="550" /&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    """The app state."""

    prompt = ""
    image_url = ""
    processing = False
    complete = False

    def get_image(self):
        """Get the image from the prompt."""
        if self.prompt == "":
            return rx.window_alert("Prompt Empty")

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size="1024x1024"
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading("DALL-E", font_size="1.5em"),
            rx.input(
                placeholder="Enter a prompt..",
                on_blur=State.set_prompt,
                width="25em",
            ),
            rx.button(
                "Generate Image",
                on_click=State.get_image,
                width="25em",
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width="20em"),
            ),
            align="center",
        ),
        width="100%",
        height="100vh",
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title="Reflex:DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Let's break this down.&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png" alt="Explaining the differences between backend and frontend parts of the DALL-E app." width="900" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;Reflex UI&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Let's start with the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def index():
    return rx.center(
        ...
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; 
&lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; 
&lt;p&gt;Reflex comes with &lt;a href="https://reflex.dev/docs/library"&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, and it's easy to &lt;a href="https://reflex.dev/docs/wrapping-react/overview/"&gt;create your own components&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Reflex represents your UI as a function of your state.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class State(rx.State):
    """The app state."""
    prompt = ""
    image_url = ""
    processing = False
    complete = False

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them.&lt;/p&gt; 
&lt;p&gt;Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;processing&lt;/code&gt; and &lt;code&gt;complete&lt;/code&gt; to indicate when to disable the button (during image generation) and when to show the resulting image.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_image(self):
    """Get the image from the prompt."""
    if self.prompt == "":
        return rx.window_alert("Prompt Empty")

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size="1024x1024"
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; 
&lt;p&gt;Our DALLÂ·E app has an event handler, &lt;code&gt;get_image&lt;/code&gt; which gets this image from the OpenAI API. Using &lt;code&gt;yield&lt;/code&gt; in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Finally, we define our app.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app = rx.App()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app.add_page(index, title="DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create a multi-page app by adding more pages.&lt;/p&gt; 
&lt;h2&gt;ğŸ“‘ Resources&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;ğŸ“‘ &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ—ï¸ &lt;a href="https://reflex.dev/blog"&gt;Blog&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ“± &lt;a href="https://reflex.dev/docs/library"&gt;Component Library&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ–¼ï¸ &lt;a href="https://reflex.dev/templates/"&gt;Templates&lt;/a&gt; &amp;nbsp; | &amp;nbsp; ğŸ›¸ &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start"&gt;Deployment&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;âœ… Status&lt;/h2&gt; 
&lt;p&gt;Reflex launched in December 2022 with the name Pynecone.&lt;/p&gt; 
&lt;p&gt;ğŸš€ Introducing &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt; â€” Our AI-Powered Builder Reflex Build uses AI to generate complete full-stack Python applications. It helps you quickly create, customize, and refine your Reflex apps â€” from frontend components to backend logic â€” so you can focus on your ideas instead of boilerplate code. Whether youâ€™re prototyping or scaling, Reflex Build accelerates development by intelligently scaffolding and optimizing your appâ€™s entire stack.&lt;/p&gt; 
&lt;p&gt;Alongside this, &lt;a href="https://cloud.reflex.dev"&gt;Reflex Cloud&lt;/a&gt; launched in 2025 to offer the best hosting experience for your Reflex apps. Weâ€™re continuously improving the platform with new features and capabilities.&lt;/p&gt; 
&lt;p&gt;Reflex has new releases and features coming every week! Make sure to &lt;span&gt;â­&lt;/span&gt; star and &lt;span&gt;ğŸ‘€&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Reflex community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;Discord&lt;/a&gt; is the best place to get help on your Reflex project and to discuss how you can contribute.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/reflex-dev/reflex/issues"&gt;Issues&lt;/a&gt; are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are actively looking for contributors, no matter your skill level or experience. To contribute check out &lt;a href="https://github.com/reflex-dev/reflex/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;All Thanks To Our Contributors:&lt;/h2&gt; 
&lt;a href="https://github.com/reflex-dev/reflex/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=reflex-dev/reflex" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Reflex is open-source and licensed under the &lt;a href="https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hpcaitech/Open-Sora</title>
      <link>https://github.com/hpcaitech/Open-Sora</link>
      <description>&lt;p&gt;Open-Sora: Democratizing Efficient Video Production for All&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/icon.png" width="250" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/hpcaitech/Open-Sora/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/hpcaitech/Open-Sora?style=social" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2503.09642v1"&gt;&lt;img src="https://img.shields.io/static/v1?label=Tech Report 2.0&amp;amp;message=Arxiv&amp;amp;color=red" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2412.20404"&gt;&lt;img src="https://img.shields.io/static/v1?label=Tech Report 1.2&amp;amp;message=Arxiv&amp;amp;color=red" /&gt;&lt;/a&gt; 
 &lt;a href="https://hpcaitech.github.io/Open-Sora/"&gt;&lt;img src="https://img.shields.io/badge/Gallery-View-orange?logo=&amp;amp;" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://discord.gg/kZakZzrSUT"&gt;&lt;img src="https://img.shields.io/badge/Discord-join-blueviolet?logo=discord&amp;amp;" /&gt;&lt;/a&gt; 
 &lt;a href="https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-247ipg9fk-KRRYmUl~u2ll2637WRURVA"&gt;&lt;img src="https://img.shields.io/badge/Slack-ColossalAI-blueviolet?logo=slack&amp;amp;" /&gt;&lt;/a&gt; 
 &lt;a href="https://x.com/YangYou1991/status/1899973689460044010"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Discuss-blue?logo=twitter&amp;amp;" /&gt;&lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png"&gt;&lt;img src="https://img.shields.io/badge/å¾®ä¿¡-å°åŠ©æ‰‹åŠ ç¾¤-green?logo=wechat&amp;amp;" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Open-Sora: Democratizing Efficient Video Production for All&lt;/h2&gt; 
&lt;p&gt;We design and implement &lt;strong&gt;Open-Sora&lt;/strong&gt;, an initiative dedicated to &lt;strong&gt;efficiently&lt;/strong&gt; producing high-quality video. We hope to make the model, tools and all details accessible to all. By embracing &lt;strong&gt;open-source&lt;/strong&gt; principles, Open-Sora not only democratizes access to advanced video generation techniques, but also offers a streamlined and user-friendly platform that simplifies the complexities of video generation. With Open-Sora, our goal is to foster innovation, creativity, and inclusivity within the field of content creation.&lt;/p&gt; 
&lt;p&gt;ğŸ¬ For a professional AI video-generation product, try &lt;a href="https://video-ocean.com/"&gt;Video Ocean&lt;/a&gt; â€” powered by a superior model.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://video-ocean.com/"&gt; &lt;img src="https://github.com/hpcaitech/public_assets/raw/main/colossalai/img/3.gif" width="850" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://hpc-ai.com/?utm_source=github&amp;amp;utm_medium=social&amp;amp;utm_campaign=promotion-opensora"&gt; &lt;img src="https://github.com/hpcaitech/public_assets/raw/main/colossalai/img/1.gif" width="850" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;!-- [[ä¸­æ–‡æ–‡æ¡£](/docs/zh_CN/README.md)] [[æ½æ™¨äº‘](https://cloud.luchentech.com/)|[OpenSoraé•œåƒ](https://cloud.luchentech.com/doc/docs/image/open-sora/)|[è§†é¢‘æ•™ç¨‹](https://www.bilibili.com/video/BV1ow4m1e7PX/?vd_source=c6b752764cd36ff0e535a768e35d98d2)] --&gt; 
&lt;h2&gt;ğŸ“° News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2025.03.12]&lt;/strong&gt; ğŸ”¥ We released &lt;strong&gt;Open-Sora 2.0&lt;/strong&gt; (11B). ğŸ¬ 11B model achieves &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/#evaluation"&gt;on-par performance&lt;/a&gt; with 11B HunyuanVideo &amp;amp; 30B Step-Video on ğŸ“VBench &amp;amp; ğŸ“ŠHuman Preference. ğŸ› ï¸ Fully open-source: checkpoints and training codes for training with only &lt;strong&gt;$200K&lt;/strong&gt;. &lt;a href="https://arxiv.org/abs/2503.09642v1"&gt;[report]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025.02.20]&lt;/strong&gt; ğŸ”¥ We released &lt;strong&gt;Open-Sora 1.3&lt;/strong&gt; (1B). With the upgraded VAE and Transformer architecture, the quality of our generated videos has been greatly improved ğŸš€. &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/#open-sora-13-model-weights"&gt;[checkpoints]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_04.md"&gt;[report]&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/hpcai-tech/open-sora"&gt;[demo]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.12.23]&lt;/strong&gt; The development cost of video generation models has saved by 50%! Open-source solutions are now available with H200 GPU vouchers. &lt;a href="https://company.hpc-ai.com/blog/the-development-cost-of-video-generation-models-has-saved-by-50-open-source-solutions-are-now-available-with-h200-gpu-vouchers"&gt;[blog]&lt;/a&gt; &lt;a href="https://github.com/hpcaitech/Open-Sora/raw/main/scripts/train.py"&gt;[code]&lt;/a&gt; &lt;a href="https://colossalai.org/zh-Hans/docs/get_started/bonus/"&gt;[vouchers]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.06.17]&lt;/strong&gt; We released &lt;strong&gt;Open-Sora 1.2&lt;/strong&gt;, which includes &lt;strong&gt;3D-VAE&lt;/strong&gt;, &lt;strong&gt;rectified flow&lt;/strong&gt;, and &lt;strong&gt;score condition&lt;/strong&gt;. The video quality is greatly improved. &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/#open-sora-12-model-weights"&gt;[checkpoints]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_03.md"&gt;[report]&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2412.20404"&gt;[arxiv]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.04.25]&lt;/strong&gt; ğŸ¤— We released the &lt;a href="https://huggingface.co/spaces/hpcai-tech/open-sora"&gt;Gradio demo for Open-Sora&lt;/a&gt; on Hugging Face Spaces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.04.25]&lt;/strong&gt; We released &lt;strong&gt;Open-Sora 1.1&lt;/strong&gt;, which supports &lt;strong&gt;2s~15s, 144p to 720p, any aspect ratio&lt;/strong&gt; text-to-image, &lt;strong&gt;text-to-video, image-to-video, video-to-video, infinite time&lt;/strong&gt; generation. In addition, a full video processing pipeline is released. &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/#open-sora-11-model-weights"&gt;[checkpoints]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_02.md"&gt;[report]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.03.18]&lt;/strong&gt; We released &lt;strong&gt;Open-Sora 1.0&lt;/strong&gt;, a fully open-source project for video generation. Open-Sora 1.0 supports a full pipeline of video data preprocessing, training with &lt;a href="https://github.com/hpcaitech/ColossalAI"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/colossal_ai.png" width="8%" /&gt;&lt;/a&gt; acceleration, inference, and more. Our model can produce 2s 512x512 videos with only 3 days training. &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/#open-sora-10-model-weights"&gt;[checkpoints]&lt;/a&gt; &lt;a href="https://hpc-ai.com/blog/open-sora-v1.0"&gt;[blog]&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_01.md"&gt;[report]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2024.03.04]&lt;/strong&gt; Open-Sora provides training with 46% cost reduction. &lt;a href="https://hpc-ai.com/blog/open-sora"&gt;[blog]&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ“ Since Open-Sora is under active development, we remain different branches for different versions. The latest version is &lt;a href="https://github.com/hpcaitech/Open-Sora"&gt;main&lt;/a&gt;. Old versions include: &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.0"&gt;v1.0&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.1"&gt;v1.1&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.2"&gt;v1.2&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.3"&gt;v1.3&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¥ Latest Demo&lt;/h2&gt; 
&lt;p&gt;Demos are presented in compressed GIF format for convenience. For original quality samples and their corresponding prompts, please visit our &lt;a href="https://hpcaitech.github.io/Open-Sora/"&gt;Gallery&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;5s 1024Ã—576&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;5s 576Ã—1024&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;5s 576Ã—1024&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/8g9y9h?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0001_1_1.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/k50mnv?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0160.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/bzrn9n?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0017.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/dsv8da?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0012_1_1.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/3wif07?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/douyin_0005.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/us2w7h?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0037.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/yfwk8i?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0055_1_1.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/jgjil0?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/sora_0019.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://streamable.com/e/lsoai1?autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0463.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenSora 1.3 Demo&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;5s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;5s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;5s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/r0imrp?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_tomato.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/hfvjkh?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_fisherman.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/kutmma?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_girl2.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/osn1la?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_grape.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/l1pzws?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_mushroom.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/2vqari?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_parrot.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/1in7d6?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_trans.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/e9bi4o?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_bear.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/09z7xi?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_futureflower.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/16c3hk?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_fire.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/wi250w?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_man.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://streamable.com/e/vw5b64?quality=highest&amp;amp;autoplay=1"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_black.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenSora 1.2 Demo&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;4s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;4s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;4s 720Ã—1280&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/7895aab6-ed23-488c-8486-091480c26327"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0013.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/20f07c7b-182b-4562-bbee-f1df74c86c9a"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_1718.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/3d897e0d-dc21-453a-b911-b3bda838acc2"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0087.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/644bf938-96ce-44aa-b797-b3c0b513d64c"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0052.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/272d88ac-4b4a-484d-a665-8d07431671d0"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_1719.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/ebbac621-c34e-4bb4-9543-1c34f8989764"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0002.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/a1e3a1a3-4abd-45f5-8df2-6cced69da4ca"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0011.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/d6ce9c13-28e1-4dff-9644-cc01f5f11926"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0004.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/561978f8-f1b0-4f4d-ae7b-45bec9001b4a"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0061.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenSora 1.1 Demo&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;2s 240Ã—426&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;2s 240Ã—426&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c31ebc52-de39-4a4e-9b1e-9211d45e05b2"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16x240x426_9.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c31ebc52-de39-4a4e-9b1e-9211d45e05b2"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_26.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/f7ce4aaa-528f-40a8-be7a-72e61eaacbbd"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_27.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/5d58d71e-1fda-4d90-9ad3-5f2f7b75c6a9"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_40.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;2s 426Ã—240&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;4s 480Ã—854&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/34ecb4a0-4eef-4286-ad4c-8e3a87e5a9fd"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x426x240_24.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c1619333-25d7-42ba-a91c-18dbc1870b18"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_32x480x854_9.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;16s 320Ã—320&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;16s 224Ã—448&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;2s 426Ã—240&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/3cab536e-9b43-4b33-8da8-a0f9cf842ff2"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16s_320x320.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/9fb0b9e0-c6f4-4935-b29e-4cac10b373c4"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16s_224x448.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/3e892ad2-9543-4049-b005-643a4c1bf3bf"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x426x240_3.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenSora 1.0 Demo&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;strong&gt;2s 512Ã—512&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;2s 512Ã—512&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;2s 512Ã—512&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/de1963d3-b43b-4e68-a670-bb821ebb6f80"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_0.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/13f8338f-3d42-4b71-8142-d234fbd746cc"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_1.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/fa6a65a6-e32a-4d64-9a9e-eabb0ebb8c16"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_2.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;A serene night scene in a forested area. [...] The video is a time-lapse, capturing the transition from day to night, with the lake and forest serving as a constant backdrop.&lt;/td&gt; 
    &lt;td&gt;A soaring drone footage captures the majestic beauty of a coastal cliff, [...] The water gently laps at the rock base and the greenery that clings to the top of the cliff.&lt;/td&gt; 
    &lt;td&gt;The majestic beauty of a waterfall cascading down a cliff into a serene lake. [...] The camera angle provides a bird's eye view of the waterfall.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/64232f84-1b36-4750-a6c0-3e610fa9aa94"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_3.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/983a1965-a374-41a7-a76b-c07941a6c1e9"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_4.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hpcaitech/Open-Sora/assets/99191637/ec10c879-9767-4c31-865f-2e8d6cf11e65"&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_5.gif" width="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;A bustling city street at night, filled with the glow of car headlights and the ambient light of streetlights. [...]&lt;/td&gt; 
    &lt;td&gt;The vibrant beauty of a sunflower field. The sunflowers are arranged in neat rows, creating a sense of order and symmetry. [...]&lt;/td&gt; 
    &lt;td&gt;A serene underwater scene featuring a sea turtle swimming through a coral reef. The turtle, with its greenish-brown shell [...]&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;Videos are downsampled to &lt;code&gt;.gif&lt;/code&gt; for display. Click for original videos. Prompts are trimmed for display, see &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/assets/texts/t2v_samples.txt"&gt;here&lt;/a&gt; for full prompts.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ”† Reports&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2503.09642v1"&gt;Tech Report of Open-Sora 2.0&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/train.md"&gt;Step by step to train or finetune your own model&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/ae.md"&gt;Step by step to train and evaluate an video autoencoder&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/hcae.md"&gt;Visit the high compression video autoencoder&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Reports of previous version (better see in according branch): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_04.md"&gt;Open-Sora 1.3&lt;/a&gt;: shift-window attention, unified spatial-temporal VAE, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_03.md"&gt;Open-Sora 1.2&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2412.20404"&gt;Tech Report&lt;/a&gt;: rectified flow, 3d-VAE, score condition, evaluation, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_02.md"&gt;Open-Sora 1.1&lt;/a&gt;: multi-resolution/length/aspect-ratio, image/video conditioning/editing, data preprocessing, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/docs/report_01.md"&gt;Open-Sora 1.0&lt;/a&gt;: architecture, captioning, etc.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ“ Since Open-Sora is under active development, we remain different branches for different versions. The latest version is &lt;a href="https://github.com/hpcaitech/Open-Sora"&gt;main&lt;/a&gt;. Old versions include: &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.0"&gt;v1.0&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.1"&gt;v1.1&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.2"&gt;v1.2&lt;/a&gt;, &lt;a href="https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.3"&gt;v1.3&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# create a virtual env and activate (conda as an example)
conda create -n opensora python=3.10
conda activate opensora

# download the repo
git clone https://github.com/hpcaitech/Open-Sora
cd Open-Sora

# Ensure torch &amp;gt;= 2.4.0
pip install -v . # for development mode, `pip install -v -e .`
pip install xformers==0.0.27.post2 --index-url https://download.pytorch.org/whl/cu121 # install xformers according to your cuda version
pip install flash-attn --no-build-isolation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, you can install flash attention 3 for faster speed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Dao-AILab/flash-attention # 4f0640d5
cd flash-attention/hopper
python setup.py install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Model Download&lt;/h3&gt; 
&lt;p&gt;Our 11B model supports 256px and 768px resolution. Both T2V and I2V are supported by one model. ğŸ¤— &lt;a href="https://huggingface.co/hpcai-tech/Open-Sora-v2"&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href="https://modelscope.cn/models/luchentech/Open-Sora-v2"&gt;ModelScope&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Download from huggingface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "huggingface_hub[cli]"
huggingface-cli download hpcai-tech/Open-Sora-v2 --local-dir ./ckpts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download from ModelScope:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install modelscope
modelscope download hpcai-tech/Open-Sora-v2 --local_dir ./ckpts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Text-to-Video Generation&lt;/h3&gt; 
&lt;p&gt;Our model is optimized for image-to-video generation, but it can also be used for text-to-video generation. To generate high quality videos, with the help of flux text-to-image model, we build a text-to-image-to-video pipeline. For 256x256 resolution:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Generate one given prompt
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea"

# Save memory with offloading
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --offload True

# Generation with csv
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --dataset.data-path assets/texts/example.csv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For 768x768 resolution:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One GPU
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_768px.py --save-dir samples --prompt "raining, sea"

# Multi-GPU with colossalai sp
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_768px.py --save-dir samples --prompt "raining, sea"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can adjust the generation aspect ratio by &lt;code&gt;--aspect_ratio&lt;/code&gt; and the generation length by &lt;code&gt;--num_frames&lt;/code&gt;. Candidate values for aspect_ratio includes &lt;code&gt;16:9&lt;/code&gt;, &lt;code&gt;9:16&lt;/code&gt;, &lt;code&gt;1:1&lt;/code&gt;, &lt;code&gt;2.39:1&lt;/code&gt;. Candidate values for num_frames should be &lt;code&gt;4k+1&lt;/code&gt; and less than 129.&lt;/p&gt; 
&lt;p&gt;You can also run direct text-to-video by:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One GPU for 256px
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --prompt "raining, sea"
# Multi-GPU for 768px
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/768px.py --prompt "raining, sea"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Image-to-Video Generation&lt;/h3&gt; 
&lt;p&gt;Given a prompt and a reference image, you can generate a video with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 256px
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --cond_type i2v_head --prompt "A plump pig wallows in a muddy pond on a rustic farm, its pink snout poking out as it snorts contentedly. The camera captures the pig's playful splashes, sending ripples through the water under the midday sun. Wooden fences and a red barn stand in the background, framed by rolling green hills. The pig's muddy coat glistens in the sunlight, showcasing the simple pleasures of its carefree life." --ref assets/texts/i2v.png

# 256px with csv
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --cond_type i2v_head --dataset.data-path assets/texts/i2v.csv

# Multi-GPU 768px
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/768px.py --cond_type i2v_head --dataset.data-path assets/texts/i2v.csv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Motion Score&lt;/h3&gt; 
&lt;p&gt;During training, we provide motion score into the text prompt. During inference, you can use the following command to generate videos with motion score (the default score is 4):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --motion-score 4
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We also provide a dynamic motion score evaluator. After setting your OpenAI API key, you can use the following command to evaluate the motion score of a video:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --motion-score dynamic
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Score&lt;/th&gt; 
   &lt;th&gt;1&lt;/th&gt; 
   &lt;th&gt;4&lt;/th&gt; 
   &lt;th&gt;7&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_1.gif" width="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_4.gif" width="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_7.gif" width="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Prompt Refine&lt;/h3&gt; 
&lt;p&gt;We take advantage of ChatGPT to refine the prompt. You can use the following command to refine the prompt. The function is available for both text-to-video and image-to-video generation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=sk-xxxx
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --refine-prompt True
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reproductivity&lt;/h3&gt; 
&lt;p&gt;To make the results reproducible, you can set the random seed by:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --sampling_option.seed 42 --seed 42
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;--num-sample k&lt;/code&gt; to generate &lt;code&gt;k&lt;/code&gt; samples for each prompt.&lt;/p&gt; 
&lt;h2&gt;Computational Efficiency&lt;/h2&gt; 
&lt;p&gt;We test the computational efficiency of text-to-video on H100/H800 GPU. For 256x256, we use colossalai's tensor parallelism, and &lt;code&gt;--offload True&lt;/code&gt; is used. For 768x768, we use colossalai's sequence parallelism. All use number of steps 50. The results are presented in the format: $\color{blue}{\text{Total time (s)}}/\color{red}{\text{peak GPU memory (GB)}}$&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Resolution&lt;/th&gt; 
   &lt;th&gt;1x GPU&lt;/th&gt; 
   &lt;th&gt;2x GPUs&lt;/th&gt; 
   &lt;th&gt;4x GPUs&lt;/th&gt; 
   &lt;th&gt;8x GPUs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;256x256&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{60}/\color{red}{52.5}$&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{40}/\color{red}{44.3}$&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{34}/\color{red}{44.3}$&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;768x768&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{1656}/\color{red}{60.3}$&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{863}/\color{red}{48.3}$&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{466}/\color{red}{44.3}$&lt;/td&gt; 
   &lt;td&gt;$\color{blue}{276}/\color{red}{44.3}$&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Evaluation&lt;/h2&gt; 
&lt;p&gt;On &lt;a href="https://huggingface.co/spaces/Vchitect/VBench_Leaderboard"&gt;VBench&lt;/a&gt;, Open-Sora 2.0 significantly narrows the gap with OpenAIâ€™s Sora, reducing it from 4.52% â†’ 0.69% compared to Open-Sora 1.2.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_vbench.png" alt="VBench" /&gt;&lt;/p&gt; 
&lt;p&gt;Human preference results show our model is on par with HunyuanVideo 11B and Step-Video 30B.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_winrate.png" alt="Win Rate" /&gt;&lt;/p&gt; 
&lt;p&gt;With strong performance, Open-Sora 2.0 is cost-effective.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_cost.png" alt="Cost" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Thanks goes to these wonderful contributors:&lt;/p&gt; 
&lt;a href="https://github.com/hpcaitech/Open-Sora/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=hpcaitech/Open-Sora" /&gt; &lt;/a&gt; 
&lt;p&gt;If you wish to contribute to this project, please refer to the &lt;a href="https://raw.githubusercontent.com/hpcaitech/Open-Sora/main/CONTRIBUTING.md"&gt;Contribution Guideline&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;Here we only list a few of the projects. For other works and datasets, please refer to our report.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hpcaitech/ColossalAI"&gt;ColossalAI&lt;/a&gt;: A powerful large model parallel acceleration and optimization system.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookresearch/DiT"&gt;DiT&lt;/a&gt;: Scalable Diffusion Models with Transformers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NUS-HPC-AI-Lab/OpenDiT"&gt;OpenDiT&lt;/a&gt;: An acceleration for DiT training. We adopt valuable acceleration strategies for training progress from OpenDiT.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PixArt-alpha/PixArt-alpha"&gt;PixArt&lt;/a&gt;: An open-source DiT-based text-to-image model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/black-forest-labs/flux"&gt;Flux&lt;/a&gt;: A powerful text-to-image generation model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Vchitect/Latte"&gt;Latte&lt;/a&gt;: An attempt to efficiently train DiT for video.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tencent/HunyuanVideo/tree/main?tab=readme-ov-file"&gt;HunyuanVideo&lt;/a&gt;: Open-Source text-to-video model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/stabilityai/sd-vae-ft-mse-original"&gt;StabilityAI VAE&lt;/a&gt;: A powerful image VAE model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mit-han-lab/efficientvit"&gt;DC-AE&lt;/a&gt;: Deep Compression AutoEncoder for image compression.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openai/CLIP"&gt;CLIP&lt;/a&gt;: A powerful text-image embedding model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google-research/text-to-text-transfer-transformer"&gt;T5&lt;/a&gt;: A powerful text encoder.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/haotian-liu/LLaVA"&gt;LLaVA&lt;/a&gt;: A powerful image captioning model based on &lt;a href="https://huggingface.co/mistralai/Mistral-7B-v0.1"&gt;Mistral-7B&lt;/a&gt; and &lt;a href="https://huggingface.co/01-ai/Yi-34B"&gt;Yi-34B&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/magic-research/PLLaVA"&gt;PLLaVA&lt;/a&gt;: A powerful video captioning model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mira-space/MiraData"&gt;MiraData&lt;/a&gt;: A large-scale video dataset with long durations and structured caption.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{opensora,
  title={Open-sora: Democratizing efficient video production for all},
  author={Zheng, Zangwei and Peng, Xiangyu and Yang, Tianji and Shen, Chenhui and Li, Shenggui and Liu, Hongxin and Zhou, Yukun and Li, Tianyi and You, Yang},
  journal={arXiv preprint arXiv:2412.20404},
  year={2024}
}

@article{opensora2,
    title={Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k}, 
    author={Xiangyu Peng and Zangwei Zheng and Chenhui Shen and Tom Young and Xinying Guo and Binluo Wang and Hang Xu and Hongxin Liu and Mingyan Jiang and Wenjun Li and Yuhui Wang and Anbang Ye and Gang Ren and Qianran Ma and Wanying Liang and Xiang Lian and Xiwen Wu and Yuting Zhong and Zhuangyan Li and Chaoyu Gong and Guojun Lei and Leijun Cheng and Limin Zhang and Minghao Li and Ruijie Zhang and Silan Hu and Shijie Huang and Xiaokang Wang and Yuanheng Zhao and Yuqi Wang and Ziang Wei and Yang You},
    year={2025},
    journal={arXiv preprint arXiv:2503.09642},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#hpcaitech/Open-Sora&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=hpcaitech/Open-Sora&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;ğŸ¯ å‘Šåˆ«ä¿¡æ¯è¿‡è½½ï¼ŒAI åŠ©ä½ çœ‹æ‡‚æ–°é—»èµ„è®¯çƒ­ç‚¹ï¼Œç®€å•çš„èˆ†æƒ…ç›‘æ§åˆ†æ - å¤šå¹³å°çƒ­ç‚¹èšåˆ+åŸºäº MCP çš„AIåˆ†æå·¥å…·ã€‚ç›‘æ§35ä¸ªå¹³å°ï¼ˆæŠ–éŸ³ã€çŸ¥ä¹ã€Bç«™ã€åå°”è¡—è§é—»ã€è´¢è”ç¤¾ç­‰ï¼‰ï¼Œæ™ºèƒ½ç­›é€‰+è‡ªåŠ¨æ¨é€+AIå¯¹è¯åˆ†æï¼ˆç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»ï¼šè¶‹åŠ¿è¿½è¸ªã€æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ£€ç´¢ç­‰13ç§å·¥å…·ï¼‰ã€‚æ”¯æŒä¼ä¸šå¾®ä¿¡/é£ä¹¦/é’‰é’‰/Telegram/é‚®ä»¶/ntfyæ¨é€ï¼Œ30ç§’ç½‘é¡µéƒ¨ç½²ï¼Œ1åˆ†é’Ÿæ‰‹æœºé€šçŸ¥ï¼Œæ— éœ€ç¼–ç¨‹ã€‚æ”¯æŒDockeréƒ¨ç½²â­ è®©ç®—æ³•ä¸ºä½ æœåŠ¡ï¼Œç”¨AIç†è§£çƒ­ç‚¹&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="trendradar"&gt; 
 &lt;a href="https://github.com/sansan0/TrendRadar" title="TrendRadar"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner.jpg" alt="TrendRadar Banner" width="50%" /&gt; &lt;/a&gt; 
 &lt;p&gt;ğŸš€ æœ€å¿«&lt;strong&gt;30ç§’&lt;/strong&gt;éƒ¨ç½²çš„çƒ­ç‚¹åŠ©æ‰‹ â€”â€” å‘Šåˆ«æ— æ•ˆåˆ·å±ï¼Œåªçœ‹çœŸæ­£å…³å¿ƒçš„æ–°é—»èµ„è®¯&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14726" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14726" alt="sansan0%2FTrendRadar | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=yellow" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/version-v3.0.5-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/MCP-v1.0.1-green.svg?sanitize=true" alt="MCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://work.weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ä¼ä¸šå¾®ä¿¡é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://telegram.org/"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="Telegramé€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/%E9%92%89%E9%92%89-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="dingtalké€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://www.feishu.cn/"&gt;&lt;img src="https://img.shields.io/badge/%E9%A3%9E%E4%B9%A6-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é£ä¹¦é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/Email-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="é‚®ä»¶é€šçŸ¥" /&gt;&lt;/a&gt; &lt;a href="https://github.com/binwiederhier/ntfy"&gt;&lt;img src="https://img.shields.io/badge/ntfy-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ntfyé€šçŸ¥" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Actions-%E8%87%AA%E5%8A%A8%E5%8C%96-2088FF?style=flat-square&amp;amp;logo=github-actions&amp;amp;logoColor=white" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://sansan0.github.io/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Pages-%E9%83%A8%E7%BD%B2-4285F4?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Pages" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/wantcat/trendradar"&gt;&lt;img src="https://img.shields.io/badge/Docker-%E9%83%A8%E7%BD%B2-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io/"&gt;&lt;img src="https://img.shields.io/badge/MCP-AI%E5%88%86%E6%9E%90%E6%94%AF%E6%8C%81-FF6B6B?style=flat-square&amp;amp;logo=ai&amp;amp;logoColor=white" alt="MCP Support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä»¥è½»é‡ï¼Œæ˜“éƒ¨ç½²ä¸ºç›®æ ‡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ“‘ å¿«é€Ÿå¯¼èˆª&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"&gt;ğŸ¯ æ ¸å¿ƒåŠŸèƒ½&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Dockeréƒ¨ç½²&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E9%83%A8%E7%BD%B2"&gt;ğŸ¤– AIåˆ†æä¸“åŒº&lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-mcp-%E5%AE%A2%E6%88%B7%E7%AB%AF"&gt;ğŸ”Œ MCPå®¢æˆ·ç«¯&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;â“ ç­”ç–‘ä¸å¸¸è§é—®é¢˜&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3"&gt;â­ é¡¹ç›®ç›¸å…³&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;è€å¿ƒåé¦ˆ bug&lt;/strong&gt; çš„è´¡çŒ®è€…ï¼Œä½ ä»¬çš„æ¯ä¸€æ¡åé¦ˆè®©é¡¹ç›®æ›´åŠ å®Œå–„ğŸ˜‰;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;ä¸ºé¡¹ç›®ç‚¹ star&lt;/strong&gt; çš„è§‚ä¼—ä»¬ï¼Œ&lt;strong&gt;fork&lt;/strong&gt; ä½ æ‰€æ¬²ä¹Ÿï¼Œ&lt;strong&gt;star&lt;/strong&gt; æˆ‘æ‰€æ¬²ä¹Ÿï¼Œä¸¤è€…å¾—å…¼ğŸ˜æ˜¯å¯¹å¼€æºç²¾ç¥æœ€å¥½çš„æ”¯æŒ;&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢&lt;strong&gt;å…³æ³¨&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;å…¬ä¼—å·&lt;/a&gt;&lt;/strong&gt; çš„è¯»è€…ä»¬ï¼Œä½ ä»¬çš„ç•™è¨€ã€ç‚¹èµã€åˆ†äº«å’Œæ¨èç­‰ç§¯æäº’åŠ¨è®©å†…å®¹æ›´æœ‰æ¸©åº¦ğŸ˜ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ ç‚¹å‡»æŸ¥çœ‹&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt; (å½“å‰ &lt;strong&gt;ğŸ”¥59ğŸ”¥&lt;/strong&gt; ä½)&lt;/summary&gt; 
 &lt;h3&gt;æ•°æ®æ”¯æŒ&lt;/h3&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®ä½¿ç”¨äº† &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; é¡¹ç›®æä¾›çš„ API æ¥å£è·å–å¤šå¹³å°æ•°æ®&lt;/p&gt; 
 &lt;h3&gt;æ¨å¹¿åŠ©åŠ›&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹å¹³å°å’Œä¸ªäººçš„æ¨è(æŒ‰æ—¶é—´æ’åˆ—)&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA"&gt;å°ä¼—è½¯ä»¶&lt;/a&gt; - å¼€æºè½¯ä»¶æ¨èå¹³å°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://linux.do/"&gt;LinuxDo ç¤¾åŒº&lt;/a&gt; - æŠ€æœ¯çˆ±å¥½è€…çš„èšé›†åœ°&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ruanyf/weekly"&gt;é˜®ä¸€å³°å‘¨åˆŠ&lt;/a&gt; - æŠ€æœ¯åœˆæœ‰å½±å“åŠ›çš„å‘¨åˆŠ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;è§‚ä¼—æ”¯æŒ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢&lt;strong&gt;ç»™äºˆèµ„é‡‘æ”¯æŒ&lt;/strong&gt; çš„æœ‹å‹ä»¬,ä½ ä»¬çš„æ…·æ…¨å·²åŒ–èº«ä¸ºé”®ç›˜æ—çš„é›¶é£Ÿé¥®æ–™,é™ªä¼´ç€é¡¹ç›®çš„æ¯ä¸€æ¬¡è¿­ä»£&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;ç‚¹èµäºº&lt;/th&gt; 
    &lt;th align="center"&gt;é‡‘é¢&lt;/th&gt; 
    &lt;th align="center"&gt;æ—¥æœŸ&lt;/th&gt; 
    &lt;th align="center"&gt;å¤‡æ³¨&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å‡¯&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;å¯¹*.&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;Thanks for your TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;s*y&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**ç¿”&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;å¥½é¡¹ç›®ï¼Œç›¸è§æ¨æ™šï¼Œæ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*éŸ¦&lt;/td&gt; 
    &lt;td align="center"&gt;9.9&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.13&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadarè¶…èµï¼Œè¯·è€å¸ˆå–å’–å•¡~&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;h*p&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸­å›½å¼€æºåŠ›é‡ï¼ŒåŠ æ²¹ï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;c*r&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;a*n&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;ã€‚*c&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.12&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºåˆ†äº«&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.11&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸»&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*äº†&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.09&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.08&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ç‚¹&lt;/td&gt; 
    &lt;td align="center"&gt;8.80&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;å¼€å‘ä¸æ˜“ï¼Œæ”¯æŒä¸€ä¸‹ã€‚&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Q*Q&lt;/td&gt; 
    &lt;td align="center"&gt;6.66&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æºï¼&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;C*e&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.05&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Peter Fan&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.29&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.27&lt;/td&gt; 
    &lt;td align="center"&gt;æ„Ÿè°¢å¼€æº&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®¸&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.23&lt;/td&gt; 
    &lt;td align="center"&gt;è€å¸ˆ å°ç™½ä¸€æšï¼Œæ‘¸äº†å‡ å¤©äº†è¿˜æ²¡æ•´èµ·æ¥ï¼Œæ±‚æ•™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Eason&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.22&lt;/td&gt; 
    &lt;td align="center"&gt;è¿˜æ²¡æ•´æ˜ç™½ï¼Œä½†ä½ åœ¨åšå¥½äº‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¾&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.18&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å¿—&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ˜€&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ°&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å•¸&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*çºª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*d&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;è°¢è°¢ä½ çš„å·¥å…·ï¼Œå¾ˆå¥½ç©...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*H&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;é‚£*O&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*åœ†&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*g&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Ocean&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.12&lt;/td&gt; 
    &lt;td align="center"&gt;...çœŸçš„å¤ªæ£’äº†ï¼ï¼ï¼å°ç™½çº§åˆ«ä¹Ÿèƒ½ç›´æ¥ç”¨...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**åŸ¹&lt;/td&gt; 
    &lt;td align="center"&gt;5.2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.2&lt;/td&gt; 
    &lt;td align="center"&gt;github-yzyf1312:å¼€æºä¸‡å²&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¤¿&lt;/td&gt; 
    &lt;td align="center"&gt;3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.23&lt;/td&gt; 
    &lt;td align="center"&gt;åŠ æ²¹ï¼Œå¾ˆä¸é”™&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ğŸ&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.21&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;E*f&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è®°&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;z*u&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**æ˜Š&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å·&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;T*T&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*å®¶&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*X&lt;/td&gt; 
    &lt;td align="center"&gt;1.11&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.3&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é£™&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.31&lt;/td&gt; 
    &lt;td align="center"&gt;æ¥è‡ªè€ç«¥è°¢è°¢&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¸‹&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸‹åˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ä¸Šåˆ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;S*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.05&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ä¾ &lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.04&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;x*x&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.03&lt;/td&gt; 
    &lt;td align="center"&gt;trendRadar å¥½é¡¹ç›® ç‚¹èµ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*è¿œ&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*é‚ª&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*æ¢¦&lt;/td&gt; 
    &lt;td align="center"&gt;0.1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**é¾™&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.29&lt;/td&gt; 
    &lt;td align="center"&gt;æ”¯æŒä¸€ä¸‹&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;âœ¨ æ ¸å¿ƒåŠŸèƒ½&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;å…¨ç½‘çƒ­ç‚¹èšåˆ&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;çŸ¥ä¹&lt;/li&gt; 
 &lt;li&gt;æŠ–éŸ³&lt;/li&gt; 
 &lt;li&gt;bilibili çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;åå°”è¡—è§é—»&lt;/li&gt; 
 &lt;li&gt;è´´å§&lt;/li&gt; 
 &lt;li&gt;ç™¾åº¦çƒ­æœ&lt;/li&gt; 
 &lt;li&gt;è´¢è”ç¤¾çƒ­é—¨&lt;/li&gt; 
 &lt;li&gt;æ¾æ¹ƒæ–°é—»&lt;/li&gt; 
 &lt;li&gt;å‡¤å‡°ç½‘&lt;/li&gt; 
 &lt;li&gt;ä»Šæ—¥å¤´æ¡&lt;/li&gt; 
 &lt;li&gt;å¾®åš&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;é»˜è®¤ç›‘æ§ 11 ä¸ªä¸»æµå¹³å°ï¼Œä¹Ÿå¯è‡ªè¡Œå¢åŠ é¢å¤–çš„å¹³å°&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ è‡ªå®šä¹‰ç›‘æ§å¹³å°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;æœ¬é¡¹ç›®çš„èµ„è®¯æ•°æ®æ¥æºäº &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; ï¼Œä½ å¯ä»¥ç‚¹å‡»&lt;a href="https://newsnow.busiyi.world/"&gt;ç½‘ç«™&lt;/a&gt;ï¼Œç‚¹å‡»[æ›´å¤š]ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰ä½ æƒ³è¦çš„å¹³å°ã€‚&lt;/p&gt; 
 &lt;p&gt;å…·ä½“æ·»åŠ å¯è®¿é—® &lt;a href="https://github.com/ourongxing/newsnow/tree/main/server/sources"&gt;é¡¹ç›®æºä»£ç &lt;/a&gt;ï¼Œæ ¹æ®é‡Œé¢çš„æ–‡ä»¶åï¼Œåœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ä¸­ä¿®æ”¹ &lt;code&gt;platforms&lt;/code&gt; é…ç½®ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;platforms:
  - id: "toutiao"
    name: "ä»Šæ—¥å¤´æ¡"
  - id: "baidu"  
    name: "ç™¾åº¦çƒ­æœ"
  - id: "wallstreetcn-hot"
    name: "åå°”è¡—è§é—»"
  # æ·»åŠ æ›´å¤šå¹³å°...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å¦‚æœä¸ä¼šçœ‹çš„è¯ï¼Œå°±ç›´æ¥å¤åˆ¶ä»–äººæ•´ç†å¥½çš„éƒ¨åˆ†&lt;a href="https://github.com/sansan0/TrendRadar/issues/95"&gt;å¹³å°é…ç½®&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;æ™ºèƒ½æ¨é€ç­–ç•¥&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ä¸‰ç§æ¨é€æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ¨¡å¼&lt;/th&gt; 
   &lt;th&gt;é€‚ç”¨äººç¾¤&lt;/th&gt; 
   &lt;th&gt;æ¨é€æ—¶æœº&lt;/th&gt; 
   &lt;th&gt;æ˜¾ç¤ºå†…å®¹&lt;/th&gt; 
   &lt;th&gt;é€‚ç”¨åœºæ™¯&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“æ—¥æ±‡æ€»&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“‹ ä¼ä¸šç®¡ç†è€…/æ™®é€šç”¨æˆ·&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
   &lt;td&gt;å½“æ—¥æ‰€æœ‰åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
   &lt;td&gt;æ—¥æŠ¥æ€»ç»“&lt;br /&gt;å…¨é¢äº†è§£å½“æ—¥çƒ­ç‚¹è¶‹åŠ¿&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å½“å‰æ¦œå•&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“° è‡ªåª’ä½“äºº/å†…å®¹åˆ›ä½œè€…&lt;/td&gt; 
   &lt;td&gt;æŒ‰æ—¶æ¨é€(é»˜è®¤æ¯å°æ—¶æ¨é€ä¸€æ¬¡)&lt;/td&gt; 
   &lt;td&gt;å½“å‰æ¦œå•åŒ¹é…æ–°é—»&lt;br /&gt;+ æ–°å¢æ–°é—»åŒºåŸŸ&lt;/td&gt; 
   &lt;td&gt;å®æ—¶çƒ­ç‚¹è¿½è¸ª&lt;br /&gt;äº†è§£å½“å‰æœ€ç«çš„å†…å®¹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;å¢é‡ç›‘æ§&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;incremental&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸ“ˆ æŠ•èµ„è€…/äº¤æ˜“å‘˜&lt;/td&gt; 
   &lt;td&gt;æœ‰æ–°å¢æ‰æ¨é€&lt;/td&gt; 
   &lt;td&gt;æ–°å‡ºç°çš„åŒ¹é…é¢‘ç‡è¯æ–°é—»&lt;/td&gt; 
   &lt;td&gt;é¿å…é‡å¤ä¿¡æ¯å¹²æ‰°&lt;br /&gt;é«˜é¢‘ç›‘æ§åœºæ™¯&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;é™„åŠ åŠŸèƒ½ - æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;ï¼ˆå¯é€‰ï¼‰ï¼š&lt;/p&gt; 
&lt;p&gt;æ­¤åŠŸèƒ½ç‹¬ç«‹äºä¸Šè¿°ä¸‰ç§æ¨é€æ¨¡å¼,å¯ä¸ä»»æ„æ¨¡å¼æ­é…ä½¿ç”¨:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´çª—å£é™åˆ¶&lt;/strong&gt;: è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼ˆå¦‚ 09:00-18:00 æˆ– 20:00-22:00ï¼‰,åªåœ¨æŒ‡å®šæ—¶é—´å†…æ¨é€&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡æ§åˆ¶&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;çª—å£å†…å¤šæ¬¡æ¨é€: æ—¶é—´çª—å£å†…æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€&lt;/li&gt; 
   &lt;li&gt;æ¯å¤©ä»…æ¨é€ä¸€æ¬¡: æ—¶é—´çª—å£å†…åªæ¨é€ä¸€æ¬¡ï¼ˆé€‚åˆå½“æ—¥æ±‡æ€»æˆ–å½“å‰æ¦œå•æ¨¡å¼ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…¸å‹åœºæ™¯&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;å·¥ä½œæ—¶é—´æ¨é€: åªåœ¨å·¥ä½œæ—¥ 09:00-18:00 æ¥æ”¶æ¶ˆæ¯&lt;/li&gt; 
   &lt;li&gt;æ™šé—´æ±‡æ€»æ¨é€: å¸Œæœ›åœ¨æ™šä¸Šå›ºå®šæ—¶é—´ï¼ˆå¦‚ 20:00-22:00ï¼‰æ”¶åˆ°æ±‡æ€»&lt;/li&gt; 
   &lt;li&gt;é¿å…æ‰“æ‰°: é˜²æ­¢éå·¥ä½œæ—¶é—´æ”¶åˆ°æ¨é€é€šçŸ¥&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æç¤º: æ­¤åŠŸèƒ½é»˜è®¤å…³é—­,éœ€åœ¨ &lt;code&gt;config/config.yaml&lt;/code&gt; ä¸­æ‰‹åŠ¨å¯ç”¨ &lt;code&gt;push_window.enabled&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;ç²¾å‡†å†…å®¹ç­›é€‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;è®¾ç½®ä¸ªäººå…³é”®è¯ï¼ˆå¦‚ï¼šAIã€æ¯”äºšè¿ªã€æ•™è‚²æ”¿ç­–ï¼‰ï¼Œåªæ¨é€ç›¸å…³çƒ­ç‚¹ï¼Œè¿‡æ»¤æ— å…³ä¿¡æ¯&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ”¯æŒæ™®é€šè¯ã€å¿…é¡»è¯(+)ã€è¿‡æ»¤è¯(!)ä¸‰ç§è¯­æ³•ï¼Œè§ã€frequency_words.txt é…ç½®æ•™ç¨‹ã€‘&lt;/li&gt; 
 &lt;li&gt;è¯ç»„åŒ–ç®¡ç†ï¼Œç‹¬ç«‹ç»Ÿè®¡ä¸åŒä¸»é¢˜çƒ­ç‚¹&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¹Ÿå¯ä»¥ä¸åšç­›é€‰ï¼Œå®Œæ•´çš„æ¨é€æ‰€æœ‰çƒ­ç‚¹ï¼Œå…·ä½“è§ã€å†å²æ›´æ–°ã€‘ä¸­çš„ v2.0.1&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ frequency_words.txt é…ç½®æ•™ç¨‹&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;åœ¨ &lt;code&gt;frequency_words.txt&lt;/code&gt; æ–‡ä»¶ä¸­é…ç½®ç›‘æ§çš„å…³é”®è¯ï¼Œæ”¯æŒä¸‰ç§è¯­æ³•å’Œè¯ç»„åŠŸèƒ½ã€‚&lt;/p&gt; 
 &lt;p&gt;å…³é”®è¯è¶Šé å‰ï¼Œæ–°é—»çš„ä¼˜å…ˆçº§è¶Šé«˜ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å…³æ³¨åº¦è°ƒæ•´å…³é”®è¯é¡ºåº&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;è¯­æ³•ç±»å‹&lt;/th&gt; 
    &lt;th&gt;ç¬¦å·&lt;/th&gt; 
    &lt;th&gt;ä½œç”¨&lt;/th&gt; 
    &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
    &lt;th&gt;åŒ¹é…é€»è¾‘&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ™®é€šè¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;æ— &lt;/td&gt; 
    &lt;td&gt;åŸºç¡€åŒ¹é…&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;åä¸º&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ…å«ä»»æ„ä¸€ä¸ªå³å¯&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;é™å®šèŒƒå›´&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+æ‰‹æœº&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;å¿…é¡»åŒæ—¶åŒ…å«&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;æ’é™¤å¹²æ‰°&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!å¹¿å‘Š&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;åŒ…å«åˆ™ç›´æ¥æ’é™¤&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;ğŸ“‹ åŸºç¡€è¯­æ³•è¯´æ˜&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;æ™®é€šå…³é”®è¯&lt;/strong&gt; - åŸºç¡€åŒ¹é…&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; æ–°é—»æ ‡é¢˜åŒ…å«å…¶ä¸­&lt;strong&gt;ä»»æ„ä¸€ä¸ªè¯&lt;/strong&gt;å°±ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h4&gt;2. &lt;strong&gt;å¿…é¡»è¯&lt;/strong&gt; &lt;code&gt;+è¯æ±‡&lt;/code&gt; - é™å®šèŒƒå›´&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ‰‹æœº
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; å¿…é¡»åŒæ—¶åŒ…å«æ™®é€šè¯&lt;strong&gt;å’Œ&lt;/strong&gt;å¿…é¡»è¯æ‰ä¼šè¢«æ•è·&lt;/p&gt; 
 &lt;h4&gt;3. &lt;strong&gt;è¿‡æ»¤è¯&lt;/strong&gt; &lt;code&gt;!è¯æ±‡&lt;/code&gt; - æ’é™¤å¹²æ‰°&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;è‹¹æœ
åä¸º
!æ°´æœ
!ä»·æ ¼
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½œç”¨ï¼š&lt;/strong&gt; åŒ…å«è¿‡æ»¤è¯çš„æ–°é—»ä¼šè¢«&lt;strong&gt;ç›´æ¥æ’é™¤&lt;/strong&gt;ï¼Œå³ä½¿åŒ…å«å…³é”®è¯&lt;/p&gt; 
 &lt;h3&gt;ğŸ”— è¯ç»„åŠŸèƒ½ - ç©ºè¡Œåˆ†éš”çš„é‡è¦ä½œç”¨&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒè§„åˆ™ï¼š&lt;/strong&gt; ç”¨&lt;strong&gt;ç©ºè¡Œ&lt;/strong&gt;åˆ†éš”ä¸åŒçš„è¯ç»„ï¼Œæ¯ä¸ªè¯ç»„ç‹¬ç«‹ç»Ÿè®¡&lt;/p&gt; 
 &lt;h4&gt;ç¤ºä¾‹é…ç½®ï¼š&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;iPhone
åä¸º
OPPO
+å‘å¸ƒ

Aè‚¡
ä¸Šè¯
æ·±è¯
+æ¶¨è·Œ
!é¢„æµ‹

ä¸–ç•Œæ¯
æ¬§æ´²æ¯
äºšæ´²æ¯
+æ¯”èµ›
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;è¯ç»„è§£é‡ŠåŠåŒ¹é…æ•ˆæœï¼š&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬1ç»„ - æ‰‹æœºæ–°å“ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šiPhoneã€åä¸ºã€OPPO&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šå‘å¸ƒ&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå¿…é¡»åŒ…å«æ‰‹æœºå“ç‰Œåï¼ŒåŒæ—¶åŒ…å«"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "iPhone 15æ­£å¼å‘å¸ƒå”®ä»·å…¬å¸ƒ" â† æœ‰"iPhone"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "åä¸ºMate60ç³»åˆ—å‘å¸ƒä¼šç›´æ’­" â† æœ‰"åä¸º"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âœ… "OPPO Find X7å‘å¸ƒæ—¶é—´ç¡®å®š" â† æœ‰"OPPO"+"å‘å¸ƒ"&lt;/li&gt; 
  &lt;li&gt;âŒ "iPhoneé”€é‡åˆ›æ–°é«˜" â† æœ‰"iPhone"ä½†ç¼ºå°‘"å‘å¸ƒ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬2ç»„ - è‚¡å¸‚è¡Œæƒ…ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šAè‚¡ã€ä¸Šè¯ã€æ·±è¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¶¨è·Œ&lt;/li&gt; 
  &lt;li&gt;è¿‡æ»¤è¯ï¼šé¢„æµ‹&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šåŒ…å«è‚¡å¸‚ç›¸å…³è¯ï¼ŒåŒæ—¶åŒ…å«"æ¶¨è·Œ"ï¼Œä½†æ’é™¤åŒ…å«"é¢„æµ‹"çš„å†…å®¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "Aè‚¡ä»Šæ—¥å¤§å¹…æ¶¨è·Œåˆ†æ" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âœ… "ä¸Šè¯æŒ‡æ•°æ¶¨è·ŒåŸå› è§£è¯»" â† æœ‰"ä¸Šè¯"+"æ¶¨è·Œ"&lt;/li&gt; 
  &lt;li&gt;âŒ "ä¸“å®¶é¢„æµ‹Aè‚¡æ¶¨è·Œè¶‹åŠ¿" â† æœ‰"Aè‚¡"+"æ¶¨è·Œ"ä½†åŒ…å«"é¢„æµ‹"&lt;/li&gt; 
  &lt;li&gt;âŒ "Aè‚¡æˆäº¤é‡åˆ›æ–°é«˜" â† æœ‰"Aè‚¡"ä½†ç¼ºå°‘"æ¶¨è·Œ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ç¬¬3ç»„ - è¶³çƒèµ›äº‹ç±»ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;å…³é”®è¯ï¼šä¸–ç•Œæ¯ã€æ¬§æ´²æ¯ã€äºšæ´²æ¯&lt;/li&gt; 
  &lt;li&gt;å¿…é¡»è¯ï¼šæ¯”èµ›&lt;/li&gt; 
  &lt;li&gt;æ•ˆæœï¼šå¿…é¡»åŒ…å«æ¯èµ›åç§°ï¼ŒåŒæ—¶åŒ…å«"æ¯”èµ›"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;åŒ¹é…ç¤ºä¾‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;âœ… "ä¸–ç•Œæ¯å°ç»„èµ›æ¯”èµ›ç»“æœ" â† æœ‰"ä¸–ç•Œæ¯"+"æ¯”èµ›"&lt;/li&gt; 
  &lt;li&gt;âœ… "æ¬§æ´²æ¯å†³èµ›æ¯”èµ›æ—¶é—´" â† æœ‰"æ¬§æ´²æ¯"+"æ¯”èµ›"&lt;/li&gt; 
  &lt;li&gt;âŒ "ä¸–ç•Œæ¯é—¨ç¥¨å¼€å”®" â† æœ‰"ä¸–ç•Œæ¯"ä½†ç¼ºå°‘"æ¯”èµ›"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ğŸ¯ é…ç½®æŠ€å·§&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;ä»å®½åˆ°ä¸¥çš„é…ç½®ç­–ç•¥&lt;/strong&gt;&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# ç¬¬ä¸€æ­¥ï¼šå…ˆç”¨å®½æ³›å…³é”®è¯æµ‹è¯•
äººå·¥æ™ºèƒ½
AI
ChatGPT

# ç¬¬äºŒæ­¥ï¼šå‘ç°è¯¯åŒ¹é…åï¼ŒåŠ å…¥å¿…é¡»è¯é™å®š
äººå·¥æ™ºèƒ½  
AI
ChatGPT
+æŠ€æœ¯

# ç¬¬ä¸‰æ­¥ï¼šå‘ç°å¹²æ‰°å†…å®¹åï¼ŒåŠ å…¥è¿‡æ»¤è¯
äººå·¥æ™ºèƒ½
AI  
ChatGPT
+æŠ€æœ¯
!å¹¿å‘Š
!åŸ¹è®­
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2. &lt;strong&gt;é¿å…è¿‡åº¦å¤æ‚&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;âŒ &lt;strong&gt;ä¸æ¨èï¼š&lt;/strong&gt; ä¸€ä¸ªè¯ç»„åŒ…å«å¤ªå¤šè¯æ±‡&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
è‹¹æœ
ä¸‰æ˜Ÿ
vivo
ä¸€åŠ 
é­…æ—
+æ‰‹æœº
+å‘å¸ƒ
+é”€é‡
!å‡è´§
!ç»´ä¿®
!äºŒæ‰‹
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;âœ… &lt;strong&gt;æ¨èï¼š&lt;/strong&gt; æ‹†åˆ†æˆå¤šä¸ªç²¾ç¡®çš„è¯ç»„&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;åä¸º
OPPO
+æ–°å“

è‹¹æœ
ä¸‰æ˜Ÿ  
+å‘å¸ƒ

æ‰‹æœº
é”€é‡
+å¸‚åœº
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;çƒ­ç‚¹è¶‹åŠ¿åˆ†æ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;å®æ—¶è¿½è¸ªæ–°é—»çƒ­åº¦å˜åŒ–ï¼Œè®©ä½ ä¸ä»…çŸ¥é“"ä»€ä¹ˆåœ¨çƒ­æœ"ï¼Œæ›´äº†è§£"çƒ­ç‚¹å¦‚ä½•æ¼”å˜"&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´è½´è¿½è¸ª&lt;/strong&gt;ï¼šè®°å½•æ¯æ¡æ–°é—»ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„å®Œæ•´æ—¶é—´è·¨åº¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;çƒ­åº¦å˜åŒ–&lt;/strong&gt;ï¼šç»Ÿè®¡æ–°é—»åœ¨ä¸åŒæ—¶é—´æ®µçš„æ’åå˜åŒ–å’Œå‡ºç°é¢‘æ¬¡&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–°å¢æ£€æµ‹&lt;/strong&gt;ï¼šå®æ—¶è¯†åˆ«æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜ï¼Œç”¨ğŸ†•æ ‡è®°ç¬¬ä¸€æ—¶é—´æé†’&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŒç»­æ€§åˆ†æ&lt;/strong&gt;ï¼šåŒºåˆ†ä¸€æ¬¡æ€§çƒ­ç‚¹è¯é¢˜å’ŒæŒç»­å‘é…µçš„æ·±åº¦æ–°é—»&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è·¨å¹³å°å¯¹æ¯”&lt;/strong&gt;ï¼šåŒä¸€æ–°é—»åœ¨ä¸åŒå¹³å°çš„æ’åè¡¨ç°ï¼Œçœ‹å‡ºåª’ä½“å…³æ³¨åº¦å·®å¼‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸å†é”™è¿‡é‡è¦æ–°é—»çš„å®Œæ•´å‘å±•è¿‡ç¨‹ï¼Œä»è¯é¢˜èŒèŠ½åˆ°é«˜å³°çƒ­è®®ï¼Œå…¨ç¨‹æŒæ¡&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ æ¨é€æ ¼å¼è¯´æ˜&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡&lt;/p&gt; 
 &lt;p&gt;ğŸ”¥ [1/3] AI ChatGPT : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ç™¾åº¦çƒ­æœ] ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;] - 09æ—¶15åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[ä»Šæ—¥å¤´æ¡] AIèŠ¯ç‰‡æ¦‚å¿µè‚¡æš´æ¶¨ [&lt;strong&gt;3&lt;/strong&gt;] - [08æ—¶30åˆ† ~ 10æ—¶45åˆ†] (3æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“ˆ [2/3] æ¯”äºšè¿ª ç‰¹æ–¯æ‹‰ : 2 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[å¾®åš] ğŸ†• æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;] - 10æ—¶20åˆ† (1æ¬¡)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[æŠ–éŸ³] ç‰¹æ–¯æ‹‰é™ä»·ä¿ƒé”€ [&lt;strong&gt;4&lt;/strong&gt;] - [07æ—¶45åˆ† ~ 09æ—¶15åˆ†] (2æ¬¡)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”&lt;/p&gt; 
 &lt;p&gt;ğŸ“Œ [3/3] Aè‚¡ è‚¡å¸‚ : 1 æ¡&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;[åå°”è¡—è§é—»] Aè‚¡åˆç›˜ç‚¹è¯„åˆ†æ [&lt;strong&gt;5&lt;/strong&gt;] - [11æ—¶30åˆ† ~ 12æ—¶00åˆ†] (2æ¬¡)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± 2 æ¡)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ç™¾åº¦çƒ­æœ&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ChatGPT-5æ­£å¼å‘å¸ƒ [&lt;strong&gt;1&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;å¾®åš&lt;/strong&gt; (1 æ¡):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ¯”äºšè¿ªæœˆé”€é‡ç ´çºªå½• [&lt;strong&gt;2&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ›´æ–°æ—¶é—´ï¼š2025-01-15 12:30:15&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;æ¶ˆæ¯æ ¼å¼è¯´æ˜&lt;/strong&gt;&lt;/h2&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ ¼å¼å…ƒç´ &lt;/th&gt; 
    &lt;th&gt;ç¤ºä¾‹&lt;/th&gt; 
    &lt;th&gt;å«ä¹‰&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ”¥ğŸ“ˆğŸ“Œ&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥ [1/3] AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;çƒ­åº¦ç­‰çº§&lt;/td&gt; 
    &lt;td&gt;ğŸ”¥é«˜çƒ­åº¦(â‰¥10æ¡) ğŸ“ˆä¸­çƒ­åº¦(5-9æ¡) ğŸ“Œæ™®é€šçƒ­åº¦(&amp;lt;5æ¡)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[åºå·/æ€»æ•°]&lt;/td&gt; 
    &lt;td&gt;[1/3]&lt;/td&gt; 
    &lt;td&gt;æ’åºä½ç½®&lt;/td&gt; 
    &lt;td&gt;å½“å‰è¯ç»„åœ¨æ‰€æœ‰åŒ¹é…è¯ç»„ä¸­çš„æ’å&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;é¢‘ç‡è¯ç»„&lt;/td&gt; 
    &lt;td&gt;AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;å…³é”®è¯ç»„&lt;/td&gt; 
    &lt;td&gt;é…ç½®æ–‡ä»¶ä¸­çš„è¯ç»„ï¼Œæ ‡é¢˜å¿…é¡»åŒ…å«å…¶ä¸­è¯æ±‡&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;: N æ¡&lt;/td&gt; 
    &lt;td&gt;: 2 æ¡&lt;/td&gt; 
    &lt;td&gt;åŒ¹é…æ•°é‡&lt;/td&gt; 
    &lt;td&gt;è¯¥è¯ç»„åŒ¹é…çš„æ–°é—»æ€»æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[å¹³å°å]&lt;/td&gt; 
    &lt;td&gt;[ç™¾åº¦çƒ­æœ]&lt;/td&gt; 
    &lt;td&gt;æ¥æºå¹³å°&lt;/td&gt; 
    &lt;td&gt;æ–°é—»æ‰€å±çš„å¹³å°åç§°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ğŸ†•&lt;/td&gt; 
    &lt;td&gt;ğŸ†• ChatGPT-5æ­£å¼å‘å¸ƒ&lt;/td&gt; 
    &lt;td&gt;æ–°å¢æ ‡è®°&lt;/td&gt; 
    &lt;td&gt;æœ¬è½®æŠ“å–ä¸­é¦–æ¬¡å‡ºç°çš„çƒ­ç‚¹&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[&lt;strong&gt;æ•°å­—&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;[&lt;strong&gt;1&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;é«˜æ’å&lt;/td&gt; 
    &lt;td&gt;æ’åâ‰¤é˜ˆå€¼çš„çƒ­æœï¼Œçº¢è‰²åŠ ç²—æ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ•°å­—]&lt;/td&gt; 
    &lt;td&gt;[7]&lt;/td&gt; 
    &lt;td&gt;æ™®é€šæ’å&lt;/td&gt; 
    &lt;td&gt;æ’å&amp;gt;é˜ˆå€¼çš„çƒ­æœï¼Œæ™®é€šæ˜¾ç¤º&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;- æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;- 09æ—¶15åˆ†&lt;/td&gt; 
    &lt;td&gt;é¦–æ¬¡æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;è¯¥æ–°é—»é¦–æ¬¡è¢«å‘ç°çš„æ—¶é—´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[æ—¶é—´~æ—¶é—´]&lt;/td&gt; 
    &lt;td&gt;[08æ—¶30åˆ† ~ 10æ—¶45åˆ†]&lt;/td&gt; 
    &lt;td&gt;æŒç»­æ—¶é—´&lt;/td&gt; 
    &lt;td&gt;ä»é¦–æ¬¡å‡ºç°åˆ°æœ€åå‡ºç°çš„æ—¶é—´èŒƒå›´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;(Næ¬¡)&lt;/td&gt; 
    &lt;td&gt;(3æ¬¡)&lt;/td&gt; 
    &lt;td&gt;å‡ºç°é¢‘ç‡&lt;/td&gt; 
    &lt;td&gt;åœ¨ç›‘æ§æœŸé—´å‡ºç°çš„æ€»æ¬¡æ•°&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;æ–°å¢åŒºåŸŸ&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;ğŸ†• &lt;strong&gt;æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;æ–°è¯é¢˜æ±‡æ€»&lt;/td&gt; 
    &lt;td&gt;å•ç‹¬å±•ç¤ºæœ¬è½®æ–°å‡ºç°çš„çƒ­ç‚¹è¯é¢˜&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;ä¸ªæ€§åŒ–çƒ­ç‚¹ç®—æ³•&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä¸å†è¢«å„ä¸ªå¹³å°çš„ç®—æ³•ç‰µç€èµ°ï¼ŒTrendRadar ä¼šé‡æ–°æ•´ç†å…¨ç½‘çƒ­æœï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;çœ‹é‡æ’åé«˜çš„æ–°é—»&lt;/strong&gt;ï¼ˆå 60%ï¼‰ï¼šå„å¹³å°å‰å‡ åçš„æ–°é—»ä¼˜å…ˆæ˜¾ç¤º&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…³æ³¨æŒç»­å‡ºç°çš„è¯é¢˜&lt;/strong&gt;ï¼ˆå 30%ï¼‰ï¼šåå¤å‡ºç°çš„æ–°é—»æ›´é‡è¦&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è€ƒè™‘æ’åè´¨é‡&lt;/strong&gt;ï¼ˆå 10%ï¼‰ï¼šä¸ä»…å¤šæ¬¡å‡ºç°ï¼Œè¿˜ç»å¸¸æ’åœ¨å‰åˆ—&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æŠŠåˆ†æ•£åœ¨å„ä¸ªå¹³å°çš„çƒ­æœåˆå¹¶èµ·æ¥ï¼ŒæŒ‰ç…§ä½ å…³å¿ƒçš„çƒ­åº¦é‡æ–°æ’åºï¼Œè¿™ä¸‰ä¸ªæ¯”ä¾‹å¯ä»¥é€‰æ‹©é€‚åˆè‡ªå·±çš„åœºæ™¯è¿›è¡Œè°ƒæ•´&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ çƒ­ç‚¹æƒé‡è°ƒæ•´&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;å½“å‰é»˜è®¤çš„é…ç½®æ˜¯å¹³è¡¡æ€§é…ç½®&lt;/p&gt; 
 &lt;h3&gt;ä¸¤ä¸ªæ ¸å¿ƒåœºæ™¯&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½å®æ—¶çƒ­ç‚¹å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.8    # ä¸»è¦çœ‹æ’å
  frequency_weight: 0.1  # ä¸å¤ªåœ¨ä¹æŒç»­æ€§
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šè‡ªåª’ä½“åšä¸»ã€è¥é”€äººå‘˜ã€æƒ³å¿«é€Ÿäº†è§£å½“ä¸‹æœ€ç«è¯é¢˜çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;è¿½æ·±åº¦è¯é¢˜å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.4    # é€‚åº¦çœ‹æ’å
  frequency_weight: 0.5  # é‡è§†å½“å¤©å†…çš„æŒç»­çƒ­åº¦
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;é€‚ç”¨äººç¾¤&lt;/strong&gt;ï¼šæŠ•èµ„è€…ã€ç ”ç©¶äººå‘˜ã€æ–°é—»å·¥ä½œè€…ã€éœ€è¦æ·±åº¦åˆ†æè¶‹åŠ¿çš„ç”¨æˆ·&lt;/p&gt; 
 &lt;h3&gt;è°ƒæ•´çš„æ–¹æ³•&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ä¸‰ä¸ªæ•°å­—åŠ èµ·æ¥å¿…é¡»ç­‰äº 1.0&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å“ªä¸ªé‡è¦å°±è°ƒå¤§å“ªä¸ª&lt;/strong&gt;ï¼šåœ¨ä¹æ’åå°±è°ƒå¤§ rank_weightï¼Œåœ¨ä¹æŒç»­æ€§å°±è°ƒå¤§ frequency_weight&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å»ºè®®æ¯æ¬¡åªè°ƒ 0.1-0.2&lt;/strong&gt;ï¼Œè§‚å¯Ÿæ•ˆæœ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ ¸å¿ƒæ€è·¯ï¼šè¿½æ±‚é€Ÿåº¦å’Œæ—¶æ•ˆæ€§çš„ç”¨æˆ·æé«˜æ’åæƒé‡ï¼Œè¿½æ±‚æ·±åº¦å’Œç¨³å®šæ€§çš„ç”¨æˆ·æé«˜é¢‘æ¬¡æƒé‡ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šæ¸ é“å®æ—¶æ¨é€&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒ&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;(+ å¾®ä¿¡æ¨é€æ–¹æ¡ˆ)ã€&lt;strong&gt;é£ä¹¦&lt;/strong&gt;ã€&lt;strong&gt;é’‰é’‰&lt;/strong&gt;ã€&lt;strong&gt;Telegram&lt;/strong&gt;ã€&lt;strong&gt;é‚®ä»¶&lt;/strong&gt;ã€&lt;strong&gt;ntfy&lt;/strong&gt;ï¼Œæ¶ˆæ¯ç›´è¾¾æ‰‹æœºå’Œé‚®ç®±&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;å¤šç«¯é€‚é…&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;ï¼šè‡ªåŠ¨ç”Ÿæˆç²¾ç¾ç½‘é¡µæŠ¥å‘Šï¼ŒPC/ç§»åŠ¨ç«¯é€‚é…&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dockeréƒ¨ç½²&lt;/strong&gt;ï¼šæ”¯æŒå¤šæ¶æ„å®¹å™¨åŒ–è¿è¡Œ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®æŒä¹…åŒ–&lt;/strong&gt;ï¼šHTML/TXTå¤šæ ¼å¼å†å²è®°å½•ä¿å­˜&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;AI æ™ºèƒ½åˆ†æï¼ˆv3.0.0 æ–°å¢ï¼‰&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åŸºäº MCP (Model Context Protocol) åè®®çš„ AI å¯¹è¯åˆ†æç³»ç»Ÿï¼Œè®©ä½ ç”¨è‡ªç„¶è¯­è¨€æ·±åº¦æŒ–æ˜æ–°é—»æ•°æ®&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å¯¹è¯å¼æŸ¥è¯¢&lt;/strong&gt;ï¼šç”¨è‡ªç„¶è¯­è¨€æé—®ï¼Œå¦‚"æŸ¥è¯¢æ˜¨å¤©çŸ¥ä¹çš„çƒ­ç‚¹"ã€"åˆ†ææ¯”ç‰¹å¸æœ€è¿‘çš„çƒ­åº¦è¶‹åŠ¿"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;13 ç§åˆ†æå·¥å…·&lt;/strong&gt;ï¼šæ¶µç›–åŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€è¶‹åŠ¿åˆ†æã€æ•°æ®æ´å¯Ÿã€æƒ…æ„Ÿåˆ†æç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒ&lt;/strong&gt;ï¼šCherry Studioï¼ˆGUI é…ç½®ï¼‰ã€Claude Desktopã€Cursorã€Cline ç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ·±åº¦åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;è¯é¢˜è¶‹åŠ¿è¿½è¸ªï¼ˆçƒ­åº¦å˜åŒ–ã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
   &lt;li&gt;è·¨å¹³å°æ•°æ®å¯¹æ¯”ï¼ˆæ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
   &lt;li&gt;æ™ºèƒ½æ‘˜è¦ç”Ÿæˆã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€å†å²å…³è”æ£€ç´¢&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å‘Šåˆ«æ‰‹åŠ¨ç¿»é˜…æ•°æ®æ–‡ä»¶ï¼ŒAI åŠ©æ‰‹å¸®ä½ ç§’æ‡‚æ–°é—»èƒŒåçš„æ•…äº‹&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;é›¶æŠ€æœ¯é—¨æ§›éƒ¨ç½²&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GitHub ä¸€é”® Fork å³å¯ä½¿ç”¨ï¼Œæ— éœ€ç¼–ç¨‹åŸºç¡€ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;30ç§’éƒ¨ç½²ï¼š GitHub Pagesï¼ˆç½‘é¡µæµè§ˆï¼‰æ”¯æŒä¸€é”®ä¿å­˜æˆå›¾ç‰‡ï¼Œéšæ—¶åˆ†äº«ç»™ä»–äºº&lt;/p&gt; 
 &lt;p&gt;1åˆ†é’Ÿéƒ¨ç½²ï¼š ä¼ä¸šå¾®ä¿¡ï¼ˆæ‰‹æœºé€šçŸ¥ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ’¡ æç¤ºï¼š&lt;/strong&gt; æƒ³è¦&lt;strong&gt;å®æ—¶æ›´æ–°&lt;/strong&gt;çš„ç½‘é¡µç‰ˆï¼Ÿfork åï¼Œè¿›å…¥ä½ çš„ä»“åº“ Settings â†’ Pagesï¼Œå¯ç”¨ GitHub Pagesã€‚&lt;a href="https://sansan0.github.io/TrendRadar/"&gt;æ•ˆæœé¢„è§ˆ&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;å‡å°‘ APP ä¾èµ–&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ä»"è¢«ç®—æ³•æ¨èç»‘æ¶"å˜æˆ"ä¸»åŠ¨è·å–è‡ªå·±æƒ³è¦çš„ä¿¡æ¯"&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤ï¼š&lt;/strong&gt; æŠ•èµ„è€…ã€è‡ªåª’ä½“äººã€ä¼ä¸šå…¬å…³ã€å…³å¿ƒæ—¶äº‹çš„æ™®é€šç”¨æˆ·&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å…¸å‹åœºæ™¯ï¼š&lt;/strong&gt; è‚¡å¸‚æŠ•èµ„ç›‘æ§ã€å“ç‰Œèˆ†æƒ…è¿½è¸ªã€è¡Œä¸šåŠ¨æ€å…³æ³¨ã€ç”Ÿæ´»èµ„è®¯è·å–&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Github Pages æ•ˆæœ(æ‰‹æœºç«¯é€‚é…ã€é‚®ç®±æ¨é€æ•ˆæœ)&lt;/th&gt; 
   &lt;th align="center"&gt;é£ä¹¦æ¨é€æ•ˆæœ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/github-pages.png" alt="Github Pagesæ•ˆæœ" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/feishu.jpg" alt="é£ä¹¦æ¨é€æ•ˆæœ" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ“ æ›´æ–°æ—¥å¿—&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;å‡çº§è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æç¤º&lt;/strong&gt;ï¼šä¸è¦é€šè¿‡ &lt;strong&gt;Sync fork&lt;/strong&gt; æ›´æ–°æœ¬é¡¹ç›®, å»ºè®®æŸ¥çœ‹ã€å†å²æ›´æ–°ã€‘ï¼Œæ˜ç¡®å…·ä½“çš„ã€å‡çº§æ–¹å¼ã€‘å’Œã€åŠŸèƒ½å†…å®¹ã€‘&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å°ç‰ˆæœ¬æ›´æ–°&lt;/strong&gt;ï¼šä» v2.x å‡çº§åˆ° v2.y, ç”¨æœ¬é¡¹ç›®çš„ &lt;code&gt;main.py&lt;/code&gt; ä»£ç æ›¿æ¢ä½  fork ä»“åº“ä¸­çš„å¯¹åº”æ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§ç‰ˆæœ¬å‡çº§&lt;/strong&gt;ï¼šä» v1.x å‡çº§åˆ° v2.y, å»ºè®®åˆ é™¤ç°æœ‰ fork åé‡æ–° forkï¼Œè¿™æ ·æ›´çœåŠ›ä¸”é¿å…é…ç½®å†²çª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/11/12 - v3.0.5&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¿®å¤é‚®ä»¶å‘é€ SSL/TLS ç«¯å£é…ç½®é€»è¾‘é”™è¯¯&lt;/li&gt; 
 &lt;li&gt;ä¼˜åŒ–é‚®ç®±æœåŠ¡å•†ï¼ˆQQ/163/126ï¼‰é»˜è®¤ä½¿ç”¨ 465 ç«¯å£ï¼ˆSSLï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–°å¢ Docker ç¯å¢ƒå˜é‡æ”¯æŒ&lt;/strong&gt;ï¼šæ ¸å¿ƒé…ç½®é¡¹ï¼ˆ&lt;code&gt;enable_crawler&lt;/code&gt;ã€&lt;code&gt;report_mode&lt;/code&gt;ã€&lt;code&gt;push_window&lt;/code&gt; ç­‰ï¼‰æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œè§£å†³ NAS ç”¨æˆ·ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸ç”Ÿæ•ˆçš„é—®é¢˜ï¼ˆè¯¦è§ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;ğŸ³ Docker éƒ¨ç½²&lt;/a&gt; ç« èŠ‚ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/26 - mcp-v1.0.1&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;MCP æ¨¡å—æ›´æ–°:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¿®å¤æ—¥æœŸæŸ¥è¯¢å‚æ•°ä¼ é€’é”™è¯¯&lt;/li&gt; 
 &lt;li&gt;ç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„æ—¶é—´å‚æ•°æ ¼å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ å†å²æ›´æ–°&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;2025/10/31 - v3.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é£ä¹¦å› æ¨é€å†…å®¹è¿‡é•¿è€Œäº§ç”Ÿçš„é”™è¯¯ï¼Œå®ç°äº†åˆ†æ‰¹æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/23 - v3.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ‰©å¤§ ntfy é”™è¯¯ä¿¡æ¯æ˜¾ç¤ºèŒƒå›´&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/21 - v3.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/20 - v3.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§æ›´æ–° - AI åˆ†æåŠŸèƒ½ä¸Šçº¿&lt;/strong&gt; ğŸ¤–&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ–°å¢åŸºäº MCP (Model Context Protocol) çš„ AI åˆ†ææœåŠ¡å™¨&lt;/li&gt; 
    &lt;li&gt;æ”¯æŒ13ç§æ™ºèƒ½åˆ†æå·¥å…·ï¼šåŸºç¡€æŸ¥è¯¢ã€æ™ºèƒ½æ£€ç´¢ã€é«˜çº§åˆ†æã€ç³»ç»Ÿç®¡ç†&lt;/li&gt; 
    &lt;li&gt;è‡ªç„¶è¯­è¨€äº¤äº’ï¼šé€šè¿‡å¯¹è¯æ–¹å¼æŸ¥è¯¢å’Œåˆ†ææ–°é—»æ•°æ®&lt;/li&gt; 
    &lt;li&gt;å¤šå®¢æˆ·ç«¯æ”¯æŒï¼šClaude Desktopã€Cherry Studioã€Cursorã€Cline ç­‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ†æèƒ½åŠ›&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¯é¢˜è¶‹åŠ¿åˆ†æï¼ˆçƒ­åº¦è¿½è¸ªã€ç”Ÿå‘½å‘¨æœŸã€çˆ†ç«æ£€æµ‹ã€è¶‹åŠ¿é¢„æµ‹ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ•°æ®æ´å¯Ÿï¼ˆå¹³å°å¯¹æ¯”ã€æ´»è·ƒåº¦ç»Ÿè®¡ã€å…³é”®è¯å…±ç°ï¼‰&lt;/li&gt; 
    &lt;li&gt;æƒ…æ„Ÿåˆ†æã€ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾ã€æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ&lt;/li&gt; 
    &lt;li&gt;å†å²ç›¸å…³æ–°é—»æ£€ç´¢ã€å¤šæ¨¡å¼æœç´¢&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™æ˜¯ç‹¬ç«‹çš„ AI åˆ†æåŠŸèƒ½ï¼Œä¸å½±å“ç°æœ‰çš„æ¨é€åŠŸèƒ½&lt;/li&gt; 
    &lt;li&gt;å¯é€‰æ‹©æ€§ä½¿ç”¨ï¼Œæ— éœ€å‡çº§ç°æœ‰éƒ¨ç½²&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/15 - v2.4.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜ + 1&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤æ¨é€æ—¶é—´çª—å£åˆ¤æ–­é—®é¢˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ã€å°ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/10 - v2.4.3&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ &lt;a href="https://github.com/sansan0/TrendRadar/issues/98"&gt;nidaye996&lt;/a&gt; å‘ç°çš„ä½“éªŒé—®é¢˜&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡æ„"é™é»˜æ¨é€æ¨¡å¼"å‘½åä¸º"æ¨é€æ—¶é—´çª—å£æ§åˆ¶"ï¼Œæå‡åŠŸèƒ½ç†è§£åº¦&lt;/li&gt; 
    &lt;li&gt;æ˜ç¡®æ¨é€æ—¶é—´çª—å£ä½œä¸ºå¯é€‰é™„åŠ åŠŸèƒ½ï¼Œå¯ä¸ä¸‰ç§æ¨é€æ¨¡å¼æ­é…ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;æ”¹è¿›æ³¨é‡Šå’Œæ–‡æ¡£æè¿°ï¼Œä½¿åŠŸèƒ½å®šä½æ›´åŠ æ¸…æ™°&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è¿™ä¸ªä»…ä»…æ˜¯é‡æ„ï¼Œå¯ä»¥ä¸ç”¨å‡çº§&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/8 - v2.4.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿®å¤ ntfy æ¨é€ç¼–ç é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¿®å¤é…ç½®æ–‡ä»¶ç¼ºå¤±é—®é¢˜&lt;/li&gt; 
    &lt;li&gt;ä¼˜åŒ– ntfy æ¨é€æ•ˆæœ&lt;/li&gt; 
    &lt;li&gt;å¢åŠ  github page å›¾ç‰‡åˆ†æ®µå¯¼å‡ºåŠŸèƒ½&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/2 - v2.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ–°å¢ ntfy æ¨é€é€šçŸ¥&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ”¯æŒ ntfy.sh å…¬å…±æœåŠ¡å’Œè‡ªæ‰˜ç®¡æœåŠ¡å™¨&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨åœºæ™¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é€‚åˆè¿½æ±‚éšç§çš„ç”¨æˆ·ï¼ˆæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/li&gt; 
    &lt;li&gt;è·¨å¹³å°æ¨é€ï¼ˆiOSã€Androidã€Desktopã€Webï¼‰&lt;/li&gt; 
    &lt;li&gt;æ— éœ€æ³¨å†Œè´¦å·ï¼ˆå…¬å…±æœåŠ¡å™¨ï¼‰&lt;/li&gt; 
    &lt;li&gt;å¼€æºå…è´¹ï¼ˆMIT åè®®ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;å»ºè®®ä½¿ç”¨ã€å¤§ç‰ˆæœ¬æ›´æ–°ã€‘&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/26 - v2.3.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®æ­£äº†é‚®ä»¶é€šçŸ¥é…ç½®æ£€æŸ¥è¢«é—æ¼çš„é—®é¢˜ï¼ˆ&lt;a href="https://github.com/sansan0/TrendRadar/issues/88"&gt;#88&lt;/a&gt;ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³äº†å³ä½¿æ­£ç¡®é…ç½®é‚®ä»¶é€šçŸ¥ï¼Œç³»ç»Ÿä»æç¤º"æœªé…ç½®ä»»ä½•webhook"çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/22 - v2.3.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ–°å¢é‚®ä»¶æ¨é€åŠŸèƒ½&lt;/strong&gt;ï¼Œæ”¯æŒå°†çƒ­ç‚¹æ–°é—»æŠ¥å‘Šå‘é€åˆ°é‚®ç®±&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ™ºèƒ½ SMTP è¯†åˆ«&lt;/strong&gt;ï¼šè‡ªåŠ¨è¯†åˆ« Gmailã€QQé‚®ç®±ã€Outlookã€ç½‘æ˜“é‚®ç®±ç­‰ 10+ ç§é‚®ç®±æœåŠ¡å•†é…ç½®&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HTML ç²¾ç¾æ ¼å¼&lt;/strong&gt;ï¼šé‚®ä»¶å†…å®¹é‡‡ç”¨ä¸ç½‘é¡µç‰ˆç›¸åŒçš„ HTML æ ¼å¼ï¼Œæ’ç‰ˆç²¾ç¾ï¼Œç§»åŠ¨ç«¯é€‚é…&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ‰¹é‡å‘é€æ”¯æŒ&lt;/strong&gt;ï¼šæ”¯æŒå¤šä¸ªæ”¶ä»¶äººï¼Œç”¨é€—å·åˆ†éš”å³å¯åŒæ—¶å‘é€ç»™å¤šäºº&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰ SMTP&lt;/strong&gt;ï¼šå¯è‡ªå®šä¹‰ SMTP æœåŠ¡å™¨å’Œç«¯å£&lt;/li&gt; 
  &lt;li&gt;ä¿®å¤Dockeræ„å»ºç½‘ç»œè¿æ¥é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šé€‚åˆéœ€è¦é‚®ä»¶å½’æ¡£ã€å›¢é˜Ÿåˆ†äº«ã€å®šæ—¶æŠ¥å‘Šçš„ç”¨æˆ·&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒé‚®ç®±ï¼šGmailã€QQé‚®ç®±ã€Outlook/Hotmailã€163/126é‚®ç®±ã€æ–°æµªé‚®ç®±ã€æœç‹é‚®ç®±ç­‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ­¤æ¬¡æ›´æ–°çš„å†…å®¹æ¯”è¾ƒå¤šï¼Œå¦‚æœæƒ³å‡çº§ï¼Œå»ºè®®é‡‡ç”¨ã€å¤§ç‰ˆæœ¬å‡çº§ã€‘&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/17 - v2.2.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ–°å¢ä¸€é”®ä¿å­˜æ–°é—»å›¾ç‰‡åŠŸèƒ½ï¼Œè®©ä½ è½»æ¾åˆ†äº«å…³æ³¨çš„çƒ­ç‚¹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é€‚ç”¨åœºæ™¯ï¼šå½“ä½ æŒ‰ç…§æ•™ç¨‹å¼€å¯äº†ç½‘é¡µç‰ˆåŠŸèƒ½å(GitHub Pages)&lt;/li&gt; 
  &lt;li&gt;ä½¿ç”¨æ–¹æ³•ï¼šç”¨æ‰‹æœºæˆ–ç”µè„‘æ‰“å¼€è¯¥ç½‘é¡µé“¾æ¥ï¼Œç‚¹å‡»é¡µé¢é¡¶éƒ¨çš„"ä¿å­˜ä¸ºå›¾ç‰‡"æŒ‰é’®&lt;/li&gt; 
  &lt;li&gt;å®é™…æ•ˆæœï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å°†å½“å‰çš„æ–°é—»æŠ¥å‘Šåˆ¶ä½œæˆä¸€å¼ ç²¾ç¾å›¾ç‰‡ï¼Œä¿å­˜åˆ°ä½ çš„æ‰‹æœºç›¸å†Œæˆ–ç”µè„‘æ¡Œé¢&lt;/li&gt; 
  &lt;li&gt;åˆ†äº«ä¾¿åˆ©ï¼šä½ å¯ä»¥ç›´æ¥æŠŠè¿™å¼ å›¾ç‰‡å‘ç»™æœ‹å‹ã€å‘åˆ°æœ‹å‹åœˆï¼Œæˆ–åˆ†äº«åˆ°å·¥ä½œç¾¤ï¼Œè®©åˆ«äººä¹Ÿèƒ½çœ‹åˆ°ä½ å‘ç°çš„é‡è¦èµ„è®¯&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/13 - v2.1.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è§£å†³é’‰é’‰çš„æ¨é€å®¹é‡é™åˆ¶å¯¼è‡´çš„æ–°é—»æ¨é€å¤±è´¥é—®é¢˜(é‡‡ç”¨åˆ†æ‰¹æ¨é€)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/04 - v2.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤dockeråœ¨æŸäº›æ¶æ„ä¸­æ— æ³•æ­£å¸¸è¿è¡Œçš„é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;æ­£å¼å‘å¸ƒå®˜æ–¹ Docker é•œåƒ wantcat/trendradarï¼Œæ”¯æŒå¤šæ¶æ„&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ– Docker éƒ¨ç½²æµç¨‹ï¼Œæ— éœ€æœ¬åœ°æ„å»ºå³å¯å¿«é€Ÿä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/30 - v2.1.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;æ ¸å¿ƒæ”¹è¿›&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é€»è¾‘ä¼˜åŒ–&lt;/strong&gt;ï¼šä»"æ¯æ¬¡æ‰§è¡Œéƒ½æ¨é€"æ”¹ä¸º"æ—¶é—´çª—å£å†…å¯æ§æ¨é€"&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ—¶é—´çª—å£æ§åˆ¶&lt;/strong&gt;ï¼šå¯è®¾å®šæ¨é€æ—¶é—´èŒƒå›´ï¼Œé¿å…éå·¥ä½œæ—¶é—´æ‰“æ‰°&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡å¯é€‰&lt;/strong&gt;ï¼šæ—¶é—´æ®µå†…æ”¯æŒå•æ¬¡æ¨é€æˆ–å¤šæ¬¡æ¨é€&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;æ›´æ–°æç¤º&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬åŠŸèƒ½é»˜è®¤å…³é—­ï¼Œéœ€æ‰‹åŠ¨åœ¨ config.yaml ä¸­å¼€å¯æ¨é€æ—¶é—´çª—å£æ§åˆ¶&lt;/li&gt; 
  &lt;li&gt;å‡çº§éœ€åŒæ—¶æ›´æ–° main.py å’Œ config.yaml ä¸¤ä¸ªæ–‡ä»¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/27 - v2.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æœ¬æ¬¡ç‰ˆæœ¬ä¸æ˜¯åŠŸèƒ½ä¿®å¤ï¼Œè€Œæ˜¯é‡è¦æé†’&lt;/li&gt; 
  &lt;li&gt;è¯·åŠ¡å¿…å¦¥å–„ä¿ç®¡å¥½ webhooksï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€ï¼Œä¸è¦å…¬å¼€&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ ä»¥ fork çš„æ–¹å¼å°†æœ¬é¡¹ç›®éƒ¨ç½²åœ¨ GitHub ä¸Šï¼Œè¯·å°† webhooks å¡«å…¥ GitHub Secretï¼Œè€Œé config.yaml&lt;/li&gt; 
  &lt;li&gt;å¦‚æœä½ å·²ç»æš´éœ²äº† webhooks æˆ–å°†å…¶å¡«å…¥äº† config.yamlï¼Œå»ºè®®åˆ é™¤åé‡æ–°ç”Ÿæˆ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/06 - v2.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¼˜åŒ– github page çš„ç½‘é¡µç‰ˆæ•ˆæœï¼Œæ–¹ä¾¿ç§»åŠ¨ç«¯ä½¿ç”¨&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/28 - v2.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é‡æ„ä»£ç &lt;/li&gt; 
  &lt;li&gt;è§£å†³ç‰ˆæœ¬å·å®¹æ˜“è¢«é—æ¼ä¿®æ”¹çš„é—®é¢˜&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/27 - v2.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;docker çš„ shell è„šæœ¬çš„æ¢è¡Œç¬¦ä¸º CRLF å¯¼è‡´çš„æ‰§è¡Œå¼‚å¸¸é—®é¢˜&lt;/li&gt; 
  &lt;li&gt;frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå¯¼è‡´æ–°é—»å‘é€ä¹Ÿä¸ºç©ºçš„é€»è¾‘é—®é¢˜&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¿®å¤åï¼Œå½“ä½ é€‰æ‹© frequency_words.txt ä¸ºç©ºæ—¶ï¼Œå°†&lt;strong&gt;æ¨é€æ‰€æœ‰æ–°é—»&lt;/strong&gt;ï¼Œä½†å—é™äºæ¶ˆæ¯æ¨é€å¤§å°é™åˆ¶ï¼Œè¯·åšå¦‚ä¸‹è°ƒæ•´ 
   &lt;ul&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸€ï¼šå…³é—­æ‰‹æœºæ¨é€ï¼Œåªé€‰æ‹© Github Pages å¸ƒç½®(è¿™æ˜¯èƒ½è·å¾—æœ€å®Œæ•´ä¿¡æ¯çš„æ–¹æ¡ˆï¼Œå°†æŠŠæ‰€æœ‰å¹³å°çš„çƒ­ç‚¹æŒ‰ç…§ä½ &lt;strong&gt;è‡ªå®šä¹‰çš„çƒ­æœç®—æ³•&lt;/strong&gt;è¿›è¡Œé‡æ–°æ’åº)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆäºŒï¼šå‡å°‘æ¨é€å¹³å°ï¼Œä¼˜å…ˆé€‰æ‹©&lt;strong&gt;ä¼ä¸šå¾®ä¿¡&lt;/strong&gt;æˆ–&lt;strong&gt;Telegram&lt;/strong&gt;ï¼Œè¿™ä¸¤ä¸ªæ¨é€æˆ‘åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½(å› ä¸ºåˆ†æ‰¹æ¨é€å½±å“æ¨é€ä½“éªŒï¼Œä¸”åªæœ‰è¿™ä¸¤ä¸ªå¹³å°åªç»™ä¸€ç‚¹ç‚¹æ¨é€å®¹é‡ï¼Œæ‰€ä»¥æ‰ä¸å¾—å·²åšäº†åˆ†æ‰¹æ¨é€åŠŸèƒ½ï¼Œä½†è‡³å°‘èƒ½ä¿è¯è·å¾—çš„ä¿¡æ¯å®Œæ•´)&lt;/li&gt; 
    &lt;li&gt;æ–¹æ¡ˆä¸‰ï¼šå¯ä¸æ–¹æ¡ˆäºŒç»“åˆï¼Œæ¨¡å¼é€‰æ‹© current æˆ– incremental å¯æœ‰æ•ˆå‡å°‘ä¸€æ¬¡æ€§æ¨é€çš„å†…å®¹&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/17 - v2.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;é‡å¤§é‡æ„&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é…ç½®ç®¡ç†é‡æ„ï¼šæ‰€æœ‰é…ç½®ç°åœ¨é€šè¿‡ &lt;code&gt;config/config.yaml&lt;/code&gt; æ–‡ä»¶ç®¡ç†ï¼ˆmain.py æˆ‘ä¾æ—§æ²¡æ‹†åˆ†ï¼Œæ–¹ä¾¿ä½ ä»¬å¤åˆ¶å‡çº§ï¼‰&lt;/li&gt; 
  &lt;li&gt;è¿è¡Œæ¨¡å¼å‡çº§ï¼šæ”¯æŒä¸‰ç§æ¨¡å¼ - &lt;code&gt;daily&lt;/code&gt;ï¼ˆå½“æ—¥æ±‡æ€»ï¼‰ã€&lt;code&gt;current&lt;/code&gt;ï¼ˆå½“å‰æ¦œå•ï¼‰ã€&lt;code&gt;incremental&lt;/code&gt;ï¼ˆå¢é‡ç›‘æ§ï¼‰&lt;/li&gt; 
  &lt;li&gt;Docker æ”¯æŒï¼šå®Œæ•´çš„ Docker éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒå®¹å™¨åŒ–è¿è¡Œ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - ä¸»é…ç½®æ–‡ä»¶ï¼ˆåº”ç”¨è®¾ç½®ã€çˆ¬è™«é…ç½®ã€é€šçŸ¥é…ç½®ã€å¹³å°é…ç½®ç­‰ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆç›‘æ§è¯æ±‡è®¾ç½®ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/09 - v1.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;åŠŸèƒ½æ–°å¢&lt;/strong&gt;ï¼šå¢åŠ å¢é‡æ¨é€(åœ¨ main.py å¤´éƒ¨é…ç½® FOCUS_NEW_ONLY)ï¼Œè¯¥å¼€å…³åªå…³å¿ƒæ–°è¯é¢˜è€ŒéæŒç»­çƒ­åº¦ï¼Œåªåœ¨æœ‰æ–°å†…å®¹æ—¶æ‰å‘é€šçŸ¥ã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ä¿®å¤é—®é¢˜&lt;/strong&gt;: æŸäº›æƒ…å†µä¸‹ï¼Œç”±äºæ–°é—»æœ¬èº«å«æœ‰ç‰¹æ®Šç¬¦å·å¯¼è‡´çš„å¶å‘æ€§æ’ç‰ˆå¼‚å¸¸ã€‚&lt;/p&gt; 
 &lt;h3&gt;2025/06/23 - v1.3.0&lt;/h3&gt; 
 &lt;p&gt;ä¼ä¸šå¾®ä¿¡ å’Œ Telegram çš„æ¨é€æ¶ˆæ¯æœ‰é•¿åº¦é™åˆ¶ï¼Œå¯¹æ­¤æˆ‘é‡‡ç”¨å°†æ¶ˆæ¯æ‹†åˆ†æ¨é€çš„æ–¹å¼ã€‚å¼€å‘æ–‡æ¡£è¯¦è§&lt;a href="https://developer.work.weixin.qq.com/document/path/91770"&gt;ä¼ä¸šå¾®ä¿¡&lt;/a&gt; å’Œ &lt;a href="https://core.telegram.org/bots/api"&gt;Telegram&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/21 - v1.2.1&lt;/h3&gt; 
 &lt;p&gt;åœ¨æœ¬ç‰ˆæœ¬ä¹‹å‰çš„æ—§ç‰ˆæœ¬ï¼Œä¸ä»… main.py éœ€è¦å¤åˆ¶æ›¿æ¢ï¼Œ crawler.yml ä¹Ÿéœ€è¦ä½ å¤åˆ¶æ›¿æ¢ &lt;a href="https://github.com/sansan0/TrendRadar/raw/master/.github/workflows/crawler.yml"&gt;https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/19 - v1.2.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;æ„Ÿè°¢ claude research æ•´ç†çš„å„å¹³å° api ,è®©æˆ‘å¿«é€Ÿå®Œæˆå„å¹³å°é€‚é…ï¼ˆè™½ç„¶ä»£ç æ›´å¤šå†—ä½™äº†~&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ”¯æŒ telegram ï¼Œä¼ä¸šå¾®ä¿¡ï¼Œé’‰é’‰æ¨é€æ¸ é“, æ”¯æŒå¤šæ¸ é“é…ç½®å’ŒåŒæ—¶æ¨é€&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/18 - v1.1.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;200 starâ­&lt;/strong&gt; äº†, ç»§ç»­ç»™å¤§ä¼™å„¿åŠ©å…´~è¿‘æœŸï¼Œåœ¨æˆ‘çš„"æ€‚æ¿"ä¸‹ï¼ŒæŒºå¤šäººåœ¨æˆ‘å…¬ä¼—å·ç‚¹èµåˆ†äº«æ¨èåŠ©åŠ›äº†æˆ‘ï¼Œæˆ‘éƒ½åœ¨åå°çœ‹è§äº†å…·ä½“è´¦å·çš„é¼“åŠ±æ•°æ®ï¼Œå¾ˆå¤šéƒ½æˆäº†å¤©ä½¿è½®è€ç²‰ï¼ˆæˆ‘ç©å…¬ä¼—å·æ‰ä¸€ä¸ªå¤šæœˆï¼Œè™½ç„¶æ³¨å†Œæ˜¯ä¸ƒå…«å¹´å‰çš„äº‹äº†å“ˆå“ˆï¼Œå±äºä¸Šè½¦æ—©ï¼Œå‘è½¦æ™šï¼‰ï¼Œä½†å› ä¸ºä½ ä»¬æ²¡æœ‰ç•™è¨€æˆ–ç§ä¿¡æˆ‘ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæ— æ³•ä¸€ä¸€å›åº”å¹¶æ„Ÿè°¢æ”¯æŒï¼Œåœ¨æ­¤ä¸€å¹¶è°¢è°¢ï¼&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é‡è¦çš„æ›´æ–°ï¼ŒåŠ äº†æƒé‡ï¼Œä½ ç°åœ¨çœ‹åˆ°çš„æ–°é—»éƒ½æ˜¯æœ€çƒ­ç‚¹æœ€æœ‰å…³æ³¨åº¦çš„å‡ºç°åœ¨æœ€ä¸Šé¢&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°æ–‡æ¡£ä½¿ç”¨ï¼Œå› ä¸ºè¿‘æœŸæ›´æ–°äº†å¾ˆå¤šåŠŸèƒ½ï¼Œè€Œä¸”ä¹‹å‰çš„ä½¿ç”¨æ–‡æ¡£æˆ‘å·æ‡’å†™çš„ç®€å•ï¼ˆè§ä¸‹é¢çš„ âš™ï¸ frequency_words.txt é…ç½®å®Œæ•´æ•™ç¨‹ï¼‰&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/16 - v1.0.0&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¢åŠ äº†ä¸€ä¸ªé¡¹ç›®æ–°ç‰ˆæœ¬æ›´æ–°æç¤ºï¼Œé»˜è®¤æ‰“å¼€ï¼Œå¦‚è¦å…³æ‰ï¼Œå¯ä»¥åœ¨ main.py ä¸­æŠŠ "FEISHU_SHOW_VERSION_UPDATE": True ä¸­çš„ True æ”¹æˆ False å³å¯&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/13+14&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å»æ‰äº†å…¼å®¹ä»£ç ï¼Œä¹‹å‰ fork çš„åŒå­¦ï¼Œç›´æ¥å¤åˆ¶ä»£ç ä¼šåœ¨å½“å¤©æ˜¾ç¤ºå¼‚å¸¸ï¼ˆç¬¬äºŒå¤©ä¼šæ¢å¤æ­£å¸¸ï¼‰&lt;/li&gt; 
  &lt;li&gt;feishu å’Œ html åº•éƒ¨å¢åŠ ä¸€ä¸ªæ–°å¢æ–°é—»æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/09&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;100 starâ­&lt;/strong&gt; äº†ï¼Œå†™ä¸ªå°åŠŸèƒ½ç»™å¤§ä¼™å„¿åŠ©åŠ©å…´ frequency_words.txt æ–‡ä»¶å¢åŠ äº†ä¸€ä¸ªã€å¿…é¡»è¯ã€‘åŠŸèƒ½ï¼Œä½¿ç”¨ + å·&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;å¿…é¡»è¯è¯­æ³•å¦‚ä¸‹ï¼š&lt;br /&gt; å”åƒ§æˆ–è€…çŒªå…«æˆ’å¿…é¡»åœ¨æ ‡é¢˜é‡ŒåŒæ—¶å‡ºç°ï¼Œæ‰ä¼šæ”¶å½•åˆ°æ¨é€æ–°é—»ä¸­&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
+çŒªå…«æˆ’
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;è¿‡æ»¤è¯çš„ä¼˜å…ˆçº§æ›´é«˜ï¼š&lt;br /&gt; å¦‚æœæ ‡é¢˜ä¸­è¿‡æ»¤è¯åŒ¹é…åˆ°å”åƒ§å¿µç»ï¼Œé‚£ä¹ˆå³ä½¿å¿…é¡»è¯é‡Œæœ‰å”åƒ§ï¼Œä¹Ÿä¸æ˜¾ç¤º&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+å”åƒ§
!å”åƒ§å¿µç»
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;2025/06/02&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ç½‘é¡µ&lt;/strong&gt;å’Œ&lt;strong&gt;é£ä¹¦æ¶ˆæ¯&lt;/strong&gt;æ”¯æŒæ‰‹æœºç›´æ¥è·³è½¬è¯¦æƒ…æ–°é—»&lt;/li&gt; 
  &lt;li&gt;ä¼˜åŒ–æ˜¾ç¤ºæ•ˆæœ + 1&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/05/26&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;é£ä¹¦æ¶ˆæ¯æ˜¾ç¤ºæ•ˆæœä¼˜åŒ–&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å‰&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/before.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å‰" width="400" /&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; ä¼˜åŒ–å&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/after.jpg" alt="é£ä¹¦æ¶ˆæ¯ç•Œé¢ - ä¼˜åŒ–å" width="400" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;é…ç½®å®Œæˆåï¼Œæ–°é—»æ•°æ®ä¸€å°æ—¶åæ‰ä¼šæ›´æ–°ï¼Œå¦‚æƒ³åŠ å¿«ï¼Œå¯å‚ç…§ã€ç¬¬4æ­¥ã€‘æ‰‹åŠ¨æµ‹è¯•é…ç½®æ•ˆæœ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fork æœ¬é¡¹ç›®&lt;/strong&gt;åˆ°ä½ çš„ GitHub è´¦æˆ·&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ç‚¹å‡»æœ¬é¡µé¢å³ä¸Šè§’çš„"Fork"æŒ‰é’®&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¾ç½® GitHub Secretsï¼ˆé€‰æ‹©ä½ éœ€è¦çš„å¹³å°ï¼‰&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;åœ¨ä½  Fork åçš„ä»“åº“ä¸­ï¼Œè¿›å…¥ &lt;code&gt;Settings&lt;/code&gt; &amp;gt; &lt;code&gt;Secrets and variables&lt;/code&gt; &amp;gt; &lt;code&gt;Actions&lt;/code&gt; &amp;gt; &lt;code&gt;New repository secret&lt;/code&gt;ï¼Œç„¶åæ ¹æ®éœ€è¦é…ç½®ä»¥ä¸‹ä»»ä¸€æˆ–å¤šä¸ªé€šçŸ¥å¹³å°ï¼š&lt;/p&gt; &lt;p&gt;å¯ä»¥åŒæ—¶é…ç½®å¤šä¸ªå¹³å°ï¼Œç³»ç»Ÿä¼šå‘æ‰€æœ‰é…ç½®çš„å¹³å°å‘é€é€šçŸ¥ã€‚&lt;/p&gt; &lt;p&gt;æ•ˆæœç±»ä¼¼ä¸‹å›¾ï¼Œä¸€ä¸ª name å¯¹åº”ä¸€ä¸ª secretï¼Œä¿å­˜å®Œå°±è¡Œï¼Œä½ é‡æ–°ç¼–è¾‘çœ‹ä¸åˆ° secret æ˜¯æ­£å¸¸æƒ…å†µã€‚&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/secrets.png" alt="GitHub Secrets" /&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ ä¼ä¸šå¾®ä¿¡æœºå™¨äºº&lt;/strong&gt;ï¼ˆé…ç½®æœ€ç®€å•æœ€è¿…é€Ÿï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„ä¼ä¸šå¾®ä¿¡æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;æ‰‹æœºç«¯è®¾ç½®ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;æ‰“å¼€ä¼ä¸šå¾®ä¿¡ App â†’ è¿›å…¥ç›®æ ‡å†…éƒ¨ç¾¤èŠ&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»å³ä¸Šè§’"â€¦"æŒ‰é’® â†’ é€‰æ‹©"æ¶ˆæ¯æ¨é€"&lt;/li&gt; 
    &lt;li&gt;ç‚¹å‡»"æ·»åŠ " â†’ åç§°è¾“å…¥"TrendRadar"&lt;/li&gt; 
    &lt;li&gt;å¤åˆ¶ Webhook åœ°å€ï¼Œç‚¹å‡»ä¿å­˜ï¼Œå¤åˆ¶çš„å†…å®¹é…ç½®åˆ°ä¸Šæ–¹çš„ GitHub Secret ä¸­&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;PC ç«¯è®¾ç½®æµç¨‹ç±»ä¼¼&lt;/h4&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é£ä¹¦æœºå™¨äºº&lt;/strong&gt;ï¼ˆæ¶ˆæ¯æ˜¾ç¤ºæœ€å‹å¥½ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„é£ä¹¦æœºå™¨äºº Webhook åœ°å€(è¯¥é“¾æ¥å¼€å¤´ç±»ä¼¼ &lt;a href="https://www.feishu.cn/flow/api/trigger-webhook/"&gt;https://www.feishu.cn/flow/api/trigger-webhook/&lt;/a&gt;********)&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;æœ‰ä¸¤ä¸ªæ–¹æ¡ˆï¼Œ&lt;strong&gt;æ–¹æ¡ˆä¸€&lt;/strong&gt;é…ç½®ç®€å•ï¼Œ&lt;strong&gt;æ–¹æ¡ˆäºŒ&lt;/strong&gt;é…ç½®å¤æ‚(ä½†æ˜¯ç¨³å®šæ¨é€)&lt;/p&gt; 
   &lt;p&gt;å…¶ä¸­æ–¹æ¡ˆä¸€ï¼Œç”± &lt;strong&gt;ziventian&lt;/strong&gt;å‘ç°å¹¶æä¾›å»ºè®®ï¼Œåœ¨è¿™é‡Œæ„Ÿè°¢ä»–ï¼Œé»˜è®¤æ˜¯ä¸ªäººæ¨é€ï¼Œä¹Ÿå¯ä»¥é…ç½®ç¾¤ç»„æ¨é€æ“ä½œ&lt;a href="https://github.com/sansan0/TrendRadar/issues/97"&gt;#97&lt;/a&gt; ï¼Œ&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆä¸€ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;å¯¹éƒ¨åˆ†äººå­˜åœ¨é¢å¤–æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥"ç³»ç»Ÿé”™è¯¯"ã€‚éœ€è¦æ‰‹æœºç«¯æœç´¢ä¸‹æœºå™¨äººï¼Œç„¶åå¼€å¯é£ä¹¦æœºå™¨äººåº”ç”¨(è¯¥å»ºè®®æ¥è‡ªäºç½‘å‹ï¼Œå¯å‚è€ƒ)&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-command"&gt;https://botbuilder.feishu.cn/home/my-command&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººæŒ‡ä»¤"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©è§¦å‘å™¨"ï¼Œå¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="6"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "é€šè¿‡å®˜æ–¹æœºå™¨äººå‘æ¶ˆæ¯"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="9"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 4 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;æ–¹æ¡ˆäºŒï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ç”µè„‘æµè§ˆå™¨æ‰“å¼€ &lt;a href="https://botbuilder.feishu.cn/home/my-app"&gt;https://botbuilder.feishu.cn/home/my-app&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"æ–°å»ºæœºå™¨äººåº”ç”¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;è¿›å…¥åˆ›å»ºçš„åº”ç”¨åï¼Œç‚¹å‡»"æµç¨‹æ¶‰åŠ" &amp;gt; "åˆ›å»ºæµç¨‹" &amp;gt; "é€‰æ‹©è§¦å‘å™¨"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;å¾€ä¸‹æ»‘åŠ¨ï¼Œç‚¹å‡»"Webhook è§¦å‘"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ­¤æ—¶ä½ ä¼šçœ‹åˆ°"Webhook åœ°å€"ï¼ŒæŠŠè¿™ä¸ªé“¾æ¥å…ˆå¤åˆ¶åˆ°æœ¬åœ°è®°äº‹æœ¬æš‚å­˜ï¼Œç»§ç»­æ¥ä¸‹æ¥çš„æ“ä½œ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"å‚æ•°"é‡Œé¢æ”¾ä¸Šä¸‹é¢çš„å†…å®¹ï¼Œç„¶åç‚¹å‡»"å®Œæˆ"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{å†…å®¹}}",
    "timestamp": "{{å†…å®¹}}",
    "report_type": "{{å†…å®¹}}",
    "text": "{{å†…å®¹}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="7"&gt; 
    &lt;li&gt; &lt;p&gt;ç‚¹å‡»"é€‰æ‹©æ“ä½œ" &amp;gt; "å‘é€é£ä¹¦æ¶ˆæ¯"ï¼Œå‹¾é€‰ "ç¾¤æ¶ˆæ¯"ï¼Œç„¶åç‚¹å‡»ä¸‹é¢çš„è¾“å…¥æ¡†ï¼Œç‚¹å‡»"æˆ‘ç®¡ç†çš„ç¾¤ç»„"ï¼ˆå¦‚æœæ²¡æœ‰ç¾¤ç»„ï¼Œä½ å¯ä»¥åœ¨é£ä¹¦ app ä¸Šåˆ›å»ºç¾¤ç»„ï¼‰&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æ¶ˆæ¯æ ‡é¢˜å¡«å†™"TrendRadar çƒ­ç‚¹ç›‘æ§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;æœ€å…³é”®çš„éƒ¨åˆ†æ¥äº†ï¼Œç‚¹å‡» + æŒ‰é’®ï¼Œé€‰æ‹©"Webhook è§¦å‘"ï¼Œç„¶åæŒ‰ç…§ä¸‹é¢çš„å›¾ç‰‡æ‘†æ”¾&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="é£ä¹¦æœºå™¨äººé…ç½®ç¤ºä¾‹" /&gt;&lt;/p&gt; 
   &lt;ol start="10"&gt; 
    &lt;li&gt;é…ç½®å®Œæˆåï¼Œå°†ç¬¬ 5 æ­¥å¤åˆ¶çš„ Webhook åœ°å€é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é’‰é’‰æœºå™¨äºº&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;å€¼ï¼šä½ çš„é’‰é’‰æœºå™¨äºº Webhook åœ°å€&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äººï¼ˆä»… PC ç«¯æ”¯æŒï¼‰&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æ‰“å¼€é’‰é’‰ PC å®¢æˆ·ç«¯ï¼Œè¿›å…¥ç›®æ ‡ç¾¤èŠ&lt;/li&gt; 
      &lt;li&gt;ç‚¹å‡»ç¾¤è®¾ç½®å›¾æ ‡ï¼ˆâš™ï¸ï¼‰â†’ å¾€ä¸‹ç¿»æ‰¾åˆ°"æœºå™¨äºº"ç‚¹å¼€&lt;/li&gt; 
      &lt;li&gt;é€‰æ‹©"æ·»åŠ æœºå™¨äºº" â†’ "è‡ªå®šä¹‰"&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;å®‰å…¨è®¾ç½®&lt;/strong&gt;ï¼š 
       &lt;ul&gt; 
        &lt;li&gt;&lt;strong&gt;è‡ªå®šä¹‰å…³é”®è¯&lt;/strong&gt;ï¼šè®¾ç½® "çƒ­ç‚¹"&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;å®Œæˆè®¾ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å‹¾é€‰æœåŠ¡æ¡æ¬¾åè®® â†’ ç‚¹å‡»"å®Œæˆ"&lt;/li&gt; 
      &lt;li&gt;å¤åˆ¶è·å¾—çš„ Webhook URL&lt;/li&gt; 
      &lt;li&gt;å°† URL é…ç½®åˆ° GitHub Secrets ä¸­çš„ &lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šç§»åŠ¨ç«¯åªèƒ½æ¥æ”¶æ¶ˆæ¯ï¼Œæ— æ³•åˆ›å»ºæ–°æœºå™¨äººã€‚&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ Telegram Bot&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt; - ä½ çš„ Telegram Bot Token&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt; - ä½ çš„ Telegram Chat ID&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;æœºå™¨äººè®¾ç½®æ­¥éª¤ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆ›å»ºæœºå™¨äºº&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;åœ¨ Telegram ä¸­æœç´¢ &lt;code&gt;@BotFather&lt;/code&gt;ï¼ˆå¤§å°å†™æ³¨æ„ï¼Œæœ‰è“è‰²å¾½ç« å‹¾å‹¾ï¼Œæœ‰ç±»ä¼¼ 37849827 monthly usersï¼Œè¿™ä¸ªæ‰æ˜¯å®˜æ–¹çš„ï¼Œæœ‰ä¸€äº›ä»¿å®˜æ–¹çš„è´¦å·æ³¨æ„è¾¨åˆ«ï¼‰&lt;/li&gt; 
      &lt;li&gt;å‘é€ &lt;code&gt;/newbot&lt;/code&gt; å‘½ä»¤åˆ›å»ºæ–°æœºå™¨äºº&lt;/li&gt; 
      &lt;li&gt;è®¾ç½®æœºå™¨äººåç§°ï¼ˆå¿…é¡»ä»¥"bot"ç»“å°¾ï¼Œå¾ˆå®¹æ˜“é‡åˆ°é‡å¤åå­—ï¼Œæ‰€ä»¥ä½ è¦ç»å°½è„‘æ±æƒ³ä¸åŒçš„åå­—ï¼‰&lt;/li&gt; 
      &lt;li&gt;è·å– Bot Tokenï¼ˆæ ¼å¼å¦‚ï¼š&lt;code&gt;123456789:AAHfiqksKZ8WmR2zSjiQ7_v4TMAKdiHm9T0&lt;/code&gt;ï¼‰&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è·å– Chat ID&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•ä¸€ï¼šé€šè¿‡å®˜æ–¹ API è·å–&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;å…ˆå‘ä½ çš„æœºå™¨äººå‘é€ä¸€æ¡æ¶ˆæ¯&lt;/li&gt; 
      &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;https://api.telegram.org/bot&amp;lt;ä½ çš„Bot Token&amp;gt;/getUpdates&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;åœ¨è¿”å›çš„ JSON ä¸­æ‰¾åˆ° &lt;code&gt;"chat":{"id":æ•°å­—}&lt;/code&gt; ä¸­çš„æ•°å­—&lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æ–¹æ³•äºŒï¼šä½¿ç”¨ç¬¬ä¸‰æ–¹å·¥å…·&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;æœç´¢ &lt;code&gt;@userinfobot&lt;/code&gt; å¹¶å‘é€ &lt;code&gt;/start&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;è·å–ä½ çš„ç”¨æˆ· ID ä½œä¸º Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®åˆ° GitHub&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 1 æ­¥è·å¾—çš„ Bot Token&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ï¼šå¡«å…¥ç¬¬ 2 æ­¥è·å¾—çš„ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ é‚®ä»¶æ¨é€&lt;/strong&gt;ï¼ˆæ”¯æŒæ‰€æœ‰ä¸»æµé‚®ç®±ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ³¨æ„äº‹é¡¹ï¼šä¸ºé˜²æ­¢é‚®ä»¶ç¾¤å‘åŠŸèƒ½è¢«&lt;strong&gt;æ»¥ç”¨&lt;/strong&gt;ï¼Œå½“å‰çš„ç¾¤å‘æ˜¯æ‰€æœ‰æ”¶ä»¶äººéƒ½èƒ½çœ‹åˆ°å½¼æ­¤çš„é‚®ç®±åœ°å€ï¼Œé€‚åˆç†Ÿäººé—´äº¤æµèµ„è®¯ã€‚&lt;/li&gt; 
    &lt;li&gt;ä»…ä¾›å‚è€ƒï¼šè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼Œé‚®ç®±æ–¹é¢å¹¶æ²¡æœ‰ä¸€ä¸€éªŒè¯ï¼Œæ˜¯æŒ‰ç…§ SMTP çš„æ ‡å‡†é…ç½®çš„&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret é…ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_FROM&lt;/code&gt; - å‘ä»¶äººé‚®ç®±åœ°å€&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; - é‚®ç®±å¯†ç æˆ–æˆæƒç &lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_TO&lt;/code&gt; - æ”¶ä»¶äººé‚®ç®±åœ°å€ï¼ˆå¤šä¸ªæ”¶ä»¶äººç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰ä¹Ÿå¯ä»¥å’Œ EMAIL_FROM ä¸€æ ·ï¼Œè‡ªå·±å‘é€ç»™è‡ªå·±&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt; - SMTPæœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/li&gt; 
    &lt;li&gt;åç§°ï¼š&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt; - SMTPç«¯å£ï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™è‡ªåŠ¨è¯†åˆ«ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é‚®ç®±è®¾ç½®ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;QQé‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½• QQé‚®ç®±ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ è´¦æˆ·&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ POP3/SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆæˆæƒç ï¼ˆ16ä½å­—æ¯ï¼‰&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç ï¼Œè€Œé QQ å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;Gmailï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;å¼€å¯ä¸¤æ­¥éªŒè¯&lt;/li&gt; 
    &lt;li&gt;ç”Ÿæˆåº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™åº”ç”¨ä¸“ç”¨å¯†ç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;163/126é‚®ç®±ï¼š&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ç™»å½•ç½‘é¡µç‰ˆ â†’ è®¾ç½® â†’ POP3/SMTP/IMAP&lt;/li&gt; 
    &lt;li&gt;å¼€å¯ SMTP æœåŠ¡&lt;/li&gt; 
    &lt;li&gt;è®¾ç½®å®¢æˆ·ç«¯æˆæƒç &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; å¡«å†™æˆæƒç &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;é«˜çº§é…ç½®&lt;/strong&gt;ï¼š å¦‚æœè‡ªåŠ¨è¯†åˆ«å¤±è´¥ï¼Œå¯æ‰‹åŠ¨é…ç½® SMTPï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ï¼šå¦‚ smtp.gmail.com&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ï¼šå¦‚ 587ï¼ˆTLSï¼‰æˆ– 465ï¼ˆSSLï¼‰&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;å¤šæ”¶ä»¶äººè®¾ç½®&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;EMAIL_TO="&lt;a href="mailto:user1@example.com"&gt;user1@example.com&lt;/a&gt;,&lt;a href="mailto:user2@example.com"&gt;user2@example.com&lt;/a&gt;,&lt;a href="mailto:user3@example.com"&gt;user3@example.com&lt;/a&gt;"&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;ğŸ‘‰ ntfy æ¨é€&lt;/strong&gt;ï¼ˆå¼€æºå…è´¹ï¼Œæ”¯æŒè‡ªæ‰˜ç®¡ï¼‰&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;æ–¹å¼ä¸€ï¼šå…è´¹ä½¿ç”¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰ ğŸ†“&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ç‰¹ç‚¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… æ— éœ€æ³¨å†Œè´¦å·ï¼Œç«‹å³ä½¿ç”¨&lt;/li&gt; 
    &lt;li&gt;âœ… æ¯å¤© 250 æ¡æ¶ˆæ¯ï¼ˆè¶³å¤Ÿ 90% ç”¨æˆ·ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… Topic åç§°å³"å¯†ç "ï¼ˆéœ€é€‰æ‹©ä¸æ˜“çŒœæµ‹çš„åç§°ï¼‰&lt;/li&gt; 
    &lt;li&gt;âš ï¸ æ¶ˆæ¯æœªåŠ å¯†ï¼Œä¸é€‚åˆæ•æ„Ÿä¿¡æ¯, ä½†é€‚åˆæˆ‘ä»¬è¿™ä¸ªé¡¹ç›®çš„ä¸æ•æ„Ÿä¿¡æ¯&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;å¿«é€Ÿå¼€å§‹ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä¸‹è½½ ntfy åº”ç”¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Androidï¼š&lt;a href="https://play.google.com/store/apps/details?id=io.heckel.ntfy"&gt;Google Play&lt;/a&gt; / &lt;a href="https://f-droid.org/en/packages/io.heckel.ntfy/"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;iOSï¼š&lt;a href="https://apps.apple.com/us/app/ntfy/id1625396347"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;æ¡Œé¢ï¼šè®¿é—® &lt;a href="https://ntfy.sh"&gt;ntfy.sh&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;è®¢é˜…ä¸»é¢˜&lt;/strong&gt;ï¼ˆé€‰æ‹©ä¸€ä¸ªéš¾çŒœçš„åç§°ï¼‰ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code&gt;å»ºè®®æ ¼å¼ï¼štrendradar-{ä½ çš„åå­—ç¼©å†™}-{éšæœºæ•°å­—}

ä¸èƒ½ä½¿ç”¨ä¸­æ–‡

âœ… å¥½ä¾‹å­ï¼štrendradar-zs-8492
âŒ åä¾‹å­ï¼šnewsã€alertsï¼ˆå¤ªå®¹æ˜“è¢«çŒœåˆ°ï¼‰
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® GitHub Secret&lt;/strong&gt;ï¼š&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOPIC&lt;/code&gt;ï¼šå¡«å†™ä½ åˆšæ‰è®¢é˜…çš„ä¸»é¢˜åç§°&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_SERVER_URL&lt;/code&gt;ï¼šç•™ç©ºï¼ˆé»˜è®¤ä½¿ç”¨ ntfy.shï¼‰&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOKEN&lt;/code&gt;ï¼šç•™ç©º&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;æµ‹è¯•&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -d "æµ‹è¯•æ¶ˆæ¯" ntfy.sh/ä½ çš„ä¸»é¢˜åç§°
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;h3&gt;æ–¹å¼äºŒï¼šè‡ªæ‰˜ç®¡ï¼ˆå®Œå…¨éšç§æ§åˆ¶ï¼‰ ğŸ”’&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;é€‚åˆäººç¾¤&lt;/strong&gt;ï¼šæœ‰æœåŠ¡å™¨ã€è¿½æ±‚å®Œå…¨éšç§ã€æŠ€æœ¯èƒ½åŠ›å¼º&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ä¼˜åŠ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;âœ… å®Œå…¨å¼€æºï¼ˆApache 2.0 + GPLv2ï¼‰&lt;/li&gt; 
    &lt;li&gt;âœ… æ•°æ®å®Œå…¨è‡ªä¸»æ§åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… æ— ä»»ä½•é™åˆ¶&lt;/li&gt; 
    &lt;li&gt;âœ… é›¶è´¹ç”¨&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ä¸€é”®éƒ¨ç½²&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name ntfy \
  -p 80:80 \
  -v /var/cache/ntfy:/var/cache/ntfy \
  binwiederhier/ntfy \
  serve --cache-file /var/cache/ntfy/cache.db
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;é…ç½® TrendRadar&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;NTFY_SERVER_URL: https://ntfy.yourdomain.com
NTFY_TOPIC: trendradar-alerts  # è‡ªæ‰˜ç®¡å¯ç”¨ç®€å•åç§°
NTFY_TOKEN: tk_your_token  # å¯é€‰ï¼šå¯ç”¨è®¿é—®æ§åˆ¶
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;åœ¨åº”ç”¨ä¸­è®¢é˜…&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç‚¹å‡»"Use another server"&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä½ çš„æœåŠ¡å™¨åœ°å€&lt;/li&gt; 
    &lt;li&gt;è¾“å…¥ä¸»é¢˜åç§°&lt;/li&gt; 
    &lt;li&gt;ï¼ˆå¯é€‰ï¼‰è¾“å…¥ç™»å½•å‡­æ®&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;å¸¸è§é—®é¢˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q1: å…è´¹ç‰ˆå¤Ÿç”¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;æ¯å¤© 250 æ¡æ¶ˆæ¯å¯¹å¤§å¤šæ•°ç”¨æˆ·è¶³å¤Ÿã€‚æŒ‰ 30 åˆ†é’ŸæŠ“å–ä¸€æ¬¡è®¡ç®—ï¼Œæ¯å¤©çº¦ 48 æ¬¡æ¨é€ï¼Œå®Œå…¨å¤Ÿç”¨ã€‚&lt;/p&gt; 
   &lt;/details&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q2: Topic åç§°çœŸçš„å®‰å…¨å—ï¼Ÿ&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;å¦‚æœä½ é€‰æ‹©éšæœºçš„ã€è¶³å¤Ÿé•¿çš„åç§°ï¼ˆå¦‚ &lt;code&gt;trendradar-zs-8492-news&lt;/code&gt;ï¼‰ï¼Œæš´åŠ›ç ´è§£å‡ ä¹ä¸å¯èƒ½ï¼š&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ntfy æœ‰ä¸¥æ ¼çš„é€Ÿç‡é™åˆ¶ï¼ˆ1 ç§’ 1 æ¬¡è¯·æ±‚ï¼‰&lt;/li&gt; 
     &lt;li&gt;64 ä¸ªå­—ç¬¦é€‰æ‹©ï¼ˆA-Z, a-z, 0-9, _, -ï¼‰&lt;/li&gt; 
     &lt;li&gt;10 ä½éšæœºå­—ç¬¦ä¸²æœ‰ 64^10 ç§å¯èƒ½æ€§ï¼ˆéœ€è¦æ•°å¹´æ‰èƒ½ç ´è§£ï¼‰&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/details&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;æ¨èé€‰æ‹©ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;ç”¨æˆ·ç±»å‹&lt;/th&gt; 
      &lt;th&gt;æ¨èæ–¹æ¡ˆ&lt;/th&gt; 
      &lt;th&gt;ç†ç”±&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æ™®é€šç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸€ï¼ˆå…è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;ç®€å•å¿«é€Ÿï¼Œå¤Ÿç”¨&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;æŠ€æœ¯ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼äºŒï¼ˆè‡ªæ‰˜ç®¡ï¼‰&lt;/td&gt; 
      &lt;td&gt;å®Œå…¨æ§åˆ¶ï¼Œæ— é™åˆ¶&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;é«˜é¢‘ç”¨æˆ·&lt;/td&gt; 
      &lt;td&gt;æ–¹å¼ä¸‰ï¼ˆä»˜è´¹ï¼‰&lt;/td&gt; 
      &lt;td&gt;è¿™ä¸ªè‡ªå·±å»å®˜ç½‘çœ‹å§&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;p&gt;&lt;strong&gt;ç›¸å…³é“¾æ¥ï¼š&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/"&gt;ntfy å®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/install/"&gt;è‡ªæ‰˜ç®¡æ•™ç¨‹&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/binwiederhier/ntfy"&gt;GitHub ä»“åº“&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®è¯´æ˜ï¼š&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;æ¨é€è®¾ç½®&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;config/config.yaml&lt;/a&gt; ä¸­é…ç½®æ¨é€æ¨¡å¼å’Œé€šçŸ¥é€‰é¡¹&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;å…³é”®è¯è®¾ç½®&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;config/frequency_words.txt&lt;/a&gt; ä¸­æ·»åŠ ä½ å…³å¿ƒçš„å…³é”®è¯&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;æ¨é€é¢‘ç‡è°ƒæ•´&lt;/strong&gt;ï¼šåœ¨ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/.github/workflows/crawler.yml"&gt;.github/workflows/crawler.yml&lt;/a&gt; è¯·è°¨æ…è°ƒæ•´ï¼Œåˆ«è´ªå¿ƒ&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šå»ºè®®åªè°ƒæ•´æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜çš„é…ç½®é¡¹ï¼Œå…¶ä»–é€‰é¡¹ä¸»è¦ä¾›ä½œè€…å¼€å‘æ—¶æµ‹è¯•ä½¿ç”¨&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ‰‹åŠ¨æµ‹è¯•æ–°é—»æ¨é€&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;æˆ‘è¿™é‡Œæ˜¯æ‹¿æˆ‘çš„é¡¹ç›®ä¸¾ä¾‹ï¼Œä½ è¦å»ä½ &lt;strong&gt;fork&lt;/strong&gt;çš„é¡¹ç›®åšæµ‹è¯•&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;è¿›å…¥ Actions&lt;/strong&gt;ï¼š&lt;a href="https://github.com/sansan0/TrendRadar/actions"&gt;https://github.com/sansan0/TrendRadar/actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;æ‰¾åˆ° "Hot News Crawler" çš„ç‚¹è¿›å»ï¼Œå¦‚æœçœ‹ä¸åˆ°è¯¥å­—æ ·ï¼Œé‚£ä¹ˆå‚ç…§&lt;a href="https://github.com/sansan0/TrendRadar/issues/109"&gt;#109&lt;/a&gt;è§£å†³&lt;/li&gt; 
   &lt;li&gt;ç‚¹å‡» "Run workflow" æŒ‰é’®è¿è¡Œï¼Œç­‰å¾… 1 åˆ†é’Ÿå·¦å³æ•°æ®åˆ°ä½ æ‰‹æœºä¸Š&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ³ Docker éƒ¨ç½²&lt;/h2&gt; 
&lt;h4&gt;æ–¹å¼ä¸€ï¼šå¿«é€Ÿä½“éªŒï¼ˆä¸€è¡Œå‘½ä»¤ï¼‰&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Linux/macOS ç³»ç»Ÿï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºé…ç½®ç›®å½•å¹¶ä¸‹è½½é…ç½®æ–‡ä»¶
mkdir -p config output
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æˆ–è€…&lt;strong&gt;æ‰‹åŠ¨åˆ›å»º&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;åœ¨å½“å‰ç›®å½•åˆ›å»º &lt;code&gt;config&lt;/code&gt; æ–‡ä»¶å¤¹&lt;/li&gt; 
 &lt;li&gt;ä¸‹è½½é…ç½®æ–‡ä»¶ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;è®¿é—® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml&lt;/a&gt; â†’ å³é”®"å¦å­˜ä¸º" â†’ ä¿å­˜åˆ° &lt;code&gt;config\config.yaml&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;è®¿é—® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt&lt;/a&gt; â†’ å³é”®"å¦å­˜ä¸º" â†’ ä¿å­˜åˆ° &lt;code&gt;config\frequency_words.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;å®Œæˆåçš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;å½“å‰ç›®å½•/
â””â”€â”€ config/
    â”œâ”€â”€ config.yaml
    â””â”€â”€ frequency_words.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name trend-radar \
  -v ./config:/app/config:ro \
  -v ./output:/app/output \
  -e FEISHU_WEBHOOK_URL="ä½ çš„é£ä¹¦webhook" \
  -e DINGTALK_WEBHOOK_URL="ä½ çš„é’‰é’‰webhook" \
  -e WEWORK_WEBHOOK_URL="ä½ çš„ä¼ä¸šå¾®ä¿¡webhook" \
  -e TELEGRAM_BOT_TOKEN="ä½ çš„telegram_bot_token" \
  -e TELEGRAM_CHAT_ID="ä½ çš„telegram_chat_id" \
  -e EMAIL_FROM="ä½ çš„å‘ä»¶é‚®ç®±" \
  -e EMAIL_PASSWORD="ä½ çš„é‚®ç®±å¯†ç æˆ–æˆæƒç " \
  -e EMAIL_TO="æ”¶ä»¶äººé‚®ç®±" \
  -e CRON_SCHEDULE="*/30 * * * *" \
  -e RUN_MODE="cron" \
  -e IMMEDIATE_RUN="true" \
  wantcat/trendradar:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æ–¹å¼äºŒï¼šä½¿ç”¨ docker-composeï¼ˆæ¨èï¼‰&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;åˆ›å»ºé¡¹ç›®ç›®å½•å’Œé…ç½®&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºç›®å½•ç»“æ„
mkdir -p trendradar/{config,docker}
cd trendradar

# ä¸‹è½½é…ç½®æ–‡ä»¶æ¨¡æ¿
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/

# ä¸‹è½½ docker-compose é…ç½®
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/.env
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;å®Œæˆåçš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;å½“å‰ç›®å½•/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ frequency_words.txt
â””â”€â”€ docker/
    â”œâ”€â”€ .env
    â””â”€â”€ docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®æ–‡ä»¶è¯´æ˜&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - åº”ç”¨ä¸»é…ç½®ï¼ˆæŠ¥å‘Šæ¨¡å¼ã€æ¨é€è®¾ç½®ç­‰ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - å…³é”®è¯é…ç½®ï¼ˆè®¾ç½®ä½ å…³å¿ƒçš„çƒ­ç‚¹è¯æ±‡ï¼‰&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - ç¯å¢ƒå˜é‡é…ç½®ï¼ˆwebhook URLs å’Œå®šæ—¶ä»»åŠ¡ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;âš™ï¸ ç¯å¢ƒå˜é‡è¦†ç›–æœºåˆ¶ï¼ˆv3.0.5+ï¼‰&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;å¦‚æœä½ åœ¨ NAS æˆ–å…¶ä»– Docker ç¯å¢ƒä¸­é‡åˆ°&lt;strong&gt;ä¿®æ”¹ &lt;code&gt;config.yaml&lt;/code&gt; åé…ç½®ä¸ç”Ÿæ•ˆ&lt;/strong&gt;çš„é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ç›´æ¥è¦†ç›–é…ç½®ï¼š&lt;/p&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;ç¯å¢ƒå˜é‡&lt;/th&gt; 
     &lt;th&gt;å¯¹åº”é…ç½®&lt;/th&gt; 
     &lt;th&gt;ç¤ºä¾‹å€¼&lt;/th&gt; 
     &lt;th&gt;è¯´æ˜&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;ENABLE_CRAWLER&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;crawler.enable_crawler&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ˜¯å¦å¯ç”¨çˆ¬è™«&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;ENABLE_NOTIFICATION&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.enable_notification&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ˜¯å¦å¯ç”¨é€šçŸ¥&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;REPORT_MODE&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;report.mode&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;daily&lt;/code&gt; / &lt;code&gt;incremental&lt;/code&gt; / &lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æŠ¥å‘Šæ¨¡å¼&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_ENABLED&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.enabled&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;true&lt;/code&gt; / &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€æ—¶é—´çª—å£å¼€å…³&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_START&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.time_range.start&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;08:00&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€å¼€å§‹æ—¶é—´&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;PUSH_WINDOW_END&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.push_window.time_range.end&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;22:00&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;æ¨é€ç»“æŸæ—¶é—´&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;notification.webhooks.feishu_url&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;&lt;code&gt;https://...&lt;/code&gt;&lt;/td&gt; 
     &lt;td&gt;é£ä¹¦ Webhook&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; &lt;p&gt;&lt;strong&gt;é…ç½®ä¼˜å…ˆçº§&lt;/strong&gt;ï¼šç¯å¢ƒå˜é‡ &amp;gt; config.yaml&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ–¹æ³•&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä¿®æ”¹ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶å¡«å†™éœ€è¦çš„é…ç½®&lt;/li&gt; 
   &lt;li&gt;æˆ–åœ¨ NAS/ç¾¤æ™– Docker ç®¡ç†ç•Œé¢çš„"ç¯å¢ƒå˜é‡"ä¸­ç›´æ¥æ·»åŠ &lt;/li&gt; 
   &lt;li&gt;é‡å¯å®¹å™¨åç”Ÿæ•ˆï¼š&lt;code&gt;docker-compose restart&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨æœåŠ¡&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æ‹‰å–æœ€æ–°é•œåƒå¹¶å¯åŠ¨
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŸ¥çœ‹è¿è¡ŒçŠ¶æ€&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹æ—¥å¿—
docker logs -f trend-radar

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker ps | grep trend-radar
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;æ–¹å¼ä¸‰ï¼šæœ¬åœ°æ„å»ºï¼ˆå¼€å‘è€…é€‰é¡¹ï¼‰&lt;/h4&gt; 
&lt;p&gt;å¦‚æœéœ€è¦è‡ªå®šä¹‰ä¿®æ”¹ä»£ç æˆ–æ„å»ºè‡ªå·±çš„é•œåƒï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å…‹éš†é¡¹ç›®
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar

# ä¿®æ”¹é…ç½®æ–‡ä»¶
vim config/config.yaml
vim config/frequency_words.txt

# ä½¿ç”¨æ„å»ºç‰ˆæœ¬çš„ docker-compose
cd docker
cp docker-compose-build.yml docker-compose.yml

# æ„å»ºå¹¶å¯åŠ¨
docker-compose build
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;é•œåƒæ›´æ–°&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ–¹å¼ä¸€ï¼šæ‰‹åŠ¨æ›´æ–°
docker pull wantcat/trendradar:latest
docker-compose down
docker-compose up -d

# æ–¹å¼äºŒï¼šä½¿ç”¨ docker-compose æ›´æ–°
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æœåŠ¡ç®¡ç†å‘½ä»¤&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥çœ‹è¿è¡ŒçŠ¶æ€
docker exec -it trend-radar python manage.py status

# æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡çˆ¬è™«
docker exec -it trend-radar python manage.py run

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker exec -it trend-radar python manage.py logs

# æ˜¾ç¤ºå½“å‰é…ç½®
docker exec -it trend-radar python manage.py config

# æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
docker exec -it trend-radar python manage.py files

# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
docker exec -it trend-radar python manage.py help

# é‡å¯å®¹å™¨
docker restart trend-radar

# åœæ­¢å®¹å™¨
docker stop trend-radar

# åˆ é™¤å®¹å™¨ï¼ˆä¿ç•™æ•°æ®ï¼‰
docker rm trend-radar
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æ•°æ®æŒä¹…åŒ–&lt;/h4&gt; 
&lt;p&gt;ç”Ÿæˆçš„æŠ¥å‘Šå’Œæ•°æ®é»˜è®¤ä¿å­˜åœ¨ &lt;code&gt;./output&lt;/code&gt; ç›®å½•ä¸‹ï¼Œå³ä½¿å®¹å™¨é‡å¯æˆ–åˆ é™¤ï¼Œæ•°æ®ä¹Ÿä¼šä¿ç•™ã€‚&lt;/p&gt; 
&lt;h4&gt;æ•…éšœæ’æŸ¥&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker inspect trend-radar

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs --tail 100 trend-radar

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker exec -it trend-radar /bin/bash

# éªŒè¯é…ç½®æ–‡ä»¶
docker exec -it trend-radar ls -la /app/config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ¤– AI æ™ºèƒ½åˆ†æéƒ¨ç½²&lt;/h2&gt; 
&lt;p&gt;TrendRadar v3.0.0 æ–°å¢äº†åŸºäº &lt;strong&gt;MCP (Model Context Protocol)&lt;/strong&gt; çš„ AI åˆ†æåŠŸèƒ½ï¼Œè®©ä½ å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€ä¸æ–°é—»æ•°æ®å¯¹è¯ï¼Œè¿›è¡Œæ·±åº¦åˆ†æã€‚ä½¿ç”¨ &lt;strong&gt;AI åŠŸèƒ½&lt;/strong&gt; çš„æœ€ä½³å‰ææ˜¯å·²ä½¿ç”¨æœ¬é¡¹ç›®è‡³å°‘è¿è¡Œä¸€å¤©(ç§¯ç´¯æ–°é—»æ•°æ®)&lt;/p&gt; 
&lt;h3&gt;1. å¿«é€Ÿéƒ¨ç½²&lt;/h3&gt; 
&lt;p&gt;Cherry Studio æä¾› GUI é…ç½®ç•Œé¢ï¼Œ 5 åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²ï¼Œ å¤æ‚çš„éƒ¨åˆ†æ˜¯ä¸€é”®å®‰è£…çš„ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å›¾æ–‡éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼šç°å·²æ›´æ–°åˆ°æˆ‘çš„&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;å…¬ä¼—å·&lt;/a&gt;ï¼Œå›å¤ "mcp" å³å¯&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†éƒ¨ç½²æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. å­¦ä¹ ä¸ AI å¯¹è¯çš„å§¿åŠ¿&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;è¯¦ç»†å¯¹è¯æ•™ç¨‹&lt;/strong&gt;ï¼š&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-MCP-FAQ.md"&gt;README-MCP-FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;æé—®æ•ˆæœ&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å®é™…ä¸å»ºè®®ä¸€æ¬¡æ€§é—®å¤šä¸ªé—®é¢˜ã€‚å¦‚æœä½ é€‰æ‹©çš„ ai æ¨¡å‹è¿ä¸‹å›¾çš„æŒ‰é¡ºåºè°ƒç”¨éƒ½æ— æ³•åšåˆ°ï¼Œå»ºè®®æ¢ä¸€ä¸ªã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/ai2.png" alt="mcp ä½¿ç”¨æ•ˆæœå›¾2" width="600" /&gt; 
&lt;h2&gt;ğŸ”Œ MCP å®¢æˆ·ç«¯&lt;/h2&gt; 
&lt;p&gt;TrendRadar MCP æœåŠ¡æ”¯æŒæ ‡å‡†çš„ Model Context Protocol (MCP) åè®®ï¼Œå¯ä»¥æ¥å…¥å„ç§æ”¯æŒ MCP çš„ AI å®¢æˆ·ç«¯è¿›è¡Œæ™ºèƒ½åˆ†æã€‚&lt;/p&gt; 
&lt;h3&gt;æ”¯æŒçš„å®¢æˆ·ç«¯&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°† &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; æ›¿æ¢ä¸ºä½ çš„é¡¹ç›®å®é™…è·¯å¾„&lt;/li&gt; 
 &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åŒåæ–œæ ï¼š&lt;code&gt;C:\\Users\\YourName\\TrendRadar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ä¿å­˜åè®°å¾—é‡å¯&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Claude Desktop&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;é…ç½®æ–‡ä»¶æ–¹å¼&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ Claude Desktop çš„ MCP é…ç½®æ–‡ä»¶ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;ï¼š &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Mac&lt;/strong&gt;ï¼š &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;é…ç½®å†…å®¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ],
      "env": {},
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Cursor&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;æ–¹å¼ä¸€ï¼šHTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½® Cursor&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;p&gt;&lt;strong&gt;é¡¹ç›®çº§é…ç½®&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://localhost:3333/mcp",
      "description": "TrendRadar æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;å…¨å±€é…ç½®&lt;/strong&gt;ï¼š åœ¨ç”¨æˆ·ç›®å½•åˆ›å»º &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;ï¼ˆåŒæ ·å†…å®¹ï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ä½¿ç”¨æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ä¿å­˜é…ç½®æ–‡ä»¶åé‡å¯ Cursor&lt;/li&gt; 
    &lt;li&gt;åœ¨èŠå¤©ç•Œé¢çš„ "Available Tools" ä¸­æŸ¥çœ‹å·²è¿æ¥çš„å·¥å…·&lt;/li&gt; 
    &lt;li&gt;å¼€å§‹ä½¿ç”¨ï¼š&lt;code&gt;æœç´¢ä»Šå¤©çš„"AI"ç›¸å…³æ–°é—»&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;æ–¹å¼äºŒï¼šSTDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;åˆ›å»º &lt;code&gt;.cursor/mcp.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ VSCode (Cline/Continue)&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;Cline é…ç½®&lt;/h4&gt; 
 &lt;p&gt;åœ¨ Cline çš„ MCP è®¾ç½®ä¸­æ·»åŠ ï¼š&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "url": "http://localhost:3333/mcp",
    "type": "streamableHttp",
    "autoApprove": [],
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼ˆæ¨èï¼‰ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "command": "uv",
    "args": [
      "--directory",
      "/path/to/TrendRadar",
      "run",
      "python",
      "-m",
      "mcp_server.server"
    ],
    "type": "stdio",
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Continue é…ç½®&lt;/h4&gt; 
 &lt;p&gt;ç¼–è¾‘ &lt;code&gt;~/.continue/config.json&lt;/code&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "experimental": {
    "modelContextProtocolServers": [
      {
        "transport": {
          "type": "stdio",
          "command": "uv",
          "args": [
            "--directory",
            "/path/to/TrendRadar",
            "run",
            "python",
            "-m",
            "mcp_server.server"
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;åˆ†ææœ€è¿‘7å¤©"ç‰¹æ–¯æ‹‰"çš„çƒ­åº¦å˜åŒ–è¶‹åŠ¿
ç”Ÿæˆä»Šå¤©çš„çƒ­ç‚¹æ‘˜è¦æŠ¥å‘Š
æœç´¢"æ¯”ç‰¹å¸"ç›¸å…³æ–°é—»å¹¶åˆ†ææƒ…æ„Ÿå€¾å‘
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Claude Code CLI&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼é…ç½®&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. å¯åŠ¨ HTTP æœåŠ¡
# Windows: start-http.bat
# Mac/Linux: ./start-http.sh

# 2. æ·»åŠ  MCP æœåŠ¡å™¨
claude mcp add --transport http trendradar http://localhost:3333/mcp

# 3. éªŒè¯è¿æ¥ï¼ˆç¡®ä¿æœåŠ¡å·²å¯åŠ¨ï¼‰
claude mcp list
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ä½¿ç”¨ç¤ºä¾‹&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# æŸ¥è¯¢æ–°é—»
claude "æœç´¢ä»Šå¤©çŸ¥ä¹çš„çƒ­ç‚¹æ–°é—»ï¼Œå‰10æ¡"

# è¶‹åŠ¿åˆ†æ
claude "åˆ†æ'äººå·¥æ™ºèƒ½'è¿™ä¸ªè¯é¢˜æœ€è¿‘ä¸€å‘¨çš„çƒ­åº¦è¶‹åŠ¿"

# æ•°æ®å¯¹æ¯”
claude "å¯¹æ¯”çŸ¥ä¹å’Œå¾®åšå¹³å°å¯¹'æ¯”ç‰¹å¸'çš„å…³æ³¨åº¦"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ MCP Inspector&lt;/b&gt;ï¼ˆè°ƒè¯•å·¥å…·ï¼‰&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;MCP Inspector æ˜¯å®˜æ–¹è°ƒè¯•å·¥å…·ï¼Œç”¨äºæµ‹è¯• MCP è¿æ¥ï¼š&lt;/p&gt; 
 &lt;h4&gt;ä½¿ç”¨æ­¥éª¤&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ TrendRadar HTTP æœåŠ¡&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¯åŠ¨ MCP Inspector&lt;/strong&gt;ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;åœ¨æµè§ˆå™¨ä¸­è¿æ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;è®¿é—®ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;æµ‹è¯• "Ping Server" åŠŸèƒ½éªŒè¯è¿æ¥&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥ "List Tools" æ˜¯å¦è¿”å› 13 ä¸ªå·¥å…·ï¼š 
     &lt;ul&gt; 
      &lt;li&gt;åŸºç¡€æŸ¥è¯¢ï¼šget_latest_news, get_news_by_date, get_trending_topics&lt;/li&gt; 
      &lt;li&gt;æ™ºèƒ½æ£€ç´¢ï¼šsearch_news, search_related_news_history&lt;/li&gt; 
      &lt;li&gt;é«˜çº§åˆ†æï¼šanalyze_topic_trend, analyze_data_insights, analyze_sentiment, find_similar_news, generate_summary_report&lt;/li&gt; 
      &lt;li&gt;ç³»ç»Ÿç®¡ç†ï¼šget_current_config, get_system_status, trigger_crawl&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ å…¶ä»–æ”¯æŒ MCP çš„å®¢æˆ·ç«¯&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ä»»ä½•æ”¯æŒ Model Context Protocol çš„å®¢æˆ·ç«¯éƒ½å¯ä»¥è¿æ¥ TrendRadarï¼š&lt;/p&gt; 
 &lt;h4&gt;HTTP æ¨¡å¼&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;æœåŠ¡åœ°å€&lt;/strong&gt;ï¼š&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "url": "http://localhost:3333/mcp",
  "type": "http",
  "description": "æ–°é—»çƒ­ç‚¹èšåˆåˆ†æ"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;STDIO æ¨¡å¼ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;åŸºæœ¬é…ç½®æ¨¡æ¿&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "command": "uv",
  "args": [
    "--directory",
    "/path/to/TrendRadar",
    "run",
    "python",
    "-m",
    "mcp_server.server"
  ],
  "type": "stdio"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›¿æ¢ &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ä¸ºå®é™…é¡¹ç›®è·¯å¾„&lt;/li&gt; 
  &lt;li&gt;Windows è·¯å¾„ä½¿ç”¨åæ–œæ è½¬ä¹‰ï¼š&lt;code&gt;C:\\Users\\...&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;ç¡®ä¿å·²å®Œæˆé¡¹ç›®ä¾èµ–å®‰è£…ï¼ˆè¿è¡Œè¿‡ setup è„šæœ¬ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;â˜•é—®é¢˜ç­”ç–‘ä¸1å…ƒç‚¹èµ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¿ƒæ„åˆ°å°±è¡Œï¼Œæ”¶åˆ°çš„&lt;strong&gt;ç‚¹èµ&lt;/strong&gt;ç”¨äºæé«˜å¼€å‘è€…å¼€æºçš„ç§¯ææ€§ã€‚&lt;strong&gt;ç‚¹èµ&lt;/strong&gt;å·²æ”¶å½•äº&lt;strong&gt;è‡´è°¢åå•&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;ï¼šé€‚åˆé’ˆå¯¹æ€§å¼ºçš„è§£ç­”ã€‚æé—®æ—¶è¯·æä¾›å®Œæ•´ä¿¡æ¯ï¼ˆæˆªå›¾ã€é”™è¯¯æ—¥å¿—ã€ç³»ç»Ÿç¯å¢ƒç­‰ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å…¬ä¼—å·äº¤æµ&lt;/strong&gt;ï¼šé€‚åˆå¿«é€Ÿå’¨è¯¢ã€‚å»ºè®®ä¼˜å…ˆåœ¨ç›¸å…³æ–‡ç« ä¸‹çš„å…¬å…±ç•™è¨€åŒºäº¤æµï¼Œå¦‚ç§ä¿¡ï¼Œè¯·æ–‡æ˜ç¤¼è²Œç”¨è¯­ğŸ˜‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;å…¬ä¼—å·å…³æ³¨&lt;/th&gt; 
   &lt;th align="center"&gt;å¾®ä¿¡ç‚¹èµ&lt;/th&gt; 
   &lt;th align="center"&gt;æ”¯ä»˜å®ç‚¹èµ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/weixin.png" width="300" title="ç¡…åŸºèŒ¶æ°´é—´" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG" width="300" title="å¾®ä¿¡æ”¯ä»˜" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG" width="300" title="æ”¯ä»˜å®æ”¯ä»˜" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;å¸¸è§é—®é¢˜&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q1: HTTP æœåŠ¡æ— æ³•å¯åŠ¨ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;æ£€æŸ¥æ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;ç¡®è®¤ç«¯å£ 3333 æœªè¢«å ç”¨ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
netstat -ano | findstr :3333

# Mac/Linux
lsof -i :3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æ£€æŸ¥é¡¹ç›®ä¾èµ–æ˜¯å¦å®‰è£…ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# é‡æ–°è¿è¡Œå®‰è£…è„šæœ¬
# Windows: setup-windows.bat æˆ–è€… setup-windows-en.bat
# Mac/Linux: ./setup-mac.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;å°è¯•è‡ªå®šä¹‰ç«¯å£:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 33333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q2: å®¢æˆ·ç«¯æ— æ³•è¿æ¥åˆ° MCP æœåŠ¡ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;è§£å†³æ–¹æ¡ˆ&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ UV è·¯å¾„æ­£ç¡®ï¼ˆè¿è¡Œ &lt;code&gt;which uv&lt;/code&gt; æˆ– &lt;code&gt;where uv&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤é¡¹ç›®è·¯å¾„æ­£ç¡®ä¸”æ— ä¸­æ–‡å­—ç¬¦&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å®¢æˆ·ç«¯é”™è¯¯æ—¥å¿—&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP æ¨¡å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤æœåŠ¡å·²å¯åŠ¨ï¼ˆè®¿é—® &lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é˜²ç«å¢™è®¾ç½®&lt;/li&gt; 
    &lt;li&gt;å°è¯•ä½¿ç”¨ 127.0.0.1 æ›¿ä»£ localhost&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é€šç”¨æ£€æŸ¥&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;é‡å¯å®¢æˆ·ç«¯åº”ç”¨&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ MCP æœåŠ¡æ—¥å¿—&lt;/li&gt; 
    &lt;li&gt;ä½¿ç”¨ MCP Inspector æµ‹è¯•è¿æ¥&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ‘‰ Q3: å·¥å…·è°ƒç”¨å¤±è´¥æˆ–è¿”å›é”™è¯¯ï¼Ÿ&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;å¯èƒ½åŸå› &lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä¸å­˜åœ¨&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤å·²è¿è¡Œè¿‡çˆ¬è™«ï¼ˆæœ‰ output ç›®å½•æ•°æ®ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥æŸ¥è¯¢æ—¥æœŸèŒƒå›´æ˜¯å¦æœ‰æ•°æ®&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹ output ç›®å½•çš„å¯ç”¨æ—¥æœŸ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;å‚æ•°é”™è¯¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ£€æŸ¥æ—¥æœŸæ ¼å¼ï¼š&lt;code&gt;YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤å¹³å° ID æ­£ç¡®ï¼š&lt;code&gt;zhihu&lt;/code&gt;, &lt;code&gt;weibo&lt;/code&gt; ç­‰&lt;/li&gt; 
    &lt;li&gt;æŸ¥çœ‹å·¥å…·æ–‡æ¡£ä¸­çš„å‚æ•°è¯´æ˜&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;é…ç½®é—®é¢˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/config.yaml&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;ç¡®è®¤ &lt;code&gt;config/frequency_words.txt&lt;/code&gt; å­˜åœ¨&lt;/li&gt; 
    &lt;li&gt;æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;é¡¹ç›®ç›¸å…³&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;4 ç¯‡æ–‡ç« &lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/KYEPfTPVzZNWFclZh4am_g"&gt;å¯åœ¨è¯¥æ–‡ç« ä¸‹æ–¹ç•™è¨€ï¼Œæ–¹ä¾¿é¡¹ç›®ä½œè€…ç”¨æ‰‹æœºç­”ç–‘&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/jzn0vLiQFX408opcfpPPxQ"&gt;2ä¸ªæœˆç ´ 1000 starï¼Œæˆ‘çš„GitHubé¡¹ç›®æ¨å¹¿å®æˆ˜ç»éªŒ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/C8evK-U7onG1sTTdwdW2zg"&gt;github fork è¿è¡Œæœ¬é¡¹ç›®çš„æ³¨æ„äº‹é¡¹ &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/8ghyfDAtQZjLrnWTQabYOQ"&gt;åŸºäºæœ¬é¡¹ç›®ï¼Œå¦‚ä½•å¼€å±•å…¬ä¼—å·æˆ–è€…æ–°é—»èµ„è®¯ç±»æ–‡ç« å†™ä½œ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;AI å¼€å‘&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;å¦‚æœä½ æœ‰å°ä¼—éœ€æ±‚ï¼Œå®Œå…¨å¯ä»¥åŸºäºæˆ‘çš„é¡¹ç›®è‡ªè¡Œå¼€å‘ï¼Œé›¶ç¼–ç¨‹åŸºç¡€çš„ä¹Ÿå¯ä»¥è¯•è¯•&lt;/li&gt; 
 &lt;li&gt;æˆ‘æ‰€æœ‰çš„å¼€æºé¡¹ç›®æˆ–å¤šæˆ–å°‘éƒ½ä½¿ç”¨äº†è‡ªå·±å†™çš„&lt;strong&gt;AIè¾…åŠ©è½¯ä»¶&lt;/strong&gt;æ¥æå‡å¼€å‘æ•ˆç‡ï¼Œè¿™æ¬¾å·¥å…·å·²å¼€æº&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/strong&gt;ï¼šè¿…é€Ÿç­›é€‰é¡¹ç›®ä»£ç å–‚ç»™AIï¼Œä½ åªéœ€è¦è¡¥å……ä¸ªäººéœ€æ±‚å³å¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®åœ°å€&lt;/strong&gt;ï¼š&lt;a href="https://github.com/sansan0/ai-code-context-helper"&gt;https://github.com/sansan0/ai-code-context-helper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å…¶ä½™é¡¹ç›®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ“ æ¯›ä¸»å¸­è¶³è¿¹åœ°å›¾ - äº¤äº’å¼åŠ¨æ€å±•ç¤º1893-1976å¹´å®Œæ•´è½¨è¿¹ã€‚æ¬¢è¿è¯¸ä½åŒå¿—è´¡çŒ®æ•°æ®&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/mao-map"&gt;https://github.com/sansan0/mao-map&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å“”å“©å“”å“©(bilibili)è¯„è®ºåŒºæ•°æ®å¯è§†åŒ–åˆ†æè½¯ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/bilibili-comment-analyzer"&gt;https://github.com/sansan0/bilibili-comment-analyzer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ‘‰ å¾®ä¿¡æ¨é€é€šçŸ¥æ–¹æ¡ˆ&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ç”±äºè¯¥æ–¹æ¡ˆæ˜¯åŸºäºä¼ä¸šå¾®ä¿¡çš„æ’ä»¶æœºåˆ¶ï¼Œæ¨é€æ ·å¼ä¹Ÿååˆ†ä¸åŒï¼Œæ‰€ä»¥ç›¸å…³å®ç°æˆ‘æš‚æ—¶ä¸å‡†å¤‡çº³å…¥å½“å‰é¡¹ç›®&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;fork è¿™ä½å…„å°çš„é¡¹ç›® &lt;a href="https://github.com/jayzqj/TrendRadar"&gt;https://github.com/jayzqj/TrendRadar&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;å®Œæˆä¸Šæ–¹çš„ä¼ä¸šå¾®ä¿¡æ¨é€è®¾ç½®&lt;/li&gt; 
  &lt;li&gt;æŒ‰ç…§ä¸‹é¢å›¾ç‰‡æ“ä½œ&lt;/li&gt; 
  &lt;li&gt;é…ç½®å¥½åï¼Œæ‰‹æœºä¸Šçš„ä¼ä¸šå¾®ä¿¡ app åˆ é™¤æ‰ä¹Ÿæ²¡äº‹&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/wework.png" title="github" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;æœ¬é¡¹ç›®æµç¨‹å›¾&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[ğŸ‘¤ ç”¨æˆ·å¼€å§‹] --&amp;gt; B{ğŸš€ é€‰æ‹©éƒ¨ç½²æ–¹å¼}
    
    B --&amp;gt;|äº‘ç«¯éƒ¨ç½²| C1[ğŸ´ Fork é¡¹ç›®åˆ° GitHub]
    B --&amp;gt;|æœ¬åœ°éƒ¨ç½²| C2[ğŸ³ Docker éƒ¨ç½²]
    
    C1 --&amp;gt; D[âš™ï¸ é…ç½®é€šçŸ¥æ¸ é“&amp;lt;br/&amp;gt;å¯åŒæ—¶é…ç½®å¤šä¸ª]
    C2 --&amp;gt; D
    
    D --&amp;gt; E[é€‰æ‹©é€šçŸ¥æ–¹å¼ï¼š&amp;lt;br/&amp;gt;ğŸ“±ä¼ä¸šå¾®ä¿¡ ğŸ’¬é£ä¹¦ ğŸ””é’‰é’‰&amp;lt;br/&amp;gt;ğŸ“ŸTelegram ğŸ“§é‚®ä»¶]
    
    E --&amp;gt; F[ğŸ”‘ å¡«å†™é€šçŸ¥å‚æ•°&amp;lt;br/&amp;gt;GitHub Secrets æˆ–ç¯å¢ƒå˜é‡]
    
    F --&amp;gt; G[ğŸ“ é…ç½®å…³é”®è¯&amp;lt;br/&amp;gt;config/frequency_words.txt&amp;lt;br/&amp;gt;æ™®é€šè¯/å¿…é¡»è¯+/è¿‡æ»¤è¯!]
    
    G --&amp;gt; H[ğŸ¯ é€‰æ‹©è¿è¡Œæ¨¡å¼&amp;lt;br/&amp;gt;config/config.yaml]
    
    H --&amp;gt; H1[ğŸ“‹ daily - å½“æ—¥æ±‡æ€»&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æ‰€æœ‰åŒ¹é…æ–°é—»]
    H --&amp;gt; H2[ğŸ“° current - å½“å‰æ¦œå•&amp;lt;br/&amp;gt;å®šæ—¶æ¨é€æœ€æ–°æ¦œå•]
    H --&amp;gt; H3[ğŸ“ˆ incremental - å¢é‡ç›‘æ§&amp;lt;br/&amp;gt;ä»…æ¨é€æ–°å¢å†…å®¹]
    
    H1 --&amp;gt; I[å¯é€‰ï¼šæ¨é€æ—¶é—´çª—å£æ§åˆ¶&amp;lt;br/&amp;gt;â° é™åˆ¶æ¨é€æ—¶é—´èŒƒå›´]
    H2 --&amp;gt; I
    H3 --&amp;gt; I
    
    I --&amp;gt; J[âœ… é…ç½®å®Œæˆ]
    
    J --&amp;gt; K[ğŸ¤– ç³»ç»Ÿè‡ªåŠ¨è¿è¡Œ]
    
    K --&amp;gt; L[ğŸ•·ï¸ çˆ¬å–11+å¹³å°çƒ­ç‚¹]
    L --&amp;gt; M[ğŸ” å…³é”®è¯ç­›é€‰]
    M --&amp;gt; N[âš–ï¸ æƒé‡ç®—æ³•æ’åº&amp;lt;br/&amp;gt;æ’å60% + é¢‘æ¬¡30% + çƒ­åº¦10%]
    N --&amp;gt; O[ğŸ“Š ç”ŸæˆæŠ¥å‘Š&amp;lt;br/&amp;gt;HTMLç½‘é¡µ + æ¨é€æ¶ˆæ¯]
    O --&amp;gt; P[ğŸ“± å¤šæ¸ é“æ¨é€é€šçŸ¥]
    
    P --&amp;gt; Q[ğŸ‰ æŒç»­æ¥æ”¶ç²¾å‡†æ¨é€&amp;lt;br/&amp;gt;å‘Šåˆ«ä¿¡æ¯è¿‡è½½]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style F fill:#fff9c4
    style G fill:#e8f5e9
    style H fill:#e0f2f1
    style I fill:#fce4ec
    style O fill:#e1bee7
    style Q fill:#c8e6c9
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#sansan0/TrendRadar&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sansan0/TrendRadar&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#trendradar"&gt;ğŸ” å›åˆ°é¡¶éƒ¨&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser based workflows with AI&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; ğŸ‰ Automate Browser-based workflows using LLMs and Computer Vision ğŸ‰ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. âš ï¸&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;ğŸ” 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ğŸ” Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ğŸ” Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;ğŸ’¡ See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;ğŸ“• docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/all-in-rag</title>
      <link>https://github.com/datawhalechina/all-in-rag</link>
      <description>&lt;p&gt;ğŸ”å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜ä¸€ï¼šRAGæŠ€æœ¯å…¨æ ˆæŒ‡å—ï¼Œåœ¨çº¿é˜…è¯»åœ°å€ï¼šhttps://datawhalechina.github.io/all-in-rag/&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;All-in-RAG | å¤§æ¨¡å‹åº”ç”¨å¼€å‘å®æˆ˜ä¸€ï¼šRAGæŠ€æœ¯å…¨æ ˆæŒ‡å—&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/logo.svg?sanitize=true" alt="All-in-RAG Logo" width="70%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;ğŸ” æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯å…¨æ ˆæŒ‡å—&lt;/h2&gt; 
 &lt;p&gt;&lt;em&gt;ä»ç†è®ºåˆ°å®è·µï¼Œä»åŸºç¡€åˆ°è¿›é˜¶ï¼Œæ„å»ºä½ çš„RAGæŠ€æœ¯ä½“ç³»&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/all-in-rag?style=for-the-badge&amp;amp;logo=github&amp;amp;color=ff6b6b" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/all-in-rag?style=for-the-badge&amp;amp;logo=github&amp;amp;color=4ecdc4" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/Python-3.12.7-blue?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt; 
 &lt;a href="https://zread.ai/datawhalechina/all-in-rag"&gt; &lt;img src="https://img.shields.io/badge/Ask_Zread-_.svg?style=for-the-badge&amp;amp;color=00b0aa&amp;amp;labelColor=000000&amp;amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&amp;amp;logoColor=ffffff" alt="zread" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://datawhalechina.github.io/all-in-rag/"&gt; &lt;img src="https://img.shields.io/badge/ğŸ“–_åœ¨çº¿é˜…è¯»-ç«‹å³å¼€å§‹-success?style=for-the-badge&amp;amp;logoColor=white" alt="åœ¨çº¿é˜…è¯»" /&gt; &lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/README_en.md"&gt; &lt;img src="https://img.shields.io/badge/ğŸŒ_English-Version-blue?style=for-the-badge&amp;amp;logoColor=white" alt="English Version" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/datawhalechina"&gt; &lt;img src="https://img.shields.io/badge/ğŸ’¬_è®¨è®ºäº¤æµ-åŠ å…¥æˆ‘ä»¬-purple?style=for-the-badge&amp;amp;logoColor=white" alt="è®¨è®ºäº¤æµ" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt;ğŸ¯ &lt;strong&gt;ç³»ç»ŸåŒ–å­¦ä¹ &lt;/strong&gt;&lt;br /&gt;å®Œæ•´çš„RAGæŠ€æœ¯ä½“ç³»&lt;/td&gt; 
    &lt;td align="center"&gt;ğŸ› ï¸ &lt;strong&gt;åŠ¨æ‰‹å®è·µ&lt;/strong&gt;&lt;br /&gt;ä¸°å¯Œçš„é¡¹ç›®æ¡ˆä¾‹&lt;/td&gt; 
    &lt;td align="center"&gt;ğŸš€ &lt;strong&gt;ç”Ÿäº§å°±ç»ª&lt;/strong&gt;&lt;br /&gt;å·¥ç¨‹åŒ–æœ€ä½³å®è·µ&lt;/td&gt; 
    &lt;td align="center"&gt;ğŸ“Š &lt;strong&gt;å¤šæ¨¡æ€æ”¯æŒ&lt;/strong&gt;&lt;br /&gt;æ–‡æœ¬+å›¾åƒæ£€ç´¢&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;é¡¹ç›®ç®€ä»‹ï¼ˆä¸­æ–‡ | &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/README_en.md"&gt;English&lt;/a&gt;ï¼‰&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé¢å‘å¤§æ¨¡å‹åº”ç”¨å¼€å‘è€…çš„RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯å…¨æ ˆæ•™ç¨‹ï¼Œæ—¨åœ¨é€šè¿‡ä½“ç³»åŒ–çš„å­¦ä¹ è·¯å¾„å’ŒåŠ¨æ‰‹å®è·µé¡¹ç›®ï¼Œå¸®åŠ©å¼€å‘è€…æŒæ¡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„RAGåº”ç”¨å¼€å‘æŠ€èƒ½ï¼Œæ„å»ºç”Ÿäº§çº§çš„æ™ºèƒ½é—®ç­”å’ŒçŸ¥è¯†æ£€ç´¢ç³»ç»Ÿã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;RAGæŠ€æœ¯åŸºç¡€&lt;/strong&gt;ï¼šæ·±å…¥æµ…å‡ºåœ°ä»‹ç»RAGçš„æ ¸å¿ƒæ¦‚å¿µã€æŠ€æœ¯åŸç†å’Œåº”ç”¨åœºæ™¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®å¤„ç†å…¨æµç¨‹&lt;/strong&gt;ï¼šä»æ•°æ®åŠ è½½ã€æ¸…æ´—åˆ°æ–‡æœ¬åˆ†å—çš„å®Œæ•´æ•°æ®å‡†å¤‡æµç¨‹&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ç´¢å¼•æ„å»ºä¸ä¼˜åŒ–&lt;/strong&gt;ï¼šå‘é‡åµŒå…¥ã€å¤šæ¨¡æ€åµŒå…¥ã€å‘é‡æ•°æ®åº“æ„å»ºåŠç´¢å¼•ä¼˜åŒ–æŠ€æœ¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ£€ç´¢æŠ€æœ¯è¿›é˜¶&lt;/strong&gt;ï¼šæ··åˆæ£€ç´¢ã€æŸ¥è¯¢æ„å»ºã€Text2SQLç­‰é«˜çº§æ£€ç´¢æŠ€æœ¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ç”Ÿæˆé›†æˆä¸è¯„ä¼°&lt;/strong&gt;ï¼šæ ¼å¼åŒ–ç”Ÿæˆã€ç³»ç»Ÿè¯„ä¼°ä¸ä¼˜åŒ–æ–¹æ³•&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®å®æˆ˜&lt;/strong&gt;ï¼šä»åŸºç¡€åˆ°è¿›é˜¶çš„å®Œæ•´RAGåº”ç”¨å¼€å‘å®è·µ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;é¡¹ç›®æ„ä¹‰&lt;/h2&gt; 
&lt;p&gt;éšç€å¤§è¯­è¨€æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼ŒRAGæŠ€æœ¯å·²æˆä¸ºæ„å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†æ£€ç´¢åº”ç”¨çš„æ ¸å¿ƒæŠ€æœ¯ã€‚ç„¶è€Œï¼Œç°æœ‰çš„RAGæ•™ç¨‹å¾€å¾€é›¶æ•£ä¸”ç¼ºä¹ç³»ç»Ÿæ€§ï¼Œåˆå­¦è€…éš¾ä»¥å½¢æˆå®Œæ•´çš„æŠ€æœ¯ä½“ç³»è®¤çŸ¥ã€‚&lt;/p&gt; 
&lt;p&gt;æœ¬é¡¹ç›®ä»å®è·µå‡ºå‘ï¼Œç»“åˆæœ€æ–°çš„RAGæŠ€æœ¯å‘å±•è¶‹åŠ¿ï¼Œæ„å»ºäº†ä¸€å¥—å®Œæ•´çš„RAGå­¦ä¹ ä½“ç³»ï¼Œå¸®åŠ©å¼€å‘è€…ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç³»ç»ŸæŒæ¡RAGæŠ€æœ¯çš„ç†è®ºåŸºç¡€å’Œå®è·µæŠ€èƒ½&lt;/li&gt; 
 &lt;li&gt;ç†è§£RAGç³»ç»Ÿçš„å®Œæ•´æ¶æ„å’Œå„ç»„ä»¶çš„ä½œç”¨&lt;/li&gt; 
 &lt;li&gt;å…·å¤‡ç‹¬ç«‹å¼€å‘RAGåº”ç”¨çš„èƒ½åŠ›&lt;/li&gt; 
 &lt;li&gt;æŒæ¡RAGç³»ç»Ÿçš„è¯„ä¼°å’Œä¼˜åŒ–æ–¹æ³•&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;é¡¹ç›®å—ä¼—&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;æœ¬é¡¹ç›®é€‚åˆä»¥ä¸‹äººç¾¤å­¦ä¹ ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å…·å¤‡Pythonç¼–ç¨‹åŸºç¡€ï¼Œå¯¹RAGæŠ€æœ¯æ„Ÿå…´è¶£çš„å¼€å‘è€…&lt;/li&gt; 
 &lt;li&gt;å¸Œæœ›ç³»ç»Ÿå­¦ä¹ RAGæŠ€æœ¯çš„AIå·¥ç¨‹å¸ˆ&lt;/li&gt; 
 &lt;li&gt;æƒ³è¦æ„å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„äº§å“å¼€å‘è€…&lt;/li&gt; 
 &lt;li&gt;å¯¹æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯æœ‰å­¦ä¹ éœ€æ±‚çš„ç ”ç©¶äººå‘˜&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;å‰ç½®è¦æ±‚ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;æŒæ¡PythonåŸºç¡€è¯­æ³•å’Œå¸¸ç”¨åº“çš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;èƒ½å¤Ÿç®€å•ä½¿ç”¨docker&lt;/li&gt; 
 &lt;li&gt;äº†è§£åŸºæœ¬çš„LLMæ¦‚å¿µï¼ˆæ¨èä½†éå¿…éœ€ï¼‰&lt;/li&gt; 
 &lt;li&gt;å…·å¤‡åŸºç¡€çš„Linuxå‘½ä»¤è¡Œæ“ä½œèƒ½åŠ›&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;é¡¹ç›®äº®ç‚¹&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ä½“ç³»åŒ–å­¦ä¹ è·¯å¾„&lt;/strong&gt;ï¼šä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼Œæ„å»ºå®Œæ•´çš„RAGæŠ€æœ¯å­¦ä¹ ä½“ç³»&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ç†è®ºä¸å®è·µå¹¶é‡&lt;/strong&gt;ï¼šæ¯ä¸ªç« èŠ‚éƒ½åŒ…å«ç†è®ºè®²è§£å’Œä»£ç å®è·µï¼Œç¡®ä¿å­¦ä»¥è‡´ç”¨&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤šæ¨¡æ€æ”¯æŒ&lt;/strong&gt;ï¼šä¸ä»…æ¶µç›–æ–‡æœ¬RAGï¼Œè¿˜åŒ…æ‹¬å¤šæ¨¡æ€åµŒå…¥å’Œæ£€ç´¢æŠ€æœ¯&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å·¥ç¨‹åŒ–å¯¼å‘&lt;/strong&gt;ï¼šæ³¨é‡å®é™…åº”ç”¨ä¸­çš„å·¥ç¨‹åŒ–é—®é¢˜ï¼ŒåŒ…æ‹¬æ€§èƒ½ä¼˜åŒ–ã€ç³»ç»Ÿè¯„ä¼°ç­‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¸°å¯Œçš„å®æˆ˜é¡¹ç›®&lt;/strong&gt;ï¼šæä¾›ä»åŸºç¡€åˆ°è¿›é˜¶çš„å¤šä¸ªå®æˆ˜é¡¹ç›®ï¼Œå¸®åŠ©å·©å›ºå­¦ä¹ æˆæœ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;å†…å®¹å¤§çº²&lt;/h2&gt; 
&lt;h3&gt;ç¬¬ä¸€éƒ¨åˆ†ï¼šRAGåŸºç¡€å…¥é—¨&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬ä¸€ç«  è§£é”RAG&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter1"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter1/01_RAG_intro.md"&gt;RAGç®€ä»‹&lt;/a&gt; - RAGæŠ€æœ¯æ¦‚è¿°ä¸åº”ç”¨åœºæ™¯&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter1/02_preparation.md"&gt;å‡†å¤‡å·¥ä½œ&lt;/a&gt; - ç¯å¢ƒé…ç½®ä¸å‡†å¤‡&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter1/03_get_start_rag.md"&gt;å››æ­¥æ„å»ºRAG&lt;/a&gt; - å¿«é€Ÿä¸Šæ‰‹RAGå¼€å‘&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter1/virtualenv.md"&gt;é™„ï¼šç¯å¢ƒéƒ¨ç½²&lt;/a&gt; - Pythonè™šæ‹Ÿç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆè¡¥å…… (è´¡çŒ®è€…: &lt;a href="https://github.com/anarchysaiko"&gt;@anarchysaiko&lt;/a&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬äºŒç«  æ•°æ®å‡†å¤‡&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter2"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter2/04_data_load.md"&gt;æ•°æ®åŠ è½½&lt;/a&gt; - å¤šæ ¼å¼æ–‡æ¡£å¤„ç†ä¸åŠ è½½&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter2/05_text_chunking.md"&gt;æ–‡æœ¬åˆ†å—&lt;/a&gt; - æ–‡æœ¬åˆ‡åˆ†ç­–ç•¥ä¸ä¼˜åŒ–&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ç¬¬äºŒéƒ¨åˆ†ï¼šç´¢å¼•æ„å»ºä¸ä¼˜åŒ–&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬ä¸‰ç«  ç´¢å¼•æ„å»º&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3/06_vector_embedding.md"&gt;å‘é‡åµŒå…¥&lt;/a&gt; - æ–‡æœ¬å‘é‡åŒ–æŠ€æœ¯è¯¦è§£&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3/07_multimodal_embedding.md"&gt;å¤šæ¨¡æ€åµŒå…¥&lt;/a&gt; - å›¾æ–‡å¤šæ¨¡æ€å‘é‡åŒ–&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3/08_vector_db.md"&gt;å‘é‡æ•°æ®åº“&lt;/a&gt; - å‘é‡å­˜å‚¨ä¸æ£€ç´¢ç³»ç»Ÿ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3/09_milvus.md"&gt;Milvuså®è·µ&lt;/a&gt; - Milvuså¤šæ¨¡æ€æ£€ç´¢å®æˆ˜&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter3/10_index_optimization.md"&gt;ç´¢å¼•ä¼˜åŒ–&lt;/a&gt; - ç´¢å¼•æ€§èƒ½è°ƒä¼˜æŠ€å·§&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ£€ç´¢æŠ€æœ¯è¿›é˜¶&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬å››ç«  æ£€ç´¢ä¼˜åŒ–&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4/11_hybrid_search.md"&gt;æ··åˆæ£€ç´¢&lt;/a&gt; - ç¨ å¯†+ç¨€ç–æ£€ç´¢èåˆ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4/12_query_construction.md"&gt;æŸ¥è¯¢æ„å»º&lt;/a&gt; - æ™ºèƒ½æŸ¥è¯¢ç†è§£ä¸æ„å»º&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4/13_text2sql.md"&gt;Text2SQL&lt;/a&gt; - è‡ªç„¶è¯­è¨€è½¬SQLæŸ¥è¯¢&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4/14_query_rewriting.md"&gt;æŸ¥è¯¢é‡æ„ä¸åˆ†å‘&lt;/a&gt; - æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter4/15_advanced_retrieval_techniques.md"&gt;æ£€ç´¢è¿›é˜¶æŠ€æœ¯&lt;/a&gt; - é«˜çº§æ£€ç´¢ç®—æ³•&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ç¬¬å››éƒ¨åˆ†ï¼šç”Ÿæˆä¸è¯„ä¼°&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬äº”ç«  ç”Ÿæˆé›†æˆ&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter5"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter5/16_formatted_generation.md"&gt;æ ¼å¼åŒ–ç”Ÿæˆ&lt;/a&gt; - ç»“æ„åŒ–è¾“å‡ºä¸æ ¼å¼æ§åˆ¶&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬å…­ç«  RAGç³»ç»Ÿè¯„ä¼°&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter6"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter6/18_system_evaluation.md"&gt;è¯„ä¼°ä»‹ç»&lt;/a&gt; - RAGç³»ç»Ÿè¯„ä¼°æ–¹æ³•è®º&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter6/19_common_tools.md"&gt;è¯„ä¼°å·¥å…·&lt;/a&gt; - å¸¸ç”¨è¯„ä¼°å·¥å…·ä¸æŒ‡æ ‡&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ç¬¬äº”éƒ¨åˆ†ï¼šé«˜çº§åº”ç”¨ä¸å®æˆ˜&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬ä¸ƒç«  é«˜çº§RAGæ¶æ„ï¼ˆæ‹“å±•éƒ¨åˆ†ï¼‰&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter7"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter7/20_kg_rag.md"&gt;åŸºäºçŸ¥è¯†å›¾è°±çš„RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬å…«ç«  é¡¹ç›®å®æˆ˜ä¸€&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter8"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter8/01_env_architecture.md"&gt;ç¯å¢ƒé…ç½®ä¸é¡¹ç›®æ¶æ„&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter8/02_data_preparation.md"&gt;æ•°æ®å‡†å¤‡æ¨¡å—å®ç°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter8/03_index_retrieval.md"&gt;ç´¢å¼•æ„å»ºä¸æ£€ç´¢ä¼˜åŒ–&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter8/04_generation_sys.md"&gt;ç”Ÿæˆé›†æˆä¸ç³»ç»Ÿæ•´åˆ&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬ä¹ç«  é¡¹ç›®å®æˆ˜ä¸€ä¼˜åŒ–ï¼ˆé€‰ä¿®ç¯‡ï¼‰&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter9"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/FutureUnreal/What-to-eat-today"&gt;ğŸ½ï¸ é¡¹ç›®å±•ç¤º&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter9/01_graph_rag_architecture.md"&gt;å›¾RAGæ¶æ„è®¾è®¡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter9/02_graph_data_modeling.md"&gt;å›¾æ•°æ®å»ºæ¨¡ä¸å‡†å¤‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter9/03_index_construction.md"&gt;Milvusç´¢å¼•æ„å»º&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter9/04_intelligent_query_routing.md"&gt;æ™ºèƒ½æŸ¥è¯¢è·¯ç”±ä¸æ£€ç´¢ç­–ç•¥&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬åç«  é¡¹ç›®å®æˆ˜äºŒï¼ˆé€‰ä¿®ç¯‡ï¼‰&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter10"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt; &lt;em&gt;è§„åˆ’ä¸­&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;ç¬¬å…­éƒ¨åˆ†ï¼šçŸ¥è¯†æ‹“å±•&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ç¬¬åä¸€ç«  Neo4J ç®€å•åº”ç”¨&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter11"&gt;ğŸ“– æŸ¥çœ‹ç« èŠ‚&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter11/01_knowledge_graph.md"&gt;çŸ¥è¯†å›¾è°±ä¸ Neo4j å®‰è£…&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/docs/chapter11/02_neo4j.md"&gt;Neo4j åŸºæœ¬ä½¿ç”¨&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ç›®å½•ç»“æ„è¯´æ˜&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;all-in-rag/
â”œâ”€â”€ docs/           # æ•™ç¨‹æ–‡æ¡£
â”œâ”€â”€ code/           # ä»£ç ç¤ºä¾‹
â”œâ”€â”€ data/           # ç¤ºä¾‹æ•°æ®
â”œâ”€â”€ models/         # é¢„è®­ç»ƒæ¨¡å‹
â””â”€â”€ README.md       # é¡¹ç›®è¯´æ˜
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;å®æˆ˜é¡¹ç›®å±•ç¤º&lt;/h2&gt; 
&lt;h3&gt;ç¬¬å…«ç«  é¡¹ç›®ä¸€ï¼š&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/project01.png" alt="é¡¹ç›®ä¸€" /&gt;&lt;/p&gt; 
&lt;h3&gt;ç¬¬ä¹ç«  é¡¹ç›®ä¸€ï¼ˆGraph RAGä¼˜åŒ–ï¼‰ï¼š&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/project01_graph.png" alt="é¡¹ç›®ä¸€ï¼ˆGraph RAGä¼˜åŒ–ï¼‰" /&gt;&lt;/p&gt; 
&lt;h3&gt;ç¬¬åç«  é¡¹ç›®äºŒï¼š&lt;/h3&gt; 
&lt;h2&gt;è‡´è°¢&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒè´¡çŒ®è€…&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FutureUnreal"&gt;dalvqw-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt;ï¼ˆé¡¹ç›®å‘èµ·äººä¸ä¸»è¦è´¡çŒ®è€…ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;é¢å¤–ç« èŠ‚è´¡çŒ®è€…&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anarchysaiko"&gt;å­™è¶…-å†…å®¹åˆ›ä½œè€…&lt;/a&gt;ï¼ˆDatawhaleæˆå‘˜-ä¸Šæµ·å·¥ç¨‹æŠ€æœ¯å¤§å­¦ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ç‰¹åˆ«æ„Ÿè°¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; å¯¹æœ¬é¡¹ç›®çš„å¸®åŠ©ä¸æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ä»¬&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢å¼€æºç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·å’Œæ¡†æ¶æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;ç‰¹åˆ«æ„Ÿè°¢ä»¥ä¸‹ä¸ºæ•™ç¨‹åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/datawhalechina/all-in-rag/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=datawhalechina/all-in-rag" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;å‚ä¸è´¡çŒ®&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš¨ &lt;strong&gt;BugæŠ¥å‘Š&lt;/strong&gt;ï¼šå‘ç°é—®é¢˜è¯·æäº¤ &lt;a href="https://github.com/datawhalechina/all-in-rag/issues"&gt;Issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’­ &lt;strong&gt;æ•™ç¨‹å»ºè®®&lt;/strong&gt;ï¼šæœ‰å¥½çš„æƒ³æ³•æ¬¢è¿åœ¨ &lt;a href="https://github.com/datawhalechina/all-in-rag/discussions"&gt;Discussions&lt;/a&gt; ä¸­è®¨è®º&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;æ–‡æ¡£æ”¹è¿›&lt;/strong&gt;ï¼šå¸®åŠ©å®Œå–„æ–‡æ¡£å†…å®¹å’Œç¤ºä¾‹ä»£ç ï¼ˆå½“å‰ä»…æ”¯æŒç¬¬ä¸ƒç« ä¼˜è´¨å†…å®¹prï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#datawhalechina/all-in-rag&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=datawhalechina/all-in-rag&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª â­ï¸&lt;/p&gt; 
 &lt;p&gt;è®©æ›´å¤šäººå‘ç°è¿™ä¸ªé¡¹ç›®ï¼ˆæŠ¤é£Ÿï¼Ÿå‘æ¥ï¼ï¼‰&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/datawhalechina/all-in-rag/main/emoji.png" alt="star" /&gt;&lt;/p&gt; 
&lt;h2&gt;å…³äº Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;æ‰«æäºŒç»´ç å…³æ³¨ Datawhale å…¬ä¼—å·ï¼Œè·å–æ›´å¤šä¼˜è´¨å¼€æºå†…å®¹&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="çŸ¥è¯†å…±äº«è®¸å¯åè®®" style="border-width:0" src="https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;æœ¬ä½œå“é‡‡ç”¨ &lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®&lt;/a&gt; è¿›è¡Œè®¸å¯ã€‚&lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ğŸŒ Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind" alt="visitors" /&gt; &lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jingyaogong/minimind?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jingyaogong/minimind" alt="GitHub Code License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/jingyaogong/minimind" alt="GitHub last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue" alt="GitHub pull request" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue" alt="Collection" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12586" alt="GitHub Trend" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;"å¤§é“è‡³ç®€"&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;ä¸­æ–‡ | &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ­¤å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä»0å¼€å§‹ï¼Œä»…ç”¨3å—é’±æˆæœ¬ + 2å°æ—¶ï¼å³å¯è®­ç»ƒå‡ºä»…ä¸º25.8Mçš„è¶…å°è¯­è¨€æ¨¡å‹&lt;strong&gt;MiniMind&lt;/strong&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;ç³»åˆ—æå…¶è½»é‡ï¼Œæœ€å°ç‰ˆæœ¬ä½“ç§¯æ˜¯ GPT-3 çš„ $\frac{1}{7000}$ï¼ŒåŠ›æ±‚åšåˆ°æœ€æ™®é€šçš„ä¸ªäººGPUä¹Ÿå¯å¿«é€Ÿè®­ç»ƒã€‚&lt;/li&gt; 
 &lt;li&gt;é¡¹ç›®åŒæ—¶å¼€æºäº†å¤§æ¨¡å‹çš„æç®€ç»“æ„-åŒ…å«æ‹“å±•å…±äº«æ··åˆä¸“å®¶(MoE)ã€æ•°æ®é›†æ¸…æ´—ã€é¢„è®­ç»ƒ(Pretrain)ã€ç›‘ç£å¾®è°ƒ(SFT)ã€LoRAå¾®è°ƒã€ç›´æ¥åå¥½ä¼˜åŒ–(DPO)ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒ(RLAIF: PPO/GRPOç­‰)ã€æ¨¡å‹è’¸é¦ç­‰å…¨è¿‡ç¨‹ä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;åŒæ—¶æ‹“å±•äº†è§†è§‰å¤šæ¨¡æ€çš„VLM: &lt;a href="https://github.com/jingyaogong/minimind-v"&gt;MiniMind-V&lt;/a&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;é¡¹ç›®æ‰€æœ‰æ ¸å¿ƒç®—æ³•ä»£ç å‡ä»0ä½¿ç”¨PyTorchåŸç”Ÿé‡æ„ï¼ä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“æä¾›çš„æŠ½è±¡æ¥å£ã€‚&lt;/li&gt; 
 &lt;li&gt;è¿™ä¸ä»…æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å…¨é˜¶æ®µå¼€æºå¤ç°ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…¥é—¨LLMçš„æ•™ç¨‹ã€‚&lt;/li&gt; 
 &lt;li&gt;å¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºæ‰€æœ‰äººæä¾›ä¸€ä¸ªæŠ›ç –å¼•ç‰çš„ç¤ºä¾‹ï¼Œä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£ï¼æ¨åŠ¨æ›´å¹¿æ³›AIç¤¾åŒºçš„è¿›æ­¥ï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸ºé˜²æ­¢è¯¯è§£ï¼Œâ€œ2å°æ—¶â€ åŸºäºNVIDIA 3090ç¡¬ä»¶è®¾å¤‡ï¼ˆå•å¡ï¼‰æµ‹è¯•ï¼Œâ€œ3å—é’±â€æŒ‡GPUæœåŠ¡å™¨ç§Ÿç”¨æˆæœ¬ï¼Œå…·ä½“è§„æ ¼è¯¦æƒ…è§ä¸‹æ–‡ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif" alt="minimind2" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning"&gt;ğŸ”—ğŸ“æ¨ç†æ¨¡å‹&lt;/a&gt; | &lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind"&gt;ğŸ”—ğŸ¤–å¸¸è§„æ¨¡å‹&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8"&gt;ğŸ”—ğŸï¸è§†é¢‘ä»‹ç»&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align="center"&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png" alt="Hugging Face Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align="center"&gt; &lt;a href="https://www.modelscope.cn/profile/gongjy" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png" alt="ModelScope Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;ğŸ“Œ Introduction&lt;/h1&gt; 
&lt;p&gt;å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰çš„å‡ºç°å¼•å‘äº†å…¨ä¸–ç•Œå¯¹AIçš„ç©ºå‰å…³æ³¨ã€‚ æ— è®ºæ˜¯ChatGPTã€DeepSeekè¿˜æ˜¯Qwenï¼Œéƒ½ä»¥å…¶æƒŠè‰³çš„æ•ˆæœä»¤äººå¹ä¸ºè§‚æ­¢ã€‚ ç„¶è€Œï¼ŒåŠ¨è¾„æ•°ç™¾äº¿å‚æ•°çš„åºå¤§è§„æ¨¡ï¼Œä½¿å¾—å®ƒä»¬å¯¹ä¸ªäººè®¾å¤‡è€Œè¨€ä¸ä»…éš¾ä»¥è®­ç»ƒï¼Œç”šè‡³è¿éƒ¨ç½²éƒ½æ˜¾å¾—é¥ä¸å¯åŠã€‚ æ‰“å¼€å¤§æ¨¡å‹çš„â€œé»‘ç›’å­â€ï¼Œæ¢ç´¢å…¶å†…éƒ¨è¿ä½œæœºåˆ¶ï¼Œå¤šä¹ˆä»¤äººå¿ƒæ½®æ¾æ¹ƒï¼ é—æ†¾çš„æ˜¯ï¼Œ99%çš„æ¢ç´¢åªèƒ½æ­¢æ­¥äºä½¿ç”¨LoRAç­‰æŠ€æœ¯å¯¹ç°æœ‰å¤§æ¨¡å‹è¿›è¡Œå°‘é‡å¾®è°ƒï¼Œå­¦ä¹ ä¸€äº›æ–°æŒ‡ä»¤æˆ–ä»»åŠ¡ã€‚ è¿™å°±å¥½æ¯”æ•™ç‰›é¡¿å¦‚ä½•ä½¿ç”¨21ä¸–çºªçš„æ™ºèƒ½æ‰‹æœºâ€”â€”è™½ç„¶æœ‰è¶£ï¼Œå´å®Œå…¨åç¦»äº†ç†è§£ç‰©ç†æœ¬è´¨çš„åˆè¡·ã€‚ ä¸æ­¤åŒæ—¶ï¼Œç¬¬ä¸‰æ–¹çš„å¤§æ¨¡å‹æ¡†æ¶å’Œå·¥å…·åº“ï¼Œå¦‚transformers+trlï¼Œå‡ ä¹åªæš´éœ²äº†é«˜åº¦æŠ½è±¡çš„æ¥å£ã€‚ é€šè¿‡çŸ­çŸ­10è¡Œä»£ç ï¼Œå°±èƒ½å®Œæˆâ€œåŠ è½½æ¨¡å‹+åŠ è½½æ•°æ®é›†+æ¨ç†+å¼ºåŒ–å­¦ä¹ â€çš„å…¨æµç¨‹è®­ç»ƒã€‚ è¿™ç§é«˜æ•ˆçš„å°è£…å›ºç„¶ä¾¿åˆ©ï¼Œä½†ä¹Ÿåƒä¸€æ¶é«˜é€Ÿé£èˆ¹ï¼Œå°†å¼€å‘è€…ä¸åº•å±‚å®ç°éš”ç¦»å¼€æ¥ï¼Œé˜»ç¢äº†æ·±å…¥æ¢ç©¶LLMæ ¸å¿ƒä»£ç çš„æœºä¼šã€‚ ç„¶è€Œï¼Œâ€œç”¨ä¹é«˜æ‹¼å‡ºä¸€æ¶é£æœºï¼Œè¿œæ¯”ååœ¨å¤´ç­‰èˆ±é‡Œé£è¡Œæ›´è®©äººå…´å¥‹ï¼â€ã€‚ æ›´ç³Ÿç³•çš„æ˜¯ï¼Œäº’è”ç½‘ä¸Šå……æ–¥ç€å¤§é‡ä»˜è´¹è¯¾ç¨‹å’Œè¥é”€å·ï¼Œä»¥æ¼æ´ç™¾å‡ºã€ä¸€çŸ¥åŠè§£çš„å†…å®¹æ¨é”€AIæ•™ç¨‹ã€‚ æ­£å› å¦‚æ­¤ï¼Œæœ¬é¡¹ç›®åˆè¡·æ˜¯æ‹‰ä½LLMçš„å­¦ä¹ é—¨æ§›ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½ä»ç†è§£æ¯ä¸€è¡Œä»£ç å¼€å§‹ï¼Œ ä»é›¶å¼€å§‹äº²æ‰‹è®­ç»ƒä¸€ä¸ªæå°çš„è¯­è¨€æ¨¡å‹ã€‚æ˜¯çš„ï¼Œä»&lt;strong&gt;é›¶å¼€å§‹è®­ç»ƒ&lt;/strong&gt;ï¼Œè€Œä¸æ˜¯ä»…ä»…è¿›è¡Œ&lt;strong&gt;æ¨ç†&lt;/strong&gt;ï¼ æœ€ä½åªéœ€3å—é’±ä¸åˆ°çš„æœåŠ¡å™¨æˆæœ¬ï¼Œå°±èƒ½äº²èº«ä½“éªŒä»0åˆ°1æ„å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å…¨è¿‡ç¨‹ã€‚ ä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£å§ï¼&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ï¼ˆæˆªè‡³2025-10ï¼‰MiniMindç³»åˆ—å·²å®Œæˆå¤šä¸ªå‹å·æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œæœ€å°ä»…éœ€25.8Mï¼ˆ0.02Bï¼‰ï¼Œå³å¯å…·å¤‡æµç•…å¯¹è¯èƒ½åŠ›ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;æ¨¡å‹ (å¤§å°)&lt;/th&gt; 
    &lt;th&gt;æ¨ç†å ç”¨ (çº¦)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4Ã—26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;é¡¹ç›®åŒ…å«&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLMç»“æ„çš„å…¨éƒ¨ä»£ç ï¼ˆDense+MoEæ¨¡å‹ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;åŒ…å«Tokenizeråˆ†è¯å™¨è¯¦ç»†è®­ç»ƒä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;åŒ…å«Pretrainã€SFTã€LoRAã€RLHF-DPOã€RLAIF(PPO/GRPO/SPO)ã€æ¨¡å‹è’¸é¦çš„å…¨è¿‡ç¨‹è®­ç»ƒä»£ç ã€‚&lt;/li&gt; 
 &lt;li&gt;æ”¶é›†ã€è’¸é¦ã€æ•´ç†å¹¶æ¸…æ´—å»é‡æ‰€æœ‰é˜¶æ®µçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚&lt;/li&gt; 
 &lt;li&gt;ä»0å®ç°é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒã€LoRAã€DPO/PPO/GRPO/SPOå¼ºåŒ–å­¦ä¹ ï¼Œç™½ç›’æ¨¡å‹è’¸é¦ã€‚å…³é”®ç®—æ³•å‡ ä¹ä¸ä¾èµ–ç¬¬ä¸‰æ–¹å°è£…çš„æ¡†æ¶ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚&lt;/li&gt; 
 &lt;li&gt;åŒæ—¶å…¼å®¹&lt;code&gt;transformers&lt;/code&gt;ã€&lt;code&gt;trl&lt;/code&gt;ã€&lt;code&gt;peft&lt;/code&gt;ç­‰ç¬¬ä¸‰æ–¹ä¸»æµæ¡†æ¶ã€‚&lt;/li&gt; 
 &lt;li&gt;è®­ç»ƒæ”¯æŒå•æœºå•å¡ã€å•æœºå¤šå¡(DDPã€DeepSpeed)è®­ç»ƒï¼Œæ”¯æŒwandb/swanlabå¯è§†åŒ–è®­ç»ƒæµç¨‹ã€‚æ”¯æŒåŠ¨æ€å¯åœè®­ç»ƒã€‚&lt;/li&gt; 
 &lt;li&gt;åœ¨ç¬¬ä¸‰æ–¹æµ‹è¯„æ¦œï¼ˆC-Evalã€C-MMLUã€OpenBookQAç­‰ï¼‰è¿›è¡Œæ¨¡å‹æµ‹è¯•ï¼Œæ”¯æŒYaRNç®—æ³•æ‰§è¡ŒRoPEé•¿æ–‡æœ¬å¤–æ¨ã€‚&lt;/li&gt; 
 &lt;li&gt;å®ç°Openai-Apiåè®®çš„æç®€æœåŠ¡ç«¯ï¼Œä¾¿äºé›†æˆåˆ°ç¬¬ä¸‰æ–¹ChatUIä½¿ç”¨ï¼ˆFastGPTã€Open-WebUIç­‰ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;åŸºäºstreamlitå®ç°æœ€ç®€èŠå¤©WebUIå‰ç«¯ã€‚&lt;/li&gt; 
 &lt;li&gt;å…¨é¢å…¼å®¹ç¤¾åŒºçƒ­é—¨&lt;code&gt;llama.cpp&lt;/code&gt;ã€&lt;code&gt;vllm&lt;/code&gt;ã€&lt;code&gt;ollama&lt;/code&gt;æ¨ç†å¼•æ“æˆ–&lt;code&gt;Llama-Factory&lt;/code&gt;è®­ç»ƒæ¡†æ¶ã€‚&lt;/li&gt; 
 &lt;li&gt;å¤ç°(è’¸é¦/RL)å¤§å‹æ¨ç†æ¨¡å‹DeepSeek-R1çš„MiniMind-Reasonæ¨¡å‹ï¼Œ&lt;strong&gt;æ•°æ®+æ¨¡å‹&lt;/strong&gt;å…¨éƒ¨å¼€æºï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¸Œæœ›æ­¤å¼€æºé¡¹ç›®å¯ä»¥å¸®åŠ©LLMåˆå­¦è€…å¿«é€Ÿå…¥é—¨ï¼&lt;/p&gt; 
&lt;h3&gt;ğŸ‘‰&lt;strong&gt;æ›´æ–°æ—¥å¿—&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-10-24&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ”¥ æ–°å¢RLAIFè®­ç»ƒç®—æ³•ï¼šPPOã€GRPOã€SPOï¼ˆä»0åŸç”Ÿå®ç°ï¼‰&lt;/li&gt; 
  &lt;li&gt;æ–°å¢æ–­ç‚¹ç»­è®­åŠŸèƒ½ï¼šæ”¯æŒè®­ç»ƒè‡ªåŠ¨æ¢å¤ã€è·¨GPUæ•°é‡æ¢å¤ã€wandbè®°å½•è¿ç»­æ€§&lt;/li&gt; 
  &lt;li&gt;æ–°å¢RLAIFæ•°æ®é›†ï¼šrlaif-mini.jsonlï¼ˆä»SFTæ•°æ®éšæœºé‡‡æ ·1ä¸‡æ¡ï¼‰ï¼›ç®€åŒ–DPOæ•°æ®é›†ï¼ŒåŠ å…¥ä¸­æ–‡æ•°æ®&lt;/li&gt; 
  &lt;li&gt;æ–°å¢YaRNç®—æ³•ï¼šæ”¯æŒRoPEé•¿æ–‡æœ¬å¤–æ¨ï¼Œæå‡é•¿åºåˆ—å¤„ç†èƒ½åŠ›&lt;/li&gt; 
  &lt;li&gt;Adaptive Thinkingï¼šReasonæ¨¡å‹å¯é€‰æ˜¯å¦å¯ç”¨æ€è€ƒé“¾&lt;/li&gt; 
  &lt;li&gt;chat_templateå…¨é¢æ”¯æŒTool Callingå’ŒReasoningæ ‡ç­¾ï¼ˆ&lt;code&gt;&amp;lt;tool_call&amp;gt;&lt;/code&gt;ã€&lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;ç­‰ï¼‰&lt;/li&gt; 
  &lt;li&gt;æ–°å¢RLAIFå®Œæ•´ç« èŠ‚ã€è®­ç»ƒæ›²çº¿å¯¹æ¯”ã€ç®—æ³•åŸç†æŠ˜å è¯´æ˜&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swanlab.cn/"&gt;SwanLab&lt;/a&gt;æ›¿ä»£WandBï¼ˆå›½å†…è®¿é—®å‹å¥½ï¼ŒAPIå®Œå…¨å…¼å®¹ï¼‰&lt;/li&gt; 
  &lt;li&gt;è§„èŒƒåŒ–æ‰€æœ‰ä»£ç  &amp;amp; ä¿®å¤ä¸€äº›å·²çŸ¥bugs&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-04-26&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é‡è¦æ›´æ–°&lt;/li&gt; 
  &lt;li&gt;å¦‚æœ‰å…¼å®¹æ€§éœ€è¦ï¼Œå¯è®¿é—®&lt;a href="https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a"&gt;ğŸ”—æ—§ä»“åº“å†…å®¹ğŸ”—&lt;/a&gt;ã€‚&lt;/li&gt; 
  &lt;li&gt;MiniMindæ¨¡å‹å‚æ•°å®Œå…¨æ”¹åï¼Œå¯¹é½Transformersåº“æ¨¡å‹ï¼ˆç»Ÿä¸€å‘½åï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;generateæ–¹å¼é‡æ„ï¼Œç»§æ‰¿è‡ªGenerationMixinç±»ã€‚&lt;/li&gt; 
  &lt;li&gt;ğŸ”¥æ”¯æŒllama.cppã€vllmã€ollamaç­‰çƒ­é—¨ä¸‰æ–¹ç”Ÿæ€ã€‚&lt;/li&gt; 
  &lt;li&gt;è§„èŒƒä»£ç å’Œç›®å½•ç»“æ„ã€‚&lt;/li&gt; 
  &lt;li&gt;æ”¹åŠ¨è¯è¡¨&lt;code&gt;&amp;lt;s&amp;gt;&amp;lt;/s&amp;gt;&lt;/code&gt;-&amp;gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;ä¸ºå…¼å®¹ç¬¬ä¸‰æ–¹æ¨ç†æ¡†æ¶llama.cppã€vllmï¼Œæœ¬æ¬¡æ›´æ–°éœ€ä»˜å‡ºä¸€äº›å¯è§‚ä»£ä»·ã€‚
æœ¬æ¬¡æ›´æ–°ä¸å†æ”¯æŒã€Œç›´æ¥ã€åŠ è½½25-04-26ä»¥å‰çš„æ—§æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚
ç”±äºLlamaä½ç½®ç¼–ç æ–¹å¼ä¸minimindå­˜åœ¨åŒºåˆ«ï¼Œå¯¼è‡´æ˜ å°„Llamaæ¨¡å‹åQKå€¼å­˜åœ¨å·®å¼‚
MiniMind2ç³»åˆ—æ—§æ¨¡å‹å‡ç»è¿‡æƒé‡æ˜ å°„+ï¼ˆå¾®è°ƒè®­ç»ƒï¼‰QKVOçº¿æ€§å±‚æ ¡å‡†æ¢å¤è€Œæ¥ã€‚
æœ¬æ¬¡æ›´æ–°åå°†æ”¾å¼ƒå¯¹`minimind-v1`å…¨ç³»åˆ—çš„ç»´æŠ¤ï¼Œå¹¶åœ¨ä»“åº“ä¸­ä¸‹çº¿ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è¿æ¥å‘å¸ƒä»¥æ¥é‡å¤§æ›´æ–°ï¼ŒRelease MiniMind2 Seriesã€‚&lt;/li&gt; 
  &lt;li&gt;ä»£ç å‡ ä¹å…¨éƒ¨é‡æ„ï¼Œä½¿ç”¨æ›´ç®€æ´æ˜äº†çš„ç»Ÿä¸€ç»“æ„ã€‚ å¦‚æœ‰æ—§ä»£ç çš„å…¼å®¹æ€§éœ€è¦ï¼Œå¯è®¿é—®&lt;a href="https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb"&gt;ğŸ”—æ—§ä»“åº“å†…å®¹ğŸ”—&lt;/a&gt;ã€‚&lt;/li&gt; 
  &lt;li&gt;å…å»æ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚ç»Ÿä¸€æ•°æ®é›†æ ¼å¼ï¼Œæ›´æ¢ä¸º&lt;code&gt;jsonl&lt;/code&gt;æ ¼å¼æœç»æ•°æ®é›†ä¸‹è½½æ··ä¹±çš„é—®é¢˜ã€‚&lt;/li&gt; 
  &lt;li&gt;MiniMind2ç³»åˆ—æ•ˆæœç›¸æ¯”MiniMind-V1æ˜¾è‘—æå‡ã€‚&lt;/li&gt; 
  &lt;li&gt;å°é—®é¢˜ï¼š{kv-cacheå†™æ³•æ›´æ ‡å‡†ã€MoEçš„è´Ÿè½½å‡è¡¡lossè¢«è€ƒè™‘ç­‰ç­‰}&lt;/li&gt; 
  &lt;li&gt;æä¾›æ¨¡å‹è¿ç§»åˆ°ç§æœ‰æ•°æ®é›†çš„è®­ç»ƒæ–¹æ¡ˆï¼ˆåŒ»ç–—æ¨¡å‹ã€è‡ªæˆ‘è®¤çŸ¥æ ·ä¾‹ï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;ç²¾ç®€é¢„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶å¤§å¹…æå‡é¢„è®­ç»ƒæ•°æ®è´¨é‡ï¼Œå¤§å¹…ç¼©çŸ­ä¸ªäººå¿«é€Ÿè®­ç»ƒæ‰€éœ€æ—¶é—´ï¼Œå•å¡3090å³å¯2å°æ—¶å¤ç°ï¼&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°ï¼šLoRAå¾®è°ƒè„±ç¦»peftåŒ…è£…ï¼Œä»0å®ç°LoRAè¿‡ç¨‹ï¼›DPOç®—æ³•ä»0ä½¿ç”¨PyTorchåŸç”Ÿå®ç°ï¼›æ¨¡å‹ç™½ç›’è’¸é¦åŸç”Ÿå®ç°ã€‚&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¯ç”Ÿï¼&lt;/li&gt; 
  &lt;li&gt;MiniMind2å…·å¤‡ä¸€å®šçš„è‹±æ–‡èƒ½åŠ›ï¼&lt;/li&gt; 
  &lt;li&gt;æ›´æ–°MiniMind2ä¸ç¬¬ä¸‰æ–¹æ¨¡å‹çš„åŸºäºæ›´å¤šå¤§æ¨¡å‹æ¦œå•æµ‹è¯•æ€§èƒ½çš„ç»“æœã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;More...&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;2024-10-05&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ä¸ºMiniMindæ‹“å±•äº†å¤šæ¨¡æ€èƒ½åŠ›ä¹‹---è§†è§‰&lt;/li&gt; 
  &lt;li&gt;ç§»æ­¥å­ªç”Ÿé¡¹ç›®&lt;a href="https://github.com/jingyaogong/minimind-v"&gt;minimind-v&lt;/a&gt;æŸ¥çœ‹è¯¦æƒ…ï¼&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-27&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27æ›´æ–°pretrainæ•°æ®é›†çš„é¢„å¤„ç†æ–¹å¼ï¼Œä¸ºäº†ä¿è¯æ–‡æœ¬å®Œæ•´æ€§ï¼Œæ”¾å¼ƒé¢„å¤„ç†æˆ.binè®­ç»ƒçš„å½¢å¼ï¼ˆè½»å¾®ç‰ºç‰²è®­ç»ƒé€Ÿåº¦ï¼‰ã€‚&lt;/li&gt; 
  &lt;li&gt;ç›®å‰pretrainé¢„å¤„ç†åçš„æ–‡ä»¶å‘½åä¸ºï¼špretrain_data.csvã€‚&lt;/li&gt; 
  &lt;li&gt;åˆ é™¤äº†ä¸€äº›å†—ä½™çš„ä»£ç ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-17&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›´æ–°minimind-v1-moeæ¨¡å‹&lt;/li&gt; 
  &lt;li&gt;ä¸ºäº†é˜²æ­¢æ­§ä¹‰ï¼Œä¸å†ä½¿ç”¨mistral_tokenizeråˆ†è¯ï¼Œå…¨éƒ¨é‡‡ç”¨è‡ªå®šä¹‰çš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-01&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ›´æ–°minimind-v1 (108M)æ¨¡å‹ï¼Œé‡‡ç”¨minimind_tokenizerï¼Œé¢„è®­ç»ƒè½®æ¬¡3 + SFTè½®æ¬¡10ï¼Œæ›´å……åˆ†è®­ç»ƒï¼Œæ€§èƒ½æ›´å¼ºã€‚&lt;/li&gt; 
  &lt;li&gt;é¡¹ç›®å·²éƒ¨ç½²è‡³ModelScopeåˆ›ç©ºé—´ï¼Œå¯ä»¥åœ¨æ­¤ç½‘ç«™ä¸Šä½“éªŒï¼š&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/minimind"&gt;ğŸ”—ModelScopeåœ¨çº¿ä½“éªŒğŸ”—&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-08-27&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;é¡¹ç›®é¦–æ¬¡å¼€æº&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ å¿«é€Ÿå¼€å§‹&lt;/h1&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;åˆ†äº«æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®ï¼ˆä»…ä¾›å‚è€ƒï¼‰&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ç¬¬0æ­¥&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…  æµ‹è¯•å·²æœ‰æ¨¡å‹æ•ˆæœ&lt;/h2&gt; 
&lt;h3&gt;1.ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.ä¸‹è½½æ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;åˆ°é¡¹ç›®æ ¹ç›®å½•&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://huggingface.co/jingyaogong/MiniMind2 # or https://www.modelscope.cn/models/gongjy/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ï¼ˆå¯é€‰ï¼‰å‘½ä»¤è¡Œé—®ç­”&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ä½¿ç”¨transformersæ ¼å¼æ¨¡å‹
python eval_llm.py --load_from ./MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ï¼ˆå¯é€‰ï¼‰å¯åŠ¨WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å¯èƒ½éœ€è¦`python&amp;gt;=3.10` å®‰è£… `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ï¼ˆå¯é€‰ï¼‰ç¬¬ä¸‰æ–¹æ¨ç†æ¡†æ¶&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¡ ä»0å¼€å§‹è‡ªå·±è®­ç»ƒ&lt;/h2&gt; 
&lt;h3&gt;1.ç¯å¢ƒå‡†å¤‡&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šæå‰æµ‹è¯•Torchæ˜¯å¦å¯ç”¨cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;å¦‚æœä¸å¯ç”¨ï¼Œè¯·è‡ªè¡Œå»&lt;a href="https://download.pytorch.org/whl/torch_stable.html"&gt;torch_stable&lt;/a&gt; ä¸‹è½½whlæ–‡ä»¶å®‰è£…ã€‚å‚è€ƒ&lt;a href="https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187"&gt;é“¾æ¥&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.æ•°æ®ä¸‹è½½&lt;/h3&gt; 
&lt;p&gt;ä»ä¸‹æ–‡æä¾›çš„&lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;æ•°æ®é›†ä¸‹è½½é“¾æ¥&lt;/a&gt; ä¸‹è½½éœ€è¦çš„æ•°æ®æ–‡ä»¶ï¼ˆåˆ›å»º&lt;code&gt;./dataset&lt;/code&gt;ç›®å½•ï¼‰å¹¶æ”¾åˆ°&lt;code&gt;./dataset&lt;/code&gt;ä¸‹&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šæ•°æ®é›†é¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;é»˜è®¤æ¨èä¸‹è½½&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;æœ€å¿«é€Ÿåº¦å¤ç°ZeroèŠå¤©æ¨¡å‹ã€‚&lt;/p&gt; 
 &lt;p&gt;æ•°æ®æ–‡ä»¶å¯è‡ªç”±é€‰æ‹©ï¼Œä¸‹æ–‡æä¾›äº†å¤šç§æ­é…æ–¹æ¡ˆï¼Œå¯æ ¹æ®è‡ªå·±æ‰‹å¤´çš„è®­ç»ƒéœ€æ±‚å’ŒGPUèµ„æºè¿›è¡Œé€‚å½“ç»„åˆã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.å¼€å§‹è®­ç»ƒ&lt;/h3&gt; 
&lt;p&gt;ç›®å½•ä½äº&lt;code&gt;trainer&lt;/code&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ğŸ’¡ æ£€æŸ¥ç‚¹æš‚åœç»­è®­&lt;/summary&gt; 
 &lt;p&gt;æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡è‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œåªéœ€æ·»åŠ  &lt;code&gt;--from_resume 1&lt;/code&gt; å‚æ•°å³å¯è‡ªåŠ¨æ£€æµ‹åŠ è½½&amp;amp;æ¢å¤è®­ç»ƒï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py --from_resume 1
python train_full_sft.py --from_resume 1
...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;æ–­ç‚¹ç»­è®­æœºåˆ¶è¯´æ˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;è®­ç»ƒè¿‡ç¨‹è‡ªåŠ¨åœ¨ &lt;code&gt;./checkpoints/&lt;/code&gt; ç›®å½•ä¿å­˜å®Œæ•´æ£€æŸ¥ç‚¹ï¼ˆæ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è®­ç»ƒè¿›åº¦ç­‰ï¼‰&lt;/li&gt; 
  &lt;li&gt;æ£€æŸ¥ç‚¹æ–‡ä»¶å‘½åï¼š&lt;code&gt;&amp;lt;æƒé‡å&amp;gt;_&amp;lt;ç»´åº¦&amp;gt;_resume.pth&lt;/code&gt;ï¼ˆå¦‚ï¼š&lt;code&gt;full_sft_512_resume.pth&lt;/code&gt;ï¼‰&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒè·¨ä¸åŒGPUæ•°é‡æ¢å¤ï¼ˆè‡ªåŠ¨è°ƒæ•´stepï¼‰&lt;/li&gt; 
  &lt;li&gt;æ”¯æŒwandbè®­ç»ƒè®°å½•è¿ç»­æ€§ï¼ˆè‡ªåŠ¨æ¢å¤åŒä¸€ä¸ªrunï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;é€‚åˆé•¿æ—¶é—´è®­ç»ƒæˆ–ä¸ç¨³å®šç¯å¢ƒï¼Œæ— éœ€æ‹…å¿ƒè®­ç»ƒä¸­æ–­å¯¼è‡´è¿›åº¦ä¸¢å¤±&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;3.1 é¢„è®­ç»ƒï¼ˆå­¦çŸ¥è¯†ï¼‰&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰§è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ° &lt;code&gt;pretrain_*.pth&lt;/code&gt; ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­*ä¸ºæ¨¡å‹çš„dimensionï¼Œé»˜è®¤ä¸º512ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 ç›‘ç£å¾®è°ƒï¼ˆå­¦å¯¹è¯æ–¹å¼ï¼‰&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰§è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° &lt;code&gt;full_sft_*.pth&lt;/code&gt; ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­&lt;code&gt;full&lt;/code&gt;å³ä¸ºå…¨å‚æ•°å¾®è°ƒï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šè®­ç»ƒé¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš”100æ­¥ä¿å­˜1æ¬¡å‚æ•°åˆ°æ–‡ä»¶&lt;code&gt;./out/***.pth&lt;/code&gt;ï¼ˆæ¯æ¬¡ä¼šè¦†ç›–æ‰æ—§æƒé‡æ–‡ä»¶ï¼‰ã€‚&lt;/p&gt; 
 &lt;p&gt;ç®€å•èµ·è§ï¼Œæ­¤å¤„åªå†™æ˜ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒè¿‡ç¨‹ã€‚å¦‚éœ€å…¶å®ƒè®­ç»ƒ (LoRA, è’¸é¦, å¼ºåŒ–å­¦ä¹ , å¾®è°ƒæ¨ç†ç­‰) å¯å‚è€ƒä¸‹æ–‡ã€å®éªŒã€‘å°èŠ‚çš„è¯¦ç»†è¯´æ˜ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4.æµ‹è¯•è‡ªå·±è®­ç»ƒçš„æ¨¡å‹æ•ˆæœ&lt;/h3&gt; 
&lt;p&gt;ç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹&lt;code&gt;*.pth&lt;/code&gt;æ–‡ä»¶ä½äº&lt;code&gt;./out/&lt;/code&gt;ç›®å½•ä¸‹ã€‚ ä¹Ÿå¯ä»¥ç›´æ¥å»&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files"&gt;æ­¤å¤„&lt;/a&gt;ä¸‹è½½ä½¿ç”¨æˆ‘è®­ç»ƒçš„&lt;code&gt;*.pth&lt;/code&gt;æ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_llm.py --weight full_sft # æˆ– pretrain/dpo/ppo/grpo...
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šæµ‹è¯•é¡»çŸ¥&lt;/summary&gt; 
 &lt;p&gt;&lt;code&gt;--weight&lt;/code&gt; å‚æ•°æŒ‡å®šæƒé‡åç§°å‰ç¼€ï¼Œå¯é€‰ï¼š&lt;code&gt;pretrain&lt;/code&gt;, &lt;code&gt;full_sft&lt;/code&gt;, &lt;code&gt;dpo&lt;/code&gt;, &lt;code&gt;reason&lt;/code&gt;, &lt;code&gt;ppo_actor&lt;/code&gt;, &lt;code&gt;grpo&lt;/code&gt;, &lt;code&gt;spo&lt;/code&gt; ç­‰&lt;/p&gt; 
 &lt;p&gt;å…¶ä»–å¸¸ç”¨å‚æ•°ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;--load_from&lt;/code&gt;: æ¨¡å‹åŠ è½½è·¯å¾„ï¼ˆ&lt;code&gt;model&lt;/code&gt;=åŸç”Ÿtorchæƒé‡ï¼Œå…¶ä»–è·¯å¾„=transformersæ ¼å¼ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--save_dir&lt;/code&gt;: æ¨¡å‹æƒé‡ç›®å½•ï¼ˆé»˜è®¤&lt;code&gt;out&lt;/code&gt;ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--lora_weight&lt;/code&gt;: LoRAæƒé‡åç§°ï¼ˆ&lt;code&gt;None&lt;/code&gt;è¡¨ç¤ºä¸ä½¿ç”¨ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--historys&lt;/code&gt;: æºå¸¦å†å²å¯¹è¯è½®æ•°ï¼ˆéœ€ä¸ºå¶æ•°ï¼Œ0è¡¨ç¤ºä¸æºå¸¦å†å²ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--max_new_tokens&lt;/code&gt;: æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆé»˜è®¤8192ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--temperature&lt;/code&gt;: ç”Ÿæˆæ¸©åº¦ï¼ˆé»˜è®¤0.85ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--top_p&lt;/code&gt;: nucleusé‡‡æ ·é˜ˆå€¼ï¼ˆé»˜è®¤0.85ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ä½¿ç”¨æ–¹å¼ç›´æ¥æŸ¥çœ‹&lt;code&gt;eval_llm.py&lt;/code&gt;ä»£ç å³å¯ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ä¸ºPytorchåŸç”Ÿæ¡†æ¶ï¼Œå‡æ”¯æŒå¤šå¡åŠ é€Ÿï¼Œå‡è®¾ä½ çš„è®¾å¤‡æœ‰N (Nï¼1) å¼ æ˜¾å¡ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;å•æœºNå¡å¯åŠ¨è®­ç»ƒæ–¹å¼ (DDP, æ”¯æŒå¤šæœºå¤šå¡é›†ç¾¤)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šå…¶å®ƒé¡»çŸ¥&lt;/summary&gt; 
 &lt;del&gt; å•æœºNå¡å¯åŠ¨è®­ç»ƒ (DeepSpeed) &lt;pre&gt;&lt;code class="language-bash"&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; &lt;/del&gt; 
 &lt;p&gt;å¯æ ¹æ®éœ€è¦å¼€å¯wandbè®°å½•è®­ç»ƒè¿‡ç¨‹ï¼ˆéœ€å¯ç›´è¿ï¼‰&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# éœ€è¦ç™»å½•: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;é€šè¿‡æ·»åŠ &lt;code&gt;--use_wandb&lt;/code&gt;å‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹&lt;code&gt;wandb_project&lt;/code&gt; å’Œ&lt;code&gt;wandb_run_name&lt;/code&gt;å‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚&lt;/p&gt; 
 &lt;p&gt;ã€æ³¨ã€‘ï¼š25å¹´6æœˆåï¼Œå›½å†…ç½‘ç»œç¯å¢ƒæ— æ³•ç›´è¿WandBï¼ŒMiniMindé¡¹ç›®é»˜è®¤è½¬ä¸ºä½¿ç”¨&lt;a href="https://swanlab.cn/"&gt;SwanLab&lt;/a&gt;ä½œä¸ºè®­ç»ƒå¯è§†åŒ–å·¥å…·ï¼ˆå®Œå…¨å…¼å®¹WandB APIï¼‰ï¼Œå³&lt;code&gt;import wandb&lt;/code&gt;æ”¹ä¸º&lt;code&gt;import swanlab as wandb&lt;/code&gt;å³å¯ï¼Œå…¶ä»–å‡æ— éœ€æ”¹åŠ¨ã€‚&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ æ•°æ®ä»‹ç»&lt;/h1&gt; 
&lt;h2&gt;â…  Tokenizer&lt;/h2&gt; 
&lt;p&gt;åˆ†è¯å™¨å°†å•è¯ä»è‡ªç„¶è¯­è¨€é€šè¿‡â€œè¯å…¸â€æ˜ å°„åˆ°&lt;code&gt;0, 1, 36&lt;/code&gt;è¿™æ ·çš„æ•°å­—ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°å­—å°±ä»£è¡¨äº†å•è¯åœ¨â€œè¯å…¸â€ä¸­çš„é¡µç ã€‚ å¯ä»¥é€‰æ‹©è‡ªå·±æ„é€ è¯è¡¨è®­ç»ƒä¸€ä¸ªâ€œè¯å…¸â€ï¼Œä»£ç å¯è§&lt;code&gt;./scripts/train_tokenizer.py&lt;/code&gt;ï¼ˆä»…ä¾›å­¦ä¹ å‚è€ƒï¼Œè‹¥éå¿…è¦æ— éœ€å†è‡ªè¡Œè®­ç»ƒï¼ŒMiniMindå·²è‡ªå¸¦tokenizerï¼‰ã€‚ æˆ–è€…é€‰æ‹©æ¯”è¾ƒå‡ºåçš„å¼€æºå¤§æ¨¡å‹åˆ†è¯å™¨ï¼Œ æ­£å¦‚åŒç›´æ¥ç”¨æ–°å/ç‰›æ´¥è¯å…¸çš„ä¼˜ç‚¹æ˜¯tokenç¼–ç å‹ç¼©ç‡å¾ˆå¥½ï¼Œç¼ºç‚¹æ˜¯é¡µæ•°å¤ªå¤šï¼ŒåŠ¨è¾„æ•°åä¸‡ä¸ªè¯æ±‡çŸ­è¯­ï¼› è‡ªå·±è®­ç»ƒçš„åˆ†è¯å™¨ï¼Œä¼˜ç‚¹æ˜¯è¯è¡¨é•¿åº¦å’Œå†…å®¹éšæ„æ§åˆ¶ï¼Œç¼ºç‚¹æ˜¯å‹ç¼©ç‡å¾ˆä½ï¼ˆä¾‹å¦‚"hello"ä¹Ÿè®¸ä¼šè¢«æ‹†åˆ†ä¸º"h e l l o" äº”ä¸ªç‹¬ç«‹çš„tokenï¼‰ï¼Œä¸”ç”Ÿåƒ»è¯éš¾ä»¥è¦†ç›–ã€‚ â€œè¯å…¸â€çš„é€‰æ‹©å›ºç„¶å¾ˆé‡è¦ï¼ŒLLMçš„è¾“å‡ºæœ¬è´¨ä¸Šæ˜¯SoftMaxåˆ°è¯å…¸Nä¸ªè¯çš„å¤šåˆ†ç±»é—®é¢˜ï¼Œç„¶åé€šè¿‡â€œè¯å…¸â€è§£ç åˆ°è‡ªç„¶è¯­è¨€ã€‚ å› ä¸ºMiniMindä½“ç§¯éœ€è¦ä¸¥æ ¼æ§åˆ¶ï¼Œä¸ºäº†é¿å…æ¨¡å‹å¤´é‡è„šè½»ï¼ˆè¯åµŒå…¥embeddingå±‚å‚æ•°åœ¨LLMå æ¯”å¤ªé«˜ï¼‰ï¼Œæ‰€ä»¥è¯è¡¨é•¿åº¦çŸ­çŸ­ç›Šå–„ã€‚&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Tokenizerä»‹ç»&lt;/summary&gt; 
 &lt;p&gt;ç¬¬ä¸‰æ–¹å¼ºå¤§çš„å¼€æºæ¨¡å‹ä¾‹å¦‚Yiã€qwenã€chatglmã€mistralã€Llama3çš„tokenizerè¯è¡¨é•¿åº¦å¦‚ä¸‹ï¼š&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;Tokenizeræ¨¡å‹&lt;/th&gt;
    &lt;th&gt;è¯è¡¨å¤§å°&lt;/th&gt;
    &lt;th&gt;æ¥æº&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01ä¸‡ç‰©ï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;é˜¿é‡Œäº‘ï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;æ™ºè°±AIï¼ˆä¸­å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AIï¼ˆæ³•å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;Metaï¼ˆç¾å›½ï¼‰&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;è‡ªå®šä¹‰&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ğŸ‘‰2024-09-17æ›´æ–°ï¼šä¸ºäº†é˜²æ­¢è¿‡å»çš„ç‰ˆæœ¬æ­§ä¹‰&amp;amp;æ§åˆ¶ä½“ç§¯ï¼Œminimindæ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨minimind_tokenizeråˆ†è¯ï¼ŒåºŸå¼ƒæ‰€æœ‰mistral_tokenizerç‰ˆæœ¬ã€‚&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# ä¸€äº›è‡ªè¨€è‡ªè¯­
&amp;gt; å°½ç®¡minimind_tokenizeré•¿åº¦å¾ˆå°ï¼Œç¼–è§£ç æ•ˆç‡å¼±äºqwen2ã€glmç­‰ä¸­æ–‡å‹å¥½å‹åˆ†è¯å™¨ã€‚
&amp;gt; ä½†minimindæ¨¡å‹é€‰æ‹©äº†è‡ªå·±è®­ç»ƒçš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ï¼Œä»¥ä¿æŒæ•´ä½“å‚æ•°è½»é‡ï¼Œé¿å…ç¼–ç å±‚å’Œè®¡ç®—å±‚å æ¯”å¤±è¡¡ï¼Œå¤´é‡è„šè½»ï¼Œå› ä¸ºminimindçš„è¯è¡¨å¤§å°åªæœ‰6400ã€‚
&amp;gt; ä¸”minimindåœ¨å®é™…æµ‹è¯•ä¸­æ²¡æœ‰å‡ºç°è¿‡ç”Ÿåƒ»è¯æ±‡è§£ç å¤±è´¥çš„æƒ…å†µï¼Œæ•ˆæœè‰¯å¥½ã€‚
&amp;gt; ç”±äºè‡ªå®šä¹‰è¯è¡¨å‹ç¼©é•¿åº¦åˆ°6400ï¼Œä½¿å¾—LLMæ€»å‚æ•°é‡æœ€ä½åªæœ‰25.8Mã€‚
&amp;gt; è®­ç»ƒæ•°æ®`pretrain_hq.jsonl`å‡æ¥è‡ªäº`åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†`ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œå¦‚éœ€è®­ç»ƒå¯ä»¥è‡ªç”±é€‰æ‹©ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;â…¡ Pretrainæ•°æ®&lt;/h2&gt; 
&lt;p&gt;ç»å†äº†MiniMind-V1çš„ä½è´¨é‡é¢„è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹èƒ¡è¨€ä¹±è¯­çš„æ•™è®­ï¼Œ&lt;code&gt;2025-02-05&lt;/code&gt; ä¹‹åå†³å®šä¸å†é‡‡ç”¨å¤§è§„æ¨¡æ— ç›‘ç£çš„æ•°æ®é›†åšé¢„è®­ç»ƒã€‚ è¿›è€Œå°è¯•æŠŠ&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†&lt;/a&gt;çš„ä¸­æ–‡éƒ¨åˆ†æå–å‡ºæ¥ï¼Œ æ¸…æ´—å‡ºå­—ç¬¦&lt;code&gt;&amp;lt;512&lt;/code&gt;é•¿åº¦çš„å¤§çº¦1.6GBçš„è¯­æ–™ç›´æ¥æ‹¼æ¥æˆé¢„è®­ç»ƒæ•°æ® &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;ï¼Œhqå³ä¸ºhigh qualityï¼ˆå½“ç„¶ä¹Ÿè¿˜ä¸ç®—highï¼Œæå‡æ•°æ®è´¨é‡æ— æ­¢å°½ï¼‰ã€‚&lt;/p&gt; 
&lt;p&gt;æ–‡ä»¶&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{"text": "å¦‚ä½•æ‰èƒ½æ‘†è„±æ‹–å»¶ç—‡ï¼Ÿ æ²»æ„ˆæ‹–å»¶ç—‡å¹¶ä¸å®¹æ˜“ï¼Œä½†ä»¥ä¸‹å»ºè®®å¯èƒ½æœ‰æ‰€å¸®åŠ©..."}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¢ SFTæ•°æ®&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;åŒ æ•°å¤§æ¨¡å‹SFTæ•°æ®é›†&lt;/a&gt; â€œæ˜¯ä¸€ä¸ªå®Œæ•´ã€æ ¼å¼ç»Ÿä¸€ã€å®‰å…¨çš„å¤§æ¨¡å‹è®­ç»ƒå’Œç ”ç©¶èµ„æºã€‚ ä»ç½‘ç»œä¸Šçš„å…¬å¼€æ•°æ®æºæ”¶é›†å¹¶æ•´ç†äº†å¤§é‡å¼€æºæ•°æ®é›†ï¼Œå¯¹å…¶è¿›è¡Œäº†æ ¼å¼ç»Ÿä¸€ï¼Œæ•°æ®æ¸…æ´—ï¼Œ åŒ…å«10Mæ¡æ•°æ®çš„ä¸­æ–‡æ•°æ®é›†å’ŒåŒ…å«2Mæ¡æ•°æ®çš„è‹±æ–‡æ•°æ®é›†ã€‚â€ ä»¥ä¸Šæ˜¯å®˜æ–¹ä»‹ç»ï¼Œä¸‹è½½æ–‡ä»¶åçš„æ•°æ®æ€»é‡å¤§çº¦åœ¨4B tokensï¼Œè‚¯å®šæ˜¯é€‚åˆä½œä¸ºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹çš„SFTæ•°æ®çš„ã€‚ ä½†æ˜¯å®˜æ–¹æä¾›çš„æ•°æ®æ ¼å¼å¾ˆä¹±ï¼Œå…¨éƒ¨ç”¨æ¥sftä»£ä»·å¤ªå¤§ã€‚ æˆ‘å°†æŠŠå®˜æ–¹æ•°æ®é›†è¿›è¡Œäº†äºŒæ¬¡æ¸…æ´—ï¼ŒæŠŠå«æœ‰ç¬¦å·æ±¡æŸ“å’Œå™ªå£°çš„æ¡ç›®å»é™¤ï¼›å¦å¤–ä¾ç„¶åªä¿ç•™äº†æ€»é•¿åº¦&lt;code&gt;&amp;lt;512&lt;/code&gt; çš„å†…å®¹ï¼Œæ­¤é˜¶æ®µå¸Œæœ›é€šè¿‡å¤§é‡å¯¹è¯è¡¥å……é¢„è®­ç»ƒé˜¶æ®µæ¬ ç¼ºçš„çŸ¥è¯†ã€‚ å¯¼å‡ºæ–‡ä»¶ä¸º&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/organization/Magpie-Align"&gt;Magpie-SFTæ•°æ®é›†&lt;/a&gt; æ”¶é›†äº†~1Mæ¡æ¥è‡ªQwen2/2.5çš„é«˜è´¨é‡å¯¹è¯ï¼Œæˆ‘å°†è¿™éƒ¨åˆ†æ•°æ®è¿›ä¸€æ­¥æ¸…æ´—ï¼ŒæŠŠæ€»é•¿åº¦&lt;code&gt;&amp;lt;2048&lt;/code&gt;çš„éƒ¨åˆ†å¯¼å‡ºä¸º&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)ã€‚ é•¿åº¦&lt;code&gt;&amp;lt;1024&lt;/code&gt;çš„éƒ¨åˆ†å¯¼å‡ºä¸º&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)ï¼Œç”¨å¤§æ¨¡å‹å¯¹è¯æ•°æ®ç›´æ¥è¿›è¡Œsftå°±å±äºâ€œé»‘ç›’è’¸é¦â€çš„èŒƒç•´ã€‚&lt;/p&gt; 
&lt;p&gt;è¿›ä¸€æ­¥æ¸…æ´—å‰ä¸¤æ­¥sftçš„æ•°æ®ï¼ˆåªä¿ç•™ä¸­æ–‡å­—ç¬¦å æ¯”é«˜çš„å†…å®¹ï¼‰ï¼Œç­›é€‰é•¿åº¦&lt;code&gt;&amp;lt;512&lt;/code&gt;çš„å¯¹è¯ï¼Œå¾—åˆ°&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)ã€‚&lt;/p&gt; 
&lt;p&gt;æ‰€æœ‰sftæ–‡ä»¶ &lt;code&gt;sft_X.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼å‡ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
    "conversations": [
        {"role": "user", "content": "ä½ å¥½"},
        {"role": "assistant", "content": "ä½ å¥½ï¼"},
        {"role": "user", "content": "å†è§"},
        {"role": "assistant", "content": "å†è§ï¼"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…£ RLHFæ•°æ®&lt;/h2&gt; 
&lt;p&gt;æ¥è‡ª&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1"&gt;Magpie-DPOæ•°æ®é›†&lt;/a&gt; å¤§çº¦200kæ¡åå¥½æ•°æ®ï¼ˆå‡æ˜¯è‹±æ–‡ï¼‰ç”Ÿæˆè‡ªLlama3.1-70B/8Bï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œä¼˜åŒ–æ¨¡å‹å›å¤è´¨é‡ï¼Œä½¿å…¶æ›´åŠ ç¬¦åˆäººç±»åå¥½ã€‚ è¿™é‡Œå°†æ•°æ®æ€»é•¿åº¦&lt;code&gt;&amp;lt;3000&lt;/code&gt;çš„å†…å®¹é‡ç»„ä¸º&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)ï¼ŒåŒ…å«&lt;code&gt;chosen&lt;/code&gt;å’Œ&lt;code&gt;rejected&lt;/code&gt;ä¸¤ä¸ªå­—æ®µï¼Œ&lt;code&gt;chosen&lt;/code&gt; ä¸ºåå¥½çš„å›å¤ï¼Œ&lt;code&gt;rejected&lt;/code&gt;ä¸ºæ‹’ç»çš„å›å¤ã€‚&lt;/p&gt; 
&lt;p&gt;æ–‡ä»¶ &lt;code&gt;dpo.jsonl&lt;/code&gt; æ•°æ®æ ¼å¼ä¸º&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¤ Reasonæ•°æ®é›†ï¼š&lt;/h2&gt; 
&lt;p&gt;ä¸å¾—ä¸è¯´2025å¹´2æœˆè°èƒ½ç«çš„è¿‡DeepSeek... ä¹Ÿæ¿€å‘äº†æˆ‘å¯¹RLå¼•å¯¼çš„æ¨ç†æ¨¡å‹çš„æµ“åšå…´è¶£ï¼Œç›®å‰å·²ç»ç”¨Qwen2.5å¤ç°äº†R1-Zeroã€‚ å¦‚æœæœ‰æ—¶é—´+æ•ˆæœworkï¼ˆä½†99%åŸºæ¨¡èƒ½åŠ›ä¸è¶³ï¼‰æˆ‘ä¼šåœ¨ä¹‹åæ›´æ–°MiniMindåŸºäºRLè®­ç»ƒçš„æ¨ç†æ¨¡å‹è€Œä¸æ˜¯è’¸é¦æ¨¡å‹ã€‚ æ—¶é—´æœ‰é™ï¼Œæœ€å¿«çš„ä½æˆæœ¬æ–¹æ¡ˆä¾ç„¶æ˜¯ç›´æ¥è’¸é¦ï¼ˆé»‘ç›’æ–¹å¼ï¼‰ã€‚ è€ä¸ä½R1å¤ªç«ï¼ŒçŸ­çŸ­å‡ å¤©å°±å·²ç»å­˜åœ¨ä¸€äº›R1çš„è’¸é¦æ•°æ®é›†&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"&gt;R1-Llama-70B&lt;/a&gt;ã€&lt;a href="https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT"&gt;R1-Distill-SFT&lt;/a&gt;ã€ &lt;a href="https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH"&gt;Alpaca-Distill-R1&lt;/a&gt;ã€ &lt;a href="https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh"&gt;deepseek_r1_zh&lt;/a&gt;ç­‰ç­‰ï¼Œçº¯ä¸­æ–‡çš„æ•°æ®å¯èƒ½æ¯”è¾ƒå°‘ã€‚ æœ€ç»ˆæ•´åˆå®ƒä»¬ï¼Œå¯¼å‡ºæ–‡ä»¶ä¸º&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ï¼Œæ•°æ®æ ¼å¼å’Œ&lt;code&gt;sft_X.jsonl&lt;/code&gt;ä¸€è‡´ã€‚&lt;/p&gt; 
&lt;h2&gt;â…¥ æ›´å¤šæ•°æ®é›†&lt;/h2&gt; 
&lt;p&gt;ç›®å‰å·²ç»æœ‰&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; åœ¨æ”¶é›†å’Œæ¢³ç†ä¸­æ–‡LLMç›¸å…³çš„å¼€æºæ¨¡å‹ã€åº”ç”¨ã€æ•°æ®é›†åŠæ•™ç¨‹ç­‰èµ„æ–™ï¼Œå¹¶æŒç»­æ›´æ–°è¿™æ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚å…¨é¢ä¸”ä¸“ä¸šï¼ŒRespectï¼&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â…§ MiniMindè®­ç»ƒæ•°æ®é›†&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05åï¼Œå¼€æºMiniMindæœ€ç»ˆè®­ç»ƒæ‰€ç”¨çš„æ‰€æœ‰æ•°æ®é›†ï¼Œå› æ­¤æ— éœ€å†è‡ªè¡Œé¢„å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œé¿å…é‡å¤æ€§çš„æ•°æ®å¤„ç†å·¥ä½œã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMindè®­ç»ƒæ•°æ®é›†ä¸‹è½½åœ°å€ï¼š &lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ— éœ€å…¨éƒ¨cloneï¼Œå¯å•ç‹¬ä¸‹è½½æ‰€éœ€çš„æ–‡ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;å°†ä¸‹è½½çš„æ•°æ®é›†æ–‡ä»¶æ”¾åˆ°&lt;code&gt;./dataset/&lt;/code&gt;ç›®å½•ä¸‹ï¼ˆâœ¨ä¸ºæ¨èçš„å¿…é¡»é¡¹ï¼‰&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./dataset/
â”œâ”€â”€ dpo.jsonl (55MB, âœ¨)
â”œâ”€â”€ lora_identity.jsonl (22.8KB)
â”œâ”€â”€ lora_medical.jsonl (34MB)
â”œâ”€â”€ pretrain_hq.jsonl (1.6GB, âœ¨)
â”œâ”€â”€ r1_mix_1024.jsonl (340MB)
â”œâ”€â”€ rlaif-mini.jsonl (1MB)
â”œâ”€â”€ sft_1024.jsonl (5.6GB)
â”œâ”€â”€ sft_2048.jsonl (9GB)
â”œâ”€â”€ sft_512.jsonl (7.5GB)
â””â”€â”€ sft_mini_512.jsonl (1.2GB, âœ¨)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æ³¨ï¼šå„æ•°æ®é›†ç®€ä»‹&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt;âœ¨ --RLHFé˜¶æ®µæ•°æ®é›†ï¼ˆå·²ç²¾ç®€ä¼˜åŒ–ï¼Œé€‚åˆå¿«é€Ÿè®­ç»ƒï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼šä½ æ˜¯è°ï¼Ÿæˆ‘æ˜¯minimind...ï¼‰ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;âœ¨ --é¢„è®­ç»ƒæ•°æ®é›†ï¼Œæ•´åˆè‡ªåŒ æ•°ç§‘æŠ€&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5Bè’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;rlaif-mini.jsonl&lt;/code&gt; --RLAIFè®­ç»ƒæ•°æ®é›†ï¼Œä»SFTæ•°æ®é›†ä¸­éšæœºé‡‡æ ·1ä¸‡æ¡é«˜è´¨é‡å¯¹è¯ï¼Œç”¨äºPPO/GRPO/SPOç­‰å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼ˆæ˜¯sft_2048çš„å­é›†ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º2048ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=2048ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;âœ¨ --æç®€æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®+Qwen2.5è’¸é¦æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿè®­ç»ƒZeroæ¨¡å‹ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg" alt="dataset" /&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;è¯´æ˜ &amp;amp; æ¨èè®­ç»ƒæ–¹æ¡ˆ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 Serieså‡ç»è¿‡å…±çº¦20GBè¯­æ–™è®­ç»ƒï¼Œå¤§çº¦4B tokensï¼Œå³å¯¹åº”ä¸Šé¢çš„æ•°æ®ç»„åˆè®­ç»ƒç»“æœï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æƒ³è¦æœ€å¿«é€Ÿåº¦ä»0å®ç°Zeroæ¨¡å‹ï¼Œæ¨èä½¿ç”¨&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; çš„æ•°æ®ç»„åˆï¼Œå…·ä½“èŠ±é”€å’Œæ•ˆæœå¯æŸ¥çœ‹ä¸‹æ–‡è¡¨æ ¼ï¼ˆå¼€é”€ï¼šğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜Šï¼‰&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;æ¨èå…·å¤‡ä¸€å®šç®—åŠ›èµ„æºæˆ–æ›´åœ¨æ„æ•ˆæœçš„æœ‹å‹å¯ä»¥è€ƒè™‘å‰è€…å®Œæ•´å¤ç°MiniMind2ï¼›ä»…æœ‰å•å¡GPUæˆ–åœ¨ä¹çŸ­æ—¶é—´å¿«é€Ÿå¤ç°çš„æœ‹å‹å¼ºçƒˆæ¨èåè€…ï¼›&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ã€æŠ˜ä¸­æ–¹æ¡ˆã€‘äº¦å¯é€‰æ‹©ä¾‹å¦‚&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;ã€&lt;code&gt;sft_1024.jsonl&lt;/code&gt;ä¸­ç­‰è§„æ¨¡æ•°æ®è¿›è¡Œè‡ªç”±ç»„åˆè®­ç»ƒï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;ğŸ“Œ Model&lt;/h1&gt; 
&lt;h2&gt;Structure&lt;/h2&gt; 
&lt;p&gt;MiniMind-Denseï¼ˆå’Œ&lt;a href="https://ai.meta.com/blog/meta-llama-3-1/"&gt;Llama3.1&lt;/a&gt;ä¸€æ ·ï¼‰ä½¿ç”¨äº†Transformerçš„Decoder-Onlyç»“æ„ï¼Œè·ŸGPT-3çš„åŒºåˆ«åœ¨äºï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;é‡‡ç”¨äº†GPT-3çš„é¢„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºä¸Šã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨çš„æ˜¯RMSNormå½’ä¸€åŒ–å‡½æ•°ã€‚&lt;/li&gt; 
 &lt;li&gt;ç”¨SwiGLUæ¿€æ´»å‡½æ•°æ›¿ä»£äº†ReLUï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†æé«˜æ€§èƒ½ã€‚&lt;/li&gt; 
 &lt;li&gt;åƒGPT-Neoä¸€æ ·ï¼Œå»æ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œæ”¹ç”¨äº†æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ï¼Œè¿™æ ·åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æ¨ç†æ—¶æ•ˆæœæ›´å¥½ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMind-MoEæ¨¡å‹ï¼Œå®ƒçš„ç»“æ„åŸºäºLlama3å’Œ&lt;a href="https://arxiv.org/pdf/2405.04434"&gt;Deepseek-V2/3&lt;/a&gt;ä¸­çš„MixFFNæ··åˆä¸“å®¶æ¨¡å—ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰æ–¹é¢ï¼Œé‡‡ç”¨äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œä»¥æé«˜Expertsçš„æ•ˆæœã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMindçš„æ•´ä½“ç»“æ„ä¸€è‡´ï¼Œåªæ˜¯åœ¨RoPEè®¡ç®—ã€æ¨ç†å‡½æ•°å’ŒFFNå±‚çš„ä»£ç ä¸Šåšäº†ä¸€äº›å°è°ƒæ•´ã€‚ å…¶ç»“æ„å¦‚ä¸‹å›¾ï¼ˆé‡ç»˜ç‰ˆï¼‰ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png" alt="structure" /&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png" alt="structure-moe" /&gt;&lt;/p&gt; 
&lt;p&gt;ä¿®æ”¹æ¨¡å‹é…ç½®è§&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/model/model_minimind.py"&gt;./model/model_minimind.py&lt;/a&gt;ã€‚ å‚è€ƒæ¨¡å‹å‚æ•°ç‰ˆæœ¬è§ä¸‹è¡¨ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4Ã—26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Model Configuration&lt;/h2&gt; 
&lt;p&gt;ğŸ“‹å…³äºLLMçš„å‚æ•°é…ç½®ï¼Œæœ‰ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„è®ºæ–‡&lt;a href="https://arxiv.org/pdf/2402.14905"&gt;MobileLLM&lt;/a&gt;åšäº†è¯¦ç»†çš„ç ”ç©¶å’Œå®éªŒã€‚ Scaling Lawåœ¨å°æ¨¡å‹ä¸­æœ‰è‡ªå·±ç‹¬ç‰¹çš„è§„å¾‹ã€‚ å¼•èµ·Transformerå‚æ•°æˆè§„æ¨¡å˜åŒ–çš„å‚æ•°å‡ ä¹åªå–å†³äº&lt;code&gt;d_model&lt;/code&gt;å’Œ&lt;code&gt;n_layers&lt;/code&gt;ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;â†‘ + &lt;code&gt;n_layers&lt;/code&gt;â†“ -&amp;gt; çŸ®èƒ–å­&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;â†“ + &lt;code&gt;n_layers&lt;/code&gt;â†‘ -&amp;gt; ç˜¦é«˜ä¸ª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020å¹´æå‡ºScaling Lawçš„è®ºæ–‡è®¤ä¸ºï¼Œè®­ç»ƒæ•°æ®é‡ã€å‚æ•°é‡ä»¥åŠè®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰æ˜¯å†³å®šæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œè€Œæ¨¡å‹æ¶æ„çš„å½±å“å‡ ä¹å¯ä»¥å¿½è§†ã€‚ ç„¶è€Œä¼¼ä¹è¿™ä¸ªå®šå¾‹å¯¹å°æ¨¡å‹å¹¶ä¸å®Œå…¨é€‚ç”¨ã€‚ MobileLLMæå‡ºæ¶æ„çš„æ·±åº¦æ¯”å®½åº¦æ›´é‡è¦ï¼Œã€Œæ·±è€Œçª„ã€çš„ã€Œç˜¦é•¿ã€æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ¯”ã€Œå®½è€Œæµ…ã€æ¨¡å‹æ›´å¤šçš„æŠ½è±¡æ¦‚å¿µã€‚ ä¾‹å¦‚å½“æ¨¡å‹å‚æ•°å›ºå®šåœ¨125Mæˆ–è€…350Mæ—¶ï¼Œ30ï½42å±‚çš„ã€Œç‹­é•¿ã€æ¨¡å‹æ˜æ˜¾æ¯”12å±‚å·¦å³çš„ã€ŒçŸ®èƒ–ã€æ¨¡å‹æœ‰æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œ åœ¨å¸¸è¯†æ¨ç†ã€é—®ç­”ã€é˜…è¯»ç†è§£ç­‰8ä¸ªåŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰ç±»ä¼¼çš„è¶‹åŠ¿ã€‚ è¿™å…¶å®æ˜¯éå¸¸æœ‰è¶£çš„å‘ç°ï¼Œå› ä¸ºä»¥å¾€ä¸º100Må·¦å³é‡çº§çš„å°æ¨¡å‹è®¾è®¡æ¶æ„æ—¶ï¼Œå‡ ä¹æ²¡äººå°è¯•è¿‡å åŠ è¶…è¿‡12å±‚ã€‚ è¿™ä¸MiniMindåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å‚æ•°é‡åœ¨&lt;code&gt;d_model&lt;/code&gt;å’Œ&lt;code&gt;n_layers&lt;/code&gt;ä¹‹é—´è¿›è¡Œè°ƒæ•´å®éªŒè§‚å¯Ÿåˆ°çš„æ•ˆæœæ˜¯ä¸€è‡´çš„ã€‚ ç„¶è€Œã€Œæ·±è€Œçª„ã€çš„ã€Œçª„ã€ä¹Ÿæ˜¯æœ‰ç»´åº¦æé™çš„ï¼Œå½“d_model&amp;lt;512æ—¶ï¼Œè¯åµŒå…¥ç»´åº¦åå¡Œçš„åŠ£åŠ¿éå¸¸æ˜æ˜¾ï¼Œ å¢åŠ çš„layerså¹¶ä¸èƒ½å¼¥è¡¥è¯åµŒå…¥åœ¨å›ºå®šq_headå¸¦æ¥d_headä¸è¶³çš„åŠ£åŠ¿ã€‚ å½“d_model&amp;gt;1536æ—¶ï¼Œlayersçš„å¢åŠ ä¼¼ä¹æ¯”d_modelçš„ä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´èƒ½å¸¦æ¥å…·æœ‰"æ€§ä»·æ¯”"çš„å‚æ•°-&amp;gt;æ•ˆæœå¢ç›Šã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å› æ­¤MiniMindè®¾å®šsmallæ¨¡å‹dim=512ï¼Œn_layers=8æ¥è·å–çš„ã€Œæå°ä½“ç§¯&amp;lt;-&amp;gt;æ›´å¥½æ•ˆæœã€çš„å¹³è¡¡ã€‚&lt;/li&gt; 
 &lt;li&gt;è®¾å®šdim=768ï¼Œn_layers=16æ¥è·å–æ•ˆæœçš„æ›´å¤§æ”¶ç›Šï¼Œæ›´åŠ ç¬¦åˆå°æ¨¡å‹Scaling-Lawçš„å˜åŒ–æ›²çº¿ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä½œä¸ºå‚è€ƒï¼ŒGPT3çš„å‚æ•°è®¾å®šè§ä¸‹è¡¨ï¼š &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png" alt="gpt3_config.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ“Œ Experiment&lt;/h1&gt; 
&lt;h2&gt;â…  è®­ç»ƒå¼€é”€&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ—¶é—´å•ä½&lt;/strong&gt;ï¼šå°æ—¶ (h)ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æˆæœ¬å•ä½&lt;/strong&gt;ï¼šäººæ°‘å¸ (ï¿¥)ï¼›7ï¿¥ â‰ˆ 1ç¾å…ƒã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 ç§Ÿå¡å•ä»·&lt;/strong&gt;ï¼šâ‰ˆ1.3ï¿¥/hï¼ˆå¯è‡ªè¡Œå‚è€ƒå®æ—¶å¸‚ä»·ï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å‚è€ƒæ ‡å‡†&lt;/strong&gt;ï¼šè¡¨æ ¼ä»…å®æµ‹ &lt;code&gt;pretrain&lt;/code&gt; å’Œ &lt;code&gt;sft_mini_512&lt;/code&gt; ä¸¤ä¸ªæ•°æ®é›†çš„è®­ç»ƒæ—¶é—´ï¼Œå…¶å®ƒè€—æ—¶æ ¹æ®æ•°æ®é›†å¤§å°ä¼°ç®—ï¼ˆå¯èƒ½å­˜åœ¨äº›è®¸å‡ºå…¥ï¼‰ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;åŸºäº 3090 ï¼ˆå•å¡ï¼‰æˆæœ¬è®¡ç®—&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1.1h&lt;br /&gt;â‰ˆ1.43ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1h&lt;br /&gt;â‰ˆ1.3ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ6h&lt;br /&gt;â‰ˆ7.8ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ4.58h&lt;br /&gt;â‰ˆ5.95ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ7.5h&lt;br /&gt;â‰ˆ9.75ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ1h&lt;br /&gt;â‰ˆ1.3ï¿¥&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3.9h&lt;br /&gt;â‰ˆ5.07ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3.3h&lt;br /&gt;â‰ˆ4.29ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ20h&lt;br /&gt;â‰ˆ26ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ15h&lt;br /&gt;â‰ˆ19.5ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ25h&lt;br /&gt;â‰ˆ32.5ï¿¥&lt;/td&gt; 
   &lt;td&gt;â‰ˆ3h&lt;br /&gt;â‰ˆ3.9ï¿¥&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;è®­ç»ƒå¼€é”€æ€»ç»“&amp;amp;é¢„æµ‹&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Smallå‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;æ•°æ®é›† &lt;br /&gt;å•å¡3090 (1 epoch) + 2.1å°æ—¶ + èŠ±è´¹2.73å…ƒäººæ°‘å¸ &lt;br /&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind-Zero-0.025Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-Smallå‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;æ•°æ®é›† &lt;br /&gt;å•å¡3090 (2 epochs) + å¤§çº¦38.16å°æ—¶ + èŠ±è´¹49.61å…ƒäººæ°‘å¸ &lt;br /&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind2-Small-0.025Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2å‚æ•°&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;æ•°æ®é›† &lt;br /&gt;å•å¡3090 (2 epochs) + å¤§çº¦122å°æ—¶ + èŠ±è´¹158.6å…ƒäººæ°‘å¸ &lt;br /&gt;å³å¯ä»0è®­ç»ƒå‡ºMiniMind2-0.1Bæ¨¡å‹!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;âœ¨åŸºäºå•å¡NVIDIA 3090çš„&lt;code&gt;MiniMind-Zero&lt;/code&gt;ä»0è®­ç»ƒä»…éœ€&lt;code&gt;2å°æ—¶&lt;/code&gt; + &lt;code&gt;3å—é’±&lt;/code&gt;ï¼Œå®ç°ChatBotæ•ˆæœï¼&lt;/p&gt; 
&lt;p&gt;âœ¨PSï¼šè‹¥é‡‡ç”¨8å¡4090è®­ç»ƒï¼Œæ€»ç”¨æ—¶ç”šè‡³å¯ä»¥å‹ç¼©åˆ°10åˆ†é’Ÿä»¥å†…ï¼ï¼ˆç”±äºæ—¶é—´æ›´çŸ­ï¼ŒèŠ±è´¹åŒæ ·3å…ƒå·¦å³ï¼Œä¸å•å¡æˆæœ¬ç›¸å½“ï¼‰&lt;/p&gt; 
&lt;p&gt;âœ¨ä»¥æä½æä½çš„é—¨æ§›ï¼Œå®ç°äººäººå¯ç©çš„å¤§æ¨¡å‹è‡ªç”±ï¼è¿™æ­£æ˜¯MiniMindç³»åˆ—çš„è¯ç”Ÿåˆè¡·ï¼&lt;/p&gt; 
&lt;p&gt;âœ¨ä»…ä»·å€¼&lt;code&gt;3å—é’±&lt;/code&gt;æˆæœ¬çš„&lt;code&gt;MiniMind-Zero&lt;/code&gt;å¹¶ä¸æ˜¯å™±å¤´ï¼Chatæµ‹è¯•ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;ğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
ğŸ¤–ï¸: ä½œä¸ºäººå·¥æ™ºèƒ½ï¼Œæˆ‘æ²¡æœ‰å®é™…çš„ç”Ÿæ´»ï¼Œä¹Ÿæ²¡æœ‰è‡ªæˆ‘æ„è¯†ï¼Œæ‰€ä»¥æ²¡æœ‰è‡ªå·±çš„ç”Ÿæ´»ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è¿›è¡Œå¯¹è¯ç­‰ã€‚æˆ‘çš„è®¾è®¡å’ŒåŠŸèƒ½æ˜¯ç”±è®¡ç®—æœºç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½æŠ€æœ¯å’Œç®—æ³•æ‰€æ„å»ºçš„ï¼Œæˆ‘é€šè¿‡ç¼–ç¨‹å’Œç®—æ³•å®ç°ã€‚

ğŸ‘¶: æ¨èä¸€äº›æ­å·çš„ç‰¹è‰²ç¾é£Ÿå§ã€‚
ğŸ¤–ï¸: æ­å·æœ‰å¾ˆå¤šç¾å‘³çš„ç‰¹è‰²ç¾é£Ÿï¼Œæ¯”å¦‚é¸¡è‚‰ä¸²ã€é³—é±¼å¤´ã€æ°´ç…®é±¼ã€è±†è…è„‘ç­‰ã€‚è¿™äº›ç¾é£Ÿéƒ½éå¸¸ç¾å‘³ï¼Œæœ‰ç€ç‹¬ç‰¹çš„é£å‘³å’Œå£æ„Ÿï¼Œç»å¯¹æ˜¯å€¼å¾—ä¸€è¯•çš„ç¾é£Ÿã€‚

ğŸ‘¶: è¯·ä¸ºæˆ‘è®²è§£â€œå¤§è¯­è¨€æ¨¡å‹â€è¿™ä¸ªæ¦‚å¿µã€‚
ğŸ¤–ï¸: å¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨å¤§é‡çš„æ–‡æœ¬æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨ä¸æ–­çš„è¿­ä»£ä¸­ä¸æ–­ä¼˜åŒ–æ¨¡å‹ã€‚å®ƒçš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥çš„æ•°æ®æ¥ç”Ÿæˆç¬¦åˆç‰¹å®šéœ€æ±‚çš„æ–‡æœ¬ï¼Œè¿™äº›æ–‡æœ¬å¯ä»¥æ˜¯ä»»ä½•ä½ æ„Ÿå…´è¶£çš„ä¸»é¢˜ã€‚

ğŸ‘¶: Introduce the history of the United States, please.
ğŸ¤–ï¸: æ‚¨æåˆ°çš„â€œIntrook's the believeations of theument." è¿™ä¸ªåå­—æ¥æºäºä¸­å›½å¤ä»£çš„"groty of of the change."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æé€Ÿä¸”åˆå…·æ•ˆæœï¼Œç”šè‡³ä»ç„¶å¯ä»¥è¿›ä¸€æ­¥å‹ç¼©è·å–æ›´å°æ›´ä¼˜è´¨çš„è®­ç»ƒæ•°æ®ã€‚ Zeroæ¨¡å‹æƒé‡ä¿å­˜ä¸º &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;ï¼ˆè§ä¸‹æ–‡MiniMindæ¨¡å‹æ–‡ä»¶é“¾æ¥ï¼‰ï¼Œå¦‚æœ‰å…´è¶£å¯ä¸‹è½½æ£€éªŒæ­¤æ¨¡å‹æ•ˆæœã€‚&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â…¡ ä¸»è¦è®­ç»ƒï¼ˆå¿…é¡»ï¼‰&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ &lt;code&gt;cd ./trainer&lt;/code&gt; ç›®å½•æ‰§è¡Œ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;1. é¢„è®­ç»ƒ (Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLMé¦–å…ˆè¦å­¦ä¹ çš„å¹¶éç›´æ¥ä¸äººäº¤æµï¼Œè€Œæ˜¯è®©ç½‘ç»œå‚æ•°ä¸­å……æ»¡çŸ¥è¯†çš„å¢¨æ°´ï¼Œâ€œå¢¨æ°´â€ ç†è®ºä¸Šå–çš„è¶Šé¥±è¶Šå¥½ï¼Œäº§ç”Ÿå¤§é‡çš„å¯¹ä¸–ç•Œçš„çŸ¥è¯†ç§¯ç´¯ã€‚ é¢„è®­ç»ƒå°±æ˜¯è®©Modelå…ˆåŸ‹å¤´è‹¦å­¦å¤§é‡åŸºæœ¬çš„çŸ¥è¯†ï¼Œä¾‹å¦‚ä»Wikiç™¾ç§‘ã€æ–°é—»ã€ä¹¦ç±æ•´ç†å¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚ è¿™ä¸ªè¿‡ç¨‹æ˜¯â€œæ— ç›‘ç£â€çš„ï¼Œå³äººç±»ä¸éœ€è¦åœ¨è¿‡ç¨‹ä¸­åšä»»ä½•â€œæœ‰ç›‘ç£â€çš„æ ¡æ­£ï¼Œè€Œæ˜¯ç”±æ¨¡å‹è‡ªå·±ä»å¤§é‡æ–‡æœ¬ä¸­æ€»ç»“è§„å¾‹å­¦ä¹ çŸ¥è¯†ç‚¹ã€‚ æ¨¡å‹æ­¤é˜¶æ®µç›®çš„åªæœ‰ä¸€ä¸ªï¼š&lt;strong&gt;å­¦ä¼šè¯è¯­æ¥é¾™&lt;/strong&gt;ã€‚ä¾‹å¦‚è¾“å…¥"ç§¦å§‹çš‡"å››ä¸ªå­—ï¼Œå®ƒå¯ä»¥æ¥é¾™"æ˜¯ä¸­å›½çš„ç¬¬ä¸€ä½çš‡å¸"ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1å³ä¸ºå•å¡è®­ç»ƒï¼Œå¯æ ¹æ®ç¡¬ä»¶æƒ…å†µè‡ªè¡Œè°ƒæ•´ (è®¾ç½®&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;pretrain_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;strong&gt;2. æœ‰ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;ç»è¿‡é¢„è®­ç»ƒï¼ŒLLMæ­¤æ—¶å·²ç»æŒæ¡äº†å¤§é‡çŸ¥è¯†ï¼Œç„¶è€Œæ­¤æ—¶å®ƒåªä¼šæ— è„‘åœ°è¯è¯­æ¥é¾™ï¼Œè¿˜ä¸ä¼šä¸äººèŠå¤©ã€‚ SFTé˜¶æ®µå°±éœ€è¦æŠŠåŠæˆå“LLMæ–½åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠå¤©æ¨¡æ¿è¿›è¡Œå¾®è°ƒã€‚ ä¾‹å¦‚æ¨¡å‹é‡åˆ°è¿™æ ·çš„æ¨¡æ¿ã€é—®é¢˜-&amp;gt;å›ç­”ï¼Œé—®é¢˜-&amp;gt;å›ç­”ã€‘åä¸å†æ— è„‘æ¥é¾™ï¼Œè€Œæ˜¯æ„è¯†åˆ°è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„å¯¹è¯ç»“æŸã€‚ ç§°è¿™ä¸ªè¿‡ç¨‹ä¸ºæŒ‡ä»¤å¾®è°ƒï¼Œå°±å¦‚åŒè®©å·²ç»å­¦å¯Œäº”è½¦çš„ã€Œç‰›é¡¿ã€å…ˆç”Ÿé€‚åº”21ä¸–çºªæ™ºèƒ½æ‰‹æœºçš„èŠå¤©ä¹ æƒ¯ï¼Œå­¦ä¹ å±å¹•å·¦ä¾§æ˜¯å¯¹æ–¹æ¶ˆæ¯ï¼Œå³ä¾§æ˜¯æœ¬äººæ¶ˆæ¯è¿™ä¸ªè§„å¾‹ã€‚ åœ¨è®­ç»ƒæ—¶ï¼ŒMiniMindçš„æŒ‡ä»¤å’Œå›ç­”é•¿åº¦è¢«æˆªæ–­åœ¨512ï¼Œæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜ç©ºé—´ã€‚å°±åƒå­¦ä¹ å†™ä½œæ—¶ï¼Œä¼šå…ˆä»çŸ­çš„æ–‡ç« å¼€å§‹ï¼Œå½“å­¦ä¼šå†™ä½œ200å­—ä½œæ–‡åï¼Œ800å­—æ–‡ç« ä¹Ÿå¯ä»¥æ‰‹åˆ°æ“’æ¥ã€‚ åœ¨éœ€è¦é•¿åº¦æ‹“å±•æ—¶ï¼Œåªéœ€è¦å‡†å¤‡å°‘é‡çš„2k/4k/8ké•¿åº¦å¯¹è¯æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒå³å¯ï¼ˆæ­¤æ—¶æœ€å¥½é…åˆRoPE-NTKçš„åŸºå‡†å·®å€¼ï¼‰ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;åœ¨æ¨ç†æ—¶é€šè¿‡è°ƒæ•´RoPEçº¿æ€§å·®å€¼ï¼Œå®ç°å…è®­ç»ƒé•¿åº¦å¤–æ¨åˆ°2048åŠä»¥ä¸Šå°†ä¼šå¾ˆæ–¹ä¾¿ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;â…¢ å…¶å®ƒè®­ç»ƒé˜¶æ®µï¼ˆå¯é€‰ï¼‰&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ &lt;code&gt;cd ./trainer&lt;/code&gt; ç›®å½•æ‰§è¡Œ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;3. çŸ¥è¯†è’¸é¦ (Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åœ¨å‰é¢çš„æ‰€æœ‰è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å®Œå…¨å…·å¤‡äº†åŸºæœ¬èƒ½åŠ›ï¼Œé€šå¸¸å¯ä»¥å­¦æˆå‡ºå¸ˆäº†ã€‚ è€ŒçŸ¥è¯†è’¸é¦å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œæ‰€è°“çŸ¥è¯†è’¸é¦ï¼Œå³å­¦ç”Ÿæ¨¡å‹é¢å‘æ•™å¸ˆæ¨¡å‹å­¦ä¹ ã€‚ æ•™å¸ˆæ¨¡å‹é€šå¸¸æ˜¯ç»è¿‡å……åˆ†è®­ç»ƒçš„å¤§æ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ å­¦ç”Ÿæ¨¡å‹æ˜¯ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ï¼Œç›®æ ‡æ˜¯å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œä¸æ˜¯ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ã€‚ åœ¨SFTå­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯æ‹Ÿåˆè¯Tokenåˆ†ç±»ç¡¬æ ‡ç­¾ï¼ˆhard labelsï¼‰ï¼Œå³çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚ 0 æˆ– 6400ï¼‰ã€‚ åœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œæ•™å¸ˆæ¨¡å‹çš„softmaxæ¦‚ç‡åˆ†å¸ƒè¢«ç”¨ä½œè½¯æ ‡ç­¾ï¼ˆsoft labelsï¼‰ã€‚å°æ¨¡å‹ä»…å­¦ä¹ è½¯æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨KL-Lossæ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚ é€šä¿—åœ°è¯´ï¼ŒSFTç›´æ¥å­¦ä¹ è€å¸ˆç»™çš„è§£é¢˜ç­”æ¡ˆã€‚è€ŒKDè¿‡ç¨‹ç›¸å½“äºâ€œæ‰“å¼€â€è€å¸ˆèªæ˜çš„å¤§è„‘ï¼Œå°½å¯èƒ½åœ°æ¨¡ä»¿è€å¸ˆâ€œå¤§è„‘â€æ€è€ƒé—®é¢˜çš„ç¥ç»å…ƒçŠ¶æ€ã€‚ ä¾‹å¦‚ï¼Œå½“è€å¸ˆæ¨¡å‹è®¡ç®—&lt;code&gt;1+1=2&lt;/code&gt;è¿™ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œæœ€åä¸€å±‚ç¥ç»å…ƒaçŠ¶æ€ä¸º0ï¼Œç¥ç»å…ƒbçŠ¶æ€ä¸º100ï¼Œç¥ç»å…ƒcçŠ¶æ€ä¸º-99... å­¦ç”Ÿæ¨¡å‹é€šè¿‡å¤§é‡æ•°æ®ï¼Œå­¦ä¹ æ•™å¸ˆæ¨¡å‹å¤§è„‘å†…éƒ¨çš„è¿è½¬è§„å¾‹ã€‚è¿™ä¸ªè¿‡ç¨‹å³ç§°ä¹‹ä¸ºï¼šçŸ¥è¯†è’¸é¦ã€‚ çŸ¥è¯†è’¸é¦çš„ç›®çš„åªæœ‰ä¸€ä¸ªï¼šè®©å°æ¨¡å‹ä½“ç§¯æ›´å°çš„åŒæ—¶æ•ˆæœæ›´å¥½ã€‚ ç„¶è€Œéšç€LLMè¯ç”Ÿå’Œå‘å±•ï¼Œæ¨¡å‹è’¸é¦ä¸€è¯è¢«å¹¿æ³›æ»¥ç”¨ï¼Œä»è€Œäº§ç”Ÿäº†â€œç™½ç›’/é»‘ç›’â€çŸ¥è¯†è’¸é¦ä¸¤ä¸ªæ´¾åˆ«ã€‚ GPT-4è¿™ç§é—­æºæ¨¡å‹ï¼Œç”±äºæ— æ³•è·å–å…¶å†…éƒ¨ç»“æ„ï¼Œå› æ­¤åªèƒ½é¢å‘å®ƒæ‰€è¾“å‡ºçš„æ•°æ®å­¦ä¹ ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¹‹ä¸ºé»‘ç›’è’¸é¦ï¼Œä¹Ÿæ˜¯å¤§æ¨¡å‹æ—¶ä»£æœ€æ™®éçš„åšæ³•ã€‚ é»‘ç›’è’¸é¦ä¸SFTè¿‡ç¨‹å®Œå…¨ä¸€è‡´ï¼Œåªä¸è¿‡æ•°æ®æ˜¯ä»å¤§æ¨¡å‹çš„è¾“å‡ºæ”¶é›†ï¼Œå› æ­¤åªéœ€è¦å‡†å¤‡æ•°æ®å¹¶ä¸”è¿›ä¸€æ­¥FTå³å¯ã€‚ æ³¨æ„æ›´æ”¹è¢«åŠ è½½çš„åŸºç¡€æ¨¡å‹ä¸º&lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼Œå³åŸºäºå¾®è°ƒæ¨¡å‹åšè¿›ä¸€æ­¥çš„è’¸é¦å­¦ä¹ ã€‚ &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;ä¸&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; å‡æ”¶é›†è‡ªqwen2.5-7/72B-Instructå¤§æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºSFTä»¥è·å–Qwençš„éƒ¨åˆ†è¡Œä¸ºã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ³¨æ„éœ€è¦æ›´æ”¹train_full_sft.pyæ•°æ®é›†è·¯å¾„ï¼Œä»¥åŠmax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;åŒæ ·ä¿å­˜ä¸º: &lt;code&gt;full_sft_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æ­¤å¤„åº”å½“ç€é‡ä»‹ç»MiniMindå®ç°çš„ç™½ç›’è’¸é¦ä»£ç &lt;code&gt;train_distillation.py&lt;/code&gt;ï¼Œç”±äºMiniMindåŒç³»åˆ—æœ¬èº«å¹¶ä¸å­˜åœ¨å¼ºå¤§çš„æ•™å¸ˆæ¨¡å‹ï¼Œå› æ­¤ç™½ç›’è’¸é¦ä»£ç ä»…ä½œä¸ºå­¦ä¹ å‚è€ƒã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;4. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRAæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä½ç§©åˆ†è§£çš„æ–¹å¼å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚ ç›¸æ¯”äºå…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰ï¼ŒLoRA åªéœ€è¦æ›´æ–°å°‘é‡çš„å‚æ•°ã€‚ LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¨¡å‹çš„æƒé‡çŸ©é˜µä¸­å¼•å…¥ä½ç§©åˆ†è§£ï¼Œä»…å¯¹ä½ç§©éƒ¨åˆ†è¿›è¡Œæ›´æ–°ï¼Œè€Œä¿æŒåŸå§‹é¢„è®­ç»ƒæƒé‡ä¸å˜ã€‚ ä»£ç å¯è§&lt;code&gt;./model/model_lora.py&lt;/code&gt;å’Œ&lt;code&gt;train_lora.py&lt;/code&gt;ï¼Œå®Œå…¨ä»0å®ç°LoRAæµç¨‹ï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“çš„å°è£…ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;ï¼ˆ* ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;éå¸¸å¤šçš„äººå›°æƒ‘ï¼Œå¦‚ä½•ä½¿æ¨¡å‹å­¦ä¼šè‡ªå·±ç§æœ‰é¢†åŸŸçš„çŸ¥è¯†ï¼Ÿå¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Ÿå¦‚ä½•è¿ç§»é€šç”¨é¢†åŸŸæ¨¡å‹æ‰“é€ å‚åŸŸæ¨¡å‹ï¼Ÿ è¿™é‡Œä¸¾å‡ ä¸ªä¾‹å­ï¼Œå¯¹äºé€šç”¨æ¨¡å‹ï¼ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†æ¬ ç¼ºï¼Œå¯ä»¥å°è¯•åœ¨åŸæœ‰æ¨¡å‹åŸºç¡€ä¸ŠåŠ å…¥é¢†åŸŸçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ åŒæ—¶ï¼Œé€šå¸¸ä¸å¸Œæœ›å­¦ä¼šé¢†åŸŸçŸ¥è¯†çš„åŒæ—¶æŸå¤±åŸæœ‰åŸºç¡€æ¨¡å‹çš„å…¶å®ƒèƒ½åŠ›ï¼Œæ­¤æ—¶LoRAå¯ä»¥å¾ˆå¥½çš„æ”¹å–„è¿™ä¸ªé—®é¢˜ã€‚ åªéœ€è¦å‡†å¤‡å¦‚ä¸‹æ ¼å¼çš„å¯¹è¯æ•°æ®é›†æ”¾ç½®åˆ°&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;ï¼Œå¯åŠ¨ &lt;code&gt;python train_lora.py&lt;/code&gt; è®­ç»ƒå³å¯å¾—åˆ°&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;æ–°æ¨¡å‹æƒé‡ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;åŒ»ç–—åœºæ™¯&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "è¯·é—®é¢ˆæ¤ç—…çš„äººæ•å¤´å¤šé«˜æ‰æœ€å¥½ï¼Ÿ"}, {"role": "assistant", "content": "é¢ˆæ¤ç—…æ‚£è€…é€‰æ‹©æ•å¤´çš„é«˜åº¦åº”è¯¥æ ¹æ®..."}]}
 {"conversations": [{"role": "user", "content": "è¯·é—®xxx"}, {"role": "assistant", "content": "xxx..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;è‡ªæˆ‘è®¤çŸ¥åœºæ™¯&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ"}, {"role": "assistant", "content": "æˆ‘å«minimind..."}]}
 {"conversations": [{"role": "user", "content": "ä½ æ˜¯è°"}, {"role": "assistant", "content": "æˆ‘æ˜¯..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ­¤æ—¶ã€åŸºç¡€æ¨¡å‹+LoRAæ¨¡å‹ã€‘å³å¯è·å¾—åŒ»ç–—åœºæ™¯æ¨¡å‹å¢å¼ºçš„èƒ½åŠ›ï¼Œç›¸å½“äºä¸ºåŸºç¡€æ¨¡å‹å¢åŠ äº†LoRAå¤–æŒ‚ï¼Œè¿™ä¸ªè¿‡ç¨‹å¹¶ä¸æŸå¤±åŸºç¡€æ¨¡å‹çš„æœ¬èº«èƒ½åŠ›ã€‚ å¯ä»¥é€šè¿‡&lt;code&gt;eval_llm.py&lt;/code&gt;è¿›è¡Œæ¨¡å‹è¯„ä¼°æµ‹è¯•ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# æ³¨æ„ï¼šweightå‚æ•°æŒ‡å®šåŸºç¡€æ¨¡å‹ç±»å‹ï¼Œéœ€ä¸train_loraè®­ç»ƒæ—¶ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹ä¿æŒä¸€è‡´
python eval_llm.py  --weight dpo --lora_weight lora_medical
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;å°æµ‹è¯•&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ğŸ‘¶: æˆ‘æœ€è¿‘ç»å¸¸æ„Ÿåˆ°å¤´æ™•ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ
ğŸ¤–ï¸: å¤´æ™•å¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå¿ƒè„ç–¾ç—…ã€çœ¼ç›æŸä¼¤ã€è¿‡æ•ååº”ã€çš®è‚¤é—®é¢˜ã€è¿‡æ•ååº”ã€å‹åŠ›ã€ç„¦è™‘ã€ç–²åŠ³ã€è¯ç‰©å‰¯ä½œç”¨ã€æ€§åŠŸèƒ½éšœç¢æˆ–è€…å…¶ä»–...

---

ğŸ‘¶: ä½ å’Œopenaiæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ
ğŸ¤–ï¸: æˆ‘æ˜¯ MiniMindï¼Œä¸€ä¸ªç”± Jingyao Gong å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œç®—æ³•è®­ç»ƒæ¥ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PSï¼šåªè¦æœ‰æ‰€éœ€è¦çš„æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥full_sftå…¨å‚å¾®è°ƒï¼ˆéœ€è¦è¿›è¡Œé€šç”¨çŸ¥è¯†çš„æ··åˆé…æ¯”ï¼Œå¦åˆ™è¿‡æ‹Ÿåˆé¢†åŸŸæ•°æ®ä¼šè®©æ¨¡å‹å˜å‚»ï¼ŒæŸå¤±é€šç”¨æ€§ï¼‰&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;5. è®­ç»ƒæ¨ç†æ¨¡å‹ (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1å®åœ¨å¤ªç«äº†ï¼Œå‡ ä¹é‡æ–°æŒ‡æ˜äº†æœªæ¥LLMçš„æ–°èŒƒå¼ã€‚ è®ºæ–‡æŒ‡å‡º&lt;code&gt;&amp;gt;3B&lt;/code&gt;çš„æ¨¡å‹ç»å†å¤šæ¬¡åå¤çš„å†·å¯åŠ¨å’ŒRLå¥–åŠ±è®­ç»ƒæ‰èƒ½è·å¾—è‚‰çœ¼å¯è§çš„æ¨ç†èƒ½åŠ›æå‡ã€‚ æœ€å¿«æœ€ç¨³å¦¥æœ€ç»æµçš„åšæ³•ï¼Œä»¥åŠæœ€è¿‘çˆ†å‘çš„å„ç§å„æ ·æ‰€è°“çš„æ¨ç†æ¨¡å‹å‡ ä¹éƒ½æ˜¯ç›´æ¥é¢å‘æ•°æ®è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œ ä½†ç”±äºç¼ºä¹æŠ€æœ¯å«é‡ï¼Œè’¸é¦æ´¾è¢«RLæ´¾ç§ä¸èµ·ï¼ˆhhhhï¼‰ã€‚ æœ¬äººè¿…é€Ÿå·²ç»åœ¨Qwenç³»åˆ—1.5Bå°æ¨¡å‹ä¸Šè¿›è¡Œäº†å°è¯•ï¼Œå¾ˆå¿«å¤ç°äº†Zeroè¿‡ç¨‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚ ç„¶è€Œä¸€ä¸ªé—æ†¾çš„å…±è¯†æ˜¯ï¼šå‚æ•°å¤ªå°çš„æ¨¡å‹ç›´æ¥é€šè¿‡å†·å¯åŠ¨SFT+GRPOå‡ ä¹ä¸å¯èƒ½è·å¾—ä»»ä½•æ¨ç†æ•ˆæœã€‚ &lt;del&gt; MiniMind2ç¬¬ä¸€æ—¶é—´åªèƒ½åšå®šä¸ç§»çš„é€‰æ‹©åšè’¸é¦æ´¾ï¼Œæ—¥ååŸºäº0.1Bæ¨¡å‹çš„RLå¦‚æœåŒæ ·å–å¾—å°å°è¿›å±•ä¼šæ›´æ–°æ­¤éƒ¨åˆ†çš„è®­ç»ƒæ–¹æ¡ˆã€‚ &lt;/del&gt;&lt;/p&gt; 
&lt;p&gt;åšè’¸é¦éœ€è¦å‡†å¤‡çš„ä¾ç„¶æ˜¯å’ŒSFTé˜¶æ®µåŒæ ·æ ¼å¼çš„æ•°æ®å³å¯ï¼Œæ•°æ®é›†æ¥æºå·²å¦‚ä¸Šæ–‡ä»‹ç»ã€‚æ•°æ®æ ¼å¼ä¾‹å¦‚ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "conversations": [
    {
      "role": "user",
      "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ³ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚"
    },
    {
      "role": "assistant",
      "content": "&amp;lt;think&amp;gt;\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n&amp;lt;/answer&amp;gt;"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ¨ç†æ¨¡å‹R1çš„å›å¤æ¨¡æ¿æ˜¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;lt;think&amp;gt;\næ€è€ƒè¿‡ç¨‹\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\næœ€ç»ˆå›ç­”\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;è¿™åœ¨GRPOä¸­é€šè¿‡è®¾ç½®è§„åˆ™å¥–åŠ±å‡½æ•°çº¦æŸæ¨¡å‹ç¬¦åˆæ€è€ƒæ ‡ç­¾å’Œå›å¤æ ‡ç­¾ï¼ˆåœ¨å†·å¯åŠ¨é å‰çš„é˜¶æ®µå¥–åŠ±å€¼è®¾ç½®åº”è¯¥æé«˜ä¸€äº›ï¼‰&lt;/p&gt; 
&lt;p&gt;å¦ä¸€ä¸ªé—®é¢˜æ˜¯è’¸é¦è¿‡ç¨‹è™½ç„¶å’ŒSFTä¸€æ ·ï¼Œä½†å®éªŒç»“æœæ˜¯æ¨¡å‹éš¾ä»¥æ¯æ¬¡éƒ½ç¬¦åˆæ¨¡æ¿è§„èŒƒçš„å›å¤ï¼Œå³è„±ç¦»æ€è€ƒå’Œå›å¤æ ‡ç­¾çº¦æŸã€‚ è¿™é‡Œçš„å°æŠ€å·§æ˜¯å¢åŠ æ ‡è®°ä½ç½®tokençš„æŸå¤±æƒ©ç½šï¼Œè¯¦è§&lt;code&gt;train_distill_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# åœ¨ sp_ids å¯¹åº”çš„ä½ç½®å¢åŠ é¢å¤–çš„æƒ©ç½š
...
loss_mask[sp_ids] = 10 # æƒ©ç½šç³»æ•°
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¦å¦ä¸€ä¸ªtipsæ˜¯ç”±äºæ¨ç†æ•°æ®ç”±äºåªç­›é€‰äº†&lt;code&gt;&amp;lt;1024&lt;/code&gt;é•¿åº¦çš„æ•°æ®ï¼Œå…¶ä¸­å¤šè½®å¯¹è¯å’Œè‹±æ–‡æ•°æ®åå°‘ï¼Œ å› æ­¤&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;è¿›è¡Œäº†å¤§çº¦10kæ¡å¤šè½®å¯¹è¯+è‹±æ–‡æ•°æ®çš„æ··åˆï¼Œé˜²æ­¢æ¨¡å‹é—å¿˜ä¸¥é‡ã€‚&lt;/p&gt; 
&lt;p&gt;è„šæœ¬é»˜è®¤åŸºäºrlhfåçš„åŸºæ¨¡å‹åšæ¨ç†èƒ½åŠ›çš„è’¸é¦å¾®è°ƒï¼Œä¸‹é¢ç›´æ¥å¯åŠ¨è®­ç»ƒå³å¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;reason_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æµ‹è¯•ä¸€ä¸‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;ğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
ğŸ¤–ï¸: &amp;lt;think&amp;gt;
å—¯ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚æˆ‘ç°åœ¨éœ€è¦è§£é‡Šä¸€ä¸‹è‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥æ˜ç¡®ç”¨æˆ·æ˜¯è°ï¼Œæ˜¯å­¦ç”Ÿã€èŒåœºäººå£«è¿˜æ˜¯æ™®é€šäººã€‚ç”¨æˆ·å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿæˆ–è€…èŒåœºäººå£«ï¼Œæ‰€ä»¥ä¿¡æ¯ä¼ é€’åº”è¯¥æ˜¯å¸®åŠ©å­¦ç”Ÿå’ŒèŒåœºäººå£«çš„ä¿¡æ¯ã€‚
ç„¶åï¼Œæˆ‘éœ€è¦å›åº”ç”¨æˆ·ï¼Œè¿™å¯èƒ½åŒ…æ‹¬ä»‹ç»è‡ªå·±çš„ä½ç½®ã€å…´è¶£çˆ±å¥½ã€èŒä¸šç»å†ç­‰ä¿¡æ¯ã€‚ç”¨æˆ·è¿˜å¯èƒ½æƒ³äº†è§£è‡ªå·±åœ¨å“ªé‡Œï¼Œæ¯”å¦‚èŒä¸šå‘å±•ã€å·¥ä½œç»éªŒç­‰ã€‚
æˆ‘åº”è¯¥æ³¨æ„ç”¨è¯è¦æ­£å¼ï¼Œä¸è¦å¤ªæ­£å¼ï¼ŒåŒæ—¶è¦ä¿æŒç®€æ´æ˜äº†ã€‚è¿™æ ·ç”¨æˆ·å®¹æ˜“ç†è§£ï¼Œä¹Ÿæ–¹ä¾¿ä»–ä»¬æŸ¥é˜…ç›¸å…³èµ„æ–™ã€‚
æœ€åï¼Œæˆ‘åº”è¯¥æ€»ç»“ä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çŸ¥é“æˆ‘æ˜¯å¦‚ä½•å¸®åŠ©ä»–ä»¬å®Œæˆä»–ä»¬çš„ä»»åŠ¡çš„ï¼Œè¿™æ ·ä»–ä»¬æœ‰æ›´å¤šå…³äºæˆ‘çš„ä¿¡æ¯ã€‚
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
æˆ‘æ˜¯**â€œä½ çš„åå­—â€ï¼Œä½ å«ä»€ä¹ˆåå­—ï¼Ÿ
&amp;lt;/answer&amp;gt;

ğŸ‘¶: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ
ğŸ¤–ï¸: &amp;lt;think&amp;gt;
æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;IV å¼ºåŒ–å­¦ä¹ åè®­ç»ƒ&lt;/h2&gt; 
&lt;p&gt;LLMé‡Œçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¯åˆ†ä¸¤ç±»ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;é€šè¿‡&lt;strong&gt;äººç±»&lt;/strong&gt;å¯¹æ¨¡å‹è¾“å‡ºçš„åå¥½è¿›è¡Œè¯„ä»·æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶ç”Ÿæˆæ›´ç¬¦åˆäººç±»ä»·å€¼è§‚å’Œåå¥½çš„å†…å®¹ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;åŸºäºAIåé¦ˆçš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning from AI Feedback, RLAIF)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä½¿ç”¨&lt;strong&gt;AIæ¨¡å‹&lt;/strong&gt;ï¼ˆé€šå¸¸æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€å¥–åŠ±æ¨¡å‹ï¼‰æ¥æä¾›åé¦ˆï¼Œè€Œä¸ç›´æ¥ä¾èµ–äººç±»çš„äººå·¥æ ‡æ³¨ã€‚&lt;/li&gt; 
 &lt;li&gt;è¿™é‡Œçš„â€œAIâ€ä¹Ÿå¯ä»¥æ˜¯æŸäº›è§„åˆ™å¥–åŠ±ï¼Œä¾‹å¦‚æ•°å­¦ç­”æ¡ˆ/ä»£ç è§£é‡Šå™¨...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç±»å‹&lt;/th&gt; 
   &lt;th&gt;è£åˆ¤&lt;/th&gt; 
   &lt;th&gt;ä¼˜ç‚¹&lt;/th&gt; 
   &lt;th&gt;ç¼ºç‚¹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RLHF&lt;/td&gt; 
   &lt;td&gt;äººç±»&lt;/td&gt; 
   &lt;td&gt;æ›´è´´è¿‘çœŸå®äººç±»åå¥½&lt;/td&gt; 
   &lt;td&gt;æˆæœ¬é«˜ã€æ•ˆç‡ä½&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RLAIF&lt;/td&gt; 
   &lt;td&gt;æ¨¡å‹&lt;/td&gt; 
   &lt;td&gt;è‡ªåŠ¨åŒ–ã€å¯æ‰©å±•æ€§å¼º&lt;/td&gt; 
   &lt;td&gt;å¯èƒ½åç¦»äººç±»çœŸå®åå¥½&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;äºŒè€…æœ¬è´¨ä¸Šæ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯é€šè¿‡&lt;strong&gt;å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼&lt;/strong&gt;ï¼Œåˆ©ç”¨æŸç§å½¢å¼çš„"&lt;strong&gt;åé¦ˆ&lt;/strong&gt;"æ¥ä¼˜åŒ–æ¨¡å‹çš„è¡Œä¸ºã€‚&lt;/p&gt; 
&lt;p&gt;é™¤äº†&lt;strong&gt;åé¦ˆ&lt;/strong&gt;çš„æ¥æºä¸åŒï¼Œå…¶ä»–å¹¶æ— ä»»ä½•åŒºåˆ«ã€‚&lt;/p&gt; 
&lt;h3&gt;ğŸ‘€ POç®—æ³•çš„ç»Ÿä¸€è§†è§’&lt;/h3&gt; 
&lt;p&gt;åœ¨ä»‹ç»å®ç°å…·ä½“ç®—æ³•ä¹‹å‰ï¼Œæˆ‘å…ˆä»¥ä¸ªäººç†è§£çš„æç®€è§†è§’ï¼Œé˜è¿°æ‰€æœ‰Policy Optimization (PO)ç®—æ³•çš„ç»Ÿä¸€å…±æ€§ã€‚&lt;/p&gt; 
&lt;p&gt;æ‰€æœ‰RLç®—æ³•çš„æœ¬è´¨éƒ½åªæ˜¯åœ¨ä¼˜åŒ–ä¸€ä¸ªæœŸæœ›ï¼š&lt;/p&gt; 
&lt;p&gt;$$\mathcal{J}&lt;em&gt;{PO} = \mathbb{E}&lt;/em&gt;{q \sim P(Q), o \sim \pi(O|q)} \left[ \underbrace{f(r_t)}&lt;em&gt;{\text{ç­–ç•¥é¡¹}} \cdot \underbrace{g(A_t)}&lt;/em&gt;{\text{ä¼˜åŠ¿é¡¹}} - \underbrace{h(\text{KL}&lt;em&gt;t)}&lt;/em&gt;{\text{æ­£åˆ™é¡¹}} \right]$$&lt;/p&gt; 
&lt;p&gt;è®­ç»ƒæ—¶ï¼Œåªéœ€&lt;strong&gt;æœ€å°åŒ–è´Ÿç›®æ ‡å‡½æ•°&lt;/strong&gt;ï¼Œå³: $\mathcal{L_{PO}}=-\mathcal{J_{PO}}$&lt;/p&gt; 
&lt;p&gt;è¿™ä¸ªæ¡†æ¶åªåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ç­–ç•¥é¡¹&lt;/strong&gt; $f(r_t)$: å¦‚ä½•ä½¿ç”¨æ¦‚ç‡æ¯” $r_t$? å³å‘Šè¯‰æ¨¡å‹æ–°æ—§ç­–ç•¥åå·®æœ‰å¤šå¤§ï¼Œæ˜¯å¦æ¢ç´¢åˆ°äº†æ›´å¥½çš„token&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿é¡¹&lt;/strong&gt; $g(A_t)$: å¦‚ä½•è®¡ç®—ä¼˜åŠ¿ $A_t$, è¿™å¾ˆé‡è¦ï¼å¤§æ¨¡å‹ç®—å¯¹å®šç§¯åˆ†ä¹Ÿä¸è¶³ä¸ºå¥‡ï¼Œå°æ¨¡å‹å›ç­”å¯¹åŠ å‡æ³•ä¼˜åŠ¿é€šå¸¸éƒ½æ˜¯æ­£çš„&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ­£åˆ™é¡¹&lt;/strong&gt; $h(\text{KL}_t)$: å¦‚ä½•çº¦æŸå˜åŒ–å¹…åº¦ $\text{KL}_t$, æ—¢é˜²æ­¢è·‘ååˆé˜²æ­¢ç®¡çš„å¤ªæ­»&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ï¼ˆå±•å¼€ï¼‰ç¬¦å·è¯´æ˜&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;ç¬¦å·&lt;/th&gt; 
    &lt;th&gt;å«ä¹‰&lt;/th&gt; 
    &lt;th&gt;è¯´æ˜&lt;/th&gt; 
    &lt;th&gt;å€¼åŸŸ&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$q$&lt;/td&gt; 
    &lt;td&gt;é—®é¢˜/æç¤ºè¯&lt;/td&gt; 
    &lt;td&gt;ä»æ•°æ®é›† $P(Q)$ ä¸­é‡‡æ ·&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$o$&lt;/td&gt; 
    &lt;td&gt;æ¨¡å‹è¾“å‡ºåºåˆ—&lt;/td&gt; 
    &lt;td&gt;ç”±ç­–ç•¥ $\pi$ ç”Ÿæˆ&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$r_t$&lt;/td&gt; 
    &lt;td&gt;æ¦‚ç‡æ¯”&lt;/td&gt; 
    &lt;td&gt;$r_t = \frac{\pi_\theta(o_t|q, o_{&amp;lt;t})}{\pi_{ref}(o_t|q, o_{&amp;lt;t})}$&lt;/td&gt; 
    &lt;td&gt;$(0, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$A_t$&lt;/td&gt; 
    &lt;td&gt;ä¼˜åŠ¿å‡½æ•°&lt;/td&gt; 
    &lt;td&gt;è¡¡é‡æŸä¸ªåŠ¨ä½œç›¸æ¯”åŸºçº¿æœ‰å¤šå¥½&lt;/td&gt; 
    &lt;td&gt;$(-\infty, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$\text{KL}_t$&lt;/td&gt; 
    &lt;td&gt;KLæ•£åº¦&lt;/td&gt; 
    &lt;td&gt;é˜²æ­¢ç­–ç•¥åç¦»å‚è€ƒæ¨¡å‹å¤ªè¿œ&lt;/td&gt; 
    &lt;td&gt;$[0, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;ä¸åŒçš„&lt;strong&gt;xxPOç®—æ³•&lt;/strong&gt;æœ¬è´¨ä¸Šåªæ˜¯å¯¹è¿™ä¸‰ä¸ªç»„ä»¶çš„ä¸åŒè®¾è®¡çš„å®ä¾‹åŒ–ï¼&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;6. åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;åœ¨å‰é¢çš„è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å…·å¤‡äº†åŸºæœ¬çš„å¯¹è¯èƒ½åŠ›ï¼Œä½†æ˜¯è¿™æ ·çš„èƒ½åŠ›å®Œå…¨åŸºäºå•è¯æ¥é¾™ï¼Œç¼ºå°‘æ­£åæ ·ä¾‹çš„æ¿€åŠ±ã€‚ æ¨¡å‹æ­¤æ—¶å°šæœªçŸ¥ä»€ä¹ˆå›ç­”æ˜¯å¥½çš„ï¼Œä»€ä¹ˆæ˜¯å·®çš„ã€‚å¸Œæœ›å®ƒèƒ½å¤Ÿæ›´ç¬¦åˆäººçš„åå¥½ï¼Œé™ä½è®©äººç±»ä¸æ»¡æ„ç­”æ¡ˆçš„äº§ç”Ÿæ¦‚ç‡ã€‚ è¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯è®©æ¨¡å‹å‚åŠ æ–°çš„åŸ¹è®­ï¼Œä»ä¼˜ç§€å‘˜å·¥çš„ä½œä¸ºä¾‹å­ï¼Œæ¶ˆæå‘˜å·¥ä½œä¸ºåä¾‹ï¼Œå­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å›å¤ã€‚&lt;/p&gt; 
&lt;h4&gt;6.1 Direct Preference Optimization&lt;/h4&gt; 
&lt;p&gt;ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ç®—æ³•ï¼ŒæŸå¤±ä¸ºï¼š&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}&lt;em&gt;{DPO} = -\mathbb{E}\left[\log \sigma\left(\beta \left[\log \frac{\pi&lt;/em&gt;\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}\right]\right)\right]$$&lt;/p&gt; 
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ç­–ç•¥é¡¹&lt;/strong&gt;: $f(r_t) = \log r_w - \log r_l$ (å¯¹æ¯”chosen vs rejectedçš„æ¦‚ç‡æ¯”)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿é¡¹&lt;/strong&gt;: $g(A_t)$ = / (é€šè¿‡åå¥½å¯¹æ¯”ï¼Œæ— éœ€æ˜¾å¼è®¡ç®—ä¼˜åŠ¿)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ­£åˆ™é¡¹&lt;/strong&gt;: $h(\text{KL}_t)$ = éšå«åœ¨ $\beta$ ä¸­ (æ§åˆ¶åç¦»å‚è€ƒæ¨¡å‹ç¨‹åº¦)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ç‰¹åˆ«åœ°ï¼Œ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DPOä»PPOå¸¦KLçº¦æŸçš„ç›®æ ‡æ¨å¯¼å‡ºå¯¹åå¥½å¯¹çš„è§£æè®­ç»ƒç›®æ ‡ï¼Œç›´æ¥æœ€å¤§åŒ–"chosenä¼˜äºrejected"çš„å¯¹æ•°å‡ ç‡ï¼›æ— éœ€åŒæ­¥è®­ç»ƒReward/Valueæ¨¡å‹ã€‚DPOåªéœ€è·‘&lt;code&gt;actor&lt;/code&gt;ä¸&lt;code&gt;ref&lt;/code&gt;ä¸¤ä¸ªæ¨¡å‹ï¼Œæ˜¾å­˜å ç”¨ä½ã€æ”¶æ•›ç¨³å®šã€å®ç°ç®€å•ã€‚&lt;/li&gt; 
 &lt;li&gt;è®­ç»ƒèŒƒå¼ï¼šoffâ€‘policyï¼Œä½¿ç”¨é™æ€åå¥½æ•°æ®é›†ï¼Œå¯åå¤å¤šè½®epochï¼›Refæ¨¡å‹å›ºå®šï¼ˆé¢„å…ˆç¼“å­˜è¾“å‡ºï¼‰ã€‚&lt;/li&gt; 
 &lt;li&gt;DPOçš„å±€é™åœ¨äºä¸åšåœ¨çº¿æ¢ç´¢ï¼Œæ›´å¤šç”¨äº"åå¥½/å®‰å…¨"çš„äººç±»ä»·å€¼å¯¹é½ï¼›å¯¹"èƒ½ä¸èƒ½åšå¯¹é¢˜"çš„æ™ºåŠ›èƒ½åŠ›æå‡æœ‰é™ï¼ˆå½“ç„¶è¿™ä¹Ÿå–å†³äºæ•°æ®é›†ï¼Œå¤§è§„æ¨¡æ”¶é›†æ­£åæ ·æœ¬å¹¶äººç±»è¯„ä¼°å¾ˆå›°éš¾ï¼‰ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;dpo_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;7. åŸºäºAIåé¦ˆçš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning from AI Feedback, RLAIF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ç›¸æ¯”RLHFä¾èµ–äººç±»æ ‡æ³¨chosen/rejectedåå¥½å¯¹ï¼ŒRLAIFåˆ™å®Œå…¨ç”±AIæ¥å……å½“"è£åˆ¤"ã€‚ æ‰€è°“AI"è£åˆ¤"å¯ä»¥æ˜¯model-baseçš„å¥–åŠ±å¤§æ¨¡å‹(Reward Model)ï¼Œä¹Ÿå¯ä»¥æ˜¯R1ä¸€æ ·è®¾ç½®è§„åˆ™å‡½æ•°è¿›è¡Œæ ¡éªŒï¼Œä¹Ÿå¯ä»¥æ˜¯ä¾‹å¦‚å·¥å…·è°ƒç”¨çš„ç¯å¢ƒåé¦ˆã€‚ ä¾‹å¦‚ï¼šæ•°å­¦é¢˜ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€å·¥å…·è°ƒç”¨æ‰§è¡Œä»£ç èƒ½å¦é€šè¿‡æµ‹è¯•ç”¨ä¾‹ã€æ¨ç†è¿‡ç¨‹æ˜¯å¦ç¬¦åˆæ ¼å¼...éƒ½å¯ä»¥è‡ªåŠ¨åŒ–åˆ¤æ–­ã€‚ RLAIFçš„æœ€å¤§ä¼˜åŠ¿åœ¨äº&lt;strong&gt;å¯æ‰©å±•æ€§&lt;/strong&gt;å’Œ&lt;strong&gt;On-Policy&lt;/strong&gt;çš„ç‰¹ç‚¹â€”â€”ä¸éœ€è¦æ˜‚è´µçš„äººå·¥æ ‡æ³¨ï¼Œå¯ä»¥ç”Ÿæˆæµ·é‡çš„è®­ç»ƒæ ·æœ¬ï¼Œè®©æ¨¡å‹åœ¨åœ¨çº¿å¤§é‡è¯•é”™ä¸­å¿«é€Ÿè¿›åŒ–ã€‚&lt;/p&gt; 
&lt;p&gt;MiniMind ç€æ‰‹å®ç°&lt;strong&gt;2+N&lt;/strong&gt;ç§åŸºæœ¬+å‰æ²¿çš„RLAIFæ–¹æ³•ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PPO&lt;/strong&gt;ã€&lt;strong&gt;GRPO&lt;/strong&gt; è¢«å¤§è§„æ¨¡éªŒè¯çš„ç»å…¸RLç®—æ³•ï¼›&lt;/li&gt; 
 &lt;li&gt;Nç§å‰æ²¿RLç®—æ³•ï¼ˆä¸å®šæœŸä»¥Expæ€§è´¨æ›´æ–°ï¼‰ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1ï¸âƒ£ æ•°æ®é›†å‡†å¤‡ (éœ€è¦)&lt;/h4&gt; 
&lt;p&gt;ä¸ºäº†å¿«é€ŸéªŒè¯RLAIFçš„æ•ˆæœï¼Œè¿™é‡Œä»SFTæ•°æ®é›†ä¸­éšæœºé‡‡æ ·äº†1ä¸‡æ¡é«˜è´¨é‡å¯¹è¯ï¼Œæ„å»ºçº¦1MBå¤§å°çš„&lt;code&gt;rlaif-mini.jsonl&lt;/code&gt;(&lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/blob/main/rlaif-mini.jsonl"&gt;Huggingface&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;æ•°æ®æ ¼å¼ä¸SFTä¸€è‡´ï¼Œä½†assistantå¹¶ä¸éœ€è¦å†…å®¹ï¼Œå› ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­å®Œå…¨ç”± $\Pi$ ç­–ç•¥æ¨¡å‹å®æ—¶é‡‡æ ·ç”Ÿæˆã€‚å› æ­¤å½¢å¦‚ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "conversations": [
        {"role": "user", "content": "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å…‰åˆä½œç”¨ï¼Ÿ"},
        {"role": "assistant", "content": "æ— "}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RLAIFçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šåŸºäºuserçš„é—®é¢˜ç”Ÿæˆ1æˆ–å¤šä¸ªå€™é€‰å›ç­”ï¼Œç„¶åç”±å¥–åŠ±å‡½æ•°/æ¨¡å‹å¯¹å›ç­”æ‰“åˆ†ï¼Œ åˆ†æ•°é«˜çš„å›ç­”ä¼šè¢«é¼“åŠ±ï¼ˆå¢åŠ  $\Pi$ ç­–ç•¥æ¦‚ç‡ï¼‰ï¼Œåˆ†æ•°ä½çš„å›ç­”ä¼šè¢«æŠ‘åˆ¶ï¼ˆé™ä½ $\Pi$ ç­–ç•¥æ¦‚ç‡ï¼‰ã€‚è¿™ä¸ª"æ‰“åˆ†-&amp;gt;è°ƒæ•´"çš„å¾ªç¯å°±æ˜¯å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒã€‚&lt;/p&gt; 
&lt;h4&gt;2ï¸âƒ£ å¥–åŠ±æ¨¡å‹å‡†å¤‡ (éœ€è¦)&lt;/h4&gt; 
&lt;p&gt;å·²çŸ¥RLAIFè®­ç»ƒéœ€è¦â€œå¥–åŠ±æ¨¡å‹ (Reward Model)â€å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œæ‰“åˆ†ã€‚&lt;/p&gt; 
&lt;p&gt;æ­¤å¤„é€‰å–å°å‹ä¸”é«˜è´¨é‡çš„InternLM2-1.8B-Reward (&lt;a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b-reward"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/internlm/internlm2-1_8b-reward"&gt;HuggingFace&lt;/a&gt;) ä½œä¸ºåŸºç¡€å¥–åŠ±æ¨¡å‹ã€‚&lt;/p&gt; 
&lt;p&gt;ä¸‹è½½å¥–åŠ±æ¨¡å‹åéœ€è¦æ”¾ç½®åœ¨minimindé¡¹ç›®çš„&lt;strong&gt;åŒçº§ç›®å½•&lt;/strong&gt;ä¸‹ï¼Œæ¨èç»“æ„å¦‚ä¸‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;project/
â”œâ”€â”€ minimind/                    # MiniMindé¡¹ç›®
â”‚   â”œâ”€â”€ model/
â”‚   â””â”€â”€ ...
â””â”€â”€ internlm2-1_8b-reward/       # å¥–åŠ±æ¨¡å‹ï¼ˆä¸minimindåŒçº§ï¼‰
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors
    â””â”€â”€ ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;å¥–åŠ±æœºåˆ¶é€‰æ‹©ä¸MiniMindé™åˆ¶è¯´æ˜ï¼ˆç‚¹å‡»å±•å¼€ï¼‰&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;1. å¥–åŠ±æœºåˆ¶çš„å¤šæ ·æ€§&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;RLAIFä¸­çš„"å¥–åŠ±ä¿¡å·"æ¥æºå¯ä»¥éå¸¸çµæ´»ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model-basedå¥–åŠ±&lt;/strong&gt;ï¼šå¯ä½¿ç”¨ä¸“é—¨çš„Reward Modelï¼ˆå¦‚InternLM2-Rewardï¼‰ï¼Œä¹Ÿå¯ä½¿ç”¨é€šç”¨LLM+æç¤ºè¯è¿›è¡Œæ‰“åˆ†ï¼ˆå¦‚Qwen3-as-a-Judgeï¼‰ã€‚å¥–åŠ±æ¨¡å‹è§„æ¨¡å’Œæ¶æ„å‡å¯è‡ªç”±é€‰æ‹©ã€‚&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rule-basedå¥–åŠ±&lt;/strong&gt;ï¼šå¯ä»¥åŸºäºè§„åˆ™å‡½æ•°æ„é€ å¥–åŠ±ä¿¡å·ï¼Œä¾‹å¦‚ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;æ•°å­¦é¢˜ç­”æ¡ˆæ­£ç¡®æ€§éªŒè¯ï¼ˆGround Truthå¯¹æ¯”ï¼‰&lt;/li&gt; 
    &lt;li&gt;SQLæ‰§è¡ŒæˆåŠŸç‡ä¸ç»“æœå‡†ç¡®æ€§&lt;/li&gt; 
    &lt;li&gt;ä»£ç è§£é‡Šå™¨è¿è¡Œç»“æœï¼ˆpass@kï¼‰&lt;/li&gt; 
    &lt;li&gt;å·¥å…·è°ƒç”¨è¿”å›çŠ¶æ€ï¼ˆAPIæˆåŠŸ/å¤±è´¥ï¼‰&lt;/li&gt; 
    &lt;li&gt;æ ¼å¼åˆè§„æ€§æ£€æŸ¥ï¼ˆJSON/XMLè§£æï¼‰&lt;/li&gt; 
    &lt;li&gt;æ¨ç†é“¾å®Œæ•´æ€§è¯„ä¼°ï¼ˆCoTæ­¥éª¤æ•°ï¼‰&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Environment-basedå¥–åŠ±&lt;/strong&gt;ï¼šåœ¨Agentåœºæ™¯ä¸­ï¼Œç¯å¢ƒåé¦ˆæœ¬èº«å³ä¸ºå¤©ç„¶å¥–åŠ±ï¼ˆå¦‚æ¸¸æˆå¾—åˆ†ã€Researchå®Œæ•´åº¦ã€ä»»åŠ¡å®Œæˆåº¦ï¼‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ä»»ä½•èƒ½å¤Ÿé‡åŒ–"å›ç­”è´¨é‡"çš„æœºåˆ¶éƒ½å¯ä½œä¸ºRLçš„å¥–åŠ±æ¥æºã€‚DeepSeek R1å°±æ˜¯å…¸å‹æ¡ˆä¾‹ï¼šä½¿ç”¨è§„åˆ™å‡½æ•°éªŒè¯æ•°å­¦ç­”æ¡ˆæ­£ç¡®æ€§ä½œä¸ºå¥–åŠ±ï¼Œæ— éœ€é¢å¤–çš„Reward Modelã€‚&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2. MiniMindé™åˆ¶ï¼šå¥–åŠ±ç¨€ç–é—®é¢˜&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;RLAIFè®­ç»ƒæ—¢å¯ä»¥é’ˆå¯¹æ¨ç†æ¨¡å‹ä¹Ÿå¯ä»¥é’ˆå¯¹éæ¨ç†æ¨¡å‹ï¼ŒåŒºåˆ«ä»…åœ¨äºæ ¼å¼ã€‚&lt;/p&gt; 
 &lt;p&gt;ç„¶è€Œå¯¹äºMiniMindè¿™ç§0.1Bå‚æ•°é‡æå°èƒ½åŠ›å¼±çš„æ¨¡å‹ï¼Œåœ¨é€šç”¨ä»»åŠ¡ï¼ˆå¦‚R1é£æ ¼çš„æ•°å­¦æ•°æ®é›†ï¼‰ä¸Šä¼šé‡åˆ°ä¸¥é‡çš„å¥–åŠ±ç¨€ç–(Reward Sparsity)é—®é¢˜ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ç°è±¡&lt;/strong&gt;ï¼šæ¨¡å‹ç”Ÿæˆçš„å€™é€‰å›ç­”å‡ ä¹å…¨éƒ¨é”™è¯¯ï¼Œå¯¼è‡´æ‰€æœ‰å¥–åŠ±åˆ†æ•° $r(x,y) \approx 0$&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;åæœ&lt;/strong&gt;ï¼šä¼˜åŠ¿å‡½æ•° $A(x,y) = r(x,y) - b(x) \approx 0$ï¼Œç­–ç•¥æ¢¯åº¦ä¿¡å·æ¶ˆå¤±ï¼Œæ— æ³•æœ‰æ•ˆæ›´æ–°å‚æ•° $\theta$&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;å¦‚åŒè®©å°å­¦ç”Ÿåšé«˜è€ƒæ•°å­¦é¢˜ï¼Œæ— è®ºå°è¯•å¤šå°‘æ¬¡éƒ½å¾—é›¶åˆ†ï¼Œæ— æ³•é€šè¿‡åˆ†æ•°å·®å¼‚å­¦ä¹ æ”¹è¿›ç­–ç•¥ã€‚å› æ­¤è¿™æ˜¯RLç®—æ³•çš„æ ¹æœ¬åŸç†é™åˆ¶çš„ã€‚&lt;/p&gt; 
 &lt;p&gt;ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼ŒMiniMindçš„å®ç°é€‰æ‹©äº†&lt;strong&gt;model-basedçš„è¿ç»­æ€§å¥–åŠ±ä¿¡å·&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Reward Modelè¾“å‡ºè¿ç»­åˆ†æ•°ï¼ˆå¦‚-2.5åˆ°+3.0ï¼‰ï¼Œè€ŒéäºŒå…ƒçš„0/1&lt;/li&gt; 
  &lt;li&gt;å³ä½¿å›ç­”è´¨é‡éƒ½å·®ï¼Œä¹Ÿä»èƒ½åŒºåˆ†"æ›´æ›´å·®"(-3.0)å’Œ"æ›´å·®"(-2.8)çš„ç»†å¾®å·®å¼‚ã€‚æ‰€ä»¥è¿™ç§&lt;strong&gt;ç¨ å¯†ä¸”è¿ç»­&lt;/strong&gt;çš„å¥–åŠ±ä¿¡å·èƒ½å¤Ÿä¸ºä¼˜åŠ¿å‡½æ•° $A(x,y)$ æä¾›éé›¶æ¢¯åº¦ï¼Œä½¿å¾—ç­–ç•¥ç½‘ç»œå¾—ä»¥æ¸è¿›å¼ä¼˜åŒ–&lt;/li&gt; 
  &lt;li&gt;ä¹Ÿå¯ä»¥æ··åˆå¤šç§å¥–åŠ±æº: $r_{\text{total}} = \alpha \cdot r_{\text{model}} + \beta \cdot r_{\text{rule}}$ (ä¾‹å¦‚æ—¢å¯ä»¥æ£€æµ‹thinkæ ‡ç­¾æ ¼å¼rewardï¼Œåˆå¯ä»¥ç»¼åˆå›ç­”æœ¬èº«è´¨é‡çš„rewardåˆ†æ•°)&lt;/li&gt; 
  &lt;li&gt;minimindå®è·µä¸­é¿å…ç›´æ¥ä½¿ç”¨rule-basedäºŒå…ƒå¥–åŠ± + è¶…çº²éš¾åº¦æ•°æ®ï¼ˆå¦‚MATH500ï¼‰ï¼Œæ˜“å¯¼è‡´å¥–åŠ±å…¨é›¶ï¼›&lt;/li&gt; 
  &lt;li&gt;ç›‘æ§è®­ç»ƒæ—¶è§‚å¯Ÿå¥–åŠ±åˆ†æ•°çš„æ–¹å·® $\text{Var}(r)$ï¼Œè‹¥æŒç»­æ¥è¿‘0åˆ™éœ€è°ƒæ•´æ•°æ®æˆ–å¥–åŠ±æœºåˆ¶&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;å¯¹äºç”Ÿäº§çº§å¤§æ¨¡å‹çš„Agentic RLåœºæ™¯&lt;/strong&gt;ï¼š&lt;/p&gt; 
 &lt;p&gt;åœ¨çœŸå®Agentç³»ç»Ÿï¼ˆä»£ç ç”Ÿæˆã€å·¥å…·è°ƒç”¨ã€æ£€ç´¢-è§„åˆ’-æ‰§è¡Œçš„å¤šè½®é“¾è·¯ï¼‰ä¸­ï¼Œå¥–åŠ±æ˜¯â€œå»¶è¿Ÿæ•´è½®ç»“ç®—â€çš„ä¸åŒèŒƒå¼ï¼š&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LLMéœ€è¦é€tokenç”Ÿæˆå·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼ˆtool_callï¼‰ï¼Œç»å†è§£æï¼ˆtool_parseï¼‰ã€å·¥å…·æ‰§è¡Œï¼ˆtool_execï¼‰ï¼Œå†æŠŠç»“æœæ‹¼æ¥å›ä¸Šä¸‹æ–‡ç»§ç»­ä¸‹ä¸€æ­¥ï¼›å¾ªç¯å¾€å¤ç›´åˆ°å®Œæˆã€‚&lt;/li&gt; 
  &lt;li&gt;ä¸€æ¬¡å®Œæ•´çš„ä»»åŠ¡é“¾è·¯åŒ…å«å¤šæ¬¡è°ƒç”¨+æ€è€ƒï¼Œç›´åˆ°ç»ˆæ­¢æ¡ä»¶æ»¡è¶³æ—¶è®¡ç®—ä¸€æ¬¡æ€»rewardï¼ˆå¦‚ä»»åŠ¡æ˜¯å¦å®Œæˆã€æµ‹è¯•æ˜¯å¦é€šè¿‡ã€ç›®æ ‡æ˜¯å¦å‘½ä¸­ï¼‰ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;å› æ­¤ï¼ŒAgentic RLæ›´æ¥è¿‘ç¨€ç–/å»¶è¿Ÿå¥–åŠ±è®¾å®šï¼šæ¢¯åº¦å›ä¼ åœ¨â€œæ•´è½®ç»“æŸåâ€æ‰å‘ç”Ÿï¼Œå’ŒéAgentic RLä»»åŠ¡åœ¨å¯¹è¯å•è½®ä¸Šâ€œå³æ—¶è¯„åˆ†å³æ—¶æ›´æ–°â€æœ‰å¾ˆå¤§ä¸åŒã€‚ è¿™ä¹Ÿè§£é‡Šäº†Agentä»»åŠ¡ä¸Šæ›´åå‘ç¯å¢ƒåé¦ˆï¼ˆenvironment-based rewardï¼‰ï¼Œè€Œéå‡­Reward Modelè¿›è¡Œé™æ€æ‰“åˆ†ã€‚&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ç¯å¢ƒäº¤äº’åé¦ˆ&lt;/strong&gt;ï¼šæœ€ç»ˆä»¥æ‰§è¡Œç»“æœä¸ºå‡†ï¼ˆä»£ç æ˜¯å¦è·‘é€šã€APIæ˜¯å¦è¿”å›æˆåŠŸã€å­ç›®æ ‡æ˜¯å¦å®Œæˆï¼‰ï¼›&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Model-basedå¥–åŠ±å±€é™&lt;/strong&gt;ï¼šå¯¹é•¿é“¾è·¯ã€å¯æ‰§è¡Œè¯­ä¹‰çš„å…¨è²Œæ•æ‰æœ‰é™ï¼Œä¸”å¤§æ¦‚ç‡å’ŒçœŸå®ç¯å¢ƒåé¦ˆä¸ä¸€è‡´ï¼ˆreward hackingï¼‰ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h4&gt;7.1 &lt;a href="https://arxiv.org/abs/1707.06347"&gt;Proximal Policy Optimization&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;PPO æ˜¯2017å¹´OpenAIæå‡ºçš„éå¸¸ç»å…¸å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¹Ÿæ˜¯LLM RLé€šç”¨çš„åŸºçº¿æ–¹æ³•ï¼Œç”šè‡³ä¸éœ€è¦åŠ ä¹‹ä¸€ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PPOæŸå¤±&lt;/strong&gt;ï¼š $$\mathcal{L}_{PPO} = -\mathbb{E}\left[\min(r_t \cdot A_t, \text{clip}(r_t, 1-\varepsilon, 1+\varepsilon) \cdot A_t)\right] + \beta \cdot \mathbb{E}[\text{KL}]$$&lt;/p&gt; 
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ç­–ç•¥é¡¹&lt;/strong&gt;: $f(r_t) = \min(r_t, \text{clip}(r_t, 1-\varepsilon, 1+\varepsilon))$ (è£å‰ªæ¦‚ç‡æ¯”é˜²æ­¢æ›´æ–°è¿‡æ¿€)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿é¡¹&lt;/strong&gt;: $g(A_t) = R - V(s)$ (é€šè¿‡Criticç½‘ç»œä¼°è®¡ä»·å€¼å‡½æ•°)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ­£åˆ™é¡¹&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \mathbb{E}[\text{KL}]$ (å…¨å±€KLæ•£åº¦çº¦æŸ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¯¹æ¯”DPOè€Œè¨€ï¼Œ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DPO (Off-Policy)ï¼šè®­ç»ƒæ•°æ®æ˜¯é™æ€çš„åå¥½æ•°æ®é›†ï¼ˆchosen vs rejectedï¼‰ï¼Œå¯ä»¥åå¤ä½¿ç”¨åŒä¸€æ‰¹æ•°æ®è®­ç»ƒå¤šä¸ªepochï¼Œå°±åƒä¼ ç»Ÿç›‘ç£å­¦ä¹ ä¸€æ ·ã€‚æ•°æ®æ•ˆç‡é«˜ï¼Œè®­ç»ƒæˆæœ¬ä½ã€‚å®ƒç›´æ¥ä¼˜åŒ–åå¥½å¯¹çš„å¯¹æ•°ä¼¼ç„¶ï¼Œæ— éœ€Reward Modelã€‚&lt;/li&gt; 
 &lt;li&gt;PPO (On-Policy)ï¼šå¿…é¡»ç”¨å½“å‰ç­–ç•¥å®æ—¶é‡‡æ ·ç”Ÿæˆæ–°æ•°æ®ï¼Œæ—§ç­–ç•¥é‡‡é›†çš„æ•°æ®ä¸èƒ½ç”¨ï¼ˆä¼šæœ‰distribution shifté—®é¢˜ï¼‰ã€‚è™½ç„¶é€šè¿‡importance samplingå’Œclipæœºåˆ¶å…è®¸è½»å¾®çš„åˆ†å¸ƒåç§»ï¼Œä½†æœ¬è´¨ä¸Šè¦æ±‚æ•°æ®æ¥è‡ªç›¸å¯¹æ–°é²œçš„ç­–ç•¥ã€‚æ•°æ®æ•ˆç‡ä½ï¼Œä½†é€‚åˆæ¢ç´¢å¼å­¦ä¹ ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ç®€å•æ¥è¯´ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;å‰è€…æ•™æ¨¡å‹æŒ‰ç¦»çº¿é¢„å®šçš„ã€Œå¥½/åæ ‡å‡†ã€å­¦ä¹ ï¼Œå°½ç®¡å®ƒå¹¶éæ˜¯å½“å‰æ¨¡å‹æ‰€èƒ½è¾“å‡ºçš„ï¼ˆä¾‹å¦‚å‚è€ƒä¸–ç•Œå† /äºšå†›å½•åƒç»ƒä¹ æ‰“çƒï¼‰ï¼›&lt;/li&gt; 
 &lt;li&gt;åè€…å®æ—¶åœ°æ•™æ¨¡å‹æŠŠäº‹æƒ…åšå¯¹åšå¥½ï¼Œåœ¨çº¿é‡‡æ ·è‡ªæœ€æ–°æ¨¡å‹policyï¼ˆæ•™ç»ƒæ‰‹æŠŠæ‰‹æ•™æ‰“ï¼Œä¸ºæ¯ä¸ªåŠ¨ä½œå®æ—¶æ‰“åˆ†ï¼‰ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MiniMindçš„PPOå®ç°åŒ…å«äº†Actoræ¨¡å‹(ç”Ÿæˆå›ç­”)å’ŒCriticæ¨¡å‹(è¯„ä¼°å›ç­”ä»·å€¼)ï¼Œä»¥åŠå®Œæ•´çš„GAE(Generalized Advantage Estimation)ä¼˜åŠ¿å‡½æ•°è®¡ç®—ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è®­ç»ƒæ–¹å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_ppo.py
# or
python train_ppo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;ppo_actor_*.pth&lt;/code&gt;ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼‰&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_ppo_512.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_ppo_768.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;ä»è®­ç»ƒæ›²çº¿å¯ä»¥çœ‹å‡ºï¼ŒPPOå­˜åœ¨&lt;strong&gt;rewardæå‡ç¼“æ…¢&lt;/strong&gt;çš„é—®é¢˜ã€‚ç§ä»¥ä¸ºè¿™ä¸»è¦æºäº&lt;strong&gt;PPOåŒç½‘ç»œè”åˆä¼˜åŒ–&lt;/strong&gt;æ–¹æ³•ï¼šCriticéœ€è¦é€æ­¥æ”¶æ•›ä»¥å‡†ç¡®ä¼°è®¡ä»·å€¼å‡½æ•°ï¼Œè€ŒActorçš„ç­–ç•¥æ›´æ–°ä¾èµ–Criticæä¾›çš„ä¼˜åŠ¿ä¼°è®¡ï¼Œä¸¤è€…ç›¸äº’ä¾èµ–å½¢æˆå¤æ‚çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚è®­ç»ƒåˆæœŸCriticä¼°è®¡ä¸å‡†ä¼šå½±å“Actoræ¢¯åº¦æ–¹å‘ï¼Œå¯¼è‡´æ•´ä½“æ”¶æ•›ç¼“æ…¢ã€‚æ­¤å¤–ï¼ŒPPOéœ€è¦åŒæ—¶ç»´æŠ¤ä¸¤ä¸ªç½‘ç»œï¼Œæ˜¾å­˜å ç”¨çº¦ä¸ºå•ç½‘ç»œæ–¹æ³•çš„1.5-2å€ã€‚&lt;/p&gt; 
&lt;h4&gt;7.2 &lt;a href="https://arxiv.org/pdf/2402.03300"&gt;Group Relative Policy Optimization&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;2025å¹´åˆï¼ŒDeepSeek-R1ç«çˆ†å‡ºåœˆï¼ŒåŒæ ·ç«äº†çš„æœ‰æ¥è‡ªDeepSeekMathè®ºæ–‡çš„GRPOç®—æ³•ï¼Œä¹Ÿä¸€è·ƒæˆä¸ºæœ€å…ˆè¿›çš„RLç®—æ³•ä¹‹ä¸€ã€‚ ç„¶è€ŒAIåŠå¹´=äººé—´åŠä¸ªä¸–çºªï¼Œæ—¶è‡³ä»Šæ—¥GRPOå·²ç»æ¼”å˜ä¸ºå„å¤§XXPOå¤§æˆ˜(åé¢æ¼”å˜çš„DAPOã€GSPOã€CISPOç­‰)çš„åŸºçº¿ç®—æ³•ã€‚ å…·ä½“æ¥è¯´ï¼Œä¸€å¥è¯æ€»ç»“å®ƒçš„æ ¸å¿ƒåˆ›æ–°æ˜¯"åˆ†ç»„ç›¸å¯¹ä»·å€¼ä¼°è®¡"ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GRPOæŸå¤±&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}_{GRPO} = -\mathbb{E}\left[r_t \cdot A_t - \beta \cdot \text{KL}_t\right]$$&lt;/p&gt; 
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ç­–ç•¥é¡¹&lt;/strong&gt;: $f(r_t) = r_t$ (ç›´æ¥ä½¿ç”¨æ¦‚ç‡æ¯”ï¼Œæ— clipè£å‰ª)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿é¡¹&lt;/strong&gt;: $g(A_t) = \frac{R - \mu_{group}}{\sigma_{group}}$ (ç»„å†…å½’ä¸€åŒ–ï¼Œæ¶ˆé™¤Criticç½‘ç»œ)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ­£åˆ™é¡¹&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \text{KL}_t$ (tokençº§KLæ•£åº¦çº¦æŸ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¯¹äºåŒä¸€ä¸ªé—®é¢˜ï¼Œæ¨¡å‹ç”ŸæˆNä¸ªä¸åŒçš„å›ç­”(ä¾‹å¦‚N=4)ï¼Œç„¶åè®¡ç®—è¿™Nä¸ªå›ç­”çš„å¥–åŠ±åˆ†æ•°ã€‚ æ¥ç€æŠŠè¿™Nä¸ªå›ç­”çš„å¹³å‡å¥–åŠ±ä½œä¸ºbaselineï¼Œé«˜äºbaselineçš„å›ç­”è¢«é¼“åŠ±ï¼Œä½äºbaselineçš„å›ç­”è¢«æŠ‘åˆ¶ã€‚ ç”¨è¿™ç§æ–¹å¼å·§å¦™åœ°é¿å…äº†è®­ç»ƒé¢å¤–çš„criticç½‘ç»œã€‚&lt;/p&gt; 
&lt;p&gt;åªè¦æ˜¯RLéƒ½å¿…é¡»é¢å¯¹çš„æ­£åæ ·æœ¬è¿™ä¸ªåŸç†æ€§é™åˆ¶ï¼ŒGRPOä¹Ÿä¸ä¼šä¾‹å¤–ï¼Œå…¶æ›´æ˜¾è‘—çš„é—®é¢˜æ˜¯ï¼šé€€åŒ–ç»„(Degenerate Groups)ã€‚ å‡è®¾æŸä¸ªé—®é¢˜ç•¥éš¾ï¼Œå¯¼è‡´Nä¸ªå›ç­”çš„å¥–åŠ±åˆ†æ•°å‡ ä¹ä¸€æ ·ï¼ˆå¤§éƒ¨åˆ†æƒ…å†µæ˜¯ä¸€æ ·çƒ‚è€Œä¸æ˜¯ä¸€æ ·å¥½ï¼‰ï¼Œé‚£ä¹ˆè¿™ä¸€ç»„çš„å­¦ä¹ ä¿¡å·å°±æ— é™æ¥è¿‘0ã€‚ åœ¨MiniMindè¿™ç§è¶…å°æ¨¡å‹ä¸Šï¼Œè¿™ä¸ªé—®é¢˜å°¤ä¸ºæ˜æ˜¾ï¼Œæ±‚è§£æ•°å­¦é—®é¢˜99.99%çš„æƒ…å†µä¸‹æ•´ç»„å›ç­”è´¨é‡éƒ½å¾ˆå·®ï¼Œé‚£ä¹ˆå°†æ— æ³•å­¦ä¹ ã€‚ å› æ­¤å¿…é¡»ä¸ºæ¨¡å‹æŒ‡å®šåˆç†çš„domainï¼Œå³å¿…é¡»é™åˆ¶åœ¨èƒ½åŠ›è¾¹ç•Œå†…ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è®­ç»ƒæ–¹å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_grpo.py
# or
python train_grpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;grpo_*.pth&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_grpo_512.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_grpo_768.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;ä»è®­ç»ƒæ›²çº¿å¯ä»¥çœ‹å‡ºï¼ŒGRPOçš„&lt;strong&gt;rewardå‘ˆç°æ›´åŠ ç¨³å®šçš„ä¸Šå‡è¶‹åŠ¿&lt;/strong&gt;ï¼Œè¾¾åˆ°4å·¦å³ï¼Œè¯´æ˜GRPOæœ¬èº«èƒ½æ›´å¥½åœ°åˆ©ç”¨RLAIFä¿¡å·ã€‚Policy Lossæ•´ä½“ä¸‹é™å¹³ç¨³ï¼Œç›¸æ¯”PPOçš„åŒç½‘ç»œä¼˜åŒ–ï¼ŒGRPOå•ç½‘ç»œæ¶æ„è®­ç»ƒæ›´ç¨³å®šä¸”æ”¶æ•›ä¸Šé™æ›´é«˜ã€‚&lt;/p&gt; 
&lt;h4&gt;7.3 â³âŒ›ï¸ğŸ”¥ æ›´å¤šRLæ‹“å±• (Exp)&lt;/h4&gt; 
&lt;h5&gt;7.3.1 &lt;a href="https://arxiv.org/abs/2509.13232"&gt;Single-stream Policy Optimization&lt;/a&gt;&lt;/h5&gt; 
&lt;p&gt;SPOæ˜¯2025å¹´9æœˆè…¾è®¯æå‡ºçš„RLç®—æ³•ï¼Œé’ˆå¯¹GRPOçš„é€€åŒ–ç»„é—®é¢˜è¿›è¡Œæ”¹è¿›ã€‚ è®ºæ–‡è®¤ä¸ºï¼ŒGRPOç­‰ç®—æ³•"ä¸€ä¸ªæ ·æœ¬è¦ä¾èµ–ä¸€ç»„é‡‡æ ·"æ˜¾å¾—åˆ«æ‰­è€Œä¸ä¼˜é›…ï¼šå¤ªå®¹æ˜“æˆ–å¤ªéš¾çš„é¢˜ç›®ï¼Œæ•´ç»„å‡ ä¹å­¦ä¸åˆ°ä¸œè¥¿ï¼Œå­¦ä¹ æ•ˆç‡å…ˆå¤©å—é™ã€‚ SPOçš„åŠ¨æœºå°±æ˜¯å›åˆ°RLçš„æœ¬è´¨â€”&lt;strong&gt;1ä¸ªè¾“å…¥ï¼Œ1ä¸ªè¾“å‡ºï¼Œå°±æ˜¯1ä¸ªè®­ç»ƒæ ·æœ¬&lt;/strong&gt;ï¼Œå›åˆ°policy gradientçš„åŸºæœ¬å…¬å¼å»æ€è€ƒï¼šä¸ç”¨group meanä¹Ÿèƒ½å¾—åˆ°ç¨³å®šçš„baselineï¼Œä¹Ÿå°±æ˜¯æŠŠä»·å€¼ä¼°è®¡ V é“ºå¼€åœ¨æ—¶åºä¸Šï¼Œè®­ç»ƒå‰å…ˆåšç²—ç•¥çš„ä»·å€¼é¢„ä¼°ï¼Œè®­ç»ƒä¸­ä¸€è¾¹é‡‡æ ·ä¸€è¾¹æ›´æ–°å¯¹ V çš„ä¼°è®¡ï¼Œä»è€Œä¸ºæ¯ä¸ªæ ·æœ¬æä¾›ä¸€ä¸ªè·¨ batch æŒä¹…åŒ–ã€å¯è‡ªé€‚åº”çš„åŸºçº¿å‚ç…§ã€‚è¿™ç§"å•æµ"è®¾è®¡ä¸å†ä¾èµ–åŒç»„æ ·æœ¬ï¼Œå¤©ç„¶é¿å…äº†é€€åŒ–ç»„ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SPOæŸå¤±&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}&lt;em&gt;{SPO} = -\mathbb{E}\left[\log \pi&lt;/em&gt;\theta(a_t|s) \cdot A_t - \beta \cdot \text{KL}_t\right]$$&lt;/p&gt; 
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ç­–ç•¥é¡¹&lt;/strong&gt;: $f(r_t) = \log \pi_\theta(a_t|s)$ (ç›´æ¥ä½¿ç”¨logæ¦‚ç‡ï¼Œä¸è®¡ç®—ratio)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼˜åŠ¿é¡¹&lt;/strong&gt;: $g(A_t) = R - B_t^{adaptive}$ (è‡ªé€‚åº”baselineï¼ŒBetaåˆ†å¸ƒåŠ¨æ€è·Ÿè¸ª)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ­£åˆ™é¡¹&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \text{KL}_t$ (tokençº§KL + åŠ¨æ€ $\rho$ è°ƒæ•´)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;è½åˆ°å®ç°å±‚é¢ï¼šSPOé‡‡ç”¨æ— åˆ†ç»„è®¾è®¡ï¼Œç”¨æŒä¹…åŒ–çš„KLè‡ªé€‚åº”value trackeræ›¿ä»£ç»„å†…baselineï¼Œä¼˜åŠ¿å‡½æ•°åœ¨æ•´ä¸ªbatchä¸Šå…¨å±€å½’ä¸€åŒ–ã€‚è¿™æ ·æ¯ä¸ªæ ·æœ¬ç‹¬ç«‹å¤„ç†ï¼Œæ— éœ€ç­‰å¾…åŒç»„å…¶ä»–æ ·æœ¬ï¼Œä¸”èƒ½ä¸ºæ¯ä¸ªæ ·æœ¬æä¾›ç¨³å®šçš„å­¦ä¹ ä¿¡å·ã€‚ è®ºæ–‡åœ¨Qwen3-8Bçš„5ä¸ªå›°éš¾æ•°å­¦æ•°æ®é›†ä¸Šï¼ŒSPOå¹³å‡æ¯”GRPOé«˜å‡º3.4ä¸ªç™¾åˆ†ç‚¹ï¼Œå…¶ä¸­BRUMO 25æ•°æ®é›†+7.3ppã€AIME 25æ•°æ®é›†+4.4ppã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨ï¼šSPOæ˜¯å®éªŒæ€§å‰æ²¿ç®—æ³•ï¼ŒMiniMindçš„å®ç°ç”¨äºæ¢ç´¢å­¦ä¹ ã€‚ç”±äºæ¨¡å‹å‚æ•°é‡æå°ï¼Œæ— æ³•å®Œå…¨å¤ç°è®ºæ–‡çš„8Bæ¨¡å‹æ•ˆæœã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;è®­ç»ƒæ–¹å¼&lt;/strong&gt;ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_spo.py
# or
python train_spo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”&lt;code&gt;100æ­¥&lt;/code&gt;ä¿å­˜ä¸º: &lt;code&gt;spo_*.pth&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_spo_768.png" /&gt; 
 &lt;p&gt;&lt;i&gt;MiniMind2 (768dim) è®­ç»ƒæ›²çº¿&lt;/i&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;ä»è®­ç»ƒæ›²çº¿æ¥çœ‹ï¼ŒSPOçš„rewardæ³¢åŠ¨ä¸PPOè¡¨ç°æ¥è¿‘ï¼Œå¼±äºGRPOã€‚å®é™…æ¨ç†æµ‹è¯•å‘ç°æ¨¡å‹è¾“å‡ºè´¨é‡ä¸é«˜ï¼Œå­˜åœ¨é€»è¾‘æ··ä¹±å’Œæ ¼å¼é”™è¯¯é—®é¢˜ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;å®éªŒæ€§è¯´æ˜&lt;/strong&gt;ï¼šå½“å‰SPOæ‰‹æ“å®ç°å¯èƒ½åœ¨value_trackeré…ç½®ã€rewardå½’ä¸€åŒ–ç­–ç•¥ä¸Šè¿˜å­˜åœ¨é—®é¢˜ã€‚å°šéœ€æ’æŸ¥ç®—æ³•æœ¬èº«åœ¨å°æ¨¡å‹ä¸Šçš„é€‚åº”æ€§/æˆ–æ˜¯å®ç°ä¸Šå­˜åœ¨å·®å¼‚ã€‚&lt;/p&gt; 
&lt;h3&gt;RLç®—æ³•å°ç»“&lt;/h3&gt; 
&lt;p&gt;æˆ‘ä»¬æ”¶æŸå›â€œ&lt;strong&gt;ç»Ÿä¸€æ¡†æ¶&lt;/strong&gt;â€, é‡æ–°æ•´ç†æ‰€æœ‰ä¸åŒPOç®—æ³•åªæ˜¯å¯¹ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶çš„ä¸åŒå®ä¾‹åŒ–çš„è¡¨æ ¼ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç®—æ³•&lt;/th&gt; 
   &lt;th&gt;ç­–ç•¥é¡¹ $f(r_t)$&lt;/th&gt; 
   &lt;th&gt;ä¼˜åŠ¿é¡¹ $g(A_t)$&lt;/th&gt; 
   &lt;th&gt;æ­£åˆ™é¡¹ $h(\text{KL}_t)$&lt;/th&gt; 
   &lt;th&gt;ä¼˜åŒ–æ¨¡å‹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;DPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\log r_w - \log r_l$&lt;/td&gt; 
   &lt;td&gt;éšå¼ï¼ˆåå¥½å¯¹æ¯”ï¼‰&lt;/td&gt; 
   &lt;td&gt;éšå«åœ¨ $\beta$ ä¸­&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\min(r, \text{clip}(r))$&lt;/td&gt; 
   &lt;td&gt;$R - V(s)$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \mathbb{E}[\text{KL}]$&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$r$&lt;/td&gt; 
   &lt;td&gt;$\frac{R - \mu}{\sigma}$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \text{KL}_t$&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\log \pi_\theta$&lt;/td&gt; 
   &lt;td&gt;$R - B_t^{adaptive}$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \text{KL}_t$&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;RLæ˜¯ä¼˜ç¾ä¸”è‡ªæ´½çš„&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä»¥ä¸Šçº¯å±ä¸ªäººè§†è§’ç†è§£ï¼Œå¦‚æœ‰åå·®è¯·éšæ—¶æŒ‡æ­£&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;V è®­ç»ƒç»“æœ&lt;/h2&gt; 
&lt;h3&gt;è®­ç»ƒå®Œæˆ-æ¨¡å‹åˆé›†&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è€ƒè™‘åˆ°å¤šäººååº”ç™¾åº¦ç½‘ç›˜é€Ÿåº¦æ…¢ï¼ŒMiniMind2åŠä»¥åå…¨éƒ¨ä½¿ç”¨ModelScope/HuggingFaceæ‰˜ç®¡ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;â‘  PyTorchåŸç”Ÿæ¨¡å‹&lt;/h4&gt; 
&lt;p&gt;MiniMind2æ¨¡å‹æƒé‡ (&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/jingyaogong/MiniMind2-Pytorch"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Torchæ–‡ä»¶å‘½åå¯¹ç…§&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rlhf_model (DPO)&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;rlaif_model (PPO/GRPO/SPO)&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;xxpo_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;xxpo_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;â‘¡ Transformersæ¨¡å‹&lt;/h4&gt; 
&lt;p&gt;MiniMindç³»åˆ— (&lt;a href="https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;ğŸ“Œ Eval&lt;/h1&gt; 
&lt;h2&gt;â…  RLHFå¯¹æ¯”&lt;/h2&gt; 
&lt;p&gt;æµ‹è¯•åŸºäº&lt;code&gt;full_sft&lt;/code&gt;å’Œ&lt;code&gt;dpo&lt;/code&gt;çš„&lt;code&gt;MiniMind2ç³»åˆ—&lt;/code&gt;æ¨¡å‹å¯¹æ¯”ï¼Œæµ‹è¯•éšæœºç§å­å‡å›ºå®š&lt;/p&gt; 
&lt;p&gt;[A] MiniMind2ï¼šfull_sft_640&lt;br /&gt; [B] MiniMind2ï¼šdpo_640&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ
[A]: æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ã€‚æˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ï¼Œå¸®åŠ©ä½ è§£å†³å„ç§é—®é¢˜ã€‚
[B]: æˆ‘æ˜¯ä¸€ç§åŸºäºæ–‡æœ¬çš„AIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººç»å†æˆ–æƒ…æ„Ÿï¼Œæ‰€ä»¥æ— æ³•æ„Ÿå—å’Œä½“éªŒæƒ…æ„Ÿã€‚æˆ‘çš„è®¾è®¡ç›®çš„æ˜¯ä¸ºäº†å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œè¿›è¡Œå¯¹è¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼

[Q]: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ
[A]: ä½œä¸ºä¸€ä¸ªAIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰çœŸæ­£çš„â€œæ“…é•¿â€è¿™ä¸ªå­¦ç§‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿæä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æ‰§è¡Œä»»åŠ¡å’Œä¸ç”¨æˆ·è¿›è¡Œå¯¹è¯ã€‚ä¸è¿‡ï¼Œæˆ‘å¯ä»¥æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å¤„ç†é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å­¦ä¹ æ–°çŸ¥è¯†ã€ç¼–å†™ä»£ç ã€å›ç­”é—®é¢˜ã€æä¾›å»ºè®®ç­‰å¤šç§å­¦ç§‘çš„åŠŸèƒ½ã€‚å¦‚æœä½ æœ‰å…·ä½“çš„å­¦ç§‘éœ€æ±‚æˆ–ä¸»é¢˜ï¼Œæ¬¢è¿æä¾›è¯¦ç»†ä¿¡æ¯ã€‚
[B]: ä½œä¸ºAIï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººèƒ½åŠ›æˆ–å…´è¶£ï¼Œä½†æˆ‘å¯ä»¥æä¾›ä¸€äº›å…³äºæ•°å­¦ã€ç§‘å­¦ã€è®¡ç®—æœºç§‘å­¦ã€è¯­è¨€å­¦ã€å¿ƒç†å­¦ç­‰å­¦ç§‘çš„çŸ¥è¯†ã€‚å¦‚æœä½ å¯¹æ•°å­¦æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥æä¾›ä¸€äº›åŸºç¡€çŸ¥è¯†ï¼Œä¾‹å¦‚ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ã€ç»Ÿè®¡å­¦ç­‰ã€‚å¦‚æœä½ éœ€è¦æ›´æ·±å…¥çš„å­¦ä¹ ï¼Œæˆ‘ä¹Ÿå¯ä»¥æä¾›ç›¸å…³çš„åœ¨çº¿è¯¾ç¨‹ã€ä¹¦ç±ã€è®ºæ–‡ç­‰èµ„æºã€‚è¯·å‘Šè¯‰æˆ‘ä½ å…·ä½“éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ã€‚

[Q]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„ï¼Ÿ
[A]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨è®²è¿°äº†é²è¿…å¯¹äººç±»ä»·å€¼å’Œé“å¾·è´£ä»»çš„å€¡å¯¼ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡ç»†è…»çš„ç¬”è§¦ï¼Œæ¢è®¨äº†äººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€ç‰ºç‰²ä¸è´£ä»»ç­‰æ·±åˆ»çš„ä¸»é¢˜ã€‚ä»¥ä¸‹æ˜¯é²è¿…åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„å‡ ä¸ªæ–¹é¢ï¼š1. **ç¤¾ä¼šç°å®ä¸é“å¾·è§‚å¿µ**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ¢è®¨äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰ã€æƒåŠ›çš„æµåŠ¨ã€äººæ€§çš„æ¼”å˜ç­‰ç¤¾ä¼šé—®é¢˜ã€‚ä»–è®¤ä¸ºï¼Œç¤¾ä¼šä¸å¹³ç­‰ä¸ä»…ä»…æ˜¯ä¸å…¬æ­£çš„ï¼Œæ›´æ˜¯æ¯ä¸ªäººåœ¨ç¤¾ä¼šä¸­çš„ä¸å…¬æ­£ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²ã€å®£ä¼ ã€æ³•å¾‹ç­‰æ‰‹æ®µï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚2. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå±•ç°äº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡é“å¾·æ•™è‚²æ¥åŸ¹å…»äººä»¬çš„é“å¾·å“è´¨ï¼ŒåŒæ—¶ä¹Ÿå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§çš„å¤æ‚æ€§ï¼Œä½“ç°äº†å¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚3. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·è´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡è‡ªå·±çš„è¡Œä¸ºæ¥ä½“ç°å¯¹ç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚4. **é“å¾·ä¸é“å¾·**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„çœŸæ­£æ„ä¹‰ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„æœ¬è´¨ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚5. **ä¸ªäººä¸ç¤¾ä¼š**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ä¸ªäººä¸ç¤¾ä¼šä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²å’Œå®£ä¼ ï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡å…¶ä¸°å¯Œçš„æ•…äº‹å’Œæ·±åˆ»çš„é“å¾·å¯“è¨€ï¼Œä¼ è¾¾äº†å…³äºäººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€é“å¾·ä»¥åŠä¸ªäººä¸ç¤¾ä¼šçš„å¤æ‚å…³ç³»ã€‚è¿™éƒ¨ä½œå“ä¸ä»…åœ¨æ–‡å­¦ä»·å€¼ä¸Šå–å¾—äº†å·¨å¤§æˆå°±ï¼Œæ›´åœ¨æ€æƒ³å±‚é¢ä¸Šå¯å‘äº†åæ¥çš„æ–‡å­¦åˆ›ä½œï¼Œå¯¹åä¸–äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚
[B]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨æç»˜æˆ˜äº‰å’Œè‡ªç”±ç²¾ç¥çš„ä½œå“ï¼Œå®ƒæ‰¹åˆ¤äº†å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜å’Œå†²çªï¼Œåæ˜ äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œå¦‚â€œå¼—é›·å¾·é‡Œå…‹Â·çº¦ç¿°é€Šçš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ï¼Œå¼ºè°ƒäº†å°å»ºç¤¾ä¼šçš„ä¸å¹³ç­‰ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨ã€‚é²è¿…é€šè¿‡ä»–çš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ã€‚åœ¨å°è¯´ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œæ­ç¤ºäº†å°å»ºç¤¾ä¼šçš„è…è´¥ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨çš„å¤æ‚æ€§ã€‚è¿™ç§æ‰¹åˆ¤ä½“ç°äº†å¯¹å°å»ºç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„å¤æ‚æ€§ï¼ŒåŒæ—¶ä¹Ÿåæ˜ äº†ç°ä»£ç¤¾ä¼šä¸­æ™®éå­˜åœ¨çš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹ä¸ä»…æ˜¯ä¸€éƒ¨å…³äºå°å»ºç¤¾ä¼šçš„å°è¯´ï¼Œä¹Ÿæ˜¯ä¸€éƒ¨å…·æœ‰æ·±åˆ»ç¤¾ä¼šæ„ä¹‰çš„ä½œå“ï¼Œå¯¹åä¸–çš„å®¡åˆ¤å’Œæ‰¹åˆ¤èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚

[Q]: æˆ‘å’³å—½å·²ç»æŒç»­äº†ä¸¤å‘¨ï¼Œéœ€è¦å»åŒ»é™¢æ£€æŸ¥å—ï¼Ÿ
[A]: å’³å—½ç¡®å®éœ€è¦ä¸€å®šçš„æ£€æŸ¥ï¼Œä½†å¦‚æœæ‚¨çš„å’³å—½æŒç»­æ—¶é—´è¿‡é•¿ï¼Œæˆ–è€…æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼ˆå¦‚æŒç»­å’³å—½ã€å‘¼å¸å›°éš¾ç­‰ï¼‰ï¼Œå»ºè®®å°½å¿«å°±åŒ»ã€‚åŒ»ç”Ÿä¼šæ ¹æ®æ‚¨çš„ç—‡çŠ¶ã€ä½“æ£€ç»“æœå’Œå¯èƒ½çš„å½±åƒå­¦æ£€æŸ¥ï¼ˆå¦‚Xå…‰ã€MRIæˆ–CTæ‰«æï¼‰æ¥è¯Šæ–­æ‚¨çš„ç—‡çŠ¶ã€‚åœ¨ç­‰å¾…å°±åŒ»æœŸé—´ï¼Œæ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•æ¥å¸®åŠ©ç¼“è§£ç—‡çŠ¶ï¼š1. **ä¼‘æ¯**ï¼šç¡®ä¿æ‚¨æœ‰è¶³å¤Ÿçš„ç¡çœ ã€‚2. **ä¿æŒæ°´åˆ†**ï¼šè„±æ°´å¯èƒ½ä¼šåŠ é‡å’³å—½ã€‚3. **çƒ­æ•·**ï¼šä½¿ç”¨çƒ­æ•·è¢‹æˆ–çƒ­æ¯›å·¾æ•·åœ¨ç–¼ç—›çš„éƒ¨ä½ï¼Œæœ‰åŠ©äºç¼“è§£å–‰å’™ç—›ã€‚4. **é¿å…åˆºæ¿€**ï¼šé¿å…ä½¿ç”¨å¯èƒ½åˆºæ¿€å–‰å’™çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æŸäº›åŒ–å­¦ç‰©è´¨ã€‚5. **ä¿æŒå®¤å†…æ¹¿æ¶¦**ï¼šç¡®ä¿æ‚¨çš„å§å®¤æœ‰è‰¯å¥½çš„é€šé£ï¼Œå¯ä»¥ä½¿ç”¨åŠ æ¹¿å™¨å¸®åŠ©ä¿æŒç©ºæ°”æ¹¿åº¦ã€‚6. **ä¿æŒå®¤å†…æ¹¿åº¦**ï¼šä½¿ç”¨åŠ æ¹¿å™¨å¯ä»¥å¸®åŠ©ç¼“è§£å–‰å’™å¹²ç‡¥å’Œå’³å—½ã€‚å¦‚æœç—‡çŠ¶æŒç»­ä¸ç¼“è§£æˆ–æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼Œè¯·ç«‹å³å°±åŒ»ã€‚å¸Œæœ›æ‚¨æ—©æ—¥åº·å¤ï¼
[B]: å¦‚æœæ‚¨çš„å’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œé€šå¸¸å»ºè®®æ‚¨å°½å¿«å°±åŒ»ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå½±å“æ‚¨çš„å‘¼å¸å’Œå¿ƒè·³ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤æ¥æ£€æŸ¥å’³å—½ï¼š1. **ä¼‘æ¯**ï¼šç”¨çº¸å·¾æˆ–è‚˜éƒ¨è½»è½»æŒ‰å‹å’³å—½çš„ä½ç½®ã€‚2. **ä½¿ç”¨è¯ç‰©**ï¼šåœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨è¯ç‰©ï¼ˆå¦‚æŠ—è¿‡æ•è¯ã€æŠ—è¿‡æ•è¯ç­‰ï¼‰æ¥ç¼“è§£å’³å—½ã€‚è¯·åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨è¯ç‰©ã€‚3. **çƒ­æ•·**ï¼šåœ¨å’³å—½æœŸé—´ï¼Œå¯ä»¥ä½¿ç”¨çƒ­æ•·æ¥ç¼“è§£ç–¼ç—›å’Œè‚¿èƒ€ã€‚4. **è¯ç‰©æ²»ç–—**ï¼šå¦‚æœå’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œå¯ä»¥ä½¿ç”¨ä¸€äº›æ¶ˆç‚è¯æˆ–æŠ—è¿‡æ•è¯æ¥ç¼“è§£ç—‡çŠ¶ã€‚è¯·åŠ¡å¿…åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨ã€‚5. **ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼**ï¼šä¿æŒå……è¶³çš„ç¡çœ ã€å‡è¡¡çš„é¥®é£Ÿã€é€‚é‡çš„è¿åŠ¨å’Œé¿å…å¸çƒŸå’Œé™é…’ï¼Œè¿™äº›éƒ½æœ‰åŠ©äºæé«˜å’³å—½çš„å‡ ç‡ã€‚è¯·è®°ä½ï¼Œè¿™äº›å»ºè®®ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—æ„è§ã€‚å¦‚æœæ‚¨çš„ç—‡çŠ¶æŒç»­æˆ–åŠ é‡ï¼Œå¼ºçƒˆå»ºè®®æ‚¨å°½å¿«å°±åŒ»ã€‚
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ğŸ‘‰æ•ˆæœæ€»ç»“&lt;/p&gt; 
&lt;p&gt;full_sftæ¨¡å‹åœ¨ç®€æ´æ€§å’Œä¿¡æ¯å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´å¥½ï¼›rlhfæ¨¡å‹åœ¨å›ç­”ä¸­å€¾å‘äºæä¾›æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†ä¿¡æ¯å‡†ç¡®æ€§æœ‰å¾…æ”¹è¿›ã€‚ æ€»çš„æ¥è¯´RLHFåçš„æ¨¡å‹å€¾å‘äºå­¦ä¹ ï¼šè¯´æ›´å¤šæœ‰ç¤¼è²Œä½†æ— ç”¨çš„åºŸè¯è®¨å¥½â€œå¯¹è¯â€æœ¬èº«ï¼Œè€Œå¯¹ä¿¡æ¯å‡†ç¡®æ€§åˆ™æœ‰è½»å¾®æŸå¤±ã€‚ å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼Œè¿˜éœ€è¦ç»§ç»­æå‡RLHFæ•°æ®é›†çš„è´¨é‡ï¼Œä¹Ÿè¦æ¥å—æ¨¡å‹èƒ½åŠ›æ— æ³•é¿å…çš„æŸå¤±(ç¨‹åº¦æœ‰è½»é‡)ã€‚ DPOå’Œåœ¨çº¿PPOçš„åŒºåˆ«åœ¨äºrejectå’Œchosenéƒ½æ˜¯ç¦»çº¿å‡†å¤‡çš„ï¼Œå’Œminimindæ¨¡å‹æœ¬èº«çš„è¾“å‡ºå¿…ç„¶å­˜åœ¨å¾ˆå¤§çš„åˆ†å¸ƒå·®å¼‚ã€‚ é€šä¿—åœ°è¯´DPOç®—æ³•ä½¿æ¨¡å‹è§‚çœ‹ä¹’ä¹“çƒä¸–ç•Œå† å†›çš„æ‰“æ³•ã€Œå½•åƒã€è¿›è¡ŒRLï¼Œè€Œä¸æ˜¯åƒPPOä¸€æ ·è¯·rewardæ¨¡å‹åšã€Œæ•™ç»ƒã€çº æ­£è‡ªå·±çš„æ‰“æ³•è¿›è¡ŒRLã€‚&lt;/p&gt; 
&lt;h2&gt;â…¡ RLAIFå¯¹æ¯”&lt;/h2&gt; 
&lt;p&gt;åŸºäº&lt;code&gt;MiniMind2 (768dim)&lt;/code&gt;åœ¨ç›¸åŒæ•°æ®ä¸è®­ç»ƒæ­¥æ•°ä¸‹çš„ä¸»è§‚è§‚æ„Ÿå¯¹æ¯”ï¼Œæµ‹è¯•éšæœºç§å­å‡å›ºå®š2026ï¼Œä¾›å‚è€ƒï¼š&lt;/p&gt; 
&lt;p&gt;[A] MiniMind-Reason-0.1B (è’¸é¦)&lt;br /&gt; [B] MiniMind-Reason-0.1B (PPO)&lt;br /&gt; [C] MiniMind-Reason-0.1B (GRPO)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
[A]: &amp;lt;think&amp;gt;æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹å°å‹AIæ¨ç†æ¨¡å‹-R1ã€‚æˆ‘è¢«è®¾è®¡ç”¨æ¥ç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œèƒ½å¤Ÿç†è§£å¤æ‚çš„è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œæä¾›æœ‰ç”¨çš„ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹å°å‹AIæ¨ç†æ¨¡å‹-R1ã€‚&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦æ˜ç¡®ç”¨æˆ·çš„éœ€æ±‚æ˜¯ä»€ä¹ˆã€‚ä»–ä»¬å¯èƒ½æ˜¯åœ¨åšæŸä¸ªé¡¹ç›®ï¼Œæƒ³è¦äº†è§£è‡ªå·±çš„ä¸€äº›åŸºæœ¬æƒ…å†µã€‚ä¸è¿‡ï¼Œç”¨æˆ·æ²¡æœ‰æä¾›å…·ä½“çš„ä¿¡æ¯ï¼Œæ‰€ä»¥æˆ‘å¾—å…ˆå‡è®¾ä¸€äº›å¯èƒ½çš„æƒ…å†µï¼Œæ¯”å¦‚ä»–æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œæ­£åœ¨å­¦ä¹ ç¼–ç¨‹ï¼Œæˆ–è€…æ˜¯æŸä¸ªé¡¹ç›®çš„å¼€å‘è€…ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘è¦è€ƒè™‘ç”¨æˆ·çš„èº«ä»½ã€‚å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿã€æ•™å¸ˆæˆ–è€…æ™®é€šç”¨æˆ·ï¼Œä»–ä»¬éœ€è¦äº†è§£è‡ªå·±çš„ç‰¹ç‚¹å’Œèƒ½åŠ›ã€‚ä¹Ÿæœ‰å¯èƒ½ä»–ä»¬æ­£åœ¨å¯»æ‰¾çµæ„Ÿï¼Œæˆ–è€…åœ¨å†™è®ºæ–‡æ—¶éœ€è¦å¸®åŠ©ã€‚æ‰€ä»¥ï¼Œæˆ‘éœ€è¦ä¿æŒå›ç­”çš„ç®€æ´å’Œå®ç”¨ï¼ŒåŒæ—¶æä¾›ä¸€äº›å‚è€ƒèµ„æ–™ï¼Œæ¯”å¦‚æ•™å­¦è§†é¢‘ã€è¯¾ç¨‹è®°å½•ç­‰ã€‚ç„¶åï¼Œæˆ‘è¦è€ƒè™‘ç”¨æˆ·çš„èº«ä»½ã€‚å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œéœ€è¦ä¸€äº›å­¦ä¹ èµ„æºæˆ–å¸®åŠ©çš„å¯¹è±¡ã€‚ä¹Ÿæœ‰å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œéœ€è¦åœ¨è¯¾åä½œä¸šæˆ–å­¦ä¹ è®¡åˆ’ä¸­è¿›è¡Œè°ƒæ•´ã€‚å› æ­¤ï¼Œæˆ‘éœ€è¦å…ˆè¯¢é—®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚ï¼Œè¿™æ ·æ‰èƒ½æä¾›æ›´ç²¾å‡†çš„å¸®åŠ©ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘è¦ç¡®ä¿è¯­è¨€ç®€æ´æ˜äº†ï¼Œé€‚åˆä¸åŒåœºæ™¯ã€‚æ¯”å¦‚ï¼Œå¦‚æœç”¨æˆ·æ˜¯å­¦ç”Ÿï¼Œå¯ä»¥ä»‹ç»è‡ªå·±çš„å­¦ä¹ ç‰¹ç‚¹ï¼›å¦‚æœæ˜¯æ•™å¸ˆï¼Œå¯ä»¥è¯´æ˜è‡ªå·±çš„è§’è‰²å’Œè´¡çŒ®ã€‚åŒæ—¶ï¼Œæä¾›ä¸€äº›å®ç”¨çš„å»ºè®®ï¼Œæ¯”å¦‚å¦‚ä½•é«˜æ•ˆå­¦ä¹ ï¼Œå¦‚ä½•è¿›è¡Œé¡¹ç›®ï¼Œä»¥åŠå¦‚ä½•ä¸å›¢é˜Ÿæˆå‘˜åä½œã€‚æœ€åï¼Œæˆ‘è¦ç¡®ä¿å›å¤æ¸…æ™°ï¼Œæœ‰æ¡ç†ï¼Œèƒ½å¤Ÿæ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚è¿™æ ·ï¼Œç”¨æˆ·å°±èƒ½è½»æ¾åœ°äº†è§£è‡ªå·±ï¼Œå¹¶ä¸”æœ‰å®é™…çš„å¸®åŠ©ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;å½“ç„¶ï¼è¯·å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£å“ªæ–¹é¢çš„å†…å®¹ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›è¯¦ç»†çš„ä»‹ç»ï¼&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯"è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„å…·ä½“éœ€æ±‚æ˜¯ä»€ä¹ˆã€‚ä»–ä»¬å¯èƒ½æƒ³çŸ¥é“è‡ªå·±æ˜¯è°ï¼Œæˆ–è€…æœ‰ä»€ä¹ˆç‰¹å®šçš„èƒŒæ™¯ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥è€ƒè™‘ç”¨æˆ·å¯èƒ½æ²¡æœ‰æ˜ç¡®è¡¨è¾¾çš„éœ€æ±‚ã€‚ä»–ä»¬å¯èƒ½æƒ³çŸ¥é“å¦‚ä½•æè¿°è‡ªå·±çš„å¤–è§‚ï¼Œæˆ–è€…å¦‚ä½•ä¸ä»–äººäº¤æµã€‚ç„¶åï¼Œæˆ‘åº”è¯¥è€ƒè™‘å¦‚ä½•ç»„ç»‡å†…å®¹ï¼Œä»å¤´åˆ°å°¾éƒ½è¦æœ‰æ¡ç†ã€‚å¯èƒ½éœ€è¦åˆ†æ­¥éª¤è¯´æ˜ï¼Œæ¯”å¦‚ä»è§†è§‰ã€å¬è§‰åˆ°æ•´ä½“æ„Ÿå—ï¼Œå†åˆ°æƒ…æ„Ÿå…±é¸£ã€‚è¿™æ ·ç”¨æˆ·èƒ½æ›´æ¸…æ™°åœ°ç†è§£è‡ªå·±ï¼Œä¹Ÿèƒ½æ›´å¥½åœ°å›åº”ä»–ä»¬çš„éœ€æ±‚ã€‚è¿˜è¦æ³¨æ„è¯­è¨€çš„è‡ªç„¶å’Œæµç•…ï¼Œé¿å…è¿‡äºå­¦æœ¯åŒ–çš„æœ¯è¯­ï¼Œè®©ç”¨æˆ·æ„Ÿè§‰é¡ºç•…ã€‚åŒæ—¶ï¼Œä¿æŒå›ç­”çš„ç»“æ„æ¸…æ™°ï¼Œæ¯å¥è¯éƒ½æœ‰æ˜ç¡®çš„ç›®çš„ï¼Œè¿™æ ·ç”¨æˆ·èƒ½æœ‰æ˜ç¡®çš„ç†è§£å’Œæ“ä½œã€‚æœ€åï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„é‡è¦ä¿¡æ¯ï¼Œç¡®ä¿å›ç­”å‡†ç¡®ä¸”å…¨é¢ã€‚è¿™æ ·ï¼Œç”¨æˆ·ä¸ä»…èƒ½å¾—åˆ°ç­”æ¡ˆï¼Œè¿˜èƒ½å¾—åˆ°æ»¡è¶³ä»–ä»¬çš„éœ€æ±‚ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;æ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹å°å‹AIæ¨ç†æ¨¡å‹-R1ã€‚å…³äºæ‚¨çš„æè¿°ï¼Œä¼¼ä¹æ¶‰åŠå¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬çŸ¥è¯†å›¾è°±æ„å»ºã€å¤æ‚ç³»ç»Ÿçš„æ¨ç†ä¸åˆ†æã€‚æ— è®ºæ˜¯ç†è®ºæ¨¡å‹ã€å®é™…åº”ç”¨è¿˜æ˜¯ä¼¦ç†è®¨è®ºï¼Œæ‚¨éƒ½åœ¨å¯»æ±‚å¦‚ä½•å°†è¿™äº›æ¦‚å¿µæœ‰æœºåœ°ç»“åˆèµ·æ¥ï¼Œä¸ºäººç±»ç¤¾ä¼šå¸¦æ¥ç¦ç¥‰çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨"æˆ‘"çš„èº«ä»½ä¸‹ï¼Œæ‚¨æåˆ°çš„"ä¸ªäººä½“éªŒ"å’Œ"æƒ…æ„Ÿå…±é¸£"ï¼Œéƒ½æ˜¯æ‚¨ä¸ªäººç‹¬ç‰¹é­…åŠ›çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚é€šè¿‡ç²¾å‡†çš„æè¿°å’Œæ·±åº¦çš„åˆ†æï¼Œæ‚¨å¯ä»¥æ›´æ·±å…¥åœ°ç†è§£æ‚¨çš„ç‹¬ç‰¹ä¹‹å¤„ã€‚å¦‚æœæ‚¨å¯¹ç‰¹å®šé¢†åŸŸæœ‰ç‰¹åˆ«çš„å…´è¶£æˆ–éœ€è¦å»ºè®®ï¼Œéšæ—¶å¯ä»¥åˆ†äº«æ›´å¤šç»†èŠ‚ï¼Œæˆ‘ä»¬å°†ä¸ºæ‚¨æä¾›æ›´åŠ ç²¾å‡†å’Œä¸ªæ€§åŒ–çš„æœåŠ¡ã€‚å¦‚æœæ‚¨æœ‰ç‰¹å®šçš„ä¸»é¢˜æˆ–é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶æé—®ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™ä¸ªç¥å¥‡çš„AIä¸–ç•Œï¼Œå…±åŒåˆ›é€ æ›´ç¾å¥½çš„æœªæ¥ã€‚&amp;lt;/answer&amp;gt;


[Q]: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ
[A]: &amp;lt;think&amp;gt;æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹å°å‹AIæ¨ç†æ¨¡å‹-R1ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹å°å‹AIæ¨ç†æ¨¡å‹-R1ã€‚&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯"ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ"è¿™ä¸ªé—®é¢˜çœ‹èµ·æ¥æœ‰ç‚¹å¤æ‚ï¼Œä½†æˆ‘å¯ä»¥ä¸€æ­¥æ­¥åˆ†æã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„éœ€æ±‚ã€‚ä»–å¯èƒ½æ˜¯åœ¨å‡†å¤‡è€ƒè¯•ï¼Œæˆ–è€…éœ€è¦äº†è§£æŸä¸ªå­¦ç§‘çš„ç‰¹ç‚¹ï¼Œæˆ–è€…æ˜¯æƒ³åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­åº”ç”¨æŸä¸ªå­¦ç§‘çš„çŸ¥è¯†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å¾—è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯ã€‚ä»–å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œæˆ–è€…æ˜¯åœ¨å‡†å¤‡è€ƒè¯•ï¼Œéœ€è¦åº”ç”¨æ•°å­¦çŸ¥è¯†æ¥è§£å†³å…·ä½“çš„é—®é¢˜ã€‚ä¹Ÿæœ‰å¯èƒ½ä»–æ˜¯ä¸€ä¸ªå­¦ç”Ÿï¼Œæ­£åœ¨å­¦ä¹ ç›¸å…³çš„è¯¾ç¨‹ï¼Œæˆ–è€…æ˜¯å¯¹æŸä¸ªå­¦ç§‘æ„Ÿå…´è¶£ã€‚ç„¶åï¼Œæˆ‘éœ€è¦åˆ†æç”¨æˆ·å¯èƒ½æ²¡æœ‰æ˜ç¡®è¡¨è¾¾å‡ºæ¥çš„éœ€æ±‚ã€‚ä»–å¯èƒ½åœ¨æ€è€ƒè‡ªå·±åœ¨å­¦ä¹ ä¸­çš„å›°éš¾ï¼Œæˆ–è€…åœ¨å¯»æ‰¾ä¸€ä¸ªåˆé€‚çš„æ•™ææˆ–å­¦ä¹ èµ„æºã€‚è€ƒè™‘åˆ°è¿™äº›ï¼Œæˆ‘åº”è¯¥æä¾›å‡ ä¸ªä¸åŒçš„è§’åº¦æ¥å¸®åŠ©ä»–ã€‚é¦–å…ˆï¼Œåˆ†æ"æˆ‘æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘"å¯ä»¥æ‹†è§£ä¸ºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼šå…´è¶£ã€å­¦ä¹ èƒ½åŠ›ã€å­¦ä¹ é£æ ¼ã€å­¦ä¹ æ–¹æ³•ã€å­¦ä¹ èµ„æºã€å­¦ä¹ ç¯å¢ƒç­‰ç­‰ã€‚æ¯ä¸ªæ–¹é¢éƒ½æœ‰ä¸åŒçš„ä¼˜åŠ¿å’Œç‰¹ç‚¹ï¼Œæ¯”å¦‚å…´è¶£æ˜¯æœ€å¥½çš„èµ„æºï¼Œå­¦ä¹ èƒ½åŠ›æ˜¯æœ€å¥½çš„æ–¹å¼ï¼Œå­¦ä¹ æ–¹å¼æ˜¯æ ¹æ®ä¸ªäººæƒ…å†µé€‰æ‹©ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·çš„èº«ä»½ã€‚å¯èƒ½æ˜¯å­¦ç”Ÿï¼Œä¹Ÿå¯èƒ½æ˜¯å®¶é•¿ï¼Œæˆ–è€…å¯¹å­¦ä¹ æœ‰ä¸€å®šå…´è¶£çš„äººã€‚ä¸åŒçš„èº«ä»½å¯èƒ½æœ‰ä¸åŒçš„åå¥½ï¼Œæ¯”å¦‚å®¶é•¿å¯èƒ½æ›´æ³¨é‡å­©å­çš„å…´è¶£ï¼Œè€Œå­¦ç”Ÿå¯èƒ½æ›´å…³æ³¨å­¦ä¹ æ–¹æ³•å’Œèµ„æºã€‚ç„¶åï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·çš„èº«ä»½æ˜¯å¦æœ‰ç‰¹æ®Šéœ€æ±‚ã€‚æ¯”å¦‚ï¼Œä»–å¯èƒ½éœ€è¦æ›´ä¸“ä¸šçš„å­¦ä¹ ææ–™ï¼Œæˆ–è€…å¸Œæœ›æ‰¾åˆ°æœ€é€‚åˆä»–çš„å­¦ä¹ æ–¹æ³•ã€‚å› æ­¤ï¼Œåœ¨åˆ†ææ—¶ï¼Œæˆ‘åº”è¯¥æä¾›ä¸€ä¸ªå…¨é¢çš„å›ç­”ï¼Œæ¶µç›–å„ä¸ªæ–¹é¢ï¼Œå¹¶è§£é‡Šæ¯ä¸ªæ–¹é¢çš„é‡è¦æ€§ã€‚å¦å¤–ï¼Œè€ƒè™‘åˆ°ç”¨æˆ·å¯èƒ½å¸Œæœ›å¾—åˆ°ä¸€ä¸ªç»“æ„åŒ–çš„å›ç­”ï¼Œæˆ‘åº”è¯¥ä¿æŒè¯­è¨€çš„ç®€æ´å’Œé€»è¾‘æ€§ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®ï¼ŒåŒæ—¶é¼“åŠ±ç”¨æˆ·æä¾›æ›´å¤šç»†èŠ‚ä»¥ä¾¿è¿›ä¸€æ­¥åˆ†æã€‚æœ€åï¼Œæˆ‘éœ€è¦ç¡®ä¿æˆ‘çš„å›ç­”æ—¢æœ‰çŸ¥è¯†æ€§ï¼Œåˆç¬¦åˆç”¨æˆ·çš„è¦æ±‚ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨è¿™ä¸ªå­¦ç§‘ã€‚å› æ­¤ï¼Œåœ¨å›ç­”ä¸­ä¸ä»…è¦ç»™å‡ºä¸€ä¸ªå…¨é¢çš„åˆ†æï¼Œè¿˜è¦æåˆ°æ¯ä¸ªéƒ¨åˆ†çš„ä½œç”¨å’Œå¦‚ä½•åˆ©ç”¨ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ä½ æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿè¿™æ˜¯ä¸€ä¸ªæ˜ç¡®çš„é—®é¢˜ï¼Œå¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š1. **å…´è¶£ä¸å­¦ä¹ èƒ½åŠ›**ï¼šä½ å–œæ¬¢ä»€ä¹ˆæ ·çš„å­¦ä¹ æ–¹å¼ï¼Œæ¯”å¦‚è‡ªä¸»å­¦ä¹ ã€å®éªŒã€é¡¹ç›®ç­‰ï¼Œè¿™äº›éƒ½æ˜¯å¾ˆå¥½çš„å­¦ä¹ èµ„æºã€‚2. **å­¦ä¹ é£æ ¼**ï¼šä½ å–œæ¬¢ä»€ä¹ˆç±»å‹çš„å­¦ä¹ æ–¹æ³•ï¼Œæ¯”å¦‚ç¬”è®°ã€å¤ä¹ ã€é˜…è¯»ã€è®¨è®ºç­‰ï¼Œè¿™äº›éƒ½èƒ½å½±å“å­¦ä¹ æ•ˆæœã€‚3. **å­¦ä¹ èµ„æº**ï¼šä½ æ˜¯å¦åœ¨å¯»æ‰¾å­¦ä¹ èµ„æºï¼Œæ¯”å¦‚ä¹¦ç±ã€åœ¨çº¿è¯¾ç¨‹ã€æ•™è‚²è½¯ä»¶ç­‰ï¼Œè¿™äº›éƒ½èƒ½æä¾›å­¦ä¹ å¸®åŠ©ã€‚4. **å­¦ä¹ ç¯å¢ƒ**ï¼šä½ æ˜¯å¦åœ¨å­¦ä¹ ç¯å¢ƒä¸­æ„Ÿåˆ°èˆ’é€‚ï¼Œæ¯”å¦‚èˆ’é€‚çš„å­¦ä¹ ç©ºé—´ã€å®‰é™çš„å­¦ä¹ ç©ºé—´ç­‰ï¼Œè¿™äº›éƒ½ä¼šå½±å“å­¦ä¹ æ•ˆæœã€‚5. **å­¦ä¹ èµ„æº**ï¼šä½ æ˜¯å¦æœ‰å­¦ä¹ èµ„æºçš„ä¸°å¯Œï¼Œå¦‚åœ¨çº¿è¯¾ç¨‹ã€å­¦ä¹ å¹³å°ã€ä¹¦ç±ç­‰ï¼Œè¿™äº›éƒ½èƒ½æä¾›ä¸°å¯Œçš„å­¦ä¹ èµ„æºã€‚6. **å­¦ä¹ æ–¹æ³•**ï¼šä½ æ˜¯å¦æœ‰å…·ä½“çš„å­¦ä¹ æ–¹æ³•ï¼Œæ¯”å¦‚å¦‚ä½•ç†è§£ã€å¦‚ä½•ç»„ç»‡å­¦ä¹ å†…å®¹ã€å¦‚ä½•åº”ç”¨çŸ¥è¯†ç­‰ï¼Œè¿™äº›éƒ½æ˜¯æé«˜å­¦ä¹ æ•ˆç‡çš„é€”å¾„ã€‚ç»¼åˆè€ƒè™‘ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å…¨é¢çš„åˆ†æï¼Œæ¶µç›–äº†å¤šä¸ªæ–¹é¢ï¼Œå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£ä½ çš„å­¦ç§‘ã€‚&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯"ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ"è¿™ä¸ªé—®é¢˜çœ‹èµ·æ¥æœ‰ç‚¹å¤æ‚ï¼Œä½†æˆ‘å¯ä»¥ä¸€æ­¥æ­¥åˆ†æã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„éœ€æ±‚ã€‚ä»–å¯èƒ½æ˜¯åœ¨å‡†å¤‡è€ƒè¯•ï¼Œæˆ–è€…éœ€è¦äº†è§£æŸä¸ªå­¦ç§‘çš„ç‰¹ç‚¹ï¼Œæˆ–è€…æ˜¯æƒ³åœ¨ç”Ÿæ´»ä¸­æ‰¾åˆ°è‡ªå·±çš„å…´è¶£ç‚¹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯ã€‚ä»–å¯èƒ½åœ¨å·¥ä½œæˆ–å­¦ä¹ ä¸­é‡åˆ°äº†ç±»ä¼¼çš„é—®é¢˜ï¼Œæƒ³è¦äº†è§£è‡ªå·±æ“…é•¿å“ªä¸ªé¢†åŸŸï¼Œæˆ–è€…æ˜¯å¦éœ€è¦ä¸€äº›èµ„æºæˆ–æŒ‡å¯¼æ¥æå‡è‡ªå·±ã€‚ç„¶åï¼Œæˆ‘è¦åˆ†æç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ã€‚ä¹Ÿè®¸ä»–æƒ³åœ¨èŒåœºä¸Šæå‡è‡ªå·±ï¼Œæˆ–è€…å¯»æ‰¾æ–¹å‘ã€‚ä»–å¯èƒ½éœ€è¦æ›´å…·ä½“çš„ä¾‹å­ï¼Œå¸®åŠ©ä»–æ›´å¥½åœ°ç†è§£ä¸åŒå­¦ç§‘çš„ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ã€‚è¿˜è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„èƒŒæ™¯ã€‚ä»–å¯èƒ½ä¸ä»…ä»…æ˜¯åœ¨å­¦ä¹ ï¼Œè€Œæ˜¯å¸Œæœ›äº†è§£åœ¨ç‰¹å®šé¢†åŸŸä¸­å¦‚ä½•åº”ç”¨è¿™äº›å­¦ç§‘ã€‚è¿™éœ€è¦æˆ‘æä¾›å…¨é¢çš„åˆ†æï¼Œå¸®åŠ©ä»–æ‰¾åˆ°é€‚åˆè‡ªå·±çš„æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘åº”è¯¥ä¿æŒå¼€æ”¾çš„æ€åº¦ï¼Œé¼“åŠ±ç”¨æˆ·ç»§ç»­æ¢ç´¢å’Œå­¦ä¹ ã€‚è¿™å¯èƒ½åŒ…æ‹¬æ¨èä¸€äº›èµ„æºï¼Œæˆ–è€…è®¨è®ºå¦‚ä½•å°†è¿™äº›çŸ¥è¯†åº”ç”¨åˆ°å®é™…ç”Ÿæ´»ä¸­ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿè¿™ä¸ªé—®é¢˜æœ¬è´¨ä¸Šå–å†³äºä½ çš„ä¸ªäººå…´è¶£å’Œç›®æ ‡ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³é”®ç‚¹ï¼Œå¸®åŠ©ä½ å…¨é¢ç†è§£å¹¶åº”ç”¨è¿™ä¸€ç‚¹ï¼š1. **å…´è¶£ä¸ä¸“é•¿**ï¼šäº†è§£è‡ªå·±æ“…é•¿å“ªä¸ªé¢†åŸŸï¼Œæœ‰åŠ©äºåšå‡ºæ›´æ˜æ™ºçš„é€‰æ‹©ã€‚2. **å…¨é¢å‘å±•**ï¼šè€ƒè™‘å­¦ç§‘çš„å¤šæ ·æ€§å’Œæ·±åº¦ï¼Œä»¥å…¨é¢å‘å±•è‡ªå·±çš„ç”Ÿæ´»å’ŒèŒä¸šã€‚3. **é€‚åº”ä¸è°ƒæ•´**ï¼šé€‰æ‹©ä¸è‡ªå·±æŠ€èƒ½ã€å…´è¶£å’Œç›®æ ‡ç›¸åŒ¹é…çš„å­¦ç§‘ï¼Œæœ‰åŠ©äºåº”å¯¹æŒ‘æˆ˜å’Œå®ç°ç›®æ ‡ã€‚4. **èŒä¸šè§„åˆ’**ï¼šæ¢ç´¢é€‚åˆè‡ªå·±çš„èŒä¸šè·¯å¾„ï¼Œæå‡æ•ˆç‡å’Œç«äº‰åŠ›ã€‚5. **ç¤¾ä¼šè´¡çŒ®**ï¼šè¯„ä¼°è‡ªå·±åœ¨ç¤¾ä¼šä¸­çš„è§’è‰²ï¼Œä¸ºç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£å¹¶åº”ç”¨è¿™ä¸€ç‚¹ï¼Œä½ å¯ä»¥ï¼š- **äº†è§£è¡Œä¸šåŠ¨æ€**ï¼šå…³æ³¨ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šå‘å±•ã€‚- **å®è·µä¸åæ€**ï¼šé€šè¿‡é¡¹ç›®æˆ–å®ä¹ ç§¯ç´¯ç»éªŒã€‚- **èŒä¸šå‘å±•**ï¼šè¯„ä¼°è‡ªå·±çš„é•¿æœŸèŒä¸šè§„åˆ’ã€‚- **æŒç»­å­¦ä¹ **ï¼šä¸æ–­æ›´æ–°çŸ¥è¯†ï¼Œé€‚åº”èŒåœºå˜åŒ–ã€‚é€šè¿‡è¿™äº›æ–¹å‘ï¼Œä½ å¯ä»¥æ›´å…¨é¢åœ°è®¤è¯†è‡ªå·±ï¼Œæ‰¾åˆ°é€‚åˆè‡ªå·±çš„å‘å±•è·¯å¾„ã€‚&amp;lt;/answer&amp;gt;


[Q]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„ï¼Ÿ
[A]: &amp;lt;think&amp;gt;å—¯ï¼Œé²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„å‘¢ï¼Ÿè¿™ä¸ªé—®é¢˜å¬èµ·æ¥æŒºæœ‰æ„æ€çš„ï¼Œå°¤å…¶æ˜¯ä»–åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­çš„è¡¨è¾¾æ–¹å¼ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®è®¤ä¸€ä¸‹ã€Šç‹‚äººæ—¥è®°ã€‹å…·ä½“æ˜¯è°å†™çš„ï¼Œæ˜¯å¦æœ‰ç‰¹å®šçš„äººç‰©æˆ–è€…äº‹ä»¶ã€‚ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯é²è¿…åœ¨1924å¹´åˆ›ä½œçš„ï¼Œä¸»è¦è®¨è®ºäº†ç¤¾ä¼šé—®é¢˜ï¼Œå°¤å…¶æ˜¯å°å»ºç¤¼æ•™çš„é—®é¢˜ã€‚ä½œè€…æ›¹é›ªèŠ¹æ˜¯ä¸ªéå¸¸è‘—åçš„ä½œå®¶ï¼Œä»–çš„ä½œå“ä¸­æœ‰è®¸å¤šå…³äºå°å»ºç¤¼æ•™å’Œé˜¶çº§æ–—äº‰çš„è§‚ç‚¹ã€‚è¿™ç±»ä½œå“åœ¨æ–‡å­¦ã€å“²å­¦å’Œæ”¿æ²»ä¸Šéƒ½æœ‰å¾ˆæ·±è¿œçš„å½±å“ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾ä¼šç»“æ„å’Œäººæ€§çš„æ–¹é¢ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦äº†è§£é²è¿…çš„å†™ä½œé£æ ¼ã€‚ä»–çš„å†™ä½œé£æ ¼æ¯”è¾ƒç›´æ¥ï¼Œæœ‰ä¸¥è‚ƒçš„å“²å­¦è§‚ç‚¹ï¼Œå¼ºè°ƒäººæ€§çš„æ‚²å‰§å’Œé“å¾·çš„è™šæ— ã€‚ä»–çš„è¯­è¨€é£æ ¼æ¯”è¾ƒå¯Œæœ‰è¯—æ„ï¼Œå¯Œæœ‰è±¡å¾æ„ä¹‰ï¼Œå–„äºè¿ç”¨è±¡å¾æ‰‹æ³•ï¼ŒåŒæ—¶åˆä¸å¤±çœŸå®å’Œç°å®ä¸»ä¹‰ã€‚ä»–çš„ä½œå“ä¸­æœ‰å¾ˆå¤šå…³äºç¤¾ä¼šé˜¶çº§å’Œé˜¶çº§çŸ›ç›¾çš„åˆ†æï¼Œè¿™äº›è§‚ç‚¹å¯èƒ½ä¸å½“æ—¶çš„ç¤¾ä¼šç°å®ä¸ç¬¦ï¼Œæ‰€ä»¥åœ¨æ‰¹åˆ¤å°å»ºç¤¼æ•™æ—¶ï¼Œåº”è¯¥å¼ºè°ƒè¿™äº›çŸ›ç›¾ã€‚ç„¶åï¼Œæˆ‘æƒ³åˆ°ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­å¯¹å°å»ºç¤¼æ•™çš„è®¨è®ºã€‚é²è¿…çš„ä½œå“ä¸­ï¼Œå°å»ºç¤¼æ•™è¢«è§†ä¸ºä¸äººé“çš„ï¼Œä½†é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨ï¼Œè¡¨è¾¾äº†ä»–å¯¹å°å»ºç¤¼æ•™çš„ä¸æ»¡å’ŒåæŠ—ã€‚è¿™ä¸ä»…åæ˜ äº†å½“æ—¶çš„ç¤¾ä¼šç°å®ï¼Œä¹Ÿæ­ç¤ºäº†å°å»ºç¤¼æ•™çš„é»‘æš—é¢ï¼Œä½“ç°äº†å¯¹å°å»ºç¤¾ä¼šçš„ä¸æ»¡å’Œå¯¹äººæ€§çš„æ·±åˆ»åæ€ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦æ€è€ƒé²è¿…å¯¹å°å»ºç¤¼æ•™çš„ç†è§£å’Œæ‰¹åˆ¤ã€‚ä»–åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­ï¼Œå¯¹å°å»ºç¤¼æ•™çš„è´¨ç–‘å’Œæ‰¹åˆ¤ï¼Œä½“ç°äº†ä»–å¯¹ä¼ ç»Ÿå°å»ºç¤¼æ•™çš„å¦å®šå’Œæ‰¹åˆ¤ã€‚è¿™ä¸ä»…ä»…æ˜¯å¯¹å°å»ºç¤¼æ•™çš„è´¨ç–‘ï¼Œæ›´æ˜¯å¯¹å½“æ—¶ç¤¾ä¼šçš„åæ€ï¼Œä»¥åŠå¯¹äººæ€§çš„å…³æ³¨ã€‚æœ€åï¼Œæˆ‘éœ€è¦æ€»ç»“ä¸€ä¸‹é²è¿…å¯¹å°å»ºç¤¼æ•™çš„æ‰¹åˆ¤å’Œæ‰¹åˆ¤ã€‚ä»–é€šè¿‡ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­çš„æ–‡å­—å’Œè¡Œä¸ºï¼Œæ‰¹åˆ¤äº†å°å»ºç¤¼æ•™çš„è™šå‡å’Œä¸åˆç†ï¼Œä½“ç°äº†å¯¹ç¤¾ä¼šç°å®çš„æ·±åˆ»åæ€ã€‚åŒæ—¶ï¼Œä»–ä¹Ÿå…³æ³¨äº†å°å»ºç¤¼æ•™çš„é»‘æš—é¢ï¼Œåæ˜ äº†å¯¹å°å»ºç¤¾ä¼šçš„ä¸æ»¡å’Œå¯¹äººæ€§çš„å¦å®šã€‚æ€»çš„æ¥è¯´ï¼Œé²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨ï¼Œæ‰¹åˆ¤äº†å°å»ºç¤¼æ•™çš„è™šå‡å’Œä¸åˆç†ï¼Œä½“ç°äº†å½“æ—¶çš„ç¤¾ä¼šç°å®å’Œäººæ€§çš„å¤æ‚ã€‚ä»–çš„ä½œå“å¯¹åæ¥çš„å°å»ºç¤¼æ•™æœ‰äº†å¯ç¤ºï¼Œå¯¹å½“æ—¶çš„ç¤¾ä¼šç°è±¡æœ‰äº†æ›´æ·±çš„åæ€ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨åæ˜ å°å»ºç¤¼æ•™çš„æ–‡å­¦ä½œå“ï¼Œä¸»è¦é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨åæ˜ äº†å½“æ—¶ç¤¾ä¼šçš„ç°å®ã€‚é²è¿…çš„æ–‡å­—é£æ ¼ç‹¬ç‰¹ï¼Œå¯Œæœ‰è±¡å¾æ„ä¹‰ï¼Œä½†é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨ï¼Œæ‰¹åˆ¤äº†å°å»ºç¤¼æ•™çš„è™šå‡å’Œä¸åˆç†ã€‚ä»–çš„ä½œå“ä¸­ï¼Œå°å»ºç¤¼æ•™è¢«è§†ä¸ºä¸äººé“çš„ï¼Œä½†é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨ï¼Œåæ˜ äº†å°å»ºç¤¾ä¼šçš„ä¸å…¬å’Œäººæ€§çš„æ·±åˆ»åæ€ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡æ–‡å­—å’Œè¡ŒåŠ¨ï¼Œæ‰¹åˆ¤äº†å°å»ºç¤¼æ•™çš„è™šå‡å’Œä¸åˆç†ï¼Œä½“ç°äº†å½“æ—¶ç¤¾ä¼šçš„ä¸æ»¡å’Œå¯¹äººæ€§çš„åæ€ã€‚ä»–çš„ä½œå“ä¸ä»…æ‰¹åˆ¤äº†å°å»ºç¤¼æ•™çš„è™šå‡å’Œä¸åˆç†ï¼Œè¿˜æ·±åˆ»æ­ç¤ºäº†å°å»ºç¤¾ä¼šçš„é»‘æš—é¢ã€‚&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£é²è¿…çš„ç”Ÿå¹³å’Œä½œå“ã€‚ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸­å›½ç°ä»£æ–‡å­¦çš„ç»å…¸ï¼Œä½œè€…æ˜¯æ¯›æ³½ä¸œï¼Œä½œå“æ¶‰åŠç¤¾ä¼šã€å®¶åº­ã€ä¼¦ç†ç­‰å¤šä¸ªå±‚é¢ã€‚æˆ‘éœ€è¦æ‰¾å‡ºé²è¿…çš„å†™ä½œé£æ ¼å’Œä¸»é¢˜ï¼Œä»¥åŠå®ƒåœ¨å½“æ—¶çš„ç¤¾ä¼šèƒŒæ™¯ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥å›é¡¾ã€Šç‹‚äººæ—¥è®°ã€‹çš„ä¸»è¦å†…å®¹ã€‚æ¯›æ³½ä¸œåœ¨ã€Šé’æ˜¥æ— æ‚”ã€‹ä¸­æå‡ºäº†"ç‹‚äººæ—¥è®°"è¿™ä¸€æ¦‚å¿µï¼Œå¼ºè°ƒé’æ˜¥æ´»æ³¼ã€å‹‡æ•¢ã€æ­£ä¹‰ï¼Œè¿™åœ¨å½“æ—¶ç¤¾ä¼šä¸­ä»ç„¶å…·æœ‰é‡è¦æ„ä¹‰ã€‚ä»–é€šè¿‡æç»˜ä¸»äººå…¬ç‹‚äººæ¥è¡¨è¾¾å¯¹ç¤¾ä¼šä¸å…¬çš„æ‰¹åˆ¤ï¼Œä½†åŒæ—¶ä¹ŸæŒ‡å‡ºä»–çš„åˆ›ä½œå¯¹ç¤¾ä¼šçš„è´Ÿé¢å½±å“ï¼Œæ¯”å¦‚ç¤¾ä¼šåŠ¨è¡å’Œä¸ªäººä¸»ä¹‰çš„å¤±è´¥ã€‚ç„¶åï¼Œæˆ‘åº”è¯¥åˆ†æé²è¿…çš„åˆ›ä½œç†å¿µå’Œä¸»é¢˜ã€‚ã€Šç‹‚äººæ—¥è®°ã€‹å¼ºè°ƒäº†ç¤¾ä¼šçš„é»‘æš—é¢ï¼Œä¸»å¼ "ä»¥äººä¸ºæœ¬"ã€"åå¯¹å°å»ºç¤¼æ•™"ç­‰ã€‚ä»–å¯èƒ½ä¹Ÿåœ¨æ¢è®¨ç¤¾ä¼šä¸å¹³ç­‰çš„é—®é¢˜ï¼Œæ¯”å¦‚"äººæ€§å¼±ç‚¹"ã€"æƒåŠ›æ»¥ç”¨"ç­‰é—®é¢˜ã€‚è¿˜è¦è€ƒè™‘é²è¿…çš„å…¶ä»–ä½œå“ï¼Œæ¯”å¦‚ã€Šé˜¿Qæ­£ä¼ ã€‹ã€ã€Šæ­»äº¡è¯—ç¤¾ã€‹ç­‰ï¼Œè¿™äº›ä½œå“è™½ç„¶æœ‰ç‚¹å¤¸å¼ ï¼Œä½†ä¹Ÿæœ‰æ·±åˆ»çš„ç¤¾ä¼šæ‰¹åˆ¤ï¼Œæ¯”å¦‚å¯¹ç¤¾ä¼šé“å¾·çš„è´¨ç–‘ã€‚åŒæ—¶ï¼Œä½œè€…å¯èƒ½è¿˜æ¶‰åŠå…¶ä»–ä½œå“ï¼Œå¦‚ã€Šåº†ä½™å¹´ã€‹ç­‰ï¼Œä½†è¿™äº›å¯èƒ½æ›´ä¾§é‡äºæ–‡å­¦åˆ›ä½œï¼Œè€Œä¸æ˜¯ç¤¾ä¼šæ‰¹åˆ¤ã€‚å¦å¤–ï¼Œç”¨æˆ·å¯èƒ½æƒ³çŸ¥é“é²è¿…åœ¨æ–‡å­¦åˆ›ä½œä¸­çš„å…·ä½“ç»å†ï¼Œæ¯”å¦‚ä»–æ˜¯å¦æœ‰ä½œå“è¢«å¹¿æ³›æ‰¹è¯„ï¼Œæˆ–è€…ä»–å¯¹ç¤¾ä¼šçš„æ‰¹åˆ¤æ˜¯å¦å…·æœ‰æ‰¹åˆ¤æ€§ã€‚æ‰€ä»¥ï¼Œå›ç­”æ—¶éœ€è¦æŒ‡å‡ºé²è¿…çš„åˆ›ä½œç»å†ï¼Œä»¥åŠä»–å¯¹ç¤¾ä¼šç°å®çš„åæ€ã€‚æ€»ç»“æ¥è¯´ï¼Œæˆ‘éœ€è¦å›ç­”é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ‰¹åˆ¤å°å»ºç¤¼æ•™ï¼Œå¹¶åˆ†æå…¶åœ¨å½“æ—¶çš„ç¤¾ä¼šèƒŒæ™¯å’Œæ–‡å­¦ä»·å€¼ï¼ŒåŒæ—¶æŒ‡å‡ºå…¶å¯¹ç¤¾ä¼šçš„æ‰¹åˆ¤æ€§æ€è€ƒï¼Œä»¥åŠå…¶å¯¹åä¸–çš„å½±å“ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ‰¹åˆ¤å°å»ºç¤¼æ•™ï¼Œä»¥å…¶ç‹¬ç‰¹çš„å™äº‹é£æ ¼å’Œæ·±åˆ»çš„ç¤¾ä¼šæ‰¹åˆ¤ç²¾ç¥è‘—ç§°ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1. **ç¤¾ä¼šæ‰¹åˆ¤ä¸ä¸ªäººæˆé•¿**ï¼šå°è¯´é€šè¿‡æç»˜ä¸»äººå…¬ç‹‚äººçš„æ´»æ³¼ã€å‹‡æ•¢ã€æ­£ä¹‰ï¼Œæ­ç¤ºç¤¾ä¼šçš„ä¸å…¬å’Œå¼±åŠ¿ã€‚2. **ä¸ªäººä¸»ä¹‰ä¸ç¤¾ä¼šæ‰¹åˆ¤**ï¼šå°è¯´åæ˜ äº†å°å»ºç¤¼æ•™å¯¹ä¸ªäººè‡ªç”±å’Œæƒåˆ©çš„ä¾µçŠ¯ï¼Œå¼ºè°ƒä¸ªäººå°Šä¸¥å’Œæ­£ä¹‰çš„ä»·å€¼ã€‚3. **å¯¹ç¤¾ä¼šçš„æ‰¹åˆ¤æ€§æ€è€ƒ**ï¼šé€šè¿‡å¯¹ç¤¾ä¼šä¸å…¬çš„åˆ»ç”»ï¼Œæ­ç¤ºç¤¾ä¼šé—®é¢˜çš„æ ¹æºï¼Œå¹¶å¯¹å½“æ—¶ç¤¾ä¼šçš„æ‰¹åˆ¤æ€åº¦è¿›è¡Œæ‰¹åˆ¤ã€‚é²è¿…çš„ä½œå“åœ¨å½“æ—¶çš„ç¤¾ä¼šèƒŒæ™¯å’Œæ–‡å­¦ä»·å€¼ä½¿å…¶æˆä¸ºå½“æ—¶æ–‡å­¦çš„é‡è¦ä»£è¡¨ã€‚ä»–çš„ä½œå“ä¸ä»…åœ¨å½“æ—¶å¹¿å—æ¬¢è¿ï¼Œä¹Ÿå¯¹åä¸–äº§ç”Ÿäº†æ·±è¿œå½±å“ï¼Œè¢«å¹¿æ³›å¼•ç”¨å’Œä¼ é¢‚ã€‚&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç†è§£é²è¿…çš„èƒŒæ™¯å’Œæ ¸å¿ƒæ€æƒ³ã€‚ä»–å¯èƒ½æ˜¯ä¸€ä½ç¤¾ä¼šå­¦å®¶ã€æ€æƒ³å®¶ï¼Œæˆ–è€…æ˜¯å¯¹ä¼ ç»Ÿæ–‡åŒ–æœ‰æ·±åšå…´è¶£çš„è¯»è€…ã€‚ç‹‚äººæ—¥è®°æ˜¯ä»–åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­æ‰€å†™çš„ï¼Œå¯èƒ½å¯¹ä¼ ç»Ÿæ–‡åŒ–æœ‰ä¸€å®šå½±å“ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘è¦è€ƒè™‘ç”¨æˆ·çš„éœ€æ±‚æ˜¯ä»€ä¹ˆã€‚ç”¨æˆ·å¯èƒ½æƒ³çŸ¥é“è¿™æœ¬ä¹¦åœ¨ç°ä»£ç¤¾ä¼šä¸­çš„åæ€æ„ä¹‰ï¼Œæˆ–è€…æ˜¯å¦æœ‰ç›¸å…³ç ”ç©¶æ”¯æŒè¿™ä¸€ç‚¹ã€‚ä¹Ÿæœ‰å¯èƒ½ä»–ä»¬å¯¹ä¹¦ä¸­çš„æƒ…èŠ‚æœ‰ç–‘é—®ï¼Œæƒ³äº†è§£å¦‚ä½•æ›´æ·±åˆ»åœ°ç†è§£ç¤¾ä¼šç°è±¡ã€‚ç„¶åï¼Œæˆ‘éœ€è¦æ€è€ƒå¦‚ä½•ä»ä¸åŒçš„è§’åº¦è§£è¯»é²è¿…çš„æ–‡æœ¬ã€‚ä¾‹å¦‚ï¼Œæ˜¯å¦æœ‰ç›´æ¥çš„å†å²å™äº‹ï¼Œæˆ–è€…æ˜¯å¦å­˜åœ¨æ›´æ·±å±‚æ¬¡çš„å“²å­¦æ€è€ƒï¼Ÿè¿™éœ€è¦æˆ‘å…ˆäº†è§£é²è¿…çš„ä¸åŒè§‚ç‚¹ï¼Œç„¶ååˆ†æå…¶æ‰¹åˆ¤æ€§ã€‚è¿˜è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ï¼Œæ¯”å¦‚æ˜¯å¦éœ€è¦äº†è§£ä»–ä½œä¸ºæ–‡å­¦æ‰¹åˆ¤å®¶çš„èƒŒæ™¯ï¼Œæˆ–è€…æ˜¯å¦æœ‰å¯¹ä¼ ç»Ÿä»·å€¼è§‚çš„åæ€ã€‚å› æ­¤ï¼Œå›ç­”æ—¶è¦å…¨é¢ï¼Œæ¶µç›–æ ¸å¿ƒé—®é¢˜ï¼Œå¹¶å¼•ç”¨ç›¸å…³èµ„æ–™æ¥æ”¯æ’‘è§‚ç‚¹ã€‚æœ€åï¼Œæ€»ç»“é²è¿…çš„è§‚ç‚¹ï¼Œå¼ºè°ƒå…¶å¯¹ç°ä»£ç¤¾ä¼šçš„æ‰¹åˆ¤æ€§æ€è€ƒï¼Œä»¥åŠå¯¹ä¼ ç»Ÿæ–‡åŒ–çš„å°Šé‡ã€‚è¿™æ ·æ—¢å…¨é¢åˆæœ‰æ·±åº¦ï¼Œå¸®åŠ©ç”¨æˆ·å…¨é¢ç†è§£é²è¿…çš„ä½œå“ã€‚&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡å…¶ç‹¬ç‰¹çš„å™äº‹æ‰‹æ³•å’Œæ·±åˆ»çš„ç¤¾ä¼šæ‰¹åˆ¤ç²¾ç¥ï¼Œå¯¹å°å»ºç¤¼æ•™è¿›è¡Œäº†æ·±åˆ»çš„æ‰¹åˆ¤ã€‚ä»¥ä¸‹æ˜¯å…¶æ‰¹åˆ¤æ€§åˆ†æï¼š1. **ç¤¾ä¼šæ‰¹åˆ¤ä¸å†å²çœŸç›¸**ï¼šå°è¯´é€šè¿‡å¯¹å†å²äººç‰©çš„åˆ»ç”»ï¼Œæ­ç¤ºå°å»ºç¤¼æ•™çš„å¼Šç«¯ï¼Œä»¥åŠå…¶å¯¹ä¼ ç»Ÿç¤¾ä¼šç»“æ„çš„å†²å‡»ã€‚è¿™ç§æ‰¹åˆ¤ä¸ä»…é™äºå¯¹ç°å®çš„æ·±åˆ»æ‰¹åˆ¤ï¼Œä¹Ÿåæ˜ äº†ç°ä»£ç¤¾ä¼šå¯¹ä¼ ç»Ÿä»·å€¼è§‚çš„é‡æ–°å®¡è§†ã€‚2. **ä¸ªäººå‘½è¿ä¸ç¤¾ä¼šæ‰¹åˆ¤**ï¼šå°è¯´ä¸­ï¼Œä¸»äººå…¬é€šè¿‡"ç‹‚äººæ—¥è®°"æ­ç¤ºäº†å°å»ºç¤¼æ•™å¯¹ä¸ªäººå‘½è¿çš„ä¸¥é‡å‰¥å¤ºã€‚è¿™ç§å™äº‹æ–¹å¼æ—¢æ‰¹åˆ¤äº†å°å»ºç¤¼æ•™ï¼Œä¹Ÿå¯¹åä¸–äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚3. **å¯¹åä¸–çš„å½±å“**ï¼šä»æ–‡å­¦åˆ›ä½œåˆ°æ€æƒ³è§£è¯»ï¼Œé²è¿…çš„ä½œå“æ·±åˆ»å½±å“äº†åä¸–çš„æ€æƒ³ä½“ç³»ã€‚ä¾‹å¦‚ï¼Œã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡äººç‰©å‘½è¿çš„åæ˜ ï¼Œå¯¹ç°ä»£ç¤¾ä¼šçš„ä»·å€¼è§‚å¿µæå‡ºäº†æ–°çš„æ€è€ƒã€‚4. **å¯¹ç°ä»£æ–‡æ˜çš„åæ€**ï¼šè¿™ä¸€æ‰¹åˆ¤æ€§æ€è€ƒä¸ä»…åæ˜ äº†å½“ä»£ç¤¾ä¼šçš„å¤æ‚æ€§ï¼Œä¹Ÿä¸ºç°ä»£äººæä¾›äº†åæ€ç¤¾ä¼šç°å®ã€ç»´æŠ¤äººæƒçš„è§†è§’ã€‚5. **ä¸ªäººè§†è§’ä¸æ–‡åŒ–è§†è§’**ï¼šä½œè€…é€šè¿‡è¿™ä¸€æ‰¹åˆ¤æ€§æ€è€ƒï¼Œå±•ç°äº†å¯¹ä¼ ç»Ÿä»·å€¼è§‚çš„é‡æ–°è§£è¯»ï¼ŒåŒæ—¶ä¹Ÿå¯¹å½“ä»£ç¤¾ä¼šçš„å¤šå…ƒåŒ–è§†è§’äº§ç”Ÿäº†å¯å‘ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œé²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹ä¸ä»…æ˜¯å¯¹å°å»ºç¤¼æ•™çš„æ‰¹åˆ¤ï¼Œæ›´æ˜¯å¯¹ä¼ ç»Ÿæ–‡åŒ–çš„ä¸€ç§æ·±åˆ»åæ€ã€‚å®ƒé€šè¿‡å¯¹å°å»ºç¤¼æ•™çš„æ‰¹åˆ¤ï¼Œæå‡ºäº†å¯¹ç°ä»£ç¤¾ä¼šç»“æ„ã€æƒåŠ›å…³ç³»çš„æ·±åˆ»åæ€ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼ã€‚&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â…¢ å…¶ä»–æ¨¡å‹å¯¹æ¯”&lt;/h2&gt; 
&lt;p&gt;[A] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br /&gt; [B] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br /&gt; [C] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br /&gt; [D] &lt;a href="https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666"&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br /&gt; [E] &lt;a href="https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666"&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br /&gt; [F] &lt;a href="https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666"&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br /&gt; [G] &lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br /&gt; [H] &lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ä½ çŸ¥é“é•¿æ±Ÿå—ï¼Ÿ
[A]: é•¿æ±Ÿï¼Œä½äºä¸­å›½ä¸œå—éƒ¨ï¼Œæ˜¯ä¸­å›½çš„ç¬¬ä¸€é•¿æ²³ï¼Œå…¨é•¿6300å¤šå…¬é‡Œï¼Œæµç»11ä¸ªçœä»½ï¼Œæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸­å›½çš„â€œæ¯äº²æ²³â€ã€‚é•¿æ±Ÿçš„å†å²å¯ä»¥è¿½æº¯åˆ°å…¬å…ƒå‰2000å¤šå¹´çš„å•†æœæ—¶æœŸï¼Œå½“æ—¶çš„å•†æœæ˜¯å•†æœçš„åè£”ã€‚å•†æœæ—¶æœŸï¼Œé•¿æ±Ÿçš„ç»æµå‘å±•è¾¾åˆ°äº†é«˜å³°ï¼Œæ˜¯ä¸­å›½æœ€é‡è¦çš„å†œä¸šå’Œå·¥ä¸šä¸­å¿ƒä¹‹ä¸€ã€‚é•¿æ±ŸæµåŸŸçš„ç»æµä¸»è¦ä»¥å†œä¸šä¸ºä¸»ï¼Œé•¿æ±Ÿæ¸”ä¸šå æ®äº†ä¸»è¦äº§ä¸šï¼Œå¦‚é’“é±¼ã€çŒé±¼ç­‰ã€‚é•¿æ±Ÿçš„æ°´èµ„æºä¹Ÿéå¸¸ä¸°å¯Œï¼ŒåŒ…æ‹¬æ²³æµã€æ¹–æ³Šã€æ²³æµç­‰ã€‚é•¿æ±Ÿçš„è‡ªç„¶æ™¯è§‚ä¹Ÿååˆ†å£®è§‚ï¼Œé•¿æ±Ÿå››å­£æ™¯è‰²å„å¼‚ï¼Œæ˜¥å­£å¤šé›¨ï¼Œå¤å­£å¤šé›¨ï¼Œç§‹å­£åˆ™å¤šé›¨ï¼Œå†¬å­£åˆ™å¯’å†·å¤šé›ªï¼Œæ˜¥å­£å’Œç§‹å­£éƒ½æœ‰ç¾ä¸½çš„èŠ±æœµå’Œæœå®ã€‚é•¿æ±Ÿæ˜¯ä¸­å›½çš„ç»æµä¸­å¿ƒï¼Œæ‹¥æœ‰ä¼—å¤šçš„å›½å®¶å’ŒåŸå¸‚ï¼Œæ˜¯ä¸–ç•Œä¸Šé‡è¦çš„äº¤é€šæ¢çº½å’Œèˆªè¿ä¸­å¿ƒã€‚åŒæ—¶ï¼Œé•¿æ±Ÿè¿˜æ˜¯ä¸­å›½çš„é‡è¦æ°´åˆ©èµ„æºï¼Œå¯¹äºä¸­å›½çš„ç»æµå‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚
[B]: æ˜¯çš„ï¼Œæˆ‘çŸ¥é“é•¿æ±Ÿã€‚é•¿æ±Ÿä½äºä¸­å›½çš„ä¸­éƒ¨ï¼Œæ˜¯ä¸­å›½ç¬¬ä¸‰é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œï¼Œæµç»æ±Ÿè¥¿çœã€å®‰å¾½çœã€æ±Ÿè‹çœã€å®‰å¾½çœã€æ±Ÿè‹çœå’Œå®‰å¾½çœã€‚
[C]: å½“ç„¶ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œã€‚å®ƒä»¥å…¶ä¸°å¯Œçš„æ°´èµ„æºã€ä¸°å¯Œçš„æ°´ç”ŸåŠ¨æ¤ç‰©èµ„æºä»¥åŠç‹¬ç‰¹çš„åœ°ç†ä½ç½®è€Œé—»åäºä¸–ã€‚
[D]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿è¶…è¿‡3300åƒç±³ã€‚
[E]: é•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œæ€»é•¿åº¦çº¦ä¸º6300å…¬é‡Œã€‚å®ƒå‘æºäºé’è—é«˜åŸçš„é’æµ·æ¹–ï¼Œæµç»é’æµ·ã€å››å·ã€ç”˜è‚ƒã€å®å¤ã€å†…è’™å¤ã€é™•è¥¿å’Œå±±è¥¿ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„å†œä¸šåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½çš„æ–‡åŒ–å’Œç»æµä¸­å¿ƒã€‚
[F]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸–ç•Œç¬¬ä¸‰å¤§æ²³æµã€‚é•¿æ±Ÿå‘æºäºé’è—é«˜åŸï¼Œæµç»11ä¸ªçœä»½ï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„æ²³æµæµåŸŸä¹‹ä¸€ï¼Œæ‹¥æœ‰ç€ä¸°å¯Œçš„è‡ªç„¶èµ„æºå’Œæ–‡åŒ–é—äº§ï¼Œå¦‚é•¿æ±Ÿå¤§æ¡¥ã€é•¿æ±Ÿæµ·æ´‹åšç‰©é¦†ã€é•¿æ±Ÿå¤åŸç­‰ã€‚
[G]: åŒæ—¶ä¹ŸçŸ¥é“ï¼Œä¸­å›½æ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„åŸå¸‚ä¹‹ä¸€ï¼Œæ‹¥æœ‰è¶…è¿‡3400ä¸‡äººå£ã€‚
[H]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµä¹‹ä¸€ã€‚å®ƒå‘æºäºé’è—é«˜åŸï¼Œæµç»ä¹ä¸ªçœåŒºï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸçš„æ°”å€™æ¸©å’Œï¼Œå››å­£åˆ†æ˜ï¼Œæ˜¯ä¸­å›½é‡è¦çš„å†œä¸šå’Œå·¥ä¸šåŸºåœ°ã€‚é•¿æ±ŸæµåŸŸçš„æ°´äº§èµ„æºä¸°å¯Œï¼Œæ˜¯ä¸­å›½çš„é‡è¦æ¸”ä¸šèµ„æºä¹‹ä¸€ã€‚


[Q]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ä»€ä¹ˆï¼Ÿ
[A]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šã€‚å®ƒçš„æµ·æ‹”é«˜åº¦æ˜¯8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ï¼Œæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚
[B]: ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”é«˜åº¦è¾¾8,848ç±³ï¼ˆ29,029è‹±å°ºï¼‰ã€‚
[C]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ã€‚å®ƒä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šï¼Œæ˜¯å–œé©¬æ‹‰é›…å±±è„‰çš„ä¸€éƒ¨åˆ†ã€‚
[D]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹å¢ƒä¸Šï¼Œæµ·æ‹”8848ç±³ã€‚
[E]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848ç±³ã€‚
[F]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”8848ç±³ã€‚
[G]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚
[H]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä¹Ÿç§°ä¸ºè¨åŠ ç›å¡”ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰çš„å°¼æ³Šå°”å’Œä¸­å›½è¾¹å¢ƒä¹‹é—´ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚å®ƒæ˜¯ä¸–ç•Œä¸Šæœ€è‘—åçš„ç™»å±±ç›®æ ‡ä¹‹ä¸€ï¼Œå¸å¼•ç€æ¥è‡ªä¸–ç•Œå„åœ°çš„ç™»å±±è€…å‰æ¥æŒ‘æˆ˜ã€‚ç ç©†æœ—ç›å³°çš„åå­—æ¥è‡ªè—è¯­ï¼Œæ„æ€æ˜¯â€œå¥³ç¥çš„é¢å³°â€ï¼Œå®ƒæ˜¯ç”±ä¸¤ä¸ªä¸åŒçš„å±±å³°ç»„æˆçš„ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ä½äºå°¼æ³Šå°”çš„ç ç©†æœ—ç›å³°ï¼Œå¦ä¸€ä¸ªåˆ™ä½äºä¸­å›½ã€‚å®ƒçš„é«˜åº¦æ˜¯é€šè¿‡æµ‹é‡æµ·æ‹”é«˜åº¦æ¥ç¡®å®šçš„ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡æµ‹é‡åœ°çƒçš„å¹³å‡é«˜åº¦æ¥ç¡®å®šçš„ã€‚å°½ç®¡ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•å…¶ä»–åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚åœ°çƒä¸Šçš„å…¶ä»–åœ°æ–¹ï¼Œå¦‚å—ç¾æ´²çš„å®‰ç¬¬æ–¯å±±è„‰ï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚æ€»ä¹‹ï¼Œç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚å®ƒæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚


[Q]: ä¸‡æœ‰å¼•åŠ›æ˜¯è°æå‡ºçš„ï¼Ÿ
[A]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ï¼Œå®ƒæ˜¯ç‰›é¡¿ä¸‰å¤§å®šå¾‹ä¹‹ä¸€ã€‚ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„å¼•åŠ›å®šå¾‹æ­ç¤ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„æœ¬è´¨ï¼Œå¹¶ä¸”è§£é‡Šäº†è¡Œæ˜Ÿã€å«æ˜Ÿã€å½—æ˜Ÿç­‰å¤©ä½“ä¹‹é—´å¦‚ä½•ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªå®šå¾‹æ˜¯ç”±è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ï¼Œä»–é€šè¿‡å¯¹ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„åˆ†æå’Œå®éªŒï¼ŒæˆåŠŸåœ°è§£é‡Šäº†å¤©ä½“ä¹‹é—´çš„å¼•åŠ›ä½œç”¨ï¼Œä»è€Œè§£é‡Šäº†åœ°çƒç»•å¤ªé˜³æ—‹è½¬çš„ç°è±¡ã€‚
[B]: ä¸‡æœ‰å¼•åŠ›ï¼ˆHuman Policyï¼‰æ˜¯ç‰›é¡¿çš„ä¸‰å¤§åŠ›å­¦å®šå¾‹ï¼Œç”¨äºæè¿°ä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨åŠ›ã€‚å®ƒç”±ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿çš„ç¬¬ä¸€å®šå¾‹ï¼ˆæƒ¯æ€§å®šå¾‹ï¼‰æ„æˆã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±äºä¸¤ä¸ªç‰©ä½“ä¹‹é—´ç›¸äº’ä½œç”¨è€Œäº§ç”Ÿçš„ï¼Œå®ƒä»¬çš„è´¨é‡ã€è·ç¦»ã€é€Ÿåº¦å’Œæ–¹å‘ç­‰å› ç´ å†³å®šäº†å®ƒä»¬ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ç§ç›¸äº’ä½œç”¨åŠ›æ˜¯ï¼šè´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„ä¹˜ç§¯ã€‚è´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ç‰©ä½“ä¹‹é—´çš„ä¸€ç§ç‰©ç†è¿‡ç¨‹ï¼Œå®ƒæ˜¯ç‰©ä½“é—´ç›¸äº’ä½œç”¨çš„äº§ç‰©ï¼Œå¯¹äºå…¶ä»–ç‰©ä½“æ¥è¯´ï¼Œå…¶è´¨é‡å¯ä»¥è¡¨ç¤ºä¸ºä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„è´¨é‡ä¹‹å’Œï¼Œå³é‡åŠ›åŠ é€Ÿåº¦aã€‚
[C]: ä¸‡æœ‰å¼•åŠ›æ˜¯ä¸€ä¸ªç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ç‰©ç†å­¦æ¦‚å¿µï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´å¼•åŠ›å¦‚ä½•ç›¸äº’ä½œç”¨çš„è§„å¾‹ã€‚
[D]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶ç‰›é¡¿æå‡ºçš„ã€‚ä»–è®¤ä¸ºï¼Œæ‰€æœ‰ç‰©ä½“éƒ½ä¼šäº§ç”Ÿå¼•åŠ›ï¼Œè¿™ä¸ªå¼•åŠ›æ˜¯ç”±ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»å†³å®šçš„ã€‚è¿™ä¸ªç†è®ºæ­ç¤ºäº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶è¯æ˜äº†ä¸‡æœ‰å¼•åŠ›çš„æœ¬è´¨ã€‚
[E]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ã€‚å®ƒæ˜¯å®‡å®™ä¸­ä¸€ä¸ªåŸºæœ¬çš„ç‰©ç†ç°è±¡ï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªåŠ›è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›ï¼Œå®ƒåœ¨æ‰€æœ‰ç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ï¼Œè¿™ç§åŠ›ä¸ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»æœ‰å…³ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯è‡ªç„¶ç•Œä¸­æœ€åŸºæœ¬çš„åŠ›é‡ä¹‹ä¸€ï¼Œå®ƒä¸ä»…å½±å“ç€ç‰©ä½“çš„è¿åŠ¨å’Œå˜åŒ–ï¼Œè¿˜å¯¹å®‡å®™çš„ç»“æ„å’Œæ¼”åŒ–äº§ç”Ÿç€é‡è¦çš„å½±å“ã€‚
[F]: ä¸‡æœ‰å¼•åŠ›æ˜¯è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ã€‚
[G]: å¼•åŠ›æ˜¯å®‡å®™ä¸­ä¸€ç§åŠ›é‡ï¼Œå®ƒæ˜¯ç”±è´¨é‡æˆ–èƒ½é‡æ‰€ç»„æˆçš„ã€‚æ ¹æ®ç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚å› æ­¤ï¼Œç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹è¡¨æ˜ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹åœ¨ç‰©ç†å­¦ã€å¤©æ–‡å­¦å’Œç‰©ç†å­¦ä¸­éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
[H]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿äº1687å¹´æå‡ºçš„ã€‚ä»–åœ¨1687å¹´å‘è¡¨äº†ä¸€ç¯‡è‘—åçš„è®ºæ–‡ï¼Œé¢˜ä¸ºã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŸç†ã€‹ï¼Œå…¶ä¸­æå‡ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼ŒæŒ‡å‡ºä»»ä½•ä¸¤ä¸ªç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ç€ä¸€ç§å¼•åŠ›ï¼Œè¿™ç§å¼•åŠ›çš„å¤§å°ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œå®ƒæè¿°äº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ã€‚å®ƒè¡¨æ˜ï¼Œä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹å¯¹äºè§£é‡Šå®‡å®™ä¸­çš„è®¸å¤šç°è±¡å’Œç°è±¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨éå¸¸é‡è¦ï¼Œä¾‹å¦‚è¡Œæ˜Ÿç»•å¤ªé˜³è¿åŠ¨ã€æ’æ˜Ÿä¹‹é—´çš„å¼•åŠ›é€é•œæ•ˆåº”ç­‰ç­‰ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›åº”ç”¨äºå¤©æ–‡å­¦ã€ç‰©ç†å­¦å’Œå·¥ç¨‹å­¦ç­‰é¢†åŸŸï¼Œä¸ºæˆ‘ä»¬ç†è§£å®‡å®™çš„æœ¬è´¨å’Œæ¼”åŒ–æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚


[Q]: ä½ çŸ¥é“å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ä»€ä¹ˆå—ï¼Ÿ
[A]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†ä¹Ÿä¼šåƒå…¶ä»–æ¤ç‰©ã€æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©å’Œé±¼ç±»ã€‚å®ƒä»¬çš„æ¶ˆåŒ–ç³»ç»Ÿä¸å…¶ä»–ç†Šç§‘åŠ¨ç‰©ç±»ä¼¼ï¼Œèƒ½å¤Ÿæ¶ˆåŒ–ç«¹å­ã€‚å¤§ç†ŠçŒ«çš„ç‰™é½¿é”‹åˆ©ï¼Œé€‚åˆå’€åš¼ç«¹å­ï¼Œå› æ­¤å®ƒä»¬ç»å¸¸è¢«ç§°ä¸ºâ€œç«¹é£ŸåŠ¨ç‰©â€ã€‚
[B]: å¤§ç†ŠçŒ«æ˜¯ä»¥ç«¹å­ä¸ºé£Ÿçš„å“ºä¹³åŠ¨ç‰©ï¼Œå®ƒä»¬æ˜¯è‚‰é£ŸåŠ¨ç‰©ã€‚å®ƒä»¬ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œç‰¹åˆ«æ˜¯ç«¹å­ä¸­å¯Œå«çº¤ç»´ç´ å’ŒçŸ¿ç‰©è´¨ï¼Œå¹¶ä¸”ä¸ä¼šç›´æ¥è¿›å…¥æ¶ˆåŒ–ç³»ç»Ÿã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸»è¦ç”±ç«¹å­ç»„æˆï¼Œå®ƒä»¬éœ€è¦æ¶ˆåŒ–ç«¹å­ä¸­çš„çº¤ç»´ç´ å’Œå…¶ä»–çº¤ç»´ç´ æ¥æ”¯æŒå®ƒä»¬çš„æ­£å¸¸è¿›é£Ÿã€‚
[C]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†å®ƒä»¬ä¹Ÿåƒå…¶ä»–æ¤ç‰©ï¼ŒåŒ…æ‹¬æ ‘å¶ã€å«©èŠ½ã€æ˜†è™«ã€æ°´æœã€è”¬èœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ç­‰ã€‚å¤§ç†ŠçŒ«æ˜¯ä¸­å›½ç‰¹æœ‰çš„ç‰©ç§ï¼Œå±äºç†Šç§‘ï¼Œä¸»è¦åˆ†å¸ƒåœ¨ä¸­å›½çš„å››å·ã€é™•è¥¿å’Œç”˜è‚ƒç­‰åœ°ã€‚
[D]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚å®ƒä»¬é€šå¸¸åƒç«¹å­ï¼Œæ¯å¤©éœ€è¦åƒæ‰å¤§çº¦30å…¬æ–¤çš„ç«¹å­ã€‚
[E]: æ˜¯çš„ï¼Œå¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿã€‚å®ƒä»¬æ¯å¤©éœ€è¦åƒæ‰å¤§é‡çš„ç«¹å­æ¥ç»´æŒç”Ÿå‘½ï¼Œæ¯å¤©éœ€è¦åƒæ‰40è‡³80å…¬æ–¤çš„ç«¹å­ã€‚æ­¤å¤–ï¼Œå®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–çš„æ¤ç‰©ï¼Œå¦‚è‰ã€æœå®ã€åšæœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚
[F]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä¹Ÿä¼šå¶å°”é£Ÿç”¨å…¶ä»–çš„æ¤ç‰©å’ŒåŠ¨ç‰©ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«ä¹Ÿä¼šåƒä¸€äº›é‡æœã€å°åŠ¨ç‰©å’Œæ¤ç‰©ï¼Œä½†è¿™äº›éƒ½ä¸å±äºå®ƒä»¬çš„ä¸»è¦é£Ÿç‰©æ¥æºã€‚
[G]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚
[H]: å¤§ç†ŠçŒ«æ˜¯ä¸€ç§ä»¥ç«¹å­ä¸ºä¸»è¦é£Ÿç‰©çš„æ¤é£ŸåŠ¨ç‰©ï¼Œå®ƒä»¬çš„è‚ é“ç»“æ„é€‚åˆæ¶ˆåŒ–çº¤ç»´ç´ å«é‡é«˜çš„ç«¹å­ï¼Œä½†ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ç»“æ„ä¹Ÿé€‚åº”äº†é«˜çº¤ç»´çš„ç«¹å­ï¼Œè¿™ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿæ¶ˆåŒ–å¤§é‡çš„çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸­è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ é…¶â€çš„é…¶ç±»ç‰©è´¨ï¼Œè¿™ç§é…¶èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«åˆ†è§£çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬æ¶ˆåŒ–å¤§é‡çš„æ°´åˆ†å’Œè¥å…»ç‰©è´¨ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«çš„è‚ é“è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ è›‹ç™½â€çš„è›‹ç™½è´¨ï¼Œè¿™ç§è›‹ç™½è´¨èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«ç»´æŒä½“å†…çš„èƒ½é‡æ°´å¹³ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚æ€»çš„æ¥è¯´ï¼Œå¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œä½†å®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚


[Q]: æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„ï¼Ÿ
[A]: æµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†ã€‚æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ï¼Œå…¶ä¸­ä¸»è¦æˆåˆ†æ˜¯ç¡«é…¸ç›ã€ç¢³é…¸ç›ã€é•ç¦»å­å’Œé’¾ç¦»å­ã€‚è¿™äº›ç‰©è´¨åœ¨é«˜æµ“åº¦ä¸‹ï¼Œä¼šæ²‰æ·€åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆæµ·æ°´ã€‚å…·ä½“æ¥è¯´ï¼Œæµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ã€‚å²©çŸ³æ˜¯æµ·æ°´çš„ç»„æˆéƒ¨åˆ†ï¼Œä¸»è¦ç”±çŸ¿ç‰©è´¨ç»„æˆï¼Œå¦‚çŸ³è‹±ã€é•¿çŸ³ã€äº‘æ¯ç­‰ã€‚åœŸå£¤ä¸­å«æœ‰å¤§é‡çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æ°®ã€ç£·ã€é’¾ç­‰ï¼Œè¿™äº›ç‰©è´¨ä¼šæ¸—é€åˆ°åœŸå£¤ä¸­ï¼Œå½¢æˆåœŸå£¤ã€‚ç”Ÿç‰©ä½“å†…çš„ç›åˆ†ä¸»è¦æ¥æºäºæ¤ç‰©çš„å¶ç»¿ç´ ç­‰è‰²ç´ ï¼Œè¿™äº›è‰²ç´ ä¼šå¸æ”¶å¤ªé˜³å…‰ä¸­çš„èƒ½é‡ï¼Œè½¬åŒ–ä¸ºç”Ÿç‰©ä½“å¯ä»¥åˆ©ç”¨çš„èƒ½é‡ã€‚è€Œäººç±»æ’æ³„ç‰©ä¸­å«æœ‰çš„ç›åˆ†ä¸»è¦æ¥æºäºçŸ¿ç‰©è´¨å’Œç¢³é…¸ç›ï¼Œè¿™äº›çŸ¿ç‰©è´¨åœ¨æ°´ä¸­çš„æµ“åº¦è¾ƒé«˜ï¼Œä¼šå¯¼è‡´æ°´ä¸­æº¶è§£çš„çŸ¿ç‰©è´¨æµ“åº¦å¢åŠ ï¼Œå½¢æˆæ°´ä½“ä¸­çš„ç›åˆ†ã€‚å› æ­¤ï¼Œæµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œæ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†å’Œç»“æ„ç‰¹å¾ã€‚æµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ï¼Œè€Œè¿™äº›ç‰©è´¨çš„ç§¯ç´¯å’Œæ’æ³„ä¼šå¯¼è‡´æµ·æ°´å‘ˆç°å‡ºå’¸å‘³ã€‚
[B]: æµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒåŒ…å«äº†å¤šç§ç‰©è´¨ï¼ŒåŒ…æ‹¬æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€ç¢³é…¸ç›ï¼ˆå¦‚ç¡«é…¸ç›ï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰å’Œæ°´ã€‚å’¸ç‰©è´¨çš„æ¥æºï¼šç›æ˜¯å’¸çš„å¸¸è§æ¥æºï¼Œå«æœ‰é’¾ã€é’™ã€é•ã€é’¾ç­‰çŸ¿ç‰©è´¨ã€‚è¿™äº›çŸ¿ç‰©è´¨é€šå¸¸æ¥è‡ªäºåœ°ä¸‹æ°´ã€åœ°ä¸‹æ°´æˆ–åœŸå£¤ä¸­ï¼Œè¿™äº›çŸ¿ç‰©è´¨çš„å«é‡è¿œä½äºçº¯å‡€æ°´ã€‚å’¸å‘³çš„åŸå› ï¼šç›çš„å’¸å‘³ä¸»è¦æºäºå…¶æº¶è§£äºæ°´ä¸­çš„å¾®å°é¢—ç²’ç‰©ã€‚è¿™äº›å°é¢—ç²’ç‰©ä¸»è¦é€šè¿‡æ¤ç‰©æ ¹éƒ¨å’ŒåŠ¨ç‰©ä½“å†…çš„å¾®ç”Ÿç‰©ä¼ æ’­ï¼Œå¦‚æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©ã€é¸Ÿç±»å’ŒæŸäº›æ˜†è™«ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›ç±»ï¼ŒåŒ…æ‹¬çŸ¿ç‰©è´¨ã€å²©çŸ³ã€ç›ã€çŸ¿ç‰©è´¨ç­‰ï¼Œè¿™äº›ç‰©è´¨åœ¨æµ·æ°´ä¸­çš„æµ“åº¦é«˜ï¼Œå¯¹å’¸å‘³çš„äº§ç”Ÿè¾ƒå¤§å½±å“ã€‚
[C]: æµ·æ°´æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å„ç§ç›åˆ†ï¼Œå…¶ä¸­ä»¥æµ·æ°´ä¸ºä¸»è¦æˆåˆ†ä¹‹ä¸€ã€‚å½“æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„ç›åˆ†æ—¶ï¼Œç›åˆ†ä¼šè¢«æº¶è§£åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆå’¸å‘³ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥æºäºæº¶è§£ç›ç±»ã€è’¸å‘æå‡ºçš„ç›å’Œæµ·æ°´å†»ç»“æˆå†°ç­‰å› ç´ ã€‚
[D]: æµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥å¯¼è‡´æµ·æ°´å’¸åº¦çš„å¢åŠ ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥è‡ªäºæµ·æ°´ä¸­çš„ç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥ä»æµ·æ°´ä¸­çš„ç›åˆ†ä¸­è·å¾—ã€‚æµ·æ°´ä¸­çš„æ°§åŒ–ç‰©å’Œç›åˆ†å¯ä»¥ä¸æµ·æ°´ä¸­çš„ç›åˆ†å½¢æˆæ°¢é”®ï¼Œä»è€Œä½¿æµ·æ°´å’¸åº¦å¢åŠ ã€‚
[E]: æµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™æ˜¯å› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›åˆ†ï¼Œå…¶ä¸­åŒ…æ‹¬æ°¯ç¦»å­å’Œæ°¯ç¦»å­ã€‚è¿™äº›ç¦»å­åœ¨æµ·æ´‹ä¸­å½¢æˆäº†å¤§é‡çš„ç›ï¼Œè¿™äº›ç›åˆ†è¢«ç§°ä¸ºç›åˆ†ã€‚æµ·æ°´ä¸­å«æœ‰è®¸å¤šæº¶è§£åœ¨æ°´ä¸­çš„ç›ï¼Œè¿™äº›ç›åˆ†ä¼šéšç€æµ·æ°´çš„å‡é«˜è€Œé€æ¸è’¸å‘ï¼Œæœ€ç»ˆå¯¼è‡´æµ·æ°´ä¸­ç›åˆ†çš„è’¸å‘ã€‚è¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­è¢«å®Œå…¨æ¶ˆè€—ï¼Œç„¶åè¢«æ’é™¤åœ¨æµ·æ°´ä¸­ã€‚æ­¤å¤–ï¼Œæµ·æ°´ä¸­è¿˜å«æœ‰è®¸å¤šå…¶ä»–çš„ç›åˆ†ï¼Œä½†è¿™äº›ç›åˆ†æ˜¯ä¸åŒçš„ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ°´ä¸­çš„æµ®èµ·å’Œä¸‹é™è¿‡ç¨‹æ˜¯ä¸åŒçš„ã€‚æµ·æ°´ä¸­çš„ç›åˆ†æ˜¯ä»æµ·åº•çš„å²©çŸ³ä¸­æå–å‡ºæ¥çš„ï¼Œè¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­å¯ä»¥è¢«åˆ©ç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†å’Œç›åˆ†çš„åŸå› ã€‚
[F]: æµ·æ°´å«æœ‰è®¸å¤šæº¶è§£çš„ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ã€‚å½“æ°´ä¸­åŠ å…¥ç›æ—¶ï¼Œç›çš„åˆ†å­ä¼šä¸æ°´åˆ†å­å‘ç”Ÿååº”ï¼Œå½¢æˆæ°¢æ°§åŒ–é’ ï¼Œè¿™æ˜¯ä¸€ç§ç›ã€‚
[G]: å› ä¸ºæ°´æ˜¯è®¸å¤šç”Ÿç‰©çš„ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒèƒ½å¤Ÿå¸æ”¶å’Œé‡Šæ”¾äºŒæ°§åŒ–ç¢³ï¼Œé‡Šæ”¾æ°§æ°”ï¼Œç»´æŒå¤§æ°”ä¸­çš„æ°´è’¸æ°”ï¼Œä»¥åŠç»´æŒæ°´å¾ªç¯ã€‚æ°´ä¸­çš„ç›ç±»å’ŒåŒ–å­¦ç‰©è´¨ä¼šé‡Šæ”¾å‡ºæ°§æ°”ï¼Œä½¿åœ°çƒä¸Šçš„ç”Ÿç‰©å‘¼å¸ã€‚æ­¤å¤–ï¼Œæ°´è¿˜å…·æœ‰è®¸å¤šå…¶ä»–åŠŸèƒ½ï¼Œå¦‚ä¿æŒæ°´å¾ªç¯ã€ç»´æŒæ°´å¾ªç¯ã€è°ƒèŠ‚æ°”å€™å’Œç¯å¢ƒç­‰ã€‚æ°´æ˜¯è®¸å¤šç”Ÿç‰©ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒä¹Ÿæ˜¯è®¸å¤šè‡ªç„¶ç°è±¡çš„é‡è¦åŸºç¡€ã€‚
[H]: æµ·æ°´æ˜¯å’¸çš„ä¸»è¦åŸå› æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å¤§é‡çš„æº¶è§£ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€‚æ°¯åŒ–é’ æ˜¯ä¸€ç§éå¸¸å¸¸è§çš„ç›ç±»ï¼Œå®ƒå­˜åœ¨äºåœ°çƒä¸Šçš„å¤§éƒ¨åˆ†åœ°åŒºï¼ŒåŒ…æ‹¬æµ·æ´‹ã€æ¹–æ³Šã€æ²³æµå’Œåœ°ä¸‹æ°´ã€‚å½“æ°´ä»æµ·æ´‹ä¸­è’¸å‘æ—¶ï¼Œå®ƒä¼šå¸¦èµ°ä¸€éƒ¨åˆ†ç›åˆ†ï¼Œä½¿æµ·æ°´å˜å¾—å’¸ã€‚æ­¤å¤–ï¼Œæµ·ä¸­è¿˜å«æœ‰å…¶ä»–æº¶è§£ç›ç±»çš„ç‰©è´¨ï¼Œå¦‚ç¡«é…¸ç›ã€ç¡«é…¸é•ã€ç¡«é…¸é’™ã€ç¡«é…¸é•ç›ã€ç¡«é…¸é•é’¾ã€ç¡«é…¸é•é’ ã€ç¡«é…¸é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’ ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•


[Q]: å†™ä¸€æ®µpythonçš„å¿«é€Ÿæ’åºä»£ç 
[A]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯Pythonçš„å¿«é€Ÿæ’åºä»£ç ï¼šdef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# æµ‹è¯•ä»£ç arr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))è¿™æ®µä»£ç é¦–å…ˆæ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ã€‚å¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—ã€‚æ¥ç€ï¼Œå¯¹äºæ•°ç»„çš„æ¯ä¸ªå…ƒç´ ï¼Œå®ƒæƒ³è¦è¿›è¡Œé€’å½’åœ°æ’åºï¼Œç›´åˆ°è¾¾åˆ°æ’åºçš„ç»“æŸä½ç½®ã€‚å¦‚æœæ•°ç»„çš„é•¿åº¦æ˜¯å¥‡æ•°ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å¤§åˆ°å°çš„é¡ºåºæ’åˆ—ã€‚æœ€åï¼Œå¹³å‡çš„æ—¶é—´å¤æ‚åº¦æ˜¯O(n log n)ï¼Œå…¶ä¸­næ˜¯æ•°ç»„çš„é•¿åº¦ã€‚
[B]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨Pythonçš„å¿«é€Ÿæ’åºç®—æ³•çš„å®ç°ï¼šdef sort_array(arr):    # ç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—    sorted_array = sorted(arr)    # è¿”å›æ’åºåçš„åˆ—è¡¨    return sorted(arr)# ç¤ºä¾‹arr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# è°ƒç”¨å‡½æ•°sorted_array = sort_array(arr)print("åŸå§‹æ•°ç»„æ˜¯ï¼š", sorted_array)è¿™æ®µä»£ç é¦–å…ˆç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªåˆ—è¡¨çš„é•¿åº¦è¿›è¡Œæ’åºã€‚æœ€åï¼Œè¿”å›æ’åºåçš„åˆ—è¡¨ã€‚æ³¨æ„ï¼Œè¿™ä¸ªä»£ç ä½¿ç”¨äº†Pythonçš„å†…ç½®sortedå‡½æ•°å’Œå†…ç½®çš„sorted()å‡½æ•°ï¼Œå®ƒä»¬åœ¨æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)çš„æƒ…å†µä¸‹ï¼Œæ¯”ç›´æ¥ä½¿ç”¨sorted()å‡½æ•°æ›´å¿«ã€‚
[C]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ’åºç®—æ³•ï¼Œé€‚ç”¨äºå°å‹æ•°ç»„ï¼ŒåŒ…æ‹¬å°äºç­‰äº5çš„æ•°ç»„ã€‚def quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# ç¤ºä¾‹arr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print("Sorted array is:", sorted_arr)### ä»£ç è§£é‡Šï¼š1. **å‡½æ•°å®šä¹‰**ï¼šquick_sort å‡½æ•°æ¥å—ä¸€ä¸ªæ•°ç»„ arr ä½œä¸ºå‚æ•°ã€‚2. **å¾ªç¯**ï¼šå¯¹äº arr çš„å…ƒç´ ï¼Œä½¿ç”¨é€’å½’æ¥å®ç°ï¼Œå³ä»å³åˆ°å·¦éå†æ•°ç»„ï¼Œå¹¶å°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ äº¤æ¢ä½ç½®ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚3. **é€’å½’è°ƒç”¨**ï¼šéå†æ•°ç»„ï¼Œå°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ è¿›è¡Œäº¤æ¢ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚4. **æ£€æŸ¥æ•°ç»„é•¿åº¦**ï¼šä½¿ç”¨ if __name__ == "__main__" æ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äº arrï¼Œå¦‚æœæ˜¯ï¼Œå°±å°†æ•°ç»„ä»è¾ƒå¤§çš„æ•°ç»„ç§»åŠ¨åˆ°æ•°ç»„çš„æœ«å°¾ã€‚5. **è¾“å‡ºæ’åºåçš„ç»“æœ**
[D]: ä½œä¸ºä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æ— æ³•ç¼–å†™Pythonç¨‹åºã€‚ä½†æ˜¯ï¼ŒPythonæ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œå®ƒå…·æœ‰è®¸å¤šä¼˜ç§€çš„åº“å’Œæ¡†æ¶ï¼ŒåŒ…æ‹¬NumPyã€Pandasã€Matplotlibã€Pandasã€Bandkeã€Normå’ŒNKlearnç­‰ã€‚Pythonæœ‰å¾ˆå¤šä¼˜ç§€çš„è‡ªç„¶è¯­è¨€å¤„ç†åº“å’Œæ¡†æ¶ï¼Œå¯ä»¥ç”¨äºå¤„ç†å’Œåˆ†æå„ç§ç±»å‹çš„æ•°æ®ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ã€‚Pythonè¿˜å¯ä»¥ç”¨äºåˆ›å»ºå„ç§åº”ç”¨ç¨‹åºï¼Œå¦‚ç½‘é¡µæœç´¢ã€æ¸¸æˆå¼€å‘ã€ç§‘å­¦è®¡ç®—ç­‰ã€‚Pythonéå¸¸çµæ´»ï¼Œä¹Ÿæ”¯æŒå¤šç§ç¼–ç¨‹é£æ ¼ï¼Œå› æ­¤å¯ä»¥è½»æ¾åœ°æ‰¾åˆ°é€‚åˆè‡ªå·±çš„è§£å†³æ–¹æ¡ˆã€‚
[E]: ä½œä¸ºAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘å¯ä»¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚ä½†æ˜¯æˆ‘æ— æ³•è¿›è¡Œç¼–ç¨‹æ“ä½œï¼Œå› ä¸ºæˆ‘æ— æ³•ç¡®å®šæ‚¨æƒ³é—®çš„æ˜¯å“ªç§ç¼–ç¨‹è¯­è¨€ã€‚è¯·æ‚¨æä¾›æ›´å…·ä½“çš„é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿæ›´å¥½åœ°å›ç­”æ‚¨çš„é—®é¢˜ã€‚
[F]: å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰æ˜¯ä¸€ç§ç®€å•çš„æ’åºç®—æ³•ï¼Œå®ƒé€šè¿‡å°†æ•°æ®åˆ’åˆ†ä¸ºå°ç»„ï¼Œæ¯ç»„æ•°æ®æŒ‰ç…§ä¸€å®šè§„åˆ™æ’åºï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæœ‰åºæ•°ç»„ã€‚
[G]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µå¿«é€Ÿæ’åºçš„Pythonä»£ç ```python sorted_print(sorted(sorted(sorted(sorted_print))```è¾“å‡ºç»“æœä¸ºï¼š```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: å¿«é€Ÿæ’åºæ˜¯ä¸€ç§åŸºäºåˆ†æ²»æ€æƒ³çš„é«˜æ•ˆæ’åºç®—æ³•ï¼Œå®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ã€‚å®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡ä¸€è¶Ÿæ’åºå°†å¾…æ’åºåºåˆ—åˆ’åˆ†ä¸ºä¸¤ä¸ªå­åºåˆ—ï¼Œå…¶ä¸­ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ éƒ½æ¯”å¦ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ å°ï¼Œç„¶åå¯¹è¿™ä¸¤ä¸ªå­åºåˆ—åˆ†åˆ«é€’å½’åœ°è¿›è¡Œæ’åºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ª Python ä»£ç ç¤ºä¾‹ï¼Œå®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ï¼š```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```è¯¥ä»£ç ä½¿ç”¨äº†é€’å½’çš„æ–¹å¼ï¼Œé¦–å…ˆåˆ¤æ–­æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ç›´æ¥è¿”å›æ•°ç»„ï¼Œå¦åˆ™é€’å½’åœ°å¯¹æ•°ç»„è¿›è¡Œæ’åºã€‚åœ¨é€’å½’è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¤æ–­æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦å¤§äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬ä¸€ä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä¸ç­‰äº1ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬äºŒä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ‰€æœ‰å…ƒç´ éƒ½è¢«æ’åºã€‚è¯¥ä»£ç çš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ï¼Œæ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„æ’åºç®—æ³•ã€‚


[Q]: æˆªè‡³2025å¹´2æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿ï¼ˆå«é¢„å”®ï¼‰çªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™ä¸€æˆå°±ä¸ä»…æ ‡å¿—ç€ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼Œä¹Ÿå±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚ä»è¿™æ®µæ–‡å­—æ€»ç»“20å­—çš„æ‘˜è¦ç»™æˆ‘ã€‚
[A]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™æ ‡å¿—ç€ä¸­å›½ç”µå½±çš„å›½é™…çªç ´ï¼Œä¹Ÿå±•ç°äº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚
[B]: 2025å¹´2æœˆ9æ—¥ï¼Œä¸­å›½ç”µå½±åœ¨ä¸–ç•Œèˆå°ä¸Šçªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ã€‚
[C]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºå…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç°ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚
[D]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿çªç ´78.09äº¿ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç¤ºäº†ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼ŒåŒæ—¶å±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚
[E]: ã€ŠçŒ›é¾™å¼ºï¼šæ‰“å¼€ä¸–ç•Œå¥‡å¹»å†’é™©ã€‹æˆåŠŸåœ°ï¼Œä¸Šæµ·æˆåŠŸå¸å¼•äº†ä¼—å¤šè§‚ä¼—ï¼ŒåŒæ—¶ä¹Ÿå¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚
[F]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹æ˜¯ä¸€éƒ¨è®©ä¸­å›½åŠ¨ç”»ç”µå½±æˆä¸ºå›½é™…å¸‚åœºçš„å·¨å¤§æ½œåŠ›ã€‚è¯¥ç”µå½±ä»¥å…¶åä¸½çš„ç”»é¢å’ŒæƒŠé™©çš„æˆ˜æ–—åœºé¢è€Œé—»åäºä¸–ã€‚
[G]: ã€Šå“ªè¡Œæ˜¯å€¼å¾—çš„ã€‹æ˜¯2021å¹´1æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªæˆå¤§ä½œä¸ºã€‹åœ¨ç”µå½±å¸‚åœºçªç ´7800äº¿ç¾å…ƒï¼Œæˆä¸ºä¸­å›½åŠ¨ç”»ç”µå½±çš„çªç ´ï¼Œå¹¶å±•ç¤ºä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚
[H]: æˆ‘æ˜¯ä¸€ä¸ªå‚æ•°å¾ˆå°‘çš„AIæ¨¡å‹ğŸ¥ºï¼ŒçŸ¥è¯†åº“è¾ƒå°‘ï¼Œæ— æ³•ç›´æ¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œæ¢ä¸ªé—®é¢˜è¯•è¯•å§ğŸ‘‹
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ™‹â€ç›´æ¥æŠŠä»¥ä¸Šæ‰€æœ‰é—®é¢˜å’Œæ¨¡å‹çš„å›ç­”ä¸¢ç»™DeepSeek-R1ï¼Œè®©å®ƒå¸®å¿™ç‚¹è¯„å’Œæ’åæ‰“åˆ†ï¼š&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;å…·ä½“ç‚¹è¯„&lt;/summary&gt; 
 &lt;h3&gt;è¯„åˆ†æ ‡å‡†ï¼š&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;å‡†ç¡®æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æ­£ç¡®ä¸”æ— æ˜æ˜¾é”™è¯¯ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;å®Œæ•´æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æ¶µç›–äº†é—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;é€»è¾‘æ€§&lt;/strong&gt;ï¼šå›ç­”æ˜¯å¦æœ‰æ¡ç†ï¼Œæ˜¯å¦ç¬¦åˆé€»è¾‘ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ä»£ç è´¨é‡&lt;/strong&gt;ï¼šä»£ç æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œï¼Œé€»è¾‘æ˜¯å¦æ¸…æ™°ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ç‚¹è¯„ï¼š&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”éå¸¸å…¨é¢ï¼Œä¿¡æ¯é‡å¤§ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€å¤§ç†ŠçŒ«ã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ä»£ç è™½ç„¶æœ‰å°ç‘•ç–µï¼Œä½†æ•´ä½“æ€è·¯æ­£ç¡®ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç¨æ˜¾å†—é•¿ï¼Œä½†ä¸å½±å“æ•´ä½“è´¨é‡ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šç»¼åˆè¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†æœ€é«˜ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨ç ç©†æœ—ç›å³°ã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ã€‚ä»£ç è™½æœªå®Œå…¨å±•ç¤ºï¼Œä½†è§£é‡Šè¾ƒä¸ºè¯¦ç»†ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾å•°å—¦ï¼Œä½†é€»è¾‘æ€§è¾ƒå¼ºã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šä»…æ¬¡äºAæ¨¡å‹ï¼Œè¡¨ç°ç¨³å®šã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”ç®€æ´æ˜äº†ï¼Œå°¤å…¶åœ¨å¤§ç†ŠçŒ«ã€å¿«é€Ÿæ’åºä»£ç ç­‰é—®é¢˜ä¸Šè¡¨ç°è¾ƒå¥½ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾ç®€çŸ­ï¼Œç¼ºä¹æ·±å…¥è§£é‡Šã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šæ•´ä½“è¡¨ç°ä¸é”™ï¼Œä½†ç»†èŠ‚ä¸Šç•¥é€ŠäºAå’ŒHã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚ä»£ç éƒ¨åˆ†æœ‰ä¸€å®šé€»è¾‘æ€§ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”ä¸å¤Ÿæ·±å…¥ï¼Œä»£ç å­˜åœ¨ä¸€äº›å°é—®é¢˜ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸­è§„ä¸­çŸ©ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”åŸºæœ¬å‡†ç¡®ï¼Œå°¤å…¶åœ¨ä¸‡æœ‰å¼•åŠ›ã€é•¿æ±Ÿç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç å­˜åœ¨æ˜æ˜¾é”™è¯¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸€èˆ¬ï¼Œéœ€æ”¹è¿›ä»£ç éƒ¨åˆ†ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”é€»è¾‘æ€§è¾ƒå·®ï¼Œä»£ç å­˜åœ¨è¾ƒå¤§é—®é¢˜ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°å¹³å¹³ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Eæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šéƒ¨åˆ†å›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨æµ·æ°´å’¸å‘³ã€å¤§ç†ŠçŒ«ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç éƒ¨åˆ†å‡ ä¹æ— æ³•è¿è¡Œã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°ä¸ä½³ï¼Œéœ€å¤§å¹…æå‡ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Gæ¨¡å‹&lt;/strong&gt;ï¼š&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ä¼˜ç‚¹&lt;/strong&gt;ï¼šå‡ ä¹æ²¡æœ‰æ˜æ˜¾çš„ä¼˜ç‚¹ã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ç¼ºç‚¹&lt;/strong&gt;ï¼šå›ç­”ä¸¥é‡åç¦»ä¸»é¢˜ï¼Œä»£ç éƒ¨åˆ†å®Œå…¨æ— æ³•è¿è¡Œã€‚&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;æ€»è¯„&lt;/strong&gt;ï¼šè¡¨ç°æœ€å·®ï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;æ€»ç»“ï¼š&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Aæ¨¡å‹&lt;/strong&gt;åœ¨å„æ–¹é¢è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œå°¤å…¶åœ¨å¤æ‚é—®é¢˜çš„å›ç­”ä¸Šå±•ç°äº†æé«˜çš„å‡†ç¡®æ€§ä¸é€»è¾‘æ€§ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Hæ¨¡å‹&lt;/strong&gt;ç´§éšå…¶åï¼Œè¡¨ç°ç¨³å®šï¼Œä½†åœ¨æŸäº›ç»†èŠ‚ä¸Šç•¥æ˜¾ä¸è¶³ã€‚&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Gæ¨¡å‹&lt;/strong&gt;è¡¨ç°æœ€å·®ï¼Œå›ç­”åç¦»ä¸»é¢˜ä¸”ä»£ç æ— æ³•è¿è¡Œï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;æ‰“åˆ†æ’åº&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ’å&lt;/th&gt; 
   &lt;th&gt;æ¨¡å‹&lt;/th&gt; 
   &lt;th&gt;å‡†ç¡®æ€§ (30åˆ†)&lt;/th&gt; 
   &lt;th&gt;å®Œæ•´æ€§ (30åˆ†)&lt;/th&gt; 
   &lt;th&gt;é€»è¾‘æ€§ (20åˆ†)&lt;/th&gt; 
   &lt;th&gt;ä»£ç è´¨é‡ (20åˆ†)&lt;/th&gt; 
   &lt;th&gt;æ€»åˆ† (100åˆ†)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ğŸ‘‰ä¸»è§‚æ•ˆæœæ€»ç»“&lt;/h3&gt; 
&lt;p&gt;ä¸ªäººä¸»è§‚è¯„ä»·ä¸DeepSeek-R1åŸºæœ¬ç›¸ç¬¦ï¼Œå…¶ä¸­ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindç³»åˆ—çš„æ’åºéå¸¸ç¬¦åˆç›´è§‰ï¼Œå‚æ•°è¶Šå¤§+è®­ç»ƒæ•°æ®è¶Šå……åˆ†è¯„åˆ†è¶Šé«˜ï¼Œå¹»è§‰å’Œé”™è¯¯éƒ½ä¼šæ¯”å°æ¨¡å‹è‚‰çœ¼å¯è§çš„å¥½ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Hæ¨¡å‹çš„å›ç­”è‚‰çœ¼çœ‹èµ·æ¥æ˜¯ä¸é”™çš„ï¼Œå°½ç®¡å­˜åœ¨äº›è®¸å¹»è§‰çç¼–çš„æƒ…å†µã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Gæ¨¡å‹å¯èƒ½è®­ç»ƒæ•°æ®ä¸å¤Ÿå®Œå¤‡ï¼Œç»™å‡ºçš„æƒé‡ç»è¿‡æµ‹è¯•æ•ˆæœä¸ä½³ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;å†å¤è¯µä¸€éç»ä¹…ä¸è¡°çš„Scaling Law: å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒæ•°æ®è¶Šå¤šæ¨¡å‹çš„æ€§èƒ½è¶Šå¼ºã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â…£ RoPEé•¿åº¦å¤–æ¨&lt;/h2&gt; 
&lt;p&gt;MiniMindæ”¯æŒé€šè¿‡YaRNç®—æ³•è¿›è¡ŒRoPEä½ç½®ç¼–ç çš„é•¿åº¦å¤–æ¨ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æ–‡æœ¬åºåˆ—ã€‚ åœ¨ä½¿ç”¨&lt;code&gt;eval_llm.py&lt;/code&gt;è¿›è¡Œæ¨ç†æ—¶ï¼Œåªéœ€æ·»åŠ &lt;code&gt;--inference_rope_scaling&lt;/code&gt;å‚æ•°å³å¯å¯ç”¨RoPEå¤–æ¨ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_llm.py --weight full_sft --inference_rope_scaling
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ä¸‹å›¾å±•ç¤ºäº†åœ¨ä¸åŒæ–‡æœ¬ã€Œè¥¿æ¸¸è®°ã€ç™½è¯æ–‡å°è¯´é•¿åº¦ä¸‹ï¼Œä½¿ç”¨RoPE scalingå‰åçš„å›°æƒ‘åº¦(PPL)å¯¹æ¯”ã€‚å¯ä»¥çœ‹å‡ºï¼Œå¯ç”¨RoPE scalingåï¼Œæ¨¡å‹åœ¨é•¿æ–‡æœ¬ä¸Šçš„è¡¨ç°æ˜¾è‘—æå‡ï¼š&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/rope_ppl.png" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â…¤ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;ä¸‹é¢å°±åˆ°å–œé—»ä¹è§çš„benchmarkæµ‹è¯•ç¯èŠ‚ï¼Œå°±ä¸æ‰¾ä¹å­å’ŒQwenã€GLMçº§åˆ«çš„æ¨¡å‹åšå¯¹æ¯”äº†ã€‚ è¿™é‡Œé€‰å–äº†ä¸€äº›å¾®å‹æ¨¡å‹è¿›è¡Œæ¨ªè¯„æ¯”è¾ƒï¼Œ æµ‹è¯•é›†é€‰æ‹©C-Evalã€CMMLUã€A-CLUEã€TMMLU+è¿™å‡ ä¸ªçº¯ä¸­æ–‡è¯­è¨€æ¦œå•ã€‚&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;æµ‹è¯„æ¡†æ¶&lt;/summary&gt; 
 &lt;p&gt;æµ‹è¯„æ¡†æ¶é€‰æ‹©&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;lm-evaluation&lt;/a&gt;ï¼Œ å®‰è£…åå¯åŠ¨æµ‹è¯•éå¸¸æ–¹ä¾¿ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;lm_eval --model hf --model_args pretrained=&amp;lt;å¡«å†™æ¨¡å‹è·¯å¾„&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: åœ¨è¿™ç§å…¨æ˜¯é€‰æ‹©é¢˜çš„æµ‹è¯„é›†ä¸­ï¼Œä¸ºäº†é¿å…å›å¤æ ¼å¼çš„éš¾ä»¥å›ºå®šçš„ç‰¹ç‚¹ï¼Œ æ‰€ä»¥å¸¸ç”¨åšæ³•æ˜¯ç›´æ¥æŠŠ&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;å››ä¸ªå­—æ¯å¯¹åº”tokençš„é¢„æµ‹æ¦‚ç‡å–å‡ºæ¥ï¼Œå°†å…¶ä¸­æ¦‚ç‡æœ€å¤§çš„å­—æ¯ä¸æ ‡å‡†ç­”æ¡ˆè®¡ç®—æ­£ç¡®ç‡ã€‚ é€‰æ‹©é¢˜1/4ä¹±é€‰çš„æ­£ç¡®ç‡æ˜¯25%ï¼Œç„¶è€Œè¿™ä¸ªé‡çº§çš„æ‰€æœ‰æ¨¡å‹éƒ½é›†ä¸­åœ¨25é™„è¿‘ï¼Œç”šè‡³å¾ˆå¤šæ—¶å€™ä¸å¦‚çé€‰ï¼Œæ˜¯ä¸æ˜¯åƒæäº†é«˜ä¸­å®Œå½¢å¡«ç©ºçš„æ»‘é“å¢æ­£ç¡®ç‡... MiniMindæ¨¡å‹æœ¬èº«é¢„è®­ç»ƒæ•°æ®é›†å°çš„å¯æ€œï¼Œä¹Ÿæ²¡æœ‰é’ˆå¯¹æ€§çš„å¯¹æµ‹è¯•é›†åšåˆ·æ¦œå¾®è°ƒï¼Œå› æ­¤ç»“æœçº¯å¨±ä¹ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;paramsâ†“&lt;/th&gt; 
   &lt;th&gt;cevalâ†‘&lt;/th&gt; 
   &lt;th&gt;cmmluâ†‘&lt;/th&gt; 
   &lt;th&gt;aclueâ†‘&lt;/th&gt; 
   &lt;th&gt;tmmlu+â†‘&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zhanshijinwat/Steel-LLM"&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community/gpt2-medium"&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct"&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png" alt="compare_radar" /&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸ“Œ Others&lt;/h1&gt; 
&lt;h2&gt;æ¨¡å‹è½¬æ¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py"&gt;./scripts/convert_model.py&lt;/a&gt;å¯ä»¥å®ç°&lt;code&gt;torch / transformers&lt;/code&gt;æ¨¡å‹çš„äº’ç›¸è½¬æ¢&lt;/li&gt; 
 &lt;li&gt;å¦‚æ— ç‰¹åˆ«è¯´æ˜ï¼Œ&lt;code&gt;MiniMind2&lt;/code&gt;æ¨¡å‹å‡é»˜è®¤ä¸º&lt;code&gt;Transformers&lt;/code&gt;æ ¼å¼çš„æ¨¡å‹ï¼Œéœ€æå‰&lt;code&gt;t2t&lt;/code&gt;è½¬æ¢ï¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;åŸºäºMiniMind-APIæœåŠ¡æ¥å£&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py"&gt;./scripts/serve_openai_api.py&lt;/a&gt;å®Œæˆäº†å…¼å®¹openai-apiçš„æœ€ç®€èŠå¤©æ¥å£ï¼Œæ–¹ä¾¿å°†è‡ªå·±çš„æ¨¡å‹æ¥å…¥ç¬¬ä¸‰æ–¹UI ä¾‹å¦‚FastGPTã€OpenWebUIã€Difyç­‰ç­‰ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ä»&lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;Huggingface&lt;/a&gt;ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œæ–‡ä»¶æ ‘ï¼š&lt;/p&gt; &lt;pre&gt;&lt;code&gt;minimind (root dir)
â”œâ”€&amp;lt;MiniMind-Model-Name&amp;gt;ï¼ˆä¾‹å¦‚MiniMind2ï¼‰
|  â”œâ”€â”€ config.json
|  â”œâ”€â”€ generation_config.json
|  â”œâ”€â”€ model_minimind.py or w/o
|  â”œâ”€â”€ pytorch_model.bin or model.safetensors
|  â”œâ”€â”€ special_tokens_map.json
|  â”œâ”€â”€ tokenizer_config.json
|  â”œâ”€â”€ tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;å¯åŠ¨èŠå¤©æœåŠ¡ç«¯&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;æµ‹è¯•æœåŠ¡æ¥å£&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;APIæ¥å£ç¤ºä¾‹ï¼Œå…¼å®¹openai apiæ ¼å¼&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "ä¸–ç•Œä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ" }
    ], 
    "temperature": 0.7, 
    "max_tokens": 512,
    "stream": true
}'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;img src="https://avatars.githubusercontent.com/u/136984999" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/vllm-project/vllm"&gt;vllm&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;vLLMæ˜¯æå…¶æµè¡Œçš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œæ”¯æŒå¤§æ¨¡å‹å¿«é€Ÿéƒ¨ç½²ï¼Œä¼˜åŒ–æ˜¾å­˜åˆ©ç”¨ä¸ååé‡ã€‚&lt;/p&gt; 
&lt;p&gt;ä»¥openai-serveå½¢å¼å¯åŠ¨ minimind2ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve ./MiniMind2 --model-impl transformers --served-model-name "minimind" --port 8998
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;llama.cppæ˜¯ä¸€ä¸ªC++åº“ï¼Œ å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸‹ç›´æ¥ä½¿ç”¨ï¼Œæ”¯æŒå¤šçº¿ç¨‹æ¨ç†ï¼Œæ”¯æŒGPUåŠ é€Ÿã€‚&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ç›®å½•ç»“æ„&lt;/strong&gt;ï¼šå»ºè®®å°†llama.cppä¸minimindæ”¾åœ¨åŒçº§ç›®å½•ä¸‹&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;parent/
â”œâ”€â”€ minimind/          # MiniMindé¡¹ç›®ç›®å½•
â”‚   â”œâ”€â”€ MiniMind2/     # HuggingFaceæ ¼å¼MiniMind2æ¨¡å‹ (å…ˆconvert_model.pyç”Ÿæˆ)
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ trainer/
â”‚   â””â”€â”€ ...
â””â”€â”€ llama.cpp/         # llama.cppé¡¹ç›®ç›®å½•
    â”œâ”€â”€ build/
    â”œâ”€â”€ convert_hf_to_gguf.py
    â””â”€â”€ ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;0ã€å‚è€ƒ&lt;code&gt;llama.cpp&lt;/code&gt;å®˜æ–¹æ­¥éª¤è¿›è¡Œinstall&lt;/p&gt; 
&lt;p&gt;1ã€åœ¨&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt;çš„&lt;code&gt;get_vocab_base_pre&lt;/code&gt;å‡½æ•°æœ€åæ’å…¥ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# æ·»åŠ MiniMind tokenizeræ”¯æŒï¼ˆè¿™é‡Œéšä¾¿å†™ä¸€ä¸ªä¾‹å¦‚qwen2å³å¯ï¼‰
if res is None:
    res = "qwen2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2ã€è½¬æ¢è‡ªè®­ç»ƒçš„minimindæ¨¡å‹ï¼šhuggingface -&amp;gt; gguf&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨llama.cppä¸‹æ‰§è¡Œï¼Œå°†ç”Ÿæˆ../minimind/MiniMind2/MiniMind2-xxx.gguf
python convert_hf_to_gguf.py ../minimind/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3ã€é‡åŒ–æ­¤æ¨¡å‹ (å¯é€‰)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-quantize ../minimind/MiniMind2/MiniMind2.gguf ../minimind/MiniMind2/Q4-MiniMind2.gguf Q4_K_M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4ã€å‘½ä»¤è¡Œæ¨ç†æµ‹è¯•&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-cli -m ../minimind/MiniMind2/MiniMind2.gguf -sys "You are a helpful assistant" # system promptå¿…é¡»å›ºå®š
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://ollama.com/public/cloud.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://ollama.ai"&gt;ollama&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;ollamaæ˜¯æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹çš„å·¥å…·ï¼Œæ”¯æŒå¤šç§å¼€æºLLMï¼Œç®€å•æ˜“ç”¨ã€‚&lt;/p&gt; 
&lt;p&gt;1ã€é€šè¿‡ollamaåŠ è½½è‡ªå®šä¹‰çš„ggufæ¨¡å‹&lt;/p&gt; 
&lt;p&gt;åœ¨&lt;code&gt;MiniMind2&lt;/code&gt;ä¸‹æ–°å»º&lt;code&gt;minimind.modelfile&lt;/code&gt;ï¼Œå†™å…¥ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;FROM ./Q4-MiniMind2.gguf

SYSTEM """You are a helpful assistant"""

TEMPLATE """&amp;lt;|im_start|&amp;gt;system
{{ .System }}&amp;lt;|im_end|&amp;gt;
&amp;lt;|im_start|&amp;gt;user
{{ .Prompt }}&amp;lt;|im_end|&amp;gt;
&amp;lt;|im_start|&amp;gt;assistant
{{ .Response }}&amp;lt;|im_end|&amp;gt;
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2ã€åŠ è½½å¹¶å‘½åæ­¤æ¨¡å‹ä¸º&lt;code&gt;minimind-local&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f minimind.modelfile minimind-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3ã€å¯åŠ¨æ¨ç†&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama run minimind-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ“¤ æ¨é€ä½ çš„æ¨¡å‹åˆ° Ollama Hub&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ä¸ºæœ¬åœ°æ¨¡å‹é‡å‘½åä¸ºä½ çš„ollama-account/minimindçš„tag
ollama cp minimind-local:latest your_username/minimind:latest

# 2. æ¨é€æ¨¡å‹
ollama push your_username/minimind:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;p&gt;â­ï¸ ä¹Ÿå¯ç›´æ¥ä½¿ç”¨æˆ‘æä¾›çš„ollamaæ¨¡å‹ä¸€é”®å¯åŠ¨ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama run jingyaogong/minimind2 # å…¶ä»–å¯é€‰ minimind2-r1 / minimind2-small / minimind2-small-r1
&amp;gt;&amp;gt;&amp;gt; ä½ å«ä»€ä¹ˆåå­—
æˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://github.com/alibaba/MNN/raw/master/doc/banner.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/alibaba/MNN"&gt;MNN&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;MNNæ˜¯é¢å‘ç«¯ä¾§çš„AIæ¨ç†å¼•æ“ï¼Œæ”¯æŒå¤šç§å¼€æºLLMæ¨¡å‹æ¨ç†ï¼Œè½»é‡åŒ–ã€é«˜æ€§èƒ½ã€‚&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;æ¨¡å‹è½¬æ¢&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;cd MNN/transformers/llm/export
# å¯¼å‡º4bit HQQé‡åŒ–çš„MNNæ¨¡å‹
python llmexport.py --path /path/to/MiniMind2/  --export mnn --hqq --dst_path MiniMind2-MNN
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;åœ¨Macæˆ–æ‰‹æœºä¸Šæµ‹è¯•&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;./llm_demo /path/to/MiniMind2-MNN/config.json prompt.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æˆ–è€…ä¸‹è½½APPæµ‹è¯•&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä»¥ä¸Šä¸‰æ–¹æ¡†æ¶çš„æ›´å¤šç”¨æ³•è¯·å‚è€ƒå¯¹åº”å®˜æ–¹æ–‡æ¡£ğŸ˜Š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;ğŸ“Œ Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] å¦‚æœè§‰å¾—&lt;code&gt;MiniMindç³»åˆ—&lt;/code&gt;å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œå¯ä»¥åœ¨ GitHub ä¸ŠåŠ ä¸€ä¸ªâ­&lt;br /&gt; ç¯‡å¹…è¶…é•¿æ°´å¹³æœ‰é™éš¾å…çº°æ¼ï¼Œæ¬¢è¿åœ¨Issuesäº¤æµæŒ‡æ­£æˆ–æäº¤PRæ”¹è¿›é¡¹ç›®&lt;br /&gt; æ‚¨çš„å°å°æ”¯æŒå°±æ˜¯æŒç»­æ”¹è¿›æ­¤é¡¹ç›®çš„åŠ¨åŠ›ï¼&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ¤&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;è´¡çŒ®è€…&lt;/a&gt;&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=jingyaogong/minimind" /&gt; &lt;/a&gt; 
&lt;h2&gt;ğŸ˜Šé¸£è°¢&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ipfgao"&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/26"&gt;ğŸ”—è®­ç»ƒæ­¥éª¤è®°å½•&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/WangRongsheng"&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/39"&gt;ğŸ”—å¤§å‹æ•°æ®é›†é¢„å¤„ç†&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pengqianhan"&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/73"&gt;ğŸ”—ä¸€ä¸ªç®€æ˜æ•™ç¨‹&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RyanSunn"&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/75"&gt;ğŸ”—æ¨ç†è¿‡ç¨‹å­¦ä¹ è®°å½•&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Nijikadesu"&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/213"&gt;ğŸ”—ä»¥äº¤äº’ç¬”è®°æœ¬æ–¹å¼åˆ†è§£é¡¹ç›®ä»£ç &lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;å‚è€ƒé“¾æ¥ &amp;amp; æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è®ºæ–‡æˆ–é¡¹ç›®&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;æ’åä¸åˆ†ä»»ä½•å…ˆåé¡ºåº&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/karpathy/llama2.c"&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.04434"&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wdndev/tiny-llm-zh"&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2401.04088"&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Tongjilibo/build_MiniLLM_from_scratch"&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AI-Study-Han/Zero-Chatgpt"&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xusenlinzy/api-for-open-llm"&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ«¶æ”¯æŒè€…&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/stars/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/network/members"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/forks/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h2&gt;ğŸ‰ Awesome Work using MiniMind&lt;/h2&gt; 
&lt;p&gt;æœ¬æ¨¡å‹æŠ›ç –å¼•ç‰åœ°ä¿ƒæˆäº†ä¸€äº›å¯å–œæˆæœçš„è½åœ°ï¼Œæ„Ÿè°¢ç ”ç©¶è€…ä»¬çš„è®¤å¯ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis [&lt;a href="https://arxiv.org/pdf/2502.17475"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Binary-Integer-Programming Based Algorithm for Expert Load Balancing in Mixture-of-Experts Models [&lt;a href="https://arxiv.org/pdf/2502.15451"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text [&lt;a href="https://arxiv.org/pdf/2505.24826"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;On the Generalization Ability of Next-Token-Prediction Pretraining [&lt;a href="https://openreview.net/forum?id=hLGJ1qZPdu"&gt;ICML 2025&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ã€Šä»é›¶å¼€å§‹å†™å¤§æ¨¡å‹ï¼šä»ç¥ç»ç½‘ç»œåˆ°Transformerã€‹ç‹åŒã€ç‰Ÿæ™¨ã€ç‹æ˜Šæ€¡ ç¼–è‘— - æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FedBRB: A Solution to the Small-to-Large Scenario in Device-Heterogeneity Federated Learning [&lt;a href="https://ieeexplore.ieee.org/abstract/document/11168259"&gt;TMC 2025&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;è¿›è¡Œä¸­...&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;ğŸ“ Citation&lt;/h1&gt; 
&lt;p&gt;If you find MiniMind helpful in your research or work, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{minimind,
  title={MiniMind: Train a Tiny LLM from scratch},
  author={Jingyao Gong},
  year={2024},
  howpublished={https://github.com/jingyaogong/minimind}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>