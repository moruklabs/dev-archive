<rss version="2.0">
  <channel>
    <title>GitHub Go Weekly Trending</title>
    <description>Weekly Trending of Go in GitHub</description>
    <pubDate>Sun, 02 Nov 2025 01:41:25 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dlvhdr/gh-dash</title>
      <link>https://github.com/dlvhdr/gh-dash</link>
      <description>&lt;p&gt;A rich terminal UI for GitHub that doesn't break your flow.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a class="underline: none;" href="https://gh-dash.dev"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/public/logo.png" /&gt; 
   &lt;img alt="Text changing depending on mode. Light: 'So light!' Dark: 'So dark!'" width="600" src="https://raw.githubusercontent.com/dlvhdr/gh-dash/main/docs/public/logo-light.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://gh-dash.dev" target="_blank"&gt;‚Üí https://gh-dash.dev ‚Üê&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; A rich terminal UI for GitHub that doesn't break your flow. &lt;br /&gt; &lt;br /&gt; &lt;a href="https://github.com/dlvhdr/gh-dash/releases"&gt;&lt;img src="https://img.shields.io/github/release/dlvhdr/gh-dash.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/SXNXp9NctV"&gt;&lt;img src="https://img.shields.io/discord/1413193703476035755?label=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/dlvhdr"&gt;&lt;img src="https://img.shields.io/github/sponsors/dlvhdr?logo=githubsponsors&amp;amp;color=EA4AAA" /&gt;&lt;/a&gt; &lt;a href="https://www.jetify.com/devbox/docs/contributor-quickstart/" alt="Built with Devbox"&gt;&lt;img src="https://www.jetify.com/img/devbox/shield_galaxy.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;img src="https://raw.githubusercontent.com/dlvhdr/gh-dash/main/docs/src/assets/overview.gif" /&gt; 
&lt;h2&gt;üìÉ Docs&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;dash&lt;/code&gt; has an extensive docs site at &lt;a href="https://gh-dash.dev/getting-started"&gt;gh-dash.dev/getting-started&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ù§Ô∏è Donating&lt;/h2&gt; 
&lt;p&gt;If you enjoy &lt;code&gt;dash&lt;/code&gt; and want to help, consider supporting the project with a donation at the &lt;a href="https://github.com/sponsors/dlvhdr"&gt;sponsors page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Discord&lt;/h2&gt; 
&lt;p&gt;Have questions? Join our &lt;a href="https://discord.gg/SXNXp9NctV"&gt;Discord community&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;üôè Contributing&lt;/h2&gt; 
&lt;p&gt;See the contribution guide at &lt;a href="https://www.gh-dash.dev/contributing/"&gt;https://www.gh-dash.dev/contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üõû Under the hood&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;dash&lt;/code&gt; uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/bubbletea"&gt;bubbletea&lt;/a&gt; for the TUI&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/lipgloss"&gt;lipgloss&lt;/a&gt; for the styling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/glamour"&gt;glamour&lt;/a&gt; for rendering markdown&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/vhs"&gt;vhs&lt;/a&gt; for generating the GIF&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spf13/cobra"&gt;cobra&lt;/a&gt; for the CLI&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cli/cli"&gt;gh&lt;/a&gt; for the GitHub functionality&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dandavison/delta"&gt;delta&lt;/a&gt; for viewing PR diffs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Author&lt;/h2&gt; 
&lt;p&gt;Dolev Hadar &lt;a href="https://github.com/dlvhdr"&gt;@dlvhdr&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helm/helm</title>
      <link>https://github.com/helm/helm</link>
      <description>&lt;p&gt;The Kubernetes Package Manager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Helm&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/helm/helm/actions?workflow=release"&gt;&lt;img src="https://github.com/helm/helm/workflows/release/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/helm.sh/helm/v4"&gt;&lt;img src="https://goreportcard.com/badge/helm.sh/helm/v4" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/helm.sh/helm/v4"&gt;&lt;img src="https://img.shields.io/static/v1?label=godoc&amp;amp;message=reference&amp;amp;color=blue" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/3131"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/3131/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/helm/helm"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/helm/helm/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/helm"&gt;&lt;img src="https://insights.production.lfx.dev/api/badge/health-score?project=helm" alt="LFX Health Score" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.&lt;/p&gt; 
&lt;p&gt;Use Helm to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Find and use &lt;a href="https://artifacthub.io/packages/search?kind=0"&gt;popular software packaged as Helm Charts&lt;/a&gt; to run in Kubernetes&lt;/li&gt; 
 &lt;li&gt;Share your own applications as Helm Charts&lt;/li&gt; 
 &lt;li&gt;Create reproducible builds of your Kubernetes applications&lt;/li&gt; 
 &lt;li&gt;Intelligently manage your Kubernetes manifest files&lt;/li&gt; 
 &lt;li&gt;Manage releases of Helm packages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm in a Handbasket&lt;/h2&gt; 
&lt;p&gt;Helm is a tool that streamlines installing and managing Kubernetes applications. Think of it like apt/yum/homebrew for Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm renders your templates and communicates with the Kubernetes API&lt;/li&gt; 
 &lt;li&gt;Helm runs on your laptop, CI/CD, or wherever you want it to run.&lt;/li&gt; 
 &lt;li&gt;Charts are Helm packages that contain at least two things: 
  &lt;ul&gt; 
   &lt;li&gt;A description of the package (&lt;code&gt;Chart.yaml&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;One or more templates, which contain Kubernetes manifest files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Charts can be stored on disk, or fetched from remote chart repositories (like Debian or RedHat packages)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm Development and Stable Versions&lt;/h2&gt; 
&lt;p&gt;Helm v4 is currently under development on the &lt;code&gt;main&lt;/code&gt; branch. This is unstable and the APIs within the Go SDK and at the command line are changing. Helm v3 (current stable) is maintained on the &lt;code&gt;dev-v3&lt;/code&gt; branch. APIs there follow semantic versioning.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Binary downloads of the Helm client can be found on &lt;a href="https://github.com/helm/helm/releases/latest"&gt;the Releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unpack the &lt;code&gt;helm&lt;/code&gt; binary and add it to your PATH and you are good to go!&lt;/p&gt; 
&lt;p&gt;If you want to use a package manager:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt; users can use &lt;code&gt;brew install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt; users can use &lt;code&gt;choco install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/windows/package-manager/"&gt;Winget&lt;/a&gt; users can use &lt;code&gt;winget install Helm.Helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://scoop.sh/"&gt;Scoop&lt;/a&gt; users can use &lt;code&gt;scoop install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://snapcraft.io/"&gt;Snapcraft&lt;/a&gt; users can use &lt;code&gt;snap install helm --classic&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev"&gt;Flox&lt;/a&gt; users can use &lt;code&gt;flox install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To rapidly get Helm up and running, start with the &lt;a href="https://helm.sh/docs/intro/quickstart/"&gt;Quick Start Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://helm.sh/docs/intro/install/"&gt;installation guide&lt;/a&gt; for more options, including installing pre-releases.&lt;/p&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;p&gt;Get started with the &lt;a href="https://helm.sh/docs/intro/quickstart/"&gt;Quick Start guide&lt;/a&gt; or plunge into the &lt;a href="https://helm.sh/docs"&gt;complete documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/helm/helm/milestones"&gt;Helm roadmap uses GitHub milestones&lt;/a&gt; to track the progress of the project.&lt;/p&gt; 
&lt;p&gt;The development of Helm v4 is currently happening on the &lt;code&gt;main&lt;/code&gt; branch while the development of Helm v3, the stable branch, is happening on the &lt;code&gt;dev-v3&lt;/code&gt; branch. Changes should be made to the &lt;code&gt;main&lt;/code&gt; branch prior to being added to the &lt;code&gt;dev-v3&lt;/code&gt; branch so that all changes are carried along to Helm v4.&lt;/p&gt; 
&lt;h2&gt;Community, discussion, contribution, and support&lt;/h2&gt; 
&lt;p&gt;You can reach the Helm community and developers via the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kubernetes.slack.com"&gt;Kubernetes Slack&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/helm-users"&gt;#helm-users&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/helm-dev"&gt;#helm-dev&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/charts"&gt;#charts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Mailing List: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://lists.cncf.io/g/cncf-helm"&gt;Helm Mailing List&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Developer Call: Thursdays at 9:30-10:00 Pacific (&lt;a href="https://github.com/helm/community/raw/master/communication.md#meetings"&gt;meeting details&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing, please refer to the &lt;a href="https://raw.githubusercontent.com/helm/helm/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; &lt;strong&gt;before submitting a pull request&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Code of conduct&lt;/h3&gt; 
&lt;p&gt;Participation in the Helm community is governed by the &lt;a href="https://raw.githubusercontent.com/helm/helm/main/code-of-conduct.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>go-gitea/gitea</title>
      <link>https://github.com/go-gitea/gitea</link>
      <description>&lt;p&gt;Git with a cup of tea! Painless self-hosted all-in-one software development service, including Git hosting, code review, team collaboration, package registry and CI/CD&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gitea&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml?query=branch%3Amain" title="Release Nightly"&gt;&lt;img src="https://github.com/go-gitea/gitea/actions/workflows/release-nightly.yml/badge.svg?branch=main" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Gitea" title="Join the Discord chat at https://discord.gg/Gitea"&gt;&lt;img src="https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=5865F2" alt="" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/code.gitea.io/gitea" title="Go Report Card"&gt;&lt;img src="https://goreportcard.com/badge/code.gitea.io/gitea" alt="" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/code.gitea.io/gitea" title="GoDoc"&gt;&lt;img src="https://pkg.go.dev/badge/code.gitea.io/gitea?status.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/go-gitea/gitea/releases/latest" title="GitHub release"&gt;&lt;img src="https://img.shields.io/github/release/go-gitea/gitea.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/go-gitea/gitea" title="Help Contribute to Open Source"&gt;&lt;img src="https://www.codetriage.com/go-gitea/gitea/badges/users.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea" title="Become a backer/sponsor of gitea"&gt;&lt;img src="https://opencollective.com/gitea/tiers/backers/badge.svg?label=backers&amp;amp;color=brightgreen" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT" title="License: MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://gitpod.io/#https://github.com/go-gitea/gitea"&gt;&lt;img src="https://img.shields.io/badge/Contribute%20with-Gitpod-908a85?logo=gitpod&amp;amp;color=green" alt="Contribute with Gitpod" /&gt;&lt;/a&gt; &lt;a href="https://translate.gitea.com" title="Crowdin"&gt;&lt;img src="https://badges.crowdin.net/gitea/localized.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/go-gitea/gitea/main/README.zh-tw.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/go-gitea/gitea/main/README.zh-cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Purpose&lt;/h2&gt; 
&lt;p&gt;The goal of this project is to make the easiest, fastest, and most painless way of setting up a self-hosted Git service.&lt;/p&gt; 
&lt;p&gt;As Gitea is written in Go, it works across &lt;strong&gt;all&lt;/strong&gt; the platforms and architectures that are supported by Go, including Linux, macOS, and Windows on x86, amd64, ARM and PowerPC architectures. This project has been &lt;a href="https://blog.gitea.com/welcome-to-gitea/"&gt;forked&lt;/a&gt; from &lt;a href="https://gogs.io"&gt;Gogs&lt;/a&gt; since November of 2016, but a lot has changed.&lt;/p&gt; 
&lt;p&gt;For online demonstrations, you can visit &lt;a href="https://demo.gitea.com"&gt;demo.gitea.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For accessing free Gitea service (with a limited number of repositories), you can visit &lt;a href="https://gitea.com/user/login"&gt;gitea.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To quickly deploy your own dedicated Gitea instance on Gitea Cloud, you can start a free trial at &lt;a href="https://cloud.gitea.com"&gt;cloud.gitea.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can find comprehensive documentation on our official &lt;a href="https://docs.gitea.com/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;It includes installation, administration, usage, development, contributing guides, and more to help you get started and explore all features effectively.&lt;/p&gt; 
&lt;p&gt;If you have any suggestions or would like to contribute to it, you can visit the &lt;a href="https://gitea.com/gitea/docs"&gt;documentation repository&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;From the root of the source tree, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;TAGS="bindata" make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or if SQLite support is required:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;TAGS="bindata sqlite sqlite_unlock_notify" make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;build&lt;/code&gt; target is split into two sub-targets:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make backend&lt;/code&gt; which requires &lt;a href="https://go.dev/dl/"&gt;Go Stable&lt;/a&gt;, the required version is defined in &lt;a href="https://raw.githubusercontent.com/go-gitea/gitea/main/go.mod"&gt;go.mod&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make frontend&lt;/code&gt; which requires &lt;a href="https://nodejs.org/en/download/"&gt;Node.js LTS&lt;/a&gt; or greater and &lt;a href="https://pnpm.io/installation"&gt;pnpm&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Internet connectivity is required to download the go and npm modules. When building from the official source tarballs which include pre-built frontend files, the &lt;code&gt;frontend&lt;/code&gt; target will not be triggered, making it possible to build without Node.js.&lt;/p&gt; 
&lt;p&gt;More info: &lt;a href="https://docs.gitea.com/installation/install-from-source"&gt;https://docs.gitea.com/installation/install-from-source&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Using&lt;/h2&gt; 
&lt;p&gt;After building, a binary file named &lt;code&gt;gitea&lt;/code&gt; will be generated in the root of the source tree by default. To run it, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./gitea web
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you're interested in using our APIs, we have experimental support with &lt;a href="https://docs.gitea.com/api"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Expected workflow is: Fork -&amp;gt; Patch -&amp;gt; Push -&amp;gt; Pull Request&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;YOU MUST READ THE &lt;a href="https://raw.githubusercontent.com/go-gitea/gitea/main/CONTRIBUTING.md"&gt;CONTRIBUTORS GUIDE&lt;/a&gt; BEFORE STARTING TO WORK ON A PULL REQUEST.&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;If you have found a vulnerability in the project, please write privately to &lt;strong&gt;&lt;a href="mailto:security@gitea.io"&gt;security@gitea.io&lt;/a&gt;&lt;/strong&gt;. Thanks!&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Translating&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://translate.gitea.com"&gt;&lt;img src="https://badges.crowdin.net/gitea/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Translations are done through &lt;a href="https://translate.gitea.com"&gt;Crowdin&lt;/a&gt;. If you want to translate to a new language, ask one of the managers in the Crowdin project to add a new language there.&lt;/p&gt; 
&lt;p&gt;You can also just create an issue for adding a language or ask on Discord on the #translation channel. If you need context or find some translation issues, you can leave a comment on the string or ask on Discord. For general translation questions there is a section in the docs. Currently a bit empty, but we hope to fill it as questions pop up.&lt;/p&gt; 
&lt;p&gt;Get more information from &lt;a href="https://docs.gitea.com/contributing/localization"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Official and Third-Party Projects&lt;/h2&gt; 
&lt;p&gt;We provide an official &lt;a href="https://gitea.com/gitea/go-sdk"&gt;go-sdk&lt;/a&gt;, a CLI tool called &lt;a href="https://gitea.com/gitea/tea"&gt;tea&lt;/a&gt; and an &lt;a href="https://gitea.com/gitea/act_runner"&gt;action runner&lt;/a&gt; for Gitea Action.&lt;/p&gt; 
&lt;p&gt;We maintain a list of Gitea-related projects at &lt;a href="https://gitea.com/gitea/awesome-gitea"&gt;gitea/awesome-gitea&lt;/a&gt;, where you can discover more third-party projects, including SDKs, plugins, themes, and more.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/Gitea" title="Join the Discord chat at https://discord.gg/Gitea"&gt;&lt;img src="https://img.shields.io/discord/322538954119184384.svg?logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=5865F2" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you have questions that are not covered by the &lt;a href="https://docs.gitea.com/"&gt;documentation&lt;/a&gt;, you can get in contact with us on our &lt;a href="https://discord.gg/Gitea"&gt;Discord server&lt;/a&gt; or create a post in the &lt;a href="https://forum.gitea.com/"&gt;discourse forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/go-gitea/people"&gt;Maintainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-gitea/gitea/graphs/contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/go-gitea/gitea/main/options/locale/TRANSLATORS"&gt;Translators&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Backers&lt;/h2&gt; 
&lt;p&gt;Thank you to all our backers! üôè [&lt;a href="https://opencollective.com/gitea#backer"&gt;Become a backer&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/gitea#backers" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/backers.svg?width=890" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [&lt;a href="https://opencollective.com/gitea#sponsor"&gt;Become a sponsor&lt;/a&gt;]&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/gitea/sponsor/0/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/0/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/1/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/1/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/2/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/2/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/3/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/3/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/4/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/4/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/5/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/5/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/6/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/6/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/7/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/7/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/8/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/8/avatar.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/gitea/sponsor/9/website" target="_blank"&gt;&lt;img src="https://opencollective.com/gitea/sponsor/9/avatar.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;How do you pronounce Gitea?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gitea is pronounced &lt;a href="https://youtu.be/EM71-2uDAoY"&gt;/…°…™‚Äôti:/&lt;/a&gt; as in "gi-tea" with a hard g.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why is this not hosted on a Gitea instance?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We're &lt;a href="https://github.com/go-gitea/gitea/issues/1029"&gt;working on it&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Where can I find the security patches?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In the &lt;a href="https://github.com/go-gitea/gitea/releases"&gt;release log&lt;/a&gt; or the &lt;a href="https://github.com/go-gitea/gitea/raw/main/CHANGELOG.md"&gt;change log&lt;/a&gt;, search for the keyword &lt;code&gt;SECURITY&lt;/code&gt; to find the security patches.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://github.com/go-gitea/gitea/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for the full license text.&lt;/p&gt; 
&lt;h2&gt;Further information&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Looking for an overview of the interface? Check it out!&lt;/summary&gt; 
 &lt;h3&gt;Login/Register Page&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/login.png" alt="Login" /&gt; &lt;img src="https://dl.gitea.com/screenshots/register.png" alt="Register" /&gt;&lt;/p&gt; 
 &lt;h3&gt;User Dashboard&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/home.png" alt="Home" /&gt; &lt;img src="https://dl.gitea.com/screenshots/issues.png" alt="Issues" /&gt; &lt;img src="https://dl.gitea.com/screenshots/pull_requests.png" alt="Pull Requests" /&gt; &lt;img src="https://dl.gitea.com/screenshots/milestones.png" alt="Milestones" /&gt;&lt;/p&gt; 
 &lt;h3&gt;User Profile&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/user_profile.png" alt="Profile" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Explore&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/explore_repos.png" alt="Repos" /&gt; &lt;img src="https://dl.gitea.com/screenshots/explore_users.png" alt="Users" /&gt; &lt;img src="https://dl.gitea.com/screenshots/explore_orgs.png" alt="Orgs" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Repository&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/repo_home.png" alt="Home" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_commits.png" alt="Commits" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_branches.png" alt="Branches" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_labels.png" alt="Labels" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_milestones.png" alt="Milestones" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_releases.png" alt="Releases" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_tags.png" alt="Tags" /&gt;&lt;/p&gt; 
 &lt;h4&gt;Repository Issue&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/repo_issues.png" alt="List" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_issue.png" alt="Issue" /&gt;&lt;/p&gt; 
 &lt;h4&gt;Repository Pull Requests&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/repo_pull_requests.png" alt="List" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_pull_request.png" alt="Pull Request" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_pull_request_file.png" alt="File" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_pull_request_commits.png" alt="Commits" /&gt;&lt;/p&gt; 
 &lt;h4&gt;Repository Actions&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/repo_actions.png" alt="List" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_actions_run.png" alt="Details" /&gt;&lt;/p&gt; 
 &lt;h4&gt;Repository Activity&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/repo_activity.png" alt="Activity" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_contributors.png" alt="Contributors" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_code_frequency.png" alt="Code Frequency" /&gt; &lt;img src="https://dl.gitea.com/screenshots/repo_recent_commits.png" alt="Recent Commits" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Organization&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://dl.gitea.com/screenshots/org_home.png" alt="Home" /&gt;&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>juicedata/juicefs</title>
      <link>https://github.com/juicedata/juicefs</link>
      <description>&lt;p&gt;JuiceFS is a distributed POSIX file system built on top of Redis and S3.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/juicedata/juicefs"&gt;&lt;img alt="JuiceFS Logo" src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-logo-new.svg?sanitize=true" width="50%" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juicedata/juicefs/releases/latest"&gt;&lt;img alt="Latest Stable Release" src="https://img.shields.io/github/v/release/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/unittests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;amp;label=Unit%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;amp;label=Integration%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/juicedata/juicefs"&gt;&lt;img alt="Go Report" src="https://goreportcard.com/badge/github.com/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://juicefs.com/docs/community/introduction"&gt;&lt;img alt="English doc" src="https://img.shields.io/badge/docs-Doc%20Center-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://go.juicefs.com/slack"&gt;&lt;img alt="Join Slack" src="https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JuiceFS&lt;/strong&gt; is a high-performance &lt;a href="https://en.wikipedia.org/wiki/POSIX"&gt;POSIX&lt;/a&gt; file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage &lt;em&gt;(e.g. Amazon S3)&lt;/em&gt;, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.&lt;/p&gt; 
&lt;p&gt;With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;Document&lt;/strong&gt;: &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlighted Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fully POSIX-compatible&lt;/strong&gt;: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Hadoop-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt; is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt; provides an S3-compatible interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Native&lt;/strong&gt;: A &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;Kubernetes CSI Driver&lt;/a&gt; is provided for easily using JuiceFS in Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shareable&lt;/strong&gt;: JuiceFS is a shared file storage that can be read and written by thousands of clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;: The confirmed modification will be immediately visible on all the servers mounted with the same file system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outstanding Performance&lt;/strong&gt;: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly &lt;em&gt;(depending on the size of the Object Storage)&lt;/em&gt;. &lt;a href="https://juicefs.com/docs/community/benchmark"&gt;Test results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Supports data encryption in transit and at rest (please refer to &lt;a href="https://juicefs.com/docs/community/security/encrypt"&gt;the guide&lt;/a&gt; for more information).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global File Locks&lt;/strong&gt;: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;: JuiceFS supports &lt;a href="https://lz4.github.io/lz4"&gt;LZ4&lt;/a&gt; or &lt;a href="https://facebook.github.io/zstd"&gt;Zstandard&lt;/a&gt; to compress all your data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#architecture"&gt;Architecture&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#advanced-topics"&gt;Advanced Topics&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#posix-compatibility"&gt;POSIX Compatibility&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#performance-benchmark"&gt;Performance Benchmark&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#supported-object-storage"&gt;Supported Object Storage&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#who-is-using"&gt;Who is using&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#roadmap"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#reporting-issues"&gt;Reporting Issues&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#contributing"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;Community&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#usage-tracking"&gt;Usage Tracking&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#license"&gt;License&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#credits"&gt;Credits&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;JuiceFS consists of three parts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;JuiceFS Client&lt;/strong&gt;: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata Engine&lt;/strong&gt;: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-arch-new.png" alt="JuiceFS Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. &lt;a href="https://juicefs.com/docs/community/architecture"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/data-structure-diagram.svg?sanitize=true" alt="data-structure-diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Each file stored in JuiceFS is split into &lt;strong&gt;"Chunk"&lt;/strong&gt; s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more &lt;strong&gt;"Slice"&lt;/strong&gt;(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed &lt;strong&gt;"Block"&lt;/strong&gt; s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. &lt;a href="https://juicefs.com/docs/community/architecture/#how-juicefs-store-files"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/how-juicefs-stores-files.svg?sanitize=true" alt="How JuiceFS stores your files" /&gt;&lt;/p&gt; 
&lt;p&gt;When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don't panic! This is just the secret of the high-performance operation of JuiceFS!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Before you begin, make sure you have:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One supported metadata engine, see &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;How to Set Up Metadata Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;One supported Object Storage for storing data blocks, see &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;Supported Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation"&gt;JuiceFS Client&lt;/a&gt; downloaded and installed&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt; to start using JuiceFS right away!&lt;/p&gt; 
&lt;h3&gt;Command Reference&lt;/h3&gt; 
&lt;p&gt;Check out all the command line options in &lt;a href="https://juicefs.com/docs/community/command_reference"&gt;command reference&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Containers&lt;/h3&gt; 
&lt;p&gt;JuiceFS can be used as a persistent volume for Docker and Podman, please check &lt;a href="https://juicefs.com/docs/community/juicefs_on_docker"&gt;here&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Kubernetes&lt;/h3&gt; 
&lt;p&gt;It is also very easy to use JuiceFS on Kubernetes. Please find more information &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Hadoop Java SDK&lt;/h3&gt; 
&lt;p&gt;If you wanna use JuiceFS in Hadoop, check &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;Redis Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;How to Setup Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/cache"&gt;Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis"&gt;Fault Diagnosis and Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fuse_mount_options"&gt;FUSE Mount Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation#windows"&gt;Using JuiceFS on Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/introduction"&gt;JuiceFS Document Center&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;POSIX Compatibility&lt;/h2&gt; 
&lt;p&gt;JuiceFS has passed all of the compatibility tests (8813 in total) in the latest &lt;a href="https://github.com/pjd/pjdfstest"&gt;pjdfstest&lt;/a&gt; .&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Close-to-open consistency&lt;/strong&gt;. Once a file is written &lt;em&gt;and&lt;/em&gt; closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.&lt;/li&gt; 
 &lt;li&gt;Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.&lt;/li&gt; 
 &lt;li&gt;Opened files remain accessible after unlink from same mount point.&lt;/li&gt; 
 &lt;li&gt;Mmap (tested with FSx).&lt;/li&gt; 
 &lt;li&gt;Fallocate with punch hole support.&lt;/li&gt; 
 &lt;li&gt;Extended attributes (xattr).&lt;/li&gt; 
 &lt;li&gt;BSD locks (flock).&lt;/li&gt; 
 &lt;li&gt;POSIX record locks (fcntl).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance Benchmark&lt;/h2&gt; 
&lt;h3&gt;Basic benchmark&lt;/h3&gt; 
&lt;p&gt;JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-bench.png" alt="JuiceFS Bench" /&gt;&lt;/p&gt; 
&lt;h3&gt;Throughput&lt;/h3&gt; 
&lt;p&gt;A sequential read/write benchmark has also been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/sequential-read-write-benchmark.svg?sanitize=true" alt="Sequential Read Write Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see &lt;a href="https://juicefs.com/docs/community/fio"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Metadata IOPS&lt;/h3&gt; 
&lt;p&gt;A simple mdtest benchmark has been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/hpc/ior"&gt;mdtest&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/metadata-benchmark.svg?sanitize=true" alt="Metadata Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see &lt;a href="https://juicefs.com/docs/community/mdtest"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Analyze performance&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor"&gt;Real-Time Performance Monitoring&lt;/a&gt; if you encountered performance issues.&lt;/p&gt; 
&lt;h2&gt;Supported Object Storage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon S3 &lt;em&gt;(and other S3 compatible Object Storage services)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Google Cloud Storage&lt;/li&gt; 
 &lt;li&gt;Azure Blob Storage&lt;/li&gt; 
 &lt;li&gt;Alibaba Cloud Object Storage Service (OSS)&lt;/li&gt; 
 &lt;li&gt;Tencent Cloud Object Storage (COS)&lt;/li&gt; 
 &lt;li&gt;Qiniu Cloud Object Storage (Kodo)&lt;/li&gt; 
 &lt;li&gt;QingStor Object Storage&lt;/li&gt; 
 &lt;li&gt;Ceph RGW&lt;/li&gt; 
 &lt;li&gt;MinIO&lt;/li&gt; 
 &lt;li&gt;Local disk&lt;/li&gt; 
 &lt;li&gt;Redis&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;JuiceFS supports numerous Object Storage services. &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Who is using&lt;/h2&gt; 
&lt;p&gt;JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented &lt;a href="https://juicefs.com/docs/community/adopters"&gt;here&lt;/a&gt;. In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented &lt;a href="https://juicefs.com/docs/community/integrations"&gt;here&lt;/a&gt;. If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.&lt;/p&gt; 
&lt;p&gt;The storage format is stable, and will be supported by all future releases.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;User and group quotas&lt;/li&gt; 
 &lt;li&gt;Snapshots&lt;/li&gt; 
 &lt;li&gt;Write once read many (WORM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reporting Issues&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/juicedata/juicefs/issues"&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;contact&lt;/a&gt; the community for any questions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for your contribution! Please refer to the &lt;a href="https://juicefs.com/docs/community/development/contributing_guide"&gt;JuiceFS Contributing Guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Welcome to join the &lt;a href="https://github.com/juicedata/juicefs/discussions"&gt;Discussions&lt;/a&gt; and the &lt;a href="https://go.juicefs.com/slack"&gt;Slack channel&lt;/a&gt; to connect with JuiceFS team members and other users.&lt;/p&gt; 
&lt;h2&gt;Usage Tracking&lt;/h2&gt; 
&lt;p&gt;JuiceFS collects &lt;strong&gt;anonymous&lt;/strong&gt; usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/pkg/usage/usage.go"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You could also disable reporting easily by command line option &lt;code&gt;--no-usage-report&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;juicefs mount --no-usage-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;JuiceFS is open-sourced under Apache License 2.0, see &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The design of JuiceFS was inspired by &lt;a href="https://research.google/pubs/pub51"&gt;Google File System&lt;/a&gt;, &lt;a href="https://hadoop.apache.org"&gt;HDFS&lt;/a&gt; and &lt;a href="https://moosefs.com"&gt;MooseFS&lt;/a&gt;. Thanks for their great work!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why doesn't JuiceFS support XXX Object Storage?&lt;/h3&gt; 
&lt;p&gt;JuiceFS supports many Object Storage services. Please check out &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;this list&lt;/a&gt; first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.&lt;/p&gt; 
&lt;h3&gt;Can I use Redis Cluster as metadata engine?&lt;/h3&gt; 
&lt;p&gt;Yes. Since &lt;a href="https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3"&gt;v1.0.0 Beta3&lt;/a&gt; JuiceFS supports the use of &lt;a href="https://redis.io/docs/manual/scaling"&gt;Redis Cluster&lt;/a&gt; as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;"Redis Best Practices"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;What's the difference between JuiceFS and XXX?&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio"&gt;"Comparison with Others"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;For more FAQs, please see the &lt;a href="https://juicefs.com/docs/community/faq"&gt;full list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#juicedata/juicefs&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=juicedata/juicefs&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>putyy/res-downloader</title>
      <link>https://github.com/putyy/res-downloader</link>
      <description>&lt;p&gt;ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader"&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/build/appicon.png" width="120" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;res-downloader&lt;/h1&gt; 
 &lt;h4&gt;üìñ ‰∏≠Êñá | &lt;a href="https://github.com/putyy/res-downloader/raw/master/README-EN.md"&gt;English&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/putyy/res-downloader" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/fork"&gt;&lt;img src="https://img.shields.io/github/forks/putyy/res-downloader" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;&lt;img src="https://img.shields.io/github/release/putyy/res-downloader" alt="GitHub release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/putyy/res-downloader/total" alt="GitHub All Releases" /&gt; &lt;a href="https://github.com/putyy/res-downloader/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/putyy/res-downloader" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏ÄÊ¨æÂü∫‰∫é Go + &lt;a href="https://github.com/wailsapp/wails"&gt;Wails&lt;/a&gt; ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® ÂäüËÉΩÁâπËâ≤&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;ÁÆÄÂçïÊòìÁî®&lt;/strong&gt;ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Â§öÂπ≥Âè∞ÊîØÊåÅ&lt;/strong&gt;ÔºöWindows / macOS / Linux&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ&lt;/strong&gt;ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â&lt;/li&gt; 
 &lt;li&gt;üì± &lt;strong&gt;Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ&lt;/strong&gt;ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;‰ª£ÁêÜÊäìÂåÖ&lt;/strong&gt;ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö ÊñáÊ°£ &amp;amp; ÁâàÊú¨&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://res.putyy.com/"&gt;Âú®Á∫øÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp"&gt;Âä†ÂÖ•‰∫§ÊµÅÁæ§&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß© &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;ÊúÄÊñ∞Áâà&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/resd-mini"&gt;MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/res-downloader/tree/old"&gt;ElectronÊóßÁâà ÊîØÊåÅWin7&lt;/a&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;em&gt;Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° &lt;code&gt;AmorousWorld&lt;/code&gt;ÔºåËØ∑Â§áÊ≥®‚Äúgithub‚Äù&lt;/em&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© ‰∏ãËΩΩÂú∞ÂùÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üÜï &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;GitHub ‰∏ãËΩΩ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://wwjv.lanzoum.com/b04wgtfyb"&gt;ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö†Ô∏è &lt;em&gt;Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ &lt;code&gt;2.3.0&lt;/code&gt; ÁâàÊú¨&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üñºÔ∏è È¢ÑËßà&lt;/h2&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/docs/images/show.webp" alt="È¢ÑËßà" /&gt;&lt;/h2&gt; 
&lt;h2&gt;üöÄ ‰ΩøÁî®ÊñπÊ≥ï&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;ÂÆâË£ÖÊó∂Âä°ÂøÖ &lt;strong&gt;ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂&lt;/strong&gt; Âπ∂ &lt;strong&gt;ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª &lt;strong&gt;‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ&lt;/li&gt; 
 &lt;li&gt;Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ&lt;/li&gt; 
 &lt;li&gt;ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ùì Â∏∏ËßÅÈóÆÈ¢ò&lt;/h2&gt; 
&lt;h3&gt;üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®Á∫øÈ¢ÑËßàÔºö&lt;a href="https://m3u8play.com/"&gt;m3u8play&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ë‰∏ãËΩΩÔºö&lt;a href="https://m3u8-down.gowas.cn/"&gt;m3u8-down&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®Ëçê‰ΩøÁî® &lt;a href="https://obsproject.com/"&gt;OBS&lt;/a&gt; ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®ËçêÂ∑•ÂÖ∑Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.neatdownloadmanager.com/index.php/en/"&gt;Neat Download Manager&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://motrix.app/download"&gt;Motrix&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª &lt;code&gt;ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö&lt;br /&gt; Âú∞ÂùÄÔºö127.0.0.1 Á´ØÂè£Ôºö8899&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß† Êõ¥Â§öÈóÆÈ¢ò&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/putyy/res-downloader/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://s.gowas.cn/d/4089"&gt;Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° ÂÆûÁé∞ÂéüÁêÜ &amp;amp; ÂàùË°∑&lt;/h2&gt; 
&lt;p&gt;Êú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ&lt;br /&gt; Â¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/"&gt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>henrygd/beszel</title>
      <link>https://github.com/henrygd/beszel</link>
      <description>&lt;p&gt;Lightweight server monitoring hub with historical data, docker stats, and alerts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Beszel&lt;/h1&gt; 
&lt;p&gt;Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.&lt;/p&gt; 
&lt;p&gt;It has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/henrygd/beszel-agent"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&amp;amp;label=agent%20image%20size" alt="agent Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/henrygd/beszel"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&amp;amp;label=hub%20image%20size" alt="hub Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/henrygd/beszel/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/henrygd/beszel?color=%239944ee" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/beszel"&gt;&lt;img src="https://badges.crowdin.net/beszel/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png" alt="Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system." /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Smaller and less resource-intensive than leading solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy setup with little manual configuration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker stats&lt;/strong&gt;: Tracks CPU, memory, and network usage history for each container.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;: Users manage their own systems. Admins can share systems across users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OAuth / OIDC&lt;/strong&gt;: Supports many OAuth2 providers. Password auth can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic backups&lt;/strong&gt;: Save to and restore from disk or S3-compatible storage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - **REST API**: Use or update your data in your own scripts and applications. --&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Beszel consists of two main components: the &lt;strong&gt;hub&lt;/strong&gt; and the &lt;strong&gt;agent&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hub&lt;/strong&gt;: A web application built on &lt;a href="https://pocketbase.io/"&gt;PocketBase&lt;/a&gt; that provides a dashboard for viewing and managing connected systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: Runs on each system you want to monitor and communicates system metrics to the hub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://beszel.dev/guide/getting-started"&gt;quick start guide&lt;/a&gt; and other documentation is available on our website, &lt;a href="https://beszel.dev"&gt;beszel.dev&lt;/a&gt;. You'll be up and running in a few minutes.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://beszel.dev/image/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://beszel.dev/image/system-full.png" alt="System page" /&gt; &lt;img src="https://beszel.dev/image/settings-notifications.png" alt="Notification Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;Supported metrics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU usage&lt;/strong&gt; - Host system and Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory usage&lt;/strong&gt; - Host system and containers. Includes swap and ZFS ARC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk usage&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk I/O&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network usage&lt;/strong&gt; - Host system and containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Load average&lt;/strong&gt; - Host system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; - Host system sensors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU usage / power draw&lt;/strong&gt; - Nvidia, AMD, and Intel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt; - Host system battery charge.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Containers&lt;/strong&gt; - Status and metrics of all running Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S.M.A.R.T.&lt;/strong&gt; - Host system disk health.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Help and discussion&lt;/h2&gt; 
&lt;p&gt;Please search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.&lt;/p&gt; 
&lt;h4&gt;Bug reports and feature requests&lt;/h4&gt; 
&lt;p&gt;Bug reports and feature requests can be posted on &lt;a href="https://github.com/henrygd/beszel/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Support and general discussion&lt;/h4&gt; 
&lt;p&gt;Support requests and general discussion can be posted on &lt;a href="https://github.com/henrygd/beszel/discussions"&gt;GitHub discussions&lt;/a&gt; or the community-run &lt;a href="https://matrix.to/#/#beszel:matrix.org"&gt;Matrix room&lt;/a&gt;: &lt;code&gt;#beszel:matrix.org&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Beszel is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/henrygd/beszel/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/redis/go-redis/actions"&gt;&lt;img src="https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build workflow" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/redis/go-redis/v9" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://redis.uptrace.dev/"&gt;&lt;img src="https://img.shields.io/badge/redis-documentation-informational" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/redis/go-redis/v9"&gt;&lt;img src="https://goreportcard.com/badge/github.com/redis/go-redis/v9" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/redis/go-redis"&gt;&lt;img src="https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;&lt;img src="https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.twitch.tv/redisinc"&gt;&lt;img src="https://img.shields.io/twitch/status/redisinc?style=social" alt="Twitch" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/redisinc"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/redisinc"&gt;&lt;img src="https://img.shields.io/twitter/follow/redisinc?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/go-redis"&gt;&lt;img src="https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow" alt="Stack Exchange questions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES"&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES"&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES"&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES"&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt;, &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://university.redis.com/"&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://launchpad.redis.com/"&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/try-free/"&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.redis.com/"&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/community/"&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/company/careers/jobs/"&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/zh/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/go-redis/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redismock"&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bsm/redislock"&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/cache"&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redis_rate"&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href="https://github.com/apache/incubator-kvrocks"&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority"&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pubsub.html"&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pipelines.html"&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/lua-scripting.html"&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-sentinel.html"&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-cluster.html"&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/ring.html"&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/redis-performance-monitoring.html"&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.io/docs/data-types/probabilistic/"&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes"&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "context"
    "fmt"

    "github.com/redis/go-redis/v9"
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     "localhost:6379",
        Password: "", // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, "key", "value", 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, "key").Result()
    if err != nil {
        panic(err)
    }
    fmt.Println("key", val)

    val2, err := rdb.Get(ctx, "key2").Result()
    if err == redis.Nil {
        fmt.Println("key2 does not exist")
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println("key2", val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href="https://github.com/redis/go-redis-entraid"&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis-entraid"
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "your-redis-server.redis.cache.windows.net:6380",
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return "user", "pass", nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return "user", "pass"
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Username: "user",
    Password: "pass",
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Password: "", // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href="https://github.com/redis/redis-specifications/tree/master/uri/redis.txt"&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
)

func ExampleClient() *redis.Client {
    url := "redis://user:password@localhost:6379/0?protocol=3"
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis/extra/redisotel/v9"
    "errors"
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is "fire and forget", meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    Password:        "",
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;res1, err := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		"idx:bicycle",
		"@pickup_zone:[CONTAINS $bike]",
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				"bike": "POINT(-0.1278 51.5074)",
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href="https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/"&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, "key", "value", 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, "key", "value", redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, "list", &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: "ASC"}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, "zset", &amp;amp;redis.ZRangeBy{
    Min: "-inf",
    Max: "+inf",
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, "out", &amp;amp;redis.ZStore{
    Keys: []string{"zset1", "zset2"},
    Weights: []int64{2, 3}
}).Result()

// EVAL "return {KEYS[1],ARGV[1]}" 1 "key" "hello"
vals, err := rdb.Eval(ctx, "return {KEYS[1],ARGV[1]}", []string{"key"}, "hello").Result()

// custom command
res, err := rdb.Do(ctx, "set", "key", "value").Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;Recommended to use Docker, just need to run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev"&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev/postgres/"&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bunrouter.uptrace.dev/"&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/uptrace/go-clickhouse"&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;‚≠ê&lt;/span&gt; &lt;a href="https://github.com/uptrace/uptrace"&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/redis/go-redis/tree/master/example/otel"&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/redis/go-redis/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=redis/go-redis" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>traefik/traefik</title>
      <link>https://github.com/traefik/traefik</link>
      <description>&lt;p&gt;The Cloud Native Application Proxy&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/content/assets/img/traefik.logo-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/content/assets/img/traefik.logo.png" /&gt; 
  &lt;img alt="Traefik" title="Traefik" src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik.logo.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://doc.traefik.io/traefik"&gt;&lt;img src="https://img.shields.io/badge/docs-current-brightgreen.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/traefik/traefik"&gt;&lt;img src="https://goreportcard.com/badge/traefik/traefik" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/traefik/traefik/raw/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the community support forum at https://community.traefik.io/" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=traefik"&gt;&lt;img src="https://img.shields.io/twitter/follow/traefik.svg?style=social" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Traefik (pronounced &lt;em&gt;traffic&lt;/em&gt;) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy. Traefik integrates with your existing infrastructure components (&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Swarm mode&lt;/a&gt;, &lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/"&gt;Etcd&lt;/a&gt;, &lt;a href="https://rancher.com"&gt;Rancher v2&lt;/a&gt;, &lt;a href="https://aws.amazon.com/ecs"&gt;Amazon ECS&lt;/a&gt;, ...) and configures itself automatically and dynamically. Pointing Traefik at your orchestrator should be the &lt;em&gt;only&lt;/em&gt; configuration step you need.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#features"&gt;Features&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#supported-backends"&gt;Supported backends&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#web-ui"&gt;Web UI&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#support"&gt;Support&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#release-cycle"&gt;Release cycle&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#maintainers"&gt;Maintainers&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#credits"&gt;Credits&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; When migrating to a new major version of Traefik, please refer to the &lt;a href="https://doc.traefik.io/traefik/migrate/v2-to-v3/"&gt;migration guide&lt;/a&gt; to ensure a smooth transition and to be aware of any breaking changes.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul). Now you want users to access these microservices, and you need a reverse proxy.&lt;/p&gt; 
&lt;p&gt;Traditional reverse-proxies require that you configure &lt;em&gt;each&lt;/em&gt; route that will connect paths and subdomains to &lt;em&gt;each&lt;/em&gt; microservice. In an environment where you add, remove, kill, upgrade, or scale your services &lt;em&gt;many&lt;/em&gt; times a day, the task of keeping the routes up to date becomes tedious.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This is when Traefik can help you!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Traefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run Traefik and let it do the work for you!&lt;/strong&gt; &lt;em&gt;(But if you'd rather configure some of your routes manually, Traefik supports that too!)&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik-architecture.png" alt="Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Continuously updates its configuration (No restarts!)&lt;/li&gt; 
 &lt;li&gt;Supports multiple load balancing algorithms&lt;/li&gt; 
 &lt;li&gt;Provides HTTPS to your microservices by leveraging &lt;a href="https://letsencrypt.org"&gt;Let's Encrypt&lt;/a&gt; (wildcard certificates support)&lt;/li&gt; 
 &lt;li&gt;Circuit breakers, retry&lt;/li&gt; 
 &lt;li&gt;See the magic through its clean web UI&lt;/li&gt; 
 &lt;li&gt;WebSocket, HTTP/2, gRPC ready&lt;/li&gt; 
 &lt;li&gt;Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)&lt;/li&gt; 
 &lt;li&gt;Keeps access logs (JSON, CLF)&lt;/li&gt; 
 &lt;li&gt;Fast&lt;/li&gt; 
 &lt;li&gt;Exposes a Rest API&lt;/li&gt; 
 &lt;li&gt;Packaged as a single binary file (made with &lt;span&gt;‚ù§Ô∏è&lt;/span&gt; with go) and available as an &lt;a href="https://hub.docker.com/r/_/traefik/"&gt;official&lt;/a&gt; docker image&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Backends&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Docker&lt;/a&gt; / &lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Swarm mode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/kubernetes-crd/"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/ecs/"&gt;ECS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/file/"&gt;File&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get your hands on Traefik, you can use the &lt;a href="https://doc.traefik.io/traefik/getting-started/quick-start/"&gt;5-Minute Quickstart&lt;/a&gt; in our documentation (you will need Docker).&lt;/p&gt; 
&lt;h2&gt;Web UI&lt;/h2&gt; 
&lt;p&gt;You can access the simple HTML frontend of Traefik.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/webui-dashboard.png" alt="Web UI Providers" /&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can find the complete documentation of Traefik v3 at &lt;a href="https://doc.traefik.io/traefik/"&gt;https://doc.traefik.io/traefik/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;To get community support, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;join the Traefik community forum: &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the chat at https://community.traefik.io/" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need commercial support, please contact &lt;a href="https://traefik.io"&gt;Traefik.io&lt;/a&gt; by mail: &lt;a href="mailto:support@traefik.io"&gt;mailto:support@traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grab the latest binary from the &lt;a href="https://github.com/traefik/traefik/releases"&gt;releases&lt;/a&gt; page and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./traefik --configFile=traefik.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or use the official tiny Docker image and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or get the sources:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/traefik/traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Introductory Videos&lt;/h2&gt; 
&lt;p&gt;You can find high level and deep dive videos on &lt;a href="https://videos.traefik.io"&gt;videos.traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;We are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey! This &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers-guidelines.md"&gt;document&lt;/a&gt; describes how to be part of the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers.md"&gt;maintainers' team&lt;/a&gt; as well as various responsibilities and guidelines for Traefik maintainers. You can also find more information on our process to review pull requests and manage issues &lt;a href="https://github.com/traefik/contributors-guide/raw/master/issue_triage.md"&gt;in this document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to contribute to the project, refer to the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CONTRIBUTING.md"&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;Release Cycle&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.&lt;/li&gt; 
 &lt;li&gt;Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).&lt;/li&gt; 
 &lt;li&gt;Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://semver.org/"&gt;Semantic Versioning&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Mailing Lists&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;General announcements, new releases: mail at &lt;a href="mailto:news+subscribe@traefik.io"&gt;news+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/news"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Security announcements: mail at &lt;a href="mailto:security+subscribe@traefik.io"&gt;security+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/security"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Kudos to &lt;a href="https://www.instagram.com/pierroks/"&gt;Peka&lt;/a&gt; for his awesome work on the gopher's logo!.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik was inspired by the gopher stickers made by &lt;a href="https://twitter.com/tenntenn"&gt;Takuya Ueda&lt;/a&gt;. The original Go gopher was designed by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renee French&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>smartcontractkit/chainlink</title>
      <link>https://github.com/smartcontractkit/chainlink</link>
      <description>&lt;p&gt;node of the decentralized oracle network, bridging on and off-chain computation&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://chain.link" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/smartcontractkit/chainlink/develop/docs/logo-chainlink-blue.svg?sanitize=true" width="225" alt="Chainlink logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/smartcontract/chainlink/tags"&gt;&lt;img src="https://img.shields.io/github/v/tag/smartcontractkit/chainlink?style=flat-square" alt="GitHub tag (latest SemVer)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smartcontractkit/chainlink/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/smartcontractkit/chainlink?style=flat-square" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smartcontractkit/chainlink/actions/workflows/changeset.yml?query=workflow%3AChangeset"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/smartcontractkit/chainlink/changeset.yml" alt="GitHub workflow changeset" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smartcontractkit/chainlink/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/smartcontractkit/chainlink?style=flat-square" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smartcontractkit/chainlink/commits/master"&gt;&lt;img src="https://img.shields.io/github/commit-activity/y/smartcontractkit/chainlink?style=flat-square" alt="GitHub commit activity" /&gt;&lt;/a&gt; &lt;a href="https://docs.chain.link/"&gt;&lt;img src="https://img.shields.io/static/v1?label=docs&amp;amp;message=latest&amp;amp;color=blue" alt="Official documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chain.link/"&gt;Chainlink&lt;/a&gt; expands the capabilities of smart contracts by enabling access to real-world data and off-chain computation while maintaining the security and reliability guarantees inherent to blockchain technology.&lt;/p&gt; 
&lt;p&gt;This repo contains the Chainlink core node and contracts. The core node is the bundled binary available to be run by node operators participating in a &lt;a href="https://link.smartcontract.com/whitepaper"&gt;decentralized oracle network&lt;/a&gt;. All major release versions have pre-built docker images available for download from the &lt;a href="https://hub.docker.com/r/smartcontract/chainlink/tags"&gt;Chainlink dockerhub&lt;/a&gt;. If you are interested in contributing please see our &lt;a href="https://raw.githubusercontent.com/smartcontractkit/chainlink/develop/docs/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;. If you are here to report a bug or request a feature, please &lt;a href="https://github.com/smartcontractkit/chainlink/issues"&gt;check currently open Issues&lt;/a&gt;. For more information about how to get started with Chainlink, check our &lt;a href="https://docs.chain.link/"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Chainlink has an active and ever growing community. &lt;a href="https://discordapp.com/invite/aSK4zew"&gt;Discord&lt;/a&gt; is the primary communication channel used for day to day communication, answering development questions, and aggregating Chainlink related content. Take a look at the &lt;a href="https://raw.githubusercontent.com/smartcontractkit/chainlink/develop/docs/COMMUNITY.md"&gt;community docs&lt;/a&gt; for more information regarding Chainlink social accounts, news, and networking.&lt;/p&gt; 
&lt;h2&gt;Build Chainlink&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/doc/install"&gt;Install Go 1.23&lt;/a&gt;, and add your GOPATH's &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;bin directory to your PATH&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Example Path for macOS &lt;code&gt;export PATH=$GOPATH/bin:$PATH&lt;/code&gt; &amp;amp; &lt;code&gt;export GOPATH=/Users/$USER/go&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://nodejs.org/en/download/package-manager/"&gt;NodeJS v20&lt;/a&gt; &amp;amp; &lt;a href="https://pnpm.io/installation#using-npm"&gt;pnpm v10 via npm&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;It might be easier long term to use &lt;a href="https://nodejs.org/en/download/package-manager/#nvm"&gt;nvm&lt;/a&gt; to switch between node versions for different projects. For example, assuming $NODE_VERSION was set to a valid version of NodeJS, you could run: &lt;code&gt;nvm install $NODE_VERSION &amp;amp;&amp;amp; nvm use $NODE_VERSION&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://wiki.postgresql.org/wiki/Detailed_installation_guides"&gt;Postgres (&amp;gt;= 12.x)&lt;/a&gt;. It is recommended to run the latest major version of postgres. 
  &lt;ul&gt; 
   &lt;li&gt;Note if you are running the official Chainlink docker image, the highest supported Postgres version is 16.x due to the bundled client.&lt;/li&gt; 
   &lt;li&gt;You should &lt;a href="https://www.postgresql.org/docs/current/ssl-tcp.html"&gt;configure Postgres&lt;/a&gt; to use SSL connection (or for testing you can set &lt;code&gt;?sslmode=disable&lt;/code&gt; in your Postgres query string).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Download Chainlink: &lt;code&gt;git clone https://github.com/smartcontractkit/chainlink &amp;amp;&amp;amp; cd chainlink&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build and install Chainlink: &lt;code&gt;make install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the node: &lt;code&gt;chainlink help&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For the latest information on setting up a development environment, see the &lt;a href="https://github.com/smartcontractkit/chainlink/wiki/Development-Setup-Guide"&gt;Development Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Build from PR&lt;/h3&gt; 
&lt;p&gt;To build an unofficial testing-only image from a feature branch or PR. You can do one of the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Send a workflow dispatch event from our &lt;a href="https://github.com/smartcontractkit/chainlink/actions/workflows/docker-build.yml"&gt;&lt;code&gt;docker-build&lt;/code&gt; workflow&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add the &lt;code&gt;build-publish&lt;/code&gt; label to your PR and then either retry the &lt;code&gt;docker-build&lt;/code&gt; workflow, or push a new commit.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Build Plugins&lt;/h3&gt; 
&lt;p&gt;Plugins are defined in yaml files within the &lt;code&gt;plugins/&lt;/code&gt; directory. Each plugin file is a yaml file and has a &lt;code&gt;plugins.&lt;/code&gt; prefix name. Plugins are installed with &lt;a href="https://github.com/smartcontractkit/chainlink-common/tree/main/pkg/loop/cmd/loopinstall"&gt;loopinstall&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install the plugins, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make install-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Some plugins (such as those in &lt;code&gt;plugins/plugins.private.yaml&lt;/code&gt;) reference private GitHub repositories. To build these plugins, you must have a GITHUB_TOKEN environment variable set, or preferably use the &lt;a href="https://cli.github.com/manual/gh"&gt;gh&lt;/a&gt; GitHub CLI tool to use the &lt;a href="https://cli.github.com/manual/gh_auth_setup-git"&gt;GitHub CLI credential helper&lt;/a&gt; like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Sets up a credential helper.
gh auth setup-git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can build the plugins with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make install-plugins-private
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Builds&lt;/h3&gt; 
&lt;p&gt;To build the experimental "plugins" Chainlink docker image, you can run this from the root of the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# The GITHUB_TOKEN is required to access private repos which are used by some plugins.
export GITHUB_TOKEN=$(gh auth token) # requires the `gh` cli tool.
make docker-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ethereum Execution Client Requirements&lt;/h3&gt; 
&lt;p&gt;In order to run the Chainlink node you must have access to a running Ethereum node with an open websocket connection. Any Ethereum based network will work once you've &lt;a href="https://github.com/smartcontractkit/chainlink#configure"&gt;configured&lt;/a&gt; the chain ID. Ethereum node versions currently tested and supported:&lt;/p&gt; 
&lt;p&gt;[Officially supported]&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openethereum/openethereum"&gt;Parity/Openethereum&lt;/a&gt; (NOTE: Parity is deprecated and support for this client may be removed in future)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ethereum/go-ethereum/releases"&gt;Geth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hyperledger/besu"&gt;Besu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[Supported but broken] These clients are supported by Chainlink, but have bugs that prevent Chainlink from working reliably on these execution clients.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NethermindEth/nethermind"&gt;Nethermind&lt;/a&gt; Blocking issues: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;del&gt;&lt;a href="https://github.com/NethermindEth/nethermind/issues/4384"&gt;https://github.com/NethermindEth/nethermind/issues/4384&lt;/a&gt;&lt;/del&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ledgerwatch/erigon"&gt;Erigon&lt;/a&gt; Blocking issues: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ledgerwatch/erigon/discussions/4946"&gt;https://github.com/ledgerwatch/erigon/discussions/4946&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/ledgerwatch/erigon/issues/4030#issuecomment-1113964017"&gt;https://github.com/ledgerwatch/erigon/issues/4030#issuecomment-1113964017&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We cannot recommend specific version numbers for ethereum nodes since the software is being continually updated, but you should usually try to run the latest version available.&lt;/p&gt; 
&lt;h2&gt;Running a local Chainlink node&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: By default, chainlink will run in TLS mode. For local development you can disable this by using a &lt;code&gt;dev build&lt;/code&gt; using &lt;code&gt;make chainlink-dev&lt;/code&gt; and setting the TOML fields:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[WebServer]
SecureCookies = false
TLS.HTTPSPort = 0

[Insecure]
DevWebServer = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can generate self signed certificates using &lt;code&gt;tools/bin/self-signed-certs&lt;/code&gt; or &lt;a href="https://github.com/smartcontractkit/chainlink/wiki/Creating-Self-Signed-Certificates"&gt;manually&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To start your Chainlink node, simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chainlink node start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default this will start on port 6688. You should be able to access the UI at &lt;a href="http://localhost:6688/"&gt;http://localhost:6688/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Chainlink provides a remote CLI client as well as a UI. Once your node has started, you can open a new terminal window to use the CLI. You will need to log in to authorize the client first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chainlink admin login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(You can also set &lt;code&gt;ADMIN_CREDENTIALS_FILE=/path/to/credentials/file&lt;/code&gt; in future if you like, to avoid having to login again).&lt;/p&gt; 
&lt;p&gt;Now you can view your current jobs with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chainlink jobs list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find out more about the Chainlink CLI, you can always run &lt;code&gt;chainlink help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://docs.chain.link/"&gt;doc&lt;/a&gt; pages on &lt;a href="https://docs.chain.link/docs/jobs/"&gt;Jobs&lt;/a&gt; to learn more about how to create Jobs.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Node configuration is managed by a combination of environment variables and direct setting via API/UI/CLI.&lt;/p&gt; 
&lt;p&gt;Check the &lt;a href="https://docs.chain.link/docs/configuration-variables"&gt;official documentation&lt;/a&gt; for more information on how to configure your node.&lt;/p&gt; 
&lt;h3&gt;External Adapters&lt;/h3&gt; 
&lt;p&gt;External adapters are what make Chainlink easily extensible, providing simple integration of custom computations and specialized APIs. A Chainlink node communicates with external adapters via a simple REST API.&lt;/p&gt; 
&lt;p&gt;For more information on creating and using external adapters, please see our &lt;a href="https://docs.chain.link/docs/external-adapters"&gt;external adapters page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Verify Official Chainlink Releases&lt;/h2&gt; 
&lt;p&gt;We use &lt;code&gt;cosign&lt;/code&gt; with OIDC keyless signing during the &lt;a href="https://github.com/smartcontractkit/chainlink/actions/workflows/build-publish.yml"&gt;Build, Sign and Publish Chainlink&lt;/a&gt; workflow.&lt;/p&gt; 
&lt;p&gt;It is encourage for any node operator building from the official Chainlink docker image to verify the tagged release version was did indeed built from this workflow.&lt;/p&gt; 
&lt;p&gt;You will need &lt;code&gt;cosign&lt;/code&gt; in order to do this verification. &lt;a href="https://docs.sigstore.dev/system_config/installation/"&gt;Follow the instruction here to install cosign&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# tag is the tagged release version - ie. 2.16.0
cosign verify index.docker.io/smartcontract/chainlink:${tag} \
      --certificate-oidc-issuer https://token.actions.githubusercontent.com \
      --certificate-identity "https://github.com/smartcontractkit/chainlink/.github/workflows/build-publish.yml@refs/tags/v${tag}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Running tests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://pnpm.io/installation#using-npm"&gt;Install pnpm 10 via npm&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/fjl/gencodec"&gt;gencodec&lt;/a&gt; and &lt;a href="https://stedolan.github.io/jq/download/"&gt;jq&lt;/a&gt; to be able to run &lt;code&gt;go generate ./...&lt;/code&gt; and &lt;code&gt;make abigen&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install mockery&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;make mockery&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Using the &lt;code&gt;make&lt;/code&gt; command will install the correct version.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Generate and compile static assets:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Prepare your development environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The tests require a postgres database. In turn, the environment variable &lt;code&gt;CL_DATABASE_URL&lt;/code&gt; must be set to value that can connect to &lt;code&gt;_test&lt;/code&gt; database, and the user must be able to create and drop the given &lt;code&gt;_test&lt;/code&gt; database.&lt;/p&gt; 
&lt;p&gt;Note: Other environment variables should not be set for all tests to pass&lt;/p&gt; 
&lt;p&gt;There helper script for initial setup to create an appropriate test user. It requires postgres to be running on localhost at port 5432. You will be prompted for the &lt;code&gt;postgres&lt;/code&gt; user password&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make setup-testdb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script will save the &lt;code&gt;CL_DATABASE_URL&lt;/code&gt; in &lt;code&gt;.dbenv&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Changes to database require migrations to be run. Similarly, &lt;code&gt;pull&lt;/code&gt;'ing the repo may require migrations to run. After the one-time setup above:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source .dbenv
make testdb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you encounter the error &lt;code&gt;database accessed by other users (SQLSTATE 55006) exit status 1&lt;/code&gt; and you want force the database creation then use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source .dbenv
make testdb-force
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;Run tests:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go test ./...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Notes&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;parallel&lt;/code&gt; flag can be used to limit CPU usage, for running tests in the background (&lt;code&gt;-parallel=4&lt;/code&gt;) - the default is &lt;code&gt;GOMAXPROCS&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;p&lt;/code&gt; flag can be used to limit the number of &lt;em&gt;packages&lt;/em&gt; tested concurrently, if they are interferring with one another (&lt;code&gt;-p=1&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;-short&lt;/code&gt; flag skips tests which depend on the database, for quickly spot checking simpler tests in around one minute&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Race Detector&lt;/h4&gt; 
&lt;p&gt;As of Go 1.1, the runtime includes a data race detector, enabled with the &lt;code&gt;-race&lt;/code&gt; flag. This is used in CI via the &lt;code&gt;tools/bin/go_core_race_tests&lt;/code&gt; script. If the action detects a race, the artifact on the summary page will include &lt;code&gt;race.*&lt;/code&gt; files with detailed stack traces.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;&lt;strong&gt;It will not issue false positives, so take its warnings seriously.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For local, targeted race detection, you can run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GORACE="log_path=$PWD/race" go test -race ./core/path/to/pkg -count 10
GORACE="log_path=$PWD/race" go test -race ./core/path/to/pkg -count 100 -run TestFooBar/sub_test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://go.dev/doc/articles/race_detector"&gt;https://go.dev/doc/articles/race_detector&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Fuzz tests&lt;/h4&gt; 
&lt;p&gt;As of Go 1.18, fuzz tests &lt;code&gt;func FuzzXXX(*testing.F)&lt;/code&gt; are included as part of the normal test suite, so existing cases are executed with &lt;code&gt;go test&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can run active fuzzing to search for new cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go test ./pkg/path -run=XXX -fuzz=FuzzTestName
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://go.dev/doc/fuzz/"&gt;https://go.dev/doc/fuzz/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Go Modules&lt;/h3&gt; 
&lt;p&gt;This repository contains three Go modules:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart RL
    github.com/smartcontractkit/chainlink/v2
    github.com/smartcontractkit/chainlink/integration-tests --&amp;gt; github.com/smartcontractkit/chainlink/v2
    github.com/smartcontractkit/chainlink/core/scripts --&amp;gt; github.com/smartcontractkit/chainlink/v2

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;integration-tests&lt;/code&gt; and &lt;code&gt;core/scripts&lt;/code&gt; modules import the root module using a relative replace in their &lt;code&gt;go.mod&lt;/code&gt; files, so dependency changes in the root &lt;code&gt;go.mod&lt;/code&gt; often require changes in those modules as well. After making a change, &lt;code&gt;go mod tidy&lt;/code&gt; can be run on all three modules using:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make gomodtidy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Code Generation&lt;/h3&gt; 
&lt;p&gt;Go generate is used to generate mocks in this project. Mocks are generated with &lt;a href="https://github.com/vektra/mockery"&gt;mockery&lt;/a&gt; and live in core/internal/mocks.&lt;/p&gt; 
&lt;h3&gt;Nix&lt;/h3&gt; 
&lt;p&gt;A &lt;a href="https://nixos.wiki/wiki/Development_environment_with_nix-shell"&gt;shell.nix&lt;/a&gt; is provided for use with the &lt;a href="https://nixos.org/"&gt;Nix package manager&lt;/a&gt;. By default,we utilize the shell through &lt;a href="https://nixos.wiki/wiki/Flakes"&gt;Nix Flakes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Nix defines a declarative, reproducible development environment. Flakes version use deterministic, frozen (&lt;code&gt;flake.lock&lt;/code&gt;) dependencies to gain more consistency/reproducibility on the built artifacts.&lt;/p&gt; 
&lt;p&gt;To use it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;a href="https://nixos.org/download.html"&gt;nix package manager&lt;/a&gt; in your system.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enable &lt;a href="https://nixos.wiki/wiki/Flakes#Enable_flakes"&gt;flakes support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run &lt;code&gt;nix develop&lt;/code&gt;. You will be put in shell containing all the dependencies.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optionally, &lt;code&gt;nix develop --command $SHELL&lt;/code&gt; will make use of your current shell instead of the default (bash).&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;direnv&lt;/code&gt; to enable it automatically when &lt;code&gt;cd&lt;/code&gt;-ing into the folder; for that, enable &lt;a href="https://github.com/nix-community/nix-direnv"&gt;nix-direnv&lt;/a&gt; and &lt;code&gt;use flake&lt;/code&gt; on it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Create a local postgres database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mkdir -p $PGDATA &amp;amp;&amp;amp; cd $PGDATA/
initdb
pg_ctl -l postgres.log -o "--unix_socket_directories='$PWD'" start
createdb chainlink_test -h localhost
createuser --superuser --password chainlink -h localhost
# then type a test password, e.g.: chainlink, and set it in shell.nix CL_DATABASE_URL
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;When re-entering project, you can restart postgres: &lt;code&gt;cd $PGDATA; pg_ctl -l postgres.log -o "--unix_socket_directories='$PWD'" start&lt;/code&gt; Now you can run tests or compile code as usual.&lt;/li&gt; 
 &lt;li&gt;When you're done, stop it: &lt;code&gt;cd $PGDATA; pg_ctl -o "--unix_socket_directories='$PWD'" stop&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Changesets&lt;/h3&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/changesets/changesets"&gt;changesets&lt;/a&gt; to manage versioning for libs and the services.&lt;/p&gt; 
&lt;p&gt;Every PR that modifies any configuration or code, should most likely accompanied by a changeset file.&lt;/p&gt; 
&lt;p&gt;To install &lt;code&gt;changesets&lt;/code&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;code&gt;pnpm&lt;/code&gt; if it is not already installed - &lt;a href="https://pnpm.io/installation"&gt;docs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;pnpm install&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Either after or before you create a commit, run the &lt;code&gt;pnpm changeset&lt;/code&gt; command to create an accompanying changeset entry which will reflect on the CHANGELOG for the next release.&lt;/p&gt; 
&lt;p&gt;The format is based on &lt;a href="https://keepachangelog.com/en/1.0.0/"&gt;Keep a Changelog&lt;/a&gt;,&lt;/p&gt; 
&lt;p&gt;and this project adheres to &lt;a href="https://semver.org/spec/v2.0.0.html"&gt;Semantic Versioning&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tips&lt;/h3&gt; 
&lt;p&gt;For more tips on how to build and test Chainlink, see our &lt;a href="https://github.com/smartcontractkit/chainlink/wiki/Development-Tips"&gt;development tips page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome to Chainlink's source code.&lt;/p&gt; 
&lt;p&gt;Please check out our &lt;a href="https://raw.githubusercontent.com/smartcontractkit/chainlink/develop/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Thank you!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/alloy</title>
      <link>https://github.com/grafana/alloy</link>
      <description>&lt;p&gt;OpenTelemetry Collector distribution with programmable pipelines&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_light.svg#gh-dark-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_dark.svg#gh-light-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/grafana/alloy/releases"&gt;&lt;img src="https://img.shields.io/github/release/grafana/alloy.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://grafana.com/docs/alloy/latest"&gt;&lt;img src="https://img.shields.io/badge/Documentation-link-blue?logo=gitbook" alt="Documentation link" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Grafana Alloy is an open source OpenTelemetry Collector distribution with built-in Prometheus pipelines and support for metrics, logs, traces, and profiles.&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/alloy_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;What can Alloy do?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Programmable pipelines&lt;/strong&gt;: Use a rich &lt;a href="https://grafana.com/docs/alloy/latest/concepts/configuration-syntax/"&gt;expression-based syntax&lt;/a&gt; for configuring powerful observability pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenTelemetry Collector Distribution&lt;/strong&gt;: Alloy is a &lt;a href="https://opentelemetry.io/docs/collector/distributions/"&gt;distribution&lt;/a&gt; of OpenTelemetry Collector and supports dozens of its components, alongside new components that make use of Alloy's programmable pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Big tent&lt;/strong&gt;: Alloy embraces Grafana's "big tent" philosophy, where Alloy can be used with other vendors or open source databases. It has components to perfectly integrate with multiple telemetry ecosystems:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://opentelemetry.io"&gt;OpenTelemetry Collector&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/loki"&gt;Grafana Loki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/pyroscope"&gt;Grafana Pyroscope&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kubernetes-native&lt;/strong&gt;: Use components to interact with native and custom Kubernetes resources; no need to learn how to use a separate Kubernetes operator.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shareable pipelines&lt;/strong&gt;: Use &lt;a href="https://grafana.com/docs/alloy/latest/concepts/modules/"&gt;modules&lt;/a&gt; to share your pipelines with the world.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic workload distribution&lt;/strong&gt;: Configure Alloy instances to form a &lt;a href="https://grafana.com/docs/alloy/latest/concepts/clustering/"&gt;cluster&lt;/a&gt; for automatic workload distribution.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Centralized configuration support&lt;/strong&gt;: Alloy supports retrieving its configuration from a &lt;a href="https://grafana.com/docs/alloy/latest/reference/config-blocks/remotecfg/"&gt;server&lt;/a&gt; for centralized configuration management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Debugging utilities&lt;/strong&gt;: Use the &lt;a href="https://grafana.com/docs/alloy/latest/tasks/debug/"&gt;built-in UI&lt;/a&gt; for visualizing and debugging pipelines.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-alloy"&gt;otelcol.receiver.otlp "example" {
  grpc {
    endpoint = "127.0.0.1:4317"
  }

  output {
    metrics = [otelcol.processor.batch.example.input]
    logs    = [otelcol.processor.batch.example.input]
    traces  = [otelcol.processor.batch.example.input]
  }
}

otelcol.processor.batch "example" {
  output {
    metrics = [otelcol.exporter.otlp.default.input]
    logs    = [otelcol.exporter.otlp.default.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = "my-otlp-grpc-server:4317"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://grafana.com/docs/alloy/latest"&gt;documentation&lt;/a&gt; to see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/alloy/latest/get-started/install/"&gt;Installation instructions&lt;/a&gt; for Alloy&lt;/li&gt; 
 &lt;li&gt;Steps for &lt;a href="https://grafana.com/docs/alloy/latest/get-started/"&gt;Getting started&lt;/a&gt; with Alloy&lt;/li&gt; 
 &lt;li&gt;The list of Alloy &lt;a href="https://grafana.com/docs/alloy/latest/reference/components/"&gt;components&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release cadence&lt;/h2&gt; 
&lt;p&gt;A new minor release is planned every six weeks.&lt;/p&gt; 
&lt;p&gt;The release cadence is best-effort: if necessary, releases may be performed outside of this cadence, or a scheduled release date can be moved forwards or backwards.&lt;/p&gt; 
&lt;p&gt;Minor releases published on cadence include updating dependencies for upstream OpenTelemetry Collector code if new versions are available. Minor releases published outside of the release cadence may not include these dependency updates.&lt;/p&gt; 
&lt;p&gt;Patch and security releases may be published at any time.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To engage with the Alloy community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Chat with us on our community Slack channel. To invite yourself to the Grafana Slack, visit &lt;a href="https://slack.grafana.com/"&gt;https://slack.grafana.com/&lt;/a&gt; and join the &lt;code&gt;#alloy&lt;/code&gt; channel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ask questions on the &lt;a href="https://community.grafana.com/c/grafana-alloy"&gt;Grafana community site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/grafana/alloy/issues/new"&gt;File an issue&lt;/a&gt; for bugs, issues, and feature suggestions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Attend the monthly &lt;a href="https://docs.google.com/document/d/1TqaZD1JPfNadZ4V81OCBPCG_TksDYGlNlGdMnTWUSpo"&gt;community call&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/grafana/alloy/raw/main/docs/developer/contributing.md"&gt;contributors guide&lt;/a&gt; to learn how to contribute.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who have already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/grafana/alloy/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=grafana/alloy" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Notifuse/notifuse</title>
      <link>https://github.com/Notifuse/notifuse</link>
      <description>&lt;p&gt;Notifuse is an open-source &amp; modern emailing platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Notifuse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/Notifuse/notifuse"&gt;&lt;img src="https://img.shields.io/badge/go%20report-A+-brightgreen.svg?style=flat" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Notifuse/notifuse/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/Notifuse/notifuse/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Go" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/Notifuse/notifuse"&gt;&lt;img src="https://codecov.io/gh/Notifuse/notifuse/graph/badge.svg?token=VZ0HBEM9OZ" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;üéØ Try the Live Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The open-source alternative to Mailchimp, Brevo, Mailjet, Listmonk, Mailerlite, and Klaviyo, Loop.so, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Notifuse is a modern, self-hosted emailing platform that allows you to send newsletters and transactional emails at a fraction of the cost. Built with Go and React, it provides enterprise-grade features with the flexibility of open-source software.&lt;/p&gt; 
&lt;img src="https://www.notifuse.com/_astro/email_editor.CGyLoCOD.png" alt="Email Editor" /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;h3&gt;üìß Email Marketing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Email Builder&lt;/strong&gt;: Drag-and-drop editor with MJML components and real-time preview&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Management&lt;/strong&gt;: Create, schedule, and send targeted email campaigns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A/B Testing&lt;/strong&gt;: Optimize campaigns with built-in testing for subject lines, content, and send times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List Management&lt;/strong&gt;: Advanced subscriber segmentation and list organization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact Profiles&lt;/strong&gt;: Rich contact management with custom fields and detailed profiles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß Developer-Friendly&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Setup&lt;/strong&gt;: Interactive setup wizard for quick deployment and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transactional API&lt;/strong&gt;: Powerful REST API for automated email delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook Integration&lt;/strong&gt;: Real-time event notifications and integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Liquid Templating&lt;/strong&gt;: Dynamic content with variables like &lt;code&gt;{{ contact.first_name }}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Provider Support&lt;/strong&gt;: Connect with Amazon SES, Mailgun, Postmark, Mailjet, SparkPost, and SMTP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä Analytics &amp;amp; Insights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open &amp;amp; Click Tracking&lt;/strong&gt;: Detailed engagement metrics and campaign performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Analytics&lt;/strong&gt;: Monitor delivery rates, opens, clicks, and conversions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Reports&lt;/strong&gt;: Comprehensive reporting and analytics dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üé® Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;S3 File Manager&lt;/strong&gt;: Integrated file management with CDN delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Centralized notification system for your applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Templates&lt;/strong&gt;: Mobile-optimized email templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Fields&lt;/strong&gt;: Flexible contact data management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workspace Management&lt;/strong&gt;: Multi-tenant support for teams and agencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;Notifuse follows clean architecture principles with clear separation of concerns:&lt;/p&gt; 
&lt;h3&gt;Backend (Go)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Domain Layer&lt;/strong&gt;: Core business logic and entities (&lt;code&gt;internal/domain/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service Layer&lt;/strong&gt;: Business logic implementation (&lt;code&gt;internal/service/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository Layer&lt;/strong&gt;: Data access and storage (&lt;code&gt;internal/repository/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Layer&lt;/strong&gt;: API handlers and middleware (&lt;code&gt;internal/http/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Frontend (React)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Console&lt;/strong&gt;: Admin interface built with React, Ant Design, and TypeScript (&lt;code&gt;console/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Embeddable widget for customer notifications (&lt;code&gt;notification_center/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;: Primary data storage with Squirrel query builder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÅ Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;‚îú‚îÄ‚îÄ cmd/                    # Application entry points
‚îú‚îÄ‚îÄ internal/               # Private application code
‚îÇ   ‚îú‚îÄ‚îÄ domain/            # Business entities and logic
‚îÇ   ‚îú‚îÄ‚îÄ service/           # Business logic implementation
‚îÇ   ‚îú‚îÄ‚îÄ repository/        # Data access layer
‚îÇ   ‚îú‚îÄ‚îÄ http/              # HTTP handlers and middleware
‚îÇ   ‚îî‚îÄ‚îÄ database/          # Database configuration
‚îú‚îÄ‚îÄ console/               # React-based admin interface
‚îú‚îÄ‚îÄ notification_center/   # Embeddable notification widget
‚îú‚îÄ‚îÄ pkg/                   # Public packages
‚îî‚îÄ‚îÄ config/                # Configuration files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;p&gt;For installation instructions, configuration options, and deployment guides, see:&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://docs.notifuse.com/installation"&gt;docs.notifuse.com/installation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.notifuse.com"&gt;Complete Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes&lt;/li&gt; 
 &lt;li&gt;Add tests&lt;/li&gt; 
 &lt;li&gt;Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Notifuse is released under the &lt;a href="https://raw.githubusercontent.com/Notifuse/notifuse/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üÜò Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://docs.notifuse.com"&gt;docs.notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Email Support&lt;/strong&gt;: &lt;a href="mailto:hello@notifuse.com"&gt;hello@notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/Notifuse/notifuse/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Why Choose Notifuse?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üí∞ Cost-Effective&lt;/strong&gt;: Self-hosted solution with no per-email pricing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Privacy-First&lt;/strong&gt;: Your data stays on your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ†Ô∏è Customizable&lt;/strong&gt;: Open-source with extensive customization options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Scalable&lt;/strong&gt;: Built to handle millions of emails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Modern&lt;/strong&gt;: Built with modern technologies and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Developer-Friendly&lt;/strong&gt;: Comprehensive API and webhook support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to get started?&lt;/strong&gt; &lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;Try the live demo&lt;/a&gt; or &lt;a href="https://docs.notifuse.com"&gt;deploy your own instance&lt;/a&gt; in minutes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.1.3-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/pipeline.jpg" alt="weknora-pipeline.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, suitable for both developers and business users&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start all services (Ollama + backend containers)
./scripts/start_all.sh
# Or
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (backup)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start ollama services (Optional)
ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;

# Start the service
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On first access, it will automatically redirect to the initialization configuration page. After configuration is complete, it will automatically redirect to the knowledge base page. Please follow the page instructions to complete model configuration.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/config.png" alt="Configuration Page" /&gt;&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Upload&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledges.png" alt="Knowledge Upload Interface" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Q&amp;amp;A Entry&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/qa.png" alt="Q&amp;amp;A Entry Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Rich Text &amp;amp; Image Responses&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/answer.png" alt="Rich Answer Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for dragging and dropping various documents, automatically identifying document structures and extracting core knowledge to establish indexes. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph2.png" alt="Knowledge Graph View 1" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph1.png" alt="Knowledge Graph View 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;h3&gt;MCP Server Integration Effects&lt;/h3&gt; 
&lt;img width="950" height="2063" alt="MCP Server Integration Demo" src="https://github.com/user-attachments/assets/09111ec8-0489-415c-969d-aa3835778e14" /&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îú‚îÄ‚îÄ scripts/     # Shell scripts
‚îú‚îÄ‚îÄ services/    # Microservice logic
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îî‚îÄ‚îÄ docs/        # Project documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîß Common Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Wipe all data from DB (use with caution)
make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chaitin/SafeLine</title>
      <link>https://github.com/chaitin/SafeLine</link>
      <description>&lt;p&gt;SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/banner.png" width="400" /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; SafeLine - Make your web apps secure &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://ly.safepoint.cloud/laA8asp"&gt;üè† Website&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/w2AeHhb"&gt;üìñ Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/hSMd4SH"&gt;üîç Live Demo&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;üôã‚Äç‚ôÇÔ∏è Discord&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/README_CN.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üëã INTRODUCTION&lt;/h2&gt; 
&lt;p&gt;SafeLine is a self-hosted &lt;strong&gt;&lt;code&gt;WAF(Web Application Firewall)&lt;/code&gt;&lt;/strong&gt; to protect your web apps from attacks and exploits.&lt;/p&gt; 
&lt;p&gt;A web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;ldap injection&lt;/code&gt;, &lt;code&gt;xpath injection&lt;/code&gt;, &lt;code&gt;RCE&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt;, &lt;code&gt;backdoor&lt;/code&gt;, &lt;code&gt;bruteforce&lt;/code&gt;, &lt;code&gt;http-flood&lt;/code&gt;, &lt;code&gt;bot abused&lt;/code&gt;, among others.&lt;/p&gt; 
&lt;h4&gt;üí° How It Works&lt;/h4&gt; 
&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/how-it-works.png" width="800" /&gt; 
&lt;p&gt;By deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine‚Äôs identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.&lt;/p&gt; 
&lt;p&gt;A WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.&lt;/p&gt; 
&lt;p&gt;its core capabilities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Defenses for web attacks&lt;/li&gt; 
 &lt;li&gt;Proactive bot abused defense&lt;/li&gt; 
 &lt;li&gt;HTML &amp;amp; JS code encryption&lt;/li&gt; 
 &lt;li&gt;IP-based rate limiting&lt;/li&gt; 
 &lt;li&gt;Web Access Control List&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö°Ô∏è Screenshots&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-1.png" width="370" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-2.png" width="370" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-3.png" width="370" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-4.png" width="370" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Get &lt;a href="https://demo.waf.chaitin.com:9443/"&gt;Live Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üî• FEATURES&lt;/h2&gt; 
&lt;p&gt;List of the main features as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;It defenses for all of web attacks, such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt; and so on.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defend your web apps against &lt;code&gt;DoS attacks&lt;/code&gt;, &lt;code&gt;bruteforce attempts&lt;/code&gt;, &lt;code&gt;traffic surges&lt;/code&gt;, and other types of abuse by throttling traffic that exceeds defined limits.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anti-Bot challenges to protect your website from &lt;code&gt;bot attacks&lt;/code&gt;, humen users will be allowed, crawlers and bots will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Authentication Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Dynamic Protection&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üß© Showcases&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Legitimate User&lt;/th&gt; 
   &lt;th&gt;Malicious User&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-attack-detected.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-access-too-fast.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Auth Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;HTML Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;JS Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] ‰∏≠ÂõΩÂ§ßÈôÜÁî®Êà∑ÂÆâË£ÖÂõΩÈôÖÁâàÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËøûÊé•‰∫ëÊúçÂä°ÔºåËØ∑Êü•Áúã &lt;a href="https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0"&gt;‰∏≠ÊñáÁâàÂÆâË£ÖÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üì¶ Installing&lt;/h4&gt; 
&lt;p&gt;Information on how to install SafeLine can be found in the &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/Deploy"&gt;Install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;‚öôÔ∏è Protecting Web Apps&lt;/h4&gt; 
&lt;p&gt;to see &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/AddApplication"&gt;Configuration&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìã More Informations&lt;/h2&gt; 
&lt;h4&gt;Effect Evaluation&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;ModSecurity, Level 1&lt;/th&gt; 
   &lt;th&gt;CloudFlare, Free&lt;/th&gt; 
   &lt;th&gt;SafeLine, Balance&lt;/th&gt; 
   &lt;th&gt;SafeLine, Strict&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total Samples&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Detection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;69.74%&lt;/td&gt; 
   &lt;td&gt;10.70%&lt;/td&gt; 
   &lt;td&gt;71.65%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.17%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;False Positive&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;17.58%&lt;/td&gt; 
   &lt;td&gt;0.07%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.07%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;0.22%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;82.20%&lt;/td&gt; 
   &lt;td&gt;98.40%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;99.45%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;99.38%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Is SafeLine Production-Ready?&lt;/h4&gt; 
&lt;p&gt;Yes, SafeLine is production-ready.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Over 180,000 installations worldwide&lt;/li&gt; 
 &lt;li&gt;Protecting over 1,000,000 Websites&lt;/li&gt; 
 &lt;li&gt;Handling over 30,000,000,000 HTTP Requests Daily&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üôã‚Äç‚ôÇÔ∏è Community&lt;/h4&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/SVnZGzHFvn"&gt;Discord&lt;/a&gt; to get community support, the core team members are identified by the STAFF role in Discord.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243120292822253598"&gt;#feedback&lt;/a&gt;: for new features discussion.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1263761679619981413"&gt;#FAQ&lt;/a&gt;: for FAQ.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243115843919806486"&gt;#general&lt;/a&gt;: for any other questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Several contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://x.com/safeline_waf"&gt;&lt;img src="https://img.shields.io/badge/X.com-000000?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=flat&amp;amp;logo=wechat&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h4&gt;üí™ PRO Edition&lt;/h4&gt; 
&lt;p&gt;Coming soon!&lt;/p&gt; 
&lt;h4&gt;üìù License&lt;/h4&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/chaitin/SafeLine/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juanfont/headscale</title>
      <link>https://github.com/juanfont/headscale</link>
      <description>&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juanfont/headscale/main/docs/logo/headscale3_header_stacked_left.png" alt="headscale logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/juanfont/headscale/actions/workflows/test.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/c84AZQhmpx"&gt;Discord server&lt;/a&gt; for a chat.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Always select the same GitHub tag as the released version you use to ensure you have the correct example configuration. The &lt;code&gt;main&lt;/code&gt; branch might contain unreleased changes. The documentation is available for stable and development versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/stable/"&gt;Documentation for the stable version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/development/"&gt;Documentation for the development version&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Tailscale&lt;/h2&gt; 
&lt;p&gt;Tailscale is &lt;a href="https://tailscale.com/"&gt;a modern VPN&lt;/a&gt; built on top of &lt;a href="https://www.wireguard.com/"&gt;Wireguard&lt;/a&gt;. It &lt;a href="https://tailscale.com/blog/how-tailscale-works/"&gt;works like an overlay network&lt;/a&gt; between the computers of your networks - using &lt;a href="https://tailscale.com/blog/how-nat-traversal-works/"&gt;NAT traversal&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Everything in Tailscale is Open Source, except the GUI clients for proprietary OS (Windows and macOS/iOS), and the control server.&lt;/p&gt; 
&lt;p&gt;The control server works as an exchange point of Wireguard public keys for the nodes in the Tailscale network. It assigns the IP addresses of the clients, creates the boundaries between each user, enables sharing machines between users, and exposes the advertised routes of your nodes.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://tailscale.com/kb/1136/tailnet/"&gt;Tailscale network (tailnet)&lt;/a&gt; is private network which Tailscale assigns to a user in terms of private users or an organisation.&lt;/p&gt; 
&lt;h2&gt;Design goal&lt;/h2&gt; 
&lt;p&gt;Headscale aims to implement a self-hosted, open source alternative to the &lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; control server. Headscale's goal is to provide self-hosters and hobbyists with an open-source server they can use for their projects and labs. It implements a narrow scope, a &lt;em&gt;single&lt;/em&gt; Tailscale network (tailnet), suitable for a personal use, or a small open-source organisation.&lt;/p&gt; 
&lt;h2&gt;Supporting Headscale&lt;/h2&gt; 
&lt;p&gt;If you like &lt;code&gt;headscale&lt;/code&gt; and find it useful, there is a sponsorship and donation buttons available in the repo.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/features/"&gt;"Features" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client OS support&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/clients/"&gt;"Client and operating system support" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running headscale&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Please note that we do not support nor encourage the use of reverse proxies and container to run Headscale.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please have a look at the &lt;a href="https://headscale.net/stable/"&gt;&lt;code&gt;documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Talks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fosdem 2023 (video): &lt;a href="https://fosdem.org/2023/schedule/event/goheadscale/"&gt;Headscale: How we are using integration testing to reimplement Tailscale&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;presented by Juan Font Alonso and Kristoffer Dalby&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is not associated with Tailscale Inc.&lt;/p&gt; 
&lt;p&gt;However, one of the active maintainers for Headscale &lt;a href="https://tailscale.com/blog/opensource"&gt;is employed by Tailscale&lt;/a&gt; and he is allowed to spend work hours contributing to the project. Contributions from this maintainer are reviewed by other maintainers.&lt;/p&gt; 
&lt;p&gt;The maintainers work together on setting the direction for the project. The underlying principle is to serve the community of self-hosters, enthusiasts and hobbyists - while having a sustainable project.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/juanfont/headscale/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;To contribute to headscale you would need the latest version of &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; and &lt;a href="https://buf.build"&gt;Buf&lt;/a&gt; (Protobuf generator).&lt;/p&gt; 
&lt;p&gt;We recommend using &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt; to setup a development environment. This can be done with &lt;code&gt;nix develop&lt;/code&gt;, which will install the tools and give you a shell. This guarantees that you will have the same dev env as &lt;code&gt;headscale&lt;/code&gt; maintainers.&lt;/p&gt; 
&lt;h3&gt;Code style&lt;/h3&gt; 
&lt;p&gt;To ensure we have some consistency with a growing number of contributions, this project has adopted linting and style/formatting rules:&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Go&lt;/strong&gt; code is linted with &lt;a href="https://golangci-lint.run"&gt;&lt;code&gt;golangci-lint&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://github.com/segmentio/golines"&gt;&lt;code&gt;golines&lt;/code&gt;&lt;/a&gt; (width 88) and &lt;a href="https://github.com/mvdan/gofumpt"&gt;&lt;code&gt;gofumpt&lt;/code&gt;&lt;/a&gt;. Please configure your editor to run the tools while developing and make sure to run &lt;code&gt;make lint&lt;/code&gt; and &lt;code&gt;make fmt&lt;/code&gt; before committing any code.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Proto&lt;/strong&gt; code is linted with &lt;a href="https://docs.buf.build/lint/overview"&gt;&lt;code&gt;buf&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;&lt;code&gt;clang-format&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;rest&lt;/strong&gt; (Markdown, YAML, etc) is formatted with &lt;a href="https://prettier.io"&gt;&lt;code&gt;prettier&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;code&gt;.golangci.yaml&lt;/code&gt; and &lt;code&gt;Makefile&lt;/code&gt; to see the specific configuration.&lt;/p&gt; 
&lt;h3&gt;Install development tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go&lt;/li&gt; 
 &lt;li&gt;Buf&lt;/li&gt; 
 &lt;li&gt;Protobuf tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Install and activate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing and building&lt;/h3&gt; 
&lt;p&gt;Some parts of the project require the generation of Go code from Protobuf (if changes are made in &lt;code&gt;proto/&lt;/code&gt;) and it must be (re-)generated with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check in changes from &lt;code&gt;gen/&lt;/code&gt; in a separate commit to make it easier to review.&lt;/p&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;p&gt;We recommend using Nix for dependency management to ensure you have all required tools. If you prefer to manage dependencies yourself, you can use Make directly:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With Nix (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With your own dependencies:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Makefile will warn you if any required tools are missing and suggest running &lt;code&gt;nix develop&lt;/code&gt;. Run &lt;code&gt;make help&lt;/code&gt; to see all available targets.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/juanfont/headscale/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=juanfont/headscale" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tailscale/tailscale</title>
      <link>https://github.com/tailscale/tailscale</link>
      <description>&lt;p&gt;The easiest, most secure way to use WireGuard and 2FA.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tailscale&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com"&gt;https://tailscale.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Private WireGuard¬Æ networks made easy&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the majority of Tailscale's open source code. Notably, it includes the &lt;code&gt;tailscaled&lt;/code&gt; daemon and the &lt;code&gt;tailscale&lt;/code&gt; CLI tool. The &lt;code&gt;tailscaled&lt;/code&gt; daemon runs on Linux, Windows, &lt;a href="https://tailscale.com/kb/1065/macos-variants/"&gt;macOS&lt;/a&gt;, and to varying degrees on FreeBSD and OpenBSD. The Tailscale iOS and Android apps use this repo's code, but this repo doesn't contain the mobile GUI code.&lt;/p&gt; 
&lt;p&gt;Other &lt;a href="https://github.com/orgs/tailscale/repositories"&gt;Tailscale repos&lt;/a&gt; of note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the Android app is at &lt;a href="https://github.com/tailscale/tailscale-android"&gt;https://github.com/tailscale/tailscale-android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Synology package is at &lt;a href="https://github.com/tailscale/tailscale-synology"&gt;https://github.com/tailscale/tailscale-synology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the QNAP package is at &lt;a href="https://github.com/tailscale/tailscale-qpkg"&gt;https://github.com/tailscale/tailscale-qpkg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Chocolatey packaging is at &lt;a href="https://github.com/tailscale/tailscale-chocolatey"&gt;https://github.com/tailscale/tailscale-chocolatey&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For background on which parts of Tailscale are open source and why, see &lt;a href="https://tailscale.com/opensource/"&gt;https://tailscale.com/opensource/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Using&lt;/h2&gt; 
&lt;p&gt;We serve packages for a variety of distros and platforms at &lt;a href="https://pkgs.tailscale.com/"&gt;https://pkgs.tailscale.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Other clients&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://tailscale.com/download"&gt;macOS, iOS, and Windows clients&lt;/a&gt; use the code in this repository but additionally include small GUI wrappers. The GUI wrappers on non-open source platforms are themselves not open source.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;We always require the latest Go release, currently Go 1.25. (While we build releases with our &lt;a href="https://github.com/tailscale/go/"&gt;Go fork&lt;/a&gt;, its use is not required.)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install tailscale.com/cmd/tailscale{,d}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're packaging Tailscale for distribution, use &lt;code&gt;build_dist.sh&lt;/code&gt; instead, to burn commit IDs and version info into the binaries:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./build_dist.sh tailscale.com/cmd/tailscale
./build_dist.sh tailscale.com/cmd/tailscaled
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your distro has conventions that preclude the use of &lt;code&gt;build_dist.sh&lt;/code&gt;, please do the equivalent of what it does in your distro's way, so that bug reports contain useful version information.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Please file any issues about this code or the hosted service on &lt;a href="https://github.com/tailscale/tailscale/issues"&gt;the issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PRs welcome! But please file bugs. Commit messages should &lt;a href="https://docs.github.com/en/github/writing-on-github/autolinked-references-and-urls"&gt;reference bugs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We require &lt;a href="https://en.wikipedia.org/wiki/Developer_Certificate_of_Origin"&gt;Developer Certificate of Origin&lt;/a&gt; &lt;code&gt;Signed-off-by&lt;/code&gt; lines in commits.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tailscale/tailscale/main/docs/commit-messages.md"&gt;commit-messages.md&lt;/a&gt; (or skim &lt;code&gt;git log&lt;/code&gt;) for our commit message style.&lt;/p&gt; 
&lt;h2&gt;About Us&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; is primarily developed by the people at &lt;a href="https://github.com/orgs/tailscale/people"&gt;https://github.com/orgs/tailscale/people&lt;/a&gt;. For other contributors, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale/graphs/contributors"&gt;https://github.com/tailscale/tailscale/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale-android/graphs/contributors"&gt;https://github.com/tailscale/tailscale-android/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;WireGuard is a registered trademark of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ollama/ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>&lt;p&gt;Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
  &amp;nbsp; 
 &lt;a href="https://ollama.com"&gt; &lt;img alt="ollama" width="240" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Ollama&lt;/h1&gt; 
&lt;p&gt;Get up and running with large language models.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/Ollama.dmg"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/OllamaSetup.exe"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -fsSL https://ollama.com/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.ollama.com/linux#manual-install"&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href="https://hub.docker.com/r/ollama/ollama"&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-python"&gt;ollama-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-js"&gt;ollama-js&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/ollama"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/ollama"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To run and chat with &lt;a href="https://ollama.com/library/gemma3"&gt;Gemma 3&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run gemma3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model library&lt;/h2&gt; 
&lt;p&gt;Ollama supports a list of models available on &lt;a href="https://ollama.com/library" title="ollama model library"&gt;ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some example models that can be downloaded:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Parameters&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;815MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;3.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;8.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:12b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;27B&lt;/td&gt; 
   &lt;td&gt;17GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:27b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QwQ&lt;/td&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run qwq&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;671B&lt;/td&gt; 
   &lt;td&gt;404GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1:671b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;109B&lt;/td&gt; 
   &lt;td&gt;67GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:scout&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;400B&lt;/td&gt; 
   &lt;td&gt;245GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:maverick&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3&lt;/td&gt; 
   &lt;td&gt;70B&lt;/td&gt; 
   &lt;td&gt;43GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;2.0GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;1.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;11B&lt;/td&gt; 
   &lt;td&gt;7.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;90B&lt;/td&gt; 
   &lt;td&gt;55GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision:90b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;405B&lt;/td&gt; 
   &lt;td&gt;231GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1:405b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;9.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4 Mini&lt;/td&gt; 
   &lt;td&gt;3.8B&lt;/td&gt; 
   &lt;td&gt;2.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4-mini&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Moondream 2&lt;/td&gt; 
   &lt;td&gt;1.4B&lt;/td&gt; 
   &lt;td&gt;829MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run moondream&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Neural Chat&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starling&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Llama&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLaVA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Granite-3.3&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run granite3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Customize a model&lt;/h2&gt; 
&lt;h3&gt;Import from GGUF&lt;/h3&gt; 
&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama create example -f Modelfile
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama run example
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Import from Safetensors&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://docs.ollama.com/import"&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; 
&lt;h3&gt;Customize a prompt&lt;/h3&gt; 
&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama3.2&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, create and run the model:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile
ollama run mario
&amp;gt;&amp;gt;&amp;gt; hi
Hello! It's your friend Mario.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on working with a Modelfile, see the &lt;a href="https://docs.ollama.com/modelfile"&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;h3&gt;Create a model&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama create mymodel -f ./Modelfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pull a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Remove a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama rm llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama cp llama3.2 my-model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiline input&lt;/h3&gt; 
&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;"""&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multimodal models&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ollama run llava "What's in this image? /Users/jmorgan/Desktop/smile.png"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: The image features a yellow smiley face, which is likely the central focus of the picture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pass the prompt as an argument&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run llama3.2 "Summarize this file: $(cat README.md)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Show model information&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama show llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List models on your computer&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List which models are currently loaded&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stop a model which is currently running&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama stop llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/development.md"&gt;developer guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Running local builds&lt;/h3&gt; 
&lt;p&gt;Next, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama run llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;REST API&lt;/h2&gt; 
&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; 
&lt;h3&gt;Generate a response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat with a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md"&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; 
&lt;h2&gt;Community Integrations&lt;/h2&gt; 
&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-webui/open-webui"&gt;Open WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat (macOS with ReactNative)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted (macOS native)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fmaclen/hollama"&gt;Hollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms-webui"&gt;Lollms-Webui&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danny-avila/LibreChat"&gt;LibreChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bionic-gpt/bionic-gpt"&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rtcfirefly/ollama-ui"&gt;HTML UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jikkuatwork/saddle"&gt;Saddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tagspaces.org"&gt;TagSpaces&lt;/a&gt; (A platform for file-based apps, &lt;a href="https://docs.tagspaces.org/ai/"&gt;utilizing Ollama&lt;/a&gt; for the generation of tags and descriptions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivanfioravanti/chatbot-ollama"&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mckaywrigley/chatbot-ui"&gt;Chatbot UI v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file"&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richawo/minimal-llm-ui"&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/Ollamac"&gt;Ollamac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enricoros/big-AGI"&gt;big-AGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheshire-cat-ai/core"&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;Amica&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BruceMacD/chatd"&gt;chatd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kghandour/Ollama-SwiftUI"&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui"&gt;NextJS Web Interface for Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://msty.app"&gt;Msty&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bin-Huang/Chatbox"&gt;Chatbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot"&gt;WinForm Ollama Copilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web"&gt;NextChat&lt;/a&gt; with &lt;a href="https://docs.nextchat.dev/models/ollama"&gt;Get Started Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmo80/alpaca-webui"&gt;Alpaca WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enoch1118/ollamaGUI"&gt;OllamaGUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/OpenAOE"&gt;OpenAOE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leonid20000/OdinRunes"&gt;Odin Runes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mrdjohnson/llm-x"&gt;LLM-X&lt;/a&gt; (Progressive Web App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mintplex-Labs/anything-llm"&gt;AnythingLLM (Docker + MacOs/Windows/Linux native app)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_basic_chat"&gt;Ollama Basic Chat: Uses HyperDiv Reactive UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drazdra/ollama-chats"&gt;Ollama-chats RPG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt; (AI-powered assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/jirapt"&gt;Jirapt&lt;/a&gt; (Jira Integration to generate issues, tasks, epics)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/ojira"&gt;ojira&lt;/a&gt; (Jira chrome plugin to easily generate descriptions for tasks)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/QA-Pilot"&gt;QA-Pilot&lt;/a&gt; (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sugarforever/chat-ollama"&gt;ChatOllama&lt;/a&gt; (Open Source Chatbot based on Ollama with Knowledge Bases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat"&gt;CRAG Ollama Chat&lt;/a&gt; (Simple Web Search with Corrective RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; (Open-source Retrieval-Augmented Generation engine based on deep document understanding)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold"&gt;StreamDeploy&lt;/a&gt; (LLM Application Scaffold)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/swuecho/chat"&gt;chat&lt;/a&gt; (chat web app for teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;Lobe Chat&lt;/a&gt; with &lt;a href="https://lobehub.com/docs/self-hosting/examples/ollama"&gt;Integrating Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datvodinh/rag-chatbot.git"&gt;Ollama RAG Chatbot&lt;/a&gt; (Local Chat with multiple PDFs using Ollama and RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt; (Flexible native client with RAG &amp;amp; multi-agent automation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Renset/macai"&gt;macai&lt;/a&gt; (macOS client for Ollama, ChatGPT, and other compatible API back-ends)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/RWKV-Runner"&gt;RWKV-Runner&lt;/a&gt; (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dezoito/ollama-grid-search"&gt;Ollama Grid Search&lt;/a&gt; (app to evaluate and compare models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Otacon/olpaka"&gt;Olpaka&lt;/a&gt; (User-friendly Flutter Web App for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CrazyNeil/OllamaSpring"&gt;OllamaSpring&lt;/a&gt; (Ollama Client for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kartikm7/llocal"&gt;LLocal.in&lt;/a&gt; (Easy to use Electron Desktop Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dcSpark/shinkai-apps"&gt;Shinkai Desktop&lt;/a&gt; (Two click install Local AI using Ollama + Files + RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeyoyt/ailama"&gt;AiLama&lt;/a&gt; (A Discord User App that allows you to interact with Ollama anywhere in Discord)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_mesop/"&gt;Ollama with Google Mesop&lt;/a&gt; (Mesop Chat Client implementation with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciPhi-AI/R2R"&gt;R2R&lt;/a&gt; (Open-source RAG engine)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elearningshow/ollama-kis"&gt;Ollama-Kis&lt;/a&gt; (A simple easy-to-use GUI with sample custom LLM for Drivers Education)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opengpa.org"&gt;OpenGPA&lt;/a&gt; (Open-source offline-first Enterprise Agentic Application)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateuszmigas/painting-droid"&gt;Painting Droid&lt;/a&gt; (Painting app with AI integrations)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kerlig.com/"&gt;Kerlig AI&lt;/a&gt; (AI writing assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;AI Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyopak/sidellama"&gt;Sidellama&lt;/a&gt; (browser-based LLM client)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;LLMStack&lt;/a&gt; (No-code multi-agent framework to build LLM agents and workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boltai.com"&gt;BoltAI for Mac&lt;/a&gt; (AI Chat Client for Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/av/harbor"&gt;Harbor&lt;/a&gt; (Containerized LLM Toolkit with Ollama as default backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/szczyglis-dev/py-gpt"&gt;PyGPT&lt;/a&gt; (AI desktop assistant for Linux, Windows, and Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jeffser/Alpaca"&gt;Alpaca&lt;/a&gt; (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/docs/content/platform/ollama.md"&gt;AutoGPT&lt;/a&gt; (AutoGPT Ollama integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jonathanhecl.com/go-crew/"&gt;Go-CREW&lt;/a&gt; (Powerful Offline RAG in Golang)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvmp/partcad/"&gt;PartCAD&lt;/a&gt; (CAD model generation with OpenSCAD and CadQuery)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j-web-ui"&gt;Ollama4j Web UI&lt;/a&gt; - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kspviswa/pyOllaMx"&gt;PyOllaMx&lt;/a&gt; - macOS application capable of chatting with both Ollama and Apple MLX models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt; - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kangfenmao/cherry-studio"&gt;Cherry Studio&lt;/a&gt; (Desktop client with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nickthecook/archyve"&gt;Archyve&lt;/a&gt; (RAG-enabling document library)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama-crew-mesop"&gt;crewAI with Mesop&lt;/a&gt; (Mesop Web Interface to run crewAI with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chyok/ollama-gui"&gt;Tkinter-based client&lt;/a&gt; (Python tkinter-based Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trendy-design/llmchat"&gt;LLMChat&lt;/a&gt; (Privacy focused, 100% local, intuitive all-in-one chat interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat"&gt;Local Multimodal AI Chat&lt;/a&gt; (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xark-argo/argo"&gt;ARGO&lt;/a&gt; (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EliasPereirah/OrionChat"&gt;OrionChat&lt;/a&gt; - OrionChat is a web interface for chatting with different AI providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bklieger-groq/g1"&gt;G1&lt;/a&gt; (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lemonit-eric-mao/ollama-web-management"&gt;Web management&lt;/a&gt; (Web management page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/promptery/promptery"&gt;Promptery&lt;/a&gt; (desktop client for Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/annilq/chat-ollama"&gt;chat-ollama&lt;/a&gt; (a React Native client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/spacellama"&gt;SpaceLlama&lt;/a&gt; (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/youlama"&gt;YouLama&lt;/a&gt; (Webapp to quickly summarize any YouTube video, supporting Invidious as well)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/dualmind"&gt;DualMind&lt;/a&gt; (Experimental app allowing two models to talk to each other in the terminal or in a web interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix"&gt;ollamarama-matrix&lt;/a&gt; (Ollama chatbot for the Matrix chat protocol)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anan1213095357/ollama-chat-app"&gt;ollama-chat-app&lt;/a&gt; (Flutter-based chat app)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.perfectmemory.ai/"&gt;Perfect Memory AI&lt;/a&gt; (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hexastack/hexabot"&gt;Hexabot&lt;/a&gt; (A conversational AI builder)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/reddit_analyzer"&gt;Reddit Rate&lt;/a&gt; (Search and Rate Reddit topics with a weighted summation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/OpenTalkGpt"&gt;OpenTalkGpt&lt;/a&gt; (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vt.ai"&gt;VT&lt;/a&gt; (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nosia-ai/nosia"&gt;Nosia&lt;/a&gt; (Easy to install and use RAG platform based on Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/witsy"&gt;Witsy&lt;/a&gt; (An AI Desktop application available for Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/US-Artificial-Intelligence/abbey"&gt;Abbey&lt;/a&gt; (A configurable AI interface server with notebooks, document storage, and YouTube support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmayboroda/minima"&gt;Minima&lt;/a&gt; (RAG with on-premises or fully local workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AidfulAI/aidful-ollama-model-delete"&gt;aidful-ollama-model-delete&lt;/a&gt; (User interface for simplified model cleanup)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ItzCrazyKns/Perplexica"&gt;Perplexica&lt;/a&gt; (An AI-powered search engine &amp;amp; an open-source alternative to Perplexity AI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oslook/ollama-webui"&gt;Ollama Chat WebUI for Docker &lt;/a&gt; (Support for local docker deployment, lightweight ollama webui)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-tooklit/ollama-docs"&gt;AI Toolkit for Visual Studio Code&lt;/a&gt; (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anilkay/MinimalNextOllamaChat"&gt;MinimalNextOllamaChat&lt;/a&gt; (Minimal Web UI for Chat and Model Control)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TilmanGriesel/chipper"&gt;Chipper&lt;/a&gt; AI interface for tinkerers (Ollama, Haystack RAG, Python)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CosmicEventHorizon/ChibiChat"&gt;ChibiChat&lt;/a&gt; (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qusaismael/localllm"&gt;LocalLLM&lt;/a&gt; (Minimal Web-App to run ollama models on it with a GUI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buiducnhat/ollamazing"&gt;Ollamazing&lt;/a&gt; (Web extension to run Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng"&gt;OpenDeepResearcher-via-searxng&lt;/a&gt; (A Deep Research equivalent endpoint with Ollama support for running locally)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AIDotNet/AntSK"&gt;AntSK&lt;/a&gt; (Out-of-the-box &amp;amp; Adaptable RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; (Ready-to-use &amp;amp; flexible RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielekp/yla"&gt;yla&lt;/a&gt; (Web interface to freely interact with your customized models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;/a&gt; (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/1Panel/"&gt;1Panel&lt;/a&gt; (Web-based Linux Server Management Tool)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;/a&gt; (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aharon-Bensadoun/Flufy"&gt;Flufy&lt;/a&gt; (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeozeozeo/ellama"&gt;Ellama&lt;/a&gt; (Friendly native app to chat with an Ollama instance)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/screenpipe"&gt;screenpipe&lt;/a&gt; Build agents powered by your screen history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hengkysteen/ollamb"&gt;Ollamb&lt;/a&gt; (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the &lt;a href="https://hengkysteen.github.io/demo/ollamb/"&gt;web demo&lt;/a&gt;.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Writeopia/Writeopia"&gt;Writeopia&lt;/a&gt; (Text editor with integration with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AppFlowy-IO/AppFlowy"&gt;AppFlowy&lt;/a&gt; (AI collaborative workspace with Ollama, cross-platform and self-hostable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cushydigit/lumina.git"&gt;Lumina&lt;/a&gt; (A lightweight, minimal React.js frontend for interacting with Ollama servers)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tiny-notepad"&gt;Tiny Notepad&lt;/a&gt; (A lightweight, notepad-like interface to chat with ollama available on PyPI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hellotunamayo/macLlama"&gt;macLlama (macOS native)&lt;/a&gt; (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philberndt/GPTranslate"&gt;GPTranslate&lt;/a&gt; (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NGC13009/ollama-launcher"&gt;ollama launcher&lt;/a&gt; (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aj-Seven/ai-hub"&gt;ai-hub&lt;/a&gt; (AI Hub supports multiple models via API keys and Chat support via Ollama API.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/mayan-edms/mayan-edms"&gt;Mayan EDMS&lt;/a&gt; (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/doolijb/serene-pub"&gt;Serene Pub&lt;/a&gt; (Beginner friendly, open source AI Roleplaying App for Windows, Mac OS and Linux. Search, download and use models with Ollama all inside the app.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aqerd/andes"&gt;Andes&lt;/a&gt; (A Visual Studio Code extension that provides a local UI interface for Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KashyapTan/clueless"&gt;Clueless&lt;/a&gt; (Open Source &amp;amp; Local Cluely: A desktop application LLM assistant to help you talk to anything on your screen using locally served Ollama models. Also undetectable to screenshare)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carbonatedWaterOrg/ollama-co2"&gt;ollama-co2&lt;/a&gt; (FastAPI web interface for monitoring and managing local and remote Ollama servers with real-time model monitoring and concurrent downloads)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;Google Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/docs/python/do-more/add-ollama/"&gt;Fly.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.koyeb.com/deploy/ollama"&gt;Koyeb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Terminal&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggozad/oterm"&gt;oterm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-kostyaev/ellama"&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zweifisch/ollama"&gt;Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paradoxical-dev/neollama"&gt;neollama&lt;/a&gt; UI client for interacting with models from within Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/David-Kunz/gen.nvim"&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomnivore/ollama.nvim"&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marco-souza/ollero.nvim"&gt;ollero.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gerazov/ollama-chat.nvim"&gt;ollama-chat.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huynle/ogpt.nvim"&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karthink/gptel"&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustinblackman/oatmeal"&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgibler/cmdh"&gt;cmdh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/npahlfer/ooo"&gt;ooo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/shell-pilot"&gt;shell-pilot&lt;/a&gt;(Interact with models via pure shell scripts on Linux or macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;tenere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taketwo/llm-ollama"&gt;llm-ollama&lt;/a&gt; for &lt;a href="https://llm.datasette.io/en/stable/"&gt;Datasette's LLM CLI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anaisbetts/typechat-cli"&gt;typechat-cli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djcopley/ShellOracle"&gt;ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusufcanb/tlm"&gt;tlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericcurtin/podman-ollama"&gt;podman-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/gollama"&gt;gollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulrobello/parllama"&gt;ParLlama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognitivetech/ollama-ebook-summary/"&gt;Ollama eBook Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_moe"&gt;Ollama Mixture of Experts (MOE) in 50 lines of code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepo-ec/vim-intelligence-bridge"&gt;vim-intelligence-bridge&lt;/a&gt; Simple interaction of "Ollama" with the Vim editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x-cmd.com/mod/ollama"&gt;x-cmd ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drunkwcodes/bb7"&gt;bb7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;SwollamaCLI&lt;/a&gt; bundled with the Swollama Swift package. &lt;a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigoden/aichat"&gt;aichat&lt;/a&gt; All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp;amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rrg92/powershai"&gt;PowershAI&lt;/a&gt; PowerShell module that brings AI to terminal on Windows, including support for Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abyss-c0re/deepshell"&gt;DeepShell&lt;/a&gt; Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/orbiton"&gt;orbiton&lt;/a&gt; Configuration-free text editor and IDE with support for tab completion with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/molbal/orca-cli"&gt;orca-cli&lt;/a&gt; Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gguf-to-ollama"&gt;GGUF-to-Ollama&lt;/a&gt; - Importing GGUF to Ollama made easy (multiplatform)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_strands"&gt;AWS-Strands-With-Ollama&lt;/a&gt; - AWS Strands Agents with Ollama Examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-multirun"&gt;ollama-multirun&lt;/a&gt; - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (&lt;a href="https://attogram.github.io/ai_test_zone/"&gt;Demo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-toolshed"&gt;ollama-bash-toolshed&lt;/a&gt; - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vtcode"&gt;VT Code&lt;/a&gt; - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter. Ollama integration for running local/cloud models with configurable endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apple Vision Pro&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Cross-platform AI chat app supporting Apple Vision Pro via "Designed for iPad")&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timescale/pgai"&gt;pgai&lt;/a&gt; - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timescale/pgai/raw/main/docs/vectorizer-quick-start.md"&gt;Get started guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md"&gt;MindsDB&lt;/a&gt; (Connects Ollama models with nearly 200 data platforms and apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philippgille/chromem-go/raw/v0.5.0/embed_ollama.go"&gt;chromem-go&lt;/a&gt; with &lt;a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbkangaroo/kangaroo"&gt;Kangaroo&lt;/a&gt; (AI-powered SQL client and admin tool for popular databases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Package managers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/ollama/"&gt;Pacman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/ollama"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://artifacthub.io/packages/helm/ollama-helm/ollama"&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/tusharhero/ollama-guix"&gt;Guix channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?show=ollama&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=ollama"&gt;Nix package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev/blog/ollama-part-one"&gt;Flox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain&lt;/a&gt; and &lt;a href="https://js.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain.js&lt;/a&gt; with &lt;a href="https://js.langchain.com/docs/tutorials/local_rag/"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://firebase.google.com/docs/genkit/plugins/ollama"&gt;Firebase Genkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;crewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://remembersoftwares.github.io/yacana/"&gt;Yacana&lt;/a&gt; (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spring-projects/spring-ai"&gt;Spring AI&lt;/a&gt; with &lt;a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html"&gt;reference&lt;/a&gt; and &lt;a href="https://github.com/tzolov/ollama-tools"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmc/langchaingo/"&gt;LangChainGo&lt;/a&gt; with &lt;a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain4j/langchain4j"&gt;LangChain4j&lt;/a&gt; with &lt;a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abraxas-365/langchain-rust"&gt;LangChainRust&lt;/a&gt; with &lt;a href="https://github.com/Abraxas-365/langchain-rust/raw/main/examples/llm_ollama.rs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tryAGI/LangChain"&gt;LangChain for .NET&lt;/a&gt; with &lt;a href="https://github.com/tryAGI/LangChain/raw/main/examples/LangChain.Samples.OpenAI/Program.cs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama"&gt;LLPhant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"&gt;LlamaIndex&lt;/a&gt; and &lt;a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama"&gt;LlamaIndexTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/presbrey/ollamafarm"&gt;OllamaFarm for Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awaescher/OllamaSharp"&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbaptista/ollama-ai"&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepperoni21/ollama-rs"&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmont-dev/ollama-hpp"&gt;Ollama-hpp for C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j"&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelfusion.dev/integration/model-provider/ollama"&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/OllamaKit"&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/breitburg/dart-ollama"&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudstudio/ollama-laravel"&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davidmigloz/langchain_dart"&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama"&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md"&gt;Haystack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brainlid/langchain"&gt;Elixir LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JBGruber/rollama"&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hauselin/ollama-r"&gt;Ollama for R - ollama-r&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lebrunel/ollama-ex"&gt;Ollama-ex for Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b-tocs/abap_btocs_ollama"&gt;Ollama Connector for SAP ABAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://testcontainers.com/modules/ollama/"&gt;Testcontainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://portkey.ai/docs/welcome/integration-guides/ollama"&gt;Portkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/svilupp/PromptingTools.jl"&gt;PromptingTools.jl&lt;/a&gt; with an &lt;a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Project-Llama/llamascript"&gt;LlamaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emirsahin1/llm-axe"&gt;llm-axe&lt;/a&gt; (Python Toolkit for Building LLM Powered Apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.gollm.co/examples/ollama-example"&gt;Gollm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gollama"&gt;Gollama for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/ollamaclient"&gt;Ollamaclient for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/tozd/go/fun"&gt;High-level function abstraction in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArdaGnsrn/ollama-php"&gt;Ollama PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agents-flex/agents-flex"&gt;Agents-Flex for Java&lt;/a&gt; with &lt;a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parakeet-nest/parakeet"&gt;Parakeet&lt;/a&gt; is a GoLang library, made to simplify the development of small generative AI applications with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andygill/haverscript"&gt;Haverscript&lt;/a&gt; with &lt;a href="https://github.com/andygill/haverscript/tree/main/examples"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattt/ollama-swift"&gt;Ollama for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;Swollama for Swift&lt;/a&gt; with &lt;a href="https://marcusziade.github.io/Swollama/documentation/swollama/"&gt;DocC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prasad89/golamify"&gt;GoLamify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharad/ollama-haskell"&gt;Ollama for Haskell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/multi-llm-ts"&gt;multi-llm-ts&lt;/a&gt; (A Typescript/JavaScript library allowing access to different LLM in a unified API)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lofcz/llmtornado"&gt;LlmTornado&lt;/a&gt; (C# library providing a unified interface for major FOSS &amp;amp; Commercial inference APIs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dravenk/ollama-zig"&gt;Ollama for Zig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lunary-ai/abso"&gt;Abso&lt;/a&gt; (OpenAI-compatible TypeScript SDK for any LLM provider)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/goodreasonai/nichey"&gt;Nichey&lt;/a&gt; is a Python package for generating custom wikis for your research topic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kassane/ollama-d"&gt;Ollama for D&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/OllamaPlusPlus"&gt;OllamaPlusPlus&lt;/a&gt; (Very simple C++ library for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-llm"&gt;any-llm&lt;/a&gt; (A single interface to use different llm providers by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mozilla-ai/any-agent"&gt;any-agent&lt;/a&gt; (A single interface to use and evaluate different agent frameworks by &lt;a href="https://www.mozilla.ai/"&gt;mozilla.ai&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio"&gt;Neuro SAN&lt;/a&gt; (Data-driven multi-agent orchestration framework) with &lt;a href="https://github.com/cognizant-ai-lab/neuro-san-studio/raw/main/docs/user_guide.md#ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ai-bot-pro/achatbot-go"&gt;achatbot-go&lt;/a&gt; a multimodal(text/audio/image) chatbot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mobile&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Maid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunshine0523/OllamaServer"&gt;Ollama Android Chat&lt;/a&gt; (No need for Termux, start the Ollama service with one click on an Android device)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MassimilianoPasquini97/raycast_ollama"&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mxyng/discollama"&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;Continue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thewh1teagle/vibe"&gt;Vibe&lt;/a&gt; (Transcribe and analyze meetings with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hinterdupfinger/obsidian-ollama"&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omagdy7/ollama-logseq"&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andersrex/notesollama"&gt;NotesOllama&lt;/a&gt; (Apple Notes Ollama plugin)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samalba/dagger-chatbot"&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mekb-turtle/discord-ai-bot"&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruecat/ollama-telegram"&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ej52/hass-ollama-conversation"&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abrenneke/rivet-plugin-ollama"&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/longy2k/obsidian-bmo-chatbot"&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/herval/cliobot"&gt;Cliobot&lt;/a&gt; (Telegram bot with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logancyang/obsidian-copilot"&gt;Copilot for Obsidian plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pfrankov/obsidian-local-gpt"&gt;Obsidian Local GPT plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama"&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ex3ndr/llama-coder"&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bernardo-bruning/ollama-copilot"&gt;Ollama Copilot&lt;/a&gt; (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rjmacarthy/twinny"&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RussellCanfield/wingman-ai"&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and Hugging Face)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n4ze3m/page-assist"&gt;Page Assist&lt;/a&gt; (Chrome Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imoize/plasmoid-ollamacontrol"&gt;Plasmoid Ollama Control&lt;/a&gt; (KDE Plasma extension that allows you to quickly manage/control Ollama model)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharhero/aitelegrambot"&gt;AI Telegram Bot&lt;/a&gt; (Telegram bot using Ollama in backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI ST Completion&lt;/a&gt; (Sublime Text 4 AI assistant plugin with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinthedang/discord-ollama"&gt;Discord-Ollama Chat Bot&lt;/a&gt; (Generalized TypeScript Discord Bot w/ Tuning Documentation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/chatGPTBox"&gt;ChatGPTBox: All in one browser extension&lt;/a&gt; with &lt;a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467"&gt;Integrating Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapmd73/Companion"&gt;Discord AI chat/moderation bot&lt;/a&gt; Chat/moderation bot written in python. Uses Ollama to create personalities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nischalj10/headless-ollama"&gt;Headless Ollama&lt;/a&gt; (Scripts to automatically install ollama client &amp;amp; models on any OS for apps that depend on ollama server)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm"&gt;Terraform AWS Ollama &amp;amp; Open WebUI&lt;/a&gt; (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama"&gt;node-red-contrib-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivostoykov/localAI"&gt;Local AI Helper&lt;/a&gt; (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jake83741/vnc-lm"&gt;vnc-lm&lt;/a&gt; (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SilasMarvin/lsp-ai"&gt;LSP-AI&lt;/a&gt; (Open-source language server for AI-powered functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Palm1r/QodeAssist"&gt;QodeAssist&lt;/a&gt; (AI-powered coding assistant plugin for Qt Creator)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ECuiDev/obsidian-quiz-generator"&gt;Obsidian Quiz Generator plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philffm/ai-summary-helper"&gt;AI Summmary Helper plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/suncloudsmoon/TextCraft"&gt;TextCraft&lt;/a&gt; (Copilot in Word alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeitlings/alfred-ollama"&gt;Alfred Ollama&lt;/a&gt; (Alfred Workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/TextLLaMA"&gt;TextLLaMA&lt;/a&gt; A Chrome Extension that helps you write emails, correct grammar, and translate into any language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zyphixor/simple-discord-ai"&gt;Simple-Discord-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innightwolfsleep/llm_telegram_bot"&gt;LLM Telegram Bot&lt;/a&gt; (telegram bot, primary for RP. Oobabooga-like buttons, &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;A1111&lt;/a&gt; API integration e.t.c)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/mcp-llm"&gt;mcp-llm&lt;/a&gt; (MCP Server to allow LLMs to call other LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/SimpleOllamaUnity"&gt;SimpleOllamaUnity&lt;/a&gt; (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/UnityCodeLama"&gt;UnityCodeLama&lt;/a&gt; (Unity Edtior tool to analyze scripts via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NativeMindBrowser/NativeMindExtension"&gt;NativeMind&lt;/a&gt; (Private, on-device AI Assistant, no cloud dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gmai.premex.se/"&gt;GMAI - Gradle Managed AI&lt;/a&gt; (Gradle plugin for automated Ollama lifecycle management during build phases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomyo-ai/nomyo-router"&gt;NOMYO Router&lt;/a&gt; (A transparent Ollama proxy with model deployment aware routing which auto-manages multiple Ollama instances in a given network)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported backends&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; project founded by Georgi Gerganov.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Observability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/docs/opik/cookbook/ollama"&gt;Opik&lt;/a&gt; is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lunary.ai/docs/integrations/ollama"&gt;Lunary&lt;/a&gt; is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT&lt;/a&gt; is an OpenTelemetry-native tool for monitoring Ollama Applications &amp;amp; GPUs using traces and metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.honeyhive.ai/integrations/ollama"&gt;HoneyHive&lt;/a&gt; is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/docs/integrations/ollama"&gt;Langfuse&lt;/a&gt; is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing"&gt;MLflow Tracing&lt;/a&gt; is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/k8s-device-plugin</title>
      <link>https://github.com/NVIDIA/k8s-device-plugin</link>
      <description>&lt;p&gt;NVIDIA device plugin for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NVIDIA device plugin for Kubernetes&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/k8s-device-plugin/actions/workflows/e2e.yaml"&gt;&lt;img src="https://github.com/NVIDIA/k8s-device-plugin/actions/workflows/e2e.yaml/badge.svg?sanitize=true" alt="End-to-end Tests" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/NVIDIA/k8s-device-plugin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/NVIDIA/k8s-device-plugin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/k8s-device-plugin/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/NVIDIA/k8s-device-plugin" alt="Latest Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#about"&gt;About&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#preparing-your-gpu-nodes"&gt;Preparing your GPU Nodes&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#example-for-debian-based-systems-with-docker-and-containerd"&gt;Example for debian-based systems with &lt;code&gt;docker&lt;/code&gt; and &lt;code&gt;containerd&lt;/code&gt;&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#install-the-nvidia-container-toolkit"&gt;Install the NVIDIA Container Toolkit&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#notes-on-cri-o-configuration"&gt;Notes on &lt;code&gt;CRI-O&lt;/code&gt; configuration&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#enabling-gpu-support-in-kubernetes"&gt;Enabling GPU Support in Kubernetes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#running-gpu-jobs"&gt;Running GPU Jobs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#configuring-the-nvidia-device-plugin-binary"&gt;Configuring the NVIDIA device plugin binary&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#as-command-line-flags-or-envvars"&gt;As command line flags or envvars&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#as-a-configuration-file"&gt;As a configuration file&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#configuration-option-details"&gt;Configuration Option Details&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#shared-access-to-gpus"&gt;Shared Access to GPUs&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#with-cuda-time-slicing"&gt;With CUDA Time-Slicing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#with-cuda-mps"&gt;With CUDA MPS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#imex-support"&gt;IMEX Support&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#catalog-of-labels"&gt;Catalog of Labels&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#deployment-via-helm"&gt;Deployment via &lt;code&gt;helm&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#configuring-the-device-plugins-helm-chart"&gt;Configuring the device plugin's &lt;code&gt;helm&lt;/code&gt; chart&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#passing-configuration-to-the-plugin-via-a-configmap"&gt;Passing configuration to the plugin via a &lt;code&gt;ConfigMap&lt;/code&gt;&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#single-config-file-example"&gt;Single Config File Example&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#multiple-config-file-example"&gt;Multiple Config File Example&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#updating-per-node-configuration-with-a-node-label"&gt;Updating Per-Node Configuration With a Node Label&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#setting-other-helm-chart-values"&gt;Setting other helm chart values&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#deploying-with-gpu-feature-discovery-for-automatic-node-labels"&gt;Deploying with gpu-feature-discovery for automatic node labels&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#deploying-gpu-feature-discovery-in-standalone-mode"&gt;Deploying gpu-feature-discovery in standalone mode&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#deploying-via-helm-install-with-a-direct-url-to-the-helm-package"&gt;Deploying via &lt;code&gt;helm install&lt;/code&gt; with a direct URL to the &lt;code&gt;helm&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#building-and-running-locally"&gt;Building and Running Locally&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#with-docker"&gt;With Docker&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#build"&gt;Build&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#run"&gt;Run&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#without-docker"&gt;Without Docker&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#build-1"&gt;Build&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#run-1"&gt;Run&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#issues-and-contributing"&gt;Issues and Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#upgrading-kubernetes-with-the-device-plugin"&gt;Upgrading Kubernetes with the Device Plugin&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;The NVIDIA device plugin for Kubernetes is a Daemonset that allows you to automatically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expose the number of GPUs on each nodes of your cluster&lt;/li&gt; 
 &lt;li&gt;Keep track of the health of your GPUs&lt;/li&gt; 
 &lt;li&gt;Run GPU enabled containers in your Kubernetes cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This repository contains NVIDIA's official implementation of the &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/"&gt;Kubernetes device plugin&lt;/a&gt;. As of v0.15.0 this repository also holds the implementation for GPU Feature Discovery labels, for further information on GPU Feature Discovery see &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/docs/gpu-feature-discovery/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The NVIDIA device plugin API is beta as of Kubernetes v1.10.&lt;/li&gt; 
 &lt;li&gt;The NVIDIA device plugin is currently lacking 
  &lt;ul&gt; 
   &lt;li&gt;Comprehensive GPU health checking features&lt;/li&gt; 
   &lt;li&gt;GPU cleanup features&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Support will only be provided for the official NVIDIA device plugin (and not for forks or other variants of this plugin).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;The list of prerequisites for running the NVIDIA device plugin is described below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;NVIDIA drivers ~= 384.81&lt;/li&gt; 
 &lt;li&gt;nvidia-docker &amp;gt;= 2.0 || nvidia-container-toolkit &amp;gt;= 1.7.0 (&amp;gt;= 1.11.0 to use integrated GPUs on Tegra-based systems)&lt;/li&gt; 
 &lt;li&gt;nvidia-container-runtime configured as the default low-level runtime&lt;/li&gt; 
 &lt;li&gt;Kubernetes version &amp;gt;= 1.10&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Preparing your GPU Nodes&lt;/h3&gt; 
&lt;p&gt;The following steps need to be executed on all your GPU nodes. This README assumes that the NVIDIA drivers and the &lt;code&gt;nvidia-container-toolkit&lt;/code&gt; have been pre-installed. It also assumes that you have configured the &lt;code&gt;nvidia-container-runtime&lt;/code&gt; as the default low-level runtime to use.&lt;/p&gt; 
&lt;p&gt;Please see: &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"&gt;https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Example for debian-based systems with &lt;code&gt;docker&lt;/code&gt; and &lt;code&gt;containerd&lt;/code&gt;&lt;/h4&gt; 
&lt;h5&gt;Install the NVIDIA Container Toolkit&lt;/h5&gt; 
&lt;p&gt;For instructions on installing and getting started with the NVIDIA Container Toolkit, refer to the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Also note the configuration instructions for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-containerd-for-kubernetes"&gt;&lt;code&gt;containerd&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-cri-o"&gt;&lt;code&gt;CRI-O&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-docker"&gt;&lt;code&gt;docker&lt;/code&gt; (Deprecated)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Remembering to restart each runtime after applying the configuration changes.&lt;/p&gt; 
&lt;p&gt;If the &lt;code&gt;nvidia&lt;/code&gt; runtime should be set as the default runtime (with non-cri docker versions, for example), the &lt;code&gt;--set-as-default&lt;/code&gt; argument must also be included in the commands above. If this is not done, a RuntimeClass needs to be defined:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Notes on &lt;code&gt;CRI-O&lt;/code&gt; configuration&lt;/h5&gt; 
&lt;p&gt;When running &lt;code&gt;kubernetes&lt;/code&gt; with &lt;code&gt;CRI-O&lt;/code&gt;, add the config file to set the &lt;code&gt;nvidia-container-runtime&lt;/code&gt; as the default low-level OCI runtime under &lt;code&gt;/etc/crio/crio.conf.d/99-nvidia.conf&lt;/code&gt;. This will take priority over the default &lt;code&gt;crun&lt;/code&gt; config file at &lt;code&gt;/etc/crio/crio.conf.d/10-crun.conf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[crio]

  [crio.runtime]
    default_runtime = "nvidia"

    [crio.runtime.runtimes]

      [crio.runtime.runtimes.nvidia]
        runtime_path = "/usr/bin/nvidia-container-runtime"
        runtime_type = "oci"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As stated in the linked documentation, this file can automatically be generated with the nvidia-ctk command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo nvidia-ctk runtime configure --runtime=crio --set-as-default --config=/etc/crio/crio.conf.d/99-nvidia.conf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;CRI-O&lt;/code&gt; uses &lt;code&gt;crun&lt;/code&gt; as default low-level OCI runtime so &lt;code&gt;crun&lt;/code&gt; needs to be added to the runtimes of the &lt;code&gt;nvidia-container-runtime&lt;/code&gt; in the config file at &lt;code&gt;/etc/nvidia-container-runtime/config.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[nvidia-container-runtime]
runtimes = ["crun", "docker-runc", "runc"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then restart &lt;code&gt;CRI-O&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo systemctl restart crio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Enabling GPU Support in Kubernetes&lt;/h3&gt; 
&lt;p&gt;Once you have configured the options above on all the GPU nodes in your cluster, you can enable GPU support by deploying the following Daemonset:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.17.1/deployments/static/nvidia-device-plugin.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This is a simple static daemonset meant to demonstrate the basic features of the &lt;code&gt;nvidia-device-plugin&lt;/code&gt;. Please see the instructions below for &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#deployment-via-helm"&gt;Deployment via &lt;code&gt;helm&lt;/code&gt;&lt;/a&gt; when deploying the plugin in a production setting.&lt;/p&gt; 
&lt;h3&gt;Running GPU Jobs&lt;/h3&gt; 
&lt;p&gt;With the daemonset deployed, NVIDIA GPUs can now be requested by a container using the &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resource type:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cat &amp;lt;&amp;lt;EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  restartPolicy: Never
  containers:
    - name: cuda-container
      image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda12.5.0
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl logs gpu-pod
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] If you do not request GPUs when you use the device plugin, the plugin exposes all the GPUs on the machine inside your container.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Configuring the NVIDIA device plugin binary&lt;/h2&gt; 
&lt;p&gt;The NVIDIA device plugin has a number of options that can be configured for it. These options can be configured as command line flags, environment variables, or via a config file when launching the device plugin. Here we explain what each of these options are and how to configure them directly against the plugin binary. The following section explains how to set these configurations when deploying the plugin via &lt;code&gt;helm&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;As command line flags or envvars&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Environment Variable&lt;/th&gt; 
   &lt;th&gt;Default Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--mig-strategy&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$MIG_STRATEGY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;"none"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--fail-on-init-error&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$FAIL_ON_INIT_ERROR&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--nvidia-driver-root&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$NVIDIA_DRIVER_ROOT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;"/"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--pass-device-specs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$PASS_DEVICE_SPECS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--device-list-strategy&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$DEVICE_LIST_STRATEGY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;"envvar"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--device-id-strategy&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$DEVICE_ID_STRATEGY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;"uuid"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--config-file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;$CONFIG_FILE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;""&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;As a configuration file&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
flags:
  migStrategy: "none"
  failOnInitError: true
  nvidiaDriverRoot: "/"
  plugin:
    passDeviceSpecs: false
    deviceListStrategy: "envvar"
    deviceIDStrategy: "uuid"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The configuration file has an explicit &lt;code&gt;plugin&lt;/code&gt; section because it is a shared configuration between the plugin and &lt;a href="https://github.com/NVIDIA/gpu-feature-discovery"&gt;&lt;code&gt;gpu-feature-discovery&lt;/code&gt;&lt;/a&gt;. All options inside the &lt;code&gt;plugin&lt;/code&gt; section are specific to the plugin. All options outside of this section are shared.&lt;/p&gt; 
&lt;h3&gt;Configuration Option Details&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;MIG_STRATEGY&lt;/code&gt;&lt;/strong&gt;: the desired strategy for exposing MIG devices on GPUs that support it&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;[none | single | mixed] (default 'none')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;MIG_STRATEGY&lt;/code&gt; option configures the daemonset to be able to expose Multi-Instance GPUs (MIG) on GPUs that support them. More information on what these strategies are and how they should be used can be found in &lt;a href="https://docs.google.com/document/d/1mdgMQ8g7WmaI_XVVRrCvHPFPOMCm5LQD5JefgAh6N8g"&gt;Supporting Multi-Instance GPUs (MIG) in Kubernetes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; With a &lt;code&gt;MIG_STRATEGY&lt;/code&gt; of mixed, you will have additional resources available to you of the form &lt;code&gt;nvidia.com/mig-&amp;lt;slice_count&amp;gt;g.&amp;lt;memory_size&amp;gt;gb&lt;/code&gt; that you can set in your pod spec to get access to a specific MIG device.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;FAIL_ON_INIT_ERROR&lt;/code&gt;&lt;/strong&gt;: fail the plugin if an error is encountered during initialization, otherwise block indefinitely&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;(default 'true')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;When set to true, the &lt;code&gt;FAIL_ON_INIT_ERROR&lt;/code&gt; option fails the plugin if an error is encountered during initialization. When set to false, it prints an error message and blocks the plugin indefinitely instead of failing. Blocking indefinitely follows legacy semantics that allow the plugin to deploy successfully on nodes that don't have GPUs on them (and aren't supposed to have GPUs on them) without throwing an error. In this way, you can blindly deploy a daemonset with the plugin on all nodes in your cluster, whether they have GPUs on them or not, without encountering an error. However, doing so means that there is no way to detect an actual error on nodes that are supposed to have GPUs on them. Failing if an initialization error is encountered is now the default and should be adopted by all new deployments.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;NVIDIA_DRIVER_ROOT&lt;/code&gt;&lt;/strong&gt;: the root path for the NVIDIA driver installation&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;(default '/')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;When the NVIDIA drivers are installed directly on the host, this should be set to &lt;code&gt;'/'&lt;/code&gt;. When installed elsewhere (e.g. via a driver container), this should be set to the root filesystem where the drivers are installed (e.g. &lt;code&gt;'/run/nvidia/driver'&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This option is only necessary when used in conjunction with the &lt;code&gt;$PASS_DEVICE_SPECS&lt;/code&gt; option described below. It tells the plugin what prefix to add to any device file paths passed back as part of the device specs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;PASS_DEVICE_SPECS&lt;/code&gt;&lt;/strong&gt;: pass the paths and desired device node permissions for any NVIDIA devices being allocated to the container&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;(default 'false')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This option exists for the sole purpose of allowing the device plugin to interoperate with the &lt;code&gt;CPUManager&lt;/code&gt; in Kubernetes. Setting this flag also requires one to deploy the daemonset with elevated privileges, so only do so if you know you need to interoperate with the &lt;code&gt;CPUManager&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;DEVICE_LIST_STRATEGY&lt;/code&gt;&lt;/strong&gt;: the desired strategy for passing the device list to the underlying runtime&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;[envvar | volume-mounts | cdi-annotations | cdi-cri ] (default 'envvar')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Multiple device list strategies can be specified (as a comma-separated list).&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;DEVICE_LIST_STRATEGY&lt;/code&gt; flag allows one to choose which strategy the plugin will use to advertise the list of GPUs allocated to a container. Possible values are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;envvar&lt;/code&gt; (default): the &lt;code&gt;NVIDIA_VISIBLE_DEVICES&lt;/code&gt; environment variable as described &lt;a href="https://github.com/NVIDIA/nvidia-container-runtime#nvidia_visible_devices"&gt;here&lt;/a&gt; is used to select the devices that are to be injected by the NVIDIA Container Runtime.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;volume-mounts&lt;/code&gt;: the list of devices is passed as a set of volume mounts instead of as an environment variable to instruct the NVIDIA Container Runtime to inject the devices. Details for the rationale behind this strategy can be found &lt;a href="https://docs.google.com/document/d/1uXVF-NWZQXgP1MLb87_kMkQvidpnkNWicdpO2l9g-fw/edit#heading=h.b3ti65rojfy5"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cdi-annotations&lt;/code&gt;: CDI annotations are used to select the devices that are to be injected. Note that this does not require the NVIDIA Container Runtime, but does required a CDI-enabled container engine.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cdi-cri&lt;/code&gt;: the &lt;code&gt;CDIDevices&lt;/code&gt; CRI field is used to select the CDI devices that are to be injected. This requires support in Kubernetes to forward these requests in the CRI to a CDI-enabled container engine.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;DEVICE_ID_STRATEGY&lt;/code&gt;&lt;/strong&gt;: the desired strategy for passing device IDs to the underlying runtime&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;[uuid | index] (default 'uuid')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;DEVICE_ID_STRATEGY&lt;/code&gt; flag allows one to choose which strategy the plugin will use to pass the device ID of the GPUs allocated to a container. The device ID has traditionally been passed as the UUID of the GPU. This flag lets a user decide if they would like to use the UUID or the index of the GPU (as seen in the output of &lt;code&gt;nvidia-smi&lt;/code&gt;) as the identifier passed to the underlying runtime. Passing the index may be desirable in situations where pods that have been allocated GPUs by the plugin get restarted with different physical GPUs attached to them.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;CONFIG_FILE&lt;/code&gt;&lt;/strong&gt;: point the plugin at a configuration file instead of relying on command line flags or environment variables&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;(default '')&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The order of precedence for setting each option is (1) command line flag, (2) environment variable, (3) configuration file. In this way, one could use a pre-defined configuration file, but then override the values set in it at launch time. As described below, a &lt;code&gt;ConfigMap&lt;/code&gt; can be used to point the plugin at a desired configuration file when deploying via &lt;code&gt;helm&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Shared Access to GPUs&lt;/h3&gt; 
&lt;p&gt;The NVIDIA device plugin allows oversubscription of GPUs through a set of extended options in its configuration file. There are two flavors of sharing available: Time-Slicing and MPS.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Time-slicing and MPS are mutually exclusive.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In the case of time-slicing, CUDA time-slicing is used to allow workloads sharing a GPU to interleave with each other. However, nothing special is done to isolate workloads that are granted replicas from the same underlying GPU, and each workload has access to the GPU memory and runs in the same fault-domain as of all the others (meaning if one workload crashes, they all do).&lt;/p&gt; 
&lt;p&gt;In the case of MPS, a control daemon is used to manage access to the shared GPU. In contrast to time-slicing, MPS does space partitioning and allows memory and compute resources to be explicitly partitioned and enforces these limits per workload.&lt;/p&gt; 
&lt;p&gt;With both time-slicing and MPS, the same sharing method is applied to all GPUs on a node. You cannot configure sharing on a per-GPU basis.&lt;/p&gt; 
&lt;h4&gt;With CUDA Time-Slicing&lt;/h4&gt; 
&lt;p&gt;The extended options for sharing using time-slicing can be seen below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  timeSlicing:
    renameByDefault: &amp;lt;bool&amp;gt;
    failRequestsGreaterThanOne: &amp;lt;bool&amp;gt;
    resources:
    - name: &amp;lt;resource-name&amp;gt;
      replicas: &amp;lt;num-replicas&amp;gt;
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That is, for each named resource under &lt;code&gt;sharing.timeSlicing.resources&lt;/code&gt;, a number of replicas can now be specified for that resource type. These replicas represent the number of shared accesses that will be granted for a GPU represented by that resource type.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;renameByDefault=true&lt;/code&gt;, then each resource will be advertised under the name &lt;code&gt;&amp;lt;resource-name&amp;gt;.shared&lt;/code&gt; instead of simply &lt;code&gt;&amp;lt;resource-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;failRequestsGreaterThanOne=true&lt;/code&gt;, then the plugin will fail to allocate any shared resources to a container if they request more than one. The container‚Äôs pod will fail with an &lt;code&gt;UnexpectedAdmissionError&lt;/code&gt; and need to be manually deleted, updated, and redeployed.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  timeSlicing:
    resources:
    - name: nvidia.com/gpu
      replicas: 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If this configuration were applied to a node with 8 GPUs on it, the plugin would now advertise 80 &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resources to Kubernetes instead of 8.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl describe node
...
Capacity:
  nvidia.com/gpu: 80
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Likewise, if the following configuration were applied to a node, then 80 &lt;code&gt;nvidia.com/gpu.shared&lt;/code&gt; resources would be advertised to Kubernetes instead of 8 &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resources.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  timeSlicing:
    renameByDefault: true
    resources:
    - name: nvidia.com/gpu
      replicas: 10
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl describe node
...
Capacity:
  nvidia.com/gpu.shared: 80
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In both cases, the plugin simply creates 10 references to each GPU and indiscriminately hands them out to anyone that asks for them.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;failRequestsGreaterThanOne=true&lt;/code&gt; were set in either of these configurations and a user requested more than one &lt;code&gt;nvidia.com/gpu&lt;/code&gt; or &lt;code&gt;nvidia.com/gpu.shared&lt;/code&gt; resource in their pod spec, then the container would fail with the resulting error:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl describe pod gpu-pod
...
Events:
  Type     Reason                    Age   From               Message
  ----     ------                    ----  ----               -------
  Warning  UnexpectedAdmissionError  13s   kubelet            Allocate failed due to rpc error: code = Unknown desc = request for 'nvidia.com/gpu: 2' too large: maximum request size for shared resources is 1, which is unexpected
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Unlike with "normal" GPU requests, requesting more than one shared GPU does not imply that you will get guaranteed access to a proportional amount of compute power. It only implies that you will get access to a GPU that is shared by other clients (each of which has the freedom to run as many processes on the underlying GPU as they want). Under the hood CUDA will simply give an equal share of time to all of the GPU processes across all of the clients. The &lt;code&gt;failRequestsGreaterThanOne&lt;/code&gt; flag is meant to help users understand this subtlety, by treating a request of &lt;code&gt;1&lt;/code&gt; as an access request rather than an exclusive resource request. Setting &lt;code&gt;failRequestsGreaterThanOne=true&lt;/code&gt; is recommended, but it is set to &lt;code&gt;false&lt;/code&gt; by default to retain backwards compatibility.&lt;/p&gt; 
&lt;p&gt;As of now, the only supported resource available for time-slicing are &lt;code&gt;nvidia.com/gpu&lt;/code&gt; as well as any of the resource types that emerge from configuring a node with the mixed MIG strategy.&lt;/p&gt; 
&lt;p&gt;For example, the full set of time-sliceable resources on a T4 card would be:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/gpu
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And the full set of time-sliceable resources on an A100 40GB card would be:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/gpu
nvidia.com/mig-1g.5gb
nvidia.com/mig-2g.10gb
nvidia.com/mig-3g.20gb
nvidia.com/mig-7g.40gb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Likewise, on an A100 80GB card, they would be:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/gpu
nvidia.com/mig-1g.10gb
nvidia.com/mig-2g.20gb
nvidia.com/mig-3g.40gb
nvidia.com/mig-7g.80gb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;With CUDA MPS&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] As of v0.15.0 of the device plugin, MPS support is considered experimental. Please see the &lt;a href="https://github.com/NVIDIA/k8s-device-plugin/releases/tag/v0.15.0"&gt;release notes&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Sharing with MPS is currently not supported on devices with MIG enabled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The extended options for sharing using MPS can be seen below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  mps:
    renameByDefault: &amp;lt;bool&amp;gt;
    resources:
    - name: &amp;lt;resource-name&amp;gt;
      replicas: &amp;lt;num-replicas&amp;gt;
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That is, for each named resource under &lt;code&gt;sharing.mps.resources&lt;/code&gt;, a number of replicas can be specified for that resource type. As is the case with time-slicing, these replicas represent the number of shared accesses that will be granted for a GPU associated with that resource type. In contrast with time-slicing, the amount of memory allowed per client (i.e. per partition) is managed by the MPS control daemon and limited to an equal fraction of the total device memory. In addition to controlling the amount of memory that each client can consume, the MPS control daemon also limits the amount of compute capacity that can be consumed by a client.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;renameByDefault=true&lt;/code&gt;, then each resource will be advertised under the name &lt;code&gt;&amp;lt;resource-name&amp;gt;.shared&lt;/code&gt; instead of simply &lt;code&gt;&amp;lt;resource-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  mps:
    resources:
    - name: nvidia.com/gpu
      replicas: 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If this configuration were applied to a node with 8 GPUs on it, the plugin would now advertise 80 &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resources to Kubernetes instead of 8.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl describe node
...
Capacity:
  nvidia.com/gpu: 80
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Likewise, if the following configuration were applied to a node, then 80 &lt;code&gt;nvidia.com/gpu.shared&lt;/code&gt; resources would be advertised to Kubernetes instead of 8 &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resources.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v1
sharing:
  mps:
    renameByDefault: true
    resources:
    - name: nvidia.com/gpu
      replicas: 10
    ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ kubectl describe node
...
Capacity:
  nvidia.com/gpu.shared: 80
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Furthermore, each of these resources -- either &lt;code&gt;nvidia.com/gpu&lt;/code&gt; or &lt;code&gt;nvidia.com/gpu.shared&lt;/code&gt; -- would have access to the same fraction (1/10) of the total memory and compute resources of the GPU.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: As of now, the only supported resource available for MPS are &lt;code&gt;nvidia.com/gpu&lt;/code&gt; resources and only with full GPUs.&lt;/p&gt; 
&lt;h3&gt;IMEX Support&lt;/h3&gt; 
&lt;p&gt;The NVIDIA GPU Device Plugin can be configured to inject IMEX channels into workloads.&lt;/p&gt; 
&lt;p&gt;This opt-in behavior is global and affects all workloads and is controlled by the &lt;code&gt;imex.channelIDs&lt;/code&gt; and &lt;code&gt;imex.required&lt;/code&gt; configuration options.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;code&gt;imex.channelIDs&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;imex.required&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Effect&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;[]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;*&lt;/td&gt; 
   &lt;td&gt;(default) No IMEX channels are added to workload requests. Note that the &lt;code&gt;imex.required&lt;/code&gt; field has no effect in this case&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;[0]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If the requested IMEX channel (&lt;code&gt;0&lt;/code&gt;) is discoverable by the NVIDIA GPU Device Plugin, the channel will be added to each workload request. If the channel cannot be discovered no channels are added to workload requests.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;[0]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If the requested IMEX channel (&lt;code&gt;0&lt;/code&gt;) is discoverable by the NVIDIA GPU Device Plugin, the channel will be added to each workload request. If the channel cannot be discovered an error will be raised since the channel was marked as &lt;code&gt;required&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: At present the only valid &lt;code&gt;imex.channelIDs&lt;/code&gt; configurations are &lt;code&gt;[]&lt;/code&gt; and &lt;code&gt;[0]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For the containerized NVIDIA GPU Device Plugin running to be able to successfully discover available IMEX channels, the corresponding device nodes must be available to the container.&lt;/p&gt; 
&lt;h2&gt;Catalog of Labels&lt;/h2&gt; 
&lt;p&gt;The NVIDIA device plugin reads and writes a number of different labels that it uses as either configuration elements or informational elements. The following table documents and describes each label along with their use. See the related table &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/docs/gpu-feature-discovery/README.md#generated-labels"&gt;here&lt;/a&gt; for the labels GFD adds.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Label Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/device-plugin.config&lt;/td&gt; 
   &lt;td&gt;Specifies the configuration to apply to the node. You apply this this label to perform per-node configuration. Refer to &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#updating-per-node-configuration-with-a-node-label"&gt;Updating Per-Node Configuration With a Node Label&lt;/a&gt; for details.&lt;/td&gt; 
   &lt;td&gt;my-mps-config&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/gpu.sharing-strategy&lt;/td&gt; 
   &lt;td&gt;Specifies the sharing strategy. The default value, &lt;code&gt;none&lt;/code&gt;, indicates no sharing. Other values are &lt;code&gt;mps&lt;/code&gt; and &lt;code&gt;time-slicing&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;time-slicing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/mig.capable&lt;/td&gt; 
   &lt;td&gt;Specifies if any device on the node supports MIG.&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/mps.capable&lt;/td&gt; 
   &lt;td&gt;Specifies if devices on the node are configured for MPS.&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/vgpu.present&lt;/td&gt; 
   &lt;td&gt;Specifies if devices on the node use vGPU.&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/vgpu.host-driver-branch&lt;/td&gt; 
   &lt;td&gt;Specifies the vGPU host driver branch on the underlying hypervisor.&lt;/td&gt; 
   &lt;td&gt;r550_40&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvidia.com/vgpu.host-driver-version&lt;/td&gt; 
   &lt;td&gt;Specifies the vGPU host driver version on the underlying hypervisor.&lt;/td&gt; 
   &lt;td&gt;550.54.16&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Deployment via &lt;code&gt;helm&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;The preferred method to deploy the device plugin is as a daemonset using &lt;code&gt;helm&lt;/code&gt;. Instructions for installing &lt;code&gt;helm&lt;/code&gt; can be found &lt;a href="https://helm.sh/docs/intro/install/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Begin by setting up the plugin's &lt;code&gt;helm&lt;/code&gt; repository and updating it at follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
helm repo update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then verify that the latest release (&lt;code&gt;v0.17.1&lt;/code&gt;) of the plugin is available:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ helm search repo nvdp --devel
NAME                     	  CHART VERSION  APP VERSION	DESCRIPTION
nvdp/nvidia-device-plugin	  0.17.1	 0.17.1		A Helm chart for ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this repo is updated, you can begin installing packages from it to deploy the &lt;code&gt;nvidia-device-plugin&lt;/code&gt; helm chart.&lt;/p&gt; 
&lt;p&gt;The most basic installation command without any options is then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --version 0.17.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You only need the to pass the &lt;code&gt;--devel&lt;/code&gt; flag to &lt;code&gt;helm search repo&lt;/code&gt; and the &lt;code&gt;--version&lt;/code&gt; flag to &lt;code&gt;helm upgrade -i&lt;/code&gt; if this is a pre-release version (e.g. &lt;code&gt;&amp;lt;version&amp;gt;-rc.1&lt;/code&gt;). Full releases will be listed without this.&lt;/p&gt; 
&lt;h3&gt;Configuring the device plugin's &lt;code&gt;helm&lt;/code&gt; chart&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;helm&lt;/code&gt; chart for the latest release of the plugin (&lt;code&gt;v0.17.1&lt;/code&gt;) includes a number of customizable values.&lt;/p&gt; 
&lt;p&gt;Prior to &lt;code&gt;v0.12.0&lt;/code&gt; the most commonly used values were those that had direct mappings to the command line options of the plugin binary. As of &lt;code&gt;v0.12.0&lt;/code&gt;, the preferred method to set these options is via a &lt;code&gt;ConfigMap&lt;/code&gt;. The primary use case of the original values is then to override an option from the &lt;code&gt;ConfigMap&lt;/code&gt; if desired. Both methods are discussed in more detail below.&lt;/p&gt; 
&lt;p&gt;The full set of values that can be set are found here: &lt;a href="https://github.com/NVIDIA/k8s-device-plugin/raw/v0.17.1/deployments/helm/nvidia-device-plugin/values.yaml"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Passing configuration to the plugin via a &lt;code&gt;ConfigMap&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;In general, we provide a mechanism to pass &lt;em&gt;multiple&lt;/em&gt; configuration files to to the plugin's &lt;code&gt;helm&lt;/code&gt; chart, with the ability to choose which configuration file should be applied to a node via a node label.&lt;/p&gt; 
&lt;p&gt;In this way, a single chart can be used to deploy each component, but custom configurations can be applied to different nodes throughout the cluster.&lt;/p&gt; 
&lt;p&gt;There are two ways to provide a &lt;code&gt;ConfigMap&lt;/code&gt; for use by the plugin:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Via an external reference to a pre-defined &lt;code&gt;ConfigMap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;As a set of named config files to build an integrated &lt;code&gt;ConfigMap&lt;/code&gt; associated with the chart&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These can be set via the chart values &lt;code&gt;config.name&lt;/code&gt; and &lt;code&gt;config.map&lt;/code&gt; respectively. In both cases, the value &lt;code&gt;config.default&lt;/code&gt; can be set to point to one of the named configs in the &lt;code&gt;ConfigMap&lt;/code&gt; and provide a default configuration for nodes that have not been customized via a node label (more on this later).&lt;/p&gt; 
&lt;h5&gt;Single Config File Example&lt;/h5&gt; 
&lt;p&gt;As an example, create a valid config file on your local filesystem, such as the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /tmp/dp-example-config0.yaml
version: v1
flags:
  migStrategy: "none"
  failOnInitError: true
  nvidiaDriverRoot: "/"
  plugin:
    passDeviceSpecs: false
    deviceListStrategy: envvar
    deviceIDStrategy: uuid
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And deploy the device plugin via helm (pointing it at this config file and giving it a name):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set-file config.map.config=/tmp/dp-example-config0.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Under the hood this will deploy a &lt;code&gt;ConfigMap&lt;/code&gt; associated with the plugin and put the contents of the &lt;code&gt;dp-example-config0.yaml&lt;/code&gt; file into it, using the name &lt;code&gt;config&lt;/code&gt; as its key. It will then start the plugin such that this config gets applied when the plugin comes online.&lt;/p&gt; 
&lt;p&gt;If you don‚Äôt want the plugin‚Äôs helm chart to create the &lt;code&gt;ConfigMap&lt;/code&gt; for you, you can also point it at a pre-created &lt;code&gt;ConfigMap&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl create ns nvidia-device-plugin
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl create cm -n nvidia-device-plugin nvidia-plugin-configs \
  --from-file=config=/tmp/dp-example-config0.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set config.name=nvidia-plugin-configs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Multiple Config File Example&lt;/h5&gt; 
&lt;p&gt;For multiple config files, the procedure is similar.&lt;/p&gt; 
&lt;p&gt;Create a second &lt;code&gt;config&lt;/code&gt; file with the following contents:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /tmp/dp-example-config1.yaml
version: v1
flags:
  migStrategy: "mixed" # Only change from config0.yaml
  failOnInitError: true
  nvidiaDriverRoot: "/"
  plugin:
    passDeviceSpecs: false
    deviceListStrategy: envvar
    deviceIDStrategy: uuid
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And redeploy the device plugin via helm (pointing it at both configs with a specified default).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set config.default=config0 \
  --set-file config.map.config0=/tmp/dp-example-config0.yaml \
  --set-file config.map.config1=/tmp/dp-example-config1.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As before, this can also be done with a pre-created &lt;code&gt;ConfigMap&lt;/code&gt; if desired:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl create ns nvidia-device-plugin
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl create cm -n nvidia-device-plugin nvidia-plugin-configs \
  --from-file=config0=/tmp/dp-example-config0.yaml \
  --from-file=config1=/tmp/dp-example-config1.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set config.default=config0 \
  --set config.name=nvidia-plugin-configs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If the &lt;code&gt;config.default&lt;/code&gt; flag is not explicitly set, then a default value will be inferred from the config if one of the config names is set to '&lt;code&gt;default&lt;/code&gt;'. If neither of these are set, then the deployment will fail unless there is only &lt;strong&gt;&lt;em&gt;one&lt;/em&gt;&lt;/strong&gt; config provided. In the case of just a single config being provided, it will be chosen as the default because there is no other option.&lt;/p&gt; 
&lt;h5&gt;Updating Per-Node Configuration With a Node Label&lt;/h5&gt; 
&lt;p&gt;With this setup, plugins on all nodes will have &lt;code&gt;config0&lt;/code&gt; configured for them by default. However, the following label can be set to change which configuration is applied:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl label nodes &amp;lt;node-name&amp;gt; ‚Äì-overwrite \
  nvidia.com/device-plugin.config=&amp;lt;config-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For example, applying a custom config for all nodes that have T4 GPUs installed on them might be:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;kubectl label node \
  --overwrite \
  --selector=nvidia.com/gpu.product=TESLA-T4 \
  nvidia.com/device-plugin.config=t4-config
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This label can be applied either &lt;em&gt;before&lt;/em&gt; or &lt;em&gt;after&lt;/em&gt; the plugin is started to get the desired configuration applied on the node. Anytime it changes value, the plugin will immediately be updated to start serving the desired configuration. If it is set to an unknown value, it will skip reconfiguration. If it is ever unset, it will fallback to the default.&lt;/p&gt; 
&lt;h4&gt;Setting other helm chart values&lt;/h4&gt; 
&lt;p&gt;As mentioned previously, the device plugin's helm chart continues to provide direct values to set the configuration options of the plugin without using a &lt;code&gt;ConfigMap&lt;/code&gt;. These should only be used to set globally applicable options (which should then never be embedded in the set of config files provided by the &lt;code&gt;ConfigMap&lt;/code&gt;), or used to override these options as desired.&lt;/p&gt; 
&lt;p&gt;These values are as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;  migStrategy:
      the desired strategy for exposing MIG devices on GPUs that support it
      [none | single | mixed] (default "none")
  failOnInitError:
      fail the plugin if an error is encountered during initialization, otherwise block indefinitely
      (default 'true')
  compatWithCPUManager:
      run with escalated privileges to be compatible with the static CPUManager policy
      (default 'false')
  deviceListStrategy:
      the desired strategy for passing the device list to the underlying runtime
      [envvar | volume-mounts | cdi-annotations | cdi-cri] (default "envvar")
  deviceIDStrategy:
      the desired strategy for passing device IDs to the underlying runtime
      [uuid | index] (default "uuid")
  nvidiaDriverRoot:
      the root path for the NVIDIA driver installation (typical values are '/' or '/run/nvidia/driver')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; There is no value that directly maps to the &lt;code&gt;PASS_DEVICE_SPECS&lt;/code&gt; configuration option of the plugin. Instead a value called &lt;code&gt;compatWithCPUManager&lt;/code&gt; is provided which acts as a proxy for this option. It both sets the &lt;code&gt;PASS_DEVICE_SPECS&lt;/code&gt; option of the plugin to true &lt;strong&gt;AND&lt;/strong&gt; makes sure that the plugin is started with elevated privileges to ensure proper compatibility with the &lt;code&gt;CPUManager&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Besides these custom configuration options for the plugin, other standard helm chart values that are commonly overridden are:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;runtimeClassName:
  the runtimeClassName to use, for use with clusters that have multiple runtimes. (typical value is 'nvidia')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please take a look in the &lt;a href="https://github.com/NVIDIA/k8s-device-plugin/raw/v0.17.1/deployments/helm/nvidia-device-plugin/values.yaml"&gt;&lt;code&gt;values.yaml&lt;/code&gt;&lt;/a&gt; file to see the full set of overridable parameters for the device plugin.&lt;/p&gt; 
&lt;p&gt;Examples of setting these options include:&lt;/p&gt; 
&lt;p&gt;Enabling compatibility with the &lt;code&gt;CPUManager&lt;/code&gt; and running with a request for 100ms of CPU time and a limit of 512MB of memory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set compatWithCPUManager=true \
  --set resources.requests.cpu=100m \
  --set resources.limits.memory=512Mi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Enabling compatibility with the &lt;code&gt;CPUManager&lt;/code&gt; and the &lt;code&gt;mixed&lt;/code&gt; &lt;code&gt;migStrategy&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set compatWithCPUManager=true \
  --set migStrategy=mixed
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Deploying with gpu-feature-discovery for automatic node labels&lt;/h4&gt; 
&lt;p&gt;As of &lt;code&gt;v0.12.0&lt;/code&gt;, the device plugin's helm chart has integrated support to deploy &lt;a href="https://github.com/NVIDIA/gpu-feature-discovery"&gt;&lt;code&gt;gpu-feature-discovery&lt;/code&gt;&lt;/a&gt; (GFD). You can use GFD to automatically generate labels for the set of GPUs available on a node. Under the hood, it leverages &lt;a href="https://kubernetes-sigs.github.io/node-feature-discovery/stable/get-started/index.html"&gt;Node Feature Discovery&lt;/a&gt; to perform this labeling.&lt;/p&gt; 
&lt;p&gt;To enable it, simply set &lt;code&gt;gfd.enabled=true&lt;/code&gt; during helm install.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version=0.17.1 \
  --namespace nvidia-device-plugin \
  --create-namespace \
  --set gfd.enabled=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Under the hood this will also deploy &lt;a href="https://github.com/kubernetes-sigs/node-feature-discovery"&gt;&lt;code&gt;node-feature-discovery&lt;/code&gt;&lt;/a&gt; (NFD) since it is a prerequisite of GFD. If you already have NFD deployed on your cluster and do not wish for it to be pulled in by this installation, you can disable it with &lt;code&gt;nfd.enabled=false&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to the standard node labels applied by GFD, the following label will also be included when deploying the plugin with the time-slicing or MPS extensions described &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/#shared-access-to-gpus"&gt;above&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/&amp;lt;resource-name&amp;gt;.replicas = &amp;lt;num-replicas&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, the &lt;code&gt;nvidia.com/&amp;lt;resource-name&amp;gt;.product&lt;/code&gt; will be modified as follows if &lt;code&gt;renameByDefault=false&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/&amp;lt;resource-name&amp;gt;.product = &amp;lt;product name&amp;gt;-SHARED
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using these labels, users have a way of selecting a shared vs. non-shared GPU in the same way they would traditionally select one GPU model over another. That is, the &lt;code&gt;SHARED&lt;/code&gt; annotation ensures that a &lt;code&gt;nodeSelector&lt;/code&gt; can be used to attract pods to nodes that have shared GPUs on them.&lt;/p&gt; 
&lt;p&gt;Since having &lt;code&gt;renameByDefault=true&lt;/code&gt; already encodes the fact that the resource is shared on the resource name, there is no need to annotate the product name with &lt;code&gt;SHARED&lt;/code&gt;. Users can already find the shared resources they need by simply requesting it in their pod spec.&lt;/p&gt; 
&lt;p&gt;Note: When running with &lt;code&gt;renameByDefault=false&lt;/code&gt; and &lt;code&gt;migStrategy=single&lt;/code&gt; both the MIG profile name and the new &lt;code&gt;SHARED&lt;/code&gt; annotation will be appended to the product name, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvidia.com/gpu.product = A100-SXM4-40GB-MIG-1g.5gb-SHARED
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Deploying gpu-feature-discovery in standalone mode&lt;/h4&gt; 
&lt;p&gt;As of v0.15.0, the device plugin's helm chart has integrated support to deploy &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/docs/gpu-feature-discovery/README.md#overview"&gt;&lt;code&gt;gpu-feature-discovery&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;When gpu-feature-discovery in deploying standalone, begin by setting up the plugin's &lt;code&gt;helm&lt;/code&gt; repository and updating it at follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
helm repo update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then verify that the latest release (&lt;code&gt;v0.17.1&lt;/code&gt;) of the plugin is available (Note that this includes the GFD chart):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm search repo nvdp --devel
NAME                     	  CHART VERSION  APP VERSION	DESCRIPTION
nvdp/nvidia-device-plugin	  0.17.1	 0.17.1		A Helm chart for ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this repo is updated, you can begin installing packages from it to deploy the &lt;code&gt;gpu-feature-discovery&lt;/code&gt; component in standalone mode.&lt;/p&gt; 
&lt;p&gt;The most basic installation command without any options is then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
  --version 0.17.1 \
  --namespace gpu-feature-discovery \
  --create-namespace \
  --set devicePlugin.enabled=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Disabling auto-deployment of NFD and running with a MIG strategy of 'mixed' in the default namespace.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp nvdp/nvidia-device-plugin \
    --version=0.17.1 \
    --set allowDefaultNamespace=true \
    --set nfd.enabled=false \
    --set migStrategy=mixed \
    --set devicePlugin.enabled=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You only need the to pass the &lt;code&gt;--devel&lt;/code&gt; flag to &lt;code&gt;helm search repo&lt;/code&gt; and the &lt;code&gt;--version&lt;/code&gt; flag to &lt;code&gt;helm upgrade -i&lt;/code&gt; if this is a pre-release version (e.g. &lt;code&gt;&amp;lt;version&amp;gt;-rc.1&lt;/code&gt;). Full releases will be listed without this.&lt;/p&gt; 
&lt;h3&gt;Deploying via &lt;code&gt;helm install&lt;/code&gt; with a direct URL to the &lt;code&gt;helm&lt;/code&gt; package&lt;/h3&gt; 
&lt;p&gt;If you prefer not to install from the &lt;code&gt;nvidia-device-plugin&lt;/code&gt; &lt;code&gt;helm&lt;/code&gt; repo, you can run &lt;code&gt;helm install&lt;/code&gt; directly against the tarball of the plugin's &lt;code&gt;helm&lt;/code&gt; package. The example below installs the same chart as the method above, except that it uses a direct URL to the &lt;code&gt;helm&lt;/code&gt; chart instead of via the &lt;code&gt;helm&lt;/code&gt; repo.&lt;/p&gt; 
&lt;p&gt;Using the default values for the flags:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;helm upgrade -i nvdp \
  --namespace nvidia-device-plugin \
  --create-namespace \
  https://nvidia.github.io/k8s-device-plugin/stable/nvidia-device-plugin-0.17.1.tgz
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Building and Running Locally&lt;/h2&gt; 
&lt;p&gt;The next sections are focused on building the device plugin locally and running it. It is intended purely for development and testing, and not required by most users. It assumes you are pinning to the latest release tag (i.e. &lt;code&gt;v0.17.1&lt;/code&gt;), but can easily be modified to work with any available tag or branch.&lt;/p&gt; 
&lt;h3&gt;With Docker&lt;/h3&gt; 
&lt;h4&gt;Build&lt;/h4&gt; 
&lt;p&gt;Option 1, pull the prebuilt image from &lt;a href="https://hub.docker.com/r/nvidia/k8s-device-plugin"&gt;Docker Hub&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker pull nvcr.io/nvidia/k8s-device-plugin:v0.17.1
docker tag nvcr.io/nvidia/k8s-device-plugin:v0.17.1 nvcr.io/nvidia/k8s-device-plugin:devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Option 2, build without cloning the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker build \
  -t nvcr.io/nvidia/k8s-device-plugin:devel \
  -f deployments/container/Dockerfile.ubuntu \
  https://github.com/NVIDIA/k8s-device-plugin.git#v0.17.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Option 3, if you want to modify the code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/NVIDIA/k8s-device-plugin.git &amp;amp;&amp;amp; cd k8s-device-plugin
docker build \
  -t nvcr.io/nvidia/k8s-device-plugin:devel \
  -f deployments/container/Dockerfile.ubuntu \
  .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run&lt;/h4&gt; 
&lt;p&gt;Without compatibility for the &lt;code&gt;CPUManager&lt;/code&gt; static policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run \
  -it \
  --security-opt=no-new-privileges \
  --cap-drop=ALL \
  --network=none \
  -v /var/lib/kubelet/device-plugins:/var/lib/kubelet/device-plugins \
  nvcr.io/nvidia/k8s-device-plugin:devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With compatibility for the &lt;code&gt;CPUManager&lt;/code&gt; static policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run \
  -it \
  --privileged \
  --network=none \
  -v /var/lib/kubelet/device-plugins:/var/lib/kubelet/device-plugins \
  nvcr.io/nvidia/k8s-device-plugin:devel --pass-device-specs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Without Docker&lt;/h3&gt; 
&lt;h4&gt;Build&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;C_INCLUDE_PATH=/usr/local/cuda/include LIBRARY_PATH=/usr/local/cuda/lib64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run&lt;/h4&gt; 
&lt;p&gt;Without compatibility for the &lt;code&gt;CPUManager&lt;/code&gt; static policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./k8s-device-plugin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With compatibility for the &lt;code&gt;CPUManager&lt;/code&gt; static policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./k8s-device-plugin --pass-device-specs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/CHANGELOG.md"&gt;changelog&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Issues and Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/CONTRIBUTING.md"&gt;Checkout the Contributing document!&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can report a bug by &lt;a href="https://github.com/NVIDIA/k8s-device-plugin/issues/new"&gt;filing a new issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;You can contribute by opening a &lt;a href="https://help.github.com/articles/using-pull-requests/"&gt;pull request&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Versioning&lt;/h3&gt; 
&lt;p&gt;Before v1.10 the versioning scheme of the device plugin had to match exactly the version of Kubernetes. After the promotion of device plugins to beta this condition was was no longer required. We quickly noticed that this versioning scheme was very confusing for users as they still expected to see a version of the device plugin for each version of Kubernetes.&lt;/p&gt; 
&lt;p&gt;This versioning scheme applies to the tags &lt;code&gt;v1.8&lt;/code&gt;, &lt;code&gt;v1.9&lt;/code&gt;, &lt;code&gt;v1.10&lt;/code&gt;, &lt;code&gt;v1.11&lt;/code&gt;, &lt;code&gt;v1.12&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;We have now changed the versioning to follow &lt;a href="https://semver.org/"&gt;SEMVER&lt;/a&gt;. The first version following this scheme has been tagged &lt;code&gt;v0.0.0&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Going forward, the major version of the device plugin will only change following a change in the device plugin API itself. For example, version &lt;code&gt;v1beta1&lt;/code&gt; of the device plugin API corresponds to version &lt;code&gt;v0.x.x&lt;/code&gt; of the device plugin. If a new &lt;code&gt;v2beta2&lt;/code&gt; version of the device plugin API comes out, then the device plugin will increase its major version to &lt;code&gt;1.x.x&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;As of now, the device plugin API for Kubernetes &amp;gt;= v1.10 is &lt;code&gt;v1beta1&lt;/code&gt;. If you have a version of Kubernetes &amp;gt;= 1.10 you can deploy any device plugin version &amp;gt; &lt;code&gt;v0.0.0&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Upgrading Kubernetes with the Device Plugin&lt;/h3&gt; 
&lt;p&gt;Upgrading Kubernetes when you have a device plugin deployed doesn't require you to do any, particular changes to your workflow. The API is versioned and is pretty stable (though it is not guaranteed to be non breaking). Starting with Kubernetes version 1.10, you can use &lt;code&gt;v0.3.0&lt;/code&gt; of the device plugin to perform upgrades, and Kubernetes won't require you to deploy a different version of the device plugin. Once a node comes back online after the upgrade, you will see GPUs re-registering themselves automatically.&lt;/p&gt; 
&lt;p&gt;Upgrading the device plugin itself is a more complex task. It is recommended to drain GPU tasks as we cannot guarantee that GPU tasks will survive a rolling upgrade. However we make best efforts to preserve GPU tasks during an upgrade.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rcourtman/Pulse</title>
      <link>https://github.com/rcourtman/Pulse</link>
      <description>&lt;p&gt;A responsive monitoring platform for Proxmox VE, PBS, and Docker with real-time metrics across nodes and containers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pulse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/rcourtman/Pulse" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;&lt;img src="https://img.shields.io/docker/pulls/rcourtman/pulse" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/rcourtman/Pulse" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Real-time monitoring for Proxmox VE, Proxmox Mail Gateway, PBS, and Docker infrastructure with alerts and webhooks.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Monitor your hybrid Proxmox and Docker estate from a single dashboard. Get instant alerts when nodes go down, containers misbehave, backups fail, or storage fills up. Supports email, Discord, Slack, Telegram, and more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.pulserelay.pro"&gt;Try the live demo ‚Üí&lt;/a&gt;&lt;/strong&gt; (read-only with mock data)&lt;/p&gt; 
&lt;img width="2872" height="1502" alt="image" src="https://github.com/user-attachments/assets/41ac125c-59e3-4bdc-bfd2-e300109aa1f7" /&gt; 
&lt;h2&gt;Support Pulse Development&lt;/h2&gt; 
&lt;p&gt;Pulse is built by a solo developer in evenings and weekends. Your support helps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keep me motivated to add new features&lt;/li&gt; 
 &lt;li&gt;Prioritize bug fixes and user requests&lt;/li&gt; 
 &lt;li&gt;Ensure Pulse stays 100% free and open-source forever&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/rcourtman"&gt;&lt;img src="https://img.shields.io/github/sponsors/rcourtman?style=social&amp;amp;label=Sponsor" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://ko-fi.com/rcourtman"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Not ready to sponsor?&lt;/strong&gt; Star the project or share it with your homelab community!&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Discovery&lt;/strong&gt;: Finds Proxmox nodes on your network, one-liner setup via generated scripts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cluster Support&lt;/strong&gt;: Configure one node, monitor entire cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest, masked in logs, never sent to frontend&lt;/li&gt; 
   &lt;li&gt;CSRF protection for all state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting (500 req/min general, 10 attempts/min for auth)&lt;/li&gt; 
   &lt;li&gt;Account lockout after failed login attempts&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Live monitoring of VMs, containers, nodes, storage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Alerts&lt;/strong&gt;: Email and webhooks (Discord, Slack, Telegram, Teams, ntfy.sh, Gotify) 
  &lt;ul&gt; 
   &lt;li&gt;Example: "VM 'webserver' is down on node 'pve1'"&lt;/li&gt; 
   &lt;li&gt;Example: "Storage 'local-lvm' at 85% capacity"&lt;/li&gt; 
   &lt;li&gt;Example: "VM 'database' is back online"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Thresholds&lt;/strong&gt;: Hysteresis-based trigger/clear levels, fractional network thresholds, per-metric search, reset-to-defaults, and Custom overrides with inline audit trail&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alert Timeline Analytics&lt;/strong&gt;: Rich history explorer with acknowledgement/clear markers, escalation breadcrumbs, and quick filters for noisy resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ceph Awareness&lt;/strong&gt;: Surface Ceph health, pool utilisation, and daemon status automatically when Proxmox exposes Ceph-backed storage&lt;/li&gt; 
 &lt;li&gt;Unified view of PBS backups, PVE backups, and snapshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Backup Explorer&lt;/strong&gt;: Cross-highlighted bar chart + grid with quick time-range pivots (24h/7d/30d/custom) and contextual tooltips for the busiest jobs&lt;/li&gt; 
 &lt;li&gt;Proxmox Mail Gateway analytics: mail volume, spam/virus trends, quarantine health, and cluster node status&lt;/li&gt; 
 &lt;li&gt;Optional Docker container monitoring via lightweight agent&lt;/li&gt; 
 &lt;li&gt;Config export/import with encryption and authentication&lt;/li&gt; 
 &lt;li&gt;Automatic stable updates with safe rollback (opt-in)&lt;/li&gt; 
 &lt;li&gt;Dark/light themes, responsive design&lt;/li&gt; 
 &lt;li&gt;Built with Go for minimal resource usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;Screenshots ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Privacy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Pulse respects your privacy:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No telemetry or analytics collection&lt;/li&gt; 
 &lt;li&gt;No phone-home functionality&lt;/li&gt; 
 &lt;li&gt;No external API calls (except for configured webhooks)&lt;/li&gt; 
 &lt;li&gt;All data stays on your server&lt;/li&gt; 
 &lt;li&gt;Open source - verify it yourself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your infrastructure data is yours alone.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Recommended: Official installer (auto-detects Proxmox and creates container)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Need to roll back to a previous release? Pass the tag you want
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.20.0

# Alternative: Docker
docker run -d -p 7655:7655 -v pulse_data:/data rcourtman/pulse:latest

# Testing: Install from main branch source (for testing latest fixes)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --source

# Alternative: Kubernetes (Helm)
helm registry login ghcr.io
helm install pulse oci://ghcr.io/rcourtman/pulse-chart \
  --version $(curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/VERSION) \
  --namespace pulse \
  --create-namespace
# Replace the VERSION lookup with a specific release if you need to pin. For local development, see docs/KUBERNETES.md.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proxmox users&lt;/strong&gt;: The installer detects PVE hosts and automatically creates an optimized LXC container. Choose Quick mode for one-minute setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/INSTALL.md"&gt;Advanced installation options ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Updating&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Automatic Updates (New!):&lt;/strong&gt; Enable during installation or via Settings UI to stay current automatically&lt;br /&gt; &lt;strong&gt;Standard Install:&lt;/strong&gt; Re-run the installer&lt;br /&gt; &lt;strong&gt;Docker:&lt;/strong&gt; &lt;code&gt;docker pull rcourtman/pulse:latest&lt;/code&gt; then recreate container&lt;/p&gt; 
&lt;h3&gt;Initial Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Interactive Setup (UI)&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;code&gt;http://&amp;lt;your-server&amp;gt;:7655&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete the mandatory security setup&lt;/strong&gt; (first-time only)&lt;/li&gt; 
 &lt;li&gt;Create your admin username and password&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;Settings ‚Üí Security ‚Üí API tokens&lt;/strong&gt; to mint dedicated tokens for automation (issue one token per integration so you can revoke credentials individually)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Automated Setup (No UI)&lt;/strong&gt; For automated deployments, configure authentication via environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start Pulse with auth pre-configured - skips setup screen
API_TOKENS="ansible-token,docker-agent-token" ./pulse

# Or use basic auth
PULSE_AUTH_USER=admin PULSE_AUTH_PASS=password ./pulse

# Plain text credentials are automatically hashed for security
# `API_TOKEN` is still accepted for back-compat, but `API_TOKENS` lets you manage multiple credentials
# You can also provide pre-hashed values if preferred
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md#automated-setup-skip-ui"&gt;Configuration Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Configure Nodes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Two authentication methods available:&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Method 1: Manual Setup (Recommended for interactive use)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;After login, go to Settings ‚Üí Nodes&lt;/li&gt; 
 &lt;li&gt;Discovered nodes appear automatically&lt;/li&gt; 
 &lt;li&gt;Click "Setup Script" next to any node&lt;/li&gt; 
 &lt;li&gt;Click "Generate Setup Code" button (creates a 6-character code valid for 5 minutes)&lt;/li&gt; 
 &lt;li&gt;Copy and run the provided one-liner on your Proxmox/PBS host&lt;/li&gt; 
 &lt;li&gt;Node is configured and monitoring starts automatically&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=ABC123" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Method 2: Automated Setup (For scripts/automation)&lt;/h4&gt; 
&lt;p&gt;Use your permanent API token directly in the URL for automation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Proxmox VE
curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=YOUR_API_TOKEN" | bash

# For Proxmox Backup Server
curl -sSL "http://pulse:7655/api/setup-script?type=pbs&amp;amp;host=https://pbs:8007&amp;amp;auth_token=YOUR_API_TOKEN" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: &lt;code&gt;pve&lt;/code&gt; for Proxmox VE, &lt;code&gt;pbs&lt;/code&gt; for Proxmox Backup Server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;host&lt;/code&gt;: Full URL of your Proxmox/PBS server (e.g., &lt;a href="https://192.168.1.100:8006"&gt;https://192.168.1.100:8006&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;auth_token&lt;/code&gt;: Either a 6-character setup code (expires in 5 min) or your permanent API token&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;backup_perms=true&lt;/code&gt; (optional): Add backup management permissions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pulse_url&lt;/code&gt; (optional): Pulse server URL if different from where script is downloaded&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script handles user creation, permissions, token generation, and registration automatically.&lt;/p&gt; 
&lt;h3&gt;Monitor Docker Containers (optional)&lt;/h3&gt; 
&lt;p&gt;Deploy the lightweight &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER_MONITORING.md"&gt;Pulse Docker agent&lt;/a&gt; on any host running Docker to stream container status and resource data back to Pulse. Install the agent alongside your stack, point it at your Pulse URL and API token, and the &lt;strong&gt;Docker&lt;/strong&gt; workspace lights up with host summaries, restart loop detection, per-container CPU/memory charts, and quick filters for stacks and unhealthy workloads.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Network Discovery&lt;/h3&gt; 
&lt;p&gt;Pulse automatically discovers Proxmox nodes on your network! By default, it scans:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;192.168.0.0/16 (home networks)&lt;/li&gt; 
 &lt;li&gt;10.0.0.0/8 (private networks)&lt;/li&gt; 
 &lt;li&gt;172.16.0.0/12 (Docker/internal networks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To scan a custom subnet instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e DISCOVERY_SUBNET="192.168.50.0/24" \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Automated Deployment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Deploy with authentication pre-configured
docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e API_TOKENS="ansible-token,docker-agent-token" \
  -e PULSE_AUTH_USER="admin" \
  -e PULSE_AUTH_PASS="your-password" \
  --restart unless-stopped \
  rcourtman/pulse:latest

# Plain text credentials are automatically hashed for security
# No setup required - API works immediately
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  pulse:
    image: rcourtman/pulse:latest
    container_name: pulse
    ports:
      - "7655:7655"
    volumes:
      - pulse_data:/data
    environment:
      # NOTE: Env vars override UI settings. Remove env var to allow UI configuration.
      
      # Network discovery (usually not needed - auto-scans common networks)
      # - DISCOVERY_SUBNET=192.168.50.0/24  # Only for non-standard networks
      
      # Ports
      # - PORT=7655                         # Backend port (default: 7655)
      # - FRONTEND_PORT=7655                # Frontend port (default: 7655)
      
      # Security (all optional - runs open by default)
      # - PULSE_AUTH_USER=admin             # Username for web UI login
      # - PULSE_AUTH_PASS=your-password     # Plain text or bcrypt hash (auto-hashed if plain)
      # - API_TOKENS=token-a,token-b        # Comma-separated tokens (plain or SHA3-256 hashed)
      # - API_TOKEN=legacy-token            # Optional single-token fallback
      # - ALLOW_UNPROTECTED_EXPORT=false    # Allow export without auth (default: false)
      
      # Security: Plain text credentials are automatically hashed
      # You can provide either:
      # 1. Plain text (auto-hashed): PULSE_AUTH_PASS=mypassword
      # 2. Pre-hashed (advanced): PULSE_AUTH_PASS='$$2a$$12$$...'
      #    Note: Escape $ as $$ in docker-compose.yml for pre-hashed values
      
      # Performance
      # - CONNECTION_TIMEOUT=10             # Connection timeout in seconds (default: 10)
      
      # CORS &amp;amp; logging
      # - ALLOWED_ORIGINS=https://app.example.com  # CORS origins (default: none, same-origin only)
      # - LOG_LEVEL=info                    # Log level: debug/info/warn/error (default: info)
    restart: unless-stopped

volumes:
  pulse_data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication required&lt;/strong&gt; - Protects your Proxmox infrastructure credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick setup wizard&lt;/strong&gt; - Secure your installation in under a minute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple auth methods&lt;/strong&gt;: Password authentication, API tokens, proxy auth (SSO), or combinations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy/SSO support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other authentication proxies (&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-grade protection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest (AES-256-GCM)&lt;/li&gt; 
   &lt;li&gt;CSRF tokens for state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting and account lockout protection&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security by design&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Frontend never receives node credentials&lt;/li&gt; 
   &lt;li&gt;API tokens visible only to authenticated users&lt;/li&gt; 
   &lt;li&gt;Export/import requires authentication when configured&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Documentation&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;h3&gt;Update Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse checks for updates and displays notifications in the UI when new versions are available. For security reasons, updates must be installed manually using the appropriate method for your deployment.&lt;/p&gt; 
&lt;h3&gt;Manual Installation (systemd)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update to latest stable
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Update to latest RC/pre-release  
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --rc

# Install specific version
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Updates&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Latest stable
docker pull rcourtman/pulse:latest

# Latest RC
docker pull rcourtman/pulse:rc

# Specific version
docker pull rcourtman/pulse:v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Quick start - most settings are in the web UI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Nodes&lt;/strong&gt;: Add/remove Proxmox instances&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí System&lt;/strong&gt;: Polling intervals, timeouts, update settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Security&lt;/strong&gt;: Authentication and API tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Thresholds and notifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apprise Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse can broadcast grouped alerts through &lt;a href="https://github.com/caronc/apprise"&gt;Apprise&lt;/a&gt; using either the local CLI or a remote Apprise API gateway. Configure everything under &lt;strong&gt;Alerts ‚Üí Notifications ‚Üí Apprise&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local CLI&lt;/strong&gt; ‚Äì Install Apprise on the Pulse host (for example &lt;code&gt;pip install apprise&lt;/code&gt;) and enter one Apprise URL per line in the delivery targets field. You can override the CLI path and timeout if the executable lives outside of &lt;code&gt;$PATH&lt;/code&gt;. Pulse skips CLI delivery automatically when no targets are configured.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote API&lt;/strong&gt; ‚Äì Point Pulse at an Apprise API server by providing the base URL (such as &lt;code&gt;https://apprise-api.local:8000&lt;/code&gt;). Optionally include a configuration key (for &lt;code&gt;/notify/{key}&lt;/code&gt; routes), an API key header/value pair, and allow self-signed certificates for lab deployments. Targets remain optional in API mode‚Äîleave the list empty to let the Apprise server use its stored defaults.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For both modes, delivery targets accept any Apprise URL (Discord, Slack, email, SMS, etc.). The timeout applies to the CLI process or HTTP request respectively.&lt;/p&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Pulse uses three separate configuration files with clear separation of concerns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - Authentication credentials only&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;system.json&lt;/code&gt; - Application settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nodes.enc&lt;/code&gt; - Encrypted node credentials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;docs/CONFIGURATION.md&lt;/a&gt; for detailed documentation on configuration structure and management.&lt;/p&gt; 
&lt;h3&gt;Email Alerts Configuration&lt;/h3&gt; 
&lt;p&gt;Configure email notifications in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Email Destinations&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Supported Providers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gmail/Google Workspace&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outlook/Office 365&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom SMTP&lt;/strong&gt;: Any SMTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Recommended Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Port 587 with STARTTLS&lt;/strong&gt; (recommended for most providers)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 465&lt;/strong&gt; for SSL/TLS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 25&lt;/strong&gt; for unencrypted (not recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Gmail Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable 2-factor authentication&lt;/li&gt; 
 &lt;li&gt;Generate app-specific password at &lt;a href="https://myaccount.google.com/apppasswords"&gt;https://myaccount.google.com/apppasswords&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp.gmail.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Outlook Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate app password at &lt;a href="https://account.microsoft.com/security"&gt;https://account.microsoft.com/security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp-mail.outlook.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Alert Configuration&lt;/h3&gt; 
&lt;p&gt;Pulse provides two complementary approaches for managing alerts:&lt;/p&gt; 
&lt;h4&gt;Custom Alert Rules (Permanent Policy)&lt;/h4&gt; 
&lt;p&gt;Configure persistent alert policies in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Custom Rules&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define thresholds for specific VMs/containers based on name patterns&lt;/li&gt; 
 &lt;li&gt;Set different thresholds for production vs development environments&lt;/li&gt; 
 &lt;li&gt;Create complex rules with AND/OR logic&lt;/li&gt; 
 &lt;li&gt;Manage all rules through the UI with priority ordering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Use for:&lt;/strong&gt; Long-term alert policies like "all database VMs should alert at 90%"&lt;/p&gt; 
&lt;h3&gt;HTTPS/TLS Configuration&lt;/h3&gt; 
&lt;p&gt;Enable HTTPS by setting these environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="HTTPS_ENABLED=true"
Environment="TLS_CERT_FILE=/etc/pulse/cert.pem"
Environment="TLS_KEY_FILE=/etc/pulse/key.pem"

# Docker
docker run -d -p 7655:7655 \
  -e HTTPS_ENABLED=true \
  -e TLS_CERT_FILE=/data/cert.pem \
  -e TLS_KEY_FILE=/data/key.pem \
  -v pulse_data:/data \
  -v /path/to/certs:/data/certs:ro \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For deployment overrides (ports, etc), use environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="FRONTEND_PORT=8080"

# Docker: -e FRONTEND_PORT=8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Full Configuration Guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Backup/Restore&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Via UI (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Settings ‚Üí Security ‚Üí Backup &amp;amp; Restore&lt;/li&gt; 
 &lt;li&gt;Export: Choose login password or custom passphrase for encryption&lt;/li&gt; 
 &lt;li&gt;Import: Upload backup file with passphrase&lt;/li&gt; 
 &lt;li&gt;Includes all settings, nodes, and custom console URLs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Via CLI:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Export (v4.0.3+)
pulse config export -o backup.enc

# Import
pulse config import -i backup.enc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Pulse shows when updates are available and provides deployment-specific instructions:&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull rcourtman/pulse:latest
docker stop pulse
docker rm pulse
# Run docker run command again with your settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The UI will detect your deployment type and show the appropriate update method when a new version is available.&lt;/p&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Status
curl http://localhost:7655/api/health

# Metrics (default time range: 1h)
curl http://localhost:7655/api/charts

# With authentication (if configured)
curl -H "X-API-Token: your-token" http://localhost:7655/api/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;Full API Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt; - Complete endpoint reference with examples&lt;/p&gt; 
&lt;h2&gt;Reverse Proxy &amp;amp; SSO&lt;/h2&gt; 
&lt;p&gt;Using Pulse behind a reverse proxy? &lt;strong&gt;WebSocket support is required for real-time updates.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NEW: Proxy Authentication Support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other SSO providers. See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Configuration Guide&lt;/a&gt; for nginx, Caddy, Apache, Traefik, HAProxy, and Cloudflare Tunnel configurations.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Authentication Issues&lt;/h3&gt; 
&lt;h4&gt;Cannot login after setting up security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Ensure bcrypt hash is exactly 60 characters and wrapped in single quotes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: MUST escape $ characters as $$ (e.g., &lt;code&gt;$$2a$$12$$...&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker run)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$2a$12$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker-compose.yml)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$$2a$$12$$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If hash is truncated or mangled, authentication will fail&lt;/li&gt; 
 &lt;li&gt;Use Quick Security Setup in the UI to avoid manual configuration errors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;.env file not created (Docker)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Expected behavior&lt;/strong&gt;: When using environment variables, no .env file is created in /data&lt;/li&gt; 
 &lt;li&gt;The .env file is only created when using Quick Security Setup or password changes&lt;/li&gt; 
 &lt;li&gt;If you provide credentials via environment variables, they take precedence&lt;/li&gt; 
 &lt;li&gt;To use Quick Security Setup: Start container WITHOUT auth environment variables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VM Disk Stats Show "-"&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;VMs require QEMU Guest Agent to report disk usage (Proxmox API returns 0 for VMs)&lt;/li&gt; 
 &lt;li&gt;Install guest agent in VM: &lt;code&gt;apt install qemu-guest-agent&lt;/code&gt; (Linux) or virtio-win tools (Windows)&lt;/li&gt; 
 &lt;li&gt;Enable in VM Options ‚Üí QEMU Guest Agent, then restart VM&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring Guide&lt;/a&gt; for setup&lt;/li&gt; 
 &lt;li&gt;Container (LXC) disk stats always work (no guest agent needed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check Proxmox API is accessible (port 8006/8007)&lt;/li&gt; 
 &lt;li&gt;Verify credentials have PVEAuditor role plus VM.GuestAgent.Audit (PVE 9) or VM.Monitor (PVE 8); the setup script applies these via the PulseMonitor role (adds Sys.Audit when available)&lt;/li&gt; 
 &lt;li&gt;For PBS: ensure API token has Datastore.Audit permission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High CPU/Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce polling interval in Settings&lt;/li&gt; 
 &lt;li&gt;Check number of monitored nodes&lt;/li&gt; 
 &lt;li&gt;Disable unused features (backups, snapshots)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker logs pulse

# Manual
journalctl -u pulse -f
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER.md"&gt;Docker Guide&lt;/a&gt; - Complete Docker deployment guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Configuration Guide&lt;/a&gt; - Complete setup and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring&lt;/a&gt; - Set up QEMU Guest Agent for accurate VM disk usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PORT_CONFIGURATION.md"&gt;Port Configuration&lt;/a&gt; - How to change the default port&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt; - Common issues and solutions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;API Reference&lt;/a&gt; - REST API endpoints and examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/WEBHOOKS.md"&gt;Webhook Guide&lt;/a&gt; - Setting up webhooks and custom payloads&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication&lt;/a&gt; - SSO integration with Authentik, Authelia, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Setup&lt;/a&gt; - nginx, Caddy, Apache, Traefik configs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security&lt;/a&gt; - Security features and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/FAQ.md"&gt;FAQ&lt;/a&gt; - Common questions and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/MIGRATION.md"&gt;Migration Guide&lt;/a&gt; - Backup and migration procedures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mandatory authentication&lt;/strong&gt; protects your infrastructure&lt;/li&gt; 
 &lt;li&gt;Credentials stored encrypted (AES-256-GCM)&lt;/li&gt; 
 &lt;li&gt;API token support for automation&lt;/li&gt; 
 &lt;li&gt;Export/import requires authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Setup script authentication&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Setup codes&lt;/strong&gt;: Temporary 6-character codes for manual setup (expire in 5 minutes)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API tokens&lt;/strong&gt;: Permanent tokens for automation and scripting&lt;/li&gt; 
   &lt;li&gt;Use setup codes when giving access to others without sharing your API token&lt;/li&gt; 
   &lt;li&gt;Use API tokens for your own automation or trusted environments&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Details ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Quick Start - Hot Reload (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch Vite + Go with automatic frontend proxying
make dev-hot
# Frontend HMR: http://127.0.0.1:5173
# Backend API:   http://127.0.0.1:7655 (served via the Go app)
# Ports come from FRONTEND_PORT/PULSE_DEV_API_PORT (loaded from .env*. Override there if you need a different port.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The backend now detects &lt;code&gt;FRONTEND_DEV_SERVER&lt;/code&gt; and proxies requests straight to the Vite dev server. Edit files under &lt;code&gt;frontend-modern/src/&lt;/code&gt; and the browser refreshes instantly‚Äîno manual rebuilds or service restarts required. Use &lt;code&gt;CTRL+C&lt;/code&gt; to stop both processes.&lt;/p&gt; 
&lt;h3&gt;Mock Mode - Develop Without Real Infrastructure&lt;/h3&gt; 
&lt;p&gt;Work on Pulse without needing Proxmox servers! Mock mode generates realistic test data and auto-reloads when toggled. The &lt;code&gt;mock.env&lt;/code&gt; configuration file is &lt;strong&gt;included in the repository&lt;/strong&gt;, so it works out of the box for all developers.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable mock mode with 7 nodes, ~90 guests
npm run mock:on

# Disable mock mode (use real infrastructure)
npm run mock:off

# Edit mock configuration
npm run mock:edit

# Create local overrides (not committed to git)
cp mock.env mock.env.local
# Edit mock.env.local with your personal preferences

# Data directories are isolated automatically:
# - Mock mode:   /opt/pulse/tmp/mock-data
# - Production:  /etc/pulse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Backend auto-reloads when mock.env changes - no manual restarts!&lt;/strong&gt; The toggle scripts keep mock data isolated from &lt;code&gt;/etc/pulse&lt;/code&gt; so your real credentials stay untouched.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/development/MOCK_MODE.md"&gt;docs/development/MOCK_MODE.md&lt;/a&gt; for full details.&lt;/p&gt; 
&lt;h3&gt;Production-like Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Watches files and rebuilds/embeds frontend into Go binary
./dev.sh
# Access at: http://localhost:7655
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Frontend only
cd frontend-modern
npm install
npm run dev

# Backend only
go build -o pulse ./cmd/pulse
./pulse

# Or use make for full rebuild
make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Visual Tour&lt;/h2&gt; 
&lt;p&gt;See Pulse in action with our &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;complete screenshot gallery ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dashboard&lt;/th&gt; 
   &lt;th&gt;Storage&lt;/th&gt; 
   &lt;th&gt;Backups&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/01-dashboard.png" alt="Dashboard" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/02-storage.png" alt="Storage" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/03-backups.png" alt="Backups" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Real-time monitoring of nodes, VMs &amp;amp; containers&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Storage pool usage across all nodes&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unified backup management &amp;amp; PBS integration&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Alerts &amp;amp; Configuration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alert Configuration&lt;/th&gt; 
   &lt;th&gt;Alert History&lt;/th&gt; 
   &lt;th&gt;Settings&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/04-alerts.png" alt="Alerts" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/05-alert-history.png" alt="Alert History" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/06-settings.png" alt="Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Configure thresholds &amp;amp; notifications&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Track patterns with visual timeline&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Manage nodes &amp;amp; authentication&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Mobile Experience&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mobile Dashboard&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/08-mobile.png" alt="Mobile" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Fully responsive interface for monitoring on the go&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;Docker Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT - See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fatedier/frp</title>
      <link>https://github.com/fatedier/frp</link>
      <description>&lt;p&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;frp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/fatedier/frp"&gt;&lt;img src="https://circleci.com/gh/fatedier/frp.svg?style=shield" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fatedier/frp/releases"&gt;&lt;img src="https://img.shields.io/github/tag/fatedier/frp.svg?label=release" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/fatedier/frp"&gt;&lt;img src="https://goreportcard.com/badge/github.com/fatedier/frp" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;amp;repository=frp"&gt;&lt;img src="https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github" alt="GitHub Releases Stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README.md"&gt;README&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README_zh.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you'd like to join them, please consider &lt;a href="https://github.com/sponsors/fatedier"&gt;sponsoring frp's development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 align="center"&gt;Gold Sponsors&lt;/h3&gt; 
&lt;!--gold sponsors start--&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Recall.ai - API for meeting recordings&lt;/h2&gt; 
 &lt;p&gt;If you're looking for a meeting recording API, consider checking out &lt;a href="https://www.recall.ai/?utm_source=github&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=fatedier-frp"&gt;Recall.ai&lt;/a&gt;,&lt;/p&gt; 
 &lt;p&gt;an API that records Zoom, Google Meet, Microsoft Teams, in-person meetings, and more.&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://requestly.com/?utm_source=github&amp;amp;utm_medium=partnered&amp;amp;utm_campaign=frp" target="_blank"&gt; &lt;img width="480px" src="https://github.com/user-attachments/assets/24670320-997d-4d62-9bca-955c59fe883d" /&gt; &lt;br /&gt; &lt;b&gt;Requestly - Free &amp;amp; Open-Source alternative to Postman&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;All-in-one platform to Test, Mock and Intercept APIs.&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.warp.dev/frp" target="_blank"&gt; &lt;img width="360px" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-01.png" /&gt; &lt;br /&gt; &lt;b&gt;Warp, built for collaborating with AI Agents&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;Available for macOS, Linux and Windows&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://jb.gg/frp" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg" /&gt; &lt;br /&gt; &lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/daytonaio/daytona" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_daytona.png" /&gt; &lt;br /&gt; &lt;b&gt;Secure and Elastic Infrastructure for Running Your AI-Generated Code&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/beclab/Olares" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg" /&gt; &lt;br /&gt; &lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;!--gold sponsors end--&gt; 
&lt;h2&gt;What is frp?&lt;/h2&gt; 
&lt;p&gt;frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;, as well as &lt;strong&gt;HTTP&lt;/strong&gt; and &lt;strong&gt;HTTPS&lt;/strong&gt; protocols, enabling requests to be forwarded to internal services via domain name.&lt;/p&gt; 
&lt;p&gt;frp also offers a P2P connect mode.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- vim-markdown-toc GFM --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#development-status"&gt;Development Status&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#about-v2"&gt;About V2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;Example Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#access-your-computer-in-a-lan-network-via-ssh"&gt;Access your computer in a LAN network via SSH&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#multiple-ssh-services-sharing-the-same-port"&gt;Multiple SSH services sharing the same port&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#accessing-internal-web-services-with-custom-domains-in-lan"&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-dns-query-requests"&gt;Forward DNS query requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-unix-domain-socket"&gt;Forward Unix Domain Socket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-a-simple-http-file-server"&gt;Expose a simple HTTP file server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enable-https-for-a-local-https-service"&gt;Enable HTTPS for a local HTTP(S) service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-your-service-privately"&gt;Expose your service privately&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#p2p-mode"&gt;P2P Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#configuration-files"&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#using-environment-variables"&gt;Using Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#split-configures-into-different-files"&gt;Split Configures Into Different Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-dashboard"&gt;Server Dashboard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-admin-ui"&gt;Client Admin UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#monitor"&gt;Monitor&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#prometheus"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#authenticating-the-client"&gt;Authenticating the Client&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#token-authentication"&gt;Token Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#oidc-authentication"&gt;OIDC Authentication&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#encryption-and-compression"&gt;Encryption and Compression&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tls"&gt;TLS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#hot-reloading-frpc-configuration"&gt;Hot-Reloading frpc configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-proxy-status-from-client"&gt;Get proxy status from client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#only-allowing-certain-ports-on-the-server"&gt;Only allowing certain ports on the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-reuse"&gt;Port Reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#bandwidth-limit"&gt;Bandwidth Limit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#for-each-proxy"&gt;For Each Proxy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-stream-multiplexing"&gt;TCP Stream Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-kcp-protocol"&gt;Support KCP Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-quic-protocol"&gt;Support QUIC Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connection-pooling"&gt;Connection Pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#load-balancing"&gt;Load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#service-health-check"&gt;Service Health Check&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#rewriting-the-http-host-header"&gt;Rewriting the HTTP Host Header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#setting-other-http-headers"&gt;Setting other HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-real-ip"&gt;Get Real IP&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#http-x-forwarded-for"&gt;HTTP X-Forwarded-For&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#proxy-protocol"&gt;Proxy Protocol&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#require-http-basic-auth-password-for-web-services"&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#custom-subdomain-names"&gt;Custom Subdomain Names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#url-routing"&gt;URL Routing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-port-multiplexing"&gt;TCP Port Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connecting-to-frps-via-proxy"&gt;Connecting to frps via PROXY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-range-mapping"&gt;Port range mapping&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-plugins"&gt;Client Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-manage-plugins"&gt;Server Manage Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#ssh-tunnel-gateway"&gt;SSH Tunnel Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#virtual-network-virtualnet"&gt;Virtual Network (VirtualNet)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-gates"&gt;Feature Gates&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#available-feature-gates"&gt;Available Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enabling-feature-gates"&gt;Enabling Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-lifecycle"&gt;Feature Lifecycle&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#donation"&gt;Donation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#github-sponsors"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#paypal"&gt;PayPal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vim-markdown-toc --&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;frp is currently under development. You can try the latest release version in the &lt;code&gt;master&lt;/code&gt; branch, or use the &lt;code&gt;dev&lt;/code&gt; branch to access the version currently in development.&lt;/p&gt; 
&lt;p&gt;We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.&lt;/p&gt; 
&lt;p&gt;We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.&lt;/p&gt; 
&lt;h3&gt;About V2&lt;/h3&gt; 
&lt;p&gt;The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.&lt;/p&gt; 
&lt;p&gt;The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.&lt;/p&gt; 
&lt;p&gt;In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone's needs.&lt;/p&gt; 
&lt;p&gt;Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.&lt;/p&gt; 
&lt;p&gt;We sincerely appreciate your support for frp.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Example Usage&lt;/h2&gt; 
&lt;p&gt;To begin, download the latest program for your operating system and architecture from the &lt;a href="https://github.com/fatedier/frp/releases"&gt;Release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Next, place the &lt;code&gt;frps&lt;/code&gt; binary and server configuration file on Server A, which has a public IP address.&lt;/p&gt; 
&lt;p&gt;Finally, place the &lt;code&gt;frpc&lt;/code&gt; binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.&lt;/p&gt; 
&lt;p&gt;Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See &lt;a href="https://github.com/fatedier/frp/issues/3637"&gt;issue 3637&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Access your computer in a LAN network via SSH&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; on server A by setting the &lt;code&gt;bindPort&lt;/code&gt; for frp clients to connect to:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt; on server A:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; on server B and set the &lt;code&gt;serverAddr&lt;/code&gt; field to the public IP address of your frps server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;localPort&lt;/code&gt; (listened on the client) and &lt;code&gt;remotePort&lt;/code&gt; (exposed on the server) are used for traffic going in and out of the frp system, while the &lt;code&gt;serverPort&lt;/code&gt; is used for communication between frps and frpc.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on server B:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access server B from another machine through server A via SSH (assuming the username is &lt;code&gt;test&lt;/code&gt;), use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 test@x.x.x.x&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple SSH services sharing the same port&lt;/h3&gt; 
&lt;p&gt;This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;bindPort = 7000
tcpmuxHTTPConnectPort = 5002
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Deploy frpc on the internal machine A with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-a.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Deploy another frpc on the internal machine B with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-b.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;To access internal machine A using SSH ProxyCommand, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-a.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access internal machine B, the only difference is the domain name, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-b.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/h3&gt; 
&lt;p&gt;Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.&lt;/p&gt; 
&lt;p&gt;Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; and set the HTTP port for vhost to 8080:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
vhostHTTPPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to configure an https proxy, you need to set up the &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Specify the &lt;code&gt;localPort&lt;/code&gt; of your web service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["www.example.com"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;Map the A record of &lt;code&gt;www.example.com&lt;/code&gt; to either the public IP of the remote frps server or a CNAME record pointing to your original domain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit your local web service using url &lt;code&gt;http://www.example.com:8080&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Forward DNS query requests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server &lt;code&gt;8.8.8.8:53&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "dns"
type = "udp"
localIP = "8.8.8.8"
localPort = 53
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start frpc:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Test DNS resolution using the &lt;code&gt;dig&lt;/code&gt; command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;dig @x.x.x.x -p 6000 www.google.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Forward Unix Domain Socket&lt;/h3&gt; 
&lt;p&gt;Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "unix_domain_socket"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "unix_domain_socket"
unixPath = "/var/run/docker.sock"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Test the configuration by getting the docker version using &lt;code&gt;curl&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;curl http://x.x.x.x:6000/version&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Expose a simple HTTP file server&lt;/h3&gt; 
&lt;p&gt;Expose a simple HTTP file server to access files stored in the LAN from the public Internet.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as described above, then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_static_file"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "static_file"
localPath = "/tmp/files"
stripPrefix = "static"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;http://x.x.x.x:6000/static/&lt;/code&gt; from your browser and specify correct username and password to view files in &lt;code&gt;/tmp/files&lt;/code&gt; on the &lt;code&gt;frpc&lt;/code&gt; machine.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable HTTPS for a local HTTP(S) service&lt;/h3&gt; 
&lt;p&gt;You may substitute &lt;code&gt;https2https&lt;/code&gt; for the plugin, and point the &lt;code&gt;localAddr&lt;/code&gt; to a HTTPS endpoint.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_https2http"
type = "https"
customDomains = ["test.example.com"]

[proxies.plugin]
type = "https2http"
localAddr = "127.0.0.1:80"
crtPath = "./server.crt"
keyPath = "./server.key"
hostHeaderRewrite = "127.0.0.1"
requestHeaders.set.x-from-where = "frp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;https://test.example.com&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Expose your service privately&lt;/h3&gt; 
&lt;p&gt;To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; same as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B with the following config. This example is for exposing the SSH service (port 22), and note the &lt;code&gt;secretKey&lt;/code&gt; field for the preshared key, and that the &lt;code&gt;remotePort&lt;/code&gt; field is removed here:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "secret_ssh"
type = "stcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the following config to access the SSH service with a security key (&lt;code&gt;secretKey&lt;/code&gt; field):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[visitors]]
name = "secret_ssh_visitor"
type = "stcp"
serverName = "secret_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;P2P Mode&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;xtcp&lt;/strong&gt; is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.&lt;/p&gt; 
&lt;p&gt;Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn't work.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B, and expose the SSH port. Note that the &lt;code&gt;remotePort&lt;/code&gt; field is removed:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[proxies]]
name = "p2p_ssh"
type = "xtcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the configuration to connect to SSH using P2P mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[visitors]]
name = "p2p_ssh_visitor"
type = "xtcp"
serverName = "p2p_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
# when automatic tunnel persistence is required, set it to true
keepTunnelOpen = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.&lt;/p&gt; 
&lt;p&gt;Read the full example configuration files to find out even more features not described here.&lt;/p&gt; 
&lt;p&gt;Examples use TOML format, but you can still use YAML or JSON.&lt;/p&gt; 
&lt;p&gt;These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frps_full_example.toml"&gt;Full configuration file for frps (Server)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frpc_full_example.toml"&gt;Full configuration file for frpc (Client)&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Environment Variables&lt;/h3&gt; 
&lt;p&gt;Environment variables can be referenced in the configuration file, using Go's standard format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "{{ .Envs.FRP_SERVER_ADDR }}"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = {{ .Envs.FRP_SSH_REMOTE_PORT }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the config above, variables can be passed into &lt;code&gt;frpc&lt;/code&gt; program like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;frpc&lt;/code&gt; will render configuration file template using OS environment variables. Remember to prefix your reference with &lt;code&gt;.Envs&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Split Configures Into Different Files&lt;/h3&gt; 
&lt;p&gt;You can split multiple proxy configs into different files and include them in the main file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
includes = ["./confd/*.toml"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ./confd/test.toml

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server Dashboard&lt;/h3&gt; 
&lt;p&gt;Check frp's status and proxies' statistics information by Dashboard.&lt;/p&gt; 
&lt;p&gt;Configure a port for dashboard to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# The default value is 127.0.0.1. Change it to 0.0.0.0 when you want to access it from a public network.
webServer.addr = "0.0.0.0"
webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://[serverAddr]:7500&lt;/code&gt; to see the dashboard, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can use HTTPS port by using your domains wildcard or normal SSL certificate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
webServer.tls.certFile = "server.crt"
webServer.tls.keyFile = "server.key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;https://[serverAddr]:7500&lt;/code&gt; to see the dashboard in secure HTTPS connection, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/dashboard.png" alt="dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Client Admin UI&lt;/h3&gt; 
&lt;p&gt;The Client Admin UI helps you check and manage frpc's configuration.&lt;/p&gt; 
&lt;p&gt;Configure an address for admin UI to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.addr = "127.0.0.1"
webServer.port = 7400
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://127.0.0.1:7400&lt;/code&gt; to see admin UI, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Monitor&lt;/h3&gt; 
&lt;p&gt;When web server is enabled, frps will save monitor data in cache for 7 days. It will be cleared after process restart.&lt;/p&gt; 
&lt;p&gt;Prometheus is also supported.&lt;/p&gt; 
&lt;h4&gt;Prometheus&lt;/h4&gt; 
&lt;p&gt;Enable dashboard first, then configure &lt;code&gt;enablePrometheus = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;http://{dashboard_addr}/metrics&lt;/code&gt; will provide prometheus monitor data.&lt;/p&gt; 
&lt;h3&gt;Authenticating the Client&lt;/h3&gt; 
&lt;p&gt;There are 2 authentication methods to authenticate frpc with frps.&lt;/p&gt; 
&lt;p&gt;You can decide which one to use by configuring &lt;code&gt;auth.method&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt;, the default one is token.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["HeartBeats"]&lt;/code&gt; will use the configured authentication method to add and validate authentication on every heartbeat between frpc and frps.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["NewWorkConns"]&lt;/code&gt; will do the same for every new work connection between frpc and frps.&lt;/p&gt; 
&lt;h4&gt;Token Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "token"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - token based authentication will be used.&lt;/p&gt; 
&lt;p&gt;Make sure to specify the same &lt;code&gt;auth.token&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt; for frpc to pass frps validation&lt;/p&gt; 
&lt;h5&gt;Token Source&lt;/h5&gt; 
&lt;p&gt;frp supports reading authentication tokens from external sources using the &lt;code&gt;tokenSource&lt;/code&gt; configuration. Currently, file-based token source is supported.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;File-based token source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "token"
auth.tokenSource.type = "file"
auth.tokenSource.file.path = "/path/to/token/file"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The token will be read from the specified file at startup. This is useful for scenarios where tokens are managed by external systems or need to be kept separate from configuration files for security reasons.&lt;/p&gt; 
&lt;h4&gt;OIDC Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "oidc"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - OIDC based authentication will be used.&lt;/p&gt; 
&lt;p&gt;OIDC stands for OpenID Connect, and the flow used is called &lt;a href="https://tools.ietf.org/html/rfc6749#section-4.4"&gt;Client Credentials Grant&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this authentication type - configure &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
auth.method = "oidc"
auth.oidc.issuer = "https://example-oidc-issuer.com/"
auth.oidc.audience = "https://oidc-audience.com/.default"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "oidc"
auth.oidc.clientID = "98692467-37de-409a-9fac-bb2585826f18" # Replace with OIDC client ID
auth.oidc.clientSecret = "oidc_secret"
auth.oidc.audience = "https://oidc-audience.com/.default"
auth.oidc.tokenEndpointURL = "https://example-oidc-endpoint.com/oauth2/v2.0/token"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encryption and Compression&lt;/h3&gt; 
&lt;p&gt;The features are off by default. You can turn on encryption and/or compression:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.useEncryption = true
transport.useCompression = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;TLS&lt;/h4&gt; 
&lt;p&gt;Since v0.50.0, the default value of &lt;code&gt;transport.tls.enable&lt;/code&gt; and &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; has been changed to true, and tls is enabled by default.&lt;/p&gt; 
&lt;p&gt;For port multiplexing, frp sends a first byte &lt;code&gt;0x17&lt;/code&gt; to dial a TLS connection. This only takes effect when you set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;To &lt;strong&gt;enforce&lt;/strong&gt; &lt;code&gt;frps&lt;/code&gt; to only accept TLS connections - configure &lt;code&gt;transport.tls.force = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;. &lt;strong&gt;This is optional.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frpc&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.enable = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frps&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.force = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need &lt;strong&gt;a root CA cert&lt;/strong&gt; and &lt;strong&gt;at least one SSL/TLS certificate&lt;/strong&gt;. It &lt;strong&gt;can&lt;/strong&gt; be self-signed or regular (such as Let's Encrypt or another SSL/TLS certificate provider).&lt;/p&gt; 
&lt;p&gt;If you using &lt;code&gt;frp&lt;/code&gt; via IP address and not hostname, make sure to set the appropriate IP address in the Subject Alternative Name (SAN) area when generating SSL/TLS Certificates.&lt;/p&gt; 
&lt;p&gt;Given an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare openssl config file. It exists at &lt;code&gt;/etc/pki/tls/openssl.cnf&lt;/code&gt; in Linux System and &lt;code&gt;/System/Library/OpenSSL/openssl.cnf&lt;/code&gt; in MacOS, and you can copy it to current path, like &lt;code&gt;cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf&lt;/code&gt;. If not, you can build it by yourself, like:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;cat &amp;gt; my-openssl.cnf &amp;lt;&amp;lt; EOF
[ ca ]
default_ca = CA_default
[ CA_default ]
x509_extensions = usr_cert
[ req ]
default_bits        = 2048
default_md          = sha256
default_keyfile     = privkey.pem
distinguished_name  = req_distinguished_name
attributes          = req_attributes
x509_extensions     = v3_ca
string_mask         = utf8only
[ req_distinguished_name ]
[ req_attributes ]
[ usr_cert ]
basicConstraints       = CA:FALSE
nsComment              = "OpenSSL Generated Certificate"
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
[ v3_ca ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always,issuer
basicConstraints       = CA:true
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build ca certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=example.ca.com" -days 5000 -out ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frps certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048

openssl req -new -sha256 -key server.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com")) \
    -out server.csr

openssl x509 -req -days 365 -sha256 \
	-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com") \
	-out server.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frpc certificatesÔºö&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out client.key 2048
openssl req -new -sha256 -key client.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:client.com,DNS:example.client.com")) \
    -out client.csr

openssl x509 -req -days 365 -sha256 \
    -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:client.com,DNS:example.client.com") \
	-out client.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hot-Reloading frpc configuration&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
webServer.addr = "127.0.0.1"
webServer.port = 7400
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run command &lt;code&gt;frpc reload -c ./frpc.toml&lt;/code&gt; and wait for about 10 seconds to let &lt;code&gt;frpc&lt;/code&gt; create or update or remove proxies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that global client parameters won't be modified except 'start'.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can run command &lt;code&gt;frpc verify -c ./frpc.toml&lt;/code&gt; before reloading to check if there are config errors.&lt;/p&gt; 
&lt;h3&gt;Get proxy status from client&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;frpc status -c ./frpc.toml&lt;/code&gt; to get status of all proxies. The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API.&lt;/p&gt; 
&lt;h3&gt;Only allowing certain ports on the server&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;allowPorts&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; is used to avoid abuse of ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
allowPorts = [
  { start = 2000, end = 3000 },
  { single = 3001 },
  { single = 3003 },
  { start = 4000, end = 50000 }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port Reuse&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt; in frps can use same port with &lt;code&gt;bindPort&lt;/code&gt;. frps will detect the connection's protocol and handle it correspondingly.&lt;/p&gt; 
&lt;p&gt;What you need to pay attention to is that if you want to configure &lt;code&gt;vhostHTTPSPort&lt;/code&gt; and &lt;code&gt;bindPort&lt;/code&gt; to the same port, you need to first set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;We would like to try to allow multiple proxies bind a same remote port with different protocols in the future.&lt;/p&gt; 
&lt;h3&gt;Bandwidth Limit&lt;/h3&gt; 
&lt;h4&gt;For Each Proxy&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.bandwidthLimit = "1MB"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimit&lt;/code&gt; in each proxy's configure to enable this feature. Supported units are &lt;code&gt;MB&lt;/code&gt; and &lt;code&gt;KB&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimitMode&lt;/code&gt; to &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;server&lt;/code&gt; to limit bandwidth on the client or server side. Default is &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Stream Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports tcp stream multiplexing since v0.10.0 like HTTP2 Multiplexing, in which case all logic connections to the same frpc are multiplexed into the same TCP connection.&lt;/p&gt; 
&lt;p&gt;You can disable this feature by modify &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml and frpc.toml, must be same
transport.tcpMux = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support KCP Protocol&lt;/h3&gt; 
&lt;p&gt;KCP is a fast and reliable protocol that can achieve the transmission effect of a reduction of the average latency by 30% to 40% and reduction of the maximum delay by a factor of three, at the cost of 10% to 20% more bandwidth wasted than TCP.&lt;/p&gt; 
&lt;p&gt;KCP mode uses UDP as the underlying transport. Using KCP in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable KCP in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for KCP.
kcpBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;kcpBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use KCP to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'kcpBindPort' in frps.toml
serverPort = 7000
transport.protocol = "kcp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support QUIC Protocol&lt;/h3&gt; 
&lt;p&gt;QUIC is a new multiplexed transport built on top of UDP.&lt;/p&gt; 
&lt;p&gt;Using QUIC in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable QUIC in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for QUIC.
quicBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;quicBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use QUIC to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'quicBindPort' in frps.toml
serverPort = 7000
transport.protocol = "quic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connection Pooling&lt;/h3&gt; 
&lt;p&gt;By default, frps creates a new frpc connection to the backend service upon a user request. With connection pooling, frps keeps a certain number of pre-established connections, reducing the time needed to establish a connection.&lt;/p&gt; 
&lt;p&gt;This feature is suitable for a large number of short connections.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure the limit of pool count each proxy can use in &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
transport.maxPoolCount = 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Enable and specify the number of connection pool:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
transport.poolCount = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load balancing&lt;/h3&gt; 
&lt;p&gt;Load balancing is supported by &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This feature is only available for types &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;tcpmux&lt;/code&gt; now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 8080
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"

[[proxies]]
name = "test2"
type = "tcp"
localPort = 8081
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;loadBalancer.groupKey&lt;/code&gt; is used for authentication.&lt;/p&gt; 
&lt;p&gt;Connections to port 80 will be dispatched to proxies in the same group randomly.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;remotePort&lt;/code&gt; in the same group should be the same.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;customDomains&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;, &lt;code&gt;locations&lt;/code&gt; should be the same.&lt;/p&gt; 
&lt;h3&gt;Service Health Check&lt;/h3&gt; 
&lt;p&gt;Health check feature can help you achieve high availability with load balancing.&lt;/p&gt; 
&lt;p&gt;Add &lt;code&gt;healthCheck.type = "tcp"&lt;/code&gt; or &lt;code&gt;healthCheck.type = "http"&lt;/code&gt; to enable health check.&lt;/p&gt; 
&lt;p&gt;With health check type &lt;strong&gt;tcp&lt;/strong&gt;, the service port will be pinged (TCPing):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 22
remotePort = 6000
# Enable TCP health check
healthCheck.type = "tcp"
# TCPing timeout seconds
healthCheck.timeoutSeconds = 3
# If health check failed 3 times in a row, the proxy will be removed from frps
healthCheck.maxFailed = 3
# A health check every 10 seconds
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With health check type &lt;strong&gt;http&lt;/strong&gt;, an HTTP request will be sent to the service and an HTTP 2xx OK response is expected:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localIP = "127.0.0.1"
localPort = 80
customDomains = ["test.example.com"]
# Enable HTTP health check
healthCheck.type = "http"
# frpc will send a GET request to '/status'
# and expect an HTTP 2xx OK response
healthCheck.path = "/status"
healthCheck.timeoutSeconds = 3
healthCheck.maxFailed = 3
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rewriting the HTTP Host Header&lt;/h3&gt; 
&lt;p&gt;By default frp does not modify the tunneled HTTP requests at all as it's a byte-for-byte copy.&lt;/p&gt; 
&lt;p&gt;However, speaking of web servers and HTTP requests, your web server might rely on the &lt;code&gt;Host&lt;/code&gt; HTTP header to determine the website to be accessed. frp can rewrite the &lt;code&gt;Host&lt;/code&gt; header when forwarding the HTTP requests, with the &lt;code&gt;hostHeaderRewrite&lt;/code&gt; field:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The HTTP request will have the &lt;code&gt;Host&lt;/code&gt; header rewritten to &lt;code&gt;Host: dev.example.com&lt;/code&gt; when it reaches the actual web server, although the request from the browser probably has &lt;code&gt;Host: test.example.com&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Setting other HTTP Headers&lt;/h3&gt; 
&lt;p&gt;Similar to &lt;code&gt;Host&lt;/code&gt;, You can override other HTTP request and response headers with proxy type &lt;code&gt;http&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
requestHeaders.set.x-from-where = "frp"
responseHeaders.set.foo = "bar"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, it will set header &lt;code&gt;x-from-where: frp&lt;/code&gt; in the HTTP request and &lt;code&gt;foo: bar&lt;/code&gt; in the HTTP response.&lt;/p&gt; 
&lt;h3&gt;Get Real IP&lt;/h3&gt; 
&lt;h4&gt;HTTP X-Forwarded-For&lt;/h4&gt; 
&lt;p&gt;This feature is for &lt;code&gt;http&lt;/code&gt; proxies or proxies with the &lt;code&gt;https2http&lt;/code&gt; and &lt;code&gt;https2https&lt;/code&gt; plugins enabled.&lt;/p&gt; 
&lt;p&gt;You can get user's real IP from HTTP request headers &lt;code&gt;X-Forwarded-For&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Proxy Protocol&lt;/h4&gt; 
&lt;p&gt;frp supports Proxy Protocol to send user's real IP to local services.&lt;/p&gt; 
&lt;p&gt;Here is an example for https service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "https"
localPort = 443
customDomains = ["test.example.com"]

# now v1 and v2 are supported
transport.proxyProtocolVersion = "v2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable Proxy Protocol support in nginx to expose user's real IP in HTTP header &lt;code&gt;X-Real-IP&lt;/code&gt;, and then read &lt;code&gt;X-Real-IP&lt;/code&gt; header in your web service for the real IP.&lt;/p&gt; 
&lt;h3&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/h3&gt; 
&lt;p&gt;Anyone who can guess your tunnel URL can access your local web server unless you protect it with a password.&lt;/p&gt; 
&lt;p&gt;This enforces HTTP Basic Auth on all requests with the username and password specified in frpc's configure file.&lt;/p&gt; 
&lt;p&gt;It can only be enabled when proxy type is http.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://test.example.com&lt;/code&gt; in the browser and now you are prompted to enter the username and password.&lt;/p&gt; 
&lt;h3&gt;Custom Subdomain Names&lt;/h3&gt; 
&lt;p&gt;It is convenient to use &lt;code&gt;subdomain&lt;/code&gt; configure for http and https types when many people share one frps server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
subDomainHost = "frps.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Resolve &lt;code&gt;*.frps.com&lt;/code&gt; to the frps server's IP. This is usually called a Wildcard DNS record.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
subdomain = "test"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can visit your web service on &lt;code&gt;test.frps.com&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that if &lt;code&gt;subdomainHost&lt;/code&gt; is not empty, &lt;code&gt;customDomains&lt;/code&gt; should not be the subdomain of &lt;code&gt;subdomainHost&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;URL Routing&lt;/h3&gt; 
&lt;p&gt;frp supports forwarding HTTP requests to different backend web services by url routing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;locations&lt;/code&gt; specifies the prefix of URL used for routing. frps first searches for the most specific prefix location given by literal strings regardless of the listed order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web01"
type = "http"
localPort = 80
customDomains = ["web.example.com"]
locations = ["/"]

[[proxies]]
name = "web02"
type = "http"
localPort = 81
customDomains = ["web.example.com"]
locations = ["/news", "/about"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;HTTP requests with URL prefix &lt;code&gt;/news&lt;/code&gt; or &lt;code&gt;/about&lt;/code&gt; will be forwarded to &lt;strong&gt;web02&lt;/strong&gt; and other requests to &lt;strong&gt;web01&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Port Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to &lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The only supported TCP port multiplexing method available at the moment is &lt;code&gt;httpconnect&lt;/code&gt; - HTTP CONNECT tunnel.&lt;/p&gt; 
&lt;p&gt;When setting &lt;code&gt;tcpmuxHTTPConnectPort&lt;/code&gt; to anything other than 0 in frps, frps will listen on this port for HTTP CONNECT requests.&lt;/p&gt; 
&lt;p&gt;The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring &lt;code&gt;customDomains&lt;/code&gt; and / or &lt;code&gt;subdomain&lt;/code&gt; under &lt;code&gt;tcpmux&lt;/code&gt; proxies, when &lt;code&gt;multiplexer = "httpconnect"&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
tcpmuxHTTPConnectPort = 1337
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "proxy1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test1"]
localPort = 80

[[proxies]]
name = "proxy2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test2"]
localPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CONNECT test1 HTTP/1.1\r\n\r\n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the connection will be routed to &lt;code&gt;proxy1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting to frps via PROXY&lt;/h3&gt; 
&lt;p&gt;frpc can connect to frps through proxy if you set OS environment variable &lt;code&gt;HTTP_PROXY&lt;/code&gt;, or if &lt;code&gt;transport.proxyURL&lt;/code&gt; is set in frpc.toml file.&lt;/p&gt; 
&lt;p&gt;It only works when protocol is tcp.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
transport.proxyURL = "http://user:pwd@192.168.1.128:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port range mapping&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Added in v0.56.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;We can use the range syntax of Go template combined with the built-in &lt;code&gt;parseNumberRangePair&lt;/code&gt; function to achieve port range mapping.&lt;/p&gt; 
&lt;p&gt;The following example, when run, will create 8 proxies named &lt;code&gt;test-6000, test-6001 ... test-6007&lt;/code&gt;, each mapping the remote port to the local port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{{- range $_, $v := parseNumberRangePair "6000-6006,6007" "6000-6006,6007" }}
[[proxies]]
name = "tcp-{{ $v.First }}"
type = "tcp"
localPort = {{ $v.First }}
remotePort = {{ $v.Second }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client Plugins&lt;/h3&gt; 
&lt;p&gt;frpc only forwards requests to local TCP or UDP ports by default.&lt;/p&gt; 
&lt;p&gt;Plugins are used for providing rich features. There are built-in plugins such as &lt;code&gt;unix_domain_socket&lt;/code&gt;, &lt;code&gt;http_proxy&lt;/code&gt;, &lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;static_file&lt;/code&gt;, &lt;code&gt;http2https&lt;/code&gt;, &lt;code&gt;https2http&lt;/code&gt;, &lt;code&gt;https2https&lt;/code&gt; and you can see &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;example usage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Using plugin &lt;strong&gt;http_proxy&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "http_proxy"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "http_proxy"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;httpUser&lt;/code&gt; and &lt;code&gt;httpPassword&lt;/code&gt; are configuration parameters used in &lt;code&gt;http_proxy&lt;/code&gt; plugin.&lt;/p&gt; 
&lt;h3&gt;Server Manage Plugins&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/server_plugin.md"&gt;document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find more plugins in &lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SSH Tunnel Gateway&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;added in v0.53.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;frp supports listening to an SSH port on the frps side and achieves TCP protocol proxying through the SSH -R protocol, without relying on frpc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
sshTunnelGateway.bindPort = 2200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running &lt;code&gt;./frps -c frps.toml&lt;/code&gt;, a private key file named &lt;code&gt;.autogen_ssh_key&lt;/code&gt; will be automatically created in the current working directory. This generated private key file will be used by the SSH server in frps.&lt;/p&gt; 
&lt;p&gt;Executing the command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -R :80:127.0.0.1:8080 v0@{frp address} -p 2200 tcp --proxy_name "test-tcp" --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;sets up a proxy on frps that forwards the local 8080 service to the port 9090.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frp (via SSH) (Ctrl+C to quit)

User:
ProxyName: test-tcp
Type: tcp
RemoteAddress: :9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is equivalent to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frpc tcp --proxy_name "test-tcp" --local_ip 127.0.0.1 --local_port 8080 --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to this &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/ssh_tunnel_gateway.md"&gt;document&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Virtual Network (VirtualNet)&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Alpha feature added in v0.62.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The VirtualNet feature enables frp to create and manage virtual network connections between clients and visitors through a TUN interface. This allows for IP-level routing between machines, extending frp beyond simple port forwarding to support full network connectivity.&lt;/p&gt; 
&lt;p&gt;For detailed information about configuration and usage, please refer to the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/virtual_net.md"&gt;VirtualNet documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Gates&lt;/h2&gt; 
&lt;p&gt;frp supports feature gates to enable or disable experimental features. This allows users to try out new features before they're considered stable.&lt;/p&gt; 
&lt;h3&gt;Available Feature Gates&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VirtualNet&lt;/td&gt; 
   &lt;td&gt;ALPHA&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Virtual network capabilities for frp&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabling Feature Gates&lt;/h3&gt; 
&lt;p&gt;To enable an experimental feature, add the feature gate to your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;featureGates = { VirtualNet = true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Lifecycle&lt;/h3&gt; 
&lt;p&gt;Features typically go through three stages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ALPHA&lt;/strong&gt;: Disabled by default, may be unstable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BETA&lt;/strong&gt;: May be enabled by default, more stable but still evolving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GA (Generally Available)&lt;/strong&gt;: Enabled by default, ready for production use&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt; - A repository for frp plugins that contains a variety of plugins implemented based on the frp extension mechanism, meeting the customization needs of different scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/tiny-frpc"&gt;gofrp/tiny-frpc&lt;/a&gt; - A lightweight version of the frp client (around 3.5MB at minimum) implemented using the ssh protocol, supporting some of the most commonly used features, suitable for devices with limited resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in getting involved? We would like to help you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take a look at our &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues list&lt;/a&gt; and consider sending a Pull Request to &lt;strong&gt;dev branch&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to add a new feature, please create an issue first to describe the new feature, as well as the implementation approach. Once a proposal is accepted, create an implementation of the new features and submit it as a pull request.&lt;/li&gt; 
 &lt;li&gt;Sorry for my poor English. Improvements for this document are welcome, even some typo fixes.&lt;/li&gt; 
 &lt;li&gt;If you have great ideas, send an email to &lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note: We prefer you to give your advise in &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues&lt;/a&gt;, so others with a same question can search it quickly and we don't need to answer them repeatedly.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Donation&lt;/h2&gt; 
&lt;p&gt;If frp helps you a lot, you can support us by:&lt;/p&gt; 
&lt;h3&gt;GitHub Sponsors&lt;/h3&gt; 
&lt;p&gt;Support us by &lt;a href="https://github.com/sponsors/fatedier"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can have your company's logo placed on README file of this project.&lt;/p&gt; 
&lt;h3&gt;PayPal&lt;/h3&gt; 
&lt;p&gt;Donate money by &lt;a href="https://www.paypal.me/fatedier"&gt;PayPal&lt;/a&gt; to my account &lt;strong&gt;&lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usememos/memos</title>
      <link>https://github.com/usememos/memos</link>
      <description>&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Memos&lt;/h1&gt; 
&lt;img align="right" height="96px" src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png" alt="Memos" /&gt; 
&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.usememos.com"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%8F%A0-usememos.com-blue?style=flat-square" alt="Home" /&gt;&lt;/a&gt; &lt;a href="https://demo.usememos.com/"&gt;&lt;img src="https://img.shields.io/badge/%E2%9C%A8-Try%20Demo-orange?style=flat-square" alt="Live Demo" /&gt;&lt;/a&gt; &lt;a href="https://www.usememos.com/docs"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%9A-Documentation-green?style=flat-square" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tfPJa4UmAv"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%92%AC-Discord-5865f2?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/neosmemo/memos"&gt;&lt;img src="https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&amp;amp;logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png" alt="Memos Demo Screenshot" height="512" /&gt; 
&lt;h3&gt;üíé Featured Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://go.warp.dev/memos"&gt;&lt;strong&gt;Warp&lt;/strong&gt; ‚Äî The AI-powered terminal built for speed and collaboration&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://go.warp.dev/memos" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png" alt="Warp - The AI-powered terminal built for speed and collaboration" width="512" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor"&gt;&lt;strong&gt;LambdaTest&lt;/strong&gt; - Cross-browser testing cloud&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor" target="_blank" rel="noopener"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" alt="LambdaTest - Cross-browser testing cloud" height="50" /&gt; &lt;/a&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Memos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Memos over cloud services?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Memos&lt;/th&gt; 
   &lt;th&gt;Cloud Services&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Self-hosted, zero telemetry&lt;/td&gt; 
   &lt;td&gt;‚ùå Your data on their servers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Free forever, MIT license&lt;/td&gt; 
   &lt;td&gt;‚ùå Subscription fees&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Instant load, no latency&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Depends on internet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ownership&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full control &amp;amp; export&lt;/td&gt; 
   &lt;td&gt;‚ùå Vendor lock-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full REST + gRPC APIs&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Limited or paid&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Open source, forkable&lt;/td&gt; 
   &lt;td&gt;‚ùå Closed ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîí Privacy-First Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Self-hosted on your infrastructure with zero telemetry&lt;/li&gt; 
   &lt;li&gt;Complete data ownership and export capabilities&lt;/li&gt; 
   &lt;li&gt;No tracking, no ads, no vendor lock-in&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Markdown Native&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full markdown support&lt;/li&gt; 
   &lt;li&gt;Plain text storage ‚Äî take your data anywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Blazing Fast&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built with Go backend and React frontend&lt;/li&gt; 
   &lt;li&gt;Optimized for performance at any scale&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Simple Deployment&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;One-line Docker installation&lt;/li&gt; 
   &lt;li&gt;Supports SQLite, MySQL, and PostgreSQL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Developer-Friendly&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full REST and gRPC APIs&lt;/li&gt; 
   &lt;li&gt;Easy integration with existing workflows&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé® Beautiful Interface&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Clean, minimal design and dark mode support&lt;/li&gt; 
   &lt;li&gt;Mobile-responsive layout&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Docker (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name memos \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:5230&lt;/code&gt; and start writing!&lt;/p&gt; 
&lt;h3&gt;Try the Live Demo&lt;/h3&gt; 
&lt;p&gt;Don't want to install yet? Try our &lt;a href="https://demo.usememos.com/"&gt;live demo&lt;/a&gt; first!&lt;/p&gt; 
&lt;h3&gt;Other Installation Methods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt; - Recommended for production deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-built Binaries&lt;/strong&gt; - Available for Linux, macOS, and Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt; - Helm charts and manifests available&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build from Source&lt;/strong&gt; - For development and customization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://www.usememos.com/docs/installation"&gt;installation guide&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! Whether you're fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ways to contribute:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/usememos/memos/issues/new?template=bug_report.md"&gt;Report bugs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/usememos/memos/issues/new?template=feature_request.md"&gt;Suggest features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://github.com/usememos/memos/pulls"&gt;Submit pull requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://github.com/usememos/memos/tree/main/docs"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåç &lt;a href="https://github.com/usememos/memos/tree/main/web/src/locales"&gt;Help with translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Love Memos? &lt;a href="https://github.com/sponsors/usememos"&gt;Sponsor us on GitHub&lt;/a&gt; to help keep the project growing!&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#usememos/memos&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=usememos/memos&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Memos is open-source software licensed under the &lt;a href="https://raw.githubusercontent.com/usememos/memos/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.usememos.com"&gt;Website&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://www.usememos.com/docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://demo.usememos.com/"&gt;Demo&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://discord.gg/tfPJa4UmAv"&gt;Discord&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://x.com/usememos"&gt;X/Twitter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Made with ‚ù§Ô∏è by the Memos community&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href="https://github.com/hashicorp/vault/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hashicorp/vault/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise"&gt;&lt;img src="https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000" alt="vault enterprise" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault's security and our users' trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/vault"&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href="https://groups.google.com/group/hashicorp-announce"&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href="https://discuss.hashicorp.com/c/vault"&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/vault/tutorials"&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href="https://developer.hashicorp.com/certifications/security-automation"&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation source: &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;https://github.com/hashicorp/web-unified-docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width="300" alt="Vault Logo" src="https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png" /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, &lt;a href="https://www.consul.io"&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're new to Vault and want to get started with security automation, please check out our &lt;a href="https://learn.hashicorp.com/collections/vault/getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/vault"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href="https://github.com/hashicorp/vault-examples"&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href="https://github.com/hashicorp/hello-vault-go"&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/collections/vault/certification"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href="https://pkg.go.dev/cmd/go#hdr-Environment_variables"&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for 'https://github.com'&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ git config --global --add url."git@github.com:".insteadOf "https://github.com/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/hashicorp/vault/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise"&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault", // or "hashicorp/vault-enterprise"
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault-enterprise",
    ImageTag:  "latest",
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn't become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector</link>
      <description>&lt;p&gt;OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.bestpractices.dev/projects/8404"&gt;&lt;img src="https://www.bestpractices.dev/projects/8404/badge" /&gt; &lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:opentelemetry"&gt; &lt;img alt="Fuzzing Status" src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/configuration/"&gt;Configuration&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector"&gt;Monitoring&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://pkg.go.dev/go.opentelemetry.io/collector"&gt;Package&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;img src="https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png" alt="OpenTelemetry Icon" width="45" height="" /&gt; OpenTelemetry Collector&lt;/h1&gt; 
&lt;p&gt;The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.&lt;/p&gt; 
&lt;p&gt;Objectives:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.&lt;/li&gt; 
 &lt;li&gt;Performant: Highly stable and performant under varying loads and configurations.&lt;/li&gt; 
 &lt;li&gt;Observable: An exemplar of an observable service.&lt;/li&gt; 
 &lt;li&gt;Extensible: Customizable without touching the core code.&lt;/li&gt; 
 &lt;li&gt;Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The OpenTelemetry Collector SIG is present at the &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;#otel-collector&lt;/a&gt; channel on the CNCF Slack and &lt;a href="https://github.com/open-telemetry/community#implementation-sigs"&gt;meets once a week&lt;/a&gt; via video calls. Everyone is invited to join those calls, which typically serves the following purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;meet the humans behind the project&lt;/li&gt; 
 &lt;li&gt;get an opinion about specific proposals&lt;/li&gt; 
 &lt;li&gt;look for a sponsor for a proposed component after trying already via GitHub and Slack&lt;/li&gt; 
 &lt;li&gt;get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We rotate our video calls between three time slots, in order to allow everyone to join at least once every three meetings. The rotation order is as follows:&lt;/p&gt; 
&lt;p&gt;Tuesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=1700"&gt;17:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Wednesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0900"&gt;09:00 PT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0500"&gt;05:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points. Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to identify who would be the other contributors interested on that topic and in which timezones they are.&lt;/p&gt; 
&lt;p&gt;Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous calls and don't want them to feel excluded.&lt;/p&gt; 
&lt;h2&gt;Supported OTLP version&lt;/h2&gt; 
&lt;p&gt;This code base is currently built against using OTLP protocol v1.5.0, considered Stable. &lt;a href="https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition"&gt;See the OpenTelemetry Protocol Stability definition here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/component-stability.md"&gt;Stability Levels and versioning&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as &lt;a href="https://go.dev/doc/devel/release#policy"&gt;defined by the Go team&lt;/a&gt;. Removing support for an unsupported Go version is not considered a breaking change.&lt;/p&gt; 
&lt;p&gt;Support for Go versions on the OpenTelemetry Collector is updated as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will add build and tests steps for the new Go minor version.&lt;/li&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will remove support for Go version &lt;code&gt;N-2&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.&lt;/p&gt; 
&lt;h2&gt;Verifying the images signatures&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To verify a signed artifact or blob, first &lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;install Cosign&lt;/a&gt;, then follow the instructions below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We are signing the images &lt;code&gt;otel/opentelemetry-collector&lt;/code&gt; and &lt;code&gt;otel/opentelemetry-collector-contrib&lt;/code&gt; using &lt;a href="https://github.com/sigstore/cosign"&gt;sigstore cosign&lt;/a&gt; tool and to verify the signatures you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&amp;lt;RELEASE_TAG&amp;gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;RELEASE_TAG&amp;gt;&lt;/code&gt;: is the release that you want to validate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;&lt;/code&gt;: is the image that you want to check&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=","Payload":{"body":"eyJhcGlWZXJzaW9uIjoiMC4wLjEiLCJraW5kIjoiaGFzaGVkcmVrb3JkIiwic3BlYyI6eyJkYXRhIjp7Imhhc2giOnsiYWxnb3JpdGhtIjoic2hhMjU2IiwidmFsdWUiOiIxMzVjY2RlN2YzZTNhYjU2NmFmYzJhYWU3MDljYmJlNmFhMDZlZWMzNDA2MWNkZjMyNmRhYzM2MmY0NWM4Yjg4In19LCJzaWduYXR1cmUiOnsiY29udGVudCI6Ik1FVUNJUURFbDV6N0diMWRVYkM5KzR4c1VvbDhMcWZNV2hiTzhkdEpwdExyMXhUNWZnSWdTdEwwN1I0ZDA5R2x0ZkV0azJVbmlJSlJhQVdrVDJNWDVtRXJNSlplc2pRPSIsInB1YmxpY0tleSI6eyJjb250ZW50IjoiTFMwdExTMUNSVWRKVGlCRFJWSlVTVVpKUTBGVVJTMHRMUzB0Q2sxSlNVaG9ha05EUW5jeVowRjNTVUpCWjBsVlNETkNjRFZTYlVSU1VpOXphMWg0YVdWUFlrcFhSbmRrUjNNNGQwTm5XVWxMYjFwSmVtb3dSVUYzVFhjS1RucEZWazFDVFVkQk1WVkZRMmhOVFdNeWJHNWpNMUoyWTIxVmRWcEhWakpOVWpSM1NFRlpSRlpSVVVSRmVGWjZZVmRrZW1SSE9YbGFVekZ3WW01U2JBcGpiVEZzV2tkc2FHUkhWWGRJYUdOT1RXcFJkMDVFUlhoTlJGRjRUMFJOTlZkb1kwNU5hbEYzVGtSRmVFMUVVWGxQUkUwMVYycEJRVTFHYTNkRmQxbElDa3R2V2tsNmFqQkRRVkZaU1V0dldrbDZhakJFUVZGalJGRm5RVVZyWlRsSE1ubHNjMjkzYVZZMmRFOVZSazlRVVhNd2NXY3hTSEV5WmpsVUx6UTJZbEFLU1ZSNE0ybFRkVXBhV0hGc1dEUldWV2Q1VlZndmNVazJhblZ2WlZSVEswaG5XVUoyYjBseVNERTFUeTltZEd0VmVtRlBRMEpwZDNkbloxbHZUVUUwUndwQk1WVmtSSGRGUWk5M1VVVkJkMGxJWjBSQlZFSm5UbFpJVTFWRlJFUkJTMEpuWjNKQ1owVkdRbEZqUkVGNlFXUkNaMDVXU0ZFMFJVWm5VVlZHTkRrMUNrdDFNRWhqTm5rek1rNUNTVTFFU21ReVpuWkxNMHBCZDBoM1dVUldVakJxUWtKbmQwWnZRVlV6T1ZCd2VqRlphMFZhWWpWeFRtcHdTMFpYYVhocE5Ga0tXa1E0ZDJkWldVZEJNVlZrUlZGRlFpOTNVamhOU0hGSFpVZG9NR1JJUW5wUGFUaDJXakpzTUdGSVZtbE1iVTUyWWxNNWRtTkhWblZNV0ZKc1lrZFdkQXBhV0ZKNVpWTTVkbU5IVm5Wa1IxWnpXbGN4YkdSSVNqVk1WMDUyWWtkNGJGa3pVblpqYVRGNVdsZDRiRmxZVG14amVUaDFXakpzTUdGSVZtbE1NMlIyQ21OdGRHMWlSemt6WTNrNWFWbFlUbXhNV0Vwc1lrZFdhR015VlhWbFYwWjBZa1ZDZVZwWFducE1NMUpvV2pOTmRtUnFRWFZQVkdkMVRVUkJOVUpuYjNJS1FtZEZSVUZaVHk5TlFVVkNRa04wYjJSSVVuZGplbTkyVEROU2RtRXlWblZNYlVacVpFZHNkbUp1VFhWYU1td3dZVWhXYVdSWVRteGpiVTUyWW01U2JBcGlibEYxV1RJNWRFMUNTVWREYVhOSFFWRlJRbWMzT0hkQlVVbEZRa2hDTVdNeVozZE9aMWxMUzNkWlFrSkJSMFIyZWtGQ1FYZFJiMDlYVlhsTlIwcHRDazVYVFhoT1JFcHNUbFJOZDA1NlFtcFpNa2swVFhwSmQxbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCWkVKbmIzSkNaMFZGUVZsUEwwMUJSVVVLUWtFNVUxcFhlR3haV0U1c1NVVk9kbUp1VW5saFYwbDNVRkZaUzB0M1dVSkNRVWRFZG5wQlFrSlJVWFppTTBKc1lta3hNRnBYZUd4aVYxWXdZMjVyZGdwaU0wSnNZbTVTYkdKSFZuUmFXRko1WlZNeGFtSXllSE5hVjA0d1lqTkpkR050Vm5OYVYwWjZXbGhOZDBoM1dVdExkMWxDUWtGSFJIWjZRVUpDWjFGU0NtTnRWbTFqZVRrd1dWZGtla3d6V1hkTWFtczBUR3BCZDA5M1dVdExkMWxDUWtGSFJIWjZRVUpEUVZGMFJFTjBiMlJJVW5kamVtOTJURE5TZG1FeVZuVUtURzFHYW1SSGJIWmliazExV2pKc01HRklWbWxrV0U1c1kyMU9kbUp1VW14aWJsRjFXVEk1ZEUxSlIwbENaMjl5UW1kRlJVRlpUeTlOUVVWS1FraHZUUXBsUjJnd1pFaENlazlwT0haYU1td3dZVWhXYVV4dFRuWmlVemwyWTBkV2RVeFlVbXhpUjFaMFdsaFNlV1ZUT1haalIxWjFaRWRXYzFwWE1XeGtTRW8xQ2t4WFRuWmlSM2hzV1ROU2RtTnBNWGxhVjNoc1dWaE9iR041T0hWYU1td3dZVWhXYVV3elpIWmpiWFJ0WWtjNU0yTjVPV2xaV0U1c1RGaEtiR0pIVm1nS1l6SlZkV1ZYUm5SaVJVSjVXbGRhZWt3elVtaGFNMDEyWkdwQmRVOVVaM1ZOUkVFMFFtZHZja0puUlVWQldVOHZUVUZGUzBKRGIwMUxSR3hzVFdwQ2FRcGFhbFpxVFZSUmVWcFVWWHBOUkdOM1dUSk9hVTlFVFhsTlIwVjVUVVJOZUU1WFdtMWFiVWt3VFZSUk1rOVhWWGRJVVZsTFMzZFpRa0pCUjBSMmVrRkNDa04zVVZCRVFURnVZVmhTYjJSWFNYUmhSemw2WkVkV2EwMUdTVWREYVhOSFFWRlJRbWMzT0hkQlVYZEZVa0Y0UTJGSVVqQmpTRTAyVEhrNWJtRllVbThLWkZkSmRWa3lPWFJNTWpsM1dsYzBkR1JIVm5OYVZ6RnNaRWhLTlV3eU9YZGFWelV3V2xkNGJHSlhWakJqYm10MFdUSTVjMkpIVm1wa1J6bDVURmhLYkFwaVIxWm9ZekpXZWsxRVowZERhWE5IUVZGUlFtYzNPSGRCVVRCRlMyZDNiMDlYVlhsTlIwcHRUbGROZUU1RVNteE9WRTEzVG5wQ2Fsa3lTVFJOZWtsM0NsbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCYUVKbmIzSkNaMFZGUVZsUEwwMUJSVTlDUWsxTlJWaEtiRnB1VFhaa1IwWnVZM2s1TWsxRE5EVUtUME0wZDAxQ2EwZERhWE5IUVZGUlFtYzNPSGRCVVRoRlEzZDNTazVFUVhkTmFsVjZUbXBqTWsxRVJVZERhWE5IUVZGUlFtYzNPSGRCVWtGRlNYZDNhQXBoU0ZJd1kwaE5Oa3g1T1c1aFdGSnZaRmRKZFZreU9YUk1NamwzV2xjMGRHUkhWbk5hVnpGc1pFaEtOVTFDWjBkRGFYTkhRVkZSUW1jM09IZEJVa1ZGQ2tObmQwbE9SR3MxVDFSbmQwMUVTWGRuV1hOSFEybHpSMEZSVVVKbk56aDNRVkpKUldaUmVEZGhTRkl3WTBoTk5reDVPVzVoV0ZKdlpGZEpkVmt5T1hRS1RESTVkMXBYTkhSa1IxWnpXbGN4YkdSSVNqVk1NamwzV2xjMU1GcFhlR3hpVjFZd1kyNXJkRmt5T1hOaVIxWnFaRWM1ZVV4WVNteGlSMVpvWXpKV2VncE1lVFZ1WVZoU2IyUlhTWFprTWpsNVlUSmFjMkl6WkhwTU0wcHNZa2RXYUdNeVZYUlpNamwxWkVoS2NGbHBOVFZaVnpGelVVaEtiRnB1VFhaa1IwWnVDbU41T1RKTlF6UTFUME0wZDAxRVowZERhWE5IUVZGUlFtYzNPSGRCVWsxRlMyZDNiMDlYVlhsTlIwcHRUbGROZUU1RVNteE9WRTEzVG5wQ2Fsa3lTVFFLVFhwSmQxbFVTWGROZWtVeFdtMWFiVmxxVVhoT1JGazFXbFJCVlVKbmIzSkNaMFZGUVZsUEwwMUJSVlZDUVZsTlFraENNV015WjNka1VWbExTM2RaUWdwQ1FVZEVkbnBCUWtaUlVtNUVSMVp2WkVoU2QyTjZiM1pNTW1Sd1pFZG9NVmxwTldwaU1qQjJZak5DYkdKcE1UQmFWM2hzWWxkV01HTnVhM1ppTTBKc0NtSnVVbXhpUjFaMFdsaFNlV1ZUTVdwaU1uaHpXbGRPTUdJelNYUmpiVlp6V2xkR2VscFlUWFpaVjA0d1lWYzVkV041T1hsa1Z6VjZUSHBuTWs1RVJYZ0tUbnBGTVU1cVkzWlpXRkl3V2xjeGQyUklUWFpOYWtGWFFtZHZja0puUlVWQldVOHZUVUZGVjBKQlowMUNia0l4V1cxNGNGbDZRMEpwWjFsTFMzZFpRZ3BDUVVoWFpWRkpSVUZuVWpoQ1NHOUJaVUZDTWtGT01EbE5SM0pIZUhoRmVWbDRhMlZJU214dVRuZExhVk5zTmpRemFubDBMelJsUzJOdlFYWkxaVFpQQ2tGQlFVSnFjM1JvUlVOUlFVRkJVVVJCUldOM1VsRkpaMWg2Y2xaME0xQjRkU3ROWVZKRkswUkdORzlGUldNMGVucHphSGR1VDJ4bGMwZGlla2xwYnpNS0wxWmpRMGxSUkZNelJ6QmlNemRhYUhRNGFITjJUSEozYkc1UFFXYzJWRXh1U1ZSS09HTjNkMVEzTW5sMVRVdFlUbFJCUzBKblozRm9hMnBQVUZGUlJBcEJkMDV1UVVSQ2EwRnFRWGxFUkZSYVFqQlRPVXBGYkZsSGJuTnZWVmhLYm04MU5Fc3ZUVUZUTlN0RFFVMU9lbWRqUWpWQ2JrRk5OMWhNUjBoV01HRnhDbVpaY21weFkyOXFia3RaUTAxSFRWRnFjalpUVGt0Q2NVaEtZVGwxTDBSTlQySlpNa0pKTVV0ME4yTnhOemhFT0VOcVMzQmFVblJoYnpadFVVMUVZMk1LUms5M2VYWnhWalJPVld0dlpsRTlQUW90TFMwdExVVk9SQ0JEUlZKVVNVWkpRMEZVUlMwdExTMHRDZz09In19fX0=","integratedTime":1712809120,"logIndex":84797936,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}},{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=","Payload":{"body":"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","integratedTime":1712809122,"logIndex":84797940,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We started signing the images with release &lt;code&gt;v0.95.0&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Here is a list of community roles with current and previous members:&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmathieu"&gt;Damien Mathieu&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jade-guiton-dd"&gt;Jade Guiton&lt;/a&gt;, Datadog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmacd"&gt;Joshua MacDonald&lt;/a&gt;, Microsoft&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, Datadog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating the role of the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/release.md#release-manager"&gt;release manager&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sincejune"&gt;Chao Weng&lt;/a&gt;, AppDynamics&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/james-bebbington"&gt;James Bebbington&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jrcamp"&gt;Jay Camp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paix√£o Kr√∂hling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nilebox"&gt;Nail Islamov&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/owais"&gt;Owais Lone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rghetia"&gt;Rahul Patel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sjkaris"&gt;Steven Karis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrewhsu"&gt;Andrew Hsu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thanks to all of our contributors!&lt;/h3&gt; 
&lt;a href="https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors"&gt; &lt;img alt="Repo contributors" src="https://contrib.rocks/image?repo=open-telemetry/opentelemetry-collector" /&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>