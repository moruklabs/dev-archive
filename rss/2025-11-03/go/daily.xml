<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sun, 02 Nov 2025 01:33:19 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>hashicorp/terraform-provider-aws</title>
      <link>https://github.com/hashicorp/terraform-provider-aws</link>
      <description>&lt;p&gt;The AWS Provider enables Terraform to manage AWS resources.&lt;/p&gt;&lt;hr&gt;&lt;a href="https://terraform.io"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset=".github/terraform_logo_dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset=".github/terraform_logo_light.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/hashicorp/terraform-provider-aws/main/.github/terraform_logo_light.svg?sanitize=true" alt="Terraform logo" title="Terraform" align="right" height="50" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Terraform AWS Provider&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discuss.hashicorp.com/c/terraform-providers/tf-aws/"&gt;&lt;img src="https://img.shields.io/badge/discuss-terraform--aws-623CE4.svg?style=flat" alt="Forums" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs"&gt;AWS Provider&lt;/a&gt; enables &lt;a href="https://terraform.io"&gt;Terraform&lt;/a&gt; to manage &lt;a href="https://aws.amazon.com"&gt;AWS&lt;/a&gt; resources.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hashicorp.github.io/terraform-provider-aws/"&gt;Contributing guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hashicorp/terraform-provider-aws/main/ROADMAP.md"&gt;Quarterly development roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hashicorp.github.io/terraform-provider-aws/faq/"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.hashicorp.com/collections/terraform/aws-get-started"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.hashicorp.com/c/terraform-providers/tf-aws/"&gt;discuss.hashicorp.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Please note:&lt;/strong&gt; We take Terraform's security and our users' trust very seriously. If you believe you have found a security issue in the Terraform AWS Provider, please responsibly disclose it by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performance‚Äîup to 40 times faster‚Äîthanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;üìö Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;Espa√±ol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;Portugu√™s&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîå Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üè¢ Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.1.3-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/pipeline.jpg" alt="weknora-pipeline.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, suitable for both developers and business users&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start all services (Ollama + backend containers)
./scripts/start_all.sh
# Or
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (backup)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start ollama services (Optional)
ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;

# Start the service
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On first access, it will automatically redirect to the initialization configuration page. After configuration is complete, it will automatically redirect to the knowledge base page. Please follow the page instructions to complete model configuration.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/config.png" alt="Configuration Page" /&gt;&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Upload&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledges.png" alt="Knowledge Upload Interface" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Q&amp;amp;A Entry&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/qa.png" alt="Q&amp;amp;A Entry Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Rich Text &amp;amp; Image Responses&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/answer.png" alt="Rich Answer Interface" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for dragging and dropping various documents, automatically identifying document structures and extracting core knowledge to establish indexes. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph2.png" alt="Knowledge Graph View 1" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/graph1.png" alt="Knowledge Graph View 2" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;h3&gt;MCP Server Integration Effects&lt;/h3&gt; 
&lt;img width="950" height="2063" alt="MCP Server Integration Demo" src="https://github.com/user-attachments/assets/09111ec8-0489-415c-969d-aa3835778e14" /&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îú‚îÄ‚îÄ scripts/     # Shell scripts
‚îú‚îÄ‚îÄ services/    # Microservice logic
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îî‚îÄ‚îÄ docs/        # Project documentation
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîß Common Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Wipe all data from DB (use with caution)
make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>VictoriaMetrics/VictoriaMetrics</title>
      <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
      <description>&lt;p&gt;VictoriaMetrics: fast, cost-effective monitoring solution and time series database&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;VictoriaMetrics&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;amp;label=&amp;amp;filter=!*-victorialogs&amp;amp;logo=github&amp;amp;labelColor=gray&amp;amp;color=gray&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest" alt="Latest Release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;labelColor=2496ED&amp;amp;color=2496ED&amp;amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics" alt="Docker Pulls" /&gt; &lt;a href="https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics"&gt;&lt;img src="https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics" alt="Go Report" /&gt;&lt;/a&gt; &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics"&gt;&lt;img src="https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;amp;label=&amp;amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE" alt="License" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/Join-4A154B?logo=slack&amp;amp;link=https%3A%2F%2Fslack.victoriametrics.com" alt="Slack" /&gt; &lt;a href="https://x.com/VictoriaMetrics/"&gt;&lt;img src="https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;amp;label=Follow&amp;amp;color=black&amp;amp;logo=x&amp;amp;labelColor=black&amp;amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/VictoriaMetrics/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;amp;label=Join&amp;amp;labelColor=red&amp;amp;logoColor=white&amp;amp;logo=reddit&amp;amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics" alt="Reddit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source srcset="docs/victoriametrics/logo_white.webp" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;source srcset="docs/victoriametrics/logo.webp" media="(prefers-color-scheme: light)" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/VictoriaMetrics/VictoriaMetrics/master/docs/victoriametrics/logo.webp" width="300" alt="VictoriaMetrics logo" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.&lt;/p&gt; 
&lt;p&gt;Here are some resources and information about VictoriaMetrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.victoriametrics.com"&gt;docs.victoriametrics.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Case studies: &lt;a href="https://docs.victoriametrics.com/victoriametrics/casestudies/"&gt;Grammarly, Roblox, Wix,...&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Available: &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest"&gt;Binary releases&lt;/a&gt;, docker images &lt;a href="https://hub.docker.com/r/victoriametrics/victoria-metrics/"&gt;Docker Hub&lt;/a&gt; and &lt;a href="https://quay.io/repository/victoriametrics/victoria-metrics"&gt;Quay&lt;/a&gt;, &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics"&gt;Source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Deployment types: &lt;a href="https://docs.victoriametrics.com/"&gt;Single-node version&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/"&gt;Cluster version&lt;/a&gt;, and &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;Enterprise version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Changelog: &lt;a href="https://docs.victoriametrics.com/victoriametrics/changelog/"&gt;CHANGELOG&lt;/a&gt;, and &lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics"&gt;How to upgrade&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community: &lt;a href="https://slack.victoriametrics.com/"&gt;Slack&lt;/a&gt;, &lt;a href="https://x.com/VictoriaMetrics"&gt;X (Twitter)&lt;/a&gt;, &lt;a href="https://www.linkedin.com/company/victoriametrics/"&gt;LinkedIn&lt;/a&gt;, &lt;a href="https://www.youtube.com/@VictoriaMetrics"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Yes, we open-source both the single-node VictoriaMetrics and the cluster version.&lt;/p&gt; 
&lt;h2&gt;Prominent features&lt;/h2&gt; 
&lt;p&gt;VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Long-term storage for Prometheus&lt;/strong&gt; or as a drop-in replacement for Prometheus and Graphite in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Powerful stream aggregation&lt;/strong&gt;: Can be used as a StatsD alternative.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ideal for big data&lt;/strong&gt;: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;Enterprise workloads&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query language&lt;/strong&gt;: Supports both PromQL and the more performant MetricsQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to setup&lt;/strong&gt;: No dependencies, single &lt;a href="https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d"&gt;small binary&lt;/a&gt;, configuration through command-line flags, but the default is also fine-tuned; backup and restore with &lt;a href="https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282"&gt;instant snapshots&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global query view&lt;/strong&gt;: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Various Protocols&lt;/strong&gt;: Support metric scraping, ingestion and backfilling in various protocol. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter"&gt;Prometheus exporters&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/"&gt;Prometheus remote write API&lt;/a&gt;, &lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format"&gt;Prometheus exposition format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/"&gt;InfluxDB line protocol&lt;/a&gt; over HTTP, TCP and UDP.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting"&gt;Graphite plaintext protocol&lt;/a&gt; with &lt;a href="https://graphite.readthedocs.io/en/latest/tags.html#carbon"&gt;tags&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet"&gt;OpenTSDB put message&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http"&gt;HTTP OpenTSDB /api/put requests&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format"&gt;JSON line format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data"&gt;Arbitrary CSV data&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format"&gt;Native binary format&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/datadog/"&gt;DataDog agent or DogStatsD&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent"&gt;NewRelic infrastructure agent&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry"&gt;OpenTelemetry metrics format&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NFS-based storages&lt;/strong&gt;: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.&lt;/li&gt; 
 &lt;li&gt;And many other features such as metrics relabeling, cardinality limiter, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Enterprise version&lt;/h2&gt; 
&lt;p&gt;In addition, the Enterprise version includes extra features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anomaly detection&lt;/strong&gt;: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backup automation&lt;/strong&gt;: Automates regular backup procedures.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple retentions&lt;/strong&gt;: Reducing storage costs by specifying different retentions for different datasets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Downsampling&lt;/strong&gt;: Reducing storage costs and increasing performance for queries over historical data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stable releases&lt;/strong&gt; with long-term support lines (&lt;a href="https://docs.victoriametrics.com/victoriametrics/lts-releases/"&gt;LTS&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive support&lt;/strong&gt;: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.&lt;/li&gt; 
 &lt;li&gt;Many other features, which you can read about on &lt;a href="https://docs.victoriametrics.com/victoriametrics/enterprise/"&gt;the Enterprise page&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="mailto:info@victoriametrics.com"&gt;Contact us&lt;/a&gt; if you need enterprise support for VictoriaMetrics. Or you can request a free trial license &lt;a href="https://victoriametrics.com/products/enterprise/trial/"&gt;here&lt;/a&gt;, downloaded Enterprise binaries are available at &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest"&gt;Github Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See &lt;a href="https://victoriametrics.com/security/"&gt;Security page&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;Some good benchmarks VictoriaMetrics achieved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal memory footprint&lt;/strong&gt;: handling millions of unique timeseries with &lt;a href="https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893"&gt;10x less RAM&lt;/a&gt; than InfluxDB, up to &lt;a href="https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f"&gt;7x less RAM&lt;/a&gt; than Prometheus, Thanos or Cortex.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly scalable and performance&lt;/strong&gt; for &lt;a href="https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b"&gt;data ingestion&lt;/a&gt; and &lt;a href="https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4"&gt;querying&lt;/a&gt;, &lt;a href="https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893"&gt;20x outperforms&lt;/a&gt; InfluxDB and TimescaleDB.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High data compression&lt;/strong&gt;: &lt;a href="https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4"&gt;70x more data points&lt;/a&gt; may be stored into limited storage than TimescaleDB, &lt;a href="https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f"&gt;7x less storage&lt;/a&gt; space is required than Prometheus, Thanos or Cortex.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reducing storage costs&lt;/strong&gt;: &lt;a href="https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly"&gt;10x more effective&lt;/a&gt; than Graphite according to the Grammarly case study.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A single-node VictoriaMetrics&lt;/strong&gt; can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See &lt;a href="https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683"&gt;VictoriaMetrics vs Thanos&lt;/a&gt;, &lt;a href="https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae"&gt;Measuring vertical scalability&lt;/a&gt;, &lt;a href="https://promcon.io/2019-munich/talks/remote-write-storage-wars/"&gt;Remote write storage wars - PromCon 2019&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized for storage&lt;/strong&gt;: &lt;a href="https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b"&gt;Works well with high-latency IO&lt;/a&gt; and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community and contributions&lt;/h2&gt; 
&lt;p&gt;Feel free asking any questions regarding VictoriaMetrics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://slack.victoriametrics.com/"&gt;Slack Inviter&lt;/a&gt; and &lt;a href="https://victoriametrics.slack.com/"&gt;Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/VictoriaMetrics/"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/victoriametrics/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/VictoriaMetrics/"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/VictoriaMetrics_en"&gt;Telegram-en&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/VictoriaMetrics_ru1"&gt;Telegram-ru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@victoriametrics/"&gt;Mastodon&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you like VictoriaMetrics and want to contribute, then please &lt;a href="https://docs.victoriametrics.com/victoriametrics/contributing/"&gt;read these docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;VictoriaMetrics Logo&lt;/h2&gt; 
&lt;p&gt;The provided &lt;a href="https://github.com/VictoriaMetrics/VictoriaMetrics/raw/master/VM_logo.zip"&gt;ZIP file&lt;/a&gt; contains three folders with different logo orientations. Each folder includes the following file types:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JPEG: Preview files&lt;/li&gt; 
 &lt;li&gt;PNG: Preview files with transparent background&lt;/li&gt; 
 &lt;li&gt;AI: Adobe Illustrator files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VictoriaMetrics Logo Usage Guidelines&lt;/h3&gt; 
&lt;h4&gt;Font&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Font Used: Lato Black&lt;/li&gt; 
 &lt;li&gt;Download here: &lt;a href="https://fonts.google.com/specimen/Lato"&gt;Lato Font&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Color Palette&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Black &lt;a href="https://www.color-hex.com/color/000000"&gt;#000000&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Purple &lt;a href="https://www.color-hex.com/color/4d0e82"&gt;#4d0e82&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Orange &lt;a href="https://www.color-hex.com/color/ff2e00"&gt;#ff2e00&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;White &lt;a href="https://www.color-hex.com/color/ffffff"&gt;#ffffff&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logo Usage Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Only use the Lato Black font as specified.&lt;/li&gt; 
 &lt;li&gt;Maintain sufficient clear space around the logo for visibility.&lt;/li&gt; 
 &lt;li&gt;Do not modify the spacing, alignment, or positioning of design elements.&lt;/li&gt; 
 &lt;li&gt;You may resize the logo as needed, but ensure all proportions remain intact.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you for your cooperation!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go install&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>coreybutler/nvm-windows</title>
      <link>https://github.com/coreybutler/nvm-windows</link>
      <description>&lt;p&gt;A node.js version management utility for Windows. Ironically written in Go.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
 &lt;h2&gt;Notice: We are working full time on Author, which includes &lt;a href="https://github.com/coreybutler/nvm-windows/wiki/Runtime"&gt;Runtime&lt;/a&gt;, the successor to NVM for Windows.&lt;/h2&gt;Complete 
 &lt;a href="https://t.co/oGqQCM9FPx"&gt;this form&lt;/a&gt; to provide your thoughts and sign up for progress updates.
 &lt;br /&gt;
 &lt;br /&gt;Updates will also be posted on the 
 &lt;a href="https://linkedin.com/company/authorsoftware"&gt;Author Software LinkedIn Page&lt;/a&gt;.
&lt;/div&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;h1 align="center"&gt;NVM for Windows&lt;/h1&gt; 
&lt;div align="center"&gt;
  The 
 &lt;a href="https://docs.microsoft.com/en-us/windows/nodejs/setup-on-windows"&gt;Microsoft&lt;/a&gt;/
 &lt;a href="https://docs.npmjs.com/cli/v9/configuring-npm/install#windows-node-version-managers"&gt;npm&lt;/a&gt;/
 &lt;a href="https://cloud.google.com/nodejs/docs/setup#installing_nvm"&gt;Google&lt;/a&gt; recommended Node.js version manager for 
 &lt;em&gt;Windows&lt;/em&gt;.
 &lt;br /&gt; 
 &lt;details&gt; 
  &lt;summary&gt;&lt;b&gt;This is not the same thing as nvm!&lt;/b&gt; (expand for details)&lt;/summary&gt; 
  &lt;p&gt;&lt;em&gt;The original &lt;a href="https://github.com/nvm-sh/nvm"&gt;nvm&lt;/a&gt; is a completely separate project for Mac/Linux only.&lt;/em&gt; This project uses an entirely different philosophy and is not just a clone of nvm. Details are listed in &lt;a href="https://raw.githubusercontent.com/coreybutler/nvm-windows/master/#bulb-why-another-version-manager"&gt;Why another version manager?&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/coreybutler/nvm-windows/master/#bulb-whats-the-big-difference"&gt;what's the big difference?&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;p&gt;&lt;a href="https://github.com/coreybutler/nvm-windows/releases"&gt;&lt;img src="https://img.shields.io/badge/-Download%20Now!-%2322A6F2" alt="Download Now" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/coreybutler/nvm-windows/master/(https://github.com/coreybutler/nvm-windows/releases)"&gt;&lt;img src="https://img.shields.io/github/v/tag/coreybutler/nvm-windows?label=Latest%20Release&amp;amp;style=social&amp;amp;x=1" alt="GitHub tag (latest SemVer)" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/release-date/coreybutler/nvm-windows?label=Released&amp;amp;style=social" alt="GitHub Release Date" /&gt; &lt;img src="https://img.shields.io/github/downloads/coreybutler/nvm-windows/total?label=Downloads&amp;amp;style=social" alt="GitHub all releases" /&gt; &lt;a href="https://github.com/coreybutler/nvm-windows/discussions"&gt;&lt;img src="https://img.shields.io/badge/-Discuss-blue" alt="Discuss" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/tweet?hashtags=nodejs&amp;amp;original_referer=http%3A%2F%2F127.0.0.1%3A91%2F&amp;amp;text=Check%20out%20NVM%20for%20Windows!&amp;amp;tw_p=tweetbutton&amp;amp;url=http%3A%2F%2Fgithub.com%2Fcoreybutler%2Fnvm-windows&amp;amp;via=goldglovecb"&gt;&lt;img src="https://img.shields.io/twitter/url?style=social&amp;amp;url=https%3A%2F%2Ftwitter.com%2Fintent%2Ftweet%3Fhashtags%3Dnodejs%26original_referer%3Dhttp%253A%252F%252F127.0.0.1%253A91%252F%26text%3DCheck%2520out%2520NVM%2520for%2520Windows%21%26tw_p%3Dtweetbutton%26url%3Dhttp%253A%252F%252Fgithub.com%252Fcoreybutler%252Fnvm-windows%26via%3Dgoldglovecb" alt="Twitter URL" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/4201" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4201" alt="coreybutler%2Fnvm-windows | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h5 align="center"&gt;Sponsors&lt;/h5&gt; 
&lt;div align="center"&gt; 
 &lt;table cellpadding="5" cellspacing="0" border="0" align="center"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://linkedin.com/company/authorsoftware"&gt;&lt;img src="https://github.com/coreybutler/staticassets/raw/master/sponsors/logo_author_software_flat.png" width="200px" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td width="33%" align="center"&gt;&lt;a href="https://ecorventures.com"&gt;&lt;img src="https://avatars.githubusercontent.com/u/8259581?s=200&amp;amp;v=4" height="30px" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td width="33%" align="center"&gt;&lt;a href="https://github.com/microsoft"&gt;&lt;img src="https://user-images.githubusercontent.com/770982/195955265-5c3dca78-7140-4ec6-b05a-f308518643ee.png" height="30px" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="4" align="center"&gt; &lt;a href="https://github.com/sponsors/coreybutler"&gt;&lt;img src="https://img.shields.io/github/sponsors/coreybutler?label=Individual%20Sponsors&amp;amp;logo=github&amp;amp;style=social" /&gt;&lt;/a&gt; &amp;nbsp;&lt;a href="https://github.com/sponsors/coreybutler"&gt;&lt;img src="https://img.shields.io/badge/-Become%20a%20Sponsor-yellow" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="4" align="center"&gt; &lt;img src="https://github.blog/wp-content/uploads/2020/09/github-stars-logo_Color.png" width="50" /&gt;&lt;br /&gt; &lt;b&gt;Can't sponsor?&lt;/b&gt;&lt;br /&gt;Consider &lt;a href="https://stars.github.com/nominate/" target="_blank"&gt;nominating @coreybutler for a Github star&lt;/a&gt;. &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt;
 &lt;b&gt;Running into issues?&lt;/b&gt; See the 
 &lt;a href="https://github.com/coreybutler/nvm-windows/wiki/Common-Issues"&gt;common issues wiki&lt;/a&gt;.
&lt;/div&gt; 
&lt;br /&gt; 
&lt;table style="background-color:red;padding:6px;border-radius:3px;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;
   &lt;td&gt; &lt;h3&gt;Seeking Feedback:&lt;/h3&gt; We're working on &lt;a href="https://github.com/coreybutler/nvm-windows/wiki/Runtime"&gt;Runtime (rt)&lt;/a&gt;, the successor to NVM For Windows. Please contribute by taking a minute to complete &lt;a href="https://t.co/oGqQCM9FPx"&gt;this form&lt;/a&gt;. Thank you! &lt;h3&gt;&lt;/h3&gt; &lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Manage multiple installations of node.js on a Windows computer.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; Similar (not identical) to &lt;a href="https://github.com/creationix/nvm"&gt;nvm&lt;/a&gt;, but for Windows. Has an installer. &lt;a href="https://github.com/coreybutler/nvm-windows/releases"&gt;Download Now&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;This has always been a node version manager, not an io.js manager, so there is no back-support for io.js. Node 4+ is supported. Remember when running &lt;code&gt;nvm install&lt;/code&gt; or &lt;code&gt;nvm use&lt;/code&gt;, Windows usually requires administrative rights (to create symlinks). To install the latest version of Node.js, run &lt;code&gt;nvm install latest&lt;/code&gt;. To install the latest stable version, run &lt;code&gt;nvm install lts&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/coreybutler/staticassets/raw/master/images/nvm-1.1.8-screenshot.jpg" alt="NVM for Windows" /&gt;&lt;/p&gt; 
&lt;p&gt;There are situations where the ability to switch between different versions of Node.js can be very useful. For example, if you want to test a module you're developing with the latest bleeding edge version without uninstalling the stable version of node, this utility can help.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/coreybutler/staticassets/raw/master/images/nvm-usage-highlighted.jpg" alt="Switch between stable and unstable versions." /&gt;&lt;/p&gt; 
&lt;h3&gt;Installation &amp;amp; Upgrades&lt;/h3&gt; 
&lt;h4&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;span&gt;‚≠ê&lt;/span&gt; Uninstall any pre-existing Node installations!! &lt;span&gt;‚≠ê&lt;/span&gt; &lt;span&gt;‚≠ê&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;The simplest (recommended) way to get NVM for Windows running properly is to uninstall any prior Node installation &lt;em&gt;before&lt;/em&gt; installing NVM for Windows. It avoids all of the pitfalls listed below. However; you may not wish to nuke your Node installation if you've highly customized it. NVM for Windows &lt;em&gt;can&lt;/em&gt; assume management of an existing installation, but there are nuances to this (dependent entirely on the permissions of the user running the installation). If you have an administrative account, it's relatively safe to install NVM for Windows before uninstalling the original Node version. If you are working in a closed environment, such as a corporate Active Directory environment where installations/uninstallations are controlled by group policy, you should really consider removing the original version of Node before installing NVM4W.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Permission Problems&lt;/em&gt; For security reasons, Windows will not allow an application from one vendor to "uninstall" an application from a different vendor. The official NVM4W installer will attempt assume management of an existing installation of Node., but it cannot actually uninstall the original Node.js version. To work around this, NVM for Windows installer attempts to copy the original Node.js installation files to the NVM root. This includes global npm modules and configurations. Once this process is complete, the original Node.js installation can be uninstalled without losing data.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PATH Installation Problems&lt;/em&gt; If you attempt to configure the &lt;code&gt;NVM_SYMLINK&lt;/code&gt; to use an existing directory (like &lt;code&gt;C:\Program Files\nodejs&lt;/code&gt;), it will fail because a symlink cannot overwrite a physical directory. This is not a problem if you choose a different symlink path (such as &lt;code&gt;C:\nvm\node&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;PATH Conflicts&lt;/em&gt; If you do not uninstall the original version, running &lt;code&gt;nvm use&lt;/code&gt; may appear to do nothing at all. Running &lt;code&gt;node -v&lt;/code&gt; will always show the original installation version. This is due to a &lt;a href="https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#why-do-i-need-to-uninstall-nodejs-before-installing-nvm-for-windows"&gt;&lt;code&gt;PATH&lt;/code&gt; conflict&lt;/a&gt; that presents when the same application is installed multiple times. In NVM4W 1.1.11+, run &lt;code&gt;nvm debug&lt;/code&gt; to determine if you have a &lt;code&gt;PATH&lt;/code&gt; conflict.&lt;/p&gt; 
&lt;p&gt;For simpliciy, we recommend uninstalling any existing versions of Node.js before using NVM for Windows. Delete any existing Node.js installation directories (e.g., &lt;code&gt;%ProgramFiles%\nodejs&lt;/code&gt;) that might remain. NVM's generated symlink will not overwrite an existing (even empty) installation directory.&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;üëÄ&lt;/span&gt; &lt;strong&gt;Backup any global &lt;code&gt;npmrc&lt;/code&gt; config&lt;/strong&gt; &lt;span&gt;üëÄ&lt;/span&gt; (e.g. &lt;code&gt;%AppData%\npm\etc\npmrc&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;Alternatively, copy the settings to the user config &lt;code&gt;%UserProfile%\.npmrc&lt;/code&gt;. Delete the existing npm install location (e.g. &lt;code&gt;%AppData%\npm&lt;/code&gt;) to prevent global module conflicts.&lt;/p&gt; 
&lt;h4&gt;Install nvm-windows&lt;/h4&gt; 
&lt;p&gt;Use the &lt;a href="https://github.com/coreybutler/nvm/releases"&gt;latest installer&lt;/a&gt; (comes with an uninstaller). Alternatively, follow the &lt;a href="https://github.com/coreybutler/nvm-windows/wiki#manual-installation"&gt;manual installation&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;If NVM4W doesn't appear to work immediately after installation, restart the terminal/powershell (not the whole computer).&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/coreybutler/staticassets/raw/master/images/nvm-installer.jpg" alt="NVM for Windows Installer" /&gt;&lt;/p&gt; 
&lt;h4&gt;Reinstall any global utilities&lt;/h4&gt; 
&lt;p&gt;After install, reinstalling global utilities (e.g. yarn) will have to be done for each installed version of node:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;nvm use 14.0.0
npm install -g yarn
nvm use 12.0.1
npm install -g yarn
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Upgrading nvm-windows&lt;/h3&gt; 
&lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; &lt;em&gt;As of v1.1.8, there is an upgrade utility that will automate the upgrade process.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;To upgrade nvm-windows&lt;/strong&gt;, run the new installer. It will safely overwrite the files it needs to update without touching your node.js installations. Make sure you use the same installation and symlink folder. If you originally installed to the default locations, you just need to click "next" on each window until it finishes.&lt;/p&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;nvm-windows runs in an Admin shell&lt;/strong&gt;. You'll need to start &lt;code&gt;powershell&lt;/code&gt; or Command Prompt as Administrator to use nvm-windows&lt;/p&gt; 
&lt;p&gt;NVM for Windows is a command line tool. Simply type &lt;code&gt;nvm&lt;/code&gt; in the console for help. The basic commands are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm arch [32|64]&lt;/code&gt;&lt;/strong&gt;: Show if node is running in 32 or 64 bit mode. Specify 32 or 64 to override the default architecture.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm debug&lt;/code&gt;&lt;/strong&gt;: Check the NVM4W process for known problems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm current&lt;/code&gt;&lt;/strong&gt;: Display active version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm install &amp;lt;version&amp;gt; [arch]&lt;/code&gt;&lt;/strong&gt;: The version can be a specific version, "latest" for the latest current version, or "lts" for the most recent LTS version. Optionally specify whether to install the 32 or 64 bit version (defaults to system arch). Set [arch] to "all" to install 32 AND 64 bit versions. Add &lt;code&gt;--insecure&lt;/code&gt; to the end of this command to bypass SSL validation of the remote download server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm list [available]&lt;/code&gt;&lt;/strong&gt;: List the node.js installations. Type &lt;code&gt;available&lt;/code&gt; at the end to show a list of versions available for download.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm on&lt;/code&gt;&lt;/strong&gt;: Enable node.js version management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm off&lt;/code&gt;&lt;/strong&gt;: Disable node.js version management (does not uninstall anything).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm proxy [url]&lt;/code&gt;&lt;/strong&gt;: Set a proxy to use for downloads. Leave &lt;code&gt;[url]&lt;/code&gt; blank to see the current proxy. Set &lt;code&gt;[url]&lt;/code&gt; to "none" to remove the proxy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm uninstall &amp;lt;version&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Uninstall a specific version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm use &amp;lt;version&amp;gt; [arch]&lt;/code&gt;&lt;/strong&gt;: Switch to use the specified version. Optionally use &lt;code&gt;latest&lt;/code&gt;, &lt;code&gt;lts&lt;/code&gt;, or &lt;code&gt;newest&lt;/code&gt;. &lt;code&gt;newest&lt;/code&gt; is the latest &lt;em&gt;installed&lt;/em&gt; version. Optionally specify 32/64bit architecture. &lt;code&gt;nvm use &amp;lt;arch&amp;gt;&lt;/code&gt; will continue using the selected version, but switch to 32/64 bit mode. For information about using &lt;code&gt;use&lt;/code&gt; in a specific directory (or using &lt;code&gt;.nvmrc&lt;/code&gt;), please refer to &lt;a href="https://github.com/coreybutler/nvm-windows/issues/16"&gt;issue #16&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm root &amp;lt;path&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Set the directory where nvm should store different versions of node.js. If &lt;code&gt;&amp;lt;path&amp;gt;&lt;/code&gt; is not set, the current root will be displayed.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm version&lt;/code&gt;&lt;/strong&gt;: Displays the current running version of NVM for Windows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm node_mirror &amp;lt;node_mirror_url&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Set the node mirror.People in China can use &lt;em&gt;&lt;a href="https://npmmirror.com/mirrors/node/"&gt;https://npmmirror.com/mirrors/node/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;nvm npm_mirror &amp;lt;npm_mirror_url&amp;gt;&lt;/code&gt;&lt;/strong&gt;: Set the npm mirror.People in China can use &lt;em&gt;&lt;a href="https://npmmirror.com/mirrors/npm/"&gt;https://npmmirror.com/mirrors/npm/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;span&gt;‚ö†&lt;/span&gt; Gotcha!&lt;/h3&gt; 
&lt;p&gt;Please note that any global npm modules you may have installed are &lt;strong&gt;not&lt;/strong&gt; shared between the various versions of node.js you have installed. Additionally, some npm modules may not be supported in the version of node you're using, so be aware of your environment as you work.&lt;/p&gt; 
&lt;h3&gt;&lt;span&gt;üìõ&lt;/span&gt; Antivirus&lt;/h3&gt; 
&lt;p&gt;Users have reported some problems using antivirus, specifically McAfee. It appears the antivirus software is manipulating access to the VBScript engine. See &lt;a href="https://github.com/coreybutler/nvm-windows/issues/133"&gt;issue #133&lt;/a&gt; for details and resolution.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;v1.1.8 is not code signed&lt;/strong&gt;, but all other versions are signed by &lt;a href="https://ecorventures.com"&gt;Ecor Ventures LLC&lt;/a&gt;/&lt;a href="https://author.io"&gt;Author.io&lt;/a&gt;. This should help prevent false positives with most antivirus software.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;v1.1.8+ was not code signed due to an expired certificate (see the &lt;a href="https://github.com/coreybutler/nvm-windows/releases/tag/1.1.8"&gt;release notes&lt;/a&gt; for reasons). &lt;strong&gt;v1.1.9 &lt;em&gt;is&lt;/em&gt; code signed&lt;/strong&gt; thanks to &lt;a href="https://github.com/ajyong"&gt;ajyong&lt;/a&gt;, who sponsored the new certificate.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Using Yarn&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;tldr;&lt;/strong&gt; &lt;code&gt;npm i -g yarn&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/coreybutler/nvm-windows/wiki/Common-Issues#how-do-i-use-yarn-with-nvm-windows"&gt;wiki&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install go from &lt;a href="http://golang.org"&gt;http://golang.org&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download source / Git Clone the repo&lt;/li&gt; 
 &lt;li&gt;Change GOARCH to amd64 in build.bat if you feel like building a 64-bit executable&lt;/li&gt; 
 &lt;li&gt;Fire up a Windows command prompt and change directory to project dir&lt;/li&gt; 
 &lt;li&gt;Execute &lt;code&gt;go get github.com/blang/semver&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Execute &lt;code&gt;go get github.com/olekukonko/tablewriter&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Execute &lt;code&gt;build.bat&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Check the &lt;code&gt;dist&lt;/code&gt;directory for generated setup program.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;span&gt;üí°&lt;/span&gt; Why another version manager?&lt;/h2&gt; 
&lt;p&gt;There are several version managers for node.js. Tools like &lt;a href="https://github.com/creationix/nvm"&gt;nvm&lt;/a&gt; and &lt;a href="https://github.com/tj/n"&gt;n&lt;/a&gt; only run on Mac OSX and Linux. Windows users are left in the cold? No. &lt;a href="https://github.com/hakobera/nvmw"&gt;nvmw&lt;/a&gt; and &lt;a href="https://github.com/marcelklehr/nodist"&gt;nodist&lt;/a&gt; are both designed for Windows. So, why another version manager for Windows?&lt;/p&gt; 
&lt;p&gt;The architecture of most node version managers for Windows rely on &lt;code&gt;.bat&lt;/code&gt; files, which do some clever tricks to set or mimic environment variables. Some of them use node itself (once it's downloaded), which is admirable, but prone to problems. Right around node 0.10.30, the installation structure changed a little, causing some of these to just stop working with anything new.&lt;/p&gt; 
&lt;p&gt;Additionally, some users struggle to install these modules since it requires a little more knowledge of node's installation structure. I believe if it were easier for people to switch between versions, people might take the time to test their code on back and future versions... which is just good practice.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üí°&lt;/span&gt; What's the big difference?&lt;/h2&gt; 
&lt;p&gt;First and foremost, this version of nvm has no dependency on node. It's written in &lt;a href="https://golang.org/"&gt;Go&lt;/a&gt;, which is a much more structured approach than hacking around a limited &lt;code&gt;.bat&lt;/code&gt; file. It does not rely on having an existing node installation. Go offers the ability to create a Mac/Linux version on the same code base. In fact, this is already underway.&lt;/p&gt; 
&lt;p&gt;The control mechanism is also quite different. There are two general ways to support multiple node installations with hot switching capabilities. The first is to modify the system &lt;code&gt;PATH&lt;/code&gt; any time you switch versions, or bypass it by using a &lt;code&gt;.bat&lt;/code&gt; file to mimic the node executable and redirect accordingly. This always seemed a little hackish to me, and there are some quirks as a result of this implementation.&lt;/p&gt; 
&lt;p&gt;The second option is to use a symlink. This concept requires putting the symlink in the system &lt;code&gt;PATH&lt;/code&gt;, then updating its target to the node installation directory you want to use. This is a straightforward approach, and seems to be what people recommend.... until they realize just how much of a pain symlinks are on Windows. This is why it hasn't happened before.&lt;/p&gt; 
&lt;p&gt;In order to create/modify a symlink, you must be running as an admin, and you must get around Windows UAC (that annoying prompt). Luckily, this is a challenge I already solved with some helper scripts in &lt;a href="https://github.com/coreybutler/node-windows"&gt;node-windows&lt;/a&gt;. As a result, NVM for Windows maintains a single symlink that is put in the system &lt;code&gt;PATH&lt;/code&gt; during installation only. Switching to different versions of node is a matter of switching the symlink target. As a result, this utility does &lt;strong&gt;not&lt;/strong&gt; require you to run &lt;code&gt;nvm use x.x.x&lt;/code&gt; every time you open a console window. When you &lt;em&gt;do&lt;/em&gt; run &lt;code&gt;nvm use x.x.x&lt;/code&gt;, the active version of node is automatically updated across all open console windows. It also persists between system reboots, so you only need to use nvm when you want to make a change.&lt;/p&gt; 
&lt;p&gt;NVM for Windows comes with an installer, courtesy of a byproduct of my work on &lt;a href="https://preview.fenixwebserver.com"&gt;Fenix Web Server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Overall, this project brings together some ideas, a few battle-hardened pieces of other modules, and support for newer versions of node.&lt;/p&gt; 
&lt;p&gt;NVM for Windows recognizes the "latest" versions using a &lt;a href="https://nodejs.org/download/release/index.json"&gt;list&lt;/a&gt; provided by the Node project. Version 1.1.1+ use this list. Before this list existed, I was scraping releases and serving it as a standalone &lt;a href="https://github.com/coreybutler/nodedistro"&gt;data feed&lt;/a&gt;. This list was used in versions 1.1.0 and prior, but is now deprecated.&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;I needed it, plain and simple. Additionally, it's apparent that &lt;a href="https://github.com/nodejs/node-v0.x-archive/issues/8075"&gt;support for multiple versions&lt;/a&gt; is not coming to node core. It was also an excuse to play with Go.&lt;/p&gt; 
&lt;h2&gt;Why Go? Why not Node?&lt;/h2&gt; 
&lt;p&gt;I chose Go because it is cross-platform, felt like less overhead than Java, has been around longer than most people think. Plus, I wanted to experiment with it. I've been asked why I didn't write it with Node. Trying to write a tool with the tool you're trying to install doesn't make sense to me. As a result, my project requirements for this were simple... something that's not Node. Node will continue to evolve and change. If you need a reminder of that, remember io.js, Ayo, all the breaking changes between 4.x.x and 6.x.x, and the shift to ES Modules in 12+. Change is inevitable in the world of software. JavaScript is extremely dynamic.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üôè&lt;/span&gt; Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to everyone who has submitted issues on and off Github, made suggestions, and generally helped make this a better project. Special thanks to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vkbansal"&gt;@vkbansal&lt;/a&gt;, who provided significant early feedback throughout the early releases.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rainabba"&gt;@rainabba&lt;/a&gt; and &lt;a href="https://github.com/sullivanpt"&gt;@sullivanpt&lt;/a&gt; for getting Node v4 support integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-h-a-d-o-w"&gt;@s-h-a-d-o-w&lt;/a&gt; who resolved the longstanding space escaping issue in path names (&lt;a href="https://github.com/coreybutler/nvm-windows/pull/355"&gt;#355&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ajyong"&gt;ajyong&lt;/a&gt; who sponsored the code signing certificate in late 2021.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://contrib.rocks/image?repo=coreybutler/nvm-windows" alt="Contributors" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>awslabs/diagram-as-code</title>
      <link>https://github.com/awslabs/diagram-as-code</link>
      <description>&lt;p&gt;Diagram-as-code for AWS architecture.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Diagram-as-code&lt;/h1&gt; 
&lt;p&gt;This command line interface (CLI) tool enables drawing infrastructure diagrams for Amazon Web Services through YAML code. It facilitates diagram-as-code without relying on image libraries.&lt;/p&gt; 
&lt;p&gt;The CLI tool promotes code reuse, testing, integration, and automating the diagramming process. It allows managing diagrams with Git by writing human-readable YAML.&lt;/p&gt; 
&lt;p&gt;Example templates are &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/examples"&gt;here&lt;/a&gt;. Check out the &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/doc/introduction.md"&gt;Introduction Guide&lt;/a&gt; as well for additional information.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/doc/static/introduction2.png" width="800" /&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/doc/static/command_demo.gif" alt="CLI Usage animation" /&gt;&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;for Gopher (go 1.21 or higher)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/awslabs/diagram-as-code/cmd/awsdac@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;for macOS user&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ brew install awsdac
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Usage:
  awsdac &amp;lt;input filename&amp;gt; [flags]

Flags:
  -c, --cfn-template               [beta] Create diagram from CloudFormation template
  -d, --dac-file                   [beta] Generate YAML file in dac (diagram-as-code) format from CloudFormation template
  -h, --help                       help for awsdac
  -o, --output string              Output file name (default "output.png")
      --override-def-file string   For testing purpose, override DefinitionFiles to another url/local file
  -t, --template                   Processes the input file as a template according to text/template.
  -v, --verbose                    Enable verbose logging
      --version                    version for awsdac
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ awsdac examples/alb-ec2.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;$ awsdac privatelink.yaml -o custom-output.png
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;[Beta] Create a diagram from CloudFormation template&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;--cfn-template&lt;/code&gt; option allows you to generate diagrams from CloudFormation templates, providing a visual representation of the resources. The tool can generate diagrams even if the CloudFormation template is not in a perfect format, enabling you to visualize the resources before actually creating the CloudFormation stack. This means you don't have to strictly adhere to the CloudFormation syntax constraints.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The functionality of generating diagrams from CloudFormation templates is currently in beta. It sometimes works correctly, but we are aware of several known issues where the tool might not produce accurate results. We are actively working on improving the tool and fixing these issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;$ awsdac examples/vpc-subnet-ec2-cfn.yaml --cfn-template
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(generated from &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/examples/vpc-subnet-ec2-cfn.yaml"&gt;the example of VPC,Subnet,EC2&lt;/a&gt;)&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/examples/vpc-subnet-ec2-cfn.png" width="500" /&gt; 
&lt;p&gt;There are some patterns where the tool may not work as expected. You can find a list of known issues and their status on the &lt;a href="https://github.com/awslabs/diagram-as-code/labels/cfn-template%20feature"&gt;issue tracker&lt;/a&gt;. Your feedback and issue reports are appreciated, as they will help enhance the tool's performance and accuracy.&lt;/p&gt; 
&lt;h4&gt;Use "--dac-file" option&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;$ awsdac examples/vpc-subnet-ec2-cfn.yaml --cfn-template --dac-file
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CloudFormation templates have various dependencies, and there is no simple parent-child relationship between resources. As a result, generating the desired diagram directly from the existing CloudFormation template formats can be challenging at this stage. We considered utilizing Metadata or comments within the CloudFormation templates to include additional information. However, this approach would make the templates excessively long, and CloudFormation templates are primarily intended for resource creation and management rather than diagram generation. Additionally, combining different lifecycle components into a single CloudFormation template could make it difficult to manage and maintain.&lt;/p&gt; 
&lt;p&gt;Therefore, instead of directly generating diagrams from CloudFormation templates, you can create a separate YAML file from CloudFormation template and customize this YAML file. This customized YAML file can then be used as input for &lt;code&gt;awsdac&lt;/code&gt; to generate the desired architecture diagrams. By decoupling the diagram generation process from the CloudFormation template structure, this approach offers greater flexibility and customization while leveraging the specialized strengths of &lt;code&gt;awsdac&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CloudFormation template --[awsdac]--&amp;gt; yaml file in awsdac format --[user custom]--&amp;gt; your desired diagram :)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Compliant with AWS architecture guidelines&lt;/strong&gt;&lt;br /&gt; Easily generate diagrams that follow &lt;a href="https://aws.amazon.com/architecture/icons"&gt;AWS diagram guidelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;&lt;br /&gt; Automatically adjust the position and size of groups.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight &amp;amp; CI/CD-friendly&lt;/strong&gt;&lt;br /&gt; Start quickly on a container; no dependency on headless browser or GUI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrate with your Infrastructure as Code&lt;/strong&gt;&lt;br /&gt; Generate diagrams to align with your IaC code without managing diagrams manually.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;As a drawing library&lt;/strong&gt;&lt;br /&gt; Use as Golang Library and integrate with other IaC tools, AI, or drawing GUI tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;&lt;br /&gt; Add definition files to create non-AWS diagrams as well.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MCP Server Integration&lt;/h2&gt; 
&lt;p&gt;The awsdac MCP server enables AI assistants and development tools to generate AWS architecture diagrams programmatically through the Model Context Protocol (MCP). This integration allows seamless diagram creation within your development workflow.&lt;/p&gt; 
&lt;h3&gt;Installation &amp;amp; MCP Client configuration&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note;&lt;/strong&gt; Currently, MCP Client Configuration depends on the MCP Client implementation. Please check the MCP client's documentation for the correct json format.&lt;/p&gt; 
&lt;h4&gt;for macOS user&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install awsdac
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;MCP Client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "awsdac-mcp-server": {
      "command": "/opt/homebrew/bin/awsdac-mcp-server",
      "args": [],
      "type": "stdio"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;MCP Client configuration with custom log:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "awsdac-mcp-server": {
      "command": "/opt/homebrew/bin/awsdac-mcp-server",
      "args": ["--log-file", "/path/to/custom/awsdac-mcp.log"],
      "type": "stdio"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;for Gopher (go 1.21 or higher)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/awslabs/diagram-as-code/cmd/awsdac-mcp-server@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "awsdac-mcp-server": {
      "command": "/Users/yourusername/go/bin/awsdac-mcp-server",
      "args": [],
      "type": "stdio"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Replace &lt;code&gt;/Users/yourusername&lt;/code&gt; with your actual home directory path.&lt;/p&gt; 
&lt;h4&gt;Finding your binary location&lt;/h4&gt; 
&lt;p&gt;If you installed via &lt;code&gt;go install&lt;/code&gt;, you can find the binary location using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Check if awsdac-mcp-server is in your PATH
which awsdac-mcp-server

# Or check common Go install locations
ls ~/go/bin/awsdac-mcp-server
ls $GOPATH/bin/awsdac-mcp-server  # if GOPATH is set
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the path returned by these commands in your MCP client configuration.&lt;/p&gt; 
&lt;h4&gt;Custom Log File (Optional)&lt;/h4&gt; 
&lt;h3&gt;Available Tools&lt;/h3&gt; 
&lt;h4&gt;generateDiagram&lt;/h4&gt; 
&lt;p&gt;Generates AWS architecture diagrams from YAML specifications and returns base64-encoded PNG images.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yamlContent&lt;/code&gt; (required): Complete YAML specification following the diagram-as-code format&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generateDiagramToFile&lt;/h4&gt; 
&lt;p&gt;Same as &lt;code&gt;generateDiagram&lt;/code&gt; but saves the image directly to a specified file path.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yamlContent&lt;/code&gt; (required): Complete YAML specification&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;outputFilePath&lt;/code&gt; (required): Path where the PNG file should be saved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;getDiagramAsCodeFormat&lt;/h4&gt; 
&lt;p&gt;Returns comprehensive format specification, examples, and best practices for creating diagram-as-code YAML files.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Generate an AWS architecture diagram showing a VPC with public and private subnets, an ALB, and EC2 instances.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, if the MCP host cannot receive large-sized image data from the MCP server, please use generateDiagramToFile to save the image data directly to a file.&lt;/p&gt; 
&lt;p&gt;To save directly to a file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Generate an AWS architecture diagram showing a VPC with public and private subnets, an ALB, and EC2 instances, then save it to /tmp/test-diagram.png.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;h4&gt;Connection Issues&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Verify the MCP server binary path in your configuration&lt;/li&gt; 
 &lt;li&gt;Check that the binary has execution permissions&lt;/li&gt; 
 &lt;li&gt;Review log files for error messages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Log Files&lt;/h4&gt; 
&lt;p&gt;By default, logs are written to &lt;code&gt;/tmp/awsdac-mcp-server.log&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To use a custom log file location, add the &lt;code&gt;--log-file&lt;/code&gt; argument to your MCP client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"args": ["--log-file", "/path/to/your/custom.log"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check the log file for detailed error messages and debugging information.&lt;/p&gt; 
&lt;h2&gt;Resource types&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/doc/resource-types.md"&gt;doc/resource-types.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Resource Link&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/doc/links.md"&gt;doc/links.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/awslabs/diagram-as-code/main/CONTRIBUTING.md#security-issue-notifications"&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache-2.0 License.&lt;/p&gt; 
&lt;h1&gt;Fix image URLs&lt;/h1&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png" /&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status" /&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack" /&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br /&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br /&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br /&gt; &lt;/strong&gt; &lt;br /&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2"&gt;https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)" /&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuard¬Æ&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector</link>
      <description>&lt;p&gt;OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.bestpractices.dev/projects/8404"&gt;&lt;img src="https://www.bestpractices.dev/projects/8404/badge" /&gt; &lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:opentelemetry"&gt; &lt;img alt="Fuzzing Status" src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/configuration/"&gt;Configuration&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector"&gt;Monitoring&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://pkg.go.dev/go.opentelemetry.io/collector"&gt;Package&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;img src="https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png" alt="OpenTelemetry Icon" width="45" height="" /&gt; OpenTelemetry Collector&lt;/h1&gt; 
&lt;p&gt;The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.&lt;/p&gt; 
&lt;p&gt;Objectives:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.&lt;/li&gt; 
 &lt;li&gt;Performant: Highly stable and performant under varying loads and configurations.&lt;/li&gt; 
 &lt;li&gt;Observable: An exemplar of an observable service.&lt;/li&gt; 
 &lt;li&gt;Extensible: Customizable without touching the core code.&lt;/li&gt; 
 &lt;li&gt;Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The OpenTelemetry Collector SIG is present at the &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;#otel-collector&lt;/a&gt; channel on the CNCF Slack and &lt;a href="https://github.com/open-telemetry/community#implementation-sigs"&gt;meets once a week&lt;/a&gt; via video calls. Everyone is invited to join those calls, which typically serves the following purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;meet the humans behind the project&lt;/li&gt; 
 &lt;li&gt;get an opinion about specific proposals&lt;/li&gt; 
 &lt;li&gt;look for a sponsor for a proposed component after trying already via GitHub and Slack&lt;/li&gt; 
 &lt;li&gt;get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We rotate our video calls between three time slots, in order to allow everyone to join at least once every three meetings. The rotation order is as follows:&lt;/p&gt; 
&lt;p&gt;Tuesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=1700"&gt;17:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Wednesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0900"&gt;09:00 PT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0500"&gt;05:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points. Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to identify who would be the other contributors interested on that topic and in which timezones they are.&lt;/p&gt; 
&lt;p&gt;Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous calls and don't want them to feel excluded.&lt;/p&gt; 
&lt;h2&gt;Supported OTLP version&lt;/h2&gt; 
&lt;p&gt;This code base is currently built against using OTLP protocol v1.5.0, considered Stable. &lt;a href="https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition"&gt;See the OpenTelemetry Protocol Stability definition here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/component-stability.md"&gt;Stability Levels and versioning&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as &lt;a href="https://go.dev/doc/devel/release#policy"&gt;defined by the Go team&lt;/a&gt;. Removing support for an unsupported Go version is not considered a breaking change.&lt;/p&gt; 
&lt;p&gt;Support for Go versions on the OpenTelemetry Collector is updated as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will add build and tests steps for the new Go minor version.&lt;/li&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will remove support for Go version &lt;code&gt;N-2&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.&lt;/p&gt; 
&lt;h2&gt;Verifying the images signatures&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To verify a signed artifact or blob, first &lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;install Cosign&lt;/a&gt;, then follow the instructions below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We are signing the images &lt;code&gt;otel/opentelemetry-collector&lt;/code&gt; and &lt;code&gt;otel/opentelemetry-collector-contrib&lt;/code&gt; using &lt;a href="https://github.com/sigstore/cosign"&gt;sigstore cosign&lt;/a&gt; tool and to verify the signatures you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&amp;lt;RELEASE_TAG&amp;gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;RELEASE_TAG&amp;gt;&lt;/code&gt;: is the release that you want to validate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;&lt;/code&gt;: is the image that you want to check&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=","Payload":{"body":"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","integratedTime":1712809120,"logIndex":84797936,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}},{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=","Payload":{"body":"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","integratedTime":1712809122,"logIndex":84797940,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We started signing the images with release &lt;code&gt;v0.95.0&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Here is a list of community roles with current and previous members:&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmathieu"&gt;Damien Mathieu&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jade-guiton-dd"&gt;Jade Guiton&lt;/a&gt;, Datadog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmacd"&gt;Joshua MacDonald&lt;/a&gt;, Microsoft&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, Datadog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating the role of the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/release.md#release-manager"&gt;release manager&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sincejune"&gt;Chao Weng&lt;/a&gt;, AppDynamics&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/james-bebbington"&gt;James Bebbington&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jrcamp"&gt;Jay Camp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paix√£o Kr√∂hling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nilebox"&gt;Nail Islamov&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/owais"&gt;Owais Lone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rghetia"&gt;Rahul Patel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sjkaris"&gt;Steven Karis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrewhsu"&gt;Andrew Hsu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thanks to all of our contributors!&lt;/h3&gt; 
&lt;a href="https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors"&gt; &lt;img alt="Repo contributors" src="https://contrib.rocks/image?repo=open-telemetry/opentelemetry-collector" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>weaviate/weaviate</title>
      <link>https://github.com/weaviate/weaviate</link>
      <description>&lt;p&gt;Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database‚Äã.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Weaviate &lt;img alt="Weaviate logo" src="https://weaviate.io/img/site/weaviate-logo-light.png" width="148" align="right" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/weaviate/weaviate"&gt;&lt;img src="https://img.shields.io/github/stars/weaviate/weaviate?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/weaviate/weaviate"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/weaviate/weaviate.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml"&gt;&lt;img src="https://github.com/weaviate/weaviate/actions/workflows/.github/workflows/pull_requests.yaml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/weaviate/weaviate"&gt;&lt;img src="https://goreportcard.com/badge/github.com/weaviate/weaviate" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/weaviate/weaviate"&gt;&lt;img src="https://codecov.io/gh/weaviate/weaviate/branch/main/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://weaviate.io/slack"&gt;&lt;img src="https://img.shields.io/badge/slack--channel-blue?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Weaviate&lt;/strong&gt; is an open-source, cloud-native vector database that stores both objects and vectors, enabling semantic search at scale. It combines vector similarity search with keyword filtering, retrieval-augmented generation (RAG), and reranking in a single query interface. Common use cases include RAG systems, semantic and image search, recommendation engines, chatbots, and content classification.&lt;/p&gt; 
&lt;p&gt;Weaviate supports two approaches to store vectors: automatic vectorization at import using &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated models&lt;/a&gt; (OpenAI, Cohere, HuggingFace, and others) or direct import of &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;pre-computed vector embeddings&lt;/a&gt;. Production deployments benefit from built-in multi-tenancy, replication, RBAC authorization, and &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#weaviate-features"&gt;many other features&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get started quickly, have a look at one of these tutorials:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart"&gt;Quickstart - Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/quickstart/local"&gt;Quickstart - local Docker instance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Weaviate offers multiple installation and deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/docker-installation"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/deploy/installation-guides/k8s-installation"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://console.weaviate.cloud"&gt;Weaviate Cloud&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.weaviate.io/deploy"&gt;installation docs&lt;/a&gt; for more deployment options, such as &lt;a href="https://docs.weaviate.io/deploy/installation-guides/aws-marketplace"&gt;AWS&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/deploy/installation-guides/gcp-marketplace"&gt;GCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;You can easily start Weaviate and a local vector embedding model with &lt;a href="https://docs.docker.com/desktop/"&gt;Docker&lt;/a&gt;. Create a &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.2
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      ENABLE_MODULES: text2vec-model2vec
      MODEL2VEC_INFERENCE_API: http://text2vec-model2vec:8080

  # A lightweight embedding model that will generate vectors from objects during import
  text2vec-model2vec:
    image: cr.weaviate.io/semitechnologies/model2vec-inference:minishlab-potion-base-32M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start Weaviate and the embedding service with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the Python client (or use another &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/#client-libraries-and-apis"&gt;client library&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U weaviate-client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The following Python example shows how easy it is to populate a Weaviate database with data, create vector embeddings and perform semantic search:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import weaviate
from weaviate.classes.config import Configure, DataType, Property

# Connect to Weaviate
client = weaviate.connect_to_local()

# Create a collection
client.collections.create(
    name="Article",
    properties=[Property(name="content", data_type=DataType.TEXT)],
    vector_config=Configure.Vectors.text2vec_model2vec(),  # Use a vectorizer to generate embeddings during import
    # vector_config=Configure.Vectors.self_provided()  # If you want to import your own pre-generated embeddings
)

# Insert objects and generate embeddings
articles = client.collections.get("Article")
articles.data.insert_many(
    [
        {"content": "Vector databases enable semantic search"},
        {"content": "Machine learning models generate embeddings"},
        {"content": "Weaviate supports hybrid search capabilities"},
    ]
)

# Perform semantic search
results = articles.query.near_text(query="Search objects by meaning", limit=1)
print(results.objects[0])

client.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example uses the &lt;code&gt;Model2Vec&lt;/code&gt; vectorizer, but you can choose any other &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;embedding model provider&lt;/a&gt; or &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;bring your own pre-generated vectors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client libraries and APIs&lt;/h2&gt; 
&lt;p&gt;Weaviate provides client libraries for several programming languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/typescript"&gt;JavaScript/TypeScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/java"&gt;Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.weaviate.io/weaviate/client-libraries/go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;C# (üöß Coming soon üöß)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are also additional &lt;a href="https://docs.weaviate.io/weaviate/client-libraries/community"&gt;community-maintained libraries&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Weaviate exposes &lt;a href="https://docs.weaviate.io/weaviate/api/rest"&gt;REST API&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/api/grpc"&gt;gRPC API&lt;/a&gt;, and &lt;a href="https://docs.weaviate.io/weaviate/api/graphql"&gt;GraphQL API&lt;/a&gt; to communicate with the database server.&lt;/p&gt; 
&lt;h2&gt;Weaviate features&lt;/h2&gt; 
&lt;p&gt;These features enable you to build AI-powered applications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Fast Search Performance&lt;/strong&gt;: Perform complex semantic &lt;a href="https://docs.weaviate.io/weaviate/search/similarity"&gt;searches&lt;/a&gt; over billions of vectors in milliseconds. Weaviate's architecture is built in Go for speed and reliability, ensuring your AI applications are highly responsive even under heavy load. See our &lt;a href="https://docs.weaviate.io/weaviate/benchmarks/ann"&gt;ANN benchmarks&lt;/a&gt; for more info.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîå Flexible Vectorization&lt;/strong&gt;: Seamlessly vectorize data at import time with &lt;a href="https://docs.weaviate.io/weaviate/model-providers"&gt;integrated vectorizers&lt;/a&gt; from OpenAI, Cohere, HuggingFace, Google, and more. Or you can import &lt;a href="https://docs.weaviate.io/weaviate/starter-guides/custom-vectors"&gt;your own vector embeddings&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Advanced Hybrid &amp;amp; Image Search&lt;/strong&gt;: Combine the power of semantic search with traditional &lt;a href="https://docs.weaviate.io/weaviate/search/bm25"&gt;keyword (BM25) search&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/search/image"&gt;image search&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/filters"&gt;advanced filtering&lt;/a&gt; to get the best results with a single API call.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ü§ñ Integrated RAG &amp;amp; Reranking&lt;/strong&gt;: Go beyond simple retrieval with built-in &lt;a href="https://docs.weaviate.io/weaviate/search/generative"&gt;generative search (RAG)&lt;/a&gt; and &lt;a href="https://docs.weaviate.io/weaviate/search/rerank"&gt;reranking&lt;/a&gt; capabilities. Power sophisticated Q&amp;amp;A systems, chatbots, and summarizers directly from your database without additional tooling.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìà Production-Ready &amp;amp; Scalable&lt;/strong&gt;: Weaviate is built for mission-critical applications. Go from rapid prototyping to production at scale with native support for &lt;a href="https://docs.weaviate.io/deploy/configuration/horizontal-scaling"&gt;horizontal scaling&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/weaviate/manage-collections/multi-tenancy"&gt;multi-tenancy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/deploy/configuration/replication"&gt;replication&lt;/a&gt;, and fine-grained &lt;a href="https://docs.weaviate.io/weaviate/configuration/rbac"&gt;role-based access control (RBAC)&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üí∞ Cost-Efficient Operations&lt;/strong&gt;: Radically lower resource consumption and operational costs with built-in &lt;a href="https://docs.weaviate.io/weaviate/configuration/compression"&gt;vector compression&lt;/a&gt;. Vector quantization and multi-vector encoding reduce memory usage with minimal impact on search performance.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a complete list of all functionalities, visit the &lt;a href="https://docs.weaviate.io"&gt;official Weaviate documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Useful resources&lt;/h2&gt; 
&lt;h3&gt;Demo projects &amp;amp; recipes&lt;/h3&gt; 
&lt;p&gt;These demos are working applications that highlight some of Weaviate's capabilities. Their source code is available on GitHub.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://elysia.weaviate.io"&gt;Elysia&lt;/a&gt; (&lt;a href="https://github.com/weaviate/elysia"&gt;GitHub&lt;/a&gt;): Elysia is a decision tree based agentic system which intelligently decides what tools to use, what results have been obtained, whether it should continue the process or whether its goal has been completed.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://verba.weaviate.io"&gt;Verba&lt;/a&gt; (&lt;a href="https://github.com/weaviate/verba"&gt;GitHub&lt;/a&gt;): A community-driven open-source application designed to offer an end-to-end, streamlined, and user-friendly interface for Retrieval-Augmented Generation (RAG) out of the box.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://healthsearch.weaviate.io"&gt;Healthsearch&lt;/a&gt; (&lt;a href="https://github.com/weaviate/healthsearch-demo"&gt;GitHub&lt;/a&gt;): An open-source project aimed at showcasing the potential of leveraging user-written reviews and queries to retrieve supplement products based on specific health effects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://awesome-moviate.weaviate.io/"&gt;Awesome-Moviate&lt;/a&gt; (&lt;a href="https://github.com/weaviate-tutorials/awesome-moviate"&gt;GitHub&lt;/a&gt;): A movie search and recommendation engine that allows keyword-based (BM25), semantic, and hybrid searches.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also maintain extensive repositories of &lt;strong&gt;Jupyter Notebooks&lt;/strong&gt; and &lt;strong&gt;TypeScript code snippets&lt;/strong&gt; that cover how to use Weaviate features and integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes/"&gt;Weaviate Python Recipes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/weaviate/recipes-ts/"&gt;Weaviate TypeScript Recipes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Blog posts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-a-vector-database"&gt;What is a Vector Database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/vector-search-explained"&gt;What is Vector Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/hybrid-search-explained"&gt;What is Hybrid Search&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/how-to-choose-an-embedding-model"&gt;How to Choose an Embedding Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/introduction-to-rag"&gt;What is RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/rag-evaluation"&gt;RAG Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/advanced-rag"&gt;Advanced RAG Techniques&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/multimodal-rag"&gt;What is Multimodal RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/what-is-agentic-rag"&gt;What is Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/graph-rag"&gt;What is Graph RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weaviate.io/blog/late-interaction-overview"&gt;Overview of Late Interaction Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;p&gt;Weaviate integrates with many external services:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Integrations&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers"&gt;Cloud Hyperscalers&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Large-scale computing and storage&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/aws"&gt;AWS&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/cloud-hyperscalers/google"&gt;Google&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure"&gt;Compute Infrastructure&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Run and scale containerized applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/modal"&gt;Modal&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicate"&gt;Replicate&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/compute-infrastructure/replicated"&gt;Replicated&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms"&gt;Data Platforms&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data ingestion and web scraping&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/data-platforms/airbyte"&gt;Airbyte&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/aryn"&gt;Aryn&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/boomi"&gt;Boomi&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/box"&gt;Box&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/confluent"&gt;Confluent&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/astronomer"&gt;Astronomer&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/context-data"&gt;Context Data&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/databricks"&gt;Databricks&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/firecrawl"&gt;Firecrawl&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/ibm"&gt;IBM&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/data-platforms/unstructured"&gt;Unstructured&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks"&gt;LLM and Agent Frameworks&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build agents and generative AI applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/agno"&gt;Agno&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/composio"&gt;Composio&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/crewai"&gt;CrewAI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dspy"&gt;DSPy&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/dynamiq"&gt;Dynamiq&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/haystack"&gt;Haystack&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/langchain"&gt;LangChain&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/llamaindex"&gt;LlamaIndex&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/n8n"&gt;N8n&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/llm-agent-frameworks/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://docs.weaviate.io/integrations/operations"&gt;Operations&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Tools for monitoring and analyzing generative AI workflows&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.weaviate.io/integrations/operations/aimon"&gt;AIMon&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/arize"&gt;Arize&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/cleanlab"&gt;Cleanlab&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/comet"&gt;Comet&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/deepeval"&gt;DeepEval&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langtrace"&gt;Langtrace&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/langwatch"&gt;LangWatch&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/nomic"&gt;Nomic&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/patronus"&gt;Patronus AI&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/ragas"&gt;Ragas&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/trulens"&gt;TruLens&lt;/a&gt;, &lt;a href="https://docs.weaviate.io/integrations/operations/wandb"&gt;Weights &amp;amp; Biases&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and appreciate contributions! Please see our &lt;a href="https://docs.weaviate.io/contributor-guide"&gt;Contributor guide&lt;/a&gt; for the development setup, code style guidelines, testing requirements and the pull request process.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://weaviate.io/slack"&gt;Slack community&lt;/a&gt; or &lt;a href="https://forum.weaviate.io/"&gt;Community forum&lt;/a&gt; to discuss ideas and get help.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BSD 3-Clause License. See &lt;a href="https://raw.githubusercontent.com/weaviate/weaviate/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aquasecurity/trivy</title>
      <link>https://github.com/aquasecurity/trivy</link>
      <description>&lt;p&gt;Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/logo.png" width="200" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml"&gt;&lt;img src="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/aquasecurity/trivy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/aquasecurity/trivy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;amp;label=docker%20pulls%20%2F%20trivy" alt="Docker Pulls" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trivy.dev/latest/docs/"&gt;üìñ Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Trivy (&lt;a href="https://raw.githubusercontent.com/aquasecurity/trivy/main/#how-to-pronounce-the-name-trivy"&gt;pronunciation&lt;/a&gt;) is a comprehensive and versatile security scanner. Trivy has &lt;em&gt;scanners&lt;/em&gt; that look for security issues, and &lt;em&gt;targets&lt;/em&gt; where it can find those issues.&lt;/p&gt; 
&lt;p&gt;Targets (what Trivy can scan):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Container Image&lt;/li&gt; 
 &lt;li&gt;Filesystem&lt;/li&gt; 
 &lt;li&gt;Git Repository (remote)&lt;/li&gt; 
 &lt;li&gt;Virtual Machine Image&lt;/li&gt; 
 &lt;li&gt;Kubernetes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Scanners (what Trivy can find there):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS packages and software dependencies in use (SBOM)&lt;/li&gt; 
 &lt;li&gt;Known vulnerabilities (CVEs)&lt;/li&gt; 
 &lt;li&gt;IaC issues and misconfigurations&lt;/li&gt; 
 &lt;li&gt;Sensitive information and secrets&lt;/li&gt; 
 &lt;li&gt;Software licenses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the &lt;a href="https://trivy.dev/latest/docs/coverage/"&gt;Scanning Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;To learn more, go to the &lt;a href="https://trivy.dev"&gt;Trivy homepage&lt;/a&gt; for feature highlights, or to the &lt;a href="https://trivy.dev/latest/docs/"&gt;Documentation site&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Get Trivy&lt;/h3&gt; 
&lt;p&gt;Trivy is available in most common distribution channels. The full list of installation options is available in the &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker run aquasec/trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Download binary from &lt;a href="https://github.com/aquasecurity/trivy/releases/latest/"&gt;https://github.com/aquasecurity/trivy/releases/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-action"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-operator"&gt;Kubernetes operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-vscode-extension"&gt;VS Code plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Canary builds&lt;/h3&gt; 
&lt;p&gt;There are canary builds (&lt;a href="https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;amp;name=canary"&gt;Docker Hub&lt;/a&gt;, &lt;a href="https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gallery.ecr.aws/aquasecurity/trivy#canary"&gt;ECR&lt;/a&gt; images and &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml"&gt;binaries&lt;/a&gt;) as generated every push to main branch.&lt;/p&gt; 
&lt;p&gt;Please be aware: canary builds might have critical bugs, it's not recommended for use in production.&lt;/p&gt; 
&lt;h3&gt;General usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy &amp;lt;target&amp;gt; [--scanners &amp;lt;scanner1,scanner2&amp;gt;] &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy image python:3.4-alpine
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov"&gt;https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy fs --scanners vuln,secret,misconfig myproject/
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov"&gt;https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy k8s --report summary cluster
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/trivy-k8s.png" alt="k8s summary" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How to pronounce the name "Trivy"?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tri&lt;/code&gt; is pronounced like &lt;strong&gt;tri&lt;/strong&gt;gger, &lt;code&gt;vy&lt;/code&gt; is pronounced like en&lt;strong&gt;vy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Want more? Check out Aqua&lt;/h2&gt; 
&lt;p&gt;If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.&lt;br /&gt; You can find a high level comparison table specific to Trivy users &lt;a href="https://trivy.dev/latest/commercial/compare/"&gt;here&lt;/a&gt;. In addition check out the &lt;a href="https://aquasec.com"&gt;https://aquasec.com&lt;/a&gt; website for more information about our products and services. If you'd like to contact Aqua or request a demo, please use this form: &lt;a href="https://www.aquasec.com/demo"&gt;https://www.aquasec.com/demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Trivy is an &lt;a href="https://aquasec.com"&gt;Aqua Security&lt;/a&gt; open source project.&lt;br /&gt; Learn about our open source work and portfolio &lt;a href="https://www.aquasec.com/products/open-source-projects/"&gt;here&lt;/a&gt;.&lt;br /&gt; Contact us about any matter by opening a GitHub Discussion &lt;a href="https://github.com/aquasecurity/trivy/discussions"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please ensure to abide by our &lt;a href="https://github.com/aquasecurity/community/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; during all interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/loki</title>
      <link>https://github.com/grafana/loki</link>
      <description>&lt;p&gt;Like Prometheus, but for logs.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/grafana/loki/main/docs/sources/logo_and_name.png" alt="Loki Logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grafana/loki/actions/workflows/check.yml"&gt;&lt;img src="https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg?sanitize=true" alt="Check" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/grafana/loki"&gt;&lt;img src="https://goreportcard.com/badge/github.com/grafana/loki" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://slack.grafana.com/"&gt;&lt;img src="https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg?sanitize=true" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:loki"&gt;&lt;img src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg?sanitize=true" alt="Fuzzing Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Loki: like Prometheus, but for logs.&lt;/h1&gt; 
&lt;p&gt;Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt;. It is designed to be very cost effective and easy to operate. It does not index the contents of the logs, but rather a set of labels for each log stream.&lt;/p&gt; 
&lt;p&gt;Compared to other log aggregation systems, Loki:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.&lt;/li&gt; 
 &lt;li&gt;indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.&lt;/li&gt; 
 &lt;li&gt;is an especially good fit for storing &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; Pod logs. Metadata such as Pod labels is automatically scraped and indexed.&lt;/li&gt; 
 &lt;li&gt;has native support in Grafana (needs Grafana v6.0).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;A Loki-based logging stack consists of 3 components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/alloy"&gt;Alloy&lt;/a&gt; is agent, responsible for gathering logs and sending them to Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/loki"&gt;Loki&lt;/a&gt; is the main service, responsible for storing logs and processing queries.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/grafana"&gt;Grafana&lt;/a&gt; for querying and displaying the logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in &lt;a href="https://github.com/grafana/alloy"&gt;Grafana Alloy&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Loki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies. Loki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/installation/"&gt;Installing Loki&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/send-data/alloy/"&gt;Installing Alloy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/get-started/"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upgrading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/upgrading/"&gt;Upgrading Loki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/"&gt;Latest release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/next/"&gt;Upcoming release&lt;/a&gt;, at the tip of the main branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Commonly used sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/api/"&gt;API documentation&lt;/a&gt; for getting logs into Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/getting-started/labels/"&gt;Labels&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/"&gt;Operations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/promtail/"&gt;Promtail&lt;/a&gt; is an agent which tails log files and pushes them to Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/promtail/pipelines/"&gt;Pipelines&lt;/a&gt; details the log processing pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/docker-driver/"&gt;Docker Driver Client&lt;/a&gt; is a Docker plugin to send logs directly to Loki from Docker containers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/query/logcli/"&gt;LogCLI&lt;/a&gt; provides a command-line interface for querying logs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/loki-canary/"&gt;Loki Canary&lt;/a&gt; monitors your Loki installation for missing logs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/troubleshooting/"&gt;Troubleshooting&lt;/a&gt; presents help dealing with error messages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/grafana/"&gt;Loki in Grafana&lt;/a&gt; describes how to set up a Loki datasource in Grafana.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback regarding Loki:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search existing thread in the Grafana Labs community forum for Loki: &lt;a href="https://community.grafana.com/c/grafana-loki/"&gt;https://community.grafana.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit &lt;a href="https://slack.grafana.com/"&gt;https://slack.grafana.com/&lt;/a&gt; and join the #loki channel.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/loki/issues/new"&gt;File an issue&lt;/a&gt; for bugs, issues and feature suggestions.&lt;/li&gt; 
 &lt;li&gt;Send an email to &lt;a href="mailto:lokiproject@googlegroups.com"&gt;lokiproject@googlegroups.com&lt;/a&gt;, or use the &lt;a href="https://groups.google.com/forum/#!forum/lokiproject"&gt;web interface&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;UI issues should be filed directly in &lt;a href="https://github.com/grafana/grafana/issues/new"&gt;Grafana&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your feedback is always welcome.&lt;/p&gt; 
&lt;h2&gt;Further Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The original &lt;a href="https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view"&gt;design doc&lt;/a&gt; for Loki is a good source for discussion of the motivation and design decisions.&lt;/li&gt; 
 &lt;li&gt;Callum Styan's March 2019 DevOpsDays Vancouver talk "&lt;a href="https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs--and-saves-you-money/"&gt;Grafana Loki: Log Aggregation for Incident Investigations&lt;/a&gt;".&lt;/li&gt; 
 &lt;li&gt;Grafana Labs blog post "&lt;a href="https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/"&gt;How We Designed Loki to Work Easily Both as Microservices and as Monoliths&lt;/a&gt;".&lt;/li&gt; 
 &lt;li&gt;Tom Wilkie's early-2019 CNCF Paris/FOSDEM talk "&lt;a href="https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/"&gt;Grafana Loki: like Prometheus, but for logs&lt;/a&gt;" (&lt;a href="https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs"&gt;slides&lt;/a&gt;, &lt;a href="https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4"&gt;video&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;David Kaltschmidt's KubeCon 2018 talk "&lt;a href="https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs"&gt;On the OSS Path to Full Observability with Grafana&lt;/a&gt;" (&lt;a href="https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki"&gt;slides&lt;/a&gt;, &lt;a href="https://www.youtube.com/watch?v=U7C5SpRtK74&amp;amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&amp;amp;index=346"&gt;video&lt;/a&gt;) on how Loki fits into a cloud-native environment.&lt;/li&gt; 
 &lt;li&gt;Goutham Veeramachaneni's blog post "&lt;a href="https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/"&gt;Loki: Prometheus-inspired, open source logging for cloud natives&lt;/a&gt;" on details of the Loki architecture.&lt;/li&gt; 
 &lt;li&gt;David Kaltschmidt's blog post "&lt;a href="https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/"&gt;Closer look at Grafana's user interface for Loki&lt;/a&gt;" on the ideas that went into the logging user interface.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Building from source&lt;/h3&gt; 
&lt;p&gt;Loki can be run in a single host, no-dependencies mode using the following commands.&lt;/p&gt; 
&lt;p&gt;You need an up-to-date version of &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;, we recommend using the version found in our &lt;a href="https://github.com/grafana/loki/raw/main/Makefile"&gt;Makefile&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Checkout source code
$ git clone https://github.com/grafana/loki
$ cd loki

# Build binary
$ go build ./cmd/loki

# Run executable
$ ./loki -config.file=./cmd/loki/loki-local-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, on Unix systems you can use &lt;code&gt;make&lt;/code&gt; to build the binary, which adds additional arguments to the &lt;code&gt;go build&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build binary
$ make loki

# Run executable
$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build Promtail on non-Linux platforms, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ go build ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Linux, Promtail requires the systemd headers to be installed if Journal support is enabled. To enable Journal support the go build tag flag &lt;code&gt;promtail_journal_enabled&lt;/code&gt; should be passed&lt;/p&gt; 
&lt;p&gt;With Journal support on Ubuntu, run with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo apt install -y libsystemd-dev
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With Journal support on CentOS, run with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo yum install -y systemd-devel
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Otherwise, to build Promtail without Journal support, run &lt;code&gt;go build&lt;/code&gt; with CGO disabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ CGO_ENABLED=0 go build ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt; for some of the organizations using Loki today. If you would like to add your organization to the list, please open a PR to add it to the list.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Grafana Loki is distributed under &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/LICENSE"&gt;AGPL-3.0-only&lt;/a&gt;. For Apache-2.0 exceptions, see &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/LICENSING.md"&gt;LICENSING.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SagerNet/sing-box</title>
      <link>https://github.com/SagerNet/sing-box</link>
      <description>&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;Sponsored by &lt;a href="https://go.warp.dev/sing-box"&gt;Warp&lt;/a&gt;, built for coding with multiple AI agents&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://go.warp.dev/sing-box"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;sing-box&lt;/h1&gt; 
&lt;p&gt;The universal proxy platform.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/sing-box/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/sing-box.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://sing-box.sagernet.org"&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>moby/moby</title>
      <link>https://github.com/moby/moby</link>
      <description>&lt;p&gt;The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Moby Project&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/moby/moby/v2"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/moby/moby/v2" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/moby/moby" alt="GitHub License" /&gt; &lt;a href="https://goreportcard.com/report/github.com/moby/moby/v2"&gt;&lt;img src="https://goreportcard.com/badge/github.com/moby/moby/v2" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/moby/moby"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/moby/moby/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10989"&gt;&lt;img src="https://www.bestpractices.dev/projects/10989/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/moby/moby/master/docs/static_files/moby-project-logo.png" alt="Moby Project logo" title="The Moby Project" /&gt;&lt;/p&gt; 
&lt;p&gt;Moby is an open-source project created by Docker to enable and accelerate software containerization.&lt;/p&gt; 
&lt;p&gt;It provides a "Lego set" of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas. Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;p&gt;Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience. It is open to the community to help set its direction.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modular: the project includes lots of components that have well-defined functions and APIs that work together.&lt;/li&gt; 
 &lt;li&gt;Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.&lt;/li&gt; 
 &lt;li&gt;Usable security: Moby provides secure defaults without compromising usability.&lt;/li&gt; 
 &lt;li&gt;Developer focused: The APIs are intended to be functional and useful to build powerful tools. They are not necessarily intended as end user tools but as components aimed at developers. Documentation and UX is aimed at developers not end users.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Audience&lt;/h2&gt; 
&lt;p&gt;The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers. It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.&lt;/p&gt; 
&lt;h2&gt;Relationship with Docker&lt;/h2&gt; 
&lt;p&gt;The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project. New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product. However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.&lt;/p&gt; 
&lt;p&gt;The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful. The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; and &lt;a href="https://www.mirantis.com/software/mirantis-container-runtime/"&gt;Mirantis Container Runtime&lt;/a&gt; are the appropriate products for these use cases.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Legal&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Brought to you courtesy of our legal counsel. For more context, please see the &lt;a href="https://github.com/moby/moby/raw/master/NOTICE"&gt;NOTICE&lt;/a&gt; document in this repo.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Use and transfer of Moby may be subject to certain restrictions by the United States and other governments.&lt;/p&gt; 
&lt;p&gt;It is your responsibility to ensure that your use and/or transfer does not violate applicable laws.&lt;/p&gt; 
&lt;p&gt;For more information, please see &lt;a href="https://www.bis.doc.gov"&gt;https://www.bis.doc.gov&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Licensing&lt;/h1&gt; 
&lt;p&gt;Moby is licensed under the Apache License, Version 2.0. See &lt;a href="https://github.com/moby/moby/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/mimir</title>
      <link>https://github.com/grafana/mimir</link>
      <description>&lt;p&gt;Grafana Mimir provides horizontally scalable, highly available, multi-tenant, long-term storage for Prometheus.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Grafana Mimir&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/grafana/mimir/main/images/logo.png" alt="Grafana Mimir logo" width="400" /&gt;&lt;/p&gt; 
&lt;p&gt;Grafana Mimir is an open source software project that provides a scalable long-term storage for &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;. Some of the core strengths of Grafana Mimir include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to install and maintain:&lt;/strong&gt; Grafana Mimir‚Äôs extensive documentation, tutorials, and deployment tooling make it quick to get started. Using its monolithic mode, you can get Grafana Mimir up and running with just one binary and no additional dependencies. Once deployed, the best-practice dashboards, alerts, and runbooks packaged with Grafana Mimir make it easy to monitor the health of the system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Massive scalability:&lt;/strong&gt; You can run Grafana Mimir's horizontally-scalable architecture across multiple machines, resulting in the ability to process orders of magnitude more time series than a single Prometheus instance. Internal testing shows that Grafana Mimir handles up to 1 billion active time series.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global view of metrics:&lt;/strong&gt; Grafana Mimir enables you to run queries that aggregate series from multiple Prometheus instances, giving you a global view of your systems. Its query engine extensively parallelizes query execution, so that even the highest-cardinality queries complete with blazing speed.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cheap, durable metric storage:&lt;/strong&gt; Grafana Mimir uses object storage for long-term data storage, allowing it to take advantage of this ubiquitous, cost-effective, high-durability technology. It is compatible with multiple object store implementations, including AWS S3, Google Cloud Storage, Azure Blob Storage, OpenStack Swift, as well as any S3-compatible object storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High availability:&lt;/strong&gt; Grafana Mimir replicates incoming metrics, ensuring that no data is lost in the event of machine failure. Its horizontally scalable architecture also means that it can be restarted, upgraded, or downgraded with zero downtime, which means no interruptions to metrics ingestion or querying.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Natively multi-tenant:&lt;/strong&gt; Grafana Mimir‚Äôs multi-tenant architecture enables you to isolate data and queries from independent teams or business units, making it possible for these groups to share the same cluster. Advanced limits and quality-of-service controls ensure that capacity is shared fairly among tenants.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Migrating to Grafana Mimir&lt;/h2&gt; 
&lt;p&gt;If you're migrating to Grafana Mimir, refer to the following documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-thanos-or-prometheus/"&gt;Migrating from Thanos or Prometheus to Grafana Mimir&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/set-up/migrate/migrate-from-cortex/"&gt;Migrating from Cortex to Grafana Mimir&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Deploying Grafana Mimir&lt;/h2&gt; 
&lt;p&gt;For information about how to deploy Grafana Mimir, refer to &lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/deploy-grafana-mimir/"&gt;Deploy Grafana Mimir&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;If you‚Äôre new to Grafana Mimir, read the &lt;a href="https://grafana.com/docs/mimir/latest/get-started/"&gt;Get started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Before deploying Grafana Mimir in a production environment, read:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/architecture/"&gt;An overview of Grafana Mimir‚Äôs architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/configure/"&gt;Configure Grafana Mimir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/operators-guide/run-production-environment/"&gt;Run Grafana Mimir in production&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Refer to the following links to access Grafana Mimir documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/latest/"&gt;Latest release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/mimir/next/"&gt;Upcoming release&lt;/a&gt;, at the tip of the &lt;code&gt;main&lt;/code&gt; branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to Grafana Mimir, refer to &lt;a href="https://github.com/grafana/mimir/tree/main/docs/internal/contributing"&gt;Contributing to Grafana Mimir&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Join the Grafana Mimir discussion&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback regarding Grafana Mimir, join the &lt;a href="https://github.com/grafana/mimir/discussions"&gt;Grafana Mimir Discussion&lt;/a&gt;. Alternatively, consider joining the monthly &lt;a href="https://docs.google.com/document/d/1E4jJcGicvLTyMEY6cUFFZUg_I8ytrBuW8r5yt1LyMv4"&gt;Grafana Mimir Community Call&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your feedback is always welcome, and you can also share it via the &lt;a href="https://slack.grafana.com/"&gt;&lt;code&gt;#mimir&lt;/code&gt; Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Grafana Mimir is distributed under &lt;a href="https://raw.githubusercontent.com/grafana/mimir/main/LICENSE"&gt;AGPL-3.0-only&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zitadel/zitadel</title>
      <link>https://github.com/zitadel/zitadel</link>
      <description>&lt;p&gt;ZITADEL - Identity infrastructure, simplified for¬†you.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/zitadel/zitadel/main/docs/static/logos/zitadel-logo-dark@2x.png#gh-light-mode-only" alt="Zitadel Logo" max-height="200px" width="auto" /&gt; &lt;img src="https://raw.githubusercontent.com/zitadel/zitadel/main/docs/static/logos/zitadel-logo-light@2x.png#gh-dark-mode-only" alt="Zitadel Logo" max-height="200px" width="auto" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/zitadel/zitadel" alt="Open in Dev Container"&gt; &lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue" /&gt; &lt;/a&gt; &lt;a href="https://github.com/zitadel/zitadel/raw/main/LICENSE" alt="License"&gt; &lt;img src="https://badgen.net/github/license/zitadel/zitadel/" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/6662"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6662/badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/semantic-release/semantic-release" alt="semantic-release"&gt; &lt;img src="https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zitadel/zitadel/actions" alt="ZITADEL Release"&gt; &lt;img alt="GitHub Workflow Status (with event)" src="https://img.shields.io/github/actions/workflow/status/zitadel/zitadel/build.yml?event=pull_request" /&gt;&lt;/a&gt; &lt;a href="https://zitadel.com/docs/support/software-release-cycles-support" alt="Release"&gt; &lt;img src="https://badgen.net/github/release/zitadel/zitadel/stable" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/zitadel/zitadel" alt="Go Report Card"&gt; &lt;img src="https://goreportcard.com/badge/github.com/zitadel/zitadel" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/zitadel/zitadel" alt="Code Coverage"&gt; &lt;img src="https://codecov.io/gh/zitadel/zitadel/branch/main/graph/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zitadel/zitadel/graphs/contributors" alt="Release"&gt; &lt;img alt="GitHub contributors" src="https://img.shields.io/github/contributors/zitadel/zitadel" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YgjEuJzZ3x" alt="Discord Chat"&gt; &lt;img src="https://badgen.net/discord/online-members/YgjEuJzZ3x" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://openid.net/certification/#OPs" alt="OpenID Connect Certified"&gt; &lt;img src="https://raw.githubusercontent.com/zitadel/zitadel/main/docs/static/logos/oidc-cert.png" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Are you searching for a user management tool that is quickly set up like Auth0 and open source like Keycloak?&lt;/p&gt; 
&lt;p&gt;Do you have a project that requires multi-tenant user management with self-service for your customers?&lt;/p&gt; 
&lt;p&gt;Look no further ‚Äî ZITADEL is the identity infrastructure, simplified for you.&lt;/p&gt; 
&lt;p&gt;We provide you with a wide range of out-of-the-box features to accelerate your project, including:&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚úÖ&lt;/span&gt; Multi-tenancy with team management&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; Secure login&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; Self-service&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; OpenID Connect&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; OAuth2.x&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; SAML2&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; LDAP&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; Passkeys / FIDO2&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; OTP&lt;br /&gt; &lt;span&gt;‚úÖ&lt;/span&gt; SCIM 2.0 Server and an unlimited audit trail is there for you, ready to use.&lt;/p&gt; 
&lt;p&gt;With ZITADEL, you are assured of a robust and customizable turnkey solution for all your authentication and authorization needs.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://zitadel.com"&gt;üè° Website&lt;/a&gt; &lt;a href="https://zitadel.com/chat"&gt;üí¨ Chat&lt;/a&gt; &lt;a href="https://zitadel.com/docs/"&gt;üìã Docs&lt;/a&gt; &lt;a href="https://zitadel.com/blog"&gt;üßë‚Äçüíª Blog&lt;/a&gt; &lt;a href="https://zitadel.com/contact/"&gt;üìû Contact&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;üëâ &lt;a href="https://zitadel.com/docs/guides/start/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Deploy ZITADEL (Self-Hosted)&lt;/h3&gt; 
&lt;p&gt;Deploying ZITADEL locally takes less than 3 minutes. Go ahead and give it a try!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/deploy/linux"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/deploy/macos"&gt;MacOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/deploy/compose"&gt;Docker compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/deploy/kubernetes"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See all guides &lt;a href="https://zitadel.com/docs/self-hosting/deploy/overview"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you are interested to get professional support for your self-hosted ZITADEL &lt;a href="https://zitadel.com/contact"&gt;please reach out to us&lt;/a&gt;!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Setup ZITADEL Cloud (SaaS)&lt;/h3&gt; 
&lt;p&gt;If you want to experience a hands-free ZITADEL, you should use &lt;a href="https://zitadel.com"&gt;ZITADEL Cloud&lt;/a&gt;. Available data regions are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üá∫üá∏ United States&lt;/li&gt; 
 &lt;li&gt;üá™üá∫ European Union&lt;/li&gt; 
 &lt;li&gt;üá¶üá∫ Australia&lt;/li&gt; 
 &lt;li&gt;üá®üá≠ Switzerland&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ZITADEL Cloud comes with a free tier, providing you with all the same features as the open-source version. Learn more about the &lt;a href="https://zitadel.com/pricing"&gt;pay-as-you-go pricing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;We are grateful to the organizations and individuals who are using ZITADEL. If you are using ZITADEL, please consider adding your name to our &lt;a href="https://raw.githubusercontent.com/zitadel/zitadel/main/ADOPTERS.md"&gt;Adopters list&lt;/a&gt; by submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Example applications&lt;/h3&gt; 
&lt;p&gt;Clone one of our &lt;a href="https://zitadel.com/docs/sdk-examples/introduction"&gt;example applications&lt;/a&gt; or deploy them directly to Vercel.&lt;/p&gt; 
&lt;h3&gt;SDKs&lt;/h3&gt; 
&lt;p&gt;Use our &lt;a href="https://zitadel.com/docs/sdk-examples/introduction"&gt;SDKs&lt;/a&gt; for your favorite language and framework.&lt;/p&gt; 
&lt;h2&gt;Why choose ZITADEL&lt;/h2&gt; 
&lt;p&gt;We built ZITADEL with a complex multi-tenancy architecture in mind and provide the best solution to handle &lt;a href="https://zitadel.com/docs/guides/solution-scenarios/b2b"&gt;B2B customers and partners&lt;/a&gt;. Yet it offers everything you need for a customer identity (&lt;a href="https://zitadel.com/docs/guides/solution-scenarios/b2c"&gt;CIAM&lt;/a&gt;) use case.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/apis/introduction"&gt;API-first approach&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/solution-scenarios/b2b"&gt;Multi-tenancy&lt;/a&gt; authentication and access management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/features/audit-trail"&gt;Strong audit trail&lt;/a&gt; thanks to &lt;a href="https://zitadel.com/docs/concepts/eventstore/overview"&gt;event sourcing&lt;/a&gt; as storage pattern&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/apis/actions/introduction"&gt;Actions&lt;/a&gt; to react on events with custom code and extended ZITADEL for you needs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/manage/customize/branding"&gt;Branding&lt;/a&gt; for a uniform user experience across multiple organizations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/features/selfservice"&gt;Self-service&lt;/a&gt; for end-users, business customers, and administrators&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.postgresql.org/"&gt;Postgres&lt;/a&gt; database as reliable and widespread storage option&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Authentication&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Single Sign On (SSO)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/features/passkeys"&gt;Passkeys support (FIDO2 / WebAuthN)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Username / Password&lt;/li&gt; 
 &lt;li&gt;Multifactor authentication with OTP, U2F, Email OTP, SMS OTP&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/identity-providers/ldap"&gt;LDAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/identity-providers/introduction"&gt;External enterprise identity providers and social logins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/solution-scenarios/device-authorization"&gt;Device authorization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openid.net/certification/#OPs"&gt;OpenID Connect certified&lt;/a&gt; =&amp;gt; &lt;a href="https://zitadel.com/docs/apis/openidoauth/endpoints"&gt;OIDC Endpoints&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html"&gt;SAML 2.0&lt;/a&gt; =&amp;gt; &lt;a href="https://zitadel.com/docs/apis/saml/endpoints"&gt;SAML Endpoints&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/login-ui/username-password"&gt;Custom sessions&lt;/a&gt; if you need to go beyond OIDC or SAML&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/service-users/authenticate-service-users"&gt;Machine-to-machine&lt;/a&gt; with JWT profile, Personal Access Tokens (PAT), and Client Credentials&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/token-exchange"&gt;Token exchange and impersonation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta"&gt;Beta: Hosted Login V2&lt;/a&gt; our new Login version 2.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Multi-Tenancy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/identity-brokering"&gt;Identity Brokering&lt;/a&gt; with templates for popular identity providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/solution-scenarios/onboarding"&gt;Customizable onboaring&lt;/a&gt; for B2B and their users&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/manage/console/projects"&gt;Delegate role management to third-parties&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/solution-scenarios/domain-discovery"&gt;Domain discovery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Integration&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/apis/introduction"&gt;GRPC and REST APIs&lt;/a&gt; for every functionality and resource&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/apis/actions/introduction"&gt;Actions&lt;/a&gt; to call any API, send webhooks, adjust workflows, or customize tokens&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/retrieve-user-roles"&gt;Role Based Access Control (RBAC)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/apis/scim2"&gt;SCIM 2.0 Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/sdk-examples/introduction"&gt;Examples and SDKs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/external-audit-log"&gt;Audit Log and SOC/SIEM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/onboarding"&gt;User registration and onboarding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/integrate/login/login-users"&gt;Hosted and custom Login user interface&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Self-Service&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/features/selfservice#registration"&gt;Self-registration&lt;/a&gt; including verification&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/features/selfservice"&gt;Self-service&lt;/a&gt; for end-users, business customers, and administrators&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/guides/manage/console/overview"&gt;Administration UI (Console)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Deployment&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/manage/database#postgres"&gt;Postgres&lt;/a&gt; (version &amp;gt;= 14)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/concepts/architecture/solution#zero-downtime-updates"&gt;Zero Downtime Updates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zitadel.com/docs/self-hosting/manage/production"&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Track upcoming features on our &lt;a href="https://zitadel.com/roadmap"&gt;roadmap&lt;/a&gt; and follow our &lt;a href="https://zitadel.com/changelog"&gt;changelog&lt;/a&gt; for recent updates.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Find details about how you can contribute in our &lt;a href="https://raw.githubusercontent.com/zitadel/zitadel/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;. Join our &lt;a href="https://zitadel.com/chat"&gt;Discord Chat&lt;/a&gt; to get help.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/zitadel/zitadel/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=zitadel/zitadel" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks/preview?repo=zitadel/zitadel"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Showcase&lt;/h2&gt; 
&lt;h3&gt;Quick Start Guide&lt;/h3&gt; 
&lt;p&gt;Secure a React Application using OpenID Connect Authorization Code with PKCE&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=5THbQljoPKg" title="Quick Start Guide"&gt;&lt;img src="https://user-images.githubusercontent.com/1366906/223662449-f17b734d-405c-4945-a8a1-200440c459e5.gif" alt="Quick Start Guide" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Login with Passkeys&lt;/h3&gt; 
&lt;p&gt;Use our Login widget to allow easy and secure access to your applications and enjoy all the benefits of Passkeys (FIDO 2 / WebAuthN):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=cZjHQYurSjw&amp;amp;list=PLTDa7jTlOyRLdABgD2zL0LGM7rx5GZ1IR&amp;amp;index=2" title="Passkeys"&gt;&lt;img src="https://user-images.githubusercontent.com/1366906/223664178-4132faef-4832-4014-b9ab-90c2a8d15436.gif" alt="Passkeys" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Admin Console&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://zitadel.com/docs/guides/manage/console/overview"&gt;Console&lt;/a&gt; or our &lt;a href="https://zitadel.com/docs/apis/introduction"&gt;APIs&lt;/a&gt; to setup organizations, projects and applications.&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://www.youtube.com/watch?v=RPpHktAcCtk" title="Console Showcase"&gt;&lt;img src="https://user-images.githubusercontent.com/1366906/223663344-67038d5f-4415-4285-ab20-9a4d397e2138.gif" alt="Console Showcase" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Login V2&lt;/h3&gt; 
&lt;p&gt;Check out our new Login V2 version in our &lt;a href="https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta"&gt;documentation&lt;/a&gt; &lt;img src="https://github.com/user-attachments/assets/cb5c5212-128b-4dc9-b11d-cabfd3f73e26" alt="New Login Showcase" /&gt;&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;You can find our security policy &lt;a href="https://raw.githubusercontent.com/zitadel/zitadel/main/SECURITY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://zitadel.com/docs/support/technical_advisory"&gt;Technical Advisories&lt;/a&gt; are published regarding major issues with the ZITADEL platform that could potentially impact security or stability in production environments.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/zitadel/zitadel/main/LICENSE"&gt;here&lt;/a&gt; are our exact licensing terms.&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See our &lt;a href="https://raw.githubusercontent.com/zitadel/zitadel/main/LICENSE"&gt;license&lt;/a&gt; for detailed information governing permissions and limitations on use.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>heroiclabs/nakama</title>
      <link>https://github.com/heroiclabs/nakama</link>
      <description>&lt;p&gt;Distributed server for social and realtime games and apps.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://heroiclabs.com" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/nakama.png" alt="Nakama - Distributed server for social and realtime games and apps" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/"&gt;&lt;img src="https://img.shields.io/github/release/heroiclabs/nakama.svg?colorA=18181B&amp;amp;colorB=825df2" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/heroiclabs/nakama"&gt;&lt;img src="https://img.shields.io/docker/pulls/heroiclabs/nakama?colorA=18181B&amp;amp;colorB=825df2&amp;amp;label=downloads" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/heroiclabs/nakama/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/heroiclabs/nakama.svg?colorA=18181B&amp;amp;colorB=825df2" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://forum.heroiclabs.com"&gt;&lt;img src="https://img.shields.io/badge/Nakama%20Forum-18181B?logo=discourse" alt="Nakama Forum" /&gt;&lt;/a&gt; &lt;a href="https://heroiclabs.com/docs"&gt;&lt;img src="https://img.shields.io/badge/Nakama%20Docs-18181B?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzU3IiBoZWlnaHQ9IjU3OSIgdmlld0JveD0iMCAwIDM1NyA1NzkiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTI3Ljc1NyAzMzYuNDQ2QzExNC4yMjUgMzM2Ljc0MyAxMDcuNzA1IDMxOS45MDYgMTAzLjk1MiAzMDguNzE0QzEwNy4yMTIgMzA4LjgxMyAxMTAuNDcxIDMwOS4wMTEgMTEzLjYzMiAzMDkuMzA4QzEyMC44NDMgMzEwLjEwMSAxMjguMDU0IDMxMi4xODEgMTMyLjY5NiAzMTguMjIyQzEzOS4xMTcgMzI2LjQ0MyAxMzMuODgyIDMzNi4zNDcgMTI3Ljg1NiAzMzYuNDQ2TTIyOS43OTYgMzM2LjQ0NkMyNDMuMzI4IDMzNi43NDMgMjQ5Ljg0OCAzMTkuOTA2IDI1My42MDEgMzA4LjcxNEMyNTAuMzQxIDMwOC44MTMgMjQ3LjA4MiAzMDkuMDExIDI0My45MjEgMzA5LjMwOEMyMzYuNzEgMzEwLjEwMSAyMjkuNDk5IDMxMi4xODEgMjI0Ljg1NyAzMTguMjIyQzIxOC40MzYgMzI2LjQ0MyAyMjMuNjcxIDMzNi4zNDcgMjI5LjY5NyAzMzYuNDQ2SDIyOS43OTZaTTE3OC4xMzQgNTMzLjQ0MUwxNzguNzI3IDUzNC4xMzRMMTc5LjQxOSA1MzMuNDQxQzE5NC42MyA1MTMuMDM4IDE5Ny42OTMgNDc0LjExNCAxNzguNzI3IDQ1NS41OTRDMTYwLjA1OCA0NzUuMjA0IDE2Mi41MjcgNTEyLjU0MyAxNzguMTM0IDUzMy40NDFaTTE3Ny45MzcgMC41OTQyNTJMMTc4LjcyNyAwTDE3OS41MTcgMC41OTQyNTJDMTk4Ljk3NyAxNC4xNjMgMjEzLjIwMSAyOC4zMjYgMjI3LjEyOSA0Ny44MzczQzI3MS44NzUgMTEwLjIzNCAzMDAuOTE2IDIxMC41NjMgMjkxLjczIDI4NC45NDRDMzEyLjk2NyAyOTQuMTU1IDMyOS41NjIgMzA5LjQwNyAzNDAuNzI0IDMyOC4yMjVDMzU4LjcwMSAzNTguNjMxIDM2Ni4wMTEgNDIwLjAzNyAzNDAuMzI5IDQ1MS45MjlDMzA3LjgzMSA0MzQuMDAyIDI2MC44MTIgNDE5Ljc0IDIxNC4xODkgNDMyLjkxM0wyMDQuODA1IDQzNi45NzRDMjI5Ljc5NiA0NzAuNTQ5IDIyOS45OTMgNTE1LjUxNCAyMDcuMDc3IDU0OS4wODlDMTk3LjI5NyA1NjMuNDUgMTg5Ljk4OCA1NjcuODA4IDE3OC40MzEgNTc5QzE2Ni42NzYgNTY4LjcgMTU4Ljg3MyA1NjIuMzYxIDE0OS43ODUgNTQ5LjA4OUMxMjYuOTY3IDUxNS41MTQgMTI3LjA2NiA0NzAuNTQ5IDE1Mi4wNTcgNDM2Ljk3NEwxNDIuNzcyIDQzMi45MTNDOTYuMTQ4NCA0MTkuNzQgNDkuMTI5OCA0MzQuMDAyIDE2LjYzMTcgNDUxLjkyOUMtOC45NTE4OCA0MjAuMDM3IC0xLjc0MTA1IDM1OC42MzEgMTYuMjM2NiAzMjguMjI1QzI3LjM5ODYgMzA5LjMwOCA0NC4wOTIxIDI5NC4wNTYgNjUuMjMwNyAyODQuOTQ0QzU2LjA0NDMgMjEwLjU2MyA4NS4wODUyIDExMC4yMzQgMTI5LjgzMiA0Ny44MzczQzE0My44NTggMjguMzI2IDE1Ny45ODQgMTQuMTYzIDE3Ny40NDMgMC41OTQyNTJIMTc3LjkzN1pNMzIyLjg0NSA0MDkuMjQyQzMyNy4wOTIgMzg3LjA1NiAzMjMuNzM0IDM2My4zODUgMzEyLjg2OCAzNDQuOTY0QzMwNi4xNTEgMzMzLjY3MyAyOTYuNjY5IDMyNC4zNjMgMjg0LjcxNiAzMTcuOTI1QzI4MS41NTUgMzI3LjgyOSAyNzcuNTA2IDMzNi44NDIgMjcyLjQ2OCAzNDQuODY1QzI1Ny4zNTUgMzY5LjEzIDIyMy41NzMgMzc4LjQ0IDIwMi4zMzUgMzU3LjY0MUMxNzIuOTk4IDMyOC44MiAxOTQuNTMyIDI3NC4wNDkgMjUzLjEwNyAyNzUuOTMxTDI2MC4xMjEgMjc2LjYyNUMyNjcuNTI5IDIwMi4zNDMgMjMzLjU0OSA5Mi40MDYzIDE3OC42MjggNDIuMjkxQzEyMy43MDggOTIuNTA1MyA4OS44MjY1IDIwMi4zNDMgOTcuMTM2MiAyNzYuNjI1TDEwNC4xNDkgMjc1LjkzMUMxNjIuNzI1IDI3NC4wNDkgMTg0LjM1NyAzMjguNzIxIDE1NC45MjIgMzU3LjY0MUMxMzMuNzgzIDM3OC40NCA5OS45MDE5IDM2OS4xMyA4NC43ODg4IDM0NC44NjVDNzkuNzUxMiAzMzYuODQyIDc1LjcwMTIgMzI3LjczIDcyLjU0MDMgMzE3LjkyNUM2MC41ODgxIDMyNC4zNjMgNTEuMTA1NCAzMzMuNzcyIDQ0LjM4ODUgMzQ0Ljk2NEMzMy41MjI4IDM2My4zODUgMzAuMTY0NCAzODcuMDU2IDM0LjQxMTggNDA5LjI0MkM4Ni4yNzA1IDM5MC4yMjYgMTI4LjM1IDM5MC43MjEgMTc4LjUzIDQxMi4zMTJDMjI4LjgwOCAzOTAuNjIyIDI3MC43ODkgMzkwLjIyNiAzMjIuNjQ3IDQwOS4yNDJIMzIyLjg0NVoiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPgo=" alt="Nakama Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Users&lt;/strong&gt; - Register/login new users via social networks, email, or device ID.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt; - Store user records, settings, and other objects in collections.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Social&lt;/strong&gt; - Users can connect with friends, and join groups. Builtin social graph to see how users can be connected.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt; - 1-on-1, group, and global chat between users. Persist messages for chat history.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiplayer&lt;/strong&gt; - Realtime, or turn-based active and passive multiplayer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leaderboards&lt;/strong&gt; - Dynamic, seasonal, get top members, or members around a user. Have as many as you need.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tournaments&lt;/strong&gt; - Invite players to compete together over prizes. Link many together to create leagues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parties&lt;/strong&gt; - Add team play to a game. Users can form a party and communicate with party members.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Purchase Validation&lt;/strong&gt; - Validate in-app purchases and subscriptions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;In-App Notifications&lt;/strong&gt; - Send messages and notifications to connected client sockets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime code&lt;/strong&gt; - Extend the server with custom logic written in Lua, TypeScript/JavaScript, or native Go code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Matchmaker&lt;/strong&gt;, &lt;strong&gt;dashboard&lt;/strong&gt;, &lt;strong&gt;metrics&lt;/strong&gt;, and &lt;a href="https://heroiclabs.com/docs"&gt;more&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Build scalable games and apps with a production ready server used by ambitious game studios and app developers &lt;a href="https://heroiclabs.com/customers/"&gt;all around the world&lt;/a&gt;. Have a look at the &lt;a href="https://heroiclabs.com/docs"&gt;documentation&lt;/a&gt; and join the &lt;a href="https://forum.heroiclabs.com"&gt;developer community&lt;/a&gt; for more info.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The server is simple to setup and run for local development and can be deployed to any cloud provider. See the &lt;a href="https://raw.githubusercontent.com/heroiclabs/nakama/master/#deployment"&gt;deployment notes&lt;/a&gt; for recommendations on how to deploy the project for production. Nakama server requires CockroachDB or another Postgres wire-compatible server as it's database.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://heroiclabs.com/docs/install-docker-quickstart/"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/en/f/f4/Docker_logo.svg?sanitize=true" width="170" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The fastest way to run the server and the database is with Docker. Setup Docker and start the daemon.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Set up a &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/docker/#running-nakama"&gt;docker-compose file&lt;/a&gt; and place it in a folder for your project.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;docker-compose -f ./docker-compose.yml up&lt;/code&gt; to download container images and run the servers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For more detailed instructions have a look at our &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/install/docker"&gt;Docker quickstart&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;Nakama Docker images are maintained on &lt;a href="https://hub.docker.com/r/heroiclabs/nakama/tags"&gt;Docker Hub&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/heroiclabs/nakama-prerelease/tags"&gt;prerelease&lt;/a&gt; images are occasionally published for cutting edge features of the server.&lt;/p&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;You can run the servers with native binaries for your platform.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the server from our &lt;a href="https://github.com/heroiclabs/nakama/releases"&gt;releases&lt;/a&gt; page and the &lt;a href="https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html"&gt;database&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Follow the database &lt;a href="https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html#before-you-begin"&gt;instructions&lt;/a&gt; to start it.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run a migration which will setup or upgrade the database schema:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;nakama migrate up --database.address "root@127.0.0.1:26257"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start Nakama and connect to the database:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;nakama --database.address "root@127.0.0.1:26257"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When connected you'll see server output which describes all settings the server uses for &lt;a href="https://heroiclabs.com/docs/nakama/getting-started/configuration"&gt;configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;{"level":"info","ts":"2018-04-29T10:14:41.249+0100","msg":"Node","name":"nakama","version":"2.0.0+7e18b09","runtime":"go1.10.1","cpu":4} &lt;br /&gt; {"level":"info","ts":"2018-04-29T10:14:41.249+0100","msg":"Database connections","dsns":["root@127.0.0.1:26257"]} &lt;br /&gt; ...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Nakama supports a variety of protocols optimized for various gameplay or app use cases. For request/response it can use GRPC or the HTTP1.1+JSON fallback (REST). For realtime communication you can use WebSockets or rUDP.&lt;/p&gt; 
&lt;p&gt;For example with the REST API to authenticate a user account with a device identifier.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl "127.0.0.1:7350/v2/account/authenticate/device?create=true" \
  --user "defaultkey:" \
  --data '{"id": "someuniqueidentifier"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;{ &lt;br /&gt; "token":"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1MjQ5OTU2NDksInVpZCI6Ijk5Y2Q1YzUyLWE5ODgtNGI2NC04YThhLTVmMTM5YTg4MTgxMiIsInVzbiI6InhBb1RxTUVSdFgifQ.-3_rXNYx3Q4jKuS7RkxeMWBzMNAm0vl93QxzRI8p_IY" &lt;br /&gt; }&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;There's a number of official &lt;a href="https://github.com/heroiclabs"&gt;client libraries&lt;/a&gt; available on GitHub with &lt;a href="https://heroiclabs.com/docs"&gt;documentation&lt;/a&gt;. The current platform/language support includes: .NET (in C#), Unity engine, JavaScript, Java (with Android), Unreal engine, Godot, Defold, and Swift (with iOS). If you'd like to contribute a client or request one let us know.&lt;/p&gt; 
&lt;h2&gt;Nakama Console&lt;/h2&gt; 
&lt;p&gt;The server provides a web UI which teams can use to inspect various data stored through the server APIs, view lightweight service metrics, manage player data, update storage objects, restrict access to production with permission profiles, and gain visibility into realtime features like active multiplayer matches. There is no separate installation required as it is embedded as part of the single server binary.&lt;/p&gt; 
&lt;p&gt;You can navigate to it on your browser on &lt;a href="http://127.0.0.1:7351"&gt;http://127.0.0.1:7351&lt;/a&gt;.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/dashboard.png" alt="Nakama Console dashboard view" title="Dashboard view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/players.png" alt="Nakama Console players view" title="Players view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/api-explorer.png" alt="Nakama Console API explorer view" title="API explorer view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/storage.png" alt="Nakama Console storage view" title="Storage object view" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/heroiclabs/nakama/master/.github/modules.png" alt="Nakama Console modules view" title="Runtime modules view" /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;p&gt;Nakama can be deployed to any cloud provider such as Google Cloud, Azure, AWS, Digital Ocean, Heroku, or your own private cloud. You should setup and provision separate nodes for Nakama and CockroachDB.&lt;/p&gt; 
&lt;p&gt;The recommended minimum production infrastructure for CockroachDB is outlined in &lt;a href="https://www.cockroachlabs.com/docs/stable/recommended-production-settings.html#basic-hardware-recommendations"&gt;these docs&lt;/a&gt; and Nakama can be run on instance types as small as "g1-small" on Google Cloud although we recommend a minimum of "n1-standard-1" in production. The specific hardware requirements will depend on what features of the server are used. Reach out to us for help and advice on what servers to run.&lt;/p&gt; 
&lt;h3&gt;Heroic Cloud&lt;/h3&gt; 
&lt;p&gt;You can support development, new features, and maintainance of the server by using the Heroic Labs' &lt;a href="https://heroiclabs.com/heroic-cloud/"&gt;Heroic Cloud&lt;/a&gt; for deployment. This service handles the uptime, replication, backups, logs, data upgrades, and all other tasks involved with production server environments.&lt;/p&gt; 
&lt;p&gt;Have a look at our &lt;a href="https://heroiclabs.com/heroic-cloud/"&gt;Heroic Cloud&lt;/a&gt; service for more details.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;The development roadmap is managed as GitHub issues and pull requests are welcome. If you're interested to add a feature which is not mentioned on the issue tracker please open one to create a discussion or drop in and discuss it in the &lt;a href="https://forum.heroiclabs.com"&gt;community forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Simple Builds&lt;/h3&gt; 
&lt;p&gt;All dependencies required for a build are vendored as part of the Go project. We recommend a modern release of the Go toolchain and do not store the codebase in the old GOPATH.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the source tree.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone "https://github.com/heroiclabs/nakama" nakama
cd nakama
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the project from source.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go build -trimpath -mod=vendor
./nakama --version
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Full Source Builds&lt;/h3&gt; 
&lt;p&gt;The codebase uses Protocol Buffers, GRPC, GRPC-Gateway, and the OpenAPI spec as part of the project. These dependencies are generated as sources and committed to the repository to simplify builds for contributors.&lt;/p&gt; 
&lt;p&gt;To build the codebase and generate all sources follow these steps.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install the toolchain.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go install \
    "google.golang.org/protobuf/cmd/protoc-gen-go" \
    "google.golang.org/grpc/cmd/protoc-gen-go-grpc" \
    "github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway" \
    "github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Re-generate the protocol buffers and gateway code.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;buf generate apigrpc -o apigrpc
buf generate console -o console
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the codebase.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go build -trimpath -mod=vendor
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;In order to run all the unit and integration tests run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker-compose -f ./docker-compose-tests.yml up --build --abort-on-container-exit; docker-compose -f ./docker-compose-tests.yml down -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create an isolated environment with Nakama and database instances, run all the tests, and drop the environment afterwards.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://github.com/heroiclabs/nakama/raw/master/LICENSE"&gt;Apache-2 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>go-rod/rod</title>
      <link>https://github.com/go-rod/rod</link>
      <description>&lt;p&gt;A Chrome DevTools Protocol driver for web automation and scraping.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/go-rod/rod"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/go-rod/rod.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/CpevuvY"&gt;&lt;img src="https://img.shields.io/discord/719933559456006165.svg?sanitize=true" alt="Discord Chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://go-rod.github.io/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://pkg.go.dev/github.com/go-rod/rod?tab=doc"&gt;API reference&lt;/a&gt; | &lt;a href="https://go-rod.github.io/#/faq/README"&gt;FAQ&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Rod is a high-level driver directly based on &lt;a href="https://chromedevtools.github.io/devtools-protocol"&gt;DevTools Protocol&lt;/a&gt;. It's designed for web automation and scraping for both high-level and low-level use, senior developers can use the low-level packages and functions to easily customize or build up their own version of Rod, the high-level functions are just examples to build a default version of Rod.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/go-rod/go-rod-chinese"&gt;‰∏≠Êñá API ÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chained context design, intuitive to timeout or cancel the long-running task&lt;/li&gt; 
 &lt;li&gt;Auto-wait elements to be ready&lt;/li&gt; 
 &lt;li&gt;Debugging friendly, auto input tracing, remote monitoring headless browser&lt;/li&gt; 
 &lt;li&gt;Thread-safe for all operations&lt;/li&gt; 
 &lt;li&gt;Automatically find or download &lt;a href="https://raw.githubusercontent.com/go-rod/rod/main/lib/launcher"&gt;browser&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;High-level helpers like WaitStable, WaitRequestIdle, HijackRequests, WaitDownload, etc&lt;/li&gt; 
 &lt;li&gt;Two-step WaitEvent design, never miss an event (&lt;a href="https://github.com/ysmood/goob"&gt;how it works&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Correctly handles nested iframes or shadow DOMs&lt;/li&gt; 
 &lt;li&gt;No zombie browser process after the crash (&lt;a href="https://github.com/ysmood/leakless"&gt;how it works&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-rod/rod/actions"&gt;CI&lt;/a&gt; enforced 100% test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Please check the &lt;a href="https://raw.githubusercontent.com/go-rod/rod/main/examples_test.go"&gt;examples_test.go&lt;/a&gt; file first, then check the &lt;a href="https://raw.githubusercontent.com/go-rod/rod/main/lib/examples"&gt;examples&lt;/a&gt; folder.&lt;/p&gt; 
&lt;p&gt;For more detailed examples, please search the unit tests. Such as the usage of method &lt;code&gt;HandleAuth&lt;/code&gt;, you can search all the &lt;code&gt;*_test.go&lt;/code&gt; files that contain &lt;code&gt;HandleAuth&lt;/code&gt;, for example, use GitHub online &lt;a href="https://github.com/go-rod/rod/search?q=HandleAuth&amp;amp;unscoped_q=HandleAuth"&gt;search in repository&lt;/a&gt;. You can also search the GitHub &lt;a href="https://github.com/go-rod/rod/issues"&gt;issues&lt;/a&gt; or &lt;a href="https://github.com/go-rod/rod/discussions"&gt;discussions&lt;/a&gt;, a lot of usage examples are recorded there.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/go-rod/rod/main/lib/examples/compare-chromedp"&gt;Here is a comparison&lt;/a&gt; of the examples between rod and Chromedp.&lt;/p&gt; 
&lt;p&gt;If you have questions, please raise an &lt;a href="https://github.com/go-rod/rod/issues"&gt;issues&lt;/a&gt;/&lt;a href="https://github.com/go-rod/rod/discussions"&gt;discussions&lt;/a&gt; or join the &lt;a href="https://discord.gg/CpevuvY"&gt;chat room&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Rod is sponsored by many organizations and individuals, thank you for your support!&lt;/p&gt; 
&lt;p&gt;Please contact &lt;a href="mailto:yad@ysmood.org"&gt;yad@ysmood.org&lt;/a&gt; if you want to be listed here.&lt;/p&gt; 
&lt;!-- markdownlint-disable MD033 --&gt; 
&lt;table style="border-collapse: collapse"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;p&gt;Browser testing via&lt;/p&gt; &lt;a href="https://www.lambdatest.com/" target="_blank"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" alt="LambdaTest Logo" width="250" height="45" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- markdownlint-enable MD033 --&gt; 
&lt;h2&gt;Join us&lt;/h2&gt; 
&lt;p&gt;Your help is more than welcome! Even just open an issue to ask a question may greatly help others.&lt;/p&gt; 
&lt;p&gt;Please read &lt;a href="http://www.catb.org/~esr/faqs/smart-questions.html"&gt;How To Ask Questions The Smart Way&lt;/a&gt; before you ask questions.&lt;/p&gt; 
&lt;p&gt;If you want to contribute please read the &lt;a href="https://raw.githubusercontent.com/go-rod/rod/main/.github/CONTRIBUTING.md"&gt;Contributor Guide&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>projectcalico/calico</title>
      <link>https://github.com/projectcalico/calico</link>
      <description>&lt;p&gt;Cloud native networking and network security&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/projectcalico/calico"&gt;&lt;img src="https://goreportcard.com/badge/github.com/projectcalico/calico" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/projectcalico/tigera-operator"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator" alt="ArtifactHub" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/calico/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/projectcalico/api"&gt;&lt;img src="https://pkg.go.dev/badge/k8s.io/kubernetes.svg?sanitize=true" alt="GoPkg" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/6064"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6064/badge" alt="CII Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Calico&lt;/h1&gt; 
 &lt;h2&gt; &lt;a href="https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart"&gt;Quickstart&lt;/a&gt; | &lt;a href="https://projectcalico.docs.tigera.io"&gt;Docs&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; | &lt;a href="https://slack.projectcalico.org"&gt;Slack&lt;/a&gt; | &lt;a href="https://github.com/projectcalico/calico/releases"&gt;Releases&lt;/a&gt; &lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;üêæ Welcome to Project Calico!&lt;/h2&gt; 
&lt;p&gt;Project Calico, created and maintained by &lt;a href="https://www.tigera.io/"&gt;Tigera&lt;/a&gt;, is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.&lt;/p&gt; 
&lt;h2&gt;üåü Why use Calico?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Plane Choice&lt;/strong&gt;: eBPF, standard Linux, Windows, and VPP ‚Äî versatility in network solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: Works across multiple distros, multiple clouds, bare metal, and VMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized Performance&lt;/strong&gt;: Engineered for high speed and low CPU usage, maximizing your cluster investments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Grows seamlessly with your Kubernetes clusters without sacrificing performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Security&lt;/strong&gt;: Get granular access controls and WireGuard encryption.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes Networking Policy Support&lt;/strong&gt;: Continually defining excellence in Kubernetes network policy standards and support.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vibrant Contributor Community&lt;/strong&gt;: Over 200 contributors from a wide array of global companies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible networking&lt;/strong&gt;: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://www.tigera.io/app/uploads/2024/02/Ecosystem_shrunken_2023.svg?sanitize=true" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü§ù Join the Calico Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats"&gt;Calico Big Cats&lt;/a&gt;: Become an ambassador and share your journey&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com"&gt;Community Meetings&lt;/a&gt;: Engage and contribute&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/labels/good%20first%20issue"&gt;Contribute on GitHub&lt;/a&gt;: Start with 'good first issues'&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.projectcalico.org/"&gt;Connect on Slack&lt;/a&gt;: Join the conversation with fellow contributors and our developers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° Contributing to Project Calico&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.tigera.io/calico/latest/about"&gt;Get Started with Project Calico&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/projectcalico/repositories"&gt;Repositories&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/raw/master/CONTRIBUTING_DOCS.md"&gt;Contribute to our docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.tigera.io/calico/latest/about/training-resources"&gt;Dive into our training and resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/issues"&gt;Make Calico better&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Projects We Maintain&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/api"&gt;Calico Golang API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigera/operator"&gt;Calico operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/vpp-dataplane"&gt;VPP dataplane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/bird"&gt;Calico BIRD&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¢ Stay Connected&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Subscribe: &lt;a href="https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter"&gt;Join our newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA"&gt;YouTube channel for updates &amp;amp; tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/blog/?_sft_category=technical-blog"&gt;Technical Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/careers/"&gt;Careers&lt;/a&gt;: Passionate about open source? Join our team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>fatedier/frp</title>
      <link>https://github.com/fatedier/frp</link>
      <description>&lt;p&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;frp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/fatedier/frp"&gt;&lt;img src="https://circleci.com/gh/fatedier/frp.svg?style=shield" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fatedier/frp/releases"&gt;&lt;img src="https://img.shields.io/github/tag/fatedier/frp.svg?label=release" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/fatedier/frp"&gt;&lt;img src="https://goreportcard.com/badge/github.com/fatedier/frp" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;amp;repository=frp"&gt;&lt;img src="https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github" alt="GitHub Releases Stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README.md"&gt;README&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README_zh.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you'd like to join them, please consider &lt;a href="https://github.com/sponsors/fatedier"&gt;sponsoring frp's development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 align="center"&gt;Gold Sponsors&lt;/h3&gt; 
&lt;!--gold sponsors start--&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Recall.ai - API for meeting recordings&lt;/h2&gt; 
 &lt;p&gt;If you're looking for a meeting recording API, consider checking out &lt;a href="https://www.recall.ai/?utm_source=github&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=fatedier-frp"&gt;Recall.ai&lt;/a&gt;,&lt;/p&gt; 
 &lt;p&gt;an API that records Zoom, Google Meet, Microsoft Teams, in-person meetings, and more.&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://requestly.com/?utm_source=github&amp;amp;utm_medium=partnered&amp;amp;utm_campaign=frp" target="_blank"&gt; &lt;img width="480px" src="https://github.com/user-attachments/assets/24670320-997d-4d62-9bca-955c59fe883d" /&gt; &lt;br /&gt; &lt;b&gt;Requestly - Free &amp;amp; Open-Source alternative to Postman&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;All-in-one platform to Test, Mock and Intercept APIs.&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.warp.dev/frp" target="_blank"&gt; &lt;img width="360px" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-01.png" /&gt; &lt;br /&gt; &lt;b&gt;Warp, built for collaborating with AI Agents&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;Available for macOS, Linux and Windows&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://jb.gg/frp" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg" /&gt; &lt;br /&gt; &lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/daytonaio/daytona" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_daytona.png" /&gt; &lt;br /&gt; &lt;b&gt;Secure and Elastic Infrastructure for Running Your AI-Generated Code&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/beclab/Olares" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg" /&gt; &lt;br /&gt; &lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;!--gold sponsors end--&gt; 
&lt;h2&gt;What is frp?&lt;/h2&gt; 
&lt;p&gt;frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;, as well as &lt;strong&gt;HTTP&lt;/strong&gt; and &lt;strong&gt;HTTPS&lt;/strong&gt; protocols, enabling requests to be forwarded to internal services via domain name.&lt;/p&gt; 
&lt;p&gt;frp also offers a P2P connect mode.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- vim-markdown-toc GFM --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#development-status"&gt;Development Status&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#about-v2"&gt;About V2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;Example Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#access-your-computer-in-a-lan-network-via-ssh"&gt;Access your computer in a LAN network via SSH&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#multiple-ssh-services-sharing-the-same-port"&gt;Multiple SSH services sharing the same port&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#accessing-internal-web-services-with-custom-domains-in-lan"&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-dns-query-requests"&gt;Forward DNS query requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-unix-domain-socket"&gt;Forward Unix Domain Socket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-a-simple-http-file-server"&gt;Expose a simple HTTP file server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enable-https-for-a-local-https-service"&gt;Enable HTTPS for a local HTTP(S) service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-your-service-privately"&gt;Expose your service privately&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#p2p-mode"&gt;P2P Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#configuration-files"&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#using-environment-variables"&gt;Using Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#split-configures-into-different-files"&gt;Split Configures Into Different Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-dashboard"&gt;Server Dashboard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-admin-ui"&gt;Client Admin UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#monitor"&gt;Monitor&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#prometheus"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#authenticating-the-client"&gt;Authenticating the Client&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#token-authentication"&gt;Token Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#oidc-authentication"&gt;OIDC Authentication&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#encryption-and-compression"&gt;Encryption and Compression&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tls"&gt;TLS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#hot-reloading-frpc-configuration"&gt;Hot-Reloading frpc configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-proxy-status-from-client"&gt;Get proxy status from client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#only-allowing-certain-ports-on-the-server"&gt;Only allowing certain ports on the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-reuse"&gt;Port Reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#bandwidth-limit"&gt;Bandwidth Limit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#for-each-proxy"&gt;For Each Proxy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-stream-multiplexing"&gt;TCP Stream Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-kcp-protocol"&gt;Support KCP Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-quic-protocol"&gt;Support QUIC Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connection-pooling"&gt;Connection Pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#load-balancing"&gt;Load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#service-health-check"&gt;Service Health Check&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#rewriting-the-http-host-header"&gt;Rewriting the HTTP Host Header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#setting-other-http-headers"&gt;Setting other HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-real-ip"&gt;Get Real IP&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#http-x-forwarded-for"&gt;HTTP X-Forwarded-For&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#proxy-protocol"&gt;Proxy Protocol&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#require-http-basic-auth-password-for-web-services"&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#custom-subdomain-names"&gt;Custom Subdomain Names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#url-routing"&gt;URL Routing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-port-multiplexing"&gt;TCP Port Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connecting-to-frps-via-proxy"&gt;Connecting to frps via PROXY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-range-mapping"&gt;Port range mapping&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-plugins"&gt;Client Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-manage-plugins"&gt;Server Manage Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#ssh-tunnel-gateway"&gt;SSH Tunnel Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#virtual-network-virtualnet"&gt;Virtual Network (VirtualNet)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-gates"&gt;Feature Gates&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#available-feature-gates"&gt;Available Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enabling-feature-gates"&gt;Enabling Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-lifecycle"&gt;Feature Lifecycle&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#donation"&gt;Donation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#github-sponsors"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#paypal"&gt;PayPal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vim-markdown-toc --&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;frp is currently under development. You can try the latest release version in the &lt;code&gt;master&lt;/code&gt; branch, or use the &lt;code&gt;dev&lt;/code&gt; branch to access the version currently in development.&lt;/p&gt; 
&lt;p&gt;We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.&lt;/p&gt; 
&lt;p&gt;We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.&lt;/p&gt; 
&lt;h3&gt;About V2&lt;/h3&gt; 
&lt;p&gt;The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.&lt;/p&gt; 
&lt;p&gt;The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.&lt;/p&gt; 
&lt;p&gt;In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone's needs.&lt;/p&gt; 
&lt;p&gt;Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.&lt;/p&gt; 
&lt;p&gt;We sincerely appreciate your support for frp.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Example Usage&lt;/h2&gt; 
&lt;p&gt;To begin, download the latest program for your operating system and architecture from the &lt;a href="https://github.com/fatedier/frp/releases"&gt;Release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Next, place the &lt;code&gt;frps&lt;/code&gt; binary and server configuration file on Server A, which has a public IP address.&lt;/p&gt; 
&lt;p&gt;Finally, place the &lt;code&gt;frpc&lt;/code&gt; binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.&lt;/p&gt; 
&lt;p&gt;Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See &lt;a href="https://github.com/fatedier/frp/issues/3637"&gt;issue 3637&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Access your computer in a LAN network via SSH&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; on server A by setting the &lt;code&gt;bindPort&lt;/code&gt; for frp clients to connect to:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt; on server A:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; on server B and set the &lt;code&gt;serverAddr&lt;/code&gt; field to the public IP address of your frps server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;localPort&lt;/code&gt; (listened on the client) and &lt;code&gt;remotePort&lt;/code&gt; (exposed on the server) are used for traffic going in and out of the frp system, while the &lt;code&gt;serverPort&lt;/code&gt; is used for communication between frps and frpc.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on server B:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access server B from another machine through server A via SSH (assuming the username is &lt;code&gt;test&lt;/code&gt;), use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 test@x.x.x.x&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple SSH services sharing the same port&lt;/h3&gt; 
&lt;p&gt;This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;bindPort = 7000
tcpmuxHTTPConnectPort = 5002
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Deploy frpc on the internal machine A with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-a.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Deploy another frpc on the internal machine B with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-b.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;To access internal machine A using SSH ProxyCommand, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-a.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access internal machine B, the only difference is the domain name, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-b.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/h3&gt; 
&lt;p&gt;Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.&lt;/p&gt; 
&lt;p&gt;Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; and set the HTTP port for vhost to 8080:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
vhostHTTPPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to configure an https proxy, you need to set up the &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Specify the &lt;code&gt;localPort&lt;/code&gt; of your web service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["www.example.com"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;Map the A record of &lt;code&gt;www.example.com&lt;/code&gt; to either the public IP of the remote frps server or a CNAME record pointing to your original domain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit your local web service using url &lt;code&gt;http://www.example.com:8080&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Forward DNS query requests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server &lt;code&gt;8.8.8.8:53&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "dns"
type = "udp"
localIP = "8.8.8.8"
localPort = 53
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start frpc:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Test DNS resolution using the &lt;code&gt;dig&lt;/code&gt; command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;dig @x.x.x.x -p 6000 www.google.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Forward Unix Domain Socket&lt;/h3&gt; 
&lt;p&gt;Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "unix_domain_socket"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "unix_domain_socket"
unixPath = "/var/run/docker.sock"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Test the configuration by getting the docker version using &lt;code&gt;curl&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;curl http://x.x.x.x:6000/version&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Expose a simple HTTP file server&lt;/h3&gt; 
&lt;p&gt;Expose a simple HTTP file server to access files stored in the LAN from the public Internet.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as described above, then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_static_file"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "static_file"
localPath = "/tmp/files"
stripPrefix = "static"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;http://x.x.x.x:6000/static/&lt;/code&gt; from your browser and specify correct username and password to view files in &lt;code&gt;/tmp/files&lt;/code&gt; on the &lt;code&gt;frpc&lt;/code&gt; machine.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable HTTPS for a local HTTP(S) service&lt;/h3&gt; 
&lt;p&gt;You may substitute &lt;code&gt;https2https&lt;/code&gt; for the plugin, and point the &lt;code&gt;localAddr&lt;/code&gt; to a HTTPS endpoint.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_https2http"
type = "https"
customDomains = ["test.example.com"]

[proxies.plugin]
type = "https2http"
localAddr = "127.0.0.1:80"
crtPath = "./server.crt"
keyPath = "./server.key"
hostHeaderRewrite = "127.0.0.1"
requestHeaders.set.x-from-where = "frp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;https://test.example.com&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Expose your service privately&lt;/h3&gt; 
&lt;p&gt;To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; same as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B with the following config. This example is for exposing the SSH service (port 22), and note the &lt;code&gt;secretKey&lt;/code&gt; field for the preshared key, and that the &lt;code&gt;remotePort&lt;/code&gt; field is removed here:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "secret_ssh"
type = "stcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the following config to access the SSH service with a security key (&lt;code&gt;secretKey&lt;/code&gt; field):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[visitors]]
name = "secret_ssh_visitor"
type = "stcp"
serverName = "secret_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;P2P Mode&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;xtcp&lt;/strong&gt; is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.&lt;/p&gt; 
&lt;p&gt;Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn't work.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B, and expose the SSH port. Note that the &lt;code&gt;remotePort&lt;/code&gt; field is removed:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[proxies]]
name = "p2p_ssh"
type = "xtcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the configuration to connect to SSH using P2P mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[visitors]]
name = "p2p_ssh_visitor"
type = "xtcp"
serverName = "p2p_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
# when automatic tunnel persistence is required, set it to true
keepTunnelOpen = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.&lt;/p&gt; 
&lt;p&gt;Read the full example configuration files to find out even more features not described here.&lt;/p&gt; 
&lt;p&gt;Examples use TOML format, but you can still use YAML or JSON.&lt;/p&gt; 
&lt;p&gt;These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frps_full_example.toml"&gt;Full configuration file for frps (Server)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frpc_full_example.toml"&gt;Full configuration file for frpc (Client)&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Environment Variables&lt;/h3&gt; 
&lt;p&gt;Environment variables can be referenced in the configuration file, using Go's standard format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "{{ .Envs.FRP_SERVER_ADDR }}"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = {{ .Envs.FRP_SSH_REMOTE_PORT }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the config above, variables can be passed into &lt;code&gt;frpc&lt;/code&gt; program like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;frpc&lt;/code&gt; will render configuration file template using OS environment variables. Remember to prefix your reference with &lt;code&gt;.Envs&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Split Configures Into Different Files&lt;/h3&gt; 
&lt;p&gt;You can split multiple proxy configs into different files and include them in the main file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
includes = ["./confd/*.toml"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ./confd/test.toml

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server Dashboard&lt;/h3&gt; 
&lt;p&gt;Check frp's status and proxies' statistics information by Dashboard.&lt;/p&gt; 
&lt;p&gt;Configure a port for dashboard to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# The default value is 127.0.0.1. Change it to 0.0.0.0 when you want to access it from a public network.
webServer.addr = "0.0.0.0"
webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://[serverAddr]:7500&lt;/code&gt; to see the dashboard, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can use HTTPS port by using your domains wildcard or normal SSL certificate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
webServer.tls.certFile = "server.crt"
webServer.tls.keyFile = "server.key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;https://[serverAddr]:7500&lt;/code&gt; to see the dashboard in secure HTTPS connection, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/dashboard.png" alt="dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Client Admin UI&lt;/h3&gt; 
&lt;p&gt;The Client Admin UI helps you check and manage frpc's configuration.&lt;/p&gt; 
&lt;p&gt;Configure an address for admin UI to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.addr = "127.0.0.1"
webServer.port = 7400
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://127.0.0.1:7400&lt;/code&gt; to see admin UI, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Monitor&lt;/h3&gt; 
&lt;p&gt;When web server is enabled, frps will save monitor data in cache for 7 days. It will be cleared after process restart.&lt;/p&gt; 
&lt;p&gt;Prometheus is also supported.&lt;/p&gt; 
&lt;h4&gt;Prometheus&lt;/h4&gt; 
&lt;p&gt;Enable dashboard first, then configure &lt;code&gt;enablePrometheus = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;http://{dashboard_addr}/metrics&lt;/code&gt; will provide prometheus monitor data.&lt;/p&gt; 
&lt;h3&gt;Authenticating the Client&lt;/h3&gt; 
&lt;p&gt;There are 2 authentication methods to authenticate frpc with frps.&lt;/p&gt; 
&lt;p&gt;You can decide which one to use by configuring &lt;code&gt;auth.method&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt;, the default one is token.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["HeartBeats"]&lt;/code&gt; will use the configured authentication method to add and validate authentication on every heartbeat between frpc and frps.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["NewWorkConns"]&lt;/code&gt; will do the same for every new work connection between frpc and frps.&lt;/p&gt; 
&lt;h4&gt;Token Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "token"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - token based authentication will be used.&lt;/p&gt; 
&lt;p&gt;Make sure to specify the same &lt;code&gt;auth.token&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt; for frpc to pass frps validation&lt;/p&gt; 
&lt;h5&gt;Token Source&lt;/h5&gt; 
&lt;p&gt;frp supports reading authentication tokens from external sources using the &lt;code&gt;tokenSource&lt;/code&gt; configuration. Currently, file-based token source is supported.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;File-based token source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "token"
auth.tokenSource.type = "file"
auth.tokenSource.file.path = "/path/to/token/file"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The token will be read from the specified file at startup. This is useful for scenarios where tokens are managed by external systems or need to be kept separate from configuration files for security reasons.&lt;/p&gt; 
&lt;h4&gt;OIDC Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "oidc"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - OIDC based authentication will be used.&lt;/p&gt; 
&lt;p&gt;OIDC stands for OpenID Connect, and the flow used is called &lt;a href="https://tools.ietf.org/html/rfc6749#section-4.4"&gt;Client Credentials Grant&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this authentication type - configure &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
auth.method = "oidc"
auth.oidc.issuer = "https://example-oidc-issuer.com/"
auth.oidc.audience = "https://oidc-audience.com/.default"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "oidc"
auth.oidc.clientID = "98692467-37de-409a-9fac-bb2585826f18" # Replace with OIDC client ID
auth.oidc.clientSecret = "oidc_secret"
auth.oidc.audience = "https://oidc-audience.com/.default"
auth.oidc.tokenEndpointURL = "https://example-oidc-endpoint.com/oauth2/v2.0/token"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encryption and Compression&lt;/h3&gt; 
&lt;p&gt;The features are off by default. You can turn on encryption and/or compression:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.useEncryption = true
transport.useCompression = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;TLS&lt;/h4&gt; 
&lt;p&gt;Since v0.50.0, the default value of &lt;code&gt;transport.tls.enable&lt;/code&gt; and &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; has been changed to true, and tls is enabled by default.&lt;/p&gt; 
&lt;p&gt;For port multiplexing, frp sends a first byte &lt;code&gt;0x17&lt;/code&gt; to dial a TLS connection. This only takes effect when you set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;To &lt;strong&gt;enforce&lt;/strong&gt; &lt;code&gt;frps&lt;/code&gt; to only accept TLS connections - configure &lt;code&gt;transport.tls.force = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;. &lt;strong&gt;This is optional.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frpc&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.enable = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frps&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.force = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need &lt;strong&gt;a root CA cert&lt;/strong&gt; and &lt;strong&gt;at least one SSL/TLS certificate&lt;/strong&gt;. It &lt;strong&gt;can&lt;/strong&gt; be self-signed or regular (such as Let's Encrypt or another SSL/TLS certificate provider).&lt;/p&gt; 
&lt;p&gt;If you using &lt;code&gt;frp&lt;/code&gt; via IP address and not hostname, make sure to set the appropriate IP address in the Subject Alternative Name (SAN) area when generating SSL/TLS Certificates.&lt;/p&gt; 
&lt;p&gt;Given an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare openssl config file. It exists at &lt;code&gt;/etc/pki/tls/openssl.cnf&lt;/code&gt; in Linux System and &lt;code&gt;/System/Library/OpenSSL/openssl.cnf&lt;/code&gt; in MacOS, and you can copy it to current path, like &lt;code&gt;cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf&lt;/code&gt;. If not, you can build it by yourself, like:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;cat &amp;gt; my-openssl.cnf &amp;lt;&amp;lt; EOF
[ ca ]
default_ca = CA_default
[ CA_default ]
x509_extensions = usr_cert
[ req ]
default_bits        = 2048
default_md          = sha256
default_keyfile     = privkey.pem
distinguished_name  = req_distinguished_name
attributes          = req_attributes
x509_extensions     = v3_ca
string_mask         = utf8only
[ req_distinguished_name ]
[ req_attributes ]
[ usr_cert ]
basicConstraints       = CA:FALSE
nsComment              = "OpenSSL Generated Certificate"
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
[ v3_ca ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always,issuer
basicConstraints       = CA:true
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build ca certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=example.ca.com" -days 5000 -out ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frps certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048

openssl req -new -sha256 -key server.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com")) \
    -out server.csr

openssl x509 -req -days 365 -sha256 \
	-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com") \
	-out server.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frpc certificatesÔºö&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out client.key 2048
openssl req -new -sha256 -key client.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:client.com,DNS:example.client.com")) \
    -out client.csr

openssl x509 -req -days 365 -sha256 \
    -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:client.com,DNS:example.client.com") \
	-out client.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hot-Reloading frpc configuration&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
webServer.addr = "127.0.0.1"
webServer.port = 7400
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run command &lt;code&gt;frpc reload -c ./frpc.toml&lt;/code&gt; and wait for about 10 seconds to let &lt;code&gt;frpc&lt;/code&gt; create or update or remove proxies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that global client parameters won't be modified except 'start'.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can run command &lt;code&gt;frpc verify -c ./frpc.toml&lt;/code&gt; before reloading to check if there are config errors.&lt;/p&gt; 
&lt;h3&gt;Get proxy status from client&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;frpc status -c ./frpc.toml&lt;/code&gt; to get status of all proxies. The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API.&lt;/p&gt; 
&lt;h3&gt;Only allowing certain ports on the server&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;allowPorts&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; is used to avoid abuse of ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
allowPorts = [
  { start = 2000, end = 3000 },
  { single = 3001 },
  { single = 3003 },
  { start = 4000, end = 50000 }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port Reuse&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt; in frps can use same port with &lt;code&gt;bindPort&lt;/code&gt;. frps will detect the connection's protocol and handle it correspondingly.&lt;/p&gt; 
&lt;p&gt;What you need to pay attention to is that if you want to configure &lt;code&gt;vhostHTTPSPort&lt;/code&gt; and &lt;code&gt;bindPort&lt;/code&gt; to the same port, you need to first set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;We would like to try to allow multiple proxies bind a same remote port with different protocols in the future.&lt;/p&gt; 
&lt;h3&gt;Bandwidth Limit&lt;/h3&gt; 
&lt;h4&gt;For Each Proxy&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.bandwidthLimit = "1MB"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimit&lt;/code&gt; in each proxy's configure to enable this feature. Supported units are &lt;code&gt;MB&lt;/code&gt; and &lt;code&gt;KB&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimitMode&lt;/code&gt; to &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;server&lt;/code&gt; to limit bandwidth on the client or server side. Default is &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Stream Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports tcp stream multiplexing since v0.10.0 like HTTP2 Multiplexing, in which case all logic connections to the same frpc are multiplexed into the same TCP connection.&lt;/p&gt; 
&lt;p&gt;You can disable this feature by modify &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml and frpc.toml, must be same
transport.tcpMux = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support KCP Protocol&lt;/h3&gt; 
&lt;p&gt;KCP is a fast and reliable protocol that can achieve the transmission effect of a reduction of the average latency by 30% to 40% and reduction of the maximum delay by a factor of three, at the cost of 10% to 20% more bandwidth wasted than TCP.&lt;/p&gt; 
&lt;p&gt;KCP mode uses UDP as the underlying transport. Using KCP in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable KCP in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for KCP.
kcpBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;kcpBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use KCP to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'kcpBindPort' in frps.toml
serverPort = 7000
transport.protocol = "kcp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support QUIC Protocol&lt;/h3&gt; 
&lt;p&gt;QUIC is a new multiplexed transport built on top of UDP.&lt;/p&gt; 
&lt;p&gt;Using QUIC in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable QUIC in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for QUIC.
quicBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;quicBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use QUIC to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'quicBindPort' in frps.toml
serverPort = 7000
transport.protocol = "quic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connection Pooling&lt;/h3&gt; 
&lt;p&gt;By default, frps creates a new frpc connection to the backend service upon a user request. With connection pooling, frps keeps a certain number of pre-established connections, reducing the time needed to establish a connection.&lt;/p&gt; 
&lt;p&gt;This feature is suitable for a large number of short connections.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure the limit of pool count each proxy can use in &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
transport.maxPoolCount = 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Enable and specify the number of connection pool:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
transport.poolCount = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load balancing&lt;/h3&gt; 
&lt;p&gt;Load balancing is supported by &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This feature is only available for types &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;tcpmux&lt;/code&gt; now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 8080
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"

[[proxies]]
name = "test2"
type = "tcp"
localPort = 8081
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;loadBalancer.groupKey&lt;/code&gt; is used for authentication.&lt;/p&gt; 
&lt;p&gt;Connections to port 80 will be dispatched to proxies in the same group randomly.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;remotePort&lt;/code&gt; in the same group should be the same.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;customDomains&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;, &lt;code&gt;locations&lt;/code&gt; should be the same.&lt;/p&gt; 
&lt;h3&gt;Service Health Check&lt;/h3&gt; 
&lt;p&gt;Health check feature can help you achieve high availability with load balancing.&lt;/p&gt; 
&lt;p&gt;Add &lt;code&gt;healthCheck.type = "tcp"&lt;/code&gt; or &lt;code&gt;healthCheck.type = "http"&lt;/code&gt; to enable health check.&lt;/p&gt; 
&lt;p&gt;With health check type &lt;strong&gt;tcp&lt;/strong&gt;, the service port will be pinged (TCPing):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 22
remotePort = 6000
# Enable TCP health check
healthCheck.type = "tcp"
# TCPing timeout seconds
healthCheck.timeoutSeconds = 3
# If health check failed 3 times in a row, the proxy will be removed from frps
healthCheck.maxFailed = 3
# A health check every 10 seconds
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With health check type &lt;strong&gt;http&lt;/strong&gt;, an HTTP request will be sent to the service and an HTTP 2xx OK response is expected:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localIP = "127.0.0.1"
localPort = 80
customDomains = ["test.example.com"]
# Enable HTTP health check
healthCheck.type = "http"
# frpc will send a GET request to '/status'
# and expect an HTTP 2xx OK response
healthCheck.path = "/status"
healthCheck.timeoutSeconds = 3
healthCheck.maxFailed = 3
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rewriting the HTTP Host Header&lt;/h3&gt; 
&lt;p&gt;By default frp does not modify the tunneled HTTP requests at all as it's a byte-for-byte copy.&lt;/p&gt; 
&lt;p&gt;However, speaking of web servers and HTTP requests, your web server might rely on the &lt;code&gt;Host&lt;/code&gt; HTTP header to determine the website to be accessed. frp can rewrite the &lt;code&gt;Host&lt;/code&gt; header when forwarding the HTTP requests, with the &lt;code&gt;hostHeaderRewrite&lt;/code&gt; field:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The HTTP request will have the &lt;code&gt;Host&lt;/code&gt; header rewritten to &lt;code&gt;Host: dev.example.com&lt;/code&gt; when it reaches the actual web server, although the request from the browser probably has &lt;code&gt;Host: test.example.com&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Setting other HTTP Headers&lt;/h3&gt; 
&lt;p&gt;Similar to &lt;code&gt;Host&lt;/code&gt;, You can override other HTTP request and response headers with proxy type &lt;code&gt;http&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
requestHeaders.set.x-from-where = "frp"
responseHeaders.set.foo = "bar"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, it will set header &lt;code&gt;x-from-where: frp&lt;/code&gt; in the HTTP request and &lt;code&gt;foo: bar&lt;/code&gt; in the HTTP response.&lt;/p&gt; 
&lt;h3&gt;Get Real IP&lt;/h3&gt; 
&lt;h4&gt;HTTP X-Forwarded-For&lt;/h4&gt; 
&lt;p&gt;This feature is for &lt;code&gt;http&lt;/code&gt; proxies or proxies with the &lt;code&gt;https2http&lt;/code&gt; and &lt;code&gt;https2https&lt;/code&gt; plugins enabled.&lt;/p&gt; 
&lt;p&gt;You can get user's real IP from HTTP request headers &lt;code&gt;X-Forwarded-For&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Proxy Protocol&lt;/h4&gt; 
&lt;p&gt;frp supports Proxy Protocol to send user's real IP to local services.&lt;/p&gt; 
&lt;p&gt;Here is an example for https service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "https"
localPort = 443
customDomains = ["test.example.com"]

# now v1 and v2 are supported
transport.proxyProtocolVersion = "v2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable Proxy Protocol support in nginx to expose user's real IP in HTTP header &lt;code&gt;X-Real-IP&lt;/code&gt;, and then read &lt;code&gt;X-Real-IP&lt;/code&gt; header in your web service for the real IP.&lt;/p&gt; 
&lt;h3&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/h3&gt; 
&lt;p&gt;Anyone who can guess your tunnel URL can access your local web server unless you protect it with a password.&lt;/p&gt; 
&lt;p&gt;This enforces HTTP Basic Auth on all requests with the username and password specified in frpc's configure file.&lt;/p&gt; 
&lt;p&gt;It can only be enabled when proxy type is http.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://test.example.com&lt;/code&gt; in the browser and now you are prompted to enter the username and password.&lt;/p&gt; 
&lt;h3&gt;Custom Subdomain Names&lt;/h3&gt; 
&lt;p&gt;It is convenient to use &lt;code&gt;subdomain&lt;/code&gt; configure for http and https types when many people share one frps server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
subDomainHost = "frps.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Resolve &lt;code&gt;*.frps.com&lt;/code&gt; to the frps server's IP. This is usually called a Wildcard DNS record.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
subdomain = "test"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can visit your web service on &lt;code&gt;test.frps.com&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that if &lt;code&gt;subdomainHost&lt;/code&gt; is not empty, &lt;code&gt;customDomains&lt;/code&gt; should not be the subdomain of &lt;code&gt;subdomainHost&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;URL Routing&lt;/h3&gt; 
&lt;p&gt;frp supports forwarding HTTP requests to different backend web services by url routing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;locations&lt;/code&gt; specifies the prefix of URL used for routing. frps first searches for the most specific prefix location given by literal strings regardless of the listed order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web01"
type = "http"
localPort = 80
customDomains = ["web.example.com"]
locations = ["/"]

[[proxies]]
name = "web02"
type = "http"
localPort = 81
customDomains = ["web.example.com"]
locations = ["/news", "/about"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;HTTP requests with URL prefix &lt;code&gt;/news&lt;/code&gt; or &lt;code&gt;/about&lt;/code&gt; will be forwarded to &lt;strong&gt;web02&lt;/strong&gt; and other requests to &lt;strong&gt;web01&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Port Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to &lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The only supported TCP port multiplexing method available at the moment is &lt;code&gt;httpconnect&lt;/code&gt; - HTTP CONNECT tunnel.&lt;/p&gt; 
&lt;p&gt;When setting &lt;code&gt;tcpmuxHTTPConnectPort&lt;/code&gt; to anything other than 0 in frps, frps will listen on this port for HTTP CONNECT requests.&lt;/p&gt; 
&lt;p&gt;The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring &lt;code&gt;customDomains&lt;/code&gt; and / or &lt;code&gt;subdomain&lt;/code&gt; under &lt;code&gt;tcpmux&lt;/code&gt; proxies, when &lt;code&gt;multiplexer = "httpconnect"&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
tcpmuxHTTPConnectPort = 1337
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "proxy1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test1"]
localPort = 80

[[proxies]]
name = "proxy2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test2"]
localPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CONNECT test1 HTTP/1.1\r\n\r\n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the connection will be routed to &lt;code&gt;proxy1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting to frps via PROXY&lt;/h3&gt; 
&lt;p&gt;frpc can connect to frps through proxy if you set OS environment variable &lt;code&gt;HTTP_PROXY&lt;/code&gt;, or if &lt;code&gt;transport.proxyURL&lt;/code&gt; is set in frpc.toml file.&lt;/p&gt; 
&lt;p&gt;It only works when protocol is tcp.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
transport.proxyURL = "http://user:pwd@192.168.1.128:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port range mapping&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Added in v0.56.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;We can use the range syntax of Go template combined with the built-in &lt;code&gt;parseNumberRangePair&lt;/code&gt; function to achieve port range mapping.&lt;/p&gt; 
&lt;p&gt;The following example, when run, will create 8 proxies named &lt;code&gt;test-6000, test-6001 ... test-6007&lt;/code&gt;, each mapping the remote port to the local port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{{- range $_, $v := parseNumberRangePair "6000-6006,6007" "6000-6006,6007" }}
[[proxies]]
name = "tcp-{{ $v.First }}"
type = "tcp"
localPort = {{ $v.First }}
remotePort = {{ $v.Second }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client Plugins&lt;/h3&gt; 
&lt;p&gt;frpc only forwards requests to local TCP or UDP ports by default.&lt;/p&gt; 
&lt;p&gt;Plugins are used for providing rich features. There are built-in plugins such as &lt;code&gt;unix_domain_socket&lt;/code&gt;, &lt;code&gt;http_proxy&lt;/code&gt;, &lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;static_file&lt;/code&gt;, &lt;code&gt;http2https&lt;/code&gt;, &lt;code&gt;https2http&lt;/code&gt;, &lt;code&gt;https2https&lt;/code&gt; and you can see &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;example usage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Using plugin &lt;strong&gt;http_proxy&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "http_proxy"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "http_proxy"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;httpUser&lt;/code&gt; and &lt;code&gt;httpPassword&lt;/code&gt; are configuration parameters used in &lt;code&gt;http_proxy&lt;/code&gt; plugin.&lt;/p&gt; 
&lt;h3&gt;Server Manage Plugins&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/server_plugin.md"&gt;document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find more plugins in &lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SSH Tunnel Gateway&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;added in v0.53.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;frp supports listening to an SSH port on the frps side and achieves TCP protocol proxying through the SSH -R protocol, without relying on frpc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
sshTunnelGateway.bindPort = 2200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running &lt;code&gt;./frps -c frps.toml&lt;/code&gt;, a private key file named &lt;code&gt;.autogen_ssh_key&lt;/code&gt; will be automatically created in the current working directory. This generated private key file will be used by the SSH server in frps.&lt;/p&gt; 
&lt;p&gt;Executing the command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -R :80:127.0.0.1:8080 v0@{frp address} -p 2200 tcp --proxy_name "test-tcp" --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;sets up a proxy on frps that forwards the local 8080 service to the port 9090.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frp (via SSH) (Ctrl+C to quit)

User:
ProxyName: test-tcp
Type: tcp
RemoteAddress: :9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is equivalent to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frpc tcp --proxy_name "test-tcp" --local_ip 127.0.0.1 --local_port 8080 --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to this &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/ssh_tunnel_gateway.md"&gt;document&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Virtual Network (VirtualNet)&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Alpha feature added in v0.62.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The VirtualNet feature enables frp to create and manage virtual network connections between clients and visitors through a TUN interface. This allows for IP-level routing between machines, extending frp beyond simple port forwarding to support full network connectivity.&lt;/p&gt; 
&lt;p&gt;For detailed information about configuration and usage, please refer to the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/virtual_net.md"&gt;VirtualNet documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Gates&lt;/h2&gt; 
&lt;p&gt;frp supports feature gates to enable or disable experimental features. This allows users to try out new features before they're considered stable.&lt;/p&gt; 
&lt;h3&gt;Available Feature Gates&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VirtualNet&lt;/td&gt; 
   &lt;td&gt;ALPHA&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Virtual network capabilities for frp&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabling Feature Gates&lt;/h3&gt; 
&lt;p&gt;To enable an experimental feature, add the feature gate to your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;featureGates = { VirtualNet = true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Lifecycle&lt;/h3&gt; 
&lt;p&gt;Features typically go through three stages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ALPHA&lt;/strong&gt;: Disabled by default, may be unstable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BETA&lt;/strong&gt;: May be enabled by default, more stable but still evolving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GA (Generally Available)&lt;/strong&gt;: Enabled by default, ready for production use&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt; - A repository for frp plugins that contains a variety of plugins implemented based on the frp extension mechanism, meeting the customization needs of different scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/tiny-frpc"&gt;gofrp/tiny-frpc&lt;/a&gt; - A lightweight version of the frp client (around 3.5MB at minimum) implemented using the ssh protocol, supporting some of the most commonly used features, suitable for devices with limited resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in getting involved? We would like to help you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take a look at our &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues list&lt;/a&gt; and consider sending a Pull Request to &lt;strong&gt;dev branch&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to add a new feature, please create an issue first to describe the new feature, as well as the implementation approach. Once a proposal is accepted, create an implementation of the new features and submit it as a pull request.&lt;/li&gt; 
 &lt;li&gt;Sorry for my poor English. Improvements for this document are welcome, even some typo fixes.&lt;/li&gt; 
 &lt;li&gt;If you have great ideas, send an email to &lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note: We prefer you to give your advise in &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues&lt;/a&gt;, so others with a same question can search it quickly and we don't need to answer them repeatedly.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Donation&lt;/h2&gt; 
&lt;p&gt;If frp helps you a lot, you can support us by:&lt;/p&gt; 
&lt;h3&gt;GitHub Sponsors&lt;/h3&gt; 
&lt;p&gt;Support us by &lt;a href="https://github.com/sponsors/fatedier"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can have your company's logo placed on README file of this project.&lt;/p&gt; 
&lt;h3&gt;PayPal&lt;/h3&gt; 
&lt;p&gt;Donate money by &lt;a href="https://www.paypal.me/fatedier"&gt;PayPal&lt;/a&gt; to my account &lt;strong&gt;&lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gtsteffaniak/filebrowser</title>
      <link>https://github.com/gtsteffaniak/filebrowser</link>
      <description>&lt;p&gt;üìÇ Web File Browser&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/gtsteffaniak/filebrowser/backend"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gtsteffaniak/filebrowser/backend" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.codacy.com/gh/gtsteffaniak/filebrowser/dashboard"&gt;&lt;img src="https://app.codacy.com/project/badge/Grade/1c48cfb7646d4009aa8c6f71287670b8" alt="Codacy Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gtsteffaniak/filebrowser/releases"&gt;&lt;img src="https://img.shields.io/github/release/gtsteffaniak/filebrowser/all.svg?sanitize=true" alt="latest version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/gtstef/filebrowser"&gt;&lt;img src="https://img.shields.io/docker/pulls/gtstef/filebrowser?label=latest%20Docker%20pulls" alt="DockerHub Pulls" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="Apache-2.0 License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/gtsteffaniak/filebrowser/wiki/Q&amp;amp;A#is-there-a-way-to-donate-or-support-this-project"&gt;&lt;img src="https://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" alt="Donate" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;img width="150" src="https://github.com/user-attachments/assets/c40b22c9-33da-47b7-bc4c-ce69bb5cc174" title="Logo" /&gt; 
 &lt;h3&gt;FileBrowser Quantum&lt;/h3&gt; The best free self-hosted web-based file manager. 
 &lt;br /&gt;
 &lt;br /&gt; 
 &lt;img width="800" src="https://github.com/user-attachments/assets/162d7a95-33b7-49bd-976c-dd6822c0d22b" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] There is no stable version -- &lt;span&gt;üöß&lt;/span&gt; coming very soon!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Pinned&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;üì¢&lt;/span&gt; &lt;a href="https://github.com/gtsteffaniak/filebrowser/discussions/1293"&gt;Stable Release &amp;amp; v1.0.0 Update&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;üìå&lt;/span&gt; &lt;a href="https://filebrowserquantum.com/"&gt;Read The Official Docs&lt;/a&gt; (currently english-only)&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;FileBrowser Quantum provides an easy way to access and manage your files from the web. It has a modern responsive interface that has many advanced features to manage users, access, sharing, and file preview and editing.&lt;/p&gt; 
&lt;p&gt;This version is called "Quantum" because it packs tons of advanced features into a tiny easy to run file. Unlike the majority of alternative options, FileBrowser Quantum is simple to install and easy to configure.&lt;/p&gt; 
&lt;p&gt;The goal for this repo is to become the best open-source self-hosted file browsing application that exists -- &lt;strong&gt;all for free&lt;/strong&gt;. This repo will always be free and open-source.&lt;/p&gt; 
&lt;p&gt;Ready to try it out? See &lt;a href="https://filebrowserquantum.com/en/docs/getting-started/"&gt;Getting Started Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How its different&lt;/h2&gt; 
&lt;p&gt;FileBrowser Quantum is a massive fork of the file browser open-source project with the following changes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;‚úÖ Multiple sources support&lt;/li&gt; 
 &lt;li&gt;‚úÖ Login support for OIDC, password + 2FA, and proxy.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Beautiful, Responsive, and Customizable user interface.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Simplified configuration via &lt;code&gt;config.yaml&lt;/code&gt; config file.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Ultra-efficient &lt;a href="https://github.com/gtsteffaniak/filebrowser/wiki/Indexing"&gt;indexing&lt;/a&gt; and real-time updates 
  &lt;ul&gt; 
   &lt;li&gt;Real-time search results as you type.&lt;/li&gt; 
   &lt;li&gt;Real-time monitoring and updates in the UI.&lt;/li&gt; 
   &lt;li&gt;Search supports file and folder sizes, along with various filters.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;‚úÖ Better listing browsing 
  &lt;ul&gt; 
   &lt;li&gt;More file type previews, such as &lt;strong&gt;office&lt;/strong&gt; and &lt;strong&gt;video&lt;/strong&gt; file previews&lt;/li&gt; 
   &lt;li&gt;Instantly switches view modes and sort order without reloading data.&lt;/li&gt; 
   &lt;li&gt;Folder sizes are displayed.&lt;/li&gt; 
   &lt;li&gt;Navigating remembers the last scroll position.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;‚úÖ Highly configurable and customizable sharing options, incuding: 
  &lt;ul&gt; 
   &lt;li&gt;share expiration time&lt;/li&gt; 
   &lt;li&gt;users who can access share (including anonymous)&lt;/li&gt; 
   &lt;li&gt;styling and themes&lt;/li&gt; 
   &lt;li&gt;file viewing, editing, and uploading permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;‚úÖ Directory-level access control that can be scoped to user or group.&lt;/li&gt; 
 &lt;li&gt;‚úÖ Developer API support 
  &lt;ul&gt; 
   &lt;li&gt;Ability to create long-lived API Tokens.&lt;/li&gt; 
   &lt;li&gt;A helpful Swagger page is available at &lt;code&gt;/swagger&lt;/code&gt; endpoint for API enabled users.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Notable features that this fork &lt;em&gt;does not&lt;/em&gt; have (removed):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;üöß&lt;/span&gt; jobs are not supported yet.&lt;/li&gt; 
 &lt;li&gt;‚ùå shell commands are completely removed and will not be returned.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;FileBrowser Quantum differs significantly from the original version. Many of these changes required a significant overhaul. Creating a fork was a necessary process to make the program better. There have been many growing pains, but a stable release is planned and coming soon.&lt;/p&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Every file and directory in the source gets indexed (by default). This enables powerful features such as instant search, but large source filesystems can increase your system requirements. &lt;a href="https://github.com/gtsteffaniak/filebrowser/wiki/Indexing"&gt;See indexing wiki&lt;/a&gt; for more info.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: depends on configured source complexity. See &lt;a href="https://github.com/gtsteffaniak/filebrowser/discussions/787"&gt;how much RAM does it require?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU&lt;/strong&gt;: Not currently used (planned)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The UI&lt;/h2&gt; 
&lt;p&gt;The UI has a simple three-component navigation system:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;(Left) Multi-action button with slide-out panel.&lt;/li&gt; 
 &lt;li&gt;(Middle) The powerful search bar.&lt;/li&gt; 
 &lt;li&gt;(Right) The view change toggle.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;All other functions are moved either into the action menu or pop-up menus. If the action does not depend on context, it will exist in the slide-out action panel. If the action is available based on context, it will show up as a pop-up menu.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="1000" src="https://github.com/user-attachments/assets/aa32b05c-f917-47bb-b07f-857edc5e47f7" title="Search GIF" /&gt; &lt;/p&gt; 
&lt;h2&gt;Official Docs&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://filebrowserquantum.com/"&gt;Official Docs&lt;/a&gt;. Contributions are welcome and encouraged! See &lt;a href="https://github.com/quantumx-apps/filebrowserDocs"&gt;FilebrowserDocs Github&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Comparison Chart&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Application Name&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://github.com/user-attachments/assets/c40b22c9-33da-47b7-bc4c-ce69bb5cc174" /&gt; Quantum&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://github.com/filebrowser/filebrowser/raw/master/frontend/public/img/logo.svg?sanitize=true" /&gt; Filebrowser&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://github.com/mickael-kerjean/filestash/raw/master/public/assets/logo/app_icon.png?raw=true" /&gt; Filestash&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://avatars.githubusercontent.com/u/19211038?s=200&amp;amp;v=4" /&gt; Nextcloud&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Google_Drive_logo.png/480px-Google_Drive_logo.png" /&gt; Google_Drive&lt;/th&gt; 
   &lt;th&gt;&lt;img width="48" src="https://avatars.githubusercontent.com/u/6422152?v=4" /&gt; FileRun&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filesystem support&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mac&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Self hostable&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Has Stable Release?&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;S3 support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;webdav support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FTP support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dedicated docs site?&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multiple sources at once&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Docker image size&lt;/td&gt; 
   &lt;td&gt;180 MB (with ffmpeg)&lt;/td&gt; 
   &lt;td&gt;31 MB&lt;/td&gt; 
   &lt;td&gt;240 MB (main image)&lt;/td&gt; 
   &lt;td&gt;250 MB&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 2 GB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Min. Memory Requirements&lt;/td&gt; 
   &lt;td&gt;256 MB&lt;/td&gt; 
   &lt;td&gt;128 MB&lt;/td&gt; 
   &lt;td&gt;128 MB (main image)&lt;/td&gt; 
   &lt;td&gt;512 MB&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;512 MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;has standalone binary&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;price&lt;/td&gt; 
   &lt;td&gt;free&lt;/td&gt; 
   &lt;td&gt;free&lt;/td&gt; 
   &lt;td&gt;free&lt;/td&gt; 
   &lt;td&gt;free tier&lt;/td&gt; 
   &lt;td&gt;free tier&lt;/td&gt; 
   &lt;td&gt;$99+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rich media preview&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Upload files from the web?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Advanced Search?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;configurable&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indexed Search?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;configurable&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Content-aware search?&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;configurable&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Custom job support&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multiple users&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Single sign-on support&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LDAP sign-on support&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Long-live API key support&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API documentation page&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mobile App&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;open source?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tags support&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;shareable web links?&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Event-based notifications&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metrics&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;file space quotas&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;text-based files editor&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Office file support&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Office file previews&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Themes&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Branding support&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;activity log&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Comments support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;trash support&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starred/pinned files&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chromecast support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Share collections of files&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Can archive selected files&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Can browse archive files&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Can convert documents&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Can convert videos&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Can convert photos&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üöß&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
  </channel>
</rss>