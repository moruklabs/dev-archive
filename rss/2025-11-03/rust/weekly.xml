<rss version="2.0">
  <channel>
    <title>GitHub Rust Weekly Trending</title>
    <description>Weekly Trending of Rust in GitHub</description>
    <pubDate>Sun, 02 Nov 2025 01:45:11 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px" /&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version" /&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Tensor Library and Deep Learning Framework that doesn't compromise on &lt;br /&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;Burn is both a tensor library and a deep learning framework optimized for numerical computing, model inference and model training. Burn leverages Rust to perform optimizations normally only available in static-graph frameworks, offering optimal speed without impacting flexibility.&lt;/p&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px" /&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Supported Backends&lt;/h3&gt; 
 &lt;p&gt;Most backends support all operating systems, so we don't mention them in the tables below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;GPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;CUDA&lt;/th&gt; 
    &lt;th&gt;ROCm&lt;/th&gt; 
    &lt;th&gt;Metal&lt;/th&gt; 
    &lt;th&gt;Vulkan&lt;/th&gt; 
    &lt;th&gt;WebGPU&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Nvidia&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;AMD&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Apple&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Intel&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qualcom&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;CPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Cpu (CubeCL)&lt;/th&gt; 
    &lt;th&gt;NdArray&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;X86&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arm&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;no-std&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let device = Default::default();

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (&lt;code&gt;burn/fusion&lt;/code&gt; feature flag), so you typically don't need to apply it manually.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#[cfg(not(feature = "fusion"))]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;;

#[cfg(feature = "fusion")]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = burn_fusion::Fusion&amp;lt;CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;&amp;gt;;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px" /&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br /&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn's native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit from all of Burn's optimizations like automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution, and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px" /&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/import-model-weights"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br /&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px" /&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>kata-containers/kata-containers</title>
      <link>https://github.com/kata-containers/kata-containers</link>
      <description>&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/&lt;/p&gt;&lt;hr&gt;&lt;img src="https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg?sanitize=true" width="900" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg?sanitize=true" alt="CI | Publish Kata Containers payload" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg?sanitize=true" alt="Kata Containers Nightly CI" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Kata Containers&lt;/h1&gt; 
&lt;p&gt;Welcome to Kata Containers!&lt;/p&gt; 
&lt;p&gt;This repository is the home of the Kata Containers code for the 2.0 and newer releases.&lt;/p&gt; 
&lt;p&gt;If you want to learn about Kata Containers, visit the main &lt;a href="https://katacontainers.io"&gt;Kata Containers website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The code is licensed under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/LICENSE"&gt;the license file&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;Kata Containers currently runs on 64-bit systems supporting the following technologies:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Virtualization technology&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x86_64&lt;/code&gt;, &lt;code&gt;amd64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.intel.com"&gt;Intel&lt;/a&gt; VT-x, AMD SVM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;aarch64&lt;/code&gt; ("&lt;code&gt;arm64&lt;/code&gt;")&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arm.com"&gt;ARM&lt;/a&gt; Hyp&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ppc64le&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;s390x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Z &amp;amp; LinuxONE SIE&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware requirements&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;Kata Containers runtime&lt;/a&gt; provides a command to determine if your host system is capable of running and creating a Kata Container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ kata-runtime check
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;This command runs a number of checks including connecting to the network to determine if a newer release of Kata Containers is available on GitHub. If you do not wish this to check to run, add the &lt;code&gt;--no-network-checks&lt;/code&gt; option.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, only a brief success / failure message is printed. If more details are needed, the &lt;code&gt;--verbose&lt;/code&gt; flag can be used to display the list of all the checks performed.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the command is run as the &lt;code&gt;root&lt;/code&gt; user additional checks are run (including checking if another incompatible hypervisor is running). When running as &lt;code&gt;root&lt;/code&gt;, network checks are automatically disabled.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;official documentation&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;Installation guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;Developer guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design"&gt;Design documents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture"&gt;Architecture overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture_3.0/"&gt;Architecture 3.0 overview&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Kata Containers uses a single &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#configuration"&gt;configuration file&lt;/a&gt; which contains a number of sections for various parts of the Kata Containers system including the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;, the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#hypervisors"&gt;hypervisor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Hypervisors&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/hypervisors.md"&gt;hypervisors document&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#hypervisor-specific-configuration"&gt;Hypervisor specific configuration details&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To learn more about the project, its community and governance, see the &lt;a href="https://github.com/kata-containers/community"&gt;community repository&lt;/a&gt;. This is the first place to go if you wish to contribute to the project.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#community"&gt;community&lt;/a&gt; section for ways to contact us.&lt;/p&gt; 
&lt;h3&gt;Raising issues&lt;/h3&gt; 
&lt;p&gt;Please raise an issue &lt;a href="https://github.com/kata-containers/kata-containers/issues"&gt;in this repository&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are reporting a security issue, please follow the &lt;a href="https://github.com/kata-containers/community#vulnerability-handling"&gt;vulnerability reporting process&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;developer guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Components&lt;/h3&gt; 
&lt;h3&gt;Main components&lt;/h3&gt; 
&lt;p&gt;The table below lists the core parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Main component run by a container manager and providing a containerd shimv2 runtime implementation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime-rs"&gt;runtime-rs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;The Rust version runtime.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Management process running inside the virtual machine / POD that sets up the container environment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/dragonball"&gt;&lt;code&gt;dragonball&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;documentation&lt;/td&gt; 
   &lt;td&gt;Documentation common to all components (such as design and install documentation).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests"&gt;tests&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;tests&lt;/td&gt; 
   &lt;td&gt;Excludes unit tests which live with the main code.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Additional components&lt;/h3&gt; 
&lt;p&gt;The table below lists the remaining parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging"&gt;packaging&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Scripts and metadata for producing packaged binaries&lt;br /&gt;(components, hypervisors, kernel and rootfs).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.kernel.org"&gt;kernel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;kernel&lt;/td&gt; 
   &lt;td&gt;Linux kernel used by the hypervisor to boot the guest image. Patches are stored &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kernel"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/osbuilder"&gt;osbuilder&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Tool to create "mini O/S" rootfs and initrd images and kernel for the hypervisor.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-debug/README.md"&gt;kata-debug&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Utility tool to gather Kata Containers debug information from Kubernetes clusters.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/agent-ctl"&gt;&lt;code&gt;agent-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides low-level access for testing the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/kata-ctl"&gt;&lt;code&gt;kata-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides advanced commands and debug facilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/trace-forwarder"&gt;&lt;code&gt;trace-forwarder&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Agent tracing helper.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/runk"&gt;&lt;code&gt;runk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Standard OCI container runtime based on the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/.github/workflows"&gt;&lt;code&gt;ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration files and scripts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/ci/openshift-ci/README.md"&gt;&lt;code&gt;ocp-ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration for the OpenShift pipelines.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kata-containers/www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Source for the &lt;a href="https://www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt; site.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/testing/kata-webhook/README.md"&gt;&lt;code&gt;Webhook&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Example of a simple admission controller webhook to annotate pods with the Kata runtime class&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Packaging and releases&lt;/h3&gt; 
&lt;p&gt;Kata Containers is now &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install/README.md#packaged-installation-methods"&gt;available natively for most distributions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/README.md"&gt;tests documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Metrics tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/metrics/README.md"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Glossary of Terms&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/kata-containers/kata-containers/wiki/Glossary"&gt;glossary of terms&lt;/a&gt; related to Kata Containers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rolldown/rolldown</title>
      <link>https://github.com/rolldown/rolldown</link>
      <description>&lt;p&gt;Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://rolldown.rs" target="_blank" rel="noopener noreferrer"&gt; &lt;img width="180" src="https://rolldown.rs/rolldown-round.svg?sanitize=true" alt="Rolldown logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/rolldown/rolldown/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/v/rolldown/latest?color=brightgreen" alt="NPM version" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/rolldown/rolldown"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="CodSpeed Badge" /&gt;&lt;/a&gt; &lt;a href="https://chat.rolldown.rs"&gt;&lt;img src="https://img.shields.io/discord/1079625926024900739?logo=discord&amp;amp;label=Discord" alt="Discord chat" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/rolldown/rolldown"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm" alt="NPM Unpacked Size (with version)" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-arm64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64" alt="NPM Unpacked Size darwin-arm64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-x64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64" alt="NPM Unpacked Size darwin-x64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu" alt="NPM Unpacked Size linux-x64-gnu" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64" alt="NPM Unpacked Size win32-x64" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi" alt="NPM Unpacked Size wasm32-wasi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pkg.pr.new/~/rolldown/rolldown"&gt;&lt;img src="https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&amp;amp;color=000&amp;amp;logoSize=auto" alt="pkg.pr.new" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz"&gt;&lt;img src="https://developer.stackblitz.com/img/open_in_stackblitz.svg?sanitize=true" alt="rolldown-starter-stackblitz" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üöß &lt;strong&gt;Beta Software&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Rolldown is currently in beta status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Rolldown&lt;/h1&gt; 
&lt;p&gt;Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in &lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;. It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.&lt;/p&gt; 
&lt;p&gt;For more information, please check out the documentation at &lt;a href="https://rolldown.rs/about"&gt;rolldown.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;VoidZero Inc.&lt;/h2&gt; 
&lt;p&gt;Rolldown is a project of &lt;a href="https://voidzero.dev/"&gt;VoidZero&lt;/a&gt;, see our announcement &lt;a href="https://voidzero.dev/posts/announcing-voidzero-inc"&gt;Announcing VoidZero - Next Generation Toolchain for JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have requirements for JavaScript tools at scale, please &lt;a href="https://forms.gle/WQgjyzYJpwurpxWKA"&gt;get in touch&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would love to have more contributors involved!&lt;/p&gt; 
&lt;p&gt;To get started, please read our &lt;a href="https://rolldown.rs/contribution-guide/"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The Rolldown project is heavily inspired by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup"&gt;Rollup&lt;/a&gt;, created by &lt;a href="https://github.com/Rich-Harris"&gt;Rich Harris&lt;/a&gt; and maintained by &lt;a href="https://github.com/lukastaegert"&gt;Lukas Taegert-Atkinson&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild"&gt;esbuild&lt;/a&gt;, created by &lt;a href="https://github.com/evanw"&gt;Evan Wallace&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And supported by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/napi-rs/napi-rs"&gt;napi-rs&lt;/a&gt; for Node.js add-ons in Rust via Node-API.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc"&gt;oxc&lt;/a&gt; for the underlying parser, resolver, and sourcemap support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project also partially contains code derived or copied from the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup/raw/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md"&gt;rollup(MIT)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild/raw/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md"&gt;esbuild(MIT)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Licenses of these projects are listed in &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/THIRD-PARTY-LICENSE"&gt;THIRD-PARTY-LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustfs/rustfs</title>
      <link>https://github.com/rustfs/rustfs</link>
      <description>&lt;p&gt;üöÄ RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rustfs.com"&gt;&lt;img src="https://rustfs.com/images/rustfs-github.png" alt="RustFS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;RustFS is a high-performance distributed object storage software built using Rust&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/ci.yml"&gt;&lt;img alt="CI" src="https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/docker.yml"&gt;&lt;img alt="Build and Push Docker Images" src="https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rustfs/rustfs" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/rustfs/rustfs" /&gt; &lt;a href="https://hellogithub.com/repository/rustfs/rustfs" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;amp;claim_uid=MsbvjYeLDKAH457&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.rustfs.com/introduction.html"&gt;Getting Started&lt;/a&gt; ¬∑ &lt;a href="https://docs.rustfs.com/"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;Bug reports&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; English | &lt;a href="https://github.com/rustfs/rustfs/raw/main/README_ZH.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=pt"&gt;Portuguese&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;RustFS is a high-performance distributed object storage software built using Rust, one of the most popular languages worldwide. Along with MinIO, it shares a range of advantages such as simplicity, S3 compatibility, open-source nature, support for data lakes, AI, and big data. Furthermore, it has a better and more user-friendly open-source license in comparison to other storage systems, being constructed under the Apache license. As Rust serves as its foundation, RustFS provides faster speed and safer distributed features for high-performance object storage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;RustFS is under rapid development. Do NOT use in production environments!&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Built with Rust, ensuring speed and efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Architecture&lt;/strong&gt;: Scalable and fault-tolerant design for large-scale deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Compatibility&lt;/strong&gt;: Seamless integration with existing S3-compatible applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Lake Support&lt;/strong&gt;: Optimized for big data and AI workloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Licensed under Apache 2.0, encouraging community contributions and transparency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly&lt;/strong&gt;: Designed with simplicity in mind, making it easy to deploy and manage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RustFS vs MinIO&lt;/h2&gt; 
&lt;p&gt;Stress test server parameters&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;parameter&lt;/th&gt; 
   &lt;th&gt;Remark&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;2 Core&lt;/td&gt; 
   &lt;td&gt;Intel Xeon(Sapphire Rapids) Platinum 8475B , 2.7/3.2 GHz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Network&lt;/td&gt; 
   &lt;td&gt;15Gbp&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Driver&lt;/td&gt; 
   &lt;td&gt;40GB x 4&lt;/td&gt; 
   &lt;td&gt;IOPS 3800 / Driver&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a"&gt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RustFS vs Other object storage&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RustFS&lt;/th&gt; 
   &lt;th&gt;Other object storage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Powerful Console&lt;/td&gt; 
   &lt;td&gt;Simple and useless Console&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Developed based on Rust language, memory is safer&lt;/td&gt; 
   &lt;td&gt;Developed in Go or C, with potential issues like memory GC/leaks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Does not report logs to third-party countries&lt;/td&gt; 
   &lt;td&gt;Reporting logs to other third countries may violate national security laws&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Licensed under Apache, more business-friendly&lt;/td&gt; 
   &lt;td&gt;AGPL V3 License and other License, polluted open source and License traps, infringement of intellectual property rights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Comprehensive S3 support, works with domestic and international cloud providers&lt;/td&gt; 
   &lt;td&gt;Full support for S3, but no local cloud vendor support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust-based development, strong support for secure and innovative devices&lt;/td&gt; 
   &lt;td&gt;Poor support for edge gateways and secure innovative devices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stable commercial prices, free community support&lt;/td&gt; 
   &lt;td&gt;High pricing, with costs up to $250,000 for 1PiB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;No risk&lt;/td&gt; 
   &lt;td&gt;Intellectual property risks and risks of prohibited uses&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get started with RustFS, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;One-click installation script (Option 1)‚Äã‚Äã&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O  https://rustfs.com/install_rustfs.sh &amp;amp;&amp;amp; bash install_rustfs.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Quick Start (Option 2)‚Äã‚Äã&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; # create data and logs directories
 mkdir -p data logs

 # using latest alpha version
 docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:alpha

 # Specific version
 docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0.alpha.45
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For docker installation, you can also run the container with docker compose. With the &lt;code&gt;docker-compose.yml&lt;/code&gt; file under root directory, running the command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker compose --profile observability up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You should be better to have a look for &lt;code&gt;docker-compose.yaml&lt;/code&gt; file. Because, several services contains in the file. Grafan,prometheus,jaeger containers will be launched using docker compose file, which is helpful for rustfs observability. If you want to start redis as well as nginx container, you can specify the corresponding profiles.&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build from Source (Option 3) - Advanced Users&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For developers who want to build RustFS Docker images from source with multi-architecture support:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;docker-buildx.sh&lt;/code&gt; script supports:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Multi-architecture builds&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Automatic version detection&lt;/strong&gt;: Uses git tags or commit hashes&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Registry flexibility&lt;/strong&gt;: Supports Docker Hub, GitHub Container Registry, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Build optimization&lt;/strong&gt;: Includes caching and parallel builds&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;You can also use Make targets for convenience:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build with helm chart(Option 4) - Cloud Native environment&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Following the instructions on &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/helm/README.md"&gt;helm chart README&lt;/a&gt; to install RustFS on kubernetes cluster.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the Console&lt;/strong&gt;: Open your web browser and navigate to &lt;code&gt;http://localhost:9000&lt;/code&gt; to access the RustFS console, default username and password is &lt;code&gt;rustfsadmin&lt;/code&gt; .&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create a Bucket&lt;/strong&gt;: Use the console to create a new bucket for your objects.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Upload Objects&lt;/strong&gt;: You can upload files directly through the console or use S3-compatible APIs to interact with your RustFS instance.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you want to access RustFS instance with &lt;code&gt;https&lt;/code&gt;, you can refer to &lt;a href="https://docs.rustfs.com/integration/tls-configured.html"&gt;TLS configuration docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, including configuration options, API references, and advanced usage, please visit our &lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or need assistance, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://github.com/rustfs/rustfs/discussions/categories/q-a"&gt;FAQ&lt;/a&gt; for common issues and solutions.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions and share your experiences.&lt;/li&gt; 
 &lt;li&gt;Open an issue on our &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt; page for bug reports or feature requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/releases"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@rustfs.com"&gt;hello@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:jobs@rustfs.com"&gt;jobs@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;RustFS is a community-driven project, and we appreciate all contributions. Check out the &lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt;Contributors&lt;/a&gt; page to see the amazing people who have helped make RustFS better.&lt;/p&gt; 
&lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt; &lt;img src="https://opencollective.com/rustfs/contributors.svg?width=890&amp;amp;limit=500&amp;amp;button=false" alt="Contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Github Trending Top&lt;/h2&gt; 
&lt;p&gt;üöÄ RustFS is beloved by open-source enthusiasts and enterprise users worldwide, often appearing on the GitHub Trending top charts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14181" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/rustfs/rustfs/refs/heads/main/docs/rustfs-trending.jpg" alt="rustfs%2Frustfs | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RustFS&lt;/strong&gt; is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zed-industries/zed</title>
      <link>https://github.com/zed-industries/zed</link>
      <description>&lt;p&gt;Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Zed&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zed.dev"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json" alt="Zed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zed-industries/zed/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to Zed, a high-performance, multiplayer code editor from the creators of &lt;a href="https://github.com/atom/atom"&gt;Atom&lt;/a&gt; and &lt;a href="https://github.com/tree-sitter/tree-sitter"&gt;Tree-sitter&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;On macOS, Linux, and Windows you can &lt;a href="https://zed.dev/download"&gt;download Zed directly&lt;/a&gt; or &lt;a href="https://zed.dev/docs/linux#installing-via-a-package-manager"&gt;install Zed via your local package manager&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Other platforms are not yet available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web (&lt;a href="https://github.com/zed-industries/zed/issues/5396"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developing Zed&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/macos.md"&gt;Building Zed for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/linux.md"&gt;Building Zed for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/windows.md"&gt;Building Zed for Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/local-collaboration.md"&gt;Running Collaboration Locally&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for ways you can contribute to Zed.&lt;/p&gt; 
&lt;p&gt;Also... we're hiring! Check out our &lt;a href="https://zed.dev/jobs"&gt;jobs&lt;/a&gt; page for open roles.&lt;/p&gt; 
&lt;h3&gt;Licensing&lt;/h3&gt; 
&lt;p&gt;License information for third party dependencies must be correctly provided for CI to pass.&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/EmbarkStudios/cargo-about"&gt;&lt;code&gt;cargo-about&lt;/code&gt;&lt;/a&gt; to automatically comply with open source licenses. If CI is failing, check the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Is it showing a &lt;code&gt;no license specified&lt;/code&gt; error for a crate you've created? If so, add &lt;code&gt;publish = false&lt;/code&gt; under &lt;code&gt;[package]&lt;/code&gt; in your crate's Cargo.toml.&lt;/li&gt; 
 &lt;li&gt;Is the error &lt;code&gt;failed to satisfy license requirements&lt;/code&gt; for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the &lt;code&gt;accepted&lt;/code&gt; array in &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Is &lt;code&gt;cargo-about&lt;/code&gt; unable to find the license for a dependency? If so, add a clarification field at the end of &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;, as specified in the &lt;a href="https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration"&gt;cargo-about book&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚ùáÔ∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üêç &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;üî© Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;üè¢ Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;üíæ Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;‚è¨ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juÀê viÀê/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Zackriya-Solutions/meeting-minutes</title>
      <link>https://github.com/Zackriya-Solutions/meeting-minutes</link>
      <description>&lt;p&gt;A free and open source, self hosted Ai based live meeting note taker and minutes summary generator that can completely run in your Local device (Mac OS and windows OS Support added. Working on adding linux support soon) https://meetily.zackriya.com/ is meetly ai&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="border-bottom: none"&gt; 
 &lt;h1&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/Meetily-6.png" style="border-radius: 10px;" /&gt; &lt;br /&gt; Privacy-First AI Meeting Assistant &lt;/h1&gt; 
 &lt;a href="https://trendshift.io/repositories/13272" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13272" alt="Zackriya-Solutions%2Fmeeting-minutes | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases/"&gt;&lt;img src="https://img.shields.io/badge/Pre_Release-Link-brightgreen" alt="Pre-Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt; &lt;img alt="GitHub Downloads (all assets, all releases)" src="https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue" alt="License" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img src="https://img.shields.io/badge/Supported_OS-macOS,_Windows-white" alt="Supported OS" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img alt="GitHub Tag" src="https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&amp;amp;color=yellow" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;h3&gt; &lt;br /&gt; Open Source ‚Ä¢ Privacy-First ‚Ä¢ Enterprise-Ready &lt;/h3&gt; 
 &lt;p align="center"&gt; Get latest &lt;a href="https://www.zackriya.com/meetily-subscribe/"&gt;&lt;b&gt;Product updates&lt;/b&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://meetily.zackriya.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.linkedin.com/company/106363062/"&gt;&lt;b&gt;LinkedIn&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/crRymMQBFH"&gt;&lt;b&gt;Meetily Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.com/invite/vCFJvN4BwJ"&gt;&lt;b&gt;Privacy-First AI&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.reddit.com/r/meetily/"&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;A privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/meetily_demo.gif" width="650" alt="Meetily Demo" /&gt; &lt;br /&gt; &lt;a href="https://youtu.be/6FnhSC_eSz8"&gt;View full Demo Video&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Table of Contents&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#why-meetily"&gt;Why Meetily?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#key-features-in-action"&gt;Key Features in Action&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#system-architecture"&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#for-developers"&gt;For Developers&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#enterprise-solutions"&gt;Enterprise Solutions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Meetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.&lt;/p&gt; 
&lt;h2&gt;Why Meetily?&lt;/h2&gt; 
&lt;p&gt;While there are many meeting transcription tools available, this solution stands out by offering:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy First:&lt;/strong&gt; All processing happens locally on your device.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost-Effective:&lt;/strong&gt; Uses open-source AI models instead of expensive APIs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; Works offline and supports multiple meeting platforms.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable:&lt;/strong&gt; Self-host and modify for your specific needs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;The Privacy Problem&lt;/summary&gt; 
 &lt;p&gt;Meeting AI tools create significant privacy and compliance risks across all sectors:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;$4.4M average cost per data breach&lt;/strong&gt; (IBM 2024)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‚Ç¨5.88 billion in GDPR fines&lt;/strong&gt; issued by 2025&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;400+ unlawful recording cases&lt;/strong&gt; filed in California this year&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Whether you're a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn't live on servers you don't control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Meetily solves this:&lt;/strong&gt; Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local First:&lt;/strong&gt; All processing is done on your machine. No data ever leaves your computer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Transcription:&lt;/strong&gt; Get a live transcript of your meeting as it happens.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Summaries:&lt;/strong&gt; Generate summaries of your meetings using powerful language models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Platform:&lt;/strong&gt; Works on macOS, Windows, and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source:&lt;/strong&gt; Meetily is open source and free to use.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;ü™ü &lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest &lt;code&gt;x64-setup.exe&lt;/code&gt; from &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Right-click the downloaded file ‚Üí &lt;strong&gt;Properties&lt;/strong&gt; ‚Üí Check &lt;strong&gt;Unblock&lt;/strong&gt; ‚Üí Click &lt;strong&gt;OK&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run the installer (if Windows shows a security warning: Click &lt;strong&gt;More info&lt;/strong&gt; ‚Üí &lt;strong&gt;Run anyway&lt;/strong&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üçé &lt;strong&gt;macOS&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Install via Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Meetily (single application - everything included!)
brew tap zackriya-solutions/meetily
brew install --cask meetily
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Upgrading from v0.0.5?&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update
brew upgrade --cask meetily
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open &lt;strong&gt;Meetily&lt;/strong&gt; from Applications folder.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Data Migration:&lt;/strong&gt; The application will ask whether to import your old database through a popup window on first launch.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üêß &lt;strong&gt;Linux&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Build from source following our detailed guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/building_in_linux.md"&gt;Building on Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/BUILDING.md"&gt;General Build Instructions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Zackriya-Solutions/meeting-minutes
cd meeting-minutes/frontend
pnpm install
pnpm run tauri:build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Key Features in Action&lt;/h2&gt; 
&lt;h3&gt;üéØ Local Transcription&lt;/h3&gt; 
&lt;p&gt;Transcribe meetings entirely on your device using &lt;strong&gt;Whisper&lt;/strong&gt; or &lt;strong&gt;Parakeet&lt;/strong&gt; models. No cloud required.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/home.png" width="650" style="border-radius: 10px;" alt="Meetily Demo" /&gt; &lt;/p&gt; 
&lt;h3&gt;ü§ñ AI-Powered Summaries&lt;/h3&gt; 
&lt;p&gt;Generate meeting summaries with your choice of AI provider. &lt;strong&gt;Ollama&lt;/strong&gt; (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/summary.png" width="650" style="border-radius: 10px;" alt="Summary generation" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/editor1.png" width="650" style="border-radius: 10px;" alt="Editor Summary generation" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîí Privacy-First Design&lt;/h3&gt; 
&lt;p&gt;All data stays on your machine. Transcription models, recordings, and transcripts are stored locally.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/settings.png" width="650" style="border-radius: 10px;" alt="Local Transcription and storage" /&gt; &lt;/p&gt; 
&lt;h3&gt;üéôÔ∏è Professional Audio Mixing&lt;/h3&gt; 
&lt;p&gt;Capture microphone and system audio simultaneously with intelligent ducking and clipping prevention.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/audio.png" width="650" style="border-radius: 10px;" alt="Device selection" /&gt; &lt;/p&gt; 
&lt;h3&gt;‚ö° GPU Acceleration&lt;/h3&gt; 
&lt;p&gt;Built-in support for hardware acceleration across platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: Apple Silicon (Metal) + CoreML&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows/Linux&lt;/strong&gt;: NVIDIA (CUDA), AMD/Intel (Vulkan)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Automatically enabled at build time - no configuration needed.&lt;/p&gt; 
&lt;h2&gt;System Architecture&lt;/h2&gt; 
&lt;p&gt;Meetily is a single, self-contained application built with &lt;a href="https://tauri.app/"&gt;Tauri&lt;/a&gt;. It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.&lt;/p&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/architecture.md"&gt;Architecture documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;For Developers&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to Meetily or build it from source, you'll need to have Rust and Node.js installed. For detailed build instructions, please see the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/BUILDING.md"&gt;Building from Source guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Enterprise Solutions&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Meetily Enterprise&lt;/strong&gt; is available for on-premise deployment, giving organizations complete control over their meeting intelligence infrastructure. This enterprise version includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;100% On-Premise Deployment&lt;/strong&gt;: Your data never leaves your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Centralized Management&lt;/strong&gt;: Support for 100+ users with administrative controls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero Vendor Lock-in&lt;/strong&gt;: Open source MIT license ensures complete ownership&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compliance Ready&lt;/strong&gt;: Meet GDPR, SOX, HIPAA, and industry-specific requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Integration&lt;/strong&gt;: APIs and webhooks for enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise solutions: &lt;a href="https://meetily.zackriya.com"&gt;https://meetily.zackriya.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - Feel free to use this project for your own purposes.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Thanks for all the contributions. Our community is what makes this project possible. Below is the list of contributors:&lt;/p&gt; 
&lt;a href="https://github.com/zackriya-solutions/meeting-minutes/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=zackriya-solutions/meeting-minutes" /&gt; &lt;/a&gt; 
&lt;p&gt;We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;Whisper.cpp&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://github.com/mediar-ai/screenpipe"&gt;Screenpipe&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://crates.io/crates/transcribe-rs"&gt;transcribe-rs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;strong&gt;NVIDIA&lt;/strong&gt; for developing the &lt;strong&gt;Parakeet&lt;/strong&gt; model.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx"&gt;istupakov&lt;/a&gt; for providing the &lt;strong&gt;ONNX conversion&lt;/strong&gt; of the Parakeet model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Zackriya-Solutions/meeting-minutes&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>servo/servo</title>
      <link>https://github.com/servo/servo</link>
      <description>&lt;p&gt;Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Servo Parallel Browser Engine Project&lt;/h1&gt; 
&lt;p&gt;Servo is a prototype web browser engine written in the &lt;a href="https://github.com/rust-lang/rust"&gt;Rust&lt;/a&gt; language. It is currently developed on 64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.&lt;/p&gt; 
&lt;p&gt;Servo welcomes contribution from everyone. Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://book.servo.org"&gt;Servo Book&lt;/a&gt; for documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://servo.org/"&gt;servo.org&lt;/a&gt; for news and guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Coordination of Servo development happens:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Here in the Github Issues&lt;/li&gt; 
 &lt;li&gt;On the &lt;a href="https://servo.zulipchat.com/"&gt;Servo Zulip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;In video calls advertised in the &lt;a href="https://github.com/servo/project/issues"&gt;Servo Project&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For more detailed build instructions, see the Servo book under &lt;a href="https://book.servo.org/hacking/setting-up-your-environment.html"&gt;Setting up your environment&lt;/a&gt;, &lt;a href="https://book.servo.org/hacking/building-servo.html"&gt;Building Servo&lt;/a&gt;, &lt;a href="https://book.servo.org/hacking/building-for-android.html"&gt;Building for Android&lt;/a&gt; and &lt;a href="https://book.servo.org/hacking/building-for-openharmony.html"&gt;Building for OpenHarmony&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install &lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt; and &lt;a href="https://brew.sh/"&gt;&lt;code&gt;brew&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;curl&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Arch: &lt;code&gt;sudo pacman -S --needed curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Debian, Ubuntu: &lt;code&gt;sudo apt install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Fedora: &lt;code&gt;sudo dnf install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gentoo: &lt;code&gt;sudo emerge net-misc/curl&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download &lt;a href="https://docs.astral.sh/uv/getting-started/installation/#standalone-installer"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://chocolatey.org/install#individual"&gt;&lt;code&gt;choco&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://win.rustup.rs/"&gt;&lt;code&gt;rustup&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Be sure to select &lt;em&gt;Quick install via the Visual Studio Community installer&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;In the Visual Studio Installer, ensure the following components are installed: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows 10/11 SDK (anything &amp;gt;= 10.0.19041.0)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&amp;gt;=19041}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.Tools.x86.x64&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;C++ ATL for latest v143 build tools (x86 &amp;amp; x64)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.ATL&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;.\mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;.\mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure that the following environment variables are set: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_NDK_ROOT&lt;/code&gt;: &lt;code&gt;$ANDROID_SDK_ROOT/ndk/28.2.13676358/&lt;/code&gt; &lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt; can be any directory (such as &lt;code&gt;~/android-sdk&lt;/code&gt;). All of the Android build dependencies will be installed there.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install the latest version of the &lt;a href="https://developer.android.com/studio#command-tools"&gt;Android command-line tools&lt;/a&gt; to &lt;code&gt;$ANDROID_SDK_ROOT/cmdline-tools/latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the following command to install the necessary components: &lt;pre&gt;&lt;code class="language-shell"&gt;sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
 "build-tools;34.0.0" \
 "emulator" \
 "ndk;28.2.13676358" \
 "platform-tools" \
 "platforms;android-33" \
 "system-images;android-33;google_apis;x86_64"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;OpenHarmony&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on to prepare the environment.&lt;/li&gt; 
 &lt;li&gt;Depending on the target distribution (e.g. &lt;code&gt;HarmonyOS NEXT&lt;/code&gt; vs pure &lt;code&gt;OpenHarmony&lt;/code&gt;) the build configuration will differ slightly.&lt;/li&gt; 
 &lt;li&gt;Ensure that the following environment variables are set 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;DEVECO_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;HarmonyOS NEXT&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_BASE_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;OpenHarmony&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_SDK_NATIVE&lt;/code&gt; (e.g. &lt;code&gt;${DEVECO_SDK_HOME}/default/openharmony/native&lt;/code&gt; or &lt;code&gt;${OHOS_BASE_SDK_HOME}/${API_VERSION}/native&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SERVO_OHOS_SIGNING_CONFIG&lt;/code&gt;: Path to json file containing a valid signing configuration for the demo app.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Review the detailed instructions at &lt;a href="https://book.servo.org/hacking/building-for-openharmony.html"&gt;Building for OpenHarmony&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The target distribution can be modified by passing &lt;code&gt;--flavor=&amp;lt;default|harmonyos&amp;gt;&lt;/code&gt; to &lt;code&gt;mach &amp;lt;build|package|install&amp;gt;&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/quiche</title>
      <link>https://github.com/cloudflare/quiche</link>
      <description>&lt;p&gt;ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudflare/quiche/master/quiche.svg?sanitize=true" alt="quiche" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/quiche"&gt;&lt;img src="https://img.shields.io/crates/v/quiche.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/quiche"&gt;&lt;img src="https://docs.rs/quiche/badge.svg?sanitize=true" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/BSD-2-Clause"&gt;&lt;img src="https://img.shields.io/github/license/cloudflare/quiche.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master" alt="build" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/"&gt;quiche&lt;/a&gt; is an implementation of the QUIC transport protocol and HTTP/3 as specified by the &lt;a href="https://quicwg.org/"&gt;IETF&lt;/a&gt;. It provides a low level API for processing QUIC packets and handling connection state. The application is responsible for providing I/O (e.g. sockets handling) as well as an event loop with support for timers.&lt;/p&gt; 
&lt;p&gt;For more information on how quiche came about and some insights into its design you can read a &lt;a href="https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/"&gt;post&lt;/a&gt; on Cloudflare's blog that goes into some more detail.&lt;/p&gt; 
&lt;h2&gt;Who uses quiche?&lt;/h2&gt; 
&lt;h3&gt;Cloudflare&lt;/h3&gt; 
&lt;p&gt;quiche powers Cloudflare edge network's &lt;a href="https://blog.cloudflare.com/http3-the-past-present-and-future/"&gt;HTTP/3 support&lt;/a&gt;. The &lt;a href="https://cloudflare-quic.com"&gt;cloudflare-quic.com&lt;/a&gt; website can be used for testing and experimentation.&lt;/p&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;Android's DNS resolver uses quiche to &lt;a href="https://security.googleblog.com/2022/07/dns-over-http3-in-android.html"&gt;implement DNS over HTTP/3&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;curl&lt;/h3&gt; 
&lt;p&gt;quiche can be &lt;a href="https://github.com/curl/curl/raw/master/docs/HTTP3.md#quiche-version"&gt;integrated into curl&lt;/a&gt; to provide support for HTTP/3.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Command-line apps&lt;/h3&gt; 
&lt;p&gt;Before diving into the quiche API, here are a few examples on how to use the quiche tools provided as part of the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/apps/"&gt;quiche-apps&lt;/a&gt; crate.&lt;/p&gt; 
&lt;p&gt;After cloning the project according to the command mentioned in the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/#building"&gt;building&lt;/a&gt; section, the client can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;while the server can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note that the certificate provided is self-signed and should not be used in production)&lt;/p&gt; 
&lt;p&gt;Use the &lt;code&gt;--help&lt;/code&gt; command-line flag to get a more detailed description of each tool's options.&lt;/p&gt; 
&lt;h3&gt;Configuring connections&lt;/h3&gt; 
&lt;p&gt;The first step in establishing a QUIC connection using quiche is creating a &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;amp;[b"example-proto"]);

// Additional configuration specific to application and use case...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object controls important aspects of the QUIC connection such as QUIC version, ALPN IDs, flow control, congestion control, idle timeout and other properties or features.&lt;/p&gt; 
&lt;p&gt;QUIC is a general-purpose transport protocol and there are several configuration properties where there is no reasonable default value. For example, the permitted number of concurrent streams of any particular type is dependent on the application running over QUIC, and other use-case specific concerns.&lt;/p&gt; 
&lt;p&gt;quiche defaults several properties to zero, applications most likely need to set these to something else to satisfy their needs using the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi"&gt;&lt;code&gt;set_initial_max_streams_bidi()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni"&gt;&lt;code&gt;set_initial_max_streams_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data"&gt;&lt;code&gt;set_initial_max_data()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_local()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_remote()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni"&gt;&lt;code&gt;set_initial_max_stream_data_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; also holds TLS configuration. This can be changed by mutators on the an existing object, or by constructing a TLS context manually and creating a configuration using &lt;a href="https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder"&gt;&lt;code&gt;with_boring_ssl_ctx_builder()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A configuration object can be shared among multiple connections.&lt;/p&gt; 
&lt;h3&gt;Connection setup&lt;/h3&gt; 
&lt;p&gt;On the client-side the &lt;a href="https://docs.quic.tech/quiche/fn.connect.html"&gt;&lt;code&gt;connect()&lt;/code&gt;&lt;/a&gt; utility function can be used to create a new connection, while &lt;a href="https://docs.quic.tech/quiche/fn.accept.html"&gt;&lt;code&gt;accept()&lt;/code&gt;&lt;/a&gt; is for servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Client connection.
let conn = quiche::connect(Some(&amp;amp;server_name), &amp;amp;scid, local, peer, &amp;amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;amp;scid, None, local, peer, &amp;amp;mut config)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Handling incoming packets&lt;/h3&gt; 
&lt;p&gt;Using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.recv"&gt;&lt;code&gt;recv()&lt;/code&gt;&lt;/a&gt; method the application can process incoming packets that belong to that connection from the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;amp;mut buf[..read], recv_info) {
        Ok(v) =&amp;gt; v,

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Generating outgoing packets&lt;/h3&gt; 
&lt;p&gt;Outgoing packet are generated using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When packets are sent, the application is responsible for maintaining a timer to react to time-based connection events. The timer expiration can be obtained using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.timeout"&gt;&lt;code&gt;timeout()&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let timeout = conn.timeout();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application is responsible for providing a timer implementation, which can be specific to the operating system or networking framework used. When a timer expires, the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout"&gt;&lt;code&gt;on_timeout()&lt;/code&gt;&lt;/a&gt; method should be called, after which additional packets might need to be sent on the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Pacing&lt;/h4&gt; 
&lt;p&gt;It is recommended that applications &lt;a href="https://datatracker.ietf.org/doc/html/rfc9002#section-7.7"&gt;pace&lt;/a&gt; sending of outgoing packets to avoid creating packet bursts that could cause short-term congestion and losses in the network.&lt;/p&gt; 
&lt;p&gt;quiche exposes pacing hints for outgoing packets through the [&lt;code&gt;at&lt;/code&gt;] field of the [&lt;code&gt;SendInfo&lt;/code&gt;] structure that is returned by the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method. This field represents the time when a specific packet should be sent into the network.&lt;/p&gt; 
&lt;p&gt;Applications can use these hints by artificially delaying the sending of packets through platform-specific mechanisms (such as the &lt;a href="https://man7.org/linux/man-pages/man8/tc-etf.8.html"&gt;&lt;code&gt;SO_TXTIME&lt;/code&gt;&lt;/a&gt; socket option on Linux), or custom methods (for example by using user-space timers).&lt;/p&gt; 
&lt;h3&gt;Sending and receiving stream data&lt;/h3&gt; 
&lt;p&gt;After some back and forth, the connection will complete its handshake and will be ready for sending or receiving application data.&lt;/p&gt; 
&lt;p&gt;Data can be sent on a stream by using the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send"&gt;&lt;code&gt;stream_send()&lt;/code&gt;&lt;/a&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b"hello", true)?;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application can check whether there are any readable streams by using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.readable"&gt;&lt;code&gt;readable()&lt;/code&gt;&lt;/a&gt; method, which returns an iterator over all the streams that have outstanding data to read.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv"&gt;&lt;code&gt;stream_recv()&lt;/code&gt;&lt;/a&gt; method can then be used to retrieve the application data from the readable stream:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there's no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;amp;mut buf) {
            println!("Got {} bytes on stream {}", read, stream_id);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP/3&lt;/h3&gt; 
&lt;p&gt;The quiche &lt;a href="https://docs.quic.tech/quiche/h3/index.html"&gt;HTTP/3 module&lt;/a&gt; provides a high level API for sending and receiving HTTP requests and responses on top of the QUIC transport protocol.&lt;/p&gt; 
&lt;p&gt;Have a look at the [quiche/examples/] directory for more complete examples on how to use the quiche API, including examples on how to use quiche in C/C++ applications (see below for more information).&lt;/p&gt; 
&lt;h2&gt;Calling quiche from C/C++&lt;/h2&gt; 
&lt;p&gt;quiche exposes a &lt;a href="https://github.com/cloudflare/quiche/raw/master/quiche/include/quiche.h"&gt;thin C API&lt;/a&gt; on top of the Rust API that can be used to more easily integrate quiche into C/C++ applications (as well as in other languages that allow calling C APIs via some form of FFI). The C API follows the same design of the Rust one, modulo the constraints imposed by the C language itself.&lt;/p&gt; 
&lt;p&gt;When running &lt;code&gt;cargo build&lt;/code&gt;, a static library called &lt;code&gt;libquiche.a&lt;/code&gt; will be built automatically alongside the Rust one. This is fully stand-alone and can be linked directly into C/C++ applications.&lt;/p&gt; 
&lt;p&gt;Note that in order to enable the FFI API, the &lt;code&gt;ffi&lt;/code&gt; feature must be enabled (it is disabled by default), by passing &lt;code&gt;--features ffi&lt;/code&gt; to &lt;code&gt;cargo&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;quiche requires Rust 1.83 or later to build. The latest stable Rust release can be installed using &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once the Rust build environment is setup, the quiche source code can be fetched using git:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ git clone --recursive https://github.com/cloudflare/quiche
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then built using cargo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;cargo can also be used to run the testsuite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;a href="https://boringssl.googlesource.com/boringssl/"&gt;BoringSSL&lt;/a&gt;, which is used to implement QUIC's cryptographic handshake based on TLS, needs to be built and linked to quiche. This is done automatically when building quiche using cargo, but requires the &lt;code&gt;cmake&lt;/code&gt; command to be available during the build process. On Windows you also need &lt;a href="https://www.nasm.us/"&gt;NASM&lt;/a&gt;. The &lt;a href="https://github.com/google/boringssl/raw/master/BUILDING.md"&gt;official BoringSSL documentation&lt;/a&gt; has more details.&lt;/p&gt; 
&lt;p&gt;In alternative you can use your own custom build of BoringSSL by configuring the BoringSSL directory with the &lt;code&gt;QUICHE_BSSL_PATH&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ QUICHE_BSSL_PATH="/path/to/boringssl" cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can use &lt;a href="https://github.com/quictls/openssl"&gt;OpenSSL/quictls&lt;/a&gt;. To enable quiche to use this vendor the &lt;code&gt;openssl&lt;/code&gt; feature can be added to the &lt;code&gt;--feature&lt;/code&gt; list. Be aware that &lt;code&gt;0-RTT&lt;/code&gt; is not supported if this vendor is used.&lt;/p&gt; 
&lt;h3&gt;Building for Android&lt;/h3&gt; 
&lt;p&gt;Building quiche for Android (NDK version 19 or higher, 21 recommended), can be done using &lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later).&lt;/p&gt; 
&lt;p&gt;First the &lt;a href="https://developer.android.com/ndk"&gt;Android NDK&lt;/a&gt; needs to be installed, either using Android Studio or directly, and the &lt;code&gt;ANDROID_NDK_HOME&lt;/code&gt; environment variable needs to be set to the NDK installation path, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then the Rust toolchain for the Android architectures needed can be installed as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the minimum API level is 21 for all target architectures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later) also needs to be installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally the quiche library can be built using the following procedure. Note that the &lt;code&gt;-t &amp;lt;architecture&amp;gt;&lt;/code&gt; and &lt;code&gt;-p &amp;lt;NDK version&amp;gt;&lt;/code&gt; options are mandatory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/raw/master/tools/android/build_android_ndk19.sh"&gt;build_android_ndk19.sh&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Building for iOS&lt;/h3&gt; 
&lt;p&gt;To build quiche for iOS, you need the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Xcode command-line tools. You can install them with Xcode or with the following command:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ xcode-select --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the Rust toolchain for iOS architectures:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-apple-ios x86_64-apple-ios
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;cargo-lipo&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-lipo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build libquiche, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;iOS build is tested in Xcode 10.1 and Xcode 11.2.&lt;/p&gt; 
&lt;h3&gt;Building Docker images&lt;/h3&gt; 
&lt;p&gt;In order to build the Docker images, simply run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ make docker-build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find the quiche Docker images on the following Docker Hub repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche"&gt;cloudflare/quiche&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche-qns"&gt;cloudflare/quiche-qns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;latest&lt;/code&gt; tag will be updated whenever quiche master branch updates.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides a server and client installed in /usr/local/bin.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche-qns&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides the script to test quiche within the &lt;a href="https://github.com/marten-seemann/quic-interop-runner"&gt;quic-interop-runner&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2018-2019, Cloudflare, Inc.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/tree/master/COPYING"&gt;COPYING&lt;/a&gt; for the license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>block/goose</title>
      <link>https://github.com/block/goose</link>
      <description>&lt;p&gt;an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;goose&lt;/h1&gt; 
 &lt;p&gt;&lt;em&gt;a local, extensible, open source AI agent that automates engineering tasks&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/goose-oss"&gt; &lt;img src="https://img.shields.io/discord/1287729918100246654?logo=discord&amp;amp;logoColor=white&amp;amp;label=Join+Us&amp;amp;color=blueviolet" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://github.com/block/goose/actions/workflows/ci.yml"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main" alt="CI" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéâ Hacktoberfest 2025 üéâ&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;goose&lt;/code&gt; is a participating project in Hacktoberfest 2025! We‚Äôre so excited for your contributions, and have created a wide variety of issues so that anyone can contribute. Whether you're a seasoned developer or a first-time open source contributor, there's something for everyone.&lt;/p&gt; 
&lt;h3&gt;To get started:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/block/goose/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/block/.github/raw/main/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/block/goose/main/ai-assisted-coding-guide.md"&gt;full Responsible AI-Assisted Coding Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a task from this project's Hacktoberfest issues in our &lt;a href="https://github.com/block/goose/issues/4705"&gt;Project Hub&lt;/a&gt; and follow the instructions. Each issue has the üè∑Ô∏è &lt;code&gt;hacktoberfest&lt;/code&gt; label.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Have questions? Connecting with us in our &lt;a href="https://discord.gg/goose-oss"&gt;Discord community&lt;/a&gt; in the &lt;code&gt;#hacktoberfest&lt;/code&gt; project channel.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - &lt;em&gt;autonomously&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Whether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.&lt;/p&gt; 
&lt;p&gt;Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/D-DpDunrbpo"&gt;&lt;img src="https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Quick Links&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/getting-started/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/getting-started"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/block/goose/raw/main/GOVERNANCE.md"&gt;Governance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;a little goose humor ü¶¢&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Why did the developer choose goose as their AI agent?&lt;/p&gt; 
 &lt;p&gt;Because it always helps them "migrate" their code to production! üöÄ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;goose around with us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/goose-oss"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@goose-oss"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/goose-oss"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/goose_oss"&gt;Twitter/X&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/opensource.block.xyz"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://njump.me/opensource@block.xyz"&gt;Nostr&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>dani-garcia/vaultwarden</title>
      <link>https://github.com/dani-garcia/vaultwarden</link>
      <description>&lt;p&gt;Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dani-garcia/vaultwarden/main/resources/vaultwarden-logo-auto.svg?sanitize=true" alt="Vaultwarden Logo" /&gt;&lt;/p&gt; 
&lt;p&gt;An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with &lt;a href="https://bitwarden.com/download/"&gt;official Bitwarden clients&lt;/a&gt; [&lt;a href="https://raw.githubusercontent.com/dani-garcia/vaultwarden/main/#disclaimer"&gt;disclaimer&lt;/a&gt;], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dani-garcia/vaultwarden/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;amp;logo=vaultwarden&amp;amp;color=005AA4" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=005AA4&amp;amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;amp;query=%24.downloads&amp;amp;label=ghcr.io%20pulls&amp;amp;cacheSeconds=14400" alt="ghcr.io Pulls" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/vaultwarden/server"&gt;&lt;img src="https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;amp;logo=docker&amp;amp;logoColor=fff&amp;amp;color=005AA4&amp;amp;label=docker.io%20pulls" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://quay.io/repository/vaultwarden/server"&gt;&lt;img src="https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;amp;logo=redhat&amp;amp;cacheSeconds=14400" alt="Quay.io" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=vaultwarden&amp;amp;color=005AA4" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=005AA4" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=005AA4" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/issues"&gt;&lt;img src="https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=005AA4&amp;amp;cacheSeconds=300" alt="Issues Open" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed"&gt;&lt;img src="https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=005AA4&amp;amp;cacheSeconds=300" alt="Issues Closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/raw/main/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;amp;logo=vaultwarden&amp;amp;color=944000&amp;amp;cacheSeconds=14400" alt="AGPL-3.0 Licensed" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://deps.rs/repo/github/dani-garcia/vaultwarden"&gt;&lt;img src="https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;amp;query=%2F*%5Blocal-name()%3D'svg'%5D%2F*%5Blocal-name()%3D'g'%5D%5B2%5D%2F*%5Blocal-name()%3D'text'%5D%5B4%5D&amp;amp;style=flat-square&amp;amp;logo=rust&amp;amp;label=dependencies&amp;amp;color=005AA4" alt="Dependency Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;label=Release%20Workflow" alt="GHA Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;label=Build%20Workflow" alt="GHA Build" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://matrix.to/#/#vaultwarden:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;amp;logo=matrix&amp;amp;logoColor=fff&amp;amp;color=953B00&amp;amp;cacheSeconds=14400" alt="Matrix Chat" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=fff&amp;amp;color=953B00&amp;amp;cacheSeconds=300" alt="GitHub Discussions" /&gt;&lt;/a&gt; &lt;a href="https://vaultwarden.discourse.group/"&gt;&lt;img src="https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;amp;style=flat-square&amp;amp;logo=discourse&amp;amp;color=953B00" alt="Discourse Discussions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;When using this server, please report any bugs or suggestions directly to us (see &lt;a href="https://raw.githubusercontent.com/dani-garcia/vaultwarden/main/#get-in-touch"&gt;Get in touch&lt;/a&gt;), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;A nearly complete implementation of the Bitwarden Client API is provided, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/managing-items/"&gt;Personal Vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/about-send/"&gt;Send&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/attachments/"&gt;Attachments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/website-icons/"&gt;Website icons&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/personal-api-key/"&gt;Personal API Key&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/getting-started-organizations/"&gt;Organizations&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bitwarden.com/help/about-collections/"&gt;Collections&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/sharing/"&gt;Password Sharing&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/user-types-access-control/"&gt;Member Roles&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/about-groups/"&gt;Groups&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/event-logs/"&gt;Event Logs&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/admin-reset/"&gt;Admin Password Reset&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/directory-sync/"&gt;Directory Connector&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/policies/"&gt;Policies&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/bitwarden-field-guide-two-step-login/"&gt;Multi/Two Factor Authentication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://bitwarden.com/help/setup-two-step-login-authenticator/"&gt;Authenticator&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/setup-two-step-login-email/"&gt;Email&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/setup-two-step-login-fido/"&gt;FIDO2 WebAuthn&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/setup-two-step-login-yubikey/"&gt;YubiKey&lt;/a&gt;, &lt;a href="https://bitwarden.com/help/setup-two-step-login-duo/"&gt;Duo&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bitwarden.com/help/emergency-access/"&gt;Emergency Access&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page"&gt;Vaultwarden Admin Backend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dani-garcia/bw_web_builds"&gt;Modified Web Vault client&lt;/a&gt; (Bundled within our containers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The web-vault requires the use a secure context for the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API"&gt;Web Crypto API&lt;/a&gt;. That means it will only work via &lt;code&gt;http://localhost:8000&lt;/code&gt; (using the port from the example below) or if you &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS"&gt;enable HTTPS&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The recommended way to install and use Vaultwarden is via our container images which are published to &lt;a href="https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden"&gt;ghcr.io&lt;/a&gt;, &lt;a href="https://hub.docker.com/r/vaultwarden/server"&gt;docker.io&lt;/a&gt; and &lt;a href="https://quay.io/repository/vaultwarden/server"&gt;quay.io&lt;/a&gt;. See &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use"&gt;which container image to use&lt;/a&gt; for an explanation of the provided tags.&lt;/p&gt; 
&lt;p&gt;There are also &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages"&gt;community driven packages&lt;/a&gt; which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki"&gt;Wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Alternatively, you can also &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Building-binary"&gt;build Vaultwarden&lt;/a&gt; yourself.&lt;/p&gt; 
&lt;p&gt;While Vaultwarden is based upon the &lt;a href="https://rocket.rs"&gt;Rocket web framework&lt;/a&gt; which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples"&gt;proxy examples&lt;/a&gt;).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;For more detailed examples on how to install, use and configure Vaultwarden you can check our &lt;a href="https://github.com/dani-garcia/vaultwarden/wiki"&gt;Wiki&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Docker/Podman CLI&lt;/h3&gt; 
&lt;p&gt;Pull the container image and mount a volume from the host for persistent storage.&lt;br /&gt; You can replace &lt;code&gt;docker&lt;/code&gt; with &lt;code&gt;podman&lt;/code&gt; if you prefer to use podman.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN="https://vw.domain.tld" \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will preserve any persistent data under &lt;code&gt;/vw-data/&lt;/code&gt;, you can adapt the path to whatever suits you.&lt;/p&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;p&gt;To use Docker compose you need to create a &lt;code&gt;compose.yaml&lt;/code&gt; which will hold the configuration to run the Vaultwarden container.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: "https://vw.domain.tld"
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h2&gt;Get in touch&lt;/h2&gt; 
&lt;p&gt;Have a question, suggestion or need help? Join our community on &lt;a href="https://matrix.to/#/#vaultwarden:matrix.org"&gt;Matrix&lt;/a&gt;, &lt;a href="https://github.com/dani-garcia/vaultwarden/discussions"&gt;GitHub Discussions&lt;/a&gt; or &lt;a href="https://vaultwarden.discourse.group/"&gt;Discourse Forums&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Encountered a bug or crash? Please search our issue tracker and discussions to see if it's already been reported. If not, please &lt;a href="https://github.com/dani-garcia/vaultwarden/discussions"&gt;start a new discussion&lt;/a&gt; or &lt;a href="https://github.com/dani-garcia/vaultwarden/issues/"&gt;create a new issue&lt;/a&gt;. Ensure you're using the latest version of Vaultwarden and there aren't any similar issues open or closed!&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks for your contribution to the project!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dani-garcia/vaultwarden/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;amp;logo=vaultwarden&amp;amp;color=005AA4" alt="Contributors Count" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/dani-garcia/vaultwarden/graphs/contributors"&gt;&lt;img src="https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden" alt="Contributors Avatars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This project is not associated with &lt;a href="https://bitwarden.com/"&gt;Bitwarden&lt;/a&gt; or Bitwarden, Inc.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.&lt;/p&gt; 
&lt;p&gt;The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project's sustainability.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Please note:&lt;/strong&gt; We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Bitwarden_RS&lt;/h2&gt; 
&lt;p&gt;This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br /&gt; Please see &lt;a href="https://github.com/dani-garcia/vaultwarden/discussions/1642"&gt;#1642 - v1.21.0 release and project rename to Vaultwarden&lt;/a&gt; for more explanation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>meta-pytorch/monarch</title>
      <link>https://github.com/meta-pytorch/monarch</link>
      <description>&lt;p&gt;PyTorch Single Controller&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monarch ü¶ã&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Monarch&lt;/strong&gt; is a distributed programming framework for PyTorch based on scalable actor messaging. It provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Remote actors with scalable messaging: Actors are grouped into collections called meshes and messages can be broadcast to all members.&lt;/li&gt; 
 &lt;li&gt;Fault tolerance through supervision trees: Actors and processes form a tree and failures propagate up the tree, providing good default error behavior and enabling fine-grained fault recovery.&lt;/li&gt; 
 &lt;li&gt;Point-to-point RDMA transfers: cheap registration of any GPU or CPU memory in a process, with the one-sided transfers based on libibverbs&lt;/li&gt; 
 &lt;li&gt;Distributed tensors: actors can work with tensor objects sharded across processes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Monarch code imperatively describes how to create processes and actors using a simple python API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from monarch.actor import Actor, endpoint, this_host

# spawn 8 trainer processes one for each gpu
training_procs = this_host().spawn_procs({"gpus": 8})


# define the actor to run on each process
class Trainer(Actor):
    @endpoint
    def train(self, step: int): ...


# create the trainers
trainers = training_procs.spawn("trainers", Trainer)

# tell all the trainers to take a step
fut = trainers.train.call(step=0)

# wait for all trainers to complete
fut.get()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://meta-pytorch.org/monarch/generated/examples/getting_started.html"&gt;introduction to monarch concepts&lt;/a&gt; provides an introduction to using these features.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Early Development Warning&lt;/strong&gt; Monarch is currently in an experimental stage. You should expect bugs, incomplete features, and APIs that may change in future versions. The project welcomes bugfixes, but to make sure things are well coordinated you should discuss any significant change before starting the work. It's recommended that you signal your intention to contribute in the issue tracker, either by filing a new issue or by claiming an existing one.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;View Monarch's hosted documentation &lt;a href="https://meta-pytorch.org/monarch/"&gt;at this link&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Note for running distributed tensors and RDMA, the local torch version must match the version that monarch was built with. Stable and nightly distributions require libmxl and libibverbs (runtime).&lt;/p&gt; 
&lt;h2&gt;Fedora&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;sudo dnf install -y libibverbs rdma-core libmlx5 libibverbs-devel rdma-core-devel&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Ubuntu&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;sudo apt install -y rdma-core libibverbs1 libmlx5-1 libibverbs-dev rdma-core-dev&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Stable&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;pip install torchmonarch&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;torchmonarch stable is built with the latest stable torch.&lt;/p&gt; 
&lt;h3&gt;Nightly&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;pip install torchmonarch-nightly&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;torchmonarch-nightly is built with torch nightly.&lt;/p&gt; 
&lt;h3&gt;Build and Install from Source&lt;/h3&gt; 
&lt;p&gt;If you're building Monarch from source, you should be building it with the nightly PyTorch as well for ABI compatibility.&lt;/p&gt; 
&lt;h4&gt;On Fedora distributions&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;
# Create and activate the conda environment
conda create -n monarchenv python=3.10 -y
conda activate monarchenv

# Install nightly rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
rustup default nightly

# Install non-python dependencies
conda install libunwind -y

# Install the correct cuda and cuda-toolkit versions for your machine
sudo dnf install cuda-toolkit-12-8 cuda-12-8

# Install clang-dev and nccl-dev
sudo dnf install clang-devel libnccl-devel
# Or, in some environments, the following may be necessary instead
conda install -c conda-forge clangdev nccl
conda update -n monarchenv --all -c conda-forge -y

# If you are building with RDMA support, build monarch with `USE_TENSOR_ENGINE=1 pip install --no-build-isolation .` and dnf install the following packages
sudo dnf install -y libibverbs rdma-core libmlx5 libibverbs-devel rdma-core-devel

# Install build dependencies
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128
pip install -r build-requirements.txt
# Install test dependencies
pip install -r python/tests/requirements.txt

# Build and install Monarch
pip install --no-build-isolation .
# or setup for development
pip install --no-build-isolation -e .

# Verify installation
pip list | grep monarch
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;On Ubuntu distributions&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Clone the repository and navigate to it
git clone https://github.com/meta-pytorch/monarch.git
cd monarch

# Install nightly rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
rustup toolchain install nightly
rustup default nightly

# Install Ubuntu-specific system dependencies
sudo apt install -y ninja-build
sudo apt install -y libunwind-dev
sudo apt install -y clang

# Set clang as the default C/C++ compiler
export CC=clang
export CXX=clang++

# Install the correct cuda and cuda-toolkit versions for your machine
sudo apt install -y cuda-toolkit-12-8 cuda-12-8

# Install build dependencies
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128
pip install -r build-requirements.txt
# Install test dependencies
pip install -r python/tests/requirements.txt

# Build and install Monarch (with tensor engine support)
pip install --no-build-isolation .

# or
# Build and install Monarch (without tensor engine support)
USE_TENSOR_ENGINE=0 pip install --no-build-isolation .

# or setup for development
pip install --no-build-isolation -e .

# Verify installation
pip list | grep monarch
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;On non-CUDA machines&lt;/h4&gt; 
&lt;p&gt;You can also build Monarch to run on non-CUDA machines, e.g. locally on a MacOS system.&lt;/p&gt; 
&lt;p&gt;Note that this does not support tensor engine, which is tied to CUDA and RDMA (via ibverbs).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;
# Create and activate the conda environment
conda create -n monarchenv python=3.10 -y
conda activate monarchenv

# Install nightly rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
rustup default nightly

# Install build dependencies
pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cpu
pip install -r build-requirements.txt
# Install test dependencies
pip install -r python/tests/requirements.txt

# Build and install Monarch
USE_TENSOR_ENGINE=0 pip install --no-build-isolation .
# or setup for development
USE_TENSOR_ENGINE=0 pip install --no-build-isolation -e .

# Verify installation
pip list | grep monarch
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running examples&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;code&gt;examples/&lt;/code&gt; directory for demonstrations of how to use Monarch's APIs.&lt;/p&gt; 
&lt;p&gt;We'll be adding more examples as we stabilize and polish functionality!&lt;/p&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;p&gt;We have both Rust and Python unit tests. Rust tests are run with &lt;code&gt;cargo-nextest&lt;/code&gt; and Python tests are run with &lt;code&gt;pytest&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Rust tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# We use cargo-nextest to run our tests, as they can provide strong process isolation
# between every test.
# Here we install it from source, but you can instead use a pre-built binary described
# here: https://nexte.st/docs/installation/pre-built-binaries/
cargo install cargo-nextest --locked
cargo nextest run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;cargo-nextest supports all of the filtering flags of "cargo test".&lt;/p&gt; 
&lt;p&gt;Python tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Make sure to install test dependencies first
pip install -r python/tests/requirements.txt
# Run unit tests. consider -s for more verbose output
pytest python/tests/ -v -m "not oss_skip"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Monarch is BSD-3 licensed, as found in the &lt;a href="https://raw.githubusercontent.com/meta-pytorch/monarch/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helix-editor/helix</title>
      <link>https://github.com/helix-editor/helix</link>
      <description>&lt;p&gt;A post-modern modal text editor.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logo_dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logo_light.svg" /&gt; 
   &lt;img alt="Helix" height="128" src="https://raw.githubusercontent.com/helix-editor/helix/master/logo_light.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/actions"&gt;&lt;img src="https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/helix-editor/helix" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://docs.helix-editor.com/"&gt;&lt;img src="https://shields.io/badge/-documentation-452859" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/helix-editor/helix" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/helix-community:matrix.org" alt="Matrix Space" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/helix-editor/helix/master/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://github.com/mawww/kakoune"&gt;Kakoune&lt;/a&gt; / &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; inspired editor, written in Rust.&lt;/p&gt; 
&lt;p&gt;The editing model is very heavily based on Kakoune; during development I found myself agreeing with most of Kakoune's design decisions.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://helix-editor.com"&gt;website&lt;/a&gt; or &lt;a href="https://docs.helix-editor.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All shortcuts/keymaps can be found &lt;a href="https://docs.helix-editor.com/keymap.html"&gt;in the documentation on the website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vim-like modal editing&lt;/li&gt; 
 &lt;li&gt;Multiple selections&lt;/li&gt; 
 &lt;li&gt;Built-in language server support&lt;/li&gt; 
 &lt;li&gt;Smart, incremental syntax highlighting and code editing via tree-sitter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although it's primarily a terminal-based editor, I am interested in exploring a custom renderer (similar to Emacs) using wgpu or skulpin.&lt;/p&gt; 
&lt;p&gt;Note: Only certain languages have indentation definitions at the moment. Check &lt;code&gt;runtime/queries/&amp;lt;lang&amp;gt;/&lt;/code&gt; for &lt;code&gt;indents.scm&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.helix-editor.com/install.html"&gt;Installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/helix-editor/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Contributing guidelines can be found &lt;a href="https://raw.githubusercontent.com/helix-editor/helix/master/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting help&lt;/h1&gt; 
&lt;p&gt;Your question might already be answered on the &lt;a href="https://github.com/helix-editor/helix/wiki/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Discuss the project on the community &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;Matrix Space&lt;/a&gt; (make sure to join &lt;code&gt;#helix-editor:matrix.org&lt;/code&gt; if you're on a client that doesn't support Matrix Spaces yet).&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/jakenvac"&gt;@jakenvac&lt;/a&gt; for designing the logo!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vortex-data/vortex</title>
      <link>https://github.com/vortex-data/vortex</link>
      <description>&lt;p&gt;An extensible, state of the art columnar file format. Formerly at @spiraldb, now an Incubation Stage project at LFAI&amp;Data, part of the Linux Foundation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üå™Ô∏è Vortex&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/vortex-data/vortex/actions"&gt;&lt;img src="https://github.com/vortex-data/vortex/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10567"&gt;&lt;img src="https://www.bestpractices.dev/projects/10567/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://docs.vortex.dev"&gt;&lt;img src="https://docs.rs/vortex/badge.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/vortex-data/vortex"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="CodSpeed Badge" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/vortex"&gt;&lt;img src="https://img.shields.io/crates/v/vortex.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/vortex-data/"&gt;&lt;img src="https://img.shields.io/pypi/v/vortex-data" alt="PyPI - Version" /&gt;&lt;/a&gt; &lt;a href="https://central.sonatype.com/artifact/dev.vortex/vortex-spark"&gt;&lt;img src="https://img.shields.io/maven-central/v/dev.vortex/vortex-spark" alt="Maven - Version" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/vortex-data/vortex"&gt;&lt;img src="https://codecov.io/github/vortex-data/vortex/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üìö &lt;a href="https://docs.vortex.dev/"&gt;Documentation&lt;/a&gt; | üìä &lt;a href="https://bench.vortex.dev"&gt;Performance Benchmarks&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Vortex is a next-generation columnar file format and toolkit designed for high-performance data processing. It is the fastest and most extensible format for building data systems backed by object storage. It provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö°Ô∏è Blazing Fast Performance&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;100x faster random access reads (vs. modern Apache Parquet)&lt;/li&gt; 
   &lt;li&gt;10-20x faster scans&lt;/li&gt; 
   &lt;li&gt;5x faster writes&lt;/li&gt; 
   &lt;li&gt;Similar compression ratios&lt;/li&gt; 
   &lt;li&gt;Efficient support for wide tables with zero-copy/zero-parse metadata&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Extensible Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Modeled after Apache DataFusion's extensible approach&lt;/li&gt; 
   &lt;li&gt;Pluggable encoding system, type system, compression strategy, &amp;amp; layout strategy&lt;/li&gt; 
   &lt;li&gt;Zero-copy compatibility with Apache Arrow&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üó≥Ô∏è Open Source, Neutral Governance&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A Linux Foundation (LF AI &amp;amp; Data) Project&lt;/li&gt; 
   &lt;li&gt;Apache-2.0 Licensed&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ÜîÔ∏è Integrations&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Arrow, DataFusion, DuckDB, Spark, Pandas, Polars, &amp;amp; more&lt;/li&gt; 
   &lt;li&gt;Apache Iceberg (coming soon)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üü¢ &lt;strong&gt;Development Status&lt;/strong&gt;: Library APIs may change from version to version, but we now consider the file format &lt;ins&gt;&lt;em&gt;stable&lt;/em&gt;&lt;/ins&gt;. From release 0.36.0, all future releases of Vortex should maintain backwards compatibility of the file format (i.e., be able to read files written by any earlier version &amp;gt;= 0.36.0).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;Logical Types&lt;/strong&gt; - Clean separation between logical schema and physical layout&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Zero-Copy Arrow Integration&lt;/strong&gt; - Seamless conversion to/from Apache Arrow arrays&lt;/li&gt; 
 &lt;li&gt;üß© &lt;strong&gt;Extensible Encodings&lt;/strong&gt; - Pluggable physical layouts with built-in optimizations&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;Cascading Compression&lt;/strong&gt; - Support for nested encoding schemes&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;High-Performance Computing&lt;/strong&gt; - Optimized compute kernels for encoded data&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Rich Statistics&lt;/strong&gt; - Lazy-loaded summary statistics for optimization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Technical Architecture&lt;/h3&gt; 
&lt;h4&gt;Logical vs Physical Design&lt;/h4&gt; 
&lt;p&gt;Vortex strictly separates logical and physical concerns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logical Layer&lt;/strong&gt;: Defines data types and schema&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Physical Layer&lt;/strong&gt;: Handles encoding and storage implementation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Encodings&lt;/strong&gt;: Compatible with Apache Arrow's memory format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extension Encodings&lt;/strong&gt;: Optimized compression schemes (RLE, dictionary, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Rust Crate&lt;/h4&gt; 
&lt;p&gt;All features are exported through the main &lt;code&gt;vortex&lt;/code&gt; crate.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo add vortex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python Package&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add vortex-data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Command Line UI (vx)&lt;/h4&gt; 
&lt;p&gt;For browsing the structure of Vortex files, you can use the &lt;code&gt;vx&lt;/code&gt; command-line tool.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install latest release
cargo install vortex-tui --locked

# Or build from source
cargo install --path vortex-tui --locked

# Usage
vx browse &amp;lt;file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;h4&gt;Prerequisites (macOS)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Optional but recommended dependencies
brew install flatbuffers protobuf  # For .fbs and .proto files
brew install duckdb               # For benchmarks

# Install Rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
# or
brew install rustup

# Initialize submodules
git submodule update --init --recursive

# Setup dependencies with uv
uv sync --all-packages
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Optimization&lt;/h3&gt; 
&lt;p&gt;For optimal performance, we suggest using &lt;a href="https://github.com/microsoft/mimalloc"&gt;MiMalloc&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust,ignore"&gt;#[global_allocator]
static GLOBAL_ALLOC: MiMalloc = MiMalloc;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Project Information&lt;/h2&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0.&lt;/p&gt; 
&lt;h3&gt;Governance&lt;/h3&gt; 
&lt;p&gt;Vortex is an independent open-source project and not controlled by any single company. The Vortex Project is a sub-project of the Linux Foundation Projects. The governance model is documented in &lt;a href="https://raw.githubusercontent.com/vortex-data/vortex/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; and is subject to the terms of the &lt;a href="https://vortex.dev/charter.pdf"&gt;Technical Charter&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/vortex-data/vortex/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h3&gt;Reporting Vulnerabilities&lt;/h3&gt; 
&lt;p&gt;If you discovery a security vulnerability, please email &lt;a href="mailto:vuln-report@vortex.dev"&gt;vuln-report@vortex.dev&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Trademarks&lt;/h3&gt; 
&lt;p&gt;Copyright ¬© Vortex a Series of LF Projects, LLC. For terms of use, trademark policy, and other project policies please see &lt;a href="https://lfprojects.org"&gt;https://lfprojects.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgments üèÜ&lt;/h2&gt; 
&lt;p&gt;The Vortex project benefits enormously from groundbreaking work from the academic &amp;amp; open-source communities.&lt;/p&gt; 
&lt;h3&gt;Research in Vortex&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cs.cit.tum.de/fileadmin/w00cfj/dis/papers/btrblocks.pdf"&gt;BtrBlocks&lt;/a&gt; - Efficient columnar compression&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.vldb.org/pvldb/vol16/p2132-afroozeh.pdf"&gt;FastLanes&lt;/a&gt; &amp;amp; &lt;a href="https://dbdbd2023.ugent.be/abstracts/felius_fastlanes.pdf"&gt;FastLanes on GPU&lt;/a&gt; - High-performance integer compression&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.vldb.org/pvldb/vol13/p2649-boncz.pdf"&gt;FSST&lt;/a&gt; - Fast random access string compression&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ir.cwi.nl/pub/33334/33334.pdf"&gt;ALP&lt;/a&gt; &amp;amp; &lt;a href="https://dl.acm.org/doi/pdf/10.1145/3736227.3736242"&gt;G-ALP&lt;/a&gt; - Adaptive lossless floating-point compression&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dl.acm.org/citation.cfm?id=3360438"&gt;Procella&lt;/a&gt; - YouTube's unified data system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.durner.dev/app/media/papers/anyblob-vldb23.pdf"&gt;Anyblob&lt;/a&gt; - High-performance access to object storage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf"&gt;ClickHouse&lt;/a&gt; - Fast analytics for everyone&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cidrdb.org/cidr2005/papers/P19.pdf"&gt;MonetDB/X100&lt;/a&gt; - Hyper-Pipelining Query Execution&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://db.in.tum.de/~leis/papers/morsels.pdf"&gt;Morsel-Driven Parallelism&lt;/a&gt;: A NUMA-Aware Query Evaluation Format for the Many-Core Age&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cwida/FastLanes/raw/dev/docs/specification.pdf"&gt;The FastLanes File Format&lt;/a&gt; - Expression Operators&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Vortex in Research&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gienieczko.com/anyblox-paper"&gt;Anyblox&lt;/a&gt; - A Framework for Self-Decoding Datasets&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3749163"&gt;F3&lt;/a&gt; - Open-Source Data File Format for the Future&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Open Source Inspiration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arrow.apache.org"&gt;Apache Arrow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/datafusion"&gt;Apache DataFusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jorgecarleitao/parquet2"&gt;parquet2&lt;/a&gt; by Jorge Leitao&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duckdb/duckdb"&gt;DuckDB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebookincubator/velox"&gt;Velox&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/facebookincubator/nimble"&gt;Nimble&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Thanks to all contributors who have shared their knowledge and code with the community! üöÄ&lt;/h4&gt;</description>
    </item>
    
    <item>
      <title>longbridge/gpui-component</title>
      <link>https://github.com/longbridge/gpui-component</link>
      <description>&lt;p&gt;Rust GUI components for building fantastic cross-platform desktop application by using GPUI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GPUI Component&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/longbridge/gpui-component/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/gpui-component/"&gt;&lt;img src="https://docs.rs/gpui-component/badge.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/gpui-component"&gt;&lt;img src="https://img.shields.io/crates/v/gpui-component.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;UI components for building fantastic desktop applications using &lt;a href="https://gpui.rs"&gt;GPUI&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Richness&lt;/strong&gt;: 60+ cross-platform desktop UI components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native&lt;/strong&gt;: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: Stateless &lt;code&gt;RenderOnce&lt;/code&gt; components, simple and user-friendly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Built-in &lt;code&gt;Theme&lt;/code&gt; and &lt;code&gt;ThemeColor&lt;/code&gt;, supporting multi-theme and variable-based configurations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile&lt;/strong&gt;: Supports sizes like &lt;code&gt;xs&lt;/code&gt;, &lt;code&gt;sm&lt;/code&gt;, &lt;code&gt;md&lt;/code&gt;, and &lt;code&gt;lg&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Layout&lt;/strong&gt;: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Virtualized Table and List components for smooth large-data rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Rendering&lt;/strong&gt;: Native support for Markdown and simple HTML.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Charting&lt;/strong&gt;: Built-in charts for visualizing your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editor&lt;/strong&gt;: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Syntax Highlighting&lt;/strong&gt;: Syntax highlighting for editor and markdown components using Tree Sitter.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Showcase&lt;/h2&gt; 
&lt;p&gt;Here is the first application: &lt;a href="https://longbridge.com/desktop"&gt;Longbridge Pro&lt;/a&gt;, built using GPUI Component.&lt;/p&gt; 
&lt;img width="1763" alt="Image" src="https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551" /&gt; 
&lt;p&gt;We built multi-theme support in the application. This feature is not included in GPUI Component itself, but is based on the &lt;code&gt;Theme&lt;/code&gt; feature, so it's easy to implement.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;GPUI and GPUI Component are still in development, so you need to add dependencies by git.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;gpui = "0.2.2"
gpui-component = "0.3.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;use gpui::*;
use gpui_component::{button::*, *};

pub struct HelloWorld;
impl Render for HelloWorld {
    fn render(&amp;amp;mut self, _: &amp;amp;mut Window, _: &amp;amp;mut Context&amp;lt;Self&amp;gt;) -&amp;gt; impl IntoElement {
        div()
            .v_flex()
            .gap_2()
            .size_full()
            .items_center()
            .justify_center()
            .child("Hello, World!")
            .child(
                Button::new("ok")
                    .primary()
                    .label("Let's Go!")
                    .on_click(|_, _, _| println!("Clicked!")),
            )
    }
}

fn main() {
    let app = Application::new();

    app.run(move |cx| {
        // This must be called before using any GPUI Component features.
        gpui_component::init(cx);

        cx.spawn(async move |cx| {
            cx.open_window(WindowOptions::default(), |window, cx| {
                let view = cx.new(|_| HelloWorld);
                // This first level on the window, should be a Root.
                cx.new(|cx| Root::new(view.into(), window, cx))
            })?;

            Ok::&amp;lt;_, anyhow::Error&amp;gt;(())
        })
        .detach();
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;WebView&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Still early and experimental; there are a lot of limitations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;GPUI Component has a &lt;code&gt;WebView&lt;/code&gt; element based on &lt;a href="https://github.com/tauri-apps/wry"&gt;Wry&lt;/a&gt;. This is an optional feature, which you can enable with a feature flag.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;gpui-component = { version = "0.3.0", features = ["webview"] }
wry = { version = "0.53.3, package = "lb-wry" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More usage examples can be found in the &lt;a href="https://github.com/longbridge/gpui-component/tree/main/crates/story"&gt;story&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Icons&lt;/h3&gt; 
&lt;p&gt;GPUI Component has an &lt;code&gt;Icon&lt;/code&gt; element, but it does not include SVG files by default.&lt;/p&gt; 
&lt;p&gt;The example uses &lt;a href="https://lucide.dev"&gt;Lucide&lt;/a&gt; icons, but you can use any icons you like. Just name the SVG files as defined in &lt;a href="https://github.com/longbridge/gpui-component/raw/main/crates/ui/src/icon.rs#L86"&gt;IconName&lt;/a&gt;. You can add any icons you need to your project.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We have a gallery of applications built with GPUI Component.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More examples can be found in the &lt;code&gt;examples&lt;/code&gt; directory. You can run them with &lt;code&gt;cargo run --example &amp;lt;example_name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://raw.githubusercontent.com/longbridge/gpui-component/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compare to others&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Features&lt;/th&gt; 
   &lt;th&gt;GPUI Component&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/iced-rs/iced"&gt;Iced&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/emilk/egui"&gt;egui&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://www.qt.io/product/qt6"&gt;Qt 6&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;C++/QML&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Core Render&lt;/td&gt; 
   &lt;td&gt;GPUI&lt;/td&gt; 
   &lt;td&gt;wgpu&lt;/td&gt; 
   &lt;td&gt;wgpu&lt;/td&gt; 
   &lt;td&gt;QT&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;License&lt;/td&gt; 
   &lt;td&gt;Apache 2.0&lt;/td&gt; 
   &lt;td&gt;MIT&lt;/td&gt; 
   &lt;td&gt;MIT/Apache 2.0&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.qt.io/qt-licensing"&gt;Commercial/LGPL&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Min Binary Size [^1]&lt;/td&gt; 
   &lt;td&gt;12MB&lt;/td&gt; 
   &lt;td&gt;11MB&lt;/td&gt; 
   &lt;td&gt;5M&lt;/td&gt; 
   &lt;td&gt;20MB [^2]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cross-Platform&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Documentation&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Good&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UI Style&lt;/td&gt; 
   &lt;td&gt;Modern&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CJK Support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Bad&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chart&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table (Large dataset)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows, Columns)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows, Columns)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table Column Resize&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text base&lt;/td&gt; 
   &lt;td&gt;Rope&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/pop-os/cosmic-text"&gt;COSMIC Text&lt;/a&gt; [^3]&lt;/td&gt; 
   &lt;td&gt;trait TextBuffer [^4]&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://doc.qt.io/qt-6/qtextdocument.html"&gt;QTextDocument&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CodeEditor&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Basic API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dock Layout&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Syntax Highlight&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tree-sitter.github.io/tree-sitter/"&gt;Tree Sitter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/trishume/syntect"&gt;Syntect&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/trishume/syntect"&gt;Syntect&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://doc.qt.io/qt-6/qsyntaxhighlighter.html"&gt;QSyntaxHighlighter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Markdown Rendering&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Markdown mix HTML&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HTML Rendering&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text Selection&lt;/td&gt; 
   &lt;td&gt;TextView&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Any Label&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Custom Theme&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Built Themes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;I18n&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Please submit an issue or PR if any mistakes or outdated are found.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;[^1]: Release builds by use simple hello world example.&lt;/p&gt; 
&lt;p&gt;[^2]: &lt;a href="https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms"&gt;Reducing Binary Size of Qt Applications&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[^3]: Iced Editor: &lt;a href="https://github.com/iced-rs/iced/raw/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68"&gt;https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[^4]: egui TextBuffer: &lt;a href="https://github.com/emilk/egui/raw/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20"&gt;https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache-2.0&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI design based on &lt;a href="https://ui.shadcn.com"&gt;shadcn/ui&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Icons from &lt;a href="https://lucide.dev"&gt;Lucide&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>jj-vcs/jj</title>
      <link>https://github.com/jj-vcs/jj</link>
      <description>&lt;p&gt;A Git-compatible VCS that is both simple and powerful&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Jujutsu‚Äîa version control system&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="jj logo" src="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/jj-logo.svg?sanitize=true" width="320" height="320" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/martinvonz/jj" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/martinvonz/jj" alt="Release date" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/jj-vcs/jj/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/martinvonz/jj" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;img src="https://img.shields.io/badge/irc-%23jujutsu-blue.svg?sanitize=true" alt="IRC" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj"&gt;Homepage&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;Installation&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/roadmap"&gt;Development Roadmap&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Jujutsu is a powerful &lt;a href="https://en.wikipedia.org/wiki/Version_control"&gt;version control system&lt;/a&gt; for software projects. You use it to get a copy of your code, track changes to the code, and finally publish those changes for others to see and use. It is designed from the ground up to be easy to use‚Äîwhether you're new or experienced, working on brand new projects alone, or large scale software projects with large histories and teams.&lt;/p&gt; 
&lt;p&gt;Jujutsu is unlike most other systems, because internally it abstracts the user interface and version control algorithms from the &lt;em&gt;storage systems&lt;/em&gt; used to serve your content. This allows it to serve as a VCS with many possible physical backends, that may have their own data or networking models‚Äîlike &lt;a href="https://www.mercurial-scm.org/"&gt;Mercurial&lt;/a&gt; or &lt;a href="https://www.breezy-vcs.org/"&gt;Breezy&lt;/a&gt;, or hybrid systems like Google's cloud-based design, &lt;a href="https://youtu.be/W71BTkUbdqE?t=645"&gt;Piper/CitC&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Today, we use Git repositories as a storage layer to serve and track content, making it &lt;strong&gt;compatible with many of your favorite Git-based tools, right now!&lt;/strong&gt; All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it should hopefully work with your favorite Git forges, too.&lt;/p&gt; 
&lt;p&gt;We combine many distinct design choices and concepts from other version control systems into a single tool. Some of those sources of inspiration include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Git&lt;/strong&gt;: We make an effort to &lt;a href="https://github.com/jj-vcs/jj/discussions/49"&gt;be fast&lt;/a&gt;‚Äîwith a snappy UX, efficient algorithms, correct data structures, and good-old-fashioned attention to detail. The default storage backend uses Git repositories for "physical storage", for wide interoperability and ease of onboarding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mercurial &amp;amp; Sapling&lt;/strong&gt;: There are many Mercurial-inspired features, such as the &lt;a href="https://jj-vcs.github.io/jj/latest/revsets/"&gt;revset&lt;/a&gt; language to select commits. There is &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison/#the-index"&gt;no explicit index&lt;/a&gt; or staging area. Branches are "anonymous" like Mercurial, so you don't need to make up a name for each small change. Primitives for rewriting history are powerful and simple. Formatting output is done with a robust template language that can be configured by the user.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Darcs&lt;/strong&gt;: Jujutsu keeps track of conflicts as &lt;a href="https://jj-vcs.github.io/jj/latest/conflicts/"&gt;first-class objects&lt;/a&gt; in its model; they are first-class in the same way commits are, while alternatives like Git simply think of conflicts as textual diffs. While not as rigorous as systems like Darcs (which is based on a formalized theory of patches, as opposed to snapshots), the effect is that many forms of conflict resolution can be performed and propagated automatically.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it adds several innovative, useful features of its own:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Working-copy-as-a-commit&lt;/strong&gt;: Changes to files are &lt;a href="https://jj-vcs.github.io/jj/latest/working-copy/"&gt;recorded automatically&lt;/a&gt; as normal commits, and amended on every subsequent change. This "snapshot" design simplifies the user-facing data model (commits are the only visible object), simplifies internal algorithms, and completely subsumes features like Git's stashes or the index/staging-area.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Operation log &amp;amp; undo&lt;/strong&gt;: Jujutsu records every operation that is performed on the repository, from commits, to pulls, to pushes. This makes debugging problems like "what just happened?" or "how did I end up here?" easier, &lt;em&gt;especially&lt;/em&gt; when you're helping your coworker answer those questions about their repository! And because everything is recorded, you can undo that mistake you just made with ease. Version control has finally entered &lt;a href="https://en.wikipedia.org/wiki/Undo#History"&gt;the 1960s&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic rebase and conflict resolution&lt;/strong&gt;: When you modify a commit, every descendent is automatically rebased on top of the freshly-modified one. This makes "patch-based" workflows a breeze. If you resolve a conflict in a commit, the &lt;em&gt;resolution&lt;/em&gt; of that conflict is also propagated through descendants as well. In effect, this is a completely transparent version of &lt;code&gt;git rebase --update-refs&lt;/code&gt; combined with &lt;code&gt;git rerere&lt;/code&gt;, supported by design.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The following features are available for use, but experimental; they may have bugs, backwards incompatible storage changes, and user-interface changes!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safe, concurrent replication&lt;/strong&gt;: Have you ever wanted to store your version controlled repositories inside a Dropbox folder? Or continuously backup repositories to S3? No? Well, now you can!&lt;/p&gt; &lt;p&gt;The fundamental problem with using filesystems like Dropbox and backup tools like &lt;code&gt;rsync&lt;/code&gt; on your typical Git/Mercurial repositories is that they rely on &lt;em&gt;local filesystem operations&lt;/em&gt; being atomic, serialized, and non-concurrent with respect to other reads and writes‚Äîwhich is &lt;em&gt;not&lt;/em&gt; true when operating on distributed file systems, or when operations like concurrent file copies (for backup) happen while lock files are being held.&lt;/p&gt; &lt;p&gt;Jujutsu is instead designed to be &lt;a href="https://jj-vcs.github.io/jj/latest/technical/concurrency/"&gt;safe under concurrent scenarios&lt;/a&gt;; simply using rsync or Dropbox and then using that resulting repository should never result in a repository in a &lt;em&gt;corrupt state&lt;/em&gt;. The worst that &lt;em&gt;should&lt;/em&gt; happen is that it will expose conflicts between the local and remote state, leaving you to resolve them.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The command-line tool is called &lt;code&gt;jj&lt;/code&gt; for now because it's easy to type and easy to replace (rare in English). The project is called "Jujutsu" because it matches "jj".&lt;/p&gt; 
&lt;p&gt;Jujutsu is relatively young, with lots of work to still be done. If you have any questions, or want to talk about future plans, please join us on Discord &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord" /&gt;&lt;/a&gt;, start a &lt;a href="https://github.com/jj-vcs/jj/discussions"&gt;GitHub Discussion&lt;/a&gt;, or send an IRC message to &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;code&gt;#jujutsu&lt;/code&gt; on Libera Chat&lt;/a&gt;. The developers monitor all of these channels[^bridge].&lt;/p&gt; 
&lt;p&gt;[^bridge]: To be more precise, the &lt;code&gt;#jujutsu&lt;/code&gt; Libera IRC channel is bridged to one of the channels on jj's Discord. Some of the developers stay on Discord and use the bridge to follow IRC.&lt;/p&gt; 
&lt;h3&gt;News and Updates üì£&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;December 2024&lt;/strong&gt;: The &lt;code&gt;jj&lt;/code&gt; Repository has moved to the &lt;code&gt;jj-vcs&lt;/code&gt; GitHub organization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;November 2024&lt;/strong&gt;: Version 0.24 is released which adds &lt;code&gt;jj file annotate&lt;/code&gt;, which is equivalent to &lt;code&gt;git blame&lt;/code&gt; or &lt;code&gt;hg annotate&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;September 2024&lt;/strong&gt;: Martin gave a &lt;a href="https://www.youtube.com/watch?v=LV0JzI8IcCY"&gt;presentation about Jujutsu&lt;/a&gt; at Git Merge 2024.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Version 0.14 is released, which deprecates &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/CHANGELOG.md#0140---2024-02-07"&gt;"jj checkout" and "jj merge"&lt;/a&gt;, as well as &lt;code&gt;jj init --git&lt;/code&gt;, which is now just called &lt;code&gt;jj git init&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 2023&lt;/strong&gt;: Version 0.10.0 is released! Now includes a bundled merge and diff editor for all platforms, "immutable revsets" to avoid accidentally &lt;code&gt;edit&lt;/code&gt;-ing the wrong revisions, and lots of polish.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin gave a presentation about Google's plans for Jujutsu at Git Merge 2022! See the &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt; or the &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;recording&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Related Media&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 2024&lt;/strong&gt;: Chris Krycho started &lt;a href="https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp"&gt;a YouTube series about Jujutsu&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Chris Krycho published an article about Jujutsu called &lt;a href="https://v5.chriskrycho.com/essays/jj-init/"&gt;jj init&lt;/a&gt; and Steve Klabnik followed up with the &lt;a href="https://steveklabnik.github.io/jujutsu-tutorial/"&gt;Jujutsu Tutorial&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2024&lt;/strong&gt;: Jujutsu was featured in an LWN.net article called &lt;a href="https://lwn.net/Articles/958468/"&gt;Jujutsu: a new, Git-compatible version control system&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin's Talk about Jujutsu at Git Merge 2022, &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;video&lt;/a&gt; and the associated &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The wiki also contains a more extensive list of &lt;a href="https://github.com/jj-vcs/jj/wiki/Media"&gt;media references&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Jujutsu is an &lt;strong&gt;experimental version control system&lt;/strong&gt;. While Git compatibility is stable, and most developers use it daily for all their needs, there may still be work-in-progress features, suboptimal UX, and workflow gaps that make it unusable for your particular use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Follow the &lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;installation instructions&lt;/a&gt; to obtain and configure &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The best way to get started is probably to go through &lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;the tutorial&lt;/a&gt;. Also see the &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison"&gt;Git comparison&lt;/a&gt;, which includes a table of &lt;code&gt;jj&lt;/code&gt; vs. &lt;code&gt;git&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;As you become more familiar with Jujutsu, the following resources may be helpful:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/glossary"&gt;Glossary&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help&lt;/code&gt; command (e.g. &lt;code&gt;jj help rebase&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help -k &amp;lt;keyword&amp;gt;&lt;/code&gt; command (e.g. &lt;code&gt;jj help -k config&lt;/code&gt;). Use &lt;code&gt;jj help --help&lt;/code&gt; to see what keywords are available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using a &lt;strong&gt;prerelease&lt;/strong&gt; version of &lt;code&gt;jj&lt;/code&gt;, you would want to consult &lt;a href="https://jj-vcs.github.io/jj/prerelease/"&gt;the docs for the prerelease (main branch) version&lt;/a&gt;. You can also get there from the docs for the latest release by using the website's version switcher. The version switcher is visible in the header of the website when you scroll to the top of any page.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Compatible with Git&lt;/h3&gt; 
&lt;p&gt;Jujutsu is designed so that the underlying data and storage model is abstract. Today, only the Git backend is production-ready. The Git backend uses the &lt;a href="https://github.com/Byron/gitoxide"&gt;gitoxide&lt;/a&gt; Rust library.&lt;/p&gt; 
&lt;p&gt;The Git backend is fully featured and maintained, and allows you to use Jujutsu with any Git remote. The commits you create will look like regular Git commits. You can fetch branches from a regular Git remote and push branches to the remote. You can always switch back to Git.&lt;/p&gt; 
&lt;p&gt;Here is how you can explore a GitHub repository with &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/git_compat.png" /&gt; 
&lt;p&gt;You can even have a &lt;a href="https://jj-vcs.github.io/jj/latest/git-compatibility#colocated-jujutsugit-repos"&gt;colocated local repository&lt;/a&gt; where you can use both &lt;code&gt;jj&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; commands interchangeably.&lt;/p&gt; 
&lt;h3&gt;The working copy is automatically committed&lt;/h3&gt; 
&lt;p&gt;Jujutsu uses a real commit to represent the working copy. Checking out a commit results a new working-copy commit on top of the target commit. Almost all commands automatically amend the working-copy commit.&lt;/p&gt; 
&lt;p&gt;The working-copy being a commit means that commands never fail because the working copy is dirty (no "error: Your local changes to the following files..."), and there is no need for &lt;code&gt;git stash&lt;/code&gt;. Also, because the working copy is a commit, commands work the same way on the working-copy commit as on any other commit, so you can set the commit message before you're done with the changes.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/working_copy.png" /&gt; 
&lt;h3&gt;The repo is the source of truth&lt;/h3&gt; 
&lt;p&gt;With Jujutsu, the working copy plays a smaller role than with Git. Commands snapshot the working copy before they start, then they update the repo, and then the working copy is updated (if the working-copy commit was modified). Almost all commands (even checkout!) operate on the commits in the repo, leaving the common functionality of snapshotting and updating of the working copy to centralized code. For example, &lt;code&gt;jj restore&lt;/code&gt; (similar to &lt;code&gt;git restore&lt;/code&gt;) can restore from any commit and into any commit, and &lt;code&gt;jj describe&lt;/code&gt; can set the commit message of any commit (defaults to the working-copy commit).&lt;/p&gt; 
&lt;h3&gt;Entire repo is under version control&lt;/h3&gt; 
&lt;p&gt;All operations you perform in the repo are recorded, along with a snapshot of the repo state after the operation. This means that you can easily restore to an earlier repo state, simply undo your operations one-by-one or even &lt;em&gt;revert&lt;/em&gt; a particular operation which does not have to be the most recent one.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/operation_log.png" /&gt; 
&lt;h3&gt;Conflicts can be recorded in commits&lt;/h3&gt; 
&lt;p&gt;If an operation results in &lt;a href="https://jj-vcs.github.io/jj/latest/glossary#conflict"&gt;conflicts&lt;/a&gt;, information about those conflicts will be recorded in the commit(s). The operation will succeed. You can then resolve the conflicts later. One consequence of this design is that there's no need to continue interrupted operations. Instead, you get a single workflow for resolving conflicts, regardless of which command caused them. This design also lets Jujutsu rebase merge commits correctly (unlike both Git and Mercurial).&lt;/p&gt; 
&lt;p&gt;Basic conflict resolution:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/resolve_conflicts.png" /&gt; 
&lt;p&gt;Juggling conflicts:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/juggle_conflicts.png" /&gt; 
&lt;h3&gt;Automatic rebase&lt;/h3&gt; 
&lt;p&gt;Whenever you modify a commit, any descendants of the old commit will be rebased onto the new commit. Thanks to the conflict design described above, that can be done even if there are conflicts. Bookmarks pointing to rebased commits will be updated. So will the working copy if it points to a rebased commit.&lt;/p&gt; 
&lt;h3&gt;Comprehensive support for rewriting history&lt;/h3&gt; 
&lt;p&gt;Besides the usual rebase command, there's &lt;code&gt;jj describe&lt;/code&gt; for editing the description (commit message) of an arbitrary commit. There's also &lt;code&gt;jj diffedit&lt;/code&gt;, which lets you edit the changes in a commit without checking it out. To split a commit into two, use &lt;code&gt;jj split&lt;/code&gt;. You can even move part of the changes in a commit to any other commit using &lt;code&gt;jj squash -i --from X --into Y&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;The tool is fairly feature-complete, but some important features like support for Git submodules are not yet completed. There are also several performance bugs. It's likely that workflows and setups different from what the core developers use are not well supported, e.g. there is no native support for email-based workflows.&lt;/p&gt; 
&lt;p&gt;Today, all core developers use &lt;code&gt;jj&lt;/code&gt; to work on &lt;code&gt;jj&lt;/code&gt;. I (Martin von Zweigbergk) have almost exclusively used &lt;code&gt;jj&lt;/code&gt; to develop the project itself since early January 2021. I haven't had to re-clone from source (I don't think I've even had to restore from backup).&lt;/p&gt; 
&lt;p&gt;There &lt;em&gt;will&lt;/em&gt; be changes to workflows and backward-incompatible changes to the on-disk formats before version 1.0.0. For any format changes, we'll try to implement transparent upgrades (as we've done with recent changes), or provide upgrade commands or scripts if requested.&lt;/p&gt; 
&lt;h2&gt;Related work&lt;/h2&gt; 
&lt;p&gt;There are several tools trying to solve similar problems as Jujutsu. See &lt;a href="https://jj-vcs.github.io/jj/latest/related-work"&gt;related work&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome outside contributions, and there's plenty of things to do, so don't be shy. Please ask if you want a pointer on something you can help with, and hopefully we can all figure something out.&lt;/p&gt; 
&lt;p&gt;We do have &lt;a href="https://jj-vcs.github.io/jj/prerelease/contributing/"&gt;a few policies and suggestions&lt;/a&gt; for contributors. The broad TL;DR:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports are very welcome!&lt;/li&gt; 
 &lt;li&gt;Every commit that lands in the &lt;code&gt;main&lt;/code&gt; branch is code reviewed.&lt;/li&gt; 
 &lt;li&gt;Please behave yourself, and obey the Community Guidelines.&lt;/li&gt; 
 &lt;li&gt;There &lt;strong&gt;is&lt;/strong&gt; a mandatory CLA you must agree to. Importantly, it &lt;strong&gt;does not&lt;/strong&gt; transfer copyright ownership to Google or anyone else; it simply gives us the right to safely redistribute and use your changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mandatory Google Disclaimer&lt;/h3&gt; 
&lt;p&gt;I (Martin von Zweigbergk, &lt;a href="mailto:martinvonz@google.com"&gt;martinvonz@google.com&lt;/a&gt;) started Jujutsu as a hobby project in late 2019, and it has evolved into my full-time project at Google, with several other Googlers (now) assisting development in various capacities. That said, &lt;strong&gt;this is not a Google product&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Jujutsu is available as Open Source Software, under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for details about copyright and redistribution.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;jj&lt;/code&gt; logo was contributed by J. Jennings and is licensed under a Creative Commons License, see &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/LICENSE"&gt;&lt;code&gt;docs/images/LICENSE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fredolx/open-tv</title>
      <link>https://github.com/Fredolx/open-tv</link>
      <description>&lt;p&gt;Ultra-fast, simple and powerful cross-platform IPTV app&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open TV&lt;/h1&gt; 
&lt;p&gt;Completely rewritten to accommodate new features and to be even speedier, Open TV has been carefully crafted to deliver the best IPTV experience.&lt;/p&gt; 
&lt;a href="https://apps.microsoft.com/detail/9PBWX3RKR1QX?launch=true&amp;amp;mode=mini"&gt; &lt;img src="https://get.microsoft.com/images/en-us%20dark.svg?sanitize=true" width="350" /&gt; &lt;/a&gt; 
&lt;a href="https://flathub.org/apps/dev.fredol.open-tv"&gt; &lt;img src="https://dl.flathub.org/assets/badges/flathub-badge-en.svg?sanitize=true" width="300" /&gt; &lt;/a&gt; 
&lt;a href="https://aur.archlinux.org/packages/open-tv-bin"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/aur-open-tv.svg?sanitize=true" width="350" /&gt; &lt;/a&gt; 
&lt;a href="https://apps.apple.com/ca/app/open-tv-open-source-iptv/id6742751800"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/app-store.svg?sanitize=true" width="300" /&gt; &lt;/a&gt; 
&lt;a href="https://play.google.com/store/apps/details?id=dev.fredol.open_tv"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/gplay.png" /&gt; &lt;/a&gt; 
&lt;h1&gt;This project NEEDS your help. Please consider donating on &lt;a href="https://github.com/sponsors/Fredolx"&gt;Github&lt;/a&gt;, &lt;a href="https://paypal.me/fredolx"&gt;Paypal&lt;/a&gt; or directly by &lt;a href="https://raw.githubusercontent.com/Fredolx/open-tv/main/#donate-crypto-thank-you"&gt;crypto&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;I've been developing and maintaining this project alone and for entirely for free over the past 2 years. I am in dire need of support to continue developing this project. I've never added annoying donation pop-ups or anything of the sort to make sure you have the fastest and cleanest IPTV experience and I'm committed to keep this project FREE &amp;amp; OPEN-SOURCE. To keep that commitment, I need your support!&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/Fredolx/open-tv/raw/main/screenshots/demo1.png" alt="Image of the app" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Import your IPTV channels from any source (M3U File, M3U link, Xtream) üóÉÔ∏è&lt;/li&gt; 
 &lt;li&gt;Record while watching üé•&lt;/li&gt; 
 &lt;li&gt;Multi IPTV sources üéä&lt;/li&gt; 
 &lt;li&gt;Control the UI from a TV remote üì∫&lt;/li&gt; 
 &lt;li&gt;Super low RAM usage, crazy speeds, and instant search üöÖ&lt;/li&gt; 
 &lt;li&gt;Refresh your sources when you need it üîÑ&lt;/li&gt; 
 &lt;li&gt;Add channels to favorites üåü&lt;/li&gt; 
 &lt;li&gt;Make your own custom channels&lt;/li&gt; 
 &lt;li&gt;Share your custom channels with friends&lt;/li&gt; 
 &lt;li&gt;Re-stream channels to friends or other devices (phone, tv)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;If you are on Windows or use the flatpak on Linux; SKIP THIS PART.&lt;/p&gt; 
&lt;p&gt;The app depends on mpv, ffmpeg and yt-dlp. If you are on MacOS, you must use Brew or MacPorts to install those dependencies.&lt;/p&gt; 
&lt;p&gt;On Fedora, you must add rpmfusion to install those packages.&lt;/p&gt; 
&lt;p&gt;On Debian or LTS distro, I would strongly suggest using a backport for yt-dlp.&lt;/p&gt; 
&lt;p&gt;The Windows build &lt;strong&gt;comes with mpv included&lt;/strong&gt; (.msi), but you can still install mpv from a package manager of your choice to always have the latest version installed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install mpv ffmpeg yt-dlp #MacOS
sudo dnf install mpv ffmpeg yt-dlp #Fedora
sudo zypper install mpv ffmpeg yt-dlp #OpenSUSE
sudo pacman -Syu mpv ffmpeg yt-dlp #Arch
sudo apt install mpv ffmpeg yt-dlp #Debian/Ubuntu
scoop install mpv ffmpeg yt-dlp # Windows
choco install mpv ffmpeg yt-dlp # Windows alternative
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;Feel free to submit any kind of feedback by creating a new issue.&lt;/p&gt; 
&lt;h2&gt;Hotkeys&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;F1: Help&lt;/li&gt; 
 &lt;li&gt;Ctrl + a: Show all channels&lt;/li&gt; 
 &lt;li&gt;Ctrl + s: Show categories&lt;/li&gt; 
 &lt;li&gt;Ctrl + d: Show favorites&lt;/li&gt; 
 &lt;li&gt;Ctrl + f: Search&lt;/li&gt; 
 &lt;li&gt;Ctrl + q: Enable/Disable livestreams&lt;/li&gt; 
 &lt;li&gt;Ctrl + w: Enable/Disable movies&lt;/li&gt; 
 &lt;li&gt;Ctrl + e: Enable/Disable series&lt;/li&gt; 
 &lt;li&gt;Backspace/Esc: Go back&lt;/li&gt; 
 &lt;li&gt;Arrow keys/Tab/Shift+Tab: Navigation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have a tv remote or air mouse that has slightly different bindings for general nav (back, up, down, left, right), please open an issue and I will add them if it's feasible. Otherwise, you can still use hwdb to make them match OpenTV's bindings.&lt;/p&gt; 
&lt;h2&gt;Settings explained&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stream Caching&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Why enabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a slow internet connection/IPTV provider causing the stream to pause often&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Why disabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If the stream often drops completely. It will prevent the stream from jumping too far ahead/behind&lt;/li&gt; 
 &lt;li&gt;If you have a good internet/provider and want lower latency&lt;/li&gt; 
 &lt;li&gt;Can prevent some weird bugs/slowdowns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Donate Crypto (Thank you!)&lt;/h2&gt; 
&lt;p&gt;BTC:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bc1q7v27u4mrxhtqzl97pcp4vl52npss760epsheu3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ETH:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0x171D5B628eff75c98c141aD5584FffA209274365
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;LTC:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ltc1qzxgp2grt9ayvpv0dur7lgzgf88yp09h2ytmga0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;BCH:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bitcoincash:qz4mauqyytkvhp9yze0qhgn2nnlv4z5glckyysxg2n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;AM7roSrxBKrS5mG7q6aXnQHZKh3ArtBxvG3x1B1VjKhj
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;BNB:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0x0C8C5217a8044b3736aD82CCFB9f099597b65253
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Open TV is an independent open-source project created to provide a fast and powerful IPTV experience. The name "Open TV" is used solely to represent this specific software and its purpose as described in the project documentation. Any other software, applications, or products bearing the same or similar name are unrelated to this project. Any resemblance to other software or applications is purely coincidental and unintended. We do not intend to cause confusion or imply affiliation with any other products or organizations that may share a similar name.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prefix-dev/pixi</title>
      <link>https://github.com/prefix-dev/pixi</link>
      <description>&lt;p&gt;Package management made easy&lt;/p&gt;&lt;hr&gt;&lt;h1&gt; &lt;a href="https://github.com/prefix-dev/pixi/"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="https://github.com/prefix-dev/pixi/assets/4995967/a3f9ff01-c9fb-4893-83c0-2a3f924df63e" type="image/webp" /&gt; 
   &lt;source srcset="https://github.com/prefix-dev/pixi/assets/4995967/e42739c4-4cd9-49bb-9d0a-45f8088494b5" type="image/png" /&gt; 
   &lt;img src="https://github.com/prefix-dev/pixi/assets/4995967/e42739c4-4cd9-49bb-9d0a-45f8088494b5" alt="banner" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;h1 align="center"&gt; &lt;p&gt;&lt;img src="https://img.shields.io/badge/license-BSD--3--Clause-blue?style=flat-square" alt="License" /&gt; &lt;a href="https://discord.gg/kKV8ZxyzY4"&gt;&lt;img src="https://img.shields.io/discord/1082332781146800168.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2&amp;amp;style=flat-square" alt="Project Chat" /&gt;&lt;/a&gt; &lt;a href="https://pixi.sh"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json&amp;amp;style=flat-square" alt="Pixi Badge" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/h1&gt; 
&lt;h1&gt;Pixi: Package Management Made Easy&lt;/h1&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pixi&lt;/code&gt; is a cross-platform, multi-language package manager and workflow tool built on the foundation of the conda ecosystem. It provides developers with an exceptional experience similar to popular package managers like &lt;a href="https://doc.rust-lang.org/cargo/"&gt;&lt;code&gt;cargo&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://docs.npmjs.com"&gt;&lt;code&gt;npm&lt;/code&gt;&lt;/a&gt;, but for any language.&lt;/p&gt; 
&lt;p&gt;Developed with ‚ù§Ô∏è at &lt;a href="https://prefix.dev"&gt;prefix.dev&lt;/a&gt;. &lt;a href="https://asciinema.org/a/636482"&gt;&lt;img src="https://github.com/prefix-dev/pixi/assets/12893423/0fc8f8c8-ac13-4c14-891b-dc613f25475b" alt="Real-time pixi_demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports &lt;strong&gt;multiple languages&lt;/strong&gt; including Python, C++, and R using Conda packages. You can find available packages on &lt;a href="https://prefix.dev"&gt;prefix.dev&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Compatible with all major operating systems: Linux, Windows, macOS (including Apple Silicon).&lt;/li&gt; 
 &lt;li&gt;Always includes an up-to-date &lt;a href="https://pixi.sh/latest/workspace/lockfile/"&gt;&lt;strong&gt;lock file&lt;/strong&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Provides a clean and simple Cargo-like &lt;strong&gt;command-line interface&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Allows you to install tools &lt;strong&gt;per-project&lt;/strong&gt; or &lt;strong&gt;system-wide&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Entirely written in &lt;strong&gt;Rust&lt;/strong&gt; and built on top of the &lt;strong&gt;&lt;a href="https://github.com/conda/rattler"&gt;rattler&lt;/a&gt;&lt;/strong&gt; library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö° &lt;a href="https://raw.githubusercontent.com/prefix-dev/pixi/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;a href="https://raw.githubusercontent.com/prefix-dev/pixi/main/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://pixi.sh/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üòç &lt;a href="https://raw.githubusercontent.com/prefix-dev/pixi/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî® &lt;a href="https://raw.githubusercontent.com/prefix-dev/pixi/main/#built-using-pixi"&gt;Built using Pixi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://github.com/prefix-dev/setup-pixi"&gt;GitHub Action&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;Pixi is ready for production! We are working hard to keep file-format changes compatible with the previous versions so that you can rely on Pixi with peace of mind.&lt;/p&gt; 
&lt;p&gt;Some notable features we envision for upcoming releases are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Build and publish&lt;/strong&gt; your project as a Conda package.&lt;/li&gt; 
 &lt;li&gt;Support for &lt;strong&gt;dependencies from source&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;More powerful "global installation" of packages towards a deterministic setup of global packages on multiple machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pixi&lt;/code&gt; can be installed on macOS, Linux, and Windows. The provided scripts will automatically download the latest version of &lt;code&gt;pixi&lt;/code&gt;, extract it, and move the &lt;code&gt;pixi&lt;/code&gt; binary to &lt;code&gt;~/.pixi/bin&lt;/code&gt;. If this directory does not exist, the script will create it.&lt;/p&gt; 
&lt;h3&gt;macOS and Linux&lt;/h3&gt; 
&lt;p&gt;To install Pixi on macOS and Linux, open a terminal and run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://pixi.sh/install.sh | sh
# or with brew
brew install pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The script will also update your &lt;code&gt;~/.bashrc&lt;/code&gt; to include &lt;code&gt;~/.pixi/bin&lt;/code&gt; in your &lt;code&gt;PATH&lt;/code&gt;, allowing you to invoke the &lt;code&gt;pixi&lt;/code&gt; command from anywhere. You might need to restart your terminal or source your shell for the changes to take effect.&lt;/p&gt; 
&lt;p&gt;Starting with macOS Catalina &lt;a href="https://support.apple.com/en-us/102360"&gt;zsh is the default login shell and interactive shell&lt;/a&gt;. Therefore, you might want to use &lt;code&gt;zsh&lt;/code&gt; instead of &lt;code&gt;bash&lt;/code&gt; in the install command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;curl -fsSL https://pixi.sh/install.sh | zsh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The script will also update your &lt;code&gt;~/.zshrc&lt;/code&gt; to include &lt;code&gt;~/.pixi/bin&lt;/code&gt; in your &lt;code&gt;PATH&lt;/code&gt;, allowing you to invoke the &lt;code&gt;pixi&lt;/code&gt; command from anywhere.&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;To install Pixi on Windows, open a PowerShell terminal (you may need to run it as an administrator) and run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;powershell -ExecutionPolicy ByPass -c "irm -useb https://pixi.sh/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Changing the &lt;a href="https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_execution_policies?view=powershell-7.4#powershell-execution-policies"&gt;execution policy&lt;/a&gt; allows running a script from the internet. Check the script you would be running with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;powershell -c "irm -useb https://pixi.sh/install.ps1 | more"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The script will inform you once the installation is successful and add the &lt;code&gt;~/.pixi/bin&lt;/code&gt; directory to your &lt;code&gt;PATH&lt;/code&gt;, which will allow you to run the &lt;code&gt;pixi&lt;/code&gt; command from any location. Or with &lt;code&gt;winget&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;winget install prefix-dev.pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Autocompletion&lt;/h3&gt; 
&lt;p&gt;To get autocompletion follow the instructions for your shell. Afterwards, restart the shell or source the shell config file.&lt;/p&gt; 
&lt;h4&gt;Bash (default on most Linux systems)&lt;/h4&gt; 
&lt;p&gt;Add the following to the end of &lt;code&gt;~/.bashrc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ~/.bashrc

eval "$(pixi completion --shell bash)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Zsh (default on macOS)&lt;/h4&gt; 
&lt;p&gt;Add the following to the end of &lt;code&gt;~/.zshrc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;# ~/.zshrc

eval "$(pixi completion --shell zsh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;PowerShell (pre-installed on all Windows systems)&lt;/h4&gt; 
&lt;p&gt;Add the following to the end of &lt;code&gt;Microsoft.PowerShell_profile.ps1&lt;/code&gt;. You can check the location of this file by querying the &lt;code&gt;$PROFILE&lt;/code&gt; variable in PowerShell. Typically the path is &lt;code&gt;~\Documents\PowerShell\Microsoft.PowerShell_profile.ps1&lt;/code&gt; or &lt;code&gt;~/.config/powershell/Microsoft.PowerShell_profile.ps1&lt;/code&gt; on -Nix.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-pwsh"&gt;(&amp;amp; pixi completion --shell powershell) | Out-String | Invoke-Expression
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Fish&lt;/h4&gt; 
&lt;p&gt;Add the following to the end of &lt;code&gt;~/.config/fish/config.fish&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-fish"&gt;# ~/.config/fish/config.fish

pixi completion --shell fish | source
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Nushell&lt;/h4&gt; 
&lt;p&gt;Add the following to your Nushell config file (find it by running &lt;code&gt;$nu.config-path&lt;/code&gt; in Nushell):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nushell"&gt;mkdir $"($nu.data-dir)/vendor/autoload"
pixi completion --shell nushell | save --force $"($nu.data-dir)/vendor/autoload/pixi-completions.nu"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Elvish&lt;/h4&gt; 
&lt;p&gt;Add the following to the end of &lt;code&gt;~/.elvish/rc.elv&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-elv"&gt;# ~/.elvish/rc.elv

eval (pixi completion --shell elvish | slurp)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Distro Packages&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/pixi/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/pixi.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Arch Linux&lt;/h4&gt; 
&lt;p&gt;You can install &lt;code&gt;pixi&lt;/code&gt; from the &lt;a href="https://archlinux.org/packages/extra/x86_64/pixi/"&gt;extra repository&lt;/a&gt; using &lt;a href="https://wiki.archlinux.org/title/Pacman"&gt;pacman&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pacman -S pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Alpine Linux&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;pixi&lt;/code&gt; is available for &lt;a href="https://pkgs.alpinelinux.org/packages?name=pixi&amp;amp;branch=edge"&gt;Alpine Edge&lt;/a&gt;. It can be installed via &lt;a href="https://wiki.alpinelinux.org/wiki/Alpine_Package_Keeper"&gt;apk&lt;/a&gt; after enabling the &lt;a href="https://wiki.alpinelinux.org/wiki/Repositories"&gt;testing repository&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;apk add pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Build/install from source&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;pixi&lt;/code&gt; is 100% written in Rust and therefore it can be installed, built and tested with cargo. To start using &lt;code&gt;pixi&lt;/code&gt; from a source build run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --locked --git https://github.com/prefix-dev/pixi.git pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We don't publish to &lt;code&gt;crates.io&lt;/code&gt; anymore, so you need to install it from the repository. The reason for this is that we depend on some unpublished crates which disallows us to publish to &lt;code&gt;crates.io&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;or when you want to make changes use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo build
cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have any issues building because of the dependency on &lt;code&gt;rattler&lt;/code&gt; checkout it's &lt;a href="https://github.com/conda/rattler/tree/main#give-it-a-try"&gt;compile steps&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Uninstall&lt;/h2&gt; 
&lt;p&gt;To uninstall, the Pixi binary should be removed. Delete &lt;code&gt;pixi&lt;/code&gt; from the &lt;code&gt;$PIXI_DIR&lt;/code&gt; which is default to &lt;code&gt;~/.pixi/bin/pixi&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;So on Linux its:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;rm ~/.pixi/bin/pixi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and on Windows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$PIXI_BIN = "$Env:LocalAppData\pixi\bin\pixi"; Remove-Item -Path $PIXI_BIN
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After this command you can still use the tools you installed with &lt;code&gt;pixi&lt;/code&gt;. To remove these as well just remove the whole &lt;code&gt;~/.pixi&lt;/code&gt; directory and remove the directory from your path.&lt;/p&gt; 
&lt;h1&gt;Usage&lt;/h1&gt; 
&lt;p&gt;The cli looks as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;‚ûú pixi
Pixi [version 0.59.0] - Developer Workflow and Environment Management for Multi-Platform, Language-Agnostic
Workspaces.

Pixi is a versatile developer workflow tool designed to streamline the management of your workspace's dependencies,
tasks, and environments.
Built on top of the Conda ecosystem, Pixi offers seamless integration with the PyPI ecosystem.

Basic Usage:
    Initialize pixi for a workspace:
    $ pixi init
    $ pixi add python numpy pytest

    Run a task:
    $ pixi task add test 'pytest -s'
    $ pixi run test

Found a Bug or Have a Feature Request?
Open an issue at: https://github.com/prefix-dev/pixi/issues

Need Help?
Ask a question on the Prefix Discord server: https://discord.gg/kKV8ZxyzY4

For more information, see the documentation at: https://pixi.sh

Usage: pixi [OPTIONS] [COMMAND]

Commands:
  add         Adds dependencies to the workspace [aliases: a]
  auth        Login to prefix.dev or anaconda.org servers to access private channels
  build       Workspace configuration
  clean       Cleanup the environments
  completion  Generates a completion script for a shell
  config      Configuration management
  exec        Run a command and install it in a temporary environment [aliases: x]
  global      Subcommand for global package management actions [aliases: g]
  info        Information about the system, workspace and environments for the current machine
  init        Creates a new workspace
  import      Imports a file into an environment in an existing workspace.
  install     Install an environment, both updating the lockfile and installing the environment [aliases: i]
  list        List the packages of the current workspace [aliases: ls]
  lock        Solve environment and update the lock file without installing the environments
  reinstall   Re-install an environment, both updating the lockfile and re-installing the environment
  remove      Removes dependencies from the workspace [aliases: rm]
  run         Runs task in the pixi environment [aliases: r]
  search      Search a conda package
  shell       Start a shell in a pixi environment, run `exit` to leave the shell [aliases: s]
  shell-hook  Print the pixi environment activation script
  task        Interact with tasks in the workspace
  tree        Show a tree of workspace dependencies [aliases: t]
  update      The `update` command checks if there are newer versions of the dependencies and updates the `pixi.lock`
              file and environments accordingly
  upgrade     Checks if there are newer versions of the dependencies and upgrades them in the lockfile and manifest
              file
  upload      Upload a conda package
  workspace   Modify the workspace configuration file through the command line
  help        Print this message or the help of the given subcommand(s)

Options:
  -V, --version  Print version

Global Options:
  -h, --help           Display help information
  -v, --verbose...     Increase logging verbosity (-v for warnings, -vv for info, -vvv for debug, -vvvv for trace)
  -q, --quiet...       Decrease logging verbosity (quiet mode)
      --color &amp;lt;COLOR&amp;gt;  Whether the log needs to be colored [env: PIXI_COLOR=] [default: auto] [possible values:
                       always, never, auto]
      --no-progress    Hide all progress bars, always turned on if stderr is not a terminal [env: PIXI_NO_PROGRESS=]
      --list           List all installed commands (built-in and extensions)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Creating a Pixi workspace&lt;/h2&gt; 
&lt;p&gt;Initialize a new workspace and navigate to the workspace directory&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pixi init myworkspace
cd myworkspace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add the dependencies you want to use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pixi add cowpy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the installed package in its environment&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pixi run cowpy "Thanks for using pixi"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Activate a shell in the environment&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pixi shell
cowpy "Thanks for using pixi"
exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out &lt;a href="https://pixi.sh/dev/first_workspace/"&gt;https://pixi.sh/dev/first_workspace/&lt;/a&gt; for a more detailed introduction to workspaces.&lt;/p&gt; 
&lt;h2&gt;Installing a conda package globally&lt;/h2&gt; 
&lt;p&gt;You can also globally install conda packages into their own environment. This behavior is similar to &lt;a href="https://github.com/pypa/pipx"&gt;&lt;code&gt;pipx&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://github.com/mariusvniekerk/condax"&gt;&lt;code&gt;condax&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pixi global install cowpy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Use in GitHub Actions&lt;/h2&gt; 
&lt;p&gt;You can use Pixi in GitHub Actions to install dependencies and run commands. It supports automatic caching of your environments.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;- uses: prefix-dev/setup-pixi@v0.8.1
- run: pixi exec cowpy "Thanks for using pixi"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://pixi.sh/latest/advanced/github_actions"&gt;documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;&lt;a name="contributing"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing üòç&lt;/h2&gt; 
&lt;p&gt;We would absolutely love for you to contribute to Pixi! Whether you want to start an issue, fix a bug you encountered, or suggest an improvement, every contribution is greatly appreciated.&lt;/p&gt; 
&lt;p&gt;If you're just getting started with our project or stepping into the Rust ecosystem for the first time, we've got your back! We recommend beginning with issues labeled as &lt;code&gt;good first issue&lt;/code&gt;. These are carefully chosen tasks that provide a smooth entry point into contributing.These issues are typically more straightforward and are a great way to get familiar with the project.&lt;/p&gt; 
&lt;p&gt;Got questions or ideas, or just want to chat? Join our lively conversations on Discord. We're very active and would be happy to welcome you to our community. &lt;a href="https://discord.gg/kKV8ZxyzY4"&gt;Join our discord server today!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a name="pixibuilt"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Built using Pixi&lt;/h2&gt; 
&lt;p&gt;To see what's being built with &lt;code&gt;pixi&lt;/code&gt; check out the &lt;a href="https://raw.githubusercontent.com/prefix-dev/pixi/main/docs/misc/Community.md"&gt;Community&lt;/a&gt; page.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>starship/starship</title>
      <link>https://github.com/starship/starship</link>
      <description>&lt;p&gt;‚òÑüååÔ∏è The minimal, blazing-fast, and infinitely customizable prompt for any shell!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="400" src="https://raw.githubusercontent.com/starship/starship/master/media/logo.png" alt="Starship ‚Äì Cross-shell prompt" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/starship/starship/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/starship/starship/workflow.yml?branch=master&amp;amp;label=workflow&amp;amp;style=flat-square" alt="GitHub Actions workflow status" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/starship"&gt;&lt;img src="https://img.shields.io/crates/v/starship?style=flat-square" alt="Crates.io version" /&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/starship/versions"&gt;&lt;img src="https://img.shields.io/repology/repositories/starship?label=in%20repositories&amp;amp;style=flat-square" alt="Packaging status" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://discord.gg/starship"&gt;&lt;img src="https://img.shields.io/discord/567163873606500352?label=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Chat on Discord" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/StarshipPrompt"&gt;&lt;img src="https://img.shields.io/badge/twitter-@StarshipPrompt-1DA1F3?style=flat-square" alt="Follow @StarshipPrompt on Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stand-with-ukraine.pp.ua"&gt;&lt;img src="https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/badges/StandWithUkraineFlat.svg?sanitize=true" alt="Stand With Ukraine" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://starship.rs"&gt;Website&lt;/a&gt; ¬∑ &lt;a href="#üöÄ-installation"&gt;Installation&lt;/a&gt; ¬∑ &lt;a href="https://starship.rs/config/"&gt;Configuration&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/starship/starship/raw/master/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-us.png" alt="English" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/de-DE/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-de.png" alt="Deutsch" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/es-ES/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-es.png" alt="Espa√±ol" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/fr-FR/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-fr.png" alt="Fran√ßais" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/id-ID/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-id.png" alt="Bahasa Indonesia" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/it-IT/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-it.png" alt="Italiano" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/ja-JP/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-jp.png" alt="Êó•Êú¨Ë™û" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/pt-BR/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-br.png" alt="Portugu√™s do Brasil" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/ru-RU/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-ru.png" alt="–†—É—Å—Å–∫–∏–π" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/uk-UA/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-ua.png" alt="–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/vi-VN/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-vn.png" alt="Ti·∫øng Vi·ªát" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/zh-CN/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-cn.png" alt="ÁÆÄ‰Ωì‰∏≠Êñá" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/starship/starship/raw/master/docs/zh-TW/guide/README.md"&gt;&lt;img height="20" src="https://raw.githubusercontent.com/starship/starship/master/media/flag-tw.png" alt="ÁπÅÈ´î‰∏≠Êñá" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/starship/starship/master/media/demo.gif" alt="Starship with iTerm2 and the Snazzy theme" width="50%" align="right" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The minimal, blazing-fast, and infinitely customizable prompt for any shell!&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast:&lt;/strong&gt; it's fast ‚Äì &lt;em&gt;really really&lt;/em&gt; fast! üöÄ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable:&lt;/strong&gt; configure every aspect of your prompt.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Universal:&lt;/strong&gt; works on any shell, on any operating system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent:&lt;/strong&gt; shows relevant information at a glance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature rich:&lt;/strong&gt; support for all your favorite tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy:&lt;/strong&gt; quick to install ‚Äì&amp;nbsp;start using it in minutes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;a href="https://starship.rs/config/"&gt;&lt;strong&gt;Explore the Starship docs&amp;nbsp;&amp;nbsp;‚ñ∂&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a name="üöÄ-installation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A &lt;a href="https://www.nerdfonts.com/"&gt;Nerd Font&lt;/a&gt; installed and enabled in your terminal (for example, try the &lt;a href="https://www.nerdfonts.com/font-downloads"&gt;FiraCode Nerd Font&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1. Install Starship&lt;/h3&gt; 
&lt;p&gt;Select your operating system from the list below to view installation instructions:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Android&lt;/summary&gt; 
 &lt;p&gt;Install Starship using any of the following package managers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Repository&lt;/th&gt; 
    &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/termux/termux-packages/tree/master/packages/starship"&gt;Termux&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pkg install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;BSD&lt;/summary&gt; 
 &lt;p&gt;Install Starship using any of the following package managers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Distribution&lt;/th&gt; 
    &lt;th&gt;Repository&lt;/th&gt; 
    &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;em&gt;Any&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;a href="https://crates.io/crates/starship"&gt;crates.io&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cargo install starship --locked&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;FreeBSD&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://www.freshports.org/shells/starship"&gt;FreshPorts&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pkg install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;NetBSD&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://pkgsrc.se/shells/starship"&gt;pkgsrc&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pkgin install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Linux&lt;/summary&gt; 
 &lt;p&gt;Install the latest version for your system:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;curl -sS https://starship.rs/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Alternatively, install Starship using any of the following package managers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Distribution&lt;/th&gt; 
    &lt;th&gt;Repository&lt;/th&gt; 
    &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;em&gt;Any&lt;/em&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;a href="https://crates.io/crates/starship"&gt;crates.io&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cargo install starship --locked&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;em&gt;Any&lt;/em&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://anaconda.org/conda-forge/starship"&gt;conda-forge&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;conda install -c conda-forge starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;em&gt;Any&lt;/em&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://formulae.brew.sh/formula/starship"&gt;Linuxbrew&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;brew install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Alpine Linux 3.13+&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://pkgs.alpinelinux.org/packages?name=starship"&gt;Alpine Linux Packages&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;apk add starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arch Linux&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/starship"&gt;Arch Linux Extra&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pacman -S starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CentOS 7+&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://copr.fedorainfracloud.org/coprs/atim/starship"&gt;Copr&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dnf copr enable atim/starship&lt;/code&gt; &lt;br /&gt; &lt;code&gt;dnf install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Debian 13+&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://sources.debian.org/src/starship/1.22.1-1/"&gt;Debian Main&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;apt install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Fedora 40+&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://copr.fedorainfracloud.org/coprs/atim/starship"&gt;Copr&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dnf copr enable atim/starship&lt;/code&gt; &lt;br /&gt; &lt;code&gt;dnf install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Gentoo&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://packages.gentoo.org/packages/app-shells/starship"&gt;Gentoo Packages&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;emerge app-shells/starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Manjaro&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pacman -S starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;NixOS&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/NixOS/nixpkgs/raw/master/pkgs/by-name/st/starship/package.nix"&gt;nixpkgs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;nix-env -iA nixpkgs.starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;openSUSE&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://software.opensuse.org/package/starship"&gt;OSS&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;zypper in starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Ubuntu 25.04+&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://packages.ubuntu.com/source/plucky/starship"&gt;Ubuntu Universe&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;apt install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Void Linux&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/void-linux/void-packages/tree/master/srcpkgs/starship"&gt;Void Linux Packages&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;xbps-install -S starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;macOS&lt;/summary&gt; 
 &lt;p&gt;Install the latest version for your system:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;curl -sS https://starship.rs/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Alternatively, install Starship using any of the following package managers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Repository&lt;/th&gt; 
    &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;a href="https://crates.io/crates/starship"&gt;crates.io&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cargo install starship --locked&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://anaconda.org/conda-forge/starship"&gt;conda-forge&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;conda install -c conda-forge starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://formulae.brew.sh/formula/starship"&gt;Homebrew&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;brew install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://ports.macports.org/port/starship"&gt;MacPorts&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;port install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Windows&lt;/summary&gt; 
 &lt;p&gt;Install the latest version for your system with the MSI-installers from the &lt;a href="https://github.com/starship/starship/releases/latest"&gt;releases section&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Install Starship using any of the following package managers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Repository&lt;/th&gt; 
    &lt;th&gt;Instructions&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;&lt;a href="https://crates.io/crates/starship"&gt;crates.io&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cargo install starship --locked&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://community.chocolatey.org/packages/starship"&gt;Chocolatey&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;choco install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://anaconda.org/conda-forge/starship"&gt;conda-forge&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;conda install -c conda-forge starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ScoopInstaller/Main/raw/master/bucket/starship.json"&gt;Scoop&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;scoop install starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/winget-pkgs/tree/master/manifests/s/Starship/Starship"&gt;winget&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;winget install --id Starship.Starship&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step 2. Set up your shell to use Starship&lt;/h3&gt; 
&lt;p&gt;Configure your shell to initialize starship. Select yours from the list below:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Bash&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.bashrc&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;eval "$(starship init bash)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Cmd&lt;/summary&gt; 
 &lt;p&gt;You need to use &lt;a href="https://chrisant996.github.io/clink/clink.html"&gt;Clink&lt;/a&gt; (v1.2.30+) with Cmd. Create a file at this path &lt;code&gt;%LocalAppData%\clink\starship.lua&lt;/code&gt; with the following contents:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-lua"&gt;load(io.popen('starship init cmd'):read("*a"))()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Elvish&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.config/elvish/rc.elv&lt;/code&gt; (&lt;code&gt;%AppData%\elvish\rc.elv&lt;/code&gt; on Windows):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;eval (starship init elvish)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: Only Elvish v0.18+ is supported. For elvish versions prior to v0.21.0 the config file might instead be &lt;code&gt;~/.elvish/rc.elv&lt;/code&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Fish&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.config/fish/config.fish&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-fish"&gt;starship init fish | source
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Ion&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.config/ion/initrc&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;eval $(starship init ion)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Nushell&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of your Nushell configuration (find it by running &lt;code&gt;$nu.config-path&lt;/code&gt; in Nushell):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;mkdir ($nu.data-dir | path join "vendor/autoload")
starship init nu | save -f ($nu.data-dir | path join "vendor/autoload/starship.nu")
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Note: Only Nushell v0.96+ is supported&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;PowerShell&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of your PowerShell configuration (find it by running &lt;code&gt;$PROFILE&lt;/code&gt;):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;Invoke-Expression (&amp;amp;starship init powershell)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Tcsh&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.tcshrc&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;eval `starship init tcsh`
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Xonsh&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.xonshrc&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;execx($(starship init xonsh))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Zsh&lt;/summary&gt; 
 &lt;p&gt;Add the following to the end of &lt;code&gt;~/.zshrc&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;eval "$(starship init zsh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Step 3. Configure Starship&lt;/h3&gt; 
&lt;p&gt;Start a new shell instance, and you should see your beautiful new shell prompt. If you're happy with the defaults, enjoy!&lt;/p&gt; 
&lt;p&gt;If you're looking to further customize Starship:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://starship.rs/config/"&gt;Configuration&lt;/a&gt;&lt;/strong&gt; ‚Äì learn how to configure Starship to tweak your prompt to your liking&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://starship.rs/presets/"&gt;Presets&lt;/a&gt;&lt;/strong&gt; ‚Äì get inspired by the pre-built configuration of others&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We are always looking for contributors of &lt;strong&gt;all skill levels&lt;/strong&gt;! If you're looking to ease your way into the project, try out a &lt;a href="https://github.com/starship/starship/labels/%22%F0%9F%8C%B1%20good%20first%20issue%22"&gt;good first issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are fluent in a non-English language, we greatly appreciate any help keeping our docs translated and up-to-date in other languages. If you would like to help, translations can be contributed on the &lt;a href="https://translate.starship.rs/"&gt;Starship Crowdin&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are interested in helping contribute to starship, please take a look at our &lt;a href="https://github.com/starship/starship/raw/master/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;. Also, feel free to drop into our &lt;a href="https://discord.gg/8Jzqu3T"&gt;Discord server&lt;/a&gt; and say hi. üëã&lt;/p&gt; 
&lt;h2&gt;üí≠ Inspired By&lt;/h2&gt; 
&lt;p&gt;Please check out these previous works that helped inspire the creation of starship. üôè&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/denysdovhan/spaceship-prompt"&gt;denysdovhan/spaceship-prompt&lt;/a&gt;&lt;/strong&gt; ‚Äì A ZSH prompt for astronauts.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/denysdovhan/robbyrussell-node"&gt;denysdovhan/robbyrussell-node&lt;/a&gt;&lt;/strong&gt; ‚Äì Cross-shell robbyrussell theme written in JavaScript.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/reujab/silver"&gt;reujab/silver&lt;/a&gt;&lt;/strong&gt; ‚Äì A cross-shell customizable powerline-like prompt with icons.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;p&gt;Support this project by &lt;a href="https://github.com/sponsors/starship"&gt;becoming a sponsor&lt;/a&gt;. Your name or logo will show up here with a link to your website.&lt;/p&gt; 
&lt;h2&gt;üîí Code Signing Policy&lt;/h2&gt; 
&lt;p&gt;Free code signing provided by &lt;a href="https://signpath.io"&gt;SignPath.io&lt;/a&gt;, certificate by &lt;a href="https://signpath.org"&gt;SignPath Foundation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Code Signing Roles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reviewers: &lt;a href="https://github.com/orgs/starship/teams/astronauts"&gt;Astronauts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Approvers and Authors: &lt;a href="https://github.com/orgs/starship/teams/mission-control"&gt;Mission Control&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This program will not transfer any information to other networked systems unless specifically requested by the user or the person installing or operating it.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;br /&gt; &lt;img width="100" src="https://raw.githubusercontent.com/starship/starship/master/media/icon.png" alt="Starship rocket icon" /&gt; &lt;/p&gt; 
&lt;h2&gt;üìù License&lt;/h2&gt; 
&lt;p&gt;Copyright ¬© 2019-present, &lt;a href="https://github.com/starship/starship/graphs/contributors"&gt;Starship Contributors&lt;/a&gt;.&lt;br /&gt; This project is &lt;a href="https://github.com/starship/starship/raw/master/LICENSE"&gt;ISC&lt;/a&gt; licensed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>solana-foundation/anchor</title>
      <link>https://github.com/solana-foundation/anchor</link>
      <description>&lt;p&gt;‚öì Solana Program Framework&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img height="170x" src="https://pbs.twimg.com/media/FVUVaO9XEAAulvK?format=png&amp;amp;name=small" /&gt; 
 &lt;h1&gt;Anchor&lt;/h1&gt; 
 &lt;p&gt; &lt;strong&gt;Solana Program Framework&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://github.com/coral-xyz/anchor/actions"&gt;&lt;img alt="Build Status" src="https://github.com/coral-xyz/anchor/actions/workflows/tests.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://anchor-lang.com"&gt;&lt;img alt="Tutorials" src="https://img.shields.io/badge/docs-tutorials-blueviolet" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NHHGSXAnXk"&gt;&lt;img alt="Discord Chat" src="https://img.shields.io/discord/889577356681945098?color=blueviolet" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/coral-xyz/anchor?color=blueviolet" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://www.anchor-lang.com/"&gt;Anchor&lt;/a&gt; is a framework providing several convenient developer tools for writing Solana programs (sometimes called 'smart contracts').&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rust eDSL for writing Solana programs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Interface_description_language"&gt;IDL&lt;/a&gt; specification&lt;/li&gt; 
 &lt;li&gt;TypeScript package for generating clients from IDL&lt;/li&gt; 
 &lt;li&gt;CLI and workspace management for developing complete applications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Anchor is the most popular framework for Solana programs.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you're familiar with developing in Ethereum's &lt;a href="https://docs.soliditylang.org/en/"&gt;Solidity&lt;/a&gt;, &lt;a href="https://www.trufflesuite.com/"&gt;Truffle&lt;/a&gt;, &lt;a href="https://github.com/ethereum/web3.js"&gt;web3.js&lt;/a&gt;, then using Anchor will be familiar. Although the DSL syntax and semantics are targeted at Solana, the high level flow of writing RPC request handlers, emitting an IDL, and generating clients from IDL is the same.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;For a quickstart guide and in depth tutorials, see the &lt;a href="https://book.anchor-lang.com"&gt;Anchor book&lt;/a&gt; and the &lt;a href="https://anchor-lang.com"&gt;Anchor documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To jump straight to examples, go &lt;a href="https://github.com/coral-xyz/anchor/tree/master/examples"&gt;here&lt;/a&gt;. For the latest Rust and TypeScript API documentation, see &lt;a href="https://docs.rs/anchor-lang"&gt;docs.rs&lt;/a&gt; and the &lt;a href="https://www.anchor-lang.com/docs/clients/typescript"&gt;typedoc&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Packages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-lang&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rust primitives for writing programs on Solana&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-lang"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-lang?color=blue" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-lang"&gt;&lt;img src="https://docs.rs/anchor-lang/badge.svg?sanitize=true" alt="Docs.rs" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-spl&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CPI clients for SPL programs on Solana&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-spl"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-spl?color=blue" alt="crates" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-spl"&gt;&lt;img src="https://docs.rs/anchor-spl/badge.svg?sanitize=true" alt="Docs.rs" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-client&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rust client for Anchor programs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-client"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-client?color=blue" alt="crates" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-client"&gt;&lt;img src="https://docs.rs/anchor-client/badge.svg?sanitize=true" alt="Docs.rs" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;@coral-xyz/anchor&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TypeScript client for Anchor programs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.npmjs.com/package/@coral-xyz/anchor"&gt;&lt;img src="https://img.shields.io/npm/v/@coral-xyz/anchor.svg?color=blue" alt="npm" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coral-xyz.github.io/anchor/ts/index.html"&gt;&lt;img src="https://img.shields.io/badge/docs-typedoc-blue" alt="Docs" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;@coral-xyz/anchor-cli&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CLI to support building and managing an Anchor workspace&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.npmjs.com/package/@coral-xyz/anchor-cli"&gt;&lt;img src="https://img.shields.io/npm/v/@coral-xyz/anchor-cli.svg?color=blue" alt="npm" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.anchor-lang.com/docs/references/cli"&gt;&lt;img src="https://img.shields.io/badge/docs-typedoc-blue" alt="Docs" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Note&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anchor is in active development, so all APIs are subject to change.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;This code is unaudited. Use at your own risk.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Here's a counter program, where only the designated &lt;code&gt;authority&lt;/code&gt; can increment the count.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use anchor_lang::prelude::*;

declare_id!("Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS");

#[program]
mod counter {
    use super::*;

    pub fn initialize(ctx: Context&amp;lt;Initialize&amp;gt;, start: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let counter = &amp;amp;mut ctx.accounts.counter;
        counter.authority = *ctx.accounts.authority.key;
        counter.count = start;
        Ok(())
    }

    pub fn increment(ctx: Context&amp;lt;Increment&amp;gt;) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let counter = &amp;amp;mut ctx.accounts.counter;
        counter.count += 1;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize&amp;lt;'info&amp;gt; {
    #[account(init, payer = authority, space = 48)]
    pub counter: Account&amp;lt;'info, Counter&amp;gt;,
    pub authority: Signer&amp;lt;'info&amp;gt;,
    pub system_program: Program&amp;lt;'info, System&amp;gt;,
}

#[derive(Accounts)]
pub struct Increment&amp;lt;'info&amp;gt; {
    #[account(mut, has_one = authority)]
    pub counter: Account&amp;lt;'info, Counter&amp;gt;,
    pub authority: Signer&amp;lt;'info&amp;gt;,
}

#[account]
pub struct Counter {
    pub authority: Pubkey,
    pub count: u64,
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more, see the &lt;a href="https://github.com/coral-xyz/anchor/tree/master/examples"&gt;examples&lt;/a&gt; and &lt;a href="https://github.com/coral-xyz/anchor/tree/master/tests"&gt;tests&lt;/a&gt; directories.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Anchor is licensed under &lt;a href="https://raw.githubusercontent.com/solana-foundation/anchor/master/LICENSE"&gt;Apache 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Anchor by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Thank you for your interest in contributing to Anchor! Please see the &lt;a href="https://raw.githubusercontent.com/solana-foundation/anchor/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to learn how.&lt;/p&gt; 
&lt;h3&gt;Thanks ‚ù§Ô∏è&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/coral-xyz/anchor/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=coral-xyz/anchor" width="100%" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>huggingface/candle</title>
      <link>https://github.com/huggingface/candle</link>
      <description>&lt;p&gt;Minimalist ML framework for Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;candle&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/hugging-face-879548962464493619"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/hugging-face-879548962464493619" alt="discord server" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/candle-core"&gt;&lt;img src="https://img.shields.io/crates/v/candle-core.svg?sanitize=true" alt="Latest version" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/candle-core"&gt;&lt;img src="https://docs.rs/candle-core/badge.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/candle/raw/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/github/license/base-org/node?color=blue" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/huggingface/candle/raw/main/LICENSE-APACHE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) and ease of use. Try our online demos: &lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;LLaMA2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-yolo"&gt;yolo&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;Make sure that you have &lt;a href="https://github.com/huggingface/candle/tree/main/candle-core"&gt;&lt;code&gt;candle-core&lt;/code&gt;&lt;/a&gt; correctly installed as described in &lt;a href="https://huggingface.github.io/candle/guide/installation.html"&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Let's see how to run a simple matrix multiplication. Write the following to your &lt;code&gt;myapp/src/main.rs&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use candle_core::{Device, Tensor};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let device = Device::Cpu;

    let a = Tensor::randn(0f32, 1., (2, 3), &amp;amp;device)?;
    let b = Tensor::randn(0f32, 1., (3, 4), &amp;amp;device)?;

    let c = a.matmul(&amp;amp;b)?;
    println!("{c}");
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;cargo run&lt;/code&gt; should display a tensor of shape &lt;code&gt;Tensor[[2, 4], f32]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Having installed &lt;code&gt;candle&lt;/code&gt; with Cuda support, simply define the &lt;code&gt;device&lt;/code&gt; to be on GPU:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt;- let device = Device::Cpu;
+ let device = Device::new_cuda(0)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more advanced examples, please have a look at the following section.&lt;/p&gt; 
&lt;h2&gt;Check out our examples&lt;/h2&gt; 
&lt;p&gt;These online demos run entirely in your browser:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-yolo"&gt;yolo&lt;/a&gt;: pose estimation and object recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;: speech recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;LLaMA2&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"&gt;Phi-1.5, and Phi-2&lt;/a&gt;: text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything Model&lt;/a&gt;: Image segmentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/radames/Candle-BLIP-Image-Captioning"&gt;BLIP&lt;/a&gt;: image captioning.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also provide some command line based examples using state of the art models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/llama/"&gt;LLaMA v1, v2, and v3&lt;/a&gt;: general LLM, includes the SOLAR-10.7B variant.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/falcon/"&gt;Falcon&lt;/a&gt;: general LLM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/codegeex4-9b/"&gt;Codegeex4&lt;/a&gt;: Code completion, code interpreter, web search, function calling, repository-level&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/glm4/"&gt;GLM4&lt;/a&gt;: Open Multilingual Multimodal Chat LMs by THUDM&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/gemma/"&gt;Gemma v1 and v2&lt;/a&gt;: 2b and 7b+/9b general LLMs from Google Deepmind.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/recurrent-gemma/"&gt;RecurrentGemma&lt;/a&gt;: 2b and 7b Griffin based models from Google that mix attention with a RNN like state.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/phi/"&gt;Phi-1, Phi-1.5, Phi-2, and Phi-3&lt;/a&gt;: 1.3b, 2.7b, and 3.8b general LLMs with performance on par with 7b models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/stable-lm/"&gt;StableLM-3B-4E1T&lt;/a&gt;: a 3b general LLM pre-trained on 1T tokens of English and code datasets. Also supports StableLM-2, a 1.6b LLM trained on 2T tokens, as well as the code variants.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mamba/"&gt;Mamba&lt;/a&gt;: an inference only implementation of the Mamba state space model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mistral/"&gt;Mistral7b-v0.1&lt;/a&gt;: a 7b general LLM with better performance than all publicly available 13b models as of 2023-09-28.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/mixtral/"&gt;Mixtral8x7b-v0.1&lt;/a&gt;: a sparse mixture of experts 8x7b general LLM with better performance than a Llama 2 70B model with much faster inference.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bigcode/"&gt;StarCoder&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/starcoder2/"&gt;StarCoder2&lt;/a&gt;: LLM specialized to code generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/qwen/"&gt;Qwen1.5&lt;/a&gt;: Bilingual (English/Chinese) LLMs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/rwkv/"&gt;RWKV v5 and v6&lt;/a&gt;: An RNN with transformer level LLM performance.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/replit-code/"&gt;Replit-code-v1.5&lt;/a&gt;: a 3.3b LLM specialized for code completion.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yi/"&gt;Yi-6B / Yi-34B&lt;/a&gt;: two bilingual (English/Chinese) general LLMs with 6b and 34b parameters.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/quantized/"&gt;Quantized LLaMA&lt;/a&gt;: quantized version of the LLaMA model using the same quantization techniques as &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/quantized/assets/aoc.gif" width="600" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/stable-diffusion/"&gt;Stable Diffusion&lt;/a&gt;: text to image generative model, support for the 1.5, 2.1, SDXL 1.0 and Turbo versions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/stable-diffusion/assets/stable-diffusion-xl.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/wuerstchen/"&gt;Wuerstchen&lt;/a&gt;: another text to image generative model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/wuerstchen/assets/cat.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yolo-v3/"&gt;yolo-v3&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/yolo-v8/"&gt;yolo-v8&lt;/a&gt;: object detection and pose estimation models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.od.jpg" width="200" /&gt;&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.pose.jpg" width="200" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/segment-anything/"&gt;segment-anything&lt;/a&gt;: image segmentation model with prompt.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://github.com/huggingface/candle/raw/main/candle-examples/examples/segment-anything/assets/sam_merged.jpg" width="200" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/segformer/"&gt;SegFormer&lt;/a&gt;: transformer based semantic segmentation model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/whisper/"&gt;Whisper&lt;/a&gt;: speech recognition model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/encodec/"&gt;EnCodec&lt;/a&gt;: high-quality audio compression model using residual vector quantization.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/metavoice/"&gt;MetaVoice&lt;/a&gt;: foundational model for text-to-speech.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/parler-tts/"&gt;Parler-TTS&lt;/a&gt;: large text-to-speech model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/t5"&gt;T5&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/bert/"&gt;Bert&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/jina-bert/"&gt;JinaBert&lt;/a&gt; : useful for sentence embeddings.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/dinov2/"&gt;DINOv2&lt;/a&gt;: computer vision model trained using self-supervision (can be used for imagenet classification, depth evaluation, segmentation).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/vgg/"&gt;VGG&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/repvgg"&gt;RepVGG&lt;/a&gt;: computer vision models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/blip/"&gt;BLIP&lt;/a&gt;: image to text model, can be used to generate captions for an image.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/clip/"&gt;CLIP&lt;/a&gt;: multi-model vision and language model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/trocr/"&gt;TrOCR&lt;/a&gt;: a transformer OCR model, with dedicated submodels for hand-writing and printed recognition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/marian-mt/"&gt;Marian-MT&lt;/a&gt;: neural machine translation model, generates the translated text from the input text.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/examples/moondream/"&gt;Moondream&lt;/a&gt;: tiny computer-vision model that can answer real-world questions about images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run them using commands like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo run --example quantized --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In order to use &lt;strong&gt;CUDA&lt;/strong&gt; add &lt;code&gt;--features cuda&lt;/code&gt; to the example command line. If you have cuDNN installed, use &lt;code&gt;--features cudnn&lt;/code&gt; for even more speedups.&lt;/p&gt; 
&lt;p&gt;There are also some wasm examples for whisper and &lt;a href="https://github.com/karpathy/llama2.c"&gt;llama2.c&lt;/a&gt;. You can either build them with &lt;code&gt;trunk&lt;/code&gt; or try them online: &lt;a href="https://huggingface.co/spaces/lmz/candle-whisper"&gt;whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/lmz/candle-llama2"&gt;llama2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm"&gt;T5&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm"&gt;Phi-1.5, and Phi-2&lt;/a&gt;, &lt;a href="https://huggingface.co/spaces/radames/candle-segment-anything-wasm"&gt;Segment Anything Model&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For LLaMA2, run the following command to retrieve the weight files and start a test server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd candle-wasm-examples/llama2-c
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json
trunk serve --release --port 8081
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then head over to &lt;a href="http://localhost:8081/"&gt;http://localhost:8081/&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ANCHOR: useful_libraries ---&gt; 
&lt;h2&gt;Useful External Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ToluClassics/candle-tutorial"&gt;&lt;code&gt;candle-tutorial&lt;/code&gt;&lt;/a&gt;: A very detailed tutorial showing how to convert a PyTorch model to Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-lora"&gt;&lt;code&gt;candle-lora&lt;/code&gt;&lt;/a&gt;: Efficient and ergonomic LoRA implementation for Candle. &lt;code&gt;candle-lora&lt;/code&gt; has&lt;br /&gt; out-of-the-box LoRA support for many models from Candle, which can be found &lt;a href="https://github.com/EricLBuehler/candle-lora/tree/master/candle-lora-transformers/examples"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KGrewal1/optimisers"&gt;&lt;code&gt;optimisers&lt;/code&gt;&lt;/a&gt;: A collection of optimisers including SGD with momentum, AdaGrad, AdaDelta, AdaMax, NAdam, RAdam, and RMSprop.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-vllm"&gt;&lt;code&gt;candle-vllm&lt;/code&gt;&lt;/a&gt;: Efficient platform for inference and serving local LLMs including an OpenAI compatible API server.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mokeyish/candle-ext"&gt;&lt;code&gt;candle-ext&lt;/code&gt;&lt;/a&gt;: An extension library to Candle that provides PyTorch functions not currently available in Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vishpat/candle-coursera-ml"&gt;&lt;code&gt;candle-coursera-ml&lt;/code&gt;&lt;/a&gt;: Implementation of ML algorithms from Coursera's &lt;a href="https://www.coursera.org/specializations/machine-learning-introduction"&gt;Machine Learning Specialization&lt;/a&gt; course.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/floneum/floneum/tree/master/interfaces/kalosm"&gt;&lt;code&gt;kalosm&lt;/code&gt;&lt;/a&gt;: A multi-modal meta-framework in Rust for interfacing with local pre-trained models with support for controlled generation, custom samplers, in-memory vector databases, audio transcription, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/candle-sampling"&gt;&lt;code&gt;candle-sampling&lt;/code&gt;&lt;/a&gt;: Sampling techniques for Candle.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jeroenvlek/gpt-from-scratch-rs"&gt;&lt;code&gt;gpt-from-scratch-rs&lt;/code&gt;&lt;/a&gt;: A port of Andrej Karpathy's &lt;em&gt;Let's build GPT&lt;/em&gt; tutorial on YouTube showcasing the Candle API on a toy problem.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tomsanbear/candle-einops"&gt;&lt;code&gt;candle-einops&lt;/code&gt;&lt;/a&gt;: A pure rust implementation of the python &lt;a href="https://github.com/arogozhnikov/einops"&gt;einops&lt;/a&gt; library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoma-network/atoma-infer"&gt;&lt;code&gt;atoma-infer&lt;/code&gt;&lt;/a&gt;: A Rust library for fast inference at scale, leveraging FlashAttention2 for efficient attention computation, PagedAttention for efficient KV-cache memory management, and multi-GPU support. It is OpenAI api compatible.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nerdai/llms-from-scratch-rs"&gt;&lt;code&gt;llms-from-scratch-rs&lt;/code&gt;&lt;/a&gt;: A comprehensive Rust translation of the code from Sebastian Raschka's Build an LLM from Scratch book.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have an addition to this list, please submit a pull request.&lt;/p&gt; 
&lt;!-- ANCHOR_END: useful_libraries ---&gt; 
&lt;!-- ANCHOR: features ---&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple syntax, looks and feels like PyTorch. 
  &lt;ul&gt; 
   &lt;li&gt;Model training.&lt;/li&gt; 
   &lt;li&gt;Embed user-defined ops/kernels, such as &lt;a href="https://github.com/huggingface/candle/raw/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152"&gt;flash-attention v2&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Backends. 
  &lt;ul&gt; 
   &lt;li&gt;Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.&lt;/li&gt; 
   &lt;li&gt;CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.&lt;/li&gt; 
   &lt;li&gt;WASM support, run your models in a browser.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Included models. 
  &lt;ul&gt; 
   &lt;li&gt;Language Models. 
    &lt;ul&gt; 
     &lt;li&gt;LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B.&lt;/li&gt; 
     &lt;li&gt;Falcon.&lt;/li&gt; 
     &lt;li&gt;StarCoder, StarCoder2.&lt;/li&gt; 
     &lt;li&gt;Phi 1, 1.5, 2, and 3.&lt;/li&gt; 
     &lt;li&gt;Mamba, Minimal Mamba&lt;/li&gt; 
     &lt;li&gt;Gemma v1 2b and 7b+, v2 2b and 9b.&lt;/li&gt; 
     &lt;li&gt;Mistral 7b v0.1.&lt;/li&gt; 
     &lt;li&gt;Mixtral 8x7b v0.1.&lt;/li&gt; 
     &lt;li&gt;StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B.&lt;/li&gt; 
     &lt;li&gt;Replit-code-v1.5-3B.&lt;/li&gt; 
     &lt;li&gt;Bert.&lt;/li&gt; 
     &lt;li&gt;Yi-6B and Yi-34B.&lt;/li&gt; 
     &lt;li&gt;Qwen1.5, Qwen1.5 MoE.&lt;/li&gt; 
     &lt;li&gt;RWKV v5 and v6.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Quantized LLMs. 
    &lt;ul&gt; 
     &lt;li&gt;Llama 7b, 13b, 70b, as well as the chat and code variants.&lt;/li&gt; 
     &lt;li&gt;Mistral 7b, and 7b instruct.&lt;/li&gt; 
     &lt;li&gt;Mixtral 8x7b.&lt;/li&gt; 
     &lt;li&gt;Zephyr 7b a and b (Mistral-7b based).&lt;/li&gt; 
     &lt;li&gt;OpenChat 3.5 (Mistral-7b based).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Text to text. 
    &lt;ul&gt; 
     &lt;li&gt;T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction).&lt;/li&gt; 
     &lt;li&gt;Marian MT (Machine Translation).&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Text to image. 
    &lt;ul&gt; 
     &lt;li&gt;Stable Diffusion v1.5, v2.1, XL v1.0.&lt;/li&gt; 
     &lt;li&gt;Wurstchen v2.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Image to text. 
    &lt;ul&gt; 
     &lt;li&gt;BLIP.&lt;/li&gt; 
     &lt;li&gt;TrOCR.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Audio. 
    &lt;ul&gt; 
     &lt;li&gt;Whisper, multi-lingual speech-to-text.&lt;/li&gt; 
     &lt;li&gt;EnCodec, audio compression model.&lt;/li&gt; 
     &lt;li&gt;MetaVoice-1B, text-to-speech model.&lt;/li&gt; 
     &lt;li&gt;Parler-TTS, text-to-speech model.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Computer Vision Models. 
    &lt;ul&gt; 
     &lt;li&gt;DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT, ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT.&lt;/li&gt; 
     &lt;li&gt;yolo-v3, yolo-v8.&lt;/li&gt; 
     &lt;li&gt;Segment-Anything Model (SAM).&lt;/li&gt; 
     &lt;li&gt;SegFormer.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;File formats: load models from safetensors, npz, ggml, or PyTorch files.&lt;/li&gt; 
 &lt;li&gt;Serverless (on CPU), small and fast deployments.&lt;/li&gt; 
 &lt;li&gt;Quantization support using the llama.cpp quantized types.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- ANCHOR_END: features ---&gt; 
&lt;h2&gt;How to use&lt;/h2&gt; 
&lt;!-- ANCHOR: cheatsheet ---&gt; 
&lt;p&gt;Cheatsheet:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Using PyTorch&lt;/th&gt; 
   &lt;th&gt;Using Candle&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.Tensor([[1, 2], [3, 4]])&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Tensor::new(&amp;amp;[[1f32, 2.], [3., 4.]], &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creation&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.zeros((2, 2))&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Tensor::zeros((2, 2), DType::F32, &amp;amp;Device::Cpu)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indexing&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor[:, :4]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.i((.., ..4))?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operations&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.view((2, 2))&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.reshape((2, 2))?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operations&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a.matmul(b)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a.matmul(&amp;amp;b)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arithmetic&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;amp;a + &amp;amp;b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Device&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to(device="cuda")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to_device(&amp;amp;Device::new_cuda(0)?)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dtype&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to(dtype=torch.float16)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tensor.to_dtype(&amp;amp;DType::F16)?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Saving&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;torch.save({"A": A}, "model.bin")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;candle::safetensors::save(&amp;amp;HashMap::from([("A", A)]), "model.safetensors")?&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Loading&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;weights = torch.load("model.bin")&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;candle::safetensors::load("model.safetensors", &amp;amp;device)&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- ANCHOR_END: cheatsheet ---&gt; 
&lt;h2&gt;Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-core"&gt;candle-core&lt;/a&gt;: Core ops, devices, and &lt;code&gt;Tensor&lt;/code&gt; struct definition&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-nn/"&gt;candle-nn&lt;/a&gt;: Tools to build real models&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-examples/"&gt;candle-examples&lt;/a&gt;: Examples of using the library in realistic settings&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-kernels/"&gt;candle-kernels&lt;/a&gt;: CUDA custom kernels&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-datasets/"&gt;candle-datasets&lt;/a&gt;: Datasets and data loaders.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-transformers"&gt;candle-transformers&lt;/a&gt;: transformers-related utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-flash-attn"&gt;candle-flash-attn&lt;/a&gt;: Flash attention v2 layer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/candle/main/candle-onnx/"&gt;candle-onnx&lt;/a&gt;: ONNX model evaluation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why should I use Candle?&lt;/h3&gt; 
&lt;!-- ANCHOR: goals ---&gt; 
&lt;p&gt;Candle's core goal is to &lt;em&gt;make serverless inference possible&lt;/em&gt;. Full machine learning frameworks like PyTorch are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight binaries.&lt;/p&gt; 
&lt;p&gt;Secondly, Candle lets you &lt;em&gt;remove Python&lt;/em&gt; from production workloads. Python overhead can seriously hurt performance, and the &lt;a href="https://www.backblaze.com/blog/the-python-gil-past-present-and-future/"&gt;GIL&lt;/a&gt; is a notorious source of headaches.&lt;/p&gt; 
&lt;p&gt;Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like &lt;a href="https://github.com/huggingface/safetensors"&gt;safetensors&lt;/a&gt; and &lt;a href="https://github.com/huggingface/tokenizers"&gt;tokenizers&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ANCHOR_END: goals ---&gt; 
&lt;h3&gt;Other ML frameworks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/coreylowman/dfdx"&gt;dfdx&lt;/a&gt; is a formidable crate, with shapes being included in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat. However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.&lt;/p&gt; &lt;p&gt;We're leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each other.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/burn-rs/burn"&gt;burn&lt;/a&gt; is a general crate that can leverage multiple backends so you can choose the best engine for your workload.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/LaurentMazare/tch-rs.git"&gt;tch-rs&lt;/a&gt; Bindings to the torch library in Rust. Extremely versatile, but they bring in the entire torch library into the runtime. The main contributor of &lt;code&gt;tch-rs&lt;/code&gt; is also involved in the development of &lt;code&gt;candle&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Errors&lt;/h3&gt; 
&lt;h4&gt;Missing symbols when compiling with the mkl feature.&lt;/h4&gt; 
&lt;p&gt;If you get some missing symbols when compiling binaries/tests using the mkl or accelerate features, e.g. for mkl you get:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  = note: /usr/bin/ld: (....o): in function `blas::sgemm':
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_' collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or for accelerate:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Undefined symbols for architecture arm64:
            "_dgemm_", referenced from:
                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...
            "_sgemm_", referenced from:
                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...
          ld: symbol(s) not found for architecture arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is likely due to a missing linker flag that was needed to enable the mkl library. You can try adding the following for mkl at the top of your binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;extern crate intel_mkl_src;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or for accelerate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;extern crate accelerate_src;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Cannot run the LLaMA examples: access to source requires login credentials&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is likely because you're not permissioned for the LLaMA-v2 model. To fix this, you have to register on the huggingface-hub, accept the &lt;a href="https://huggingface.co/meta-llama/Llama-2-7b-hf"&gt;LLaMA-v2 model conditions&lt;/a&gt;, and set up your authentication token. See issue &lt;a href="https://github.com/huggingface/candle/issues/350"&gt;#350&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h4&gt;Missing cute/cutlass headers when compiling flash-attn&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;  In file included from kernels/flash_fwd_launch_template.h:11:0,
                   from kernels/flash_fwd_hdim224_fp16_sm80.cu:5:
  kernels/flash_fwd_kernel.h:8:10: fatal error: cute/algorithm/copy.hpp: No such file or directory
   #include &amp;lt;cute/algorithm/copy.hpp&amp;gt;
            ^~~~~~~~~~~~~~~~~~~~~~~~~
  compilation terminated.
  Error: nvcc error while compiling:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/cutlass"&gt;cutlass&lt;/a&gt; is provided as a git submodule so you may want to run the following command to check it in properly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git submodule update --init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Compiling with flash-attention fails&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‚Äò...‚Äô:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a bug in gcc-11 triggered by the Cuda compiler. To fix this, install a different, supported gcc version - for example gcc-10, and specify the path to the compiler in the NVCC_CCBIN environment variable.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env NVCC_CCBIN=/usr/lib/gcc/x86_64-linux-gnu/10 cargo ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linking error on windows when running rustdoc or mdbook tests&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;Couldn't compile the test.
---- .\candle-book\src\inference\hub.md - Using_the_hub::Using_in_a_real_model_ (line 50) stdout ----
error: linking with `link.exe` failed: exit code: 1181
//very long chain of linking
 = note: LINK : fatal error LNK1181: cannot open input file 'windows.0.48.5.lib'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you link all native libraries that might be located outside a project target, e.g., to run mdbook tests, you should run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mdbook test candle-book -L .\target\debug\deps\ `
-L native=$env:USERPROFILE\.cargo\registry\src\index.crates.io-6f17d22bba15001f\windows_x86_64_msvc-0.42.2\lib `
-L native=$env:USERPROFILE\.cargo\registry\src\index.crates.io-6f17d22bba15001f\windows_x86_64_msvc-0.48.5\lib
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extremely slow model load time with WSL&lt;/h4&gt; 
&lt;p&gt;This may be caused by the models being loaded from &lt;code&gt;/mnt/c&lt;/code&gt;, more details on &lt;a href="https://stackoverflow.com/questions/68972448/why-is-wsl-extremely-slow-when-compared-with-native-windows-npm-yarn-processing"&gt;stackoverflow&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Tracking down errors&lt;/h4&gt; 
&lt;p&gt;You can set &lt;code&gt;RUST_BACKTRACE=1&lt;/code&gt; to be provided with backtraces when a candle error is generated.&lt;/p&gt; 
&lt;h4&gt;CudaRC error&lt;/h4&gt; 
&lt;p&gt;If you encounter an error like this one &lt;code&gt;called &lt;/code&gt;Result::unwrap()&lt;code&gt;on an&lt;/code&gt;Err&lt;code&gt; value: LoadLibraryExW { source: Os { code: 126, kind: Uncategorized, message: "The specified module could not be found." } }&lt;/code&gt; on windows. To fix copy and rename these 3 files (make sure they are in path). The paths depend on your cuda version. &lt;code&gt;c:\Windows\System32\nvcuda.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;cuda.dll&lt;/code&gt; &lt;code&gt;c:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin\cublas64_12.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;cublas.dll&lt;/code&gt; &lt;code&gt;c:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin\curand64_10.dll&lt;/code&gt; -&amp;gt; &lt;code&gt;curand.dll&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>0xPlaygrounds/rig</title>
      <link>https://github.com/0xPlaygrounds/rig</link>
      <description>&lt;p&gt;‚öôÔ∏èü¶Ä Build modular and scalable LLM Applications in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="img/rig-playgrounds-dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="img/rig-playgrounds-light.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/rig-playgrounds-light.svg?sanitize=true" style="width: 40%; height: 40%;" alt="Rig logo" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; &lt;a href="https://docs.rig.rs"&gt;&lt;img src="https://img.shields.io/badge/üìñ docs-rig.rs-dca282.svg" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://docs.rs/rig-core/latest/rig/"&gt;&lt;img src="https://img.shields.io/badge/docs-API Reference-dca282.svg" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://crates.io/crates/rig-core"&gt;&lt;img src="https://img.shields.io/crates/v/rig-core.svg?color=dca282" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://crates.io/crates/rig-core"&gt;&lt;img src="https://img.shields.io/crates/d/rig-core.svg?color=dca282" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://discord.gg/playgrounds"&gt;&lt;img src="https://img.shields.io/discord/511303648119226382?color=%236d82cc&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/0xPlaygrounds/rig"&gt;&lt;img src="https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social" alt="stars - rig" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/ryzomeai"&gt;&lt;img src="https://img.shields.io/twitter/follow/ryzomeai" /&gt;&lt;/a&gt; &amp;nbsp; &lt;br /&gt; &lt;/p&gt; &amp;nbsp; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://docs.rig.rs"&gt;üìë Docs&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://rig.rs"&gt;üåê Website&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://github.com/0xPlaygrounds/rig/issues/new"&gt;ü§ù Contribute&lt;/a&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;a href="https://docs.rig.rs/guides"&gt;‚úçüèΩ Blogs&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;‚ú® If you would like to help spread the word about Rig, please consider starring the repo!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Here be dragons! As we plan to ship a torrent of features in the following months, future updates &lt;strong&gt;will&lt;/strong&gt; contain &lt;strong&gt;breaking changes&lt;/strong&gt;. With Rig evolving, we'll annotate changes and highlight migration paths as we encounter them.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#what-is-rig"&gt;What is Rig?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#high-level-features"&gt;High-level features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#who-is-using-rig-in-production"&gt;Who's using Rig in production?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#get-started"&gt;Get Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#simple-example"&gt;Simple example&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/#integrations"&gt;Integrations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Rig?&lt;/h2&gt; 
&lt;p&gt;Rig is a Rust library for building scalable, modular, and ergonomic &lt;strong&gt;LLM-powered&lt;/strong&gt; applications.&lt;/p&gt; 
&lt;p&gt;More information about this crate can be found in the &lt;a href="https://docs.rig.rs"&gt;official&lt;/a&gt; &amp;amp; &lt;a href="https://docs.rs/rig-core/latest/rig/"&gt;crate&lt;/a&gt; (API Reference) documentations.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Agentic workflows that can handle multi-turn streaming and prompting&lt;/li&gt; 
 &lt;li&gt;Full &lt;a href="https://opentelemetry.io/docs/specs/semconv/gen-ai/"&gt;GenAI Semantic Convention&lt;/a&gt; compatibility&lt;/li&gt; 
 &lt;li&gt;20+ model providers, all under one singular unified interface&lt;/li&gt; 
 &lt;li&gt;10+ vector store integrations, all under one singular unified interface&lt;/li&gt; 
 &lt;li&gt;Full support for LLM completion and embedding workflows&lt;/li&gt; 
 &lt;li&gt;Support for transcription, audio generation and image generation model capabilities&lt;/li&gt; 
 &lt;li&gt;Integrate LLMs in your app with minimal boilerplate&lt;/li&gt; 
 &lt;li&gt;Full WASM compatibility (core library only)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Who is using Rig in production?&lt;/h2&gt; 
&lt;p&gt;Below is a non-exhaustive list of companies and people who are using Rig in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.stjude.org/"&gt;St Jude&lt;/a&gt; - Using Rig for a chatbot utility as part of &lt;a href="https://github.com/stjude/proteinpaint"&gt;&lt;code&gt;proteinpaint&lt;/code&gt;&lt;/a&gt;, a genomics visualisation tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.coralprotocol.org/"&gt;Coral Protocol&lt;/a&gt; - Using Rig extensively, both internally as well as part of the &lt;a href="https://github.com/Coral-Protocol/coral-rs"&gt;Coral Rust SDK.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vtcode"&gt;VT Code&lt;/a&gt; - VT Code is a Rust-based terminal coding agent with semantic code intelligence via Tree-sitter and ast-grep. VT Code uses &lt;code&gt;rig&lt;/code&gt; for simplifying LLM calls and implement model picker.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dria.co/"&gt;Dria&lt;/a&gt; - a decentralised AI network. Currently using Rig as part of their &lt;a href="https://github.com/firstbatchxyz/dkn-compute-node"&gt;compute node.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nethermind.io/"&gt;Nethermind&lt;/a&gt; - Using Rig as part of their &lt;a href="https://github.com/NethermindEth/nine"&gt;Neural Interconnected Nodes Engine&lt;/a&gt; framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/piotrostr/listen"&gt;Listen&lt;/a&gt; - A framework aiming to become the go-to framework for AI portfolio management agents. Powers &lt;a href="https://app.listen-rs.com/"&gt;the Listen app.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Are you also using Rig in production? &lt;a href="https://www.github.com/0xPlaygrounds/rig/issues"&gt;Open an issue&lt;/a&gt; to have your name added!&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo add rig-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Simple example:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use rig::{completion::Prompt, providers::openai};

#[tokio::main]
async fn main() {
    // Create OpenAI client and model
    // This requires the `OPENAI_API_KEY` environment variable to be set.
    let openai_client = openai::Client::from_env();

    let gpt4 = openai_client.agent("gpt-4").build();

    // Prompt the model and print its response
    let response = gpt4
        .prompt("Who are you?")
        .await
        .expect("Failed to prompt GPT-4");

    println!("GPT-4: {response}");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note using &lt;code&gt;#[tokio::main]&lt;/code&gt; requires you enable tokio's &lt;code&gt;macros&lt;/code&gt; and &lt;code&gt;rt-multi-thread&lt;/code&gt; features or just &lt;code&gt;full&lt;/code&gt; to enable all features (&lt;code&gt;cargo add tokio --features macros,rt-multi-thread&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;You can find more examples each crate's &lt;code&gt;examples&lt;/code&gt; (ie. &lt;a href="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/rig-core/examples"&gt;&lt;code&gt;rig-core/examples&lt;/code&gt;&lt;/a&gt;) directory. More detailed use cases walkthroughs are regularly published on our &lt;a href="https://dev.to/0thtachi"&gt;Dev.to Blog&lt;/a&gt; and added to Rig's official documentation &lt;a href="http://docs.rig.rs"&gt;(docs.rig.rs)&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Supported Integrations&lt;/h2&gt; 
&lt;p&gt;Vector stores are available as separate companion-crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MongoDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb"&gt;&lt;code&gt;rig-mongodb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LanceDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb"&gt;&lt;code&gt;rig-lancedb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Neo4j: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j"&gt;&lt;code&gt;rig-neo4j&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qdrant: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant"&gt;&lt;code&gt;rig-qdrant&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SQLite: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-sqlite"&gt;&lt;code&gt;rig-sqlite&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SurrealDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-surrealdb"&gt;&lt;code&gt;rig-surrealdb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Milvus: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-milvus"&gt;&lt;code&gt;rig-milvus&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ScyllaDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-scylladb"&gt;&lt;code&gt;rig-scylladb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AWS S3Vectors: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-s3vectors"&gt;&lt;code&gt;rig-s3vectors&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HelixDB: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-helixdb"&gt;&lt;code&gt;rig-helixdb&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following providers are available as separate companion-crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AWS Bedrock: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-bedrock"&gt;&lt;code&gt;rig-bedrock&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fastembed: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-fastembed"&gt;&lt;code&gt;rig-fastembed&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Eternal AI: &lt;a href="https://github.com/0xPlaygrounds/rig/tree/main/rig-eternalai"&gt;&lt;code&gt;rig-eternalai&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We also have some other associated crates that have additional functionality you may find helpful when using Rig:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;rig-onchain-kit&lt;/code&gt; - the &lt;a href="https://github.com/0xPlaygrounds/rig-onchain-kit"&gt;Rig Onchain Kit.&lt;/a&gt; Intended to make interactions between Solana/EVM and Rig much easier to implement.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;br /&gt; &lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/0xPlaygrounds/rig/main/img/built-by-playgrounds.svg?sanitize=true" alt="Build by Playgrounds" width="30%" /&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nautechsystems/nautilus_trader</title>
      <link>https://github.com/nautechsystems/nautilus_trader</link>
      <description>&lt;p&gt;A high-performance algorithmic trading platform and event-driven backtester&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png" width="500" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codecov.io/gh/nautechsystems/nautilus_trader"&gt;&lt;img src="https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/nautechsystems/nautilus_trader"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="codspeed" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/nautilus_trader" alt="pythons" /&gt; &lt;img src="https://img.shields.io/pypi/v/nautilus_trader" alt="pypi-version" /&gt; &lt;img src="https://img.shields.io/pypi/format/nautilus_trader?color=blue" alt="pypi-format" /&gt; &lt;a href="https://pepy.tech/project/nautilus-trader"&gt;&lt;img src="https://pepy.tech/badge/nautilus-trader" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NautilusTrader"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Branch&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Rust&lt;/th&gt; 
   &lt;th align="left"&gt;Python&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://nautilustrader.io/docs/"&gt;https://nautilustrader.io/docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: &lt;a href="mailto:support@nautilustrader.io"&gt;support@nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.&lt;/p&gt; 
&lt;p&gt;The platform is &lt;em&gt;AI-first&lt;/em&gt;, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.&lt;/p&gt; 
&lt;p&gt;NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.&lt;/p&gt; 
&lt;p&gt;The platform is also universal, and asset-class-agnostic ‚Äî with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto, DeFi, and Betting ‚Äî enabling seamless operations across multiple venues simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png" alt="nautilus-trader" title="nautilus-trader" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Core is written in Rust with asynchronous networking using &lt;a href="https://crates.io/crates/tokio"&gt;tokio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Modular adapters mean any REST API or WebSocket feed can be integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Time in force &lt;code&gt;IOC&lt;/code&gt;, &lt;code&gt;FOK&lt;/code&gt;, &lt;code&gt;GTC&lt;/code&gt;, &lt;code&gt;GTD&lt;/code&gt;, &lt;code&gt;DAY&lt;/code&gt;, &lt;code&gt;AT_THE_OPEN&lt;/code&gt;, &lt;code&gt;AT_THE_CLOSE&lt;/code&gt;, advanced order types and conditional triggers. Execution instructions &lt;code&gt;post-only&lt;/code&gt;, &lt;code&gt;reduce-only&lt;/code&gt;, and icebergs. Contingency orders including &lt;code&gt;OCO&lt;/code&gt;, &lt;code&gt;OUO&lt;/code&gt;, &lt;code&gt;OTO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Add user-defined custom components, or assemble entire systems from scratch leveraging the &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; and &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting&lt;/strong&gt;: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live&lt;/strong&gt;: Use identical strategy implementations between backtesting and live deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-venue&lt;/strong&gt;: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Training&lt;/strong&gt;: Backtest engine fast enough to be used to train AI trading agents (RL/ES).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png" alt="Alt text" title="nautilus" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;nautilus - from ancient Greek 'sailor' and naus 'ship'.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why NautilusTrader?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant event-driven Python&lt;/strong&gt;: Native binary core components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parity between backtesting and live trading&lt;/strong&gt;: Identical strategy code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduced operational risk&lt;/strong&gt;: Enhanced risk management functionality, logical accuracy, and type safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly extendable&lt;/strong&gt;: Message bus, custom components and actors, custom data, custom adapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.&lt;/p&gt; 
&lt;p&gt;One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; or &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt;. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.&lt;/p&gt; 
&lt;h2&gt;Why Python?&lt;/h2&gt; 
&lt;p&gt;Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the &lt;em&gt;de facto lingua franca&lt;/em&gt; of data science, machine learning, and artificial intelligence.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is "blazingly fast" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.&lt;/p&gt; 
&lt;p&gt;Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî eliminating many classes of bugs at compile-time.&lt;/p&gt; 
&lt;p&gt;The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and &lt;a href="https://pyo3.rs"&gt;PyO3&lt;/a&gt;‚Äîno Rust toolchain is required at install time.&lt;/p&gt; 
&lt;p&gt;This project makes the &lt;a href="https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html"&gt;Soundness Pledge&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúThe intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is modularly designed to work with &lt;em&gt;adapters&lt;/em&gt;, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.&lt;/p&gt; 
&lt;p&gt;The following integrations are currently supported; see &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;docs/integrations/&lt;/a&gt; for details:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;ID&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://betfair.com"&gt;Betfair&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BETFAIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sports Betting Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.com"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bitmex.com"&gt;BitMEX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BITMEX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bitmex.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bybit.com"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BYBIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinbase.com/en/international-exchange"&gt;Coinbase International&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;COINBASE_INTX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://databento.com"&gt;Databento&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABENTO&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DYDX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hyperliquid.xyz"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HYPERLIQUID&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/building-orange" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.interactivebrokers.com"&gt;Interactive Brokers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;INTERACTIVE_BROKERS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brokerage (multi-venue)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://okx.com"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OKX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://polymarket.com"&gt;Polymarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;POLYMARKET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prediction Market (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tardis.dev"&gt;Tardis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TARDIS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt;: The default client ID for the integrations adapter clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: The type of integration (often the venue type).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;building&lt;/code&gt;: Under construction and likely not in a usable state.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;beta&lt;/code&gt;: Completed to a minimally working state and in a beta testing phase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt;: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;Integrations&lt;/a&gt; documentation for further details.&lt;/p&gt; 
&lt;h2&gt;Versioning and releases&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;NautilusTrader is still under active development&lt;/strong&gt;. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a &lt;strong&gt;best-effort basis&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We aim to follow a &lt;strong&gt;bi-weekly release schedule&lt;/strong&gt;, though experimental or larger features may cause delays.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;p&gt;We aim to maintain a stable, passing build across all branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;master&lt;/code&gt;: Reflects the source code for the latest released version; recommended for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt;: Daily snapshots of the &lt;code&gt;develop&lt;/code&gt; branch for early testing; merged at &lt;strong&gt;14:00 UTC&lt;/strong&gt; and as required.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt;: Active development branch for contributors and feature work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md"&gt;roadmap&lt;/a&gt; aims to achieve a &lt;strong&gt;stable API for version 2.x&lt;/strong&gt; (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Precision mode&lt;/h2&gt; 
&lt;p&gt;NautilusTrader supports two precision modes for its core value types (&lt;code&gt;Price&lt;/code&gt;, &lt;code&gt;Quantity&lt;/code&gt;, &lt;code&gt;Money&lt;/code&gt;), which differ in their internal bit-width and maximum decimal precision.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-precision&lt;/strong&gt;: 128-bit integers with up to 16 decimals of precision, and a larger value range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard-precision&lt;/strong&gt;: 64-bit integers with up to 9 decimals of precision, and a smaller value range.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;By default, the official Python wheels ship in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support. For the Rust crates, the default is standard-precision unless you explicitly enable the &lt;code&gt;high-precision&lt;/code&gt; feature flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust feature flag&lt;/strong&gt;: To enable high-precision mode in Rust, add the &lt;code&gt;high-precision&lt;/code&gt; feature to your Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
nautilus_model = { version = "*", features = ["high-precision"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using the latest supported version of Python and installing &lt;a href="https://pypi.org/project/nautilus_trader/"&gt;nautilus_trader&lt;/a&gt; inside a virtual environment to isolate dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are two supported ways to install&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pre-built binary wheel from PyPI &lt;em&gt;or&lt;/em&gt; the Nautech Systems package index.&lt;/li&gt; 
 &lt;li&gt;Build from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We highly recommend installing using the &lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt; package manager with a "vanilla" CPython.&lt;/p&gt; 
 &lt;p&gt;Conda and other Python distributions &lt;em&gt;may&lt;/em&gt; work but aren‚Äôt officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;p&gt;To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From the Nautech Systems package index&lt;/h3&gt; 
&lt;p&gt;The Nautech Systems package index (&lt;code&gt;packages.nautechsystems.io&lt;/code&gt;) complies with &lt;a href="https://peps.python.org/pep-0503/"&gt;PEP-503&lt;/a&gt; and hosts both stable and development binary wheels for &lt;code&gt;nautilus_trader&lt;/code&gt;. This enables users to install either the latest stable release or pre-release versions for testing.&lt;/p&gt; 
&lt;h4&gt;Stable wheels&lt;/h4&gt; 
&lt;p&gt;Stable wheels correspond to official releases of &lt;code&gt;nautilus_trader&lt;/code&gt; on PyPI, and use standard versioning.&lt;/p&gt; 
&lt;p&gt;To install the latest stable release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Use &lt;code&gt;--extra-index-url&lt;/code&gt; instead of &lt;code&gt;--index-url&lt;/code&gt; if you want pip to fall back to PyPI automatically:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Development wheels&lt;/h4&gt; 
&lt;p&gt;Development wheels are published from both the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; branches, allowing users to test features and fixes ahead of stable releases.&lt;/p&gt; 
&lt;p&gt;This process also helps preserve compute resources and provides easy access to the exact binaries tested in CI pipelines, while adhering to &lt;a href="https://peps.python.org/pep-0440/"&gt;PEP-440&lt;/a&gt; versioning standards:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; wheels use the version format &lt;code&gt;dev{date}+{build_number}&lt;/code&gt; (e.g., &lt;code&gt;1.208.0.dev20241212+7001&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; wheels use the version format &lt;code&gt;a{date}&lt;/code&gt; (alpha) (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Nightly&lt;/th&gt; 
   &lt;th align="left"&gt;Develop&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Development wheels from the &lt;code&gt;develop&lt;/code&gt; branch publish for every supported platform except Linux ARM64. Skipping that target keeps CI feedback fast while avoiding unnecessary build resource usage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;We do not recommend using development wheels in production environments, such as live trading controlling real capital.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation commands&lt;/h4&gt; 
&lt;p&gt;By default, pip will install the latest stable release. Adding the &lt;code&gt;--pre&lt;/code&gt; flag ensures that pre-release versions, including development wheels, are considered.&lt;/p&gt; 
&lt;p&gt;To install the latest available pre-release (including development wheels):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific development wheel (e.g., &lt;code&gt;1.221.0a20251026&lt;/code&gt; for October 26, 2025):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nautilus_trader==1.221.0a20251026 --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available versions&lt;/h4&gt; 
&lt;p&gt;You can view all available versions of &lt;code&gt;nautilus_trader&lt;/code&gt; on the &lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;package index&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To programmatically fetch and list available versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&amp;lt;=&amp;lt;a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;On Linux, confirm your glibc version with &lt;code&gt;ldd --version&lt;/code&gt; and ensure it reports &lt;strong&gt;2.35&lt;/strong&gt; or newer before installing binary wheels.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Branch updates&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): Build and publish continuously with every merged commit.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): Build and publish daily when we automatically merge the &lt;code&gt;develop&lt;/code&gt; branch at &lt;strong&gt;14:00 UTC&lt;/strong&gt; (if there are changes).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Retention policies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): We retain only the most recent wheel build.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): We retain only the 30 most recent wheel builds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Verifying build provenance&lt;/h4&gt; 
&lt;p&gt;All release artifacts (wheels and source distributions) published to PyPI, GitHub Releases, and the Nautech Systems package index include cryptographic attestations that prove their authenticity and build provenance.&lt;/p&gt; 
&lt;p&gt;These attestations are generated automatically during the CI/CD pipeline using &lt;a href="https://slsa.dev/"&gt;SLSA&lt;/a&gt; build provenance, and can be verified to ensure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The artifact was built by the official NautilusTrader GitHub Actions workflow.&lt;/li&gt; 
 &lt;li&gt;The artifact corresponds to a specific commit SHA in the repository.&lt;/li&gt; 
 &lt;li&gt;The artifact hasn't been tampered with since it was built.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To verify a wheel file using the GitHub CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gh attestation verify nautilus_trader-1.220.0-*.whl --owner nautechsystems
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This provides supply chain security by allowing you to cryptographically verify that the installed package came from the official NautilusTrader build process.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Attestation verification requires the &lt;a href="https://cli.github.com/"&gt;GitHub CLI&lt;/a&gt; (&lt;code&gt;gh&lt;/code&gt;) to be installed. Development wheels from &lt;code&gt;develop&lt;/code&gt; and &lt;code&gt;nightly&lt;/code&gt; branches are also attested and can be verified the same way.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;p&gt;It's possible to install from source using pip if you first install the build dependencies as specified in the &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; (the Rust toolchain installer):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl https://sh.rustup.rs -sSf | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Download and install &lt;a href="https://win.rustup.rs/x86_64"&gt;&lt;code&gt;rustup-init.exe&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Install "Desktop development with C++" using &lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Build Tools for Visual Studio 2022&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;rustc --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;cargo&lt;/code&gt; in the current shell:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Start a new PowerShell&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://clang.llvm.org/"&gt;clang&lt;/a&gt; (a C language frontend for LLVM):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install clang
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p&gt;Add Clang to your &lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Build Tools for Visual Studio 2022&lt;/a&gt;:&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (latest) = checked | Modify&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;clang&lt;/code&gt; in the current shell:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;[System.Environment]::SetEnvironmentVariable('path', "C:\Program Files\Microsoft Visual Studio\2022\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;clang --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install uv (see the &lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv installation guide&lt;/a&gt; for more details):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows (PowerShell):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://astral.sh/uv/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source with &lt;code&gt;git&lt;/code&gt;, and install from the project's root directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;--depth 1&lt;/code&gt; flag fetches just the latest commit for a faster, lightweight clone.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt; &lt;p&gt;Set environment variables for PyO3 compilation (Linux and macOS only):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Adjust the Python version and architecture in the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; to match your system. Use &lt;code&gt;uv python list&lt;/code&gt; to find the exact path for your Python installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for other options and further details.&lt;/p&gt; 
&lt;h2&gt;Redis&lt;/h2&gt; 
&lt;p&gt;Using &lt;a href="https://redis.io"&gt;Redis&lt;/a&gt; with NautilusTrader is &lt;strong&gt;optional&lt;/strong&gt; and only required if configured as the backend for a &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; database or &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;. See the &lt;strong&gt;Redis&lt;/strong&gt; section of the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation#redis"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Makefile&lt;/h2&gt; 
&lt;p&gt;A &lt;code&gt;Makefile&lt;/code&gt; is provided to automate most installation and build tasks for development. Some of the targets include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make install&lt;/code&gt;: Installs in &lt;code&gt;release&lt;/code&gt; build mode with all dependency groups and extras.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-debug&lt;/code&gt;: Same as &lt;code&gt;make install&lt;/code&gt; but with &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-just-deps&lt;/code&gt;: Installs just the &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt; dependencies (does not install package).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;: Runs the build script in &lt;code&gt;release&lt;/code&gt; build mode (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-debug&lt;/code&gt;: Runs the build script in &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;release&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel-debug&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;debug&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make cargo-test&lt;/code&gt;: Runs all Rust crate tests using &lt;code&gt;cargo-nextest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;: Deletes all build results, such as &lt;code&gt;.so&lt;/code&gt; or &lt;code&gt;.dll&lt;/code&gt; files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt;: &lt;strong&gt;CAUTION&lt;/strong&gt; Removes all artifacts not in the git index from the repository. This includes source files which have not been &lt;code&gt;git add&lt;/code&gt;ed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make docs&lt;/code&gt;: Builds the documentation HTML using Sphinx.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pre-commit&lt;/code&gt;: Runs the pre-commit checks over all files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make ruff&lt;/code&gt;: Runs ruff over all files using the &lt;code&gt;pyproject.toml&lt;/code&gt; config (with autofix).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pytest&lt;/code&gt;: Runs all tests with &lt;code&gt;pytest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test-performance&lt;/code&gt;: Runs performance tests with &lt;a href="https://codspeed.io"&gt;codspeed&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make help&lt;/code&gt; for documentation on all available make targets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md"&gt;crates/infrastructure/TESTS.md&lt;/a&gt; file for running the infrastructure integration tests.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py"&gt;indicator&lt;/a&gt; example written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/"&gt;indicator&lt;/a&gt; implementations written in Cython.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/"&gt;strategy&lt;/a&gt; examples written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/"&gt;backtest&lt;/a&gt; examples using a &lt;code&gt;BacktestEngine&lt;/code&gt; directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;Docker containers are built using the base image &lt;code&gt;python:3.12-slim&lt;/code&gt; with the following variant tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:latest&lt;/code&gt; has the latest release version installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:latest&lt;/code&gt; has the latest release version installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can pull the container images as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/&amp;lt;image_variant_tag&amp;gt; --platform linux/amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can launch the backtest example container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64
docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open your browser at the following address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;http://127.0.0.1:8888/lab
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the &lt;code&gt;log_level&lt;/code&gt; to &lt;code&gt;ERROR&lt;/code&gt; in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jupyterlab/jupyterlab/issues/12845"&gt;https://github.com/jupyterlab/jupyterlab/issues/12845&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/deshaw/jupyterlab-limit-output"&gt;https://github.com/deshaw/jupyterlab-limit-output&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the &lt;a href="https://nautilustrader.io/docs/latest/developer_guide/"&gt;Developer Guide&lt;/a&gt; for helpful information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make build-debug&lt;/code&gt; to compile after changes to Rust or Cython code for the most efficient development workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Testing with Rust&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://nexte.st"&gt;cargo-nextest&lt;/a&gt; is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.&lt;/p&gt; 
&lt;p&gt;You can install cargo-nextest by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-nextest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run Rust tests with &lt;code&gt;make cargo-test&lt;/code&gt;, which uses &lt;strong&gt;cargo-nextest&lt;/strong&gt; with an efficient profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an &lt;a href="https://github.com/nautechsystems/nautilus_trader/issues"&gt;issue&lt;/a&gt; on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.&lt;/p&gt; 
&lt;p&gt;Before getting started, be sure to review the &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope"&gt;open-source scope&lt;/a&gt; outlined in the project‚Äôs roadmap to understand what‚Äôs in and out of scope.&lt;/p&gt; 
&lt;p&gt;Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Pull requests should target the &lt;code&gt;develop&lt;/code&gt; branch (the default branch). This is where new features and improvements are integrated before release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community of users and contributors on &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord&lt;/a&gt; to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.&lt;/p&gt; 
 &lt;p&gt;All official updates and communications from NautilusTrader will be shared exclusively through &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;, our &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord server&lt;/a&gt;, or our X (Twitter) account: &lt;a href="https://x.com/NautilusTrader"&gt;@NautilusTrader&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;If you encounter any suspicious activity, please report it to the appropriate platform and contact us at &lt;a href="mailto:info@nautechsystems.io"&gt;info@nautechsystems.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code for NautilusTrader is available on GitHub under the &lt;a href="https://www.gnu.org/licenses/lgpl-3.0.en.html"&gt;GNU Lesser General Public License v3.0&lt;/a&gt;. Contributions to the project are welcome and require the completion of a standard &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md"&gt;Contributor License Agreement (CLA)&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;NautilusTrader‚Ñ¢ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;¬© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png" alt="nautechsystems" title="nautechsystems" /&gt; &lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png" width="128" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uutils/coreutils</title>
      <link>https://github.com/uutils/coreutils</link>
      <description>&lt;p&gt;Cross-platform Rust rewrite of the GNU coreutils&lt;/p&gt;&lt;hr&gt;&lt;div class="oranda-hide"&gt; 
 &lt;div align="center"&gt; 
  &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/logo.svg?sanitize=true" alt="uutils logo" /&gt;&lt;/p&gt; 
  &lt;h1&gt;uutils coreutils&lt;/h1&gt; 
  &lt;p&gt;&lt;a href="https://crates.io/crates/coreutils"&gt;&lt;img src="https://img.shields.io/crates/v/coreutils.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/wQVJbvJ"&gt;&lt;img src="https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;amp;longCache=true&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uutils/coreutils/raw/main/LICENSE"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/repo/github/uutils/coreutils"&gt;&lt;img src="https://deps.rs/repo/github/uutils/coreutils/status.svg?sanitize=true" alt="dependency status" /&gt;&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;a href="https://codecov.io/gh/uutils/coreutils"&gt;&lt;img src="https://codecov.io/gh/uutils/coreutils/branch/main/graph/badge.svg?sanitize=true" alt="CodeCov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/MSRV-1.85.0-brightgreen" alt="MSRV" /&gt; &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;&lt;img src="https://hosted.weblate.org/widget/rust-coreutils/svg-badge.svg?sanitize=true" alt="Weblate" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p&gt;uutils coreutils is a cross-platform reimplementation of the GNU coreutils in &lt;a href="http://www.rust-lang.org"&gt;Rust&lt;/a&gt;. While all programs have been implemented, some options might be missing or different behavior might be experienced.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;p&gt;To install it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install coreutils
~/.cargo/bin/coreutils
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;!-- markdownlint-disable-next-line MD026 --&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;uutils coreutils aims to be a drop-in replacement for the GNU utils. Differences with GNU are treated as bugs.&lt;/p&gt; 
&lt;p&gt;Our key objectives include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Matching GNU's output (stdout and error code) exactly&lt;/li&gt; 
 &lt;li&gt;Better error messages&lt;/li&gt; 
 &lt;li&gt;Providing comprehensive internationalization support (UTF-8)&lt;/li&gt; 
 &lt;li&gt;Improved performances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/extensions.md"&gt;Extensions&lt;/a&gt; when relevant (example: --progress)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uutils aims to work on as many platforms as possible, to be able to use the same utils on Linux, macOS, Windows and other platforms. This ensures, for example, that scripts can be easily transferred between platforms.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;h2&gt;Documentation&lt;/h2&gt; 
 &lt;p&gt;uutils has both user and developer documentation available:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://uutils.github.io/coreutils/docs/"&gt;User Manual&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.rs/crate/coreutils/"&gt;Developer Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Both can also be generated locally, the instructions for that can be found in the &lt;a href="https://github.com/uutils/uutils.github.io"&gt;coreutils docs&lt;/a&gt; repository.&lt;/p&gt; 
 &lt;p&gt;Use &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;weblate/rust-coreutils&lt;/a&gt; to translate the Rust coreutils into your language.&lt;/p&gt; 
 &lt;!-- ANCHOR: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;Requirements&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Rust (&lt;code&gt;cargo&lt;/code&gt;, &lt;code&gt;rustc&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;GNU Make (optional)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Rust Version&lt;/h3&gt; 
 &lt;p&gt;uutils follows Rust's release channels and is tested against stable, beta and nightly. The current Minimum Supported Rust Version (MSRV) is &lt;code&gt;1.85.0&lt;/code&gt;.&lt;/p&gt; 
 &lt;h2&gt;Building&lt;/h2&gt; 
 &lt;p&gt;There are currently two methods to build the uutils binaries: either Cargo or GNU Make.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Building the full package, including all documentation, requires both Cargo and GNU Make on a Unix platform.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;For either method, we first need to fetch the repository:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/uutils/coreutils
cd coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Cargo&lt;/h3&gt; 
 &lt;p&gt;Building uutils using Cargo is easy because the process is the same as for every other Rust program:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command builds the most portable common core set of uutils into a multicall (BusyBox-type) binary, named 'coreutils', on most Rust-supported platforms.&lt;/p&gt; 
 &lt;p&gt;Additional platform-specific uutils are often available. Building these expanded sets of uutils for a platform (on that platform) is as simple as specifying it as a feature:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release --features macos
# or ...
cargo build --release --features windows
# or ...
cargo build --release --features unix
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build SELinux-specific features, including &lt;code&gt;chcon&lt;/code&gt; and &lt;code&gt;runcon&lt;/code&gt;, ensure that &lt;code&gt;libselinux&lt;/code&gt; and &lt;code&gt;libclang&lt;/code&gt; are installed on your system. Then, run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;cargo build --release --features unix,feat_selinux
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you don't want to build every utility available on your platform into the final binary, you can also specify which ones you want to build manually. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --features "base32 cat echo rm" --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you want to build the utilities as individual binaries, that is also possible:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release --bins --workspace --exclude coreutils --exclude uu_runcon --exclude uu_chcon
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Each utility is contained in its own package within the main repository, named "uu_UTILNAME". To build selected individual utilities, use the &lt;code&gt;--package&lt;/code&gt; [aka &lt;code&gt;-p&lt;/code&gt;] option. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;GNU Make&lt;/h3&gt; 
 &lt;p&gt;Building using &lt;code&gt;make&lt;/code&gt; is a simple process as well.&lt;/p&gt; 
 &lt;p&gt;To simply build all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;In release mode:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROFILE=release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Installation&lt;/h2&gt; 
 &lt;h3&gt;Install with Cargo&lt;/h3&gt; 
 &lt;p&gt;Likewise, installing can simply be done using:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --path . --locked
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command will install uutils into Cargo's &lt;em&gt;bin&lt;/em&gt; folder (&lt;em&gt;e.g.&lt;/em&gt; &lt;code&gt;$HOME/.cargo/bin&lt;/code&gt;).&lt;/p&gt; 
 &lt;p&gt;This does not install files necessary for shell completion or manpages. For manpages or shell completion to work, use &lt;code&gt;GNU Make&lt;/code&gt; or see &lt;code&gt;Manually install shell completions&lt;/code&gt;/&lt;code&gt;Manually install manpages&lt;/code&gt;.&lt;/p&gt; 
 &lt;h3&gt;Install with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To install all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install using &lt;code&gt;sudo&lt;/code&gt; switch &lt;code&gt;-E&lt;/code&gt; must be used:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;sudo -E make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install every program with a prefix (e.g. uu-echo uu-cat):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Set install parent directory (default value is /usr/local):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Installing with &lt;code&gt;make&lt;/code&gt; installs shell completions for all installed utilities for &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt;. Completions for &lt;code&gt;elvish&lt;/code&gt; and &lt;code&gt;powershell&lt;/code&gt; can also be generated; See &lt;code&gt;Manually install shell completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;To skip installation of completions and manpages:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make COMPLETIONS=n MANPAGES=n install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install shell completions&lt;/h3&gt; 
 &lt;p&gt;The &lt;code&gt;uudoc&lt;/code&gt; binary generates completions for the &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;elvish&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt;, &lt;code&gt;powershell&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt; shells to stdout.&lt;/p&gt; 
 &lt;p&gt;Install &lt;code&gt;uudoc&lt;/code&gt; by&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --bin uudoc --features uudoc --path .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then use the installed binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;uudoc completion &amp;lt;utility&amp;gt; &amp;lt;shell&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install completions for &lt;code&gt;ls&lt;/code&gt; on &lt;code&gt;bash&lt;/code&gt; to &lt;code&gt;/usr/local/share/bash-completion/completions/ls&lt;/code&gt;, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;uudoc completion ls bash &amp;gt; /usr/local/share/bash-completion/completions/ls.bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Completion for prefixed &lt;code&gt;cp&lt;/code&gt; with &lt;code&gt;uu-&lt;/code&gt; on &lt;code&gt;zsh&lt;/code&gt; is generated by&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;env PROG_PREFIX=uu- uudoc completion cp zsh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install manpages&lt;/h3&gt; 
 &lt;p&gt;To generate manpages, the syntax is:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uudoc manpage &amp;lt;utility&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install the manpage for &lt;code&gt;ls&lt;/code&gt; to &lt;code&gt;/usr/local/share/man/man1/ls.1&lt;/code&gt; run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uudoc manpage ls &amp;gt; /usr/local/share/man/man1/ls.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Un-installation&lt;/h2&gt; 
 &lt;p&gt;Un-installation differs depending on how you have installed uutils. If you used Cargo to install, use Cargo to uninstall. If you used GNU Make to install, use Make to uninstall.&lt;/p&gt; 
 &lt;h3&gt;Uninstall with Cargo&lt;/h3&gt; 
 &lt;p&gt;To uninstall uutils:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo uninstall coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Uninstall with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To uninstall all utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall every program with a set prefix:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall from a custom parent directory:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- ANCHOR_END: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;GNU test suite compatibility&lt;/h2&gt; 
 &lt;p&gt;Below is the evolution of how many GNU tests uutils passes. A more detailed breakdown of the GNU test results of the main branch can be found &lt;a href="https://uutils.github.io/coreutils/docs/test_coverage.html"&gt;in the user manual&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/orgs/uutils/projects/1"&gt;https://github.com/orgs/uutils/projects/1&lt;/a&gt; for the main meta bugs (many are missing).&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/uutils/coreutils-tracking/raw/main/gnu-results.svg?raw=true" alt="Evolution over time" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- close oranda-hide div --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to uutils, please see &lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uutils is licensed under the MIT License - see the &lt;code&gt;LICENSE&lt;/code&gt; file for details&lt;/p&gt; 
&lt;p&gt;GNU Coreutils is licensed under the GPL 3.0 or later.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>