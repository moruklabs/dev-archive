<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Thu, 07 Aug 2025 01:35:40 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>zellij-org/zellij</title>
      <link>https://github.com/zellij-org/zellij</link>
      <description>&lt;p&gt;A terminal workspace with batteries included&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br&gt; &lt;img src="https://raw.githubusercontent.com/zellij-org/zellij/main/assets/logo.png" alt="logo" width="200"&gt; &lt;br&gt; Zellij &lt;br&gt; &lt;br&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/CrUAFH3"&gt;&lt;img alt="Discord Chat" src="https://img.shields.io/discord/771367133715628073?color=5865F2&amp;amp;label=discord&amp;amp;style=flat-square"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23zellij_general:matrix.org"&gt;&lt;img alt="Matrix Chat" src="https://img.shields.io/matrix/zellij_general:matrix.org?color=1d7e64&amp;amp;label=matrix%20chat&amp;amp;style=flat-square&amp;amp;logo=matrix"&gt;&lt;/a&gt; &lt;a href="https://zellij.dev/documentation/"&gt;&lt;img alt="Zellij documentation" src="https://img.shields.io/badge/zellij-documentation-fc0060?style=flat-square"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/zellij-org/zellij/main/assets/demo.gif" alt="demo"&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; [&lt;a href="https://zellij.dev/documentation/installation"&gt;Installation&lt;/a&gt;] [&lt;a href="https://zellij.dev/screencasts/"&gt;Screencasts &amp;amp; Tutorials&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/configuration"&gt;Configuration&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/layouts"&gt;Layouts&lt;/a&gt;] [&lt;a href="https://zellij.dev/documentation/faq"&gt;FAQ&lt;/a&gt;] &lt;/h4&gt; 
&lt;h1&gt;What is this?&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#origin-of-the-name"&gt;Zellij&lt;/a&gt; is a workspace aimed at developers, ops-oriented people and anyone who loves the terminal. Similar programs are sometimes called "Terminal Multiplexers".&lt;/p&gt; 
&lt;p&gt;Zellij is designed around the philosophy that one must not sacrifice simplicity for power, taking pride in its great experience out of the box as well as the advanced features it places at its users' fingertips.&lt;/p&gt; 
&lt;p&gt;Zellij is geared toward beginner and power users alike - allowing deep customizability, personal automation through &lt;a href="https://zellij.dev/documentation/layouts.html"&gt;layouts&lt;/a&gt;, true multiplayer collaboration, unique UX features such as floating and stacked panes, and a &lt;a href="https://zellij.dev/documentation/plugins.html"&gt;plugin system&lt;/a&gt; allowing one to create plugins in any language that compiles to WebAssembly.&lt;/p&gt; 
&lt;p&gt;You can get started by &lt;a href="https://zellij.dev/documentation/installation.html"&gt;installing&lt;/a&gt; Zellij and checking out the &lt;a href="https://zellij.dev/screencasts/"&gt;Screencasts &amp;amp; Tutorials&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more details about our future plans, read about upcoming features in our &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#roadmap"&gt;roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How do I install it?&lt;/h2&gt; 
&lt;p&gt;The easiest way to install Zellij is through a &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/docs/THIRD_PARTY_INSTALL.md"&gt;package for your OS&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If one is not available for your OS, you could download a prebuilt binary from the &lt;a href="https://github.com/zellij-org/zellij/releases/latest"&gt;latest release&lt;/a&gt; and place it in your &lt;code&gt;$PATH&lt;/code&gt;. If you'd like, we could &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/#try-zellij-without-installing"&gt;automatically choose one for you&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install (compile) with &lt;code&gt;cargo&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo install --locked zellij
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Try Zellij without installing&lt;/h4&gt; 
&lt;p&gt;bash/zsh:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -L https://zellij.dev/launch)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;fish/xonsh:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash -c 'bash &amp;lt;(curl -L https://zellij.dev/launch)'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installing from &lt;code&gt;main&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Installing Zellij from the &lt;code&gt;main&lt;/code&gt; branch is not recommended. This branch represents pre-release code, is constantly being worked on and may contain broken or unusable features. In addition, using it may corrupt the cache for future versions, forcing users to clear it before they can use the officially released version.&lt;/p&gt; 
&lt;p&gt;That being said - no-one will stop you from using it (and bug reports involving new features are greatly appreciated), but please consider using the latest release instead as detailed at the top of this section.&lt;/p&gt; 
&lt;h2&gt;How do I start a development environment?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Clone the project&lt;/li&gt; 
 &lt;li&gt;In the project folder, for debug builds run: &lt;code&gt;cargo xtask run&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;To run all tests: &lt;code&gt;cargo xtask test&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more build commands, see &lt;a href="https://raw.githubusercontent.com/zellij-org/zellij/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;For configuring Zellij, please see the &lt;a href="https://zellij.dev/documentation/configuration.html"&gt;Configuration Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;About issues in this repository&lt;/h2&gt; 
&lt;p&gt;Issues in this repository, whether open or closed, do not necessarily indicate a problem or a bug in the software. They only indicate that the reporter wanted to communicate their experiences or thoughts to the maintainers. The Zellij maintainers do their best to go over and reply to all issue reports, but unfortunately cannot promise these will always be dealt with or even read. Your understanding is appreciated.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Presented here is the project roadmap, divided into three main sections.&lt;/p&gt; 
&lt;p&gt;These are issues that are either being actively worked on or are planned for the near future.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;If you'll click on the image, you'll be led to an SVG version of it on the website where you can directly click on every issue&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://zellij.dev/roadmap"&gt;&lt;img src="https://github.com/zellij-org/zellij/assets/795598/9c5b573b-20f5-41c6-908b-6b21c5fd456e" alt="roadmap"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Origin of the Name&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Zellij"&gt;From Wikipedia, the free encyclopedia&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Zellij (Arabic: الزليج, romanized: zillīj; also spelled zillij or zellige) is a style of mosaic tilework made from individually hand-chiseled tile pieces. The pieces were typically of different colours and fitted together to form various patterns on the basis of tessellations, most notably elaborate Islamic geometric motifs such as radiating star patterns composed of various polygons. This form of Islamic art is one of the main characteristics of architecture in the western Islamic world. It is found in the architecture of Morocco, the architecture of Algeria, early Islamic sites in Tunisia, and in the historic monuments of al-Andalus (in the Iberian Peninsula).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt; 
&lt;h2&gt;Sponsored by&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://terminaltrove.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/121595180?s=200&amp;amp;v=4" width="80px"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nautechsystems/nautilus_trader</title>
      <link>https://github.com/nautechsystems/nautilus_trader</link>
      <description>&lt;p&gt;A high-performance algorithmic trading platform and event-driven backtester&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png" width="500"&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codecov.io/gh/nautechsystems/nautilus_trader"&gt;&lt;img src="https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H" alt="codecov"&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/nautechsystems/nautilus_trader"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="codspeed"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/nautilus_trader" alt="pythons"&gt; &lt;img src="https://img.shields.io/pypi/v/nautilus_trader" alt="pypi-version"&gt; &lt;img src="https://img.shields.io/pypi/format/nautilus_trader?color=blue" alt="pypi-format"&gt; &lt;a href="https://pepy.tech/project/nautilus-trader"&gt;&lt;img src="https://pepy.tech/badge/nautilus-trader" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NautilusTrader"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Branch&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Rust&lt;/th&gt; 
   &lt;th align="left"&gt;Python&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13*&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;* Windows builds are currently pinned to CPython 3.13.2, see &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/getting_started/installation.md"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://nautilustrader.io/docs/"&gt;https://nautilustrader.io/docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: &lt;a href="mailto:support@nautilustrader.io"&gt;support@nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.&lt;/p&gt; 
&lt;p&gt;The platform is &lt;em&gt;AI-first&lt;/em&gt;, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.&lt;/p&gt; 
&lt;p&gt;NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.&lt;/p&gt; 
&lt;p&gt;The platform is also universal, and asset-class-agnostic — with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png" alt="nautilus-trader" title="nautilus-trader"&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Core is written in Rust with asynchronous networking using &lt;a href="https://crates.io/crates/tokio"&gt;tokio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Modular adapters mean any REST API or WebSocket feed can be integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Time in force &lt;code&gt;IOC&lt;/code&gt;, &lt;code&gt;FOK&lt;/code&gt;, &lt;code&gt;GTC&lt;/code&gt;, &lt;code&gt;GTD&lt;/code&gt;, &lt;code&gt;DAY&lt;/code&gt;, &lt;code&gt;AT_THE_OPEN&lt;/code&gt;, &lt;code&gt;AT_THE_CLOSE&lt;/code&gt;, advanced order types and conditional triggers. Execution instructions &lt;code&gt;post-only&lt;/code&gt;, &lt;code&gt;reduce-only&lt;/code&gt;, and icebergs. Contingency orders including &lt;code&gt;OCO&lt;/code&gt;, &lt;code&gt;OUO&lt;/code&gt;, &lt;code&gt;OTO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Add user-defined custom components, or assemble entire systems from scratch leveraging the &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; and &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting&lt;/strong&gt;: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live&lt;/strong&gt;: Use identical strategy implementations between backtesting and live deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-venue&lt;/strong&gt;: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Training&lt;/strong&gt;: Backtest engine fast enough to be used to train AI trading agents (RL/ES).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png" alt="Alt text" title="nautilus"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;nautilus - from ancient Greek 'sailor' and naus 'ship'.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why NautilusTrader?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant event-driven Python&lt;/strong&gt;: Native binary core components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parity between backtesting and live trading&lt;/strong&gt;: Identical strategy code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduced operational risk&lt;/strong&gt;: Enhanced risk management functionality, logical accuracy, and type safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly extendable&lt;/strong&gt;: Message bus, custom components and actors, custom data, custom adapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.&lt;/p&gt; 
&lt;p&gt;One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; or &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt;. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.&lt;/p&gt; 
&lt;h2&gt;Why Python?&lt;/h2&gt; 
&lt;p&gt;Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the &lt;em&gt;de facto lingua franca&lt;/em&gt; of data science, machine learning, and artificial intelligence.&lt;/p&gt; 
&lt;p&gt;developer/user communities. However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python's rich ecosystem of libraries and communities.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is "blazingly fast" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.&lt;/p&gt; 
&lt;p&gt;Rust’s rich type system and ownership model guarantees memory-safety and thread-safety deterministically — eliminating many classes of bugs at compile-time.&lt;/p&gt; 
&lt;p&gt;The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and &lt;a href="https://pyo3.rs"&gt;PyO3&lt;/a&gt;—no Rust toolchain is required at install time.&lt;/p&gt; 
&lt;p&gt;This project makes the &lt;a href="https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html"&gt;Soundness Pledge&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;“The intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.”&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is modularly designed to work with &lt;em&gt;adapters&lt;/em&gt;, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.&lt;/p&gt; 
&lt;p&gt;The following integrations are currently supported; see &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;docs/integrations/&lt;/a&gt; for details:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;ID&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://betfair.com"&gt;Betfair&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BETFAIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sports Betting Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.com"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.us"&gt;Binance US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.binance.com/en/futures"&gt;Binance Futures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bybit.com"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BYBIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinbase.com/en/international-exchange"&gt;Coinbase International&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;COINBASE_INTX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://databento.com"&gt;Databento&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABENTO&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DYDX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hyperliquid.xyz"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HYPERLIQUID&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/building-orange" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.interactivebrokers.com"&gt;Interactive Brokers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;INTERACTIVE_BROKERS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brokerage (multi-venue)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://okx.com"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OKX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/beta-yellow" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://polymarket.com"&gt;Polymarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;POLYMARKET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prediction Market (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tardis.dev"&gt;Tardis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TARDIS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt;: The default client ID for the integrations adapter clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: The type of integration (often the venue type).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;building&lt;/code&gt;: Under construction and likely not in a usable state.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;beta&lt;/code&gt;: Completed to a minimally working state and in a beta testing phase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt;: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/integrations/index.html"&gt;Integrations&lt;/a&gt; documentation for further details.&lt;/p&gt; 
&lt;h2&gt;Versioning and releases&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;NautilusTrader is still under active development&lt;/strong&gt;. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a &lt;strong&gt;best-effort basis&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;We aim to follow a &lt;strong&gt;bi-weekly release schedule&lt;/strong&gt;, though experimental or larger features may cause delays.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;p&gt;We aim to maintain a stable, passing build across all branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;master&lt;/code&gt;: Reflects the source code for the latest released version; recommended for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt;: Daily snapshots of the &lt;code&gt;develop&lt;/code&gt; branch for early testing; merged at &lt;strong&gt;14:00 UTC&lt;/strong&gt; or on demand.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt;: Active development branch for contributors and feature work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md"&gt;roadmap&lt;/a&gt; aims to achieve a &lt;strong&gt;stable API for version 2.x&lt;/strong&gt; (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Precision mode&lt;/h2&gt; 
&lt;p&gt;NautilusTrader supports two precision modes for its core value types (&lt;code&gt;Price&lt;/code&gt;, &lt;code&gt;Quantity&lt;/code&gt;, &lt;code&gt;Money&lt;/code&gt;), which differ in their internal bit-width and maximum decimal precision.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-precision&lt;/strong&gt;: 128-bit integers with up to 16 decimals of precision, and a larger value range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard-precision&lt;/strong&gt;: 64-bit integers with up to 9 decimals of precision, and a smaller value range.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;By default, the official Python wheels &lt;strong&gt;ship&lt;/strong&gt; in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support. For the Rust crates, the default is standard-precision unless you explicitly enable the &lt;code&gt;high-precision&lt;/code&gt; feature flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust feature flag&lt;/strong&gt;: To enable high-precision mode in Rust, add the &lt;code&gt;high-precision&lt;/code&gt; feature to your Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
nautilus_model = { version = "*", features = ["high-precision"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using the latest supported version of Python and installing &lt;a href="https://pypi.org/project/nautilus_trader/"&gt;nautilus_trader&lt;/a&gt; inside a virtual environment to isolate dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are two supported ways to install&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pre-built binary wheel from PyPI &lt;em&gt;or&lt;/em&gt; the Nautech Systems package index.&lt;/li&gt; 
 &lt;li&gt;Build from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We highly recommend installing using the &lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt; package manager with a "vanilla" CPython.&lt;/p&gt; 
 &lt;p&gt;Conda and other Python distributions &lt;em&gt;may&lt;/em&gt; work but aren’t officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;p&gt;To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From the Nautech Systems package index&lt;/h3&gt; 
&lt;p&gt;The Nautech Systems package index (&lt;code&gt;packages.nautechsystems.io&lt;/code&gt;) complies with &lt;a href="https://peps.python.org/pep-0503/"&gt;PEP-503&lt;/a&gt; and hosts both stable and development binary wheels for &lt;code&gt;nautilus_trader&lt;/code&gt;. This enables users to install either the latest stable release or pre-release versions for testing.&lt;/p&gt; 
&lt;h4&gt;Stable wheels&lt;/h4&gt; 
&lt;p&gt;Stable wheels correspond to official releases of &lt;code&gt;nautilus_trader&lt;/code&gt; on PyPI, and use standard versioning.&lt;/p&gt; 
&lt;p&gt;To install the latest stable release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Development wheels&lt;/h4&gt; 
&lt;p&gt;Development wheels are published from both the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; branches, allowing users to test features and fixes ahead of stable releases.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Wheels from the &lt;code&gt;develop&lt;/code&gt; branch are only built for the Linux x86_64 platform to save time and compute resources, while &lt;code&gt;nightly&lt;/code&gt; wheels support additional platforms as shown below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Nightly&lt;/th&gt; 
   &lt;th align="left"&gt;Develop&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines, while adhering to &lt;a href="https://peps.python.org/pep-0440/"&gt;PEP-440&lt;/a&gt; versioning standards:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; wheels use the version format &lt;code&gt;dev{date}+{build_number}&lt;/code&gt; (e.g., &lt;code&gt;1.208.0.dev20241212+7001&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; wheels use the version format &lt;code&gt;a{date}&lt;/code&gt; (alpha) (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;We do not recommend using development wheels in production environments, such as live trading controlling real capital.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation commands&lt;/h4&gt; 
&lt;p&gt;By default, pip will install the latest stable release. Adding the &lt;code&gt;--pre&lt;/code&gt; flag ensures that pre-release versions, including development wheels, are considered.&lt;/p&gt; 
&lt;p&gt;To install the latest available pre-release (including development wheels):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific development wheel (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt; for December 12, 2024):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available versions&lt;/h4&gt; 
&lt;p&gt;You can view all available versions of &lt;code&gt;nautilus_trader&lt;/code&gt; on the &lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;package index&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To programmatically fetch and list available versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&amp;lt;=&amp;lt;a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Branch updates&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): Build and publish continuously with every merged commit.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): Build and publish daily when we automatically merge the &lt;code&gt;develop&lt;/code&gt; branch at &lt;strong&gt;14:00 UTC&lt;/strong&gt; (if there are changes).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Retention policies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): We retain only the most recent wheel build.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): We retain only the 10 most recent wheel builds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;It's possible to install from source using pip if you first install the build dependencies as specified in the &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; (the Rust toolchain installer):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl https://sh.rustup.rs -sSf | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Download and install &lt;a href="https://win.rustup.rs/x86_64"&gt;&lt;code&gt;rustup-init.exe&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Install "Desktop development with C++" with &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;rustc --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;cargo&lt;/code&gt; in the current shell:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Start a new PowerShell&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://clang.llvm.org/"&gt;clang&lt;/a&gt; (a C language frontend for LLVM):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install clang
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p&gt;Add Clang to your &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;:&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (12.0.0 - x64…) = checked | Modify&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;clang&lt;/code&gt; in the current shell:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;[System.Environment]::SetEnvironmentVariable('path', "C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;clang --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install uv (see the &lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv installation guide&lt;/a&gt; for more details):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source with &lt;code&gt;git&lt;/code&gt;, and install from the project's root directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;--depth 1&lt;/code&gt; flag fetches just the latest commit for a faster, lightweight clone.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt; &lt;p&gt;Set environment variables for PyO3 compilation (Linux and macOS only):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Adjust the Python version and architecture in the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; to match your system. Use &lt;code&gt;uv python list&lt;/code&gt; to find the exact path for your Python installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for other options and further details.&lt;/p&gt; 
&lt;h2&gt;Redis&lt;/h2&gt; 
&lt;p&gt;Using &lt;a href="https://redis.io"&gt;Redis&lt;/a&gt; with NautilusTrader is &lt;strong&gt;optional&lt;/strong&gt; and only required if configured as the backend for a &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; database or &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;. See the &lt;strong&gt;Redis&lt;/strong&gt; section of the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation#redis"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Makefile&lt;/h2&gt; 
&lt;p&gt;A &lt;code&gt;Makefile&lt;/code&gt; is provided to automate most installation and build tasks for development. Some of the targets include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make install&lt;/code&gt;: Installs in &lt;code&gt;release&lt;/code&gt; build mode with all dependency groups and extras.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-debug&lt;/code&gt;: Same as &lt;code&gt;make install&lt;/code&gt; but with &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-just-deps&lt;/code&gt;: Installs just the &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt; dependencies (does not install package).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;: Runs the build script in &lt;code&gt;release&lt;/code&gt; build mode (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-debug&lt;/code&gt;: Runs the build script in &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;release&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel-debug&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;debug&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make cargo-test&lt;/code&gt;: Runs all Rust crate tests using &lt;code&gt;cargo-nextest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;: Deletes all build results, such as &lt;code&gt;.so&lt;/code&gt; or &lt;code&gt;.dll&lt;/code&gt; files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt;: &lt;strong&gt;CAUTION&lt;/strong&gt; Removes all artifacts not in the git index from the repository. This includes source files which have not been &lt;code&gt;git add&lt;/code&gt;ed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make docs&lt;/code&gt;: Builds the documentation HTML using Sphinx.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pre-commit&lt;/code&gt;: Runs the pre-commit checks over all files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make ruff&lt;/code&gt;: Runs ruff over all files using the &lt;code&gt;pyproject.toml&lt;/code&gt; config (with autofix).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pytest&lt;/code&gt;: Runs all tests with &lt;code&gt;pytest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test-performance&lt;/code&gt;: Runs performance tests with &lt;a href="https://codspeed.io"&gt;codspeed&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make help&lt;/code&gt; for documentation on all available make targets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md"&gt;crates/infrastructure/TESTS.md&lt;/a&gt; file for running the infrastructure integration tests.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py"&gt;indicator&lt;/a&gt; example written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/"&gt;indicator&lt;/a&gt; examples written in Cython.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/"&gt;strategy&lt;/a&gt; examples written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/"&gt;backtest&lt;/a&gt; examples using a &lt;code&gt;BacktestEngine&lt;/code&gt; directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;Docker containers are built using the base image &lt;code&gt;python:3.12-slim&lt;/code&gt; with the following variant tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:latest&lt;/code&gt; has the latest release version installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:latest&lt;/code&gt; has the latest release version installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can pull the container images as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/&amp;lt;image_variant_tag&amp;gt; --platform linux/amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can launch the backtest example container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64
docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open your browser at the following address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;http://127.0.0.1:8888/lab
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the &lt;code&gt;log_level&lt;/code&gt; to &lt;code&gt;ERROR&lt;/code&gt; in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jupyterlab/jupyterlab/issues/12845"&gt;https://github.com/jupyterlab/jupyterlab/issues/12845&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/deshaw/jupyterlab-limit-output"&gt;https://github.com/deshaw/jupyterlab-limit-output&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the &lt;a href="https://nautilustrader.io/docs/latest/developer_guide/index.html"&gt;Developer Guide&lt;/a&gt; for helpful information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make build-debug&lt;/code&gt; to compile after changes to Rust or Cython code for the most efficient development workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Testing with Rust&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://nexte.st"&gt;cargo-nextest&lt;/a&gt; is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.&lt;/p&gt; 
&lt;p&gt;You can install cargo-nextest by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-nextest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run Rust tests with &lt;code&gt;make cargo-test&lt;/code&gt;, which uses &lt;strong&gt;cargo-nextest&lt;/strong&gt; with an efficient profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an &lt;a href="https://github.com/nautechsystems/nautilus_trader/issues"&gt;issue&lt;/a&gt; on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.&lt;/p&gt; 
&lt;p&gt;Before getting started, be sure to review the &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope"&gt;open-source scope&lt;/a&gt; outlined in the project’s roadmap to understand what’s in and out of scope.&lt;/p&gt; 
&lt;p&gt;Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Pull requests should target the &lt;code&gt;develop&lt;/code&gt; branch (the default branch). This is where new features and improvements are integrated before release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community of users and contributors on &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord&lt;/a&gt; to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.&lt;/p&gt; 
 &lt;p&gt;All official updates and communications from NautilusTrader will be shared exclusively through &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;, our &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord server&lt;/a&gt;, or our X (Twitter) account: &lt;a href="https://x.com/NautilusTrader"&gt;@NautilusTrader&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;If you encounter any suspicious activity, please report it to the appropriate platform and contact us at &lt;a href="mailto:info@nautechsystems.io"&gt;info@nautechsystems.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code for NautilusTrader is available on GitHub under the &lt;a href="https://www.gnu.org/licenses/lgpl-3.0.en.html"&gt;GNU Lesser General Public License v3.0&lt;/a&gt;. Contributions to the project are welcome and require the completion of a standard &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md"&gt;Contributor License Agreement (CLA)&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;NautilusTrader™ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png" alt="nautechsystems" title="nautechsystems"&gt; &lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png" width="128"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rolldown/rolldown</title>
      <link>https://github.com/rolldown/rolldown</link>
      <description>&lt;p&gt;Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://rolldown.rs" target="_blank" rel="noopener noreferrer"&gt; &lt;img width="180" src="https://rolldown.rs/rolldown-round.svg?sanitize=true" alt="Rolldown logo"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/rolldown/rolldown/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/v/rolldown/latest?color=brightgreen" alt="NPM version"&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/rolldown/rolldown"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="CodSpeed Badge"&gt;&lt;/a&gt; &lt;a href="https://chat.rolldown.rs"&gt;&lt;img src="https://img.shields.io/discord/1079625926024900739?logo=discord&amp;amp;label=Discord" alt="Discord chat"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/rolldown/rolldown"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.npmjs.com/package/rolldown/v/latest"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm" alt="NPM Unpacked Size (with version)"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-arm64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64" alt="NPM Unpacked Size darwin-arm64"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-darwin-x64"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64" alt="NPM Unpacked Size darwin-x64"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu" alt="NPM Unpacked Size linux-x64-gnu"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64" alt="NPM Unpacked Size win32-x64"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi"&gt;&lt;img src="https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi" alt="NPM Unpacked Size wasm32-wasi"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pkg.pr.new/~/rolldown/rolldown"&gt;&lt;img src="https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&amp;amp;color=000&amp;amp;logoSize=auto" alt="pkg.pr.new"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz"&gt;&lt;img src="https://developer.stackblitz.com/img/open_in_stackblitz.svg?sanitize=true" alt="rolldown-starter-stackblitz"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🚧 &lt;strong&gt;Beta Software&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Rolldown is currently in beta status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Rolldown&lt;/h1&gt; 
&lt;p&gt;Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in &lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;. It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.&lt;/p&gt; 
&lt;p&gt;For more information, please check out the documentation at &lt;a href="https://rolldown.rs/about"&gt;rolldown.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;VoidZero Inc.&lt;/h2&gt; 
&lt;p&gt;Rolldown is a project of &lt;a href="https://voidzero.dev/"&gt;VoidZero&lt;/a&gt;, see our announcement &lt;a href="https://voidzero.dev/posts/announcing-voidzero-inc"&gt;Announcing VoidZero - Next Generation Toolchain for JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have requirements for JavaScript tools at scale, please &lt;a href="https://forms.gle/WQgjyzYJpwurpxWKA"&gt;get in touch&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would love to have more contributors involved!&lt;/p&gt; 
&lt;p&gt;To get started, please read our &lt;a href="https://rolldown.rs/contrib-guide/"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The Rolldown project is heavily inspired by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup"&gt;Rollup&lt;/a&gt;, created by &lt;a href="https://github.com/Rich-Harris"&gt;Rich Harris&lt;/a&gt; and maintained by &lt;a href="https://github.com/lukastaegert"&gt;Lukas Taegert-Atkinson&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild"&gt;esbuild&lt;/a&gt;, created by &lt;a href="https://github.com/evanw"&gt;Evan Wallace&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And supported by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/napi-rs/napi-rs"&gt;napi-rs&lt;/a&gt; for Node.js add-ons in Rust via Node-API.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc"&gt;oxc&lt;/a&gt; for the underlying parser, resolver, and sourcemap support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project also partially contains code derived or copied from the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rollup/rollup/raw/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md"&gt;rollup(MIT)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evanw/esbuild/raw/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md"&gt;esbuild(MIT)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Licenses of these projects are listed in &lt;a href="https://raw.githubusercontent.com/rolldown/rolldown/main/THIRD-PARTY-LICENSE"&gt;THIRD-PARTY-LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cocoindex-io/cocoindex</title>
      <link>https://github.com/cocoindex-io/cocoindex</link>
      <description>&lt;p&gt;Data transformation framework for AI. Ultra performant, with incremental processing.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/github.svg?sanitize=true" alt="CocoIndex"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Data transformation for AI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub"&gt;&lt;/a&gt; &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;&lt;img src="https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white" alt="License"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/cocoindex/"&gt;&lt;img src="https://img.shields.io/pypi/v/cocoindex?color=5B5BD6" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/cocoindex"&gt;&lt;img src="https://img.shields.io/pypi/dm/cocoindex" alt="PyPI - Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="release"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;&lt;img src="https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13939" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13939" alt="cocoindex-io%2Fcocoindex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box. Exceptional developer velocity. Production-ready at day 0.&lt;/p&gt; 
&lt;p&gt;⭐ Drop a star to help us grow!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=en"&gt;English&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru"&gt;Русский&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh"&gt;中文&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/transformation.svg?sanitize=true" alt="CocoIndex Transformation"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;CocoIndex makes it super easy to transform data with AI workloads, and keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/venn-features.png" alt="CocoIndex Features" width="400"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;Either creating embedding, building knowledge graphs, or any data transformations - beyond traditional SQL.&lt;/p&gt; 
&lt;h2&gt;Exceptional velocity&lt;/h2&gt; 
&lt;p&gt;Just declare transformation in dataflow with ~100 lines of python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# import
data['content'] = flow_builder.add_source(...)

# transform
data['out'] = data['content']
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CocoIndex follows the idea of &lt;a href="https://en.wikipedia.org/wiki/Dataflow_programming"&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.&lt;/p&gt; 
&lt;h2&gt;Build like LEGO&lt;/h2&gt; 
&lt;p&gt;Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/components.svg?sanitize=true" alt="CocoIndex Features"&gt; &lt;/p&gt; 
&lt;h2&gt;Data Freshness&lt;/h2&gt; 
&lt;p&gt;CocoIndex keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6" alt="Incremental Processing" width="700"&gt; &lt;/p&gt; 
&lt;p&gt;It has out-of-box support for incremental indexing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;minimal recomputation on source or logic change.&lt;/li&gt; 
 &lt;li&gt;(re-)processing necessary portions; reuse cache when possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start:&lt;/h2&gt; 
&lt;p&gt;If you're new to CocoIndex, we recommend checking out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📖 &lt;a href="https://cocoindex.io/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⚡ &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🎬 &lt;a href="https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT"&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;a href="https://cocoindex.io/docs/getting_started/installation#-install-postgres"&gt;Install Postgres&lt;/a&gt; if you don't have one. CocoIndex uses it for incremental processing.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Define data flow&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@cocoindex.flow_def(name="TextEmbedding")
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope["documents"] = flow_builder.add_source(cocoindex.sources.LocalFile(path="markdown_files"))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope["documents"].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc["chunks"] = doc["content"].transform(
            cocoindex.functions.SplitRecursively(),
            language="markdown", chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc["chunks"].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk["embedding"] = chunk["text"].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model="sentence-transformers/all-MiniLM-L6-v2"))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc["filename"], location=chunk["location"],
                                   text=chunk["text"], embedding=chunk["embedding"])

    # Export collected data to a vector index.
    doc_embeddings.export(
        "doc_embeddings",
        cocoindex.targets.Postgres(),
        primary_key_fields=["filename", "location"],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name="embedding",
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It defines an index flow like this:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="400" alt="Data Flow" src="https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463"&gt; &lt;/p&gt; 
&lt;h2&gt;🚀 Examples and demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding"&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding"&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding"&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction"&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding"&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/azure_blob_embedding"&gt;Azure Blob Storage Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Azure Blob Storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding"&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph"&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant"&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker"&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation"&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search"&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/face_recognition"&gt;Face Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Recognize faces in images and build embedding index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/paper_metadata"&gt;Paper Metadata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index papers in PDF files, and build metadata tables for each paper&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/multi_format_indexing"&gt;Multi Format Indexing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build visual document index from PDFs and images with ColPali for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_output_files"&gt;Custom Output Files&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Convert markdown files to HTML files and save them to a local directory, using &lt;em&gt;CocoIndex Custom Targets&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More coming and stay tuned 👀!&lt;/p&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit &lt;a href="https://cocoindex.io/docs"&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions from our community ❤️. For details on contributing or running the project for development, check out our &lt;a href="https://cocoindex.io/docs/about/contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;👥 Community&lt;/h2&gt; 
&lt;p&gt;Welcome with a huge coconut hug 🥥⋆｡˚🤗. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; 
&lt;p&gt;Join our community here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🌟 &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;👋 &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;▶️ &lt;a href="https://www.youtube.com/@cocoindex-io"&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📜 &lt;a href="https://cocoindex.io/blogs/"&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support us:&lt;/h2&gt; 
&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ⭐ at GitHub repo &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub"&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>biomejs/biome</title>
      <link>https://github.com/biomejs/biome</link>
      <description>&lt;p&gt;A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-dark-transparent.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg"&gt; 
  &lt;img alt="Shows the banner of Biome, with its logo and the phrase 'Biome - Toolchain of the web'." src="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg?sanitize=true" width="700"&gt; 
 &lt;/picture&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/biomejs/biome/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI on main"&gt;&lt;/a&gt; &lt;a href="https://biomejs.dev/chat"&gt;&lt;img src="https://badgen.net/discord/online-members/BypW39g6Yc?icon=discord&amp;amp;label=discord&amp;amp;color=60a5fa" alt="Discord chat"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@biomejs/biome/v/latest"&gt;&lt;img src="https://badgen.net/npm/v/@biomejs/biome?icon=npm&amp;amp;color=60a5fa&amp;amp;label=%40biomejs%2Fbiome" alt="npm version"&gt;&lt;/a&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=biomejs.biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Visual%20Studio%20Marketplace&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="VSCode version"&gt;&lt;/a&gt; &lt;a href="https://open-vsx.org/extension/biomejs/biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Open%20VSX%20Registry&amp;amp;logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyB2aWV3Qm94PSI0LjYgNSA5Ni4yIDEyMi43IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Ik0zMCA0NC4yTDUyLjYgNUg3LjN6TTQuNiA4OC41aDQ1LjNMMjcuMiA0OS40em01MSAwbDIyLjYgMzkuMiAyMi42LTM5LjJ6IiBmaWxsPSIjYzE2MGVmIi8+CiAgPHBhdGggZD0iTTUyLjYgNUwzMCA0NC4yaDQ1LjJ6TTI3LjIgNDkuNGwyMi43IDM5LjEgMjIuNi0zOS4xem01MSAwTDU1LjYgODguNWg0NS4yeiIgZmlsbD0iI2E2MGVlNSIvPgo8L3N2Zz4=&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="Open VSX version"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- Insert new entries lexicographically by language code.
     For example given below is the same order as these files appear on page:
     https://github.com/biomejs/biome/tree/main/packages/@biomejs/biome --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.hi.md"&gt;हिन्दी&lt;/a&gt; | English | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.fr.md"&gt;Français&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-TW.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ja.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.pt-BR.md"&gt;Português do Brasil&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.kr.md"&gt;한국어&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ru.md"&gt;Русский&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.uk.md"&gt;Українська&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://raw.githubusercontent.com/biomejs/biome/main/benchmark#formatting"&gt;fast formatter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt; and &lt;em&gt;GraphQL&lt;/em&gt; that scores &lt;strong&gt;&lt;a href="https://console.algora.io/challenges/prettier"&gt;97% compatibility with &lt;em&gt;Prettier&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://github.com/biomejs/biome/tree/main/benchmark#linting"&gt;performant linter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt;, and &lt;em&gt;GraphQL&lt;/em&gt; that features &lt;strong&gt;&lt;a href="https://biomejs.dev/linter/rules/"&gt;more than 300 rules&lt;/a&gt;&lt;/strong&gt; from ESLint, typescript-eslint, and &lt;a href="https://github.com/biomejs/biome/discussions/3"&gt;other sources&lt;/a&gt;. It &lt;strong&gt;outputs detailed and contextualized diagnostics&lt;/strong&gt; that help you to improve your code and become a better programmer!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is designed from the start to be used &lt;a href="https://biomejs.dev/guides/editors/first-party-extensions/"&gt;interactively within an editor&lt;/a&gt;. It can format and lint malformed code as you are writing it.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install --save-dev --save-exact @biomejs/biome
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# format files
npx @biomejs/biome format --write

# lint files and apply the safe fixes
npx @biomejs/biome lint --write

# run format, lint, etc. and apply the safe fixes
npx @biomejs/biome check --write

# check all files against format, lint, etc. in CI environments
npx @biomejs/biome ci
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to give Biome a run without installing it, use the &lt;a href="https://biomejs.dev/playground/"&gt;online playground&lt;/a&gt;, compiled to WebAssembly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://biomejs.dev/"&gt;homepage&lt;/a&gt; to learn more about Biome, or directly head to the &lt;a href="https://biomejs.dev/guides/getting-started/"&gt;Getting Started guide&lt;/a&gt; to start using Biome.&lt;/p&gt; 
&lt;h2&gt;More about Biome&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has sane defaults and it doesn't require configuration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; aims to support &lt;a href="https://biomejs.dev/internals/language-support/"&gt;all main languages&lt;/a&gt; of modern web development.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; &lt;a href="https://biomejs.dev/guides/manual-installation/"&gt;doesn't require Node.js&lt;/a&gt; to function.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has first-class LSP support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; wants to offer a high-quality &lt;em&gt;Developer Experience&lt;/em&gt;, with descriptive diagnostics and great performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; unifies functionalities that have previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelize work, caching, and configuration.&lt;/p&gt; 
&lt;p&gt;Read more about our &lt;a href="https://biomejs.dev/internals/philosophy/"&gt;project philosophy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-MIT"&gt;MIT licensed&lt;/a&gt; or &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-APACHE"&gt;Apache 2.0 licensed&lt;/a&gt; and moderated under the &lt;a href="https://github.com/biomejs/biome/tree/main/CODE_OF_CONDUCT.md"&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Funding&lt;/h2&gt; 
&lt;p&gt;You can fund the project in different ways&lt;/p&gt; 
&lt;h3&gt;Project sponsorship and funding&lt;/h3&gt; 
&lt;p&gt;You can sponsor or fund the project via &lt;a href="https://opencollective.com/biome"&gt;Open collective&lt;/a&gt; or &lt;a href="https://github.com/sponsors/biomejs"&gt;GitHub sponsors&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Biome offers a simple sponsorship program that allows companies to get visibility and recognition among various developers.&lt;/p&gt; 
&lt;p&gt;Biome offers &lt;a href="https://biomejs.dev/enterprise"&gt;enterprise support&lt;/a&gt;, where Core Contributors can be employed to work on company-focused projects.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://depot.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png"&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-dark@3x.png"&gt; 
      &lt;img src="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png" width="400" alt="Depot logo"&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Silver Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://l2beat.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/l2beat/c2b2a27/logo/256.png" height="100" alt="L2BEAT logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://www.phoenixlabs.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/phoenix-labs/2824ed4/logo/100.png?height=100" height="100" alt="Phoenix Labs logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://lokalise.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14294501?s=200&amp;amp;v=4" height="100" alt="Lokalise logo"&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Bronze Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://nanabit.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/nanabit/d15fd98/logo/256.png?height=80" width="80" alt="Nanabit logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://vital.io/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25357309?s=200" width="80" alt="Vital logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://coderabbit.ai/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/132028505?s=200&amp;amp;v=4" width="80" alt="CodeRabbit logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://forge42.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/161314831?s=200&amp;amp;v=4" width="80" alt="Forge42 logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="http://rstudio.org/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/513560?s=200&amp;amp;v=4" width="80" alt="RStudio logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://pennylane.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/57875210?s=200&amp;amp;v=4" width="80" alt="Pennylane logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://jetbrains.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png" width="100" alt="JetBrains logo"&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>rerun-io/rerun</title>
      <link>https://github.com/rerun-io/rerun</link>
      <description>&lt;p&gt;Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.rerun.io/"&gt; &lt;img alt="banner" src="https://user-images.githubusercontent.com/1148717/218142418-1d320929-6b7a-486e-8277-fbeef2432529.png"&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;h1 align="center"&gt; &lt;a href="https://pypi.org/project/rerun-sdk/"&gt; &lt;img alt="PyPi" src="https://img.shields.io/pypi/v/rerun-sdk.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://crates.io/crates/rerun"&gt; &lt;img alt="crates.io" src="https://img.shields.io/crates/v/rerun.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://github.com/rerun-io/rerun/raw/main/LICENSE-MIT"&gt; &lt;img alt="MIT" src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://github.com/rerun-io/rerun/raw/main/LICENSE-APACHE"&gt; &lt;img alt="Apache" src="https://img.shields.io/badge/license-Apache-blue.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://discord.gg/Gcm8BbTaAj"&gt; &lt;img alt="Rerun Discord" src="https://img.shields.io/discord/1062300748202921994?label=Rerun%20Discord"&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;h1&gt;Time-aware multimodal data stack and visualizations&lt;/h1&gt; 
&lt;p&gt;Rerun is building the multimodal data stack to model, ingest, store, query and view robotics-style data. It's used in areas like robotics, spatial and embodied AI, generative media, industrial processing, simulation, security, and health.&lt;/p&gt; 
&lt;p&gt;Rerun is easy to use! Use the Rerun SDK (available for C++, Python and Rust) to log data like images, tensors, point clouds, and text. Logs are streamed to the Rerun Viewer for live visualization or to file for later use. You can also query the logged data through &lt;a href="https://rerun.io/docs/howto/dataframe-api"&gt;our dataframe API&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/#getting-started"&gt;Get started&lt;/a&gt; in minutes – no account needed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/viewer"&gt;Run the Rerun Viewer in your browser&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/what-is-rerun"&gt;Read about what Rerun is and who it is for&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A short taste&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import rerun as rr  # pip install rerun-sdk

rr.init("rerun_example_app")

rr.spawn()  # Spawn a child process with a viewer and connect
# rr.save("recording.rrd")  # Stream all logs to disk
# rr.connect_grpc()  # Connect to a remote viewer

# Associate subsequent data with 42 on the “frame” timeline
rr.set_time("frame", sequence=42)

# Log colored 3D points to the entity at `path/to/points`
rr.log("path/to/points", rr.Points3D(positions, colors=colors))
…
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/full.png" alt=""&gt; 
  &lt;source media="(max-width: 480px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/480w.png"&gt; 
  &lt;source media="(max-width: 768px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/768w.png"&gt; 
  &lt;source media="(max-width: 1024px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1024w.png"&gt; 
  &lt;source media="(max-width: 1200px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1200w.png"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/cpp"&gt;&lt;strong&gt;C++&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/python"&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/a&gt;: &lt;code&gt;pip install rerun-sdk&lt;/code&gt; or on &lt;a href="https://github.com/conda-forge/rerun-sdk-feedstock"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/rust"&gt;&lt;strong&gt;Rust&lt;/strong&gt;&lt;/a&gt;: &lt;code&gt;cargo add rerun&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installing the Rerun Viewer binary&lt;/h3&gt; 
&lt;p&gt;To stream log data over the network or load our &lt;code&gt;.rrd&lt;/code&gt; data files you also need the &lt;code&gt;rerun&lt;/code&gt; binary. It can be installed with &lt;code&gt;pip install rerun-sdk&lt;/code&gt; or with &lt;code&gt;cargo install rerun-cli --locked --features nasm&lt;/code&gt; (see note below). Note that only the Python SDK comes bundled with the Viewer whereas C++ &amp;amp; Rust always rely on a separate install.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: the &lt;code&gt;nasm&lt;/code&gt; Cargo feature requires the &lt;a href="https://github.com/netwide-assembler/nasm"&gt;&lt;code&gt;nasm&lt;/code&gt;&lt;/a&gt; CLI to be installed and available in your path. Alternatively, you may skip enabling this feature, but this may result in inferior video decoding performance.&lt;/p&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;rerun --help&lt;/code&gt; in any terminal.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;📚 &lt;a href="http://rerun.io/docs"&gt;High-level docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⏃ &lt;a href="https://www.rerun.io/docs/reference/types"&gt;Loggable Types&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;a href="http://rerun.io/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📖 &lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/docs/snippets/INDEX.md"&gt;Code snippets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🌊 &lt;a href="https://ref.rerun.io/docs/cpp"&gt;C++ API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐍 &lt;a href="https://ref.rerun.io/docs/python"&gt;Python API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🦀 &lt;a href="https://docs.rs/rerun/"&gt;Rust API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⁉️ &lt;a href="https://www.rerun.io/docs/getting-started/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;We are in active development. There are many features we want to add, and the API is still evolving. &lt;em&gt;Expect breaking changes!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Some shortcomings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/7115"&gt;The viewer slows down when there are too many entities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/1611"&gt;We don't support transparency yet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The data you want to visualize must fit in RAM 
  &lt;ul&gt; 
   &lt;li&gt;See &lt;a href="https://www.rerun.io/docs/howto/limit-ram"&gt;https://www.rerun.io/docs/howto/limit-ram&lt;/a&gt; for how to bound memory use.&lt;/li&gt; 
   &lt;li&gt;We plan on having a disk-based data store some time in the future.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/1136"&gt;Multi-million point clouds can be slow&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Rerun for?&lt;/h2&gt; 
&lt;p&gt;Rerun is built to help you understand and improve complex processes that include rich multimodal data, like 2D, 3D, text, time series, tensors, etc. It is used in many industries, including robotics, simulation, computer vision, or anything that involves a lot of sensors or other signals that evolve over time.&lt;/p&gt; 
&lt;h3&gt;Example use case&lt;/h3&gt; 
&lt;p&gt;Say you're building a vacuum cleaning robot and it keeps running into walls. Why is it doing that? You need some tool to debug it, but a normal debugger isn't gonna be helpful. Similarly, just logging text won't be very helpful either. The robot may log "Going through doorway" but that won't explain why it thinks the wall is a door.&lt;/p&gt; 
&lt;p&gt;What you need is a visual and temporal debugger, that can log all the different representations of the world the robots holds in its little head, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RGB camera feed&lt;/li&gt; 
 &lt;li&gt;depth images&lt;/li&gt; 
 &lt;li&gt;lidar scan&lt;/li&gt; 
 &lt;li&gt;segmentation image (how the robot interprets what it sees)&lt;/li&gt; 
 &lt;li&gt;its 3D map of the apartment&lt;/li&gt; 
 &lt;li&gt;all the objects the robot has detected (or thinks it has detected), as 3D shapes in the 3D map&lt;/li&gt; 
 &lt;li&gt;its confidence in its prediction&lt;/li&gt; 
 &lt;li&gt;etc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You also want to see how all these streams of data evolve over time so you can go back and pinpoint exactly what went wrong, when and why.&lt;/p&gt; 
&lt;p&gt;Maybe it turns out that a glare from the sun hit one of the sensors in the wrong way, confusing the segmentation network leading to bad object detection. Or maybe it was a bug in the lidar scanning code. Or maybe the robot thought it was somewhere else in the apartment, because its odometry was broken. Or it could be one of a thousand other things. Rerun will help you find out!&lt;/p&gt; 
&lt;p&gt;But seeing the world from the point of the view of the robot is not just for debugging - it will also give you ideas on how to improve the algorithms, new test cases to set up, or datasets to collect. It will also let you explain the brains of the robot to your colleagues, boss, and customers. And so on. Seeing is believing, and an image is worth a thousand words, and multimodal temporal logging is worth a thousand images :)&lt;/p&gt; 
&lt;p&gt;While seeing and understanding your data is core to making progress in robotics, there is one more thing: You can also use the data you collected for visualization to create new datasets for training and evaluating the models and algorithms that run on your robot. Rerun provides query APIs to make it easy to extract clean datasets from your recording for exactly that purpose.&lt;/p&gt; 
&lt;p&gt;Of course, Rerun is useful for much more than just robots. Any time you have any form of sensors, or 2D or 3D state evolving over time, Rerun is a great tool.&lt;/p&gt; 
&lt;h2&gt;Business model&lt;/h2&gt; 
&lt;p&gt;Rerun uses an open-core model. Everything in this repository will stay open source and free (both as in beer and as in freedom).&lt;/p&gt; 
&lt;p&gt;We are also building a commercial data platform. Right now that is only available for a few select design partners. &lt;a href="https://rerun.io/pricing"&gt;Click here if you're interested&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Rerun open source project targets the needs of individual developers. The commercial product targets the needs specific to teams that build and run computer vision and robotics products.&lt;/p&gt; 
&lt;h2&gt;How to cite Rerun&lt;/h2&gt; 
&lt;p&gt;When using Rerun in your research, please cite it to acknowledge its contribution to your work. This can be done by including a reference to Rerun in the software or methods section of your paper.&lt;/p&gt; 
&lt;p&gt;Suggested citation format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{RerunSDK,
  title = {Rerun: A Visualization SDK for Multimodal Data},
  author = {{Rerun Development Team}},
  url = {https://www.rerun.io},
  version = {insert version number},
  date = {insert date of usage},
  year = {2024},
  publisher = {{Rerun Technologies AB}},
  address = {Online},
  note = {Available from https://www.rerun.io/ and https://github.com/rerun-io/rerun}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please replace "insert version number" with the version of Rerun you used and "insert date of usage" with the date(s) you used the tool in your research. This citation format helps ensure that Rerun's development team receives appropriate credit for their work and facilitates the tool's discovery by other researchers.&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/ARCHITECTURE.md"&gt;&lt;code&gt;ARCHITECTURE.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CODE_OF_CONDUCT.md"&gt;&lt;code&gt;CODE_OF_CONDUCT.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CODE_STYLE.md"&gt;&lt;code&gt;CODE_STYLE.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/BUILD.md"&gt;&lt;code&gt;BUILD.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/rerun_py/README.md"&gt;&lt;code&gt;rerun_py/README.md&lt;/code&gt;&lt;/a&gt; - instructions for Python SDK&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/rerun_cpp/README.md"&gt;&lt;code&gt;rerun_cpp/README.md&lt;/code&gt;&lt;/a&gt; - instructions for C++ SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing a pre-release Python SDK&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the correct &lt;code&gt;.whl&lt;/code&gt; from &lt;a href="https://github.com/rerun-io/rerun/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;pip install rerun_sdk&amp;lt;…&amp;gt;.whl&lt;/code&gt; (replace &lt;code&gt;&amp;lt;…&amp;gt;&lt;/code&gt; with the actual filename)&lt;/li&gt; 
 &lt;li&gt;Test it: &lt;code&gt;rerun --version&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;⚡️ &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🗂️ Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;❇️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;🐍 &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;🛠️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;🔩 Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;🏢 Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;💾 Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;⏬ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🖥️ Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juː viː/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral"&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>lumina-ai-inc/chunkr</title>
      <link>https://github.com/lumina-ai-inc/chunkr</link>
      <description>&lt;p&gt;Vision infrastructure to turn complex documents into RAG/LLM-ready data&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lumina-ai-inc/chunkr"&gt; &lt;img src="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/images/logo.svg?sanitize=true" alt="Logo" width="80" height="80"&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Chunkr | Open Source Document Intelligence API&lt;/h3&gt; 
 &lt;p align="center"&gt; Production-ready API service for document layout analysis, OCR, and semantic chunking.&lt;br&gt;Convert PDFs, PPTs, Word docs &amp;amp; images into RAG/LLM-ready chunks. &lt;br&gt;&lt;br&gt; &lt;b&gt;Layout Analysis&lt;/b&gt; | &lt;b&gt;OCR + Bounding Boxes&lt;/b&gt; | &lt;b&gt;Structured HTML and markdown&lt;/b&gt; | &lt;b&gt;VLM Processing controls&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;a href="https://www.chunkr.ai"&gt;&lt;img src="https://img.shields.io/badge/Try_it_out-chunkr.ai-blue?style=flat&amp;amp;logo=rocket&amp;amp;height=20" alt="Try it out" height="20"&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/lumina-ai-inc/chunkr/issues/new"&gt;&lt;img src="https://img.shields.io/badge/Report_Bug-GitHub_Issues-red?style=flat&amp;amp;logo=github&amp;amp;height=20" alt="Report Bug" height="20"&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#connect-with-us"&gt;&lt;img src="https://img.shields.io/badge/Contact-Get_in_Touch-green?style=flat&amp;amp;logo=mail&amp;amp;height=20" alt="Contact" height="20"&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://discord.gg/XzKWFByKzW"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;height=20" alt="Discord" height="20"&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://deepwiki.com/lumina-ai-inc/chunkr"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.chunkr.ai" width="1200" height="630"&gt; &lt;img src="https://chunkr.ai/og-image.png" style="bor"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#super-quick-start"&gt;(Super) Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#opensource-vs-commercial-api-vs-enterprise"&gt;OpenSource vs Commercial API vs Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#quick-start-with-docker-compose"&gt;Quick Start with Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#llm-configuration"&gt;LLM Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#using-modelsyaml-recommended"&gt;Using models.yaml (Recommended)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#using-environment-variables-basic"&gt;Using environment variables (Basic)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#common-llm-api-providers"&gt;Common LLM API Providers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#licensing"&gt;Licensing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#connect-with-us"&gt;Connect With Us&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;(Super) Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://www.chunkr.ai"&gt;chunkr.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Make an account and copy your API key&lt;/li&gt; 
 &lt;li&gt;Install our Python SDK:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install chunkr-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Use the SDK to process your documents:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from chunkr_ai import Chunkr

# Initialize with your API key from chunkr.ai
chunkr = Chunkr(api_key="your_api_key")

# Upload a document (URL or local file path)
url = "https://chunkr-web.s3.us-east-1.amazonaws.com/landing_page/input/science.pdf"
task = chunkr.upload(url)

# Export results in various formats
html = task.html(output_file="output.html")
markdown = task.markdown(output_file="output.md")
content = task.content(output_file="output.txt")
task.json(output_file="output.json")

# Clean up
chunkr.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.chunkr.ai"&gt;docs&lt;/a&gt; for more information and examples.&lt;/p&gt; 
&lt;h2&gt;OpenSource vs Commercial API vs Enterprise&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Source&lt;/th&gt; 
   &lt;th&gt;Commercial API&lt;/th&gt; 
   &lt;th&gt;Enterprise&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Perfect for&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Development &amp;amp; testing&lt;/td&gt; 
   &lt;td&gt;Production applications&lt;/td&gt; 
   &lt;td&gt;Large-scale/High security deployments&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Layout Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic models&lt;/td&gt; 
   &lt;td&gt;Advanced models&lt;/td&gt; 
   &lt;td&gt;Advanced + custom-tuned&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OCR Accuracy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Standard models&lt;/td&gt; 
   &lt;td&gt;Premium models&lt;/td&gt; 
   &lt;td&gt;Premium + domain-tuned&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;VLM Processing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic vision models&lt;/td&gt; 
   &lt;td&gt;Enhanced VLM models&lt;/td&gt; 
   &lt;td&gt;Enhanced + custom fine-tunes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Excel Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;❌&lt;/td&gt; 
   &lt;td&gt;✅ Native parser&lt;/td&gt; 
   &lt;td&gt;✅ Native parser&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Document Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;PDF, PPT, Word, Images&lt;/td&gt; 
   &lt;td&gt;PDF, PPT, Word, Images, Excel&lt;/td&gt; 
   &lt;td&gt;PDF, PPT, Word, Images, Excel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted&lt;/td&gt; 
   &lt;td&gt;Fully managed&lt;/td&gt; 
   &lt;td&gt;Fully managed (On-prem or Chunkr-hosted)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Discord community&lt;/td&gt; 
   &lt;td&gt;Priority email + community&lt;/td&gt; 
   &lt;td&gt;24/7 dedicated founing team support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Migration Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Community resources&lt;/td&gt; 
   &lt;td&gt;Documentation + email&lt;/td&gt; 
   &lt;td&gt;Dedicated migration team&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quick Start with Docker Compose&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Prerequisites:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.docker.com/get-docker/"&gt;Docker and Docker Compose&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"&gt;NVIDIA Container Toolkit&lt;/a&gt; (for GPU support, optional)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lumina-ai-inc/chunkr
cd chunkr
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment variables:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the example environment file
cp .env.example .env

# Configure your llm models
cp models.example.yaml models.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on how to set up LLMs, see &lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/#llm-configuration"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start the services:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For GPU deployment:
docker compose up -d

# For CPU-only deployment:
docker compose -f compose.yaml -f compose.cpu.yaml up -d

# For Mac ARM architecture (M1, M2, M3, etc.):
docker compose -f compose.yaml -f compose.cpu.yaml -f compose.mac.yaml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;Access the services:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Web UI: &lt;code&gt;http://localhost:5173&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;API: &lt;code&gt;http://localhost:8000&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Stop the services when done:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For GPU deployment:
docker compose down

# For CPU-only deployment:
docker compose -f compose.yaml -f compose.cpu.yaml down

# For Mac ARM architecture (M1, M2, M3, etc.):
docker compose -f compose.yaml -f compose.cpu.yaml -f compose.mac.yaml down
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;LLM Configuration&lt;/h2&gt; 
&lt;p&gt;Chunkr supports two ways to configure LLMs:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;models.yaml file&lt;/strong&gt;: Advanced configuration for multiple LLMs with additional options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Environment variables&lt;/strong&gt;: Simple configuration for a single LLM&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using models.yaml (Recommended)&lt;/h3&gt; 
&lt;p&gt;For more flexible configuration with multiple models, default/fallback options, and rate limits:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy the example file to create your configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp models.example.yaml models.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Edit the models.yaml file with your configuration. Example:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;models:
  - id: gpt-4o
    model: gpt-4o
    provider_url: https://api.openai.com/v1/chat/completions
    api_key: "your_openai_api_key_here"
    default: true
    rate-limit: 200 # requests per minute - optional
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Benefits of using models.yaml:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configure multiple LLM providers simultaneously&lt;/li&gt; 
 &lt;li&gt;Set default and fallback models&lt;/li&gt; 
 &lt;li&gt;Add distributed rate limits per model&lt;/li&gt; 
 &lt;li&gt;Reference models by ID in API requests (see docs for more info)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Read the &lt;code&gt;models.example.yaml&lt;/code&gt; file for more information on the available options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Using environment variables (Basic)&lt;/h3&gt; 
&lt;p&gt;You can use any OpenAI API compatible endpoint by setting the following variables in your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;LLM__KEY:
LLM__MODEL:
LLM__URL:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Common LLM API Providers&lt;/h3&gt; 
&lt;p&gt;Below is a table of common LLM providers and their configuration details to get you started:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;API URL&lt;/th&gt; 
   &lt;th&gt;Documentation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://api.openai.com/v1/chat/completions"&gt;https://api.openai.com/v1/chat/completions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/docs"&gt;OpenAI Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google AI Studio&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"&gt;https://generativelanguage.googleapis.com/v1beta/openai/chat/completions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://ai.google.dev/gemini-api/docs/openai"&gt;Google AI Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://openrouter.ai/api/v1/chat/completions"&gt;https://openrouter.ai/api/v1/chat/completions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://openrouter.ai/models"&gt;OpenRouter Models&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Self-Hosted&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8000/v1"&gt;http://localhost:8000/v1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html"&gt;VLLM&lt;/a&gt; or &lt;a href="https://ollama.com/blog/openai-compatibility"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;The core of this project is dual-licensed:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lumina-ai-inc/chunkr/main/LICENSE"&gt;GNU Affero General Public License v3.0 (AGPL-3.0)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Commercial License&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To use Chunkr without complying with the AGPL-3.0 license terms you can &lt;a href="mailto:mehul@chunkr.ai"&gt;contact us&lt;/a&gt; or visit our &lt;a href="https://chunkr.ai"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect With Us&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📧 Email: &lt;a href="mailto:mehul@chunkr.ai"&gt;mehul@chunkr.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📅 Schedule a call: &lt;a href="https://cal.com/mehulc/30min"&gt;Book a 30-minute meeting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🌐 Visit our website: &lt;a href="https://chunkr.ai"&gt;chunkr.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>valadaptive/ntsc-rs</title>
      <link>https://github.com/valadaptive/ntsc-rs</link>
      <description>&lt;p&gt;Free, open-source VHS effect. Standalone application + plugin (After Effects, Premiere, and OpenFX).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://ntsc.rs"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/img/logo-darkmode.svg"&gt; 
   &lt;img alt="ntsc-rs logo" src="https://raw.githubusercontent.com/valadaptive/ntsc-rs/main/docs/img/logo-lightmode.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;strong&gt;ntsc-rs&lt;/strong&gt; is a video effect which emulates NTSC and VHS video artifacts. It can be used as an After Effects, Premiere, or OpenFX plugin, or as a standalone application.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/valadaptive/ntsc-rs/main/docs/img/appdemo.png" alt="Screenshot of the ntsc-rs standalone application"&gt;&lt;/p&gt; 
&lt;h2&gt;Download and Install&lt;/h2&gt; 
&lt;p&gt;The latest version of ntsc-rs can be downloaded from &lt;a href="https://github.com/valadaptive/ntsc-rs/releases"&gt;the releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading, &lt;a href="https://ntsc.rs/docs/standalone-installation/"&gt;read the documentation for how to run it&lt;/a&gt;. In particular, ntsc-rs will not work properly on Linux unless you install all of the GStreamer packages listed in the documentation.&lt;/p&gt; 
&lt;h2&gt;More information&lt;/h2&gt; 
&lt;p&gt;ntsc-rs is a rough Rust port of &lt;a href="https://github.com/JargeZ/ntscqt"&gt;ntscqt&lt;/a&gt;, a PyQt-based GUI for &lt;a href="https://github.com/zhuker/ntsc"&gt;ntsc&lt;/a&gt;, itself a Python port of &lt;a href="https://github.com/joncampbell123/composite-video-simulator"&gt;composite-video-simulator&lt;/a&gt;. Reimplementing the image processing in multithreaded Rust allows it to run at (mostly) real-time speeds.&lt;/p&gt; 
&lt;p&gt;It's not an exact port--some processing passes have visibly different results, and some new ones have been added.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>eythaann/Seelen-UI</title>
      <link>https://github.com/eythaann/Seelen-UI</link>
      <description>&lt;p&gt;The Fully Customizable Desktop Environment for Windows 10/11.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/logo.svg?sanitize=true" width="44" align="top" alt="Seelen UI Logo"&gt; Seelen UI &lt;/h1&gt; 
&lt;h2 align="center"&gt; Fully Customizable Desktop Environment for Windows &lt;br&gt; Available in 70+ Languages &lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/eythaann/seelen-ui/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/eythaann/seelen-ui.svg?sanitize=true" alt="Contributors"&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/eythaann/seelen-ui.svg?sanitize=true" alt="Last Commit"&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/eythaann/seelen-ui.svg?sanitize=true" alt="Version"&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/eythaann/seelen-ui/total.svg?sanitize=true" alt="Downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/preview.png" width="100%" alt="Screenshot of Seelen UI desktop showing a customized desktop environment"&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://apps.microsoft.com/detail/Seelen%20UI/9p67c2d4t9fb?mode=full" target="_blank" rel="noopener noreferrer" aria-label="Download Seelen UI from Microsoft Store"&gt; &lt;img src="https://get.microsoft.com/images/en-us%20dark.svg?sanitize=true" width="100%" alt="Download Seelen UI from Microsoft Store"&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://discord.gg/ABfASx5ZAJ" target="_blank" rel="noopener noreferrer" aria-label="Join the Seelen UI Discord community"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/discord-alt.png" width="100%" alt="Join the Seelen UI Discord community"&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://www.digitalocean.com/?refcode=955c7335abf5&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge" target="_blank" rel="noopener noreferrer" aria-label="DigitalOcean Referral Badge"&gt; &lt;img src="https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg?sanitize=true" width="100%" alt="DigitalOcean Referral Badge"&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://seelen.io/apps/seelen-ui"&gt;Seelen UI&lt;/a&gt; is a tool designed to enhance your Windows desktop experience with a focus on customization and productivity. It integrates smoothly into your system, providing a range of features that allow you to personalize your desktop and optimize your workflow.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be Creative&lt;/strong&gt;: Seelen UI lets you tailor your desktop to fit your style and needs. You can adjust menus, widgets, icons, and other elements to create a personalized and visually appealing desktop environment.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/theme_preview.png" alt="Seelen UI Custom Theme"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhance Your Productivity&lt;/strong&gt;: Seelen UI helps you organize your desktop efficiently. With a Tiling Windows Manager, windows automatically arrange themselves to support multitasking, making your work more streamlined.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/twm_preview.png" alt="Seelen UI Tiling Window Manager"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enjoy your music&lt;/strong&gt;: With an integrated media module that's compatible with most music players, Seelen UI allows you to enjoy your music seamlessly. You can pause, resume, and skip tracks at any time without the need to open additional windows.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/media_module_preview.png" alt="Seelen UI Media Module"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be faster!&lt;/strong&gt;: With an app launcher inspired by Rofi, Seelen UI provides a simple and intuitive way to quickly access your applications and execute commands.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/app_launcher_preview.png" alt="Seelen UI App Launcher"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User-Friendly Configuration&lt;/strong&gt;: Seelen UI offers an intuitive interface for easy customization. Adjust settings such as themes, taskbar layouts, icons, etc. With just a few clicks.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/settings_preview.png" alt="Seelen UI Settings"&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] Seelen UI requires the WebView runtime to be installed. On Windows 11, it comes pre-installed with the system. However, on Windows 10, the WebView runtime is included with the &lt;code&gt;setup.exe&lt;/code&gt; installer. Additionally, Microsoft Edge is necessary to function correctly. Some users may have modified their system and removed Edge, so please ensure both Edge and the WebView runtime are installed on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] On fresh installations of Windows, the app might show a white or dark screen. You only need to update your Windows through Windows Update and restart your PC.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can choose from different installation options based on your preference:&lt;/p&gt; 
&lt;h3&gt;Microsoft Store &lt;em&gt;(recommended)&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://www.microsoft.com/store/productId/9P67C2D4T9FB?ocid=pdpshare"&gt;Store&lt;/a&gt; page. This is the recommended option because you will receive updates and a secure version of the program.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/em&gt;: It may take around 1 to 3 business days for changes to be reflected in the Microsoft Store, as updates are approved by real people in the store.&lt;/p&gt; 
&lt;h3&gt;Winget&lt;/h3&gt; 
&lt;p&gt;Install the latest version using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-pwsh"&gt;winget install --id Seelen.SeelenUI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This option also uses the signed &lt;code&gt;.msix&lt;/code&gt; package and ensures you have the latest secure version. Similar to the Microsoft Store, it may take around 1 to 3 business days for changes to be reflected in Winget, as updates are approved by real people in the &lt;code&gt;winget-pkg&lt;/code&gt; project.&lt;/p&gt; 
&lt;h3&gt;.msix Installer&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.msix&lt;/code&gt; installer from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page. This package is signed, ensuring a secure installation. This is the same option as the Microsoft Store but is a portable installer.&lt;/p&gt; 
&lt;h3&gt;.exe Installer&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page and run the &lt;code&gt;setup.exe&lt;/code&gt; installer. This option is less recommended as the installer is not signed, which may cause it to be flagged as a potential threat by some antivirus programs. The &lt;code&gt;setup.exe&lt;/code&gt; is updated more quickly than the Microsoft Store or Winget versions and also it receives notifications updates on new release.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once installed or extracted, simply open the program. The easy-to-use and intuitive GUI will guide you through the configuration process. Customize your desktop environment effortlessly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For in-depth details on various aspects of Seelen UI, explore the following documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/languages.md"&gt;Languages&lt;/a&gt; - Information regarding translations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/toolbar.md"&gt;Toolbar&lt;/a&gt; - Details about customizing and using the toolbar.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://seelen.io/blog/seelen-ui-theme-tutorial"&gt;Themes&lt;/a&gt; - Guidance on creating and applying themes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/window_manager.md"&gt;Window Manager&lt;/a&gt; - Instructions on configuring the window manager.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project&lt;/a&gt; - General information about the project and its structure.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upcoming Features&lt;/h2&gt; 
&lt;p&gt;I’m excited to share some upcoming features for Seelen UI! Here’s a glimpse of what’s planned for the future:&lt;/p&gt; 
&lt;h3&gt;&lt;del&gt;App Launcher&lt;/del&gt; ✅&lt;/h3&gt; 
&lt;p&gt;I’m planning to develop an app launcher inspired by &lt;a href="https://github.com/davatorium/rofi"&gt;Rofi&lt;/a&gt; on Linux. This feature will provide a sleek and highly customizable way to quickly access your applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/files/master/rofi/previews/colorful/main.gif" alt="App Launcher Preview"&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/dctxmei/rofi-themes"&gt;rofi-themes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Customizable Popup Widgets&lt;/h3&gt; 
&lt;p&gt;I aim to introduce a set of fully customizable popup widgets, similar to the features available in &lt;a href="https://github.com/elkowar/eww"&gt;EWW&lt;/a&gt;. These widgets will be highly configurable and adaptable to your needs, providing an enhanced and interactive way to manage your desktop environment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/widgets/main/previews/dashboard.png" alt="Customizable Widgets Preview"&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/adi1090x/widgets"&gt;adi1090x&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Alt + Tab (Task Switching)&lt;/h3&gt; 
&lt;p&gt;An upgraded Alt + Tab system for task switching is on the horizon. This will offer a more visually appealing and functional experience, allowing for smoother transitions between open applications and windows.&lt;/p&gt; 
&lt;h3&gt;Custom Virtual Desktops Viewer and Animations&lt;/h3&gt; 
&lt;p&gt;I’m also working on a custom virtual desktops viewer and dynamic animations to improve navigation between different workspaces. This will provide a more intuitive and immersive multitasking experience.&lt;/p&gt; 
&lt;p&gt;Stay tuned for more updates as I develop these features. I appreciate your support and enthusiasm!&lt;/p&gt; 
&lt;p&gt;Happy customizing!&lt;/p&gt; 
&lt;p&gt;The Seelen UI Team&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/CONTRIBUTING"&gt;Contribution Guidelines&lt;/a&gt; to get started with terms.&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project Documentation&lt;/a&gt; to understand the project structure and how to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;For inquiries and support, please contact me on &lt;a href="https://discord.gg/ABfASx5ZAJ"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;See you later&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;                   .      .&amp;amp;     _,x&amp;amp;"``
                    &amp;amp; .   &amp;amp;'  ;.&amp;amp;&amp;amp;'
              &amp;amp;.  . &amp;amp;.&amp;amp;     .0&amp;amp;&amp;amp;&amp;amp;;&amp;amp;""`
         .    '&amp;amp;  &amp;amp;.&amp;amp;&amp;amp;&amp;amp;  .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
       .&amp;amp;         ;&amp;amp;&amp;amp;&amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
      &amp;amp;&amp;amp;          &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;     &amp;amp;&amp;amp;&amp;amp;
     0&amp;amp;    .     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;""
    &amp;amp;&amp;amp;   .0     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
   0&amp;amp;&amp;amp; .&amp;amp;'     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
  :&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;    . &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; 
  0&amp;amp;&amp;amp;&amp;amp;&amp;amp;    &amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;'   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;               .&amp;amp;&amp;amp;&amp;amp;x&amp;amp;
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;   :&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0.&amp;amp;'        , .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;;.
  &amp;amp;&amp;amp;&amp;amp;&amp;amp;.  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;        .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'               .
  0&amp;amp;&amp;amp;&amp;amp;&amp;amp;  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;       ,&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;                &amp;amp;
  :&amp;amp;&amp;amp;&amp;amp;&amp;amp;; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0       ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             ;  .0
   0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0     ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             &amp;amp;  &amp;amp;;
    0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0   :',;".&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;".&amp;amp;             &amp;amp;&amp;amp; &amp;amp;0
     0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0  ',;',&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;" ,&amp;amp;'             &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
      0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0 ,x&amp;amp;&amp;amp;&amp;amp;&amp;amp;" .&amp;amp;&amp;amp;&amp;amp;              &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
        0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; .&amp;amp;&amp;amp;&amp;amp;&amp;amp;"'''"&amp;amp;&amp;amp;"&amp;amp;&amp;amp;            &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
         0&amp;amp;&amp;amp; .&amp;amp;&amp;amp;;``       `&amp;amp;: :&amp;amp;         &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
            &amp;amp;"' &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;   &amp;amp;"&amp;amp; &amp;amp;"&amp;amp;   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
              0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
                 0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0         Seelen
                      0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;p&gt;📌 &lt;strong&gt;Official Website&lt;/strong&gt;: &lt;a href="https://seelen.io"&gt;https://seelen.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Seelen Inc © 2025 - All rights reserved&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openobserve/openobserve</title>
      <link>https://github.com/openobserve/openobserve</link>
      <description>&lt;p&gt;🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces, RUM, Error tracking, Session replay).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://openobserve.ai"&gt;&lt;img src="https://openobserve.ai/img/logo/o2-logo-readme.svg?sanitize=true" alt="OpenObserve"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces).&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/openobserve/openobserve" target="_blank"&gt; &lt;img src="https://img.shields.io/github/last-commit/openobserve/openobserve" alt="Last Commit"&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/stargazers" target="_blank"&gt; &lt;img src="https://img.shields.io/github/stars/openobserve/openobserve" alt="GitHub Stars"&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/issues" target="_blank"&gt; &lt;img src="https://img.shields.io/github/issues/openobserve/openobserve" alt="GitHub Issues"&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/graphs/contributors" target="_blank"&gt; &lt;img src="https://img.shields.io/github/contributors/openobserve/openobserve" alt="Contributors"&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/releases" target="_blank"&gt; &lt;img src="https://img.shields.io/github/v/release/openobserve/openobserve" alt="GitHub Release"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.&lt;/p&gt; 
&lt;p&gt;It is straightforward and easy to operate, in contrast to Elasticsearch, which requires understanding and tuning numerous settings. Get OpenObserve up and running in under 2 minutes.&lt;/p&gt; 
&lt;p&gt;OpenObserve serves as a seamless replacement for Elasticsearch for users who ingest data using APIs and perform searches. OpenObserve comes with its own user interface, eliminating the need for separate installation.&lt;/p&gt; 
&lt;p&gt;You can reduce your log storage costs by ~140x compared to Elasticsearch by using OpenObserve. Below, we present the results from pushing logs from our production Kubernetes cluster to both Elasticsearch and OpenObserve using Fluent Bit.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_vs_es.png" alt="OpenObserve Vs Elasticsearch"&gt;&lt;/p&gt; 
&lt;h2&gt;🎥 Introduction Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4VwuC1tpRP4"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/o2_intro.webp" alt="OpenObserve Introduction"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌟 Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logs, Metrics, Traces&lt;/strong&gt;: Comprehensive support for various data types.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenTelemetry Support&lt;/strong&gt;: Full compatibility with OTLP for logs, metrics, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real User Monitoring (RUM)&lt;/strong&gt;: Includes performance tracking, error logging, and session replay.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dashboards, Reports, Alerts&lt;/strong&gt;: Features over 18 different chart types for comprehensive data visualization for on-the-fly analysis and reporting along with alerting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: Enrich, redact, reduce, normalize data on the fly. Stream processing for logs to metrics and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Embedded GUI&lt;/strong&gt;: Intuitive and user-friendly interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL and PromQL Support&lt;/strong&gt;: Query logs and traces with SQL, and metrics with SQL and PromQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary or HA Installation&lt;/strong&gt;: Install using a single binary for small deployments or in HA mode for large deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile Storage Options&lt;/strong&gt;: Supports local disk, S3, MinIO, GCS, Azure Blob Storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability and Clustering&lt;/strong&gt;: Ensures reliable and scalable performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Schema&lt;/strong&gt;: Adapts to your data structure seamlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Authentication&lt;/strong&gt;: Secure and ready to use.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of Operation&lt;/strong&gt;: Designed for simplicity and efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Upgrades&lt;/strong&gt;: Hassle-free updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multilingual UI&lt;/strong&gt;: Supports 11 languages, including English, Spanish, German, French, Chinese, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a full list of features, check the &lt;a href="https://openobserve.ai/docs/#project-status-features-and-roadmap"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;⚡️ Quick start&lt;/h2&gt; 
&lt;h3&gt;🐳 Docker:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL="root@example.com" \
      -e ZO_ROOT_USER_PASSWORD="Complexpass#123" \
      public.ecr.aws/zinclabs/openobserve:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🐙 Docker Compose:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:latest
    restart: unless-stopped
    environment:
      ZO_ROOT_USER_EMAIL: "root@example.com"
      ZO_ROOT_USER_PASSWORD: "Complexpass#123"
    ports:
      - "5080:5080"
    volumes:
      - data:/data
volumes:
  data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other ways to quickly install OpenObserve or use OpenObserve cloud, check &lt;a href="https://openobserve.ai/docs/quickstart"&gt;quickstart documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For installing OpenObserve in HA mode, check &lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;HA deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ## Enterprise Vs Open source Vs Cloud edition

OpenObserve is available in three different editions:


| Feature | Open Source (Self hosted) | Enterprise (Self hosted) | Cloud |
| --- | --- | --- | --- | 
| Logs | ✅ | ✅ | ✅ |
| Metrics | ✅ | ✅ | ✅ |
| Traces | ✅ | ✅ | ✅ |
| RUM | ✅ | ✅ | ✅ |
| Alerts | ✅ | ✅ | ✅ |
| Dashboards | ✅ | ✅ | ✅ |
| Reports | ✅ | ✅ | ✅ |
| VRL functions | ✅ | ✅ | ✅ |
| Pipelines | ✅ | ✅ | ✅ |
| High Availability | ✅ | ✅ | ✅ |
| Multitenancy (Organizations) | ✅ | ✅ | ✅ |
| Dynamic schema and schema evolution | ✅ | ✅ | ✅ |
| Advanced multilingual GUI | ✅ | ✅ | ✅ |
| Single Sign On | ❌ | ✅ | ✅ |
| Role Based Access Control (RBAC) | ❌ | ✅ | ✅ |
| Federated search / Super cluster | ❌ | ✅ | ❌ |
| Query management | ❌ | ✅ | ❌ |
| Workload management (QoS) | ❌ | ✅ | ❌ |
| Audit trail | ❌ | ✅ | ❌ |
| Ability to influence roadmap | ❌ | ✅ | ✅ on enterprise plan |
| License | AGPL | Enterprise | Cloud |
| Support | Community | Enterprise | Cloud |
| Cost | Free | If self hosted, free for up to 200 GB/Day data ingested &lt;br&gt; Paid thereafter  | Free 200 GB/Month data ingested &lt;br&gt; Paid thereafter | --&gt; 
&lt;h2&gt;📷 Screenshots&lt;/h2&gt; 
&lt;h3&gt;Home&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_home.png" alt="Home"&gt;&lt;/p&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/logs.png" alt="Logs"&gt;&lt;/p&gt; 
&lt;h3&gt;Traces (OpenTelemetry)&lt;/h3&gt; 
&lt;p&gt;Trace details page &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces.png" alt="Traces using OpenTelemetry"&gt;&lt;/p&gt; 
&lt;p&gt;Golden metrics based on traces &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces-overall.png" alt="Traces golden metrics"&gt;&lt;/p&gt; 
&lt;h3&gt;Visualizations and Dashboards&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard.png" alt="Dashboard"&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard2.png" alt="Dashboard"&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/create-panel.png" alt="Create panel"&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/map.png" alt="Map"&gt;&lt;/p&gt; 
&lt;h3&gt;Front end monitoring&lt;/h3&gt; 
&lt;p&gt;Performance analytics &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/performance.png" alt="Performance"&gt;&lt;/p&gt; 
&lt;p&gt;Session replay &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/session-replay.png" alt="Session replay"&gt;&lt;/p&gt; 
&lt;p&gt;Error tracking &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/error-tracking.png" alt="Error tracking"&gt;&lt;/p&gt; 
&lt;h3&gt;Alerts&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/alerts.png" alt="Alerts"&gt;&lt;/p&gt; 
&lt;h3&gt;Streams&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/streams.png" alt="Streams"&gt;&lt;/p&gt; 
&lt;h3&gt;Ingestion&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion1.png" alt="Ingestion"&gt;&lt;/p&gt; 
&lt;h3&gt;Pipeline&lt;/h3&gt; 
&lt;p&gt;Pipeline &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/pipeline.png" alt="Pipeline"&gt;&lt;/p&gt; 
&lt;p&gt;Function &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/function.png" alt="Function"&gt;&lt;/p&gt; 
&lt;h3&gt;IAM&lt;/h3&gt; 
&lt;p&gt;SSO (Single Sign On) &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/sso.png" alt="SSO"&gt;&lt;/p&gt; 
&lt;p&gt;RBAC (Role Based Access Control) &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/iam_rbac.png" alt="RBAC"&gt;&lt;/p&gt; 
&lt;h3&gt;SBOM&lt;/h3&gt; 
&lt;p&gt;Software Bill of Materials for OpenObserve&lt;/p&gt; 
&lt;h4&gt;Rust&lt;/h4&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/openobserve.cdx.xml"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cargo-cyclonedx:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo-cyclonedx cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;JavaScript&lt;/h4&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/web/sbom.json"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cyclonedx-npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @cyclonedx/cyclonedx-npm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd web
cyclonedx-npm &amp;gt; sbom.json         
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;⚖️ License&lt;/h2&gt; 
&lt;p&gt;OpenObserve is licensed under the AGPL-3.0 license. For more details, see the &lt;a href="https://github.com/openobserve/openobserve/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🌍 Community&lt;/h2&gt; 
&lt;h3&gt;🔗 Join OpenObserve community on Slack&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/slack.png" alt="Slack"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Easiest way to get support is to join the &lt;a href="https://short.openobserve.ai/community"&gt;Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;📱 Join OpenObserve community on WeChat&lt;/h3&gt; 
&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/wechat_qr.jpg" width="300"&gt;</description>
    </item>
    
    <item>
      <title>tauri-apps/tauri</title>
      <link>https://github.com/tauri-apps/tauri</link>
      <description>&lt;p&gt;Build smaller, faster, and more secure desktop and mobile applications with a web frontend.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/splash.png" alt="Tauri"&gt; 
&lt;p&gt;&lt;a href="https://github.com/tauri-apps/tauri/tree/dev"&gt;&lt;img src="https://img.shields.io/badge/status-stable-blue.svg?sanitize=true" alt="status"&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/License-MIT%20or%20Apache%202-green.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/tauri-apps/tauri/actions/workflows/test-core.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tauri-apps/tauri/test-core.yml?label=test%20core&amp;amp;logo=github" alt="test core"&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=shield" alt="FOSSA Status"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/tauri"&gt;&lt;img src="https://img.shields.io/badge/chat-discord-7289da.svg?sanitize=true" alt="Chat Server"&gt;&lt;/a&gt; &lt;a href="https://tauri.app"&gt;&lt;img src="https://img.shields.io/badge/website-tauri.app-purple.svg?sanitize=true" alt="website"&gt;&lt;/a&gt; &lt;a href="https://good-labs.github.io/greater-good-affirmation"&gt;&lt;img src="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg?sanitize=true" alt="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg"&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/sponsor-Open%20Collective-blue.svg?sanitize=true" alt="support"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Tauri is a framework for building tiny, blazingly fast binaries for all major desktop platforms. Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface. The backend of the application is a rust-sourced binary with an API that the front-end can interact with.&lt;/p&gt; 
&lt;p&gt;The user interface in Tauri apps currently leverages &lt;a href="https://docs.rs/tao"&gt;&lt;code&gt;tao&lt;/code&gt;&lt;/a&gt; as a window handling library on macOS, Windows, Linux, Android and iOS. To render your application, Tauri uses &lt;a href="https://github.com/tauri-apps/wry"&gt;WRY&lt;/a&gt;, a library which provides a unified interface to the system webview, leveraging WKWebView on macOS &amp;amp; iOS, WebView2 on Windows, WebKitGTK on Linux and Android System WebView on Android.&lt;/p&gt; 
&lt;p&gt;To learn more about the details of how all of these pieces fit together, please consult this &lt;a href="https://github.com/tauri-apps/tauri/raw/dev/ARCHITECTURE.md"&gt;ARCHITECTURE.md&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you are interested in making a tauri app, please visit the &lt;a href="https://tauri.app"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The quickest way to get started is to install the &lt;a href="https://v2.tauri.app/start/prerequisites/"&gt;prerequisites&lt;/a&gt; for your system and create a new project with &lt;a href="https://github.com/tauri-apps/create-tauri-app/#usage"&gt;&lt;code&gt;create-tauri-app&lt;/code&gt;&lt;/a&gt;. For example with &lt;code&gt;npm&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm create tauri-app@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The list of Tauri's features includes, but is not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in app bundler to create app bundles in formats like &lt;code&gt;.app&lt;/code&gt;, &lt;code&gt;.dmg&lt;/code&gt;, &lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, &lt;code&gt;.AppImage&lt;/code&gt; and Windows installers like &lt;code&gt;.exe&lt;/code&gt; (via NSIS) and &lt;code&gt;.msi&lt;/code&gt; (via WiX).&lt;/li&gt; 
 &lt;li&gt;Built-in self updater (desktop only)&lt;/li&gt; 
 &lt;li&gt;System tray icons&lt;/li&gt; 
 &lt;li&gt;Native notifications&lt;/li&gt; 
 &lt;li&gt;Native WebView Protocol (tauri doesn't create a localhost http(s) server to serve the WebView contents)&lt;/li&gt; 
 &lt;li&gt;GitHub action for streamlined CI&lt;/li&gt; 
 &lt;li&gt;VS Code extension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Platforms&lt;/h3&gt; 
&lt;p&gt;Tauri currently supports development and distribution on the following platforms:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Versions&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Windows&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;macOS&lt;/td&gt; 
   &lt;td align="left"&gt;10.15 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Linux&lt;/td&gt; 
   &lt;td align="left"&gt;webkit2gtk 4.0 for Tauri v1 (for example Ubuntu 18.04). webkit2gtk 4.1 for Tauri v2 (for example Ubuntu 22.04).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;iOS/iPadOS&lt;/td&gt; 
   &lt;td align="left"&gt;9 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Android&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above (currently 8 and above)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Before you start working on something, it's best to check if there is an existing issue first. It's also a good idea to stop by the Discord server and confirm with the team if it makes sense or if someone else is already working on it.&lt;/p&gt; 
&lt;p&gt;Please make sure to read the &lt;a href="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; before making a pull request.&lt;/p&gt; 
&lt;p&gt;Thank you to everyone contributing to Tauri!&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Documentation in a polyglot system is a tricky proposition. To this end, we prefer to use inline documentation in the Rust &amp;amp; JS source code as much as possible. Check out the hosting repository for the documentation site for further information: &lt;a href="https://github.com/tauri-apps/tauri-docs"&gt;https://github.com/tauri-apps/tauri-docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://crabnebula.dev" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/sponsors/crabnebula.svg?sanitize=true" alt="CrabNebula" width="283"&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For the complete list of sponsors please visit our &lt;a href="https://tauri.app#sponsors"&gt;website&lt;/a&gt; and &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Organization&lt;/h2&gt; 
&lt;p&gt;Tauri aims to be a sustainable collective based on principles that guide &lt;a href="https://sfosc.org"&gt;sustainable free and open software communities&lt;/a&gt;. To this end it has become a Programme within the &lt;a href="https://commonsconservancy.org/"&gt;Commons Conservancy&lt;/a&gt;, and you can contribute financially via &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;Code: (c) 2015 - Present - The Tauri Programme within The Commons Conservancy.&lt;/p&gt; 
&lt;p&gt;MIT or MIT/Apache 2.0 where applicable.&lt;/p&gt; 
&lt;p&gt;Logo: CC-BY-NC-ND&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original Tauri Logo Designs by &lt;a href="https://alve.io/"&gt;Alve Larsson&lt;/a&gt;, &lt;a href="https://github.com/nothingismagick"&gt;Daniel Thompson-Yvetot&lt;/a&gt; and &lt;a href="https://github.com/akryum"&gt;Guillaume Chau&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=large" alt="FOSSA Status"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>typst/typst</title>
      <link>https://github.com/typst/typst</link>
      <description>&lt;p&gt;A new markup-based typesetting system that is powerful and easy to learn.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img alt="Typst" src="https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png"&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://typst.app/docs/"&gt; &lt;img alt="Documentation" src="https://img.shields.io/website?down_message=offline&amp;amp;label=docs&amp;amp;up_color=007aff&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app%2Fdocs"&gt;&lt;/a&gt; &lt;a href="https://typst.app/"&gt; &lt;img alt="Typst App" src="https://img.shields.io/website?down_message=offline&amp;amp;label=typst.app&amp;amp;up_color=239dad&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/2uDybryKPe"&gt; &lt;img alt="Discord Server" src="https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=555"&gt;&lt;/a&gt; &lt;a href="https://github.com/typst/typst/raw/main/LICENSE"&gt; &lt;img alt="Apache-2 License" src="https://img.shields.io/badge/license-Apache%202-brightgreen"&gt;&lt;/a&gt; &lt;a href="https://typst.app/jobs/"&gt; &lt;img alt="Jobs at Typst" src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;amp;query=%24.jobs.text&amp;amp;label=jobs&amp;amp;color=%23A561FF&amp;amp;cacheSeconds=1800"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Typst is a new markup-based typesetting system that is designed to be as powerful as LaTeX while being much easier to learn and use. Typst has:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in markup for the most common formatting tasks&lt;/li&gt; 
 &lt;li&gt;Flexible functions for everything else&lt;/li&gt; 
 &lt;li&gt;A tightly integrated scripting system&lt;/li&gt; 
 &lt;li&gt;Math typesetting, bibliography management, and more&lt;/li&gt; 
 &lt;li&gt;Fast compile times thanks to incremental compilation&lt;/li&gt; 
 &lt;li&gt;Friendly error messages in case something goes wrong&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This repository contains the Typst compiler and its CLI, which is everything you need to compile Typst documents locally. For the best writing experience, consider signing up to our &lt;a href="https://typst.app/"&gt;collaborative online editor&lt;/a&gt; for free.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A &lt;a href="https://typst.app/docs/tutorial/"&gt;gentle introduction&lt;/a&gt; to Typst is available in our documentation. However, if you want to see the power of Typst encapsulated in one image, here it is:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Example" width="900" src="https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png"&gt; &lt;/p&gt; 
&lt;p&gt;Let's dissect what's going on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;em&gt;set rules&lt;/em&gt; to configure element properties like the size of pages or the numbering of headings. By setting the page height to &lt;code&gt;auto&lt;/code&gt;, it scales to fit the content. Set rules accommodate the most common configurations. If you need full control, you can also use &lt;a href="https://typst.app/docs/reference/styling/#show-rules"&gt;show rules&lt;/a&gt; to completely redefine the appearance of an element.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We insert a heading with the &lt;code&gt;= Heading&lt;/code&gt; syntax. One equals sign creates a top level heading, two create a subheading and so on. Typst has more lightweight markup like this, see the &lt;a href="https://typst.app/docs/reference/syntax/"&gt;syntax&lt;/a&gt; reference for a full list.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://typst.app/docs/reference/math/"&gt;Mathematical equations&lt;/a&gt; are enclosed in dollar signs. By adding extra spaces around the contents of an equation, we can put it into a separate block. Multi-letter identifiers are interpreted as Typst definitions and functions unless put into quotes. This way, we don't need backslashes for things like &lt;code&gt;floor&lt;/code&gt; and &lt;code&gt;sqrt&lt;/code&gt;. And &lt;code&gt;phi.alt&lt;/code&gt; applies the &lt;code&gt;alt&lt;/code&gt; modifier to the &lt;code&gt;phi&lt;/code&gt; to select a particular symbol variant.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, we get to some &lt;a href="https://typst.app/docs/reference/scripting/"&gt;scripting&lt;/a&gt;. To input code into a Typst document, we can write a hash followed by an expression. We define two variables and a recursive function to compute the n-th fibonacci number. Then, we display the results in a center-aligned table. The table function takes its cells row-by-row. Therefore, we first pass the formulas &lt;code&gt;$F_1$&lt;/code&gt; to &lt;code&gt;$F_8$&lt;/code&gt; and then the computed fibonacci numbers. We apply the spreading operator (&lt;code&gt;..&lt;/code&gt;) to both because they are arrays and we want to pass the arrays' items as individual arguments.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Text version of the code example.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-typst"&gt;#set page(width: 10cm, height: auto)
#set heading(numbering: "1.")

= Fibonacci sequence
The Fibonacci sequence is defined through the
recurrence relation $F_n = F_(n-1) + F_(n-2)$.
It can also be expressed in _closed form:_

$ F_n = round(1 / sqrt(5) phi.alt^n), quad
  phi.alt = (1 + sqrt(5)) / 2 $

#let count = 8
#let nums = range(1, count + 1)
#let fib(n) = (
  if n &amp;lt;= 2 { 1 }
  else { fib(n - 1) + fib(n - 2) }
)

The first #count numbers of the sequence are:

#align(center, table(
  columns: count,
  ..nums.map(n =&amp;gt; $F_#n$),
  ..nums.map(n =&amp;gt; str(fib(n))),
))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Typst's CLI is available from different sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can get sources and pre-built binaries for the latest release of Typst from the &lt;a href="https://github.com/typst/typst/releases/"&gt;releases page&lt;/a&gt;. Download the archive for your platform and place it in a directory that is in your &lt;code&gt;PATH&lt;/code&gt;. To stay up to date with future releases, you can simply run &lt;code&gt;typst update&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can install Typst through different package managers. Note that the versions in the package managers might lag behind the latest release.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Linux: 
    &lt;ul&gt; 
     &lt;li&gt;View &lt;a href="https://repology.org/project/typst/versions"&gt;Typst on Repology&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;View &lt;a href="https://snapcraft.io/typst"&gt;Typst's Snap&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;macOS: &lt;code&gt;brew install typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Windows: &lt;code&gt;winget install --id Typst.Typst&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you have a &lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; toolchain installed, you can install&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;the latest released Typst version with &lt;code&gt;cargo install --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;a development version with &lt;code&gt;cargo install --git https://github.com/typst/typst --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Nix users can&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use the &lt;code&gt;typst&lt;/code&gt; package with &lt;code&gt;nix-shell -p typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;build and run a development version with &lt;code&gt;nix run github:typst/typst -- --version&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Docker users can run a prebuilt image with &lt;code&gt;docker run ghcr.io/typst/typst:latest --help&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have installed Typst, you can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also watch source files and automatically recompile on changes. This is faster than compiling from scratch each time because Typst has incremental compilation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Watches source files and recompiles on changes.
typst watch file.typ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Typst further allows you to add custom font paths for your project and list all of the fonts it discovered:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other CLI subcommands and options, see below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you prefer an integrated IDE-like experience with autocompletion and instant preview, you can also check out our &lt;a href="https://typst.app/"&gt;free web app&lt;/a&gt;. Alternatively, there is a community-created language server called &lt;a href="https://myriad-dreamin.github.io/tinymist/"&gt;Tinymist&lt;/a&gt; which is integrated into various editor extensions.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The main places where the community gathers are our &lt;a href="https://forum.typst.app/"&gt;Forum&lt;/a&gt; and our &lt;a href="https://discord.gg/2uDybryKPe"&gt;Discord server&lt;/a&gt;. The Forum is a great place to ask questions, help others, and share cool things you created with Typst. The Discord server is more suitable for quicker questions, discussions about contributing, or just to chat. We'd be happy to see you there!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://typst.app/universe/"&gt;Typst Universe&lt;/a&gt; is where the community shares templates and packages. If you want to share your own creations, you can submit them to our &lt;a href="https://github.com/typst/packages/"&gt;package repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you had a bad experience in our community, please &lt;a href="https://typst.app/contact"&gt;reach out to us&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love to see contributions from the community. If you experience bugs, feel free to open an issue. If you would like to implement a new feature or bug fix, please follow the steps outlined in the &lt;a href="https://github.com/typst/typst/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To build Typst yourself, first ensure that you have the &lt;a href="https://rustup.rs/"&gt;latest stable Rust&lt;/a&gt; installed. Then, clone this repository and build the CLI with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/typst/typst
cd typst
cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The optimized binary will be stored in &lt;code&gt;target/release/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Another good way to contribute is by &lt;a href="https://github.com/typst/packages/"&gt;sharing packages&lt;/a&gt; with the community.&lt;/p&gt; 
&lt;h2&gt;Pronunciation and Spelling&lt;/h2&gt; 
&lt;p&gt;IPA: /taɪpst/. "Ty" like in &lt;strong&gt;Ty&lt;/strong&gt;pesetting and "pst" like in Hi&lt;strong&gt;pst&lt;/strong&gt;er. When writing about Typst, capitalize its name as a proper noun, with a capital "T".&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;p&gt;All of Typst has been designed with three key goals in mind: Power, simplicity, and performance. We think it's time for a system that matches the power of LaTeX, is easy to learn and use, all while being fast enough to realize instant preview. To achieve these goals, we follow three core design principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplicity through Consistency:&lt;/strong&gt; If you know how to do one thing in Typst, you should be able to transfer that knowledge to other things. If there are multiple ways to do the same thing, one of them should be at a different level of abstraction than the other. E.g. it's okay that &lt;code&gt;= Introduction&lt;/code&gt; and &lt;code&gt;#heading[Introduction]&lt;/code&gt; do the same thing because the former is just syntax sugar for the latter.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Power through Composability:&lt;/strong&gt; There are two ways to make something flexible: Have a knob for everything or have a few knobs that you can combine in many ways. Typst is designed with the second way in mind. We provide systems that you can compose in ways we've never even thought of. TeX is also in the second category, but it's a bit low-level and therefore people use LaTeX instead. But there, we don't really have that much composability. Instead, there's a package for everything (&lt;code&gt;\usepackage{knob}&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance through Incrementality:&lt;/strong&gt; All Typst language features must accommodate for incremental compilation. Luckily we have &lt;a href="https://github.com/typst/comemo/"&gt;&lt;code&gt;comemo&lt;/code&gt;&lt;/a&gt;, a system for incremental compilation which does most of the hard work in the background.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We'd like to thank everyone who is supporting Typst's development, be it via &lt;a href="https://github.com/sponsors/typst/"&gt;GitHub sponsors&lt;/a&gt; or elsewhere. In particular, special thanks[^1] go to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://posit.co/blog/posit-and-typst/"&gt;Posit&lt;/a&gt; for financing a full-time compiler engineer&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; for supporting work on Typst via multiple grants through the &lt;a href="https://nlnet.nl/core"&gt;NGI Zero Core&lt;/a&gt; fund: 
  &lt;ul&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-HTML/"&gt;HTML export&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-Accessibility/"&gt;PDF accessibility&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.science-startups.berlin/"&gt;Science &amp;amp; Startups&lt;/a&gt; for having financed Typst development from January through June 2023 via the Berlin Startup Scholarship&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/"&gt;Zerodha&lt;/a&gt; for their generous one-time sponsorship&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[^1]: This list only includes contributions for our open-source work that exceed or are expected to exceed €10K.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>category-labs/monad-bft</title>
      <link>https://github.com/category-labs/monad-bft</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monad BFT&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/monad-crypto/monad-bft/actions/workflows/randomized.yml/badge.svg?branch=master" alt="Nightly Tests"&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains implementation for the Monad consensus client and JsonRpc server. Monad consensus collects transactions and produces blocks which are written to a ledger filestream. These blocks are consumed by Monad execution, which then updates the state of the blockchain. The &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-triedb/README.md"&gt;triedb&lt;/a&gt; is a database which stores block information and the blockchain state.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;p&gt;The most straightforward way to start a consensus client + an execution client + a JsonRpc server. Run the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;cd docker/single-node&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nets/run.sh&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using Cargo&lt;/h3&gt; 
&lt;p&gt;To run a Monad consensus client, follow instructions &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-node/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To run a JsonRpc server, follow instructions &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-rpc/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;sequenceDiagram
autonumber
    participant D as Driver
    box Purple Executor
    participant S as impl Stream
    participant E as impl Executor
    end
    participant State
    participant PersistenceLogger
    loop
    D -&amp;gt;&amp;gt;+ S: CALL next()
    Note over S: blocks until event ready
    S --&amp;gt;&amp;gt;- D: RETURN Event
    D -&amp;gt;&amp;gt; PersistenceLogger: CALL push(Event)
    D -&amp;gt;&amp;gt;+ State: CALL update(Event)
    Note over State: mutate state
    State --&amp;gt;&amp;gt;- D: RETURN Vec&amp;lt;Command&amp;gt;
    D -&amp;gt;&amp;gt; E: CALL exec(Vec&amp;lt;Command&amp;gt;)
    Note over E: apply side effects
    end
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>aome510/spotify-player</title>
      <link>https://github.com/aome510/spotify-player</link>
      <description>&lt;p&gt;A Spotify player in the terminal with full feature parity&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;spotify_player&lt;/h1&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#spotify-connect"&gt;Spotify Connect&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#streaming"&gt;Streaming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#media-control"&gt;Media Control&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#image"&gt;Image&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#notify"&gt;Notify&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#mouse-support"&gt;Mouse support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#daemon"&gt;Daemon&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#fuzzy-search"&gt;Fuzzy search&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#cli-commands"&gt;CLI commands&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#commands"&gt;Commands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#configurations"&gt;Configurations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#caches"&gt;Caches&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#logging"&gt;Logging&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#acknowledgement"&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; is a fast, easy to use, and configurable terminal music player.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimalist UI with an intuitive paging and popup system.&lt;/li&gt; 
 &lt;li&gt;Highly &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md"&gt;configurable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feature parity with the official Spotify application.&lt;/li&gt; 
 &lt;li&gt;Support remote control with &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#spotify-connect"&gt;Spotify Connect&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#streaming"&gt;streaming&lt;/a&gt; songs directly from the terminal.&lt;/li&gt; 
 &lt;li&gt;Support synced lyrics.&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#media-control"&gt;cross-platform media control&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#image"&gt;image rendering&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#notify"&gt;desktop notification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Support running the application as &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#daemon"&gt;a daemon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Offer a wide range of &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#cli-commands"&gt;CLI commands&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;A demo of &lt;code&gt;spotify_player&lt;/code&gt; &lt;code&gt;v0.5.0-pre-release&lt;/code&gt; on &lt;a href="https://www.youtube.com/watch/Jbfe9GLNWbA"&gt;youtube&lt;/a&gt; or on &lt;a href="https://asciinema.org/a/446913"&gt;asciicast&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;Checkout &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/examples/README.md"&gt;examples/README.md&lt;/a&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;By default, the application's installed binary is &lt;code&gt;spotify_player&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;A Spotify Premium account is &lt;strong&gt;required&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Dependencies&lt;/h4&gt; 
&lt;h5&gt;Windows and MacOS&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust and cargo&lt;/a&gt; as the build dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Linux&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust and cargo&lt;/a&gt; as the build dependencies&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;install &lt;code&gt;openssl&lt;/code&gt;, &lt;code&gt;alsa-lib&lt;/code&gt; (&lt;code&gt;streaming&lt;/code&gt; feature), &lt;code&gt;libdbus&lt;/code&gt; (&lt;code&gt;media-control&lt;/code&gt; feature).&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For example, on Debian based systems, run the below command to install application's dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt install libssl-dev libasound2-dev libdbus-1-dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;On RHEL/Fedora based systems, run the below command to install application's dependencies :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo dnf install openssl-devel alsa-lib-devel dbus-devel
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;or if you're using &lt;code&gt;yum&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install openssl-devel alsa-lib-devel dbus-devel
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;Application's prebuilt binaries can be found in the &lt;a href="https://github.com/aome510/spotify-player/releases"&gt;Releases Page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: to run the application, Linux systems need to install additional dependencies as specified in the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#linux"&gt;Dependencies section&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;brew install spotify_player&lt;/code&gt; to install the application.&lt;/p&gt; 
&lt;h3&gt;Scoop&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;scoop install spotify-player&lt;/code&gt; to install the application.&lt;/p&gt; 
&lt;h3&gt;Cargo&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;cargo install spotify_player --locked&lt;/code&gt; to install the application from &lt;a href="https://crates.io/crates/spotify_player"&gt;crates.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Arch Linux&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;pacman -S spotify-player&lt;/code&gt; to install the application.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Defaults to PulseAudio / Pipewire audio backend. For a different one, please consider modifying the &lt;a href="https://gitlab.archlinux.org/archlinux/packaging/packages/spotify-player"&gt;official PKGBUILD&lt;/a&gt; and rebuilding it manually. See &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#audio-backend"&gt;Audio Backends&lt;/a&gt; for a list of options.&lt;/p&gt; 
&lt;h3&gt;Void Linux&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;xbps-install -S spotify-player&lt;/code&gt; to install the application.&lt;/p&gt; 
&lt;h3&gt;FreeBSD&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;pkg install spotify-player&lt;/code&gt; to install the &lt;code&gt;spotify_player&lt;/code&gt; binary from FreeBSD ports.&lt;/p&gt; 
&lt;h3&gt;NetBSD&lt;/h3&gt; 
&lt;p&gt;Using the package manager, run &lt;code&gt;pkgin install spotify-player&lt;/code&gt; to install from the official repositories.&lt;/p&gt; 
&lt;p&gt;Building from source,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd /usr/pkgsrc/audio/spotify-player
make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NixOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://search.nixos.org/packages?channel=unstable&amp;amp;show=spotify-player&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=spotify-player"&gt;spotify-player&lt;/a&gt; is available as a Nix package and can be installed via &lt;code&gt;nix-shell -p spotify-player&lt;/code&gt; or as part of your system configuration.&lt;/p&gt; 
&lt;p&gt;If you want to build the source locally you can run &lt;code&gt;nix-shell&lt;/code&gt; in the root of a checkout of the source code. The provided &lt;code&gt;shell.nix&lt;/code&gt; file will install the build prerequisites.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#streaming"&gt;streaming&lt;/a&gt; feature is disabled when using the docker image.&lt;/p&gt; 
&lt;p&gt;You can download the binary image of the latest build from the &lt;code&gt;master&lt;/code&gt; branch by running&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker pull aome510/spotify_player:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then run&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -it aome510/spotify_player:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;to run the application.&lt;/p&gt; 
&lt;p&gt;You can also use your local config folder to configure the application or your local cache folder to store the application's cache data when running the docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm \
-v $APP_CONFIG_FOLDER:/app/config/ \
-v $APP_CACHE_FOLDER:/app/cache/ \
-it aome510/spotify_player:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Spotify Connect&lt;/h3&gt; 
&lt;p&gt;To enable a full &lt;a href="https://www.spotify.com/us/connect/"&gt;Spotify connect&lt;/a&gt; support, user will need to register a Spotify application and specify the application's &lt;code&gt;client_id&lt;/code&gt; in the general configuration file as described in the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md#general"&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;More details about registering a Spotify application can be found in the &lt;a href="https://developer.spotify.com/documentation/general/guides/authorization/app-settings/"&gt;official Spotify documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When &lt;code&gt;spotify_player&lt;/code&gt; runs with your own &lt;code&gt;client_id&lt;/code&gt;, press &lt;strong&gt;D&lt;/strong&gt; (default shortcut for &lt;code&gt;SwitchDevice&lt;/code&gt; command) to get the list of available devices, then press &lt;strong&gt;enter&lt;/strong&gt; (default shortcut for &lt;code&gt;ChooseSelected&lt;/code&gt; command) to connect to the selected device.&lt;/p&gt; 
&lt;h3&gt;Streaming&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; supports streaming, which needs to be built/installed with &lt;code&gt;streaming&lt;/code&gt; feature (&lt;strong&gt;enabled&lt;/strong&gt; by default) &lt;strong&gt;and&lt;/strong&gt; with an audio backend (&lt;code&gt;rodio-backend&lt;/code&gt; by default). The streaming feature allows to &lt;code&gt;spotify_player&lt;/code&gt; to play music directly from terminal.&lt;/p&gt; 
&lt;p&gt;The application uses &lt;a href="https://github.com/librespot-org/librespot"&gt;librespot&lt;/a&gt; library to create an integrated Spotify client while running. The integrated client will register a Spotify speaker device under the &lt;code&gt;spotify-player&lt;/code&gt; name, which is accessible on the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#spotify-connect"&gt;Spotify connect&lt;/a&gt; device list.&lt;/p&gt; 
&lt;h4&gt;Audio backend&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; uses &lt;a href="https://github.com/RustAudio/rodio"&gt;rodio&lt;/a&gt; as the default &lt;a href="https://github.com/librespot-org/librespot/wiki/Audio-Backends"&gt;audio backend&lt;/a&gt;. List of available audio backends:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;alsa-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pulseaudio-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rodio-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;portaudio-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jackaudio-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rodiojack-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sdl-backend&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;gstreamer-backend&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;User can change the audio backend when building/installing the application by specifying the &lt;code&gt;--features&lt;/code&gt; option. For example, to install &lt;code&gt;spotify_player&lt;/code&gt; with &lt;code&gt;pulseaudio-backend&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --no-default-features --features pulseaudio-backend
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;needs to specify &lt;code&gt;--no-default-features&lt;/code&gt; here because &lt;code&gt;rodio-backend&lt;/code&gt; is one of the default features.&lt;/li&gt; 
 &lt;li&gt;user will need to install additional dependencies depending on the selected audio backend. More details can be found in the &lt;a href="https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies"&gt;Librespot documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;streaming&lt;/code&gt; feature can be also disabled upon installing by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Media Control&lt;/h3&gt; 
&lt;p&gt;To enable media control support, &lt;code&gt;spotify_player&lt;/code&gt; needs to be built/installed with &lt;code&gt;media-control&lt;/code&gt; feature (&lt;strong&gt;enabled&lt;/strong&gt; by default) and set the &lt;code&gt;enable_media_control&lt;/code&gt; config option to &lt;code&gt;true&lt;/code&gt; in the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md#media-control"&gt;general configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Media control support is implemented using &lt;a href="https://wiki.archlinux.org/title/MPRIS"&gt;MPRIS DBus&lt;/a&gt; on Linux and OS window event listener on Windows and MacOS.&lt;/p&gt; 
&lt;h3&gt;Image&lt;/h3&gt; 
&lt;p&gt;To enable image rendering support, &lt;code&gt;spotify_player&lt;/code&gt; needs to be built/installed with &lt;code&gt;image&lt;/code&gt; feature (&lt;strong&gt;disabled&lt;/strong&gt; by default). To install the application with &lt;code&gt;image&lt;/code&gt; feature included, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --features image
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; supports rendering image in a full resolution if the application is run on either &lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/"&gt;Kitty&lt;/a&gt; or &lt;a href="https://iterm2.com/documentation-images.html"&gt;iTerm2&lt;/a&gt;. Otherwise, the image will be displayed as &lt;a href="https://en.wikipedia.org/wiki/Block_Elements"&gt;block characters&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; also supports rendering images with &lt;code&gt;sixel&lt;/code&gt; behind &lt;code&gt;sixel&lt;/code&gt; feature flag, which also enables &lt;code&gt;image&lt;/code&gt; feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --features sixel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not all terminals supported by &lt;a href="https://github.com/saitoha/libsixel"&gt;libsixel&lt;/a&gt; are supported by &lt;code&gt;spotify_player&lt;/code&gt; as it relies on a &lt;a href="https://github.com/atanunq/viuer"&gt;third-party library&lt;/a&gt; for image rendering. A possible list of supported terminals can be found in &lt;a href="https://github.com/atanunq/viuer/raw/dc81f44a97727e04be0b000712e9233c92116ff8/src/printer/sixel.rs#L83-L95"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Images rendered by &lt;code&gt;sixel&lt;/code&gt; can have a &lt;em&gt;weird&lt;/em&gt; scale. It's recommended to tweak the &lt;code&gt;cover_img_scale&lt;/code&gt; config option to get the best result as the scaling works differently with different terminals and fonts.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples of image rendering:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;iTerm2:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/40011582/172966798-0aadc431-b0c3-4433-adf3-7526684fc2a0.png" alt="iTerm2"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Kitty:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/40011582/172967028-8cfb2daa-1642-499a-a5bf-8ed77f2b3fac.png" alt="kitty"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sixel (&lt;code&gt;foot&lt;/code&gt; terminal, &lt;code&gt;cover_img_scale=1.8&lt;/code&gt;):&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/40011582/219880331-58ac1c30-bbb0-4c99-a6cc-e5b7c9c81455.png" alt="sixel"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Others:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/40011582/172967325-d2098037-e19e-440a-a38a-5b076253ecb1.png" alt="others"&gt;&lt;/p&gt; 
&lt;h4&gt;Pixelate&lt;/h4&gt; 
&lt;p&gt;If your terminal supports high-res images, but you like the pixelated look you can enable the &lt;code&gt;pixelate&lt;/code&gt; feature, which also enables the &lt;code&gt;image&lt;/code&gt; feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --features pixelate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The amount of pixels can be tweaked via the &lt;code&gt;cover_img_pixels&lt;/code&gt; config option.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;code&gt;cover_img_pixels&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;8&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;16&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;32&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;64&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;example&lt;/td&gt; 
   &lt;td&gt;&lt;img width="100" alt="8x8" src="https://github.com/user-attachments/assets/4137aaea-ce28-4019-8cd5-2d14327e72e4"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img width="100" alt="16x16" src="https://github.com/user-attachments/assets/0ca94748-093a-468c-8fb3-1f5639666eb6"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img width="100" alt="32x32" src="https://github.com/user-attachments/assets/f5d0f2da-0439-47e4-91c9-3a2aa73ac90c"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img width="100" alt="64x64" src="https://github.com/user-attachments/assets/d06ef731-38fa-424d-9672-313f56c193d0"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To temporarily disable the &lt;code&gt;pixelate&lt;/code&gt; feature just set &lt;code&gt;cover_img_pixels&lt;/code&gt; to a high value like &lt;code&gt;512&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Notify&lt;/h3&gt; 
&lt;p&gt;To enable desktop notification support, &lt;code&gt;spotify_player&lt;/code&gt; needs to be built/installed with &lt;code&gt;notify&lt;/code&gt; feature (&lt;strong&gt;disabled&lt;/strong&gt; by default). To install the application with &lt;code&gt;notify&lt;/code&gt; feature included, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --features notify
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: the notification support in &lt;code&gt;MacOS&lt;/code&gt; and &lt;code&gt;Windows&lt;/code&gt; are quite restricted compared to &lt;code&gt;Linux&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Mouse support&lt;/h3&gt; 
&lt;p&gt;Currently, the only supported use case for mouse is to seek to a position of the current playback by left-clicking to such position in the playback's progress bar.&lt;/p&gt; 
&lt;h3&gt;Daemon&lt;/h3&gt; 
&lt;p&gt;To enable a &lt;a href="https://en.wikipedia.org/wiki/Daemon_(computing)"&gt;daemon&lt;/a&gt; support, &lt;code&gt;spotify_player&lt;/code&gt; needs to be built/installed with &lt;code&gt;daemon&lt;/code&gt; feature (&lt;strong&gt;disabled&lt;/strong&gt; by default). To install the application with &lt;code&gt;daemon&lt;/code&gt; feature included, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --features daemon
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run the application as a daemon by specifying the &lt;code&gt;-d&lt;/code&gt; or &lt;code&gt;--daemon&lt;/code&gt; option: &lt;code&gt;spotify_player -d&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;daemon&lt;/code&gt; feature is not supported on Windows&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;daemon&lt;/code&gt; feature requires the &lt;code&gt;streaming&lt;/code&gt; feature to be enabled and the application to be built with &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/#audio-backend"&gt;an audio backend&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;because of the OS's restrictions, &lt;code&gt;daemon&lt;/code&gt; feature doesn't work with the &lt;code&gt;media-control&lt;/code&gt; feature on MacOS, which is &lt;strong&gt;enabled by default&lt;/strong&gt;. In other words, if you want to use the &lt;code&gt;daemon&lt;/code&gt; feature on MacOS, you must install the application with &lt;code&gt;media-control&lt;/code&gt; feature &lt;strong&gt;disabled&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install spotify_player --no-default-features --features daemon,rodio-backend
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fuzzy search&lt;/h3&gt; 
&lt;p&gt;To enable &lt;a href="https://en.wikipedia.org/wiki/Approximate_string_matching"&gt;fuzzy search&lt;/a&gt; support, &lt;code&gt;spotify_player&lt;/code&gt; needs to be built/installed with &lt;code&gt;fzf&lt;/code&gt; feature (&lt;strong&gt;disabled&lt;/strong&gt; by default).&lt;/p&gt; 
&lt;h3&gt;CLI Commands&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; offers several CLI commands to interact with Spotify:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;get&lt;/code&gt;: Get Spotify data (playlist/album/artist data, user's data, etc)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback&lt;/code&gt;: Interact with the playback (start a playback, play-pause, next, etc)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;search&lt;/code&gt;: Search spotify&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;connect&lt;/code&gt;: Connect to a Spotify device&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like&lt;/code&gt;: Like currently playing track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;authenticate&lt;/code&gt;: Authenticate the application&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt;: Playlist editing (new, delete, import, fork, etc)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details, run &lt;code&gt;spotify_player -h&lt;/code&gt; or &lt;code&gt;spotify_player {command} -h&lt;/code&gt;, in which &lt;code&gt;{command}&lt;/code&gt; is a CLI command.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;When using the CLI for the first time, you'll need to run &lt;code&gt;spotify_player authenticate&lt;/code&gt; to authenticate the application beforehand.&lt;/li&gt; 
 &lt;li&gt;Under the hood, CLI command is handled by sending requests to a &lt;code&gt;spotify_player&lt;/code&gt; client socket running on port &lt;code&gt;client_port&lt;/code&gt;, &lt;a href="https://github.com/aome510/spotify-player/raw/master/docs/config.md#general"&gt;a general application configuration&lt;/a&gt; with a default value of &lt;code&gt;8080&lt;/code&gt;. If there is no running application's instance, a new client will be created upon handling the CLI commands, which increases the latency of the command.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Scripting&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;spotify_player&lt;/code&gt; command-line interface makes scripting easy. With the &lt;code&gt;search&lt;/code&gt; subcommand, you can search Spotify and retrieve data in JSON format, enabling queries with tools like &lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here’s an example of starting playback for the first track from a search query:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;read -p "Search spotify: " query
spotify_player playback start track --id $(spotify_player search "$query" | jq '.tracks.[0].id' | xargs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;p&gt;To go to the shortcut help page, press &lt;code&gt;?&lt;/code&gt; or &lt;code&gt;C-h&lt;/code&gt; (default shortcuts for &lt;code&gt;OpenCommandHelp&lt;/code&gt; command).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can search in the shortcut help page (and some other pages) using &lt;code&gt;Search&lt;/code&gt; command&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;RefreshPlayback&lt;/code&gt; can be used to manually update the playback status.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;RestartIntegratedClient&lt;/code&gt; is useful when user wants to switch to another audio device (headphone, earphone, etc) without restarting the application, as the integrated client will be re-initialized with the new device.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;List of supported commands:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default shortcuts&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;NextTrack&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;next track&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;n&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PreviousTrack&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;previous track&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;p&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ResumePause&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;resume/pause based on the current playback&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;space&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PlayRandom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;play a random track in the current context&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Repeat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;cycle the repeat mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ToggleFakeTrackRepeatMode&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;toggle fake track repeat mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;M-r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Shuffle&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;toggle the shuffle mode&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-s&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VolumeChange&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;change playback volume by an offset (default shortcuts use 5%)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Mute&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;toggle playback volume between 0% and previous level&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;_&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SeekForward&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;seek forward by 5s&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;gt;&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SeekBackward&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;seek backward by 5s&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Quit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;quit the application&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-c&lt;/code&gt;, &lt;code&gt;q&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ClosePopup&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;close a popup&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;esc&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SelectNextOrScrollDown&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the next item in a list/table or scroll down (supports vim-style count: 5j)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;j&lt;/code&gt;, &lt;code&gt;C-n&lt;/code&gt;, &lt;code&gt;down&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SelectPreviousOrScrollUp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the previous item in a list/table or scroll up (supports vim-style count: 10k)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;k&lt;/code&gt;, &lt;code&gt;C-p&lt;/code&gt;, &lt;code&gt;up&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PageSelectNextOrScrollDown&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the next page item in a list/table or scroll a page down (supports vim-style count: 3C-f)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;page_down&lt;/code&gt;, &lt;code&gt;C-f&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PageSelectPreviousOrScrollUp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the previous page item in a list/table or scroll a page up (supports vim-style count: 2C-b)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;page_up&lt;/code&gt;, &lt;code&gt;C-b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SelectFirstOrScrollToTop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the first item in a list/table or scroll to the top&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g g&lt;/code&gt;, &lt;code&gt;home&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SelectLastOrScrollToBottom&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;select the last item in a list/table or scroll to the bottom&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;G&lt;/code&gt;, &lt;code&gt;end&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ChooseSelected&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;choose the selected item&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;enter&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;RefreshPlayback&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;manually refresh the current playback&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;RestartIntegratedClient&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;restart the integrated client (&lt;code&gt;streaming&lt;/code&gt; feature only)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;R&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ShowActionsOnSelectedItem&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup showing actions on a selected item&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g a&lt;/code&gt;, &lt;code&gt;C-space&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ShowActionsOnCurrentTrack&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup showing actions on the current track&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;a&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AddSelectedItemToQueue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;add the selected item to queue&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Z&lt;/code&gt;, &lt;code&gt;C-z&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FocusNextWindow&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;focus the next focusable window (if any)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tab&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FocusPreviousWindow&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;focus the previous focusable window (if any)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;backtab&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SwitchTheme&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for switching theme&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;T&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SwitchDevice&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for switching device&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;D&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for searching in the current page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BrowseUserPlaylists&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for browsing user's playlists&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;u p&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BrowseUserFollowedArtists&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for browsing user's followed artists&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;u a&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BrowseUserSavedAlbums&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a popup for browsing user's saved albums&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;u A&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CurrentlyPlayingContextPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the currently playing context page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g space&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;TopTrackPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the user top track page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g t&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;RecentlyPlayedTrackPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the user recently played track page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LikedTrackPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the user liked track page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g y&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LyricsPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the lyrics page of the current track&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g L&lt;/code&gt;, &lt;code&gt;l&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LibraryPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the user library page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g l&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SearchPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the search page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g s&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BrowsePage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the browse page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;Queue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the queue page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;z&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OpenCommandHelp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the command help page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?&lt;/code&gt;, &lt;code&gt;C-h&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PreviousPage&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;go to the previous page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;backspace&lt;/code&gt;, &lt;code&gt;C-q&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OpenSpotifyLinkFromClipboard&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;open a Spotify link from clipboard&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;O&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortTrackByTitle&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the track table (if any) by track's title&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s t&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortTrackByArtists&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the track table (if any) by track's artists&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s a&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortTrackByAlbum&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the track table (if any) by track's album&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s A&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortTrackByAddedDate&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the track table (if any) by track's added date&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s D&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortTrackByDuration&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the track table (if any) by track's duration&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s d&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortLibraryAlphabetically&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the library alphabetically&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s l a&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SortLibraryByRecent&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;sort the library (playlists and albums) by recently added items&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s l r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ReverseOrder&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;reverse the order of the track table (if any)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;s r&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;MovePlaylistItemUp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;move playlist item up one position&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-k&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;MovePlaylistItemDown&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;move playlist item down one position&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-j&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CreatePlaylist&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;create a new playlist&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;N&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;JumpToCurrentTrackInContext&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;jump to the current track in the context&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;g c&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;JumpToHighlightTrackInContext&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;jump to the currently highlighted search result in the context&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C-g&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To add new shortcuts or modify the default shortcuts, please refer to the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md#keymaps"&gt;keymaps section&lt;/a&gt; in the configuration documentation.&lt;/p&gt; 
&lt;h3&gt;Actions&lt;/h3&gt; 
&lt;p&gt;A general list of actions is available; however, not all Spotify items (track, album, artist, or playlist) implement each action. To get the list of available actions on an item, call the &lt;code&gt;ShowActionsOnCurrentTrack&lt;/code&gt; command or the &lt;code&gt;ShowActionsOnSelectedItem&lt;/code&gt; command, then press enter (default binding for the &lt;code&gt;ChooseSelected&lt;/code&gt; command) to initiate the selected action. Some actions may not appear in the popup but can be bound to a shortcut.&lt;/p&gt; 
&lt;p&gt;List of available actions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GoToArtist&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GoToAlbum&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GoToRadio&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AddToLibrary&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AddToPlaylist&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AddToQueue&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AddToLiked&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DeleteFromLiked&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DeleteFromLibrary&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DeleteFromPlaylist&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ShowActionsOnAlbum&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ShowActionsOnArtist&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ShowActionsOnShow&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ToggleLiked&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;CopyLink&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Follow&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Unfollow&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These actions can also be bound to a shortcut. To add new shortcuts, please refer to the &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md#actions"&gt;actions section&lt;/a&gt; in the configuration documentation.&lt;/p&gt; 
&lt;h3&gt;Search Page&lt;/h3&gt; 
&lt;p&gt;When first entering the search page, the application focuses on the search input. User can then input text, delete one character backward using &lt;code&gt;backspace&lt;/code&gt;, or search the text using &lt;code&gt;enter&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To move the focus from the search input to the other windows such as track results, album results, etc, use &lt;code&gt;FocusNextWindow&lt;/code&gt; or &lt;code&gt;FocusPreviousWindow&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Configurations&lt;/h2&gt; 
&lt;p&gt;By default, &lt;code&gt;spotify_player&lt;/code&gt; will look into &lt;code&gt;$HOME/.config/spotify-player&lt;/code&gt; for application's configuration files. This can be changed by either specifying &lt;code&gt;-c &amp;lt;FOLDER_PATH&amp;gt;&lt;/code&gt; or &lt;code&gt;--config-folder &amp;lt;FOLDER_PATH&amp;gt;&lt;/code&gt; option.&lt;/p&gt; 
&lt;p&gt;If an application configuration file is not found, one will be created with default values.&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/docs/config.md"&gt;the configuration documentation&lt;/a&gt; for more details on the configuration options.&lt;/p&gt; 
&lt;h2&gt;Caches&lt;/h2&gt; 
&lt;p&gt;By default, &lt;code&gt;spotify_player&lt;/code&gt; will look into &lt;code&gt;$HOME/.cache/spotify-player&lt;/code&gt; for application's cache files, which include log files, Spotify's authorization credentials, audio cache files, etc. This can be changed by either specifying &lt;code&gt;-C &amp;lt;FOLDER_PATH&amp;gt;&lt;/code&gt; or &lt;code&gt;--cache-folder &amp;lt;FOLDER_PATH&amp;gt;&lt;/code&gt; option.&lt;/p&gt; 
&lt;h3&gt;Logging&lt;/h3&gt; 
&lt;p&gt;The application stores logs inside the &lt;code&gt;$APP_CACHE_FOLDER/spotify-player-*.log&lt;/code&gt; file. For debugging or submitting an issue, user can also refer to the backtrace file in &lt;code&gt;$APP_CACHE_FOLDER/spotify-player-*.backtrace&lt;/code&gt;, which includes the application's backtrace in case of panics/unexpected errors.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; uses &lt;code&gt;RUST_LOG&lt;/code&gt; environment variable to define the application's &lt;a href="https://docs.rs/log/0.4.14/log/enum.Level.html"&gt;logging level&lt;/a&gt;. &lt;code&gt;RUST_LOG&lt;/code&gt; is default to be &lt;code&gt;spotify_player=INFO&lt;/code&gt;, which only shows the application's logs.&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;spotify_player&lt;/code&gt; is written in &lt;a href="https://www.rust-lang.org"&gt;Rust&lt;/a&gt; and is built on top of awesome libraries such as &lt;a href="https://github.com/ratatui/ratatui"&gt;ratatui&lt;/a&gt;, &lt;a href="https://github.com/ramsayleung/rspotify"&gt;rspotify&lt;/a&gt;, &lt;a href="https://github.com/librespot-org/librespot"&gt;librespot&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/aome510/spotify-player/master/spotify_player/Cargo.toml"&gt;many more&lt;/a&gt;. It's highly inspired by &lt;a href="https://github.com/Rigellute/spotify-tui"&gt;spotify-tui&lt;/a&gt; and &lt;a href="https://github.com/hrkfdn/ncspot"&gt;ncspot&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seanmonstar/warp</title>
      <link>https://github.com/seanmonstar/warp</link>
      <description>&lt;p&gt;A super-easy, composable, web server framework for warp speeds.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;warp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/warp"&gt;&lt;img src="https://img.shields.io/crates/v/warp.svg?sanitize=true" alt="crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/warp"&gt;&lt;img src="https://docs.rs/warp/badge.svg?sanitize=true" alt="Released API docs"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/seanmonstar/warp/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed"&gt;&lt;/a&gt; &lt;a href="https://github.com/seanmonstar/warp/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/seanmonstar/warp/workflows/CI/badge.svg?sanitize=true" alt="GHA Build Status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RFsPjyt"&gt;&lt;img src="https://img.shields.io/discord/500028886025895936.svg?logo=discord" alt="Discord chat"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A super-easy, composable, web server framework for warp speeds.&lt;/p&gt; 
&lt;p&gt;The fundamental building block of &lt;code&gt;warp&lt;/code&gt; is the &lt;code&gt;Filter&lt;/code&gt;: they can be combined and composed to express rich requirements on requests.&lt;/p&gt; 
&lt;p&gt;Thanks to its &lt;code&gt;Filter&lt;/code&gt; system, warp provides these out of the box:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Path routing and parameter extraction&lt;/li&gt; 
 &lt;li&gt;Header requirements and extraction&lt;/li&gt; 
 &lt;li&gt;Query string deserialization&lt;/li&gt; 
 &lt;li&gt;JSON and Form bodies&lt;/li&gt; 
 &lt;li&gt;Multipart form data&lt;/li&gt; 
 &lt;li&gt;Static Files and Directories&lt;/li&gt; 
 &lt;li&gt;Websockets&lt;/li&gt; 
 &lt;li&gt;Access logging&lt;/li&gt; 
 &lt;li&gt;Gzip, Deflate, and Brotli compression&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Since it builds on top of &lt;a href="https://hyper.rs"&gt;hyper&lt;/a&gt;, you automatically get:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HTTP/1&lt;/li&gt; 
 &lt;li&gt;HTTP/2&lt;/li&gt; 
 &lt;li&gt;Asynchronous&lt;/li&gt; 
 &lt;li&gt;One of the fastest HTTP implementations&lt;/li&gt; 
 &lt;li&gt;Tested and &lt;strong&gt;correct&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;Add warp and Tokio to your dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;tokio = { version = "1", features = ["full"] }
warp = { version = "0.4", features = ["server"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then get started in your &lt;code&gt;main.rs&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use warp::Filter;

#[tokio::main]
async fn main() {
    // GET /hello/warp =&amp;gt; 200 OK with body "Hello, warp!"
    let hello = warp::path!("hello" / String)
        .map(|name| format!("Hello, {}!", name));

    warp::serve(hello)
        .run(([127, 0, 0, 1], 3030))
        .await;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information you can check the &lt;a href="https://docs.rs/warp"&gt;docs&lt;/a&gt; or the &lt;a href="https://github.com/seanmonstar/warp/tree/master/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tensorzero/tensorzero</title>
      <link>https://github.com/tensorzero/tensorzero</link>
      <description>&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" alt="TensorZero Logo" width="128" height="128"&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;h1&gt;TensorZero&lt;/h1&gt; 
&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://www.tensorzero.com/github-trending-badge.svg?sanitize=true" alt="#1 Repository Of The Day"&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TensorZero is an open-source stack for &lt;em&gt;industrial-grade LLM applications&lt;/em&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gateway:&lt;/strong&gt; access every LLM provider through a unified API, built for performance (&amp;lt;1ms p99 latency)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; store inferences and feedback in your database, available programmatically or in the UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimization:&lt;/strong&gt; collect metrics and human feedback to optimize prompts, models, and inference strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation:&lt;/strong&gt; benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experimentation:&lt;/strong&gt; ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take what you need, adopt incrementally, and complement with other tools.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/" target="_blank"&gt;Website&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs" target="_blank"&gt;Docs&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.x.com/tensorzero" target="_blank"&gt;Twitter&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/slack" target="_blank"&gt;Slack&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/discord" target="_blank"&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart" target="_blank"&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank"&gt;API Reference&lt;/a&gt;&lt;/b&gt; · &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt; 1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br&gt; 2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br&gt; 3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Here's a case study: &lt;b&gt;&lt;a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms"&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;🌐 LLM Gateway&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Access every major LLM provider (API or self-hosted) through a single unified API&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Infer with streaming, tool use, structured generation (JSON mode), batch, multimodal (VLMs), file inputs, caching, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Define prompt templates and schemas to enforce a consistent, typed interface between your application and the LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Satisfy extreme throughput and latency needs, thanks to 🦀 Rust: &amp;lt;1ms p99 latency overhead at 10k+ QPS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Integrate using our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API (use any programming language)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Ensure high availability with routing, retries, fallbacks, load balancing, granular timeouts, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: embeddings; real-time voice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway natively supports: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock"&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker"&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure"&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks"&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic"&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini"&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini"&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/groq"&gt;Groq&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic"&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral"&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai"&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/sglang"&gt;SGLang&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/tgi"&gt;TGI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/together"&gt;Together AI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm"&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; &lt;em&gt; Need something else? Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible"&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;. &lt;/em&gt; &lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway supports advanced features like: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks"&gt;Retries &amp;amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations"&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas"&gt;Prompt Templates &amp;amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/experimentation/"&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/configuration-reference"&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference"&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference"&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching"&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback"&gt;Metrics &amp;amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/episodes"&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;em&gt;&amp;amp; a lot more...&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; The TensorZero Gateway is written in Rust 🦀 with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS). See &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br&gt; &lt;/p&gt; &lt;p&gt; You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;. &lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python — TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Try other providers easily: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python — OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Python client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about artificial intelligence.",
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) — OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Node client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions →&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-ts"&gt;import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Write a haiku about artificial intelligence.",
    },
  ],
});
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms — HTTP API&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions →&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Write a haiku about artificial intelligence."
        }
      ]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;🔍 LLM Observability&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time — all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Store inferences and feedback (metrics, human edits, etc.) in your own database&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Build datasets for optimization, evaluation, and other workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Replay historical inferences with new prompts, models, inference strategies, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Export OpenTelemetry (OTLP) traces to your favorite general-purpose observability tool&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability » Inference&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability » Function&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;h3&gt;📈 LLM Optimization&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies — using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your models with supervised fine-tuning, RLHF, and other techniques&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your prompts with automated prompt engineering algorithms like MIPROv2&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your inference strategy with dynamic in-context learning, chain of thought, best/mixture-of-N sampling, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enable a feedback loop for your LLMs: a data &amp;amp; learning flywheel turning production data into smarter, faster, and cheaper models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: programmatic optimization; synthetic data generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Model Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Supervised Fine-tuning — UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Preference Fine-tuning (DPO) — Jupyter Notebook&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; 
&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling"&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot"&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h4&gt;Prompt Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool — here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h3&gt;📊 LLM Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Evaluate individual inferences with &lt;em&gt;static evaluations&lt;/em&gt; powered by heuristics or LLM judges (≈ unit tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Evaluate end-to-end workflows with &lt;em&gt;dynamic evaluations&lt;/em&gt; with complete flexibility (≈ integration tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize LLM judges just like any other TensorZero function to align them to human preferences&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: more built-in evaluators; headless evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation » UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation » CLI&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
semantic_match: 0.98 ± 0.01
item_count: 7.15 ± 0.39&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;🧪 LLM Experimentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Ship with confidence with built-in A/B testing for models, prompts, providers, hyperparameters, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enforce principled experiments (RCTs) in complex workflows, including multi-turn and compound LLM systems&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: multi-armed bandits; AI-managed experiments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&amp;amp; more!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Build simple applications or massive deployments with GitOps-friendly orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Extend TensorZero with built-in escape hatches, programmatic-first usage, direct database access, and more&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: UI playground&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb"&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it's easy to set up an LLM application with TensorZero.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href="https://www.tensorzero.com/slack"&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://www.tensorzero.com/discord"&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href="mailto:hello@tensorzero.com"&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Work with us.&lt;/strong&gt; We're &lt;strong&gt;&lt;a href="https://www.tensorzero.com/jobs"&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;. We'd also welcome &lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/raw/main/CONTRIBUTING.md"&gt;open-source contributions&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero's data &amp;amp; learning flywheel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner"&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task — at a fraction of the cost and latency — using a small amount of training data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/"&gt;Agentic RAG — Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences"&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You'll see TensorZero's "data flywheel in a box" in action: better variants leads to better data, and better data leads to better variants. You'll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/"&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool — here, DSPy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>risingwavelabs/risingwave</title>
      <link>https://github.com/risingwavelabs/risingwave</link>
      <description>&lt;p&gt;Real-time event streaming platform. real-time data ingestion, stream processing, online serving, and data management.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source srcset=".github/RisingWave-logo-dark.svg" width="500px" media="(prefers-color-scheme: dark)"&gt; 
  &lt;img src="https://raw.githubusercontent.com/risingwavelabs/risingwave/main/.github/RisingWave-logo-light.svg?sanitize=true" width="500px"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;🌊 Ride the Wave of Streaming Data.&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.risingwave.com/"&gt;Docs&lt;/a&gt; | &lt;a href="https://docs.risingwave.com/get-started/rw-benchmarks-stream-processing"&gt;Benchmarks&lt;/a&gt; | &lt;a href="https://docs.risingwave.com/demos/overview"&gt;Demos&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/risingwavelabs/risingwave/releases/latest" target="_blank"&gt; &lt;img alt="Release" src="https://img.shields.io/github/v/release/risingwavelabs/risingwave.svg?sort=semver"&gt; &lt;/a&gt; 
 &lt;a href="https://go.risingwave.com/slack" target="_blank"&gt; &lt;img alt="Slack" src="https://badgen.net/badge/Slack/Join%20RisingWave/0abd59?icon=slack"&gt; &lt;/a&gt; 
 &lt;a href="https://x.com/risingwavelabs" target="_blank"&gt; &lt;img alt="X" src="https://img.shields.io/twitter/follow/risingwavelabs"&gt; &lt;/a&gt; 
 &lt;a href="https://www.youtube.com/@risingwave-labs" target="_blank"&gt; &lt;img alt="YouTube" src="https://img.shields.io/youtube/channel/views/UCsHwdyBRxBpmkA5RRd0YNEA"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;RisingWave is a real-time event streaming platform designed to offer the &lt;i&gt;&lt;b&gt;simplest&lt;/b&gt;&lt;/i&gt; and &lt;i&gt;&lt;b&gt;most cost-effective&lt;/b&gt;&lt;/i&gt; way to &lt;b&gt;process&lt;/b&gt;, &lt;b&gt;analyze&lt;/b&gt;, and &lt;b&gt;manage&lt;/b&gt; real-time event data — with built-in support for the &lt;a href="https://iceberg.apache.org/"&gt;Apache Iceberg™&lt;/a&gt; open table format. It provides both a Postgres-compatible &lt;a href="https://docs.risingwave.com/sql/overview"&gt;SQL interface&lt;/a&gt; and a DataFrame-style &lt;a href="https://docs.risingwave.com/python-sdk/intro"&gt;Python interface&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RisingWave can &lt;b&gt;ingest&lt;/b&gt; millions of events per second, continuously &lt;b&gt;join and analyze&lt;/b&gt; live streams with historical data, &lt;b&gt;serve&lt;/b&gt; ad-hoc queries at low latency, and &lt;b&gt;persist&lt;/b&gt; fresh, consistent results to Apache Iceberg™ or any other downstream system.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/risingwavelabs/risingwave/main/docs/dev/src/images/architecture_20250609.jpg" alt="RisingWave"&gt;&lt;/p&gt; 
&lt;h2&gt;Try it out in 60 seconds&lt;/h2&gt; 
&lt;p&gt;Install RisingWave standalone mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -L https://risingwave.com/sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To learn about other installation options, such as using a Docker image, see &lt;a href="https://docs.risingwave.com/docs/current/get-started/"&gt;Quick Start&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stream, Store, and Query — All in One&lt;/h2&gt; 
&lt;p&gt;RisingWave delivers a full &lt;strong&gt;end-to-end streaming data platform&lt;/strong&gt; — combining real-time processing with built-in storage and open-format persistence.&lt;/p&gt; 
&lt;p&gt;It supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ingestion:&lt;/strong&gt; Ingest millions of events per second from streaming and batch sources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stream processing:&lt;/strong&gt; Perform real-time incremental processing to join and analyze live data with historical tables.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Delivery:&lt;/strong&gt; Deliver fresh, consistent results to data lakes (e.g., Apache Iceberg™) or any destination.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;What sets RisingWave apart is its integrated storage engine:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Online serving:&lt;/strong&gt; Row-based storage optimized for point and range queries with single-digit millisecond latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Offline persistence:&lt;/strong&gt; Built-in Apache Iceberg™ integration for low-cost, durable storage with open access for external query engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With RisingWave, real-time data isn’t just processed — it’s stored, queried, and shared across your entire stack.&lt;/p&gt; 
&lt;h2&gt;Key design decisions&lt;/h2&gt; 
&lt;p&gt;RisingWave is designed to be easier to use and more cost-efficient:&lt;/p&gt; 
&lt;h3&gt;PostgreSQL compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless integration:&lt;/strong&gt; Connects via the PostgreSQL wire protocol, working with psql, JDBC, and any Postgres tool.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expressive SQL:&lt;/strong&gt; Supports structured, semi-structured, and unstructured data with a familiar SQL dialect.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No manual state tuning:&lt;/strong&gt; Eliminates complex state management configurations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;S3 as primary storage&lt;/h3&gt; 
&lt;p&gt;RisingWave stores tables, materialized views, and internal states of stream processing jobs in S3 (or equivalent object storage), providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High performance:&lt;/strong&gt; Optimized for complex queries, including joins and time windowing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast recovery:&lt;/strong&gt; Restores from system failures within seconds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.risingwave.com/deploy/k8s-cluster-scaling"&gt;Dynamic scaling&lt;/a&gt;:&lt;/strong&gt; Instantly adjusts resources to handle workload spikes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Elastic disk cache&lt;/h3&gt; 
&lt;p&gt;Beyond caching hot data in memory, RisingWave supports &lt;a href="https://docs.risingwave.com/get-started/disk-cache"&gt;&lt;strong&gt;elastic disk cache&lt;/strong&gt;&lt;/a&gt;, a powerful performance optimization that uses local disks or EBS for efficient data caching. This minimizes access to S3, lowering processing latency and cutting S3 access costs.&lt;/p&gt; 
&lt;h3&gt;Apache Iceberg™ native support&lt;/h3&gt; 
&lt;p&gt;RisingWave &lt;a href="https://docs.risingwave.com/iceberg/overview"&gt;&lt;strong&gt;natively integrates with Apache Iceberg™&lt;/strong&gt;&lt;/a&gt;, enabling continuous ingestion of streaming data into Iceberg tables. It can also read directly from Iceberg, perform automatic compaction, and maintain table health over time. Since Iceberg is an open table format, results are accessible by other query engines — making storage not only cost-efficient, but interoperable by design.&lt;/p&gt; 
&lt;h2&gt;In what use cases does RisingWave excel?&lt;/h2&gt; 
&lt;p&gt;RisingWave is particularly effective for the following use cases:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Streaming analytics&lt;/strong&gt;: Achieve sub-second data freshness in live dashboards, ideal for high-stakes scenarios like stock trading, sports betting, and IoT monitoring.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Event-driven applications&lt;/strong&gt;: Develop sophisticated monitoring and alerting systems for critical applications such as fraud and anomaly detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time data enrichment&lt;/strong&gt;: Continuously ingest data from diverse sources, conduct real-time data enrichment, and efficiently deliver the results to downstream systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature engineering&lt;/strong&gt;: Transform batch and streaming data into features in your machine learning models using a unified codebase, ensuring seamless integration and consistency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production deployments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://cloud.risingwave.com"&gt;&lt;strong&gt;RisingWave Cloud&lt;/strong&gt;&lt;/a&gt; offers the easiest way to run RisingWave in production.&lt;/p&gt; 
&lt;p&gt;For &lt;strong&gt;Docker deployment&lt;/strong&gt;, please refer to &lt;a href="https://docs.risingwave.com/docs/current/risingwave-docker-compose/"&gt;Docker Compose&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For &lt;strong&gt;Kubernetes deployment&lt;/strong&gt;, please refer to &lt;a href="https://docs.risingwave.com/docs/current/risingwave-k8s-helm/"&gt;Kubernetes with Helm&lt;/a&gt; or &lt;a href="https://docs.risingwave.com/docs/current/risingwave-kubernetes/"&gt;Kubernetes with Operator&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Looking for help, discussions, collaboration opportunities, or a casual afternoon chat with our fellow engineers and community members? Join our &lt;a href="https://risingwave.com/slack"&gt;Slack workspace&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Notes on telemetry&lt;/h2&gt; 
&lt;p&gt;RisingWave uses &lt;a href="https://scarf.sh/"&gt;Scarf&lt;/a&gt; to collect anonymized installation analytics. These analytics help support us understand and improve the distribution of our package. The privacy policy of Scarf is available at &lt;a href="https://about.scarf.sh/privacy-policy"&gt;https://about.scarf.sh/privacy-policy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RisingWave also collects anonymous usage statistics to better understand how the community is using RisingWave. The sole intention of this exercise is to help improve the product. Users may opt out easily at any time. Please refer to the &lt;a href="https://docs.risingwave.com/docs/current/telemetry/"&gt;user documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;RisingWave is distributed under the Apache License (Version 2.0). Please refer to &lt;a href="https://raw.githubusercontent.com/risingwavelabs/risingwave/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thanks for your interest in contributing to the project! Please refer to &lt;a href="https://risingwavelabs.github.io/risingwave/"&gt;RisingWave Developer Guide&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Myriad-Dreamin/tinymist</title>
      <link>https://github.com/Myriad-Dreamin/tinymist</link>
      <description>&lt;p&gt;Tinymist [ˈtaɪni mɪst] is an integrated language service for Typst [taɪpst].&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tinymist&lt;/h1&gt; 
&lt;p&gt;Tinymist [ˈtaɪni mɪst] is an integrated language service for &lt;a href="https://typst.app/"&gt;Typst&lt;/a&gt; [taɪpst]. You can also call it &lt;ruby&gt;微&lt;rt&gt;wēi&lt;/rt&gt;&lt;/ruby&gt;&lt;ruby&gt;霭&lt;rt&gt;ǎi&lt;/rt&gt;&lt;/ruby&gt; in Chinese.&lt;/p&gt; 
&lt;p&gt;It contains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;an analyzing library for Typst, see &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/crates/tinymist-query/"&gt;tinymist-query&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;a CLI for Typst, see &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/crates/tinymist/"&gt;tinymist&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;which provides a language server for Typst, see &lt;a href="https://myriad-dreamin.github.io/tinymist/feature/language.html"&gt;Language Features&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;which provides a preview server for Typst, see &lt;a href="https://myriad-dreamin.github.io/tinymist/feature/preview.html"&gt;Preview Feature&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;a VSCode extension for Typst, see &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/editors/vscode/"&gt;Tinymist VSCode Extension&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Language service (LSP) features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/semantic-highlight-guide"&gt;Semantic highlighting&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The "semantic highlighting" is supplementary to &lt;a href="https://code.visualstudio.com/api/language-extensions/syntax-highlight-guide"&gt;"syntax highlighting"&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#provide-code-actions"&gt;Code actions&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also known as "quick fixes" or "refactorings".&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#format-source-code-in-an-editor"&gt;Formatting (Reformatting)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Provide the user with support for formatting whole documents, using &lt;a href="https://github.com/astrale-sharp/typstfmt"&gt;typstfmt&lt;/a&gt; or &lt;a href="https://github.com/Enter-tainer/typstyle"&gt;typstyle&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#highlight-all-occurrences-of-a-symbol-in-a-document"&gt;Document highlight&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Highlight all break points in a loop context.&lt;/li&gt; 
   &lt;li&gt;(Todo) Highlight all exit points in a function context.&lt;/li&gt; 
   &lt;li&gt;(Todo) Highlight all captures in a closure context.&lt;/li&gt; 
   &lt;li&gt;(Todo) Highlight all occurrences of a symbol in a document.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_documentLink"&gt;Document links&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Renders path or link references in the document, such as &lt;code&gt;image("path.png")&lt;/code&gt; or &lt;code&gt;bibliography(style: "path.csl")&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/getstarted/userinterface#_outline-view"&gt;Document symbols&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also known as "document outline" or "table of contents" &lt;em&gt;in Typst&lt;/em&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://burkeholland.gitbook.io/vs-code-can-do-that/exercise-3-navigation-and-refactoring/folding-sections"&gt;Folding ranges&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;You can collapse code/content blocks and headings.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#show-definitions-of-a-symbol"&gt;Goto definitions&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Right-click on a symbol and select "Go to Definition".&lt;/li&gt; 
   &lt;li&gt;Or ctrl+click on a symbol.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#find-all-references-to-a-symbol"&gt;References&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Right-click on a symbol and select "Go to References" or "Find References".&lt;/li&gt; 
   &lt;li&gt;Or ctrl+click on a symbol.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#show-hovers"&gt;Hover tips&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also known as "hovering tooltip".&lt;/li&gt; 
   &lt;li&gt;Render docs according to &lt;a href="https://github.com/Mc-Zen/tidy"&gt;tidy&lt;/a&gt; style.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jetbrains.com/help/idea/inlay-hints.html"&gt;Inlay hints&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Inlay hints are special markers that appear in the editor and provide you with additional information about your code, like the names of the parameters that a called method expects.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#show-color-decorators"&gt;Color Provider&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;View all inlay colorful label for color literals in your document.&lt;/li&gt; 
   &lt;li&gt;Change the color literal's value by a color picker or its code presentation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/blogs/2017/02/12/code-lens-roundup"&gt;Code Lens&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Should give contextual buttons along with code. For example, a button for exporting your document to various formats at the start of the document.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#rename-symbols"&gt;Rename symbols and embedded paths&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#help-with-function-and-method-signatures"&gt;Help with function and method signatures&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/api/language-extensions/programmatic-language-features#show-all-symbol-definitions-in-folder"&gt;Workspace Symbols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/dynamics365/business-central/dev-itpro/developer/devenv-code-actions"&gt;Code Action&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Increasing/Decreasing heading levels.&lt;/li&gt; 
   &lt;li&gt;Turn equation into "inline", "block" or "multiple-line block" styles.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rust-lang/rust-analyzer/raw/master/docs/dev/lsp-extensions.md#on-enter"&gt;experimental/onEnter&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;kbd&gt;Enter&lt;/kbd&gt; inside triple-slash comments automatically inserts &lt;code&gt;///&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;kbd&gt;Enter&lt;/kbd&gt; in the middle or after a trailing space in &lt;code&gt;//&lt;/code&gt; inserts &lt;code&gt;//&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;kbd&gt;Enter&lt;/kbd&gt; inside &lt;code&gt;//!&lt;/code&gt; doc comments automatically inserts &lt;code&gt;//!&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;kbd&gt;Enter&lt;/kbd&gt; inside equation markups automatically inserts indents.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Extra features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Compiles to PDF on save (configurable to as-you-type, or other options). Check &lt;a href="https://myriad-dreamin.github.io/tinymist/feature/export.html"&gt;Docs: Exporting Documents&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Also compiles to SVG, PNG, HTML, Markdown, Text, and other formats by commands, vscode tasks, or code lenses.&lt;/li&gt; 
 &lt;li&gt;Provides test, benchmark, coverage collecting on documents and modules. Check &lt;a href="https://myriad-dreamin.github.io/tinymist/feature/testing.html"&gt;Docs: Testing Features&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Provides builtin linting. Check &lt;a href="https://myriad-dreamin.github.io/tinymist/feature/linting.html"&gt;Docs: Linting Features&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Provides a status bar item to show the current document's compilation status and words count.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/tools/editor-tools/"&gt;Editor tools&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;View a list of templates in template gallery. (&lt;code&gt;tinymist.showTemplateGallery&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Click a button in template gallery to initialize a new project with a template. (&lt;code&gt;tinymist.initTemplate&lt;/code&gt; and &lt;code&gt;tinymist.initTemplateInPlace&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Trace execution in current document (&lt;code&gt;tinymist.profileCurrentFile&lt;/code&gt;).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Versioning and Release Cycle&lt;/h2&gt; 
&lt;p&gt;Tinymist's versions follow the &lt;a href="https://semver.org/"&gt;Semantic Versioning&lt;/a&gt; scheme, in format of &lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;. Besides, tinymist follows special rules for the version number:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If a version is suffixed with &lt;code&gt;-rcN&lt;/code&gt; (
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="assets/images/introduction/frame_0.svg"&gt;
   &lt;img src="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/assets/images/introduction/frame_1.svg?sanitize=true" alt="typst-frame"&gt;
  &lt;/picture&gt;), e.g. &lt;code&gt;0.11.0-rc1&lt;/code&gt; and &lt;code&gt;0.12.1-rc1&lt;/code&gt;, it means this version is a release candidate. It is used to test publish script and E2E functionalities. These versions will not be published to the marketplace.&lt;/li&gt; 
 &lt;li&gt;If the &lt;code&gt;PATCH&lt;/code&gt; number is odd, e.g. &lt;code&gt;0.11.1&lt;/code&gt; and &lt;code&gt;0.12.3&lt;/code&gt;, it means this version is a nightly release. The nightly release will use both &lt;a href="https://github.com/Myriad-Dreamin/tinymist/tree/main"&gt;tinymist&lt;/a&gt; and &lt;a href="https://github.com/typst/typst/tree/main"&gt;typst&lt;/a&gt; at &lt;strong&gt;main branch&lt;/strong&gt;. They will be published as prerelease version to the marketplace. Note that in nightly releases, we change &lt;code&gt;#sys.version&lt;/code&gt; to the next minor release to help develop documents with nightly features. For example, in tinymist nightly v0.12.1 or v0.12.3, the &lt;code&gt;#sys.version&lt;/code&gt; is changed to &lt;code&gt;version(0, 13, 0)&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Otherwise, if the &lt;code&gt;PATCH&lt;/code&gt; number is even, e.g. &lt;code&gt;0.11.0&lt;/code&gt; and &lt;code&gt;0.12.2&lt;/code&gt;, it means this version is a regular release. The regular release will always use the recent stable version of tinymist and typst.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The release cycle is as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If there is a typst version update, a new major or minor version will be released intermediately. This means tinymist will always align the minor version with typst.&lt;/li&gt; 
 &lt;li&gt;If there is at least a bug or feature added this week, a new patch version will be released.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Follow the instructions to enable tinymist in your favorite editor.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/vscode.html"&gt;VS Cod(e,ium)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/neovim.html"&gt;Neovim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/emacs.html"&gt;Emacs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/sublime-text.html"&gt;Sublime Text&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/helix.html"&gt;Helix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://myriad-dreamin.github.io/tinymist/frontend/zed.html"&gt;Zed&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing Regular/Nightly Prebuilds from GitHub&lt;/h2&gt; 
&lt;p&gt;Note: if you are not knowing what is a regular/nightly release, please don't follow this section.&lt;/p&gt; 
&lt;p&gt;Besides published releases specific for each editors, you can also download the latest regular/nightly prebuilts from GitHub and install them manually.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Regular prebuilts can be found in &lt;a href="https://github.com/Myriad-Dreamin/tinymist/releases"&gt;GitHub Releases&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Nightly prebuilts can be found in &lt;a href="https://github.com/Myriad-Dreamin/tinymist/actions"&gt;GitHub Actions&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;(Suggested) Use the &lt;a href="https://github.com/hongjr03/tinymist-nightly-installer"&gt;tinymist-nightly-installer&lt;/a&gt; to install the nightly prebuilts automatically. 
    &lt;ul&gt; 
     &lt;li&gt;Unix (Bash): &lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://github.com/hongjr03/tinymist-nightly-installer/releases/latest/download/run.sh | bash
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
     &lt;li&gt;Windows (PowerShell): &lt;pre&gt;&lt;code class="language-bash"&gt;iwr https://github.com/hongjr03/tinymist-nightly-installer/releases/latest/download/run.ps1 -UseBasicParsing | iex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;The prebuilts for other revisions can also be found manually. For example, if you are seeking a nightly release for the featured &lt;a href="https://github.com/Myriad-Dreamin/tinymist/pull/468"&gt;PR: build: bump version to 0.11.17-rc1&lt;/a&gt;, you could click and go to the &lt;a href="https://github.com/Myriad-Dreamin/tinymist/actions/runs/10120639466"&gt;action page&lt;/a&gt; run for the related commits and download the artifacts.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To install extension file (the file with &lt;code&gt;.vsix&lt;/code&gt; extension) manually, please &lt;kbd&gt;Ctrl+Shift+X&lt;/kbd&gt; in the editor window and drop the downloaded vsix file into the opened extensions view.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://myriad-dreamin.github.io/tinymist/"&gt;Online Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Packaging&lt;/h2&gt; 
&lt;p&gt;Stable Channel:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/tinymist/versions" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/tinymist.svg?sanitize=true" alt="Packaging status" style="max-width: 100%; height: auto;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Nightly Channel:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/tinymist-nightly/versions" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/tinymist-nightly.svg?sanitize=true" alt="Packaging status" style="max-width: 100%; height: auto;"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;h3&gt;Short Terms&lt;/h3&gt; 
&lt;p&gt;To encourage contributions, we create many &lt;a href="https://github.com/Myriad-Dreamin/tinymist/pulls"&gt;Pull Requests&lt;/a&gt; in draft to navigate short-term plans. They give you a hint of what or where to start in this large repository.&lt;/p&gt; 
&lt;h3&gt;Long Terms&lt;/h3&gt; 
&lt;p&gt;We are planning to implement the following features in typst v0.14.0 or spare time in weekend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Type checking: complete the type checker.&lt;/li&gt; 
 &lt;li&gt;Periscope renderer: It is disabled since vscode reject to render SVGs containing foreignObjects.&lt;/li&gt; 
 &lt;li&gt;Inlay hint: It is disabled &lt;em&gt;by default&lt;/em&gt; because of performance issues.&lt;/li&gt; 
 &lt;li&gt;Find references of dictionary fields and named function arguments.&lt;/li&gt; 
 &lt;li&gt;Improve symbol view's appearance.&lt;/li&gt; 
 &lt;li&gt;Improve package view. 
  &lt;ul&gt; 
   &lt;li&gt;Navigate to symbols by clicking on the symbol name in the view.&lt;/li&gt; 
   &lt;li&gt;Automatically locate the symbol item in the view when viewing local documentation.&lt;/li&gt; 
   &lt;li&gt;Remember the recently invoked package commands, e.g. "Open Docs of @preview/cetz:0.3.1", "Open directory of @preview/touying:0.5.3".&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improve label view. 
  &lt;ul&gt; 
   &lt;li&gt;Group labels.&lt;/li&gt; 
   &lt;li&gt;Search labels.&lt;/li&gt; 
   &lt;li&gt;Keep (persist) group preferences.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Improve Typst Preview. 
  &lt;ul&gt; 
   &lt;li&gt;Pin drop-down: Set the file to preview in the drop-down for clients that doesn't support passing arguments to the preview command.&lt;/li&gt; 
   &lt;li&gt;Render in web worker (another thread) to reduce overhead on the electron's main thread.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Spell checking: There is already a branch but no suitable (default) spell checking library is found. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/crate-ci/typos"&gt;typos&lt;/a&gt; is great for typst. &lt;a href="https://github.com/Automattic/harper"&gt;harper&lt;/a&gt; looks promise.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are interested by any above features, please feel free to send Issues to discuss or PRs to implement to &lt;a href="https://github.com/Myriad-Dreamin/tinymist"&gt;GitHub.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file for contribution guidelines.&lt;/p&gt; 
&lt;h2&gt;Sponsoring&lt;/h2&gt; 
&lt;p&gt;Tinymist thrives on community love and remains proudly independent. While we don't accept direct project funding, we warmly welcome support for our maintainers' personal efforts. Please go to &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/MAINTAINERS.md"&gt;Maintainers Page&lt;/a&gt; and &lt;a href="https://github.com/Myriad-Dreamin/tinymist/graphs/contributors"&gt;Contributors Page&lt;/a&gt; and find their personal pages for more information. It is also welcomed to directly ask questions about sponsoring on the &lt;a href="https://github.com/Myriad-Dreamin/tinymist/issues/new"&gt;GitHub Issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Partially code is inherited from &lt;a href="https://github.com/nvarner/typst-lsp"&gt;typst-lsp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/editors/vscode#symbol-view"&gt;integrating&lt;/a&gt; &lt;strong&gt;offline&lt;/strong&gt; handwritten-stroke recognizer is powered by &lt;a href="https://detypify.quarticcat.com/"&gt;Detypify&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/editors/vscode#preview-command"&gt;integrating&lt;/a&gt; preview service is powered by &lt;a href="https://github.com/Enter-tainer/typst-preview"&gt;typst-preview&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/Myriad-Dreamin/tinymist/main/editors/vscode#managing-local-packages"&gt;integrating&lt;/a&gt; local package management functions are adopted from &lt;a href="https://github.com/OrangeX4/vscode-typst-sync"&gt;vscode-typst-sync&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>vectordotdev/vector</title>
      <link>https://github.com/vectordotdev/vector</link>
      <description>&lt;p&gt;A high-performance observability data pipeline.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/vectordotdev/vector/actions/workflows/nightly.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg?sanitize=true" alt="Nightly"&gt;&lt;/a&gt; &lt;a href="https://github.com/vectordotdev/vector/actions/workflows/e2e.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/e2e.yml/badge.svg?sanitize=true" alt="E2E Test Suite"&gt;&lt;/a&gt; &lt;a href="https://github.com/vectordotdev/vector/actions/workflows/component_features.yml"&gt;&lt;img src="https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg?sanitize=true" alt="Component Features"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/vectordotdev/vector/master/website/static/img/diagram.svg?sanitize=true" alt="Vector"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://vector.dev/docs/setup/quickstart/"&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/docs/"&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/guides/"&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/components/"&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://chat.vector.dev"&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://vector.dev/releases/latest/download/"&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp; &lt;a href="https://rust-doc.vector.dev/"&gt;Rust Crate Docs&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;What is Vector?&lt;/h2&gt; 
&lt;p&gt;Vector is a high-performance, end-to-end (agent &amp;amp; aggregator) observability data pipeline that puts you in control of your observability data. &lt;a href="https://vector.dev/docs/reference/configuration/sources/"&gt;Collect&lt;/a&gt;, &lt;a href="https://vector.dev/docs/reference/configuration/transforms/"&gt;transform&lt;/a&gt;, and &lt;a href="https://vector.dev/docs/reference/configuration/sinks/"&gt;route&lt;/a&gt; all your logs and metrics to any vendors you want today and any other vendors you may want tomorrow. Vector enables dramatic cost reduction, novel data enrichment, and data security where you need it, not where it is most convenient for your vendors. Additionally, it is open source and up to 10x faster than every alternative in the space.&lt;/p&gt; 
&lt;p&gt;To get started, follow our &lt;a href="https://vector.dev/docs/setup/quickstart/"&gt;&lt;strong&gt;quickstart guide&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://vector.dev/docs/setup/installation/"&gt;&lt;strong&gt;install Vector&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Vector is maintained by the Datadog's &lt;a href="https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team"&gt;Community Open Source Engineering team&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Principles&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt; - Built in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, Vector's primary design goal is reliability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end&lt;/strong&gt; - Deploys as an &lt;a href="https://vector.dev/docs/setup/deployment/roles/#agent"&gt;agent&lt;/a&gt; or &lt;a href="https://vector.dev/docs/setup/deployment/roles/#aggregator"&gt;aggregator&lt;/a&gt;. Vector is a complete platform.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified&lt;/strong&gt; - &lt;a href="https://vector.dev/docs/architecture/data-model/log/"&gt;Logs&lt;/a&gt;, &lt;a href="https://vector.dev/docs/architecture/data-model/metric/"&gt;metrics&lt;/a&gt; (beta), and traces (coming soon). One tool for all of your data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce total observability costs.&lt;/li&gt; 
 &lt;li&gt;Transition vendors without disrupting workflows.&lt;/li&gt; 
 &lt;li&gt;Enhance data quality and improve insights.&lt;/li&gt; 
 &lt;li&gt;Consolidate agents and eliminate agent fatigue.&lt;/li&gt; 
 &lt;li&gt;Improve overall observability performance and reliability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vector is relied on by startups and enterprises like &lt;strong&gt;Atlassian&lt;/strong&gt;, &lt;strong&gt;T-Mobile&lt;/strong&gt;, &lt;strong&gt;Comcast&lt;/strong&gt;, &lt;strong&gt;Zendesk&lt;/strong&gt;, &lt;strong&gt;Discord&lt;/strong&gt;, &lt;strong&gt;Fastly&lt;/strong&gt;, &lt;strong&gt;CVS&lt;/strong&gt;, &lt;strong&gt;Trivago&lt;/strong&gt;, &lt;strong&gt;Tuple&lt;/strong&gt;, &lt;strong&gt;Douban&lt;/strong&gt;, &lt;strong&gt;Visa&lt;/strong&gt;, &lt;strong&gt;Mambu&lt;/strong&gt;, &lt;strong&gt;Blockfi&lt;/strong&gt;, &lt;strong&gt;Claranet&lt;/strong&gt;, &lt;strong&gt;Instacart&lt;/strong&gt;, &lt;strong&gt;Forcepoint&lt;/strong&gt;, and &lt;a href="https://github.com/vectordotdev/vector/issues/790"&gt;many more&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector is &lt;strong&gt;downloaded over 100,000 times per day&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector's largest user &lt;strong&gt;processes over 500TB daily&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Vector has &lt;strong&gt;over 500 contributors&lt;/strong&gt; and growing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All user documentation is available at &lt;strong&gt;&lt;a href="https://vector.dev/docs"&gt;vector.dev/docs&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Other Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendar.vector.dev"&gt;&lt;strong&gt;Vector Calendar&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Policies&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/CODE_OF_CONDUCT.md"&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/PRIVACY.md"&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/RELEASES.md"&gt;&lt;strong&gt;Releases&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/raw/master/VERSIONING.md"&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/vectordotdev/vector/security/policy"&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Comparisons&lt;/h2&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;p&gt;The following performance tests demonstrate baseline performance between common protocols with the exception of the Regex Parsing test.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Test&lt;/th&gt; 
   &lt;th&gt;Vector&lt;/th&gt; 
   &lt;th&gt;Filebeat&lt;/th&gt; 
   &lt;th&gt;FluentBit&lt;/th&gt; 
   &lt;th&gt;FluentD&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;SplunkUF&lt;/th&gt; 
   &lt;th&gt;SplunkHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance"&gt;TCP to Blackhole&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;86mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;64.4mib/s&lt;/td&gt; 
   &lt;td&gt;27.7mib/s&lt;/td&gt; 
   &lt;td&gt;40.6mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance"&gt;File to TCP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;76.7mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;7.8mib/s&lt;/td&gt; 
   &lt;td&gt;35mib/s&lt;/td&gt; 
   &lt;td&gt;26.1mib/s&lt;/td&gt; 
   &lt;td&gt;3.1mib/s&lt;/td&gt; 
   &lt;td&gt;40.1mib/s&lt;/td&gt; 
   &lt;td&gt;39mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance"&gt;Regex Parsing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;13.2mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;20.5mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;2.6mib/s&lt;/td&gt; 
   &lt;td&gt;4.6mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;7.8mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance"&gt;TCP to HTTP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;26.7mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;19.6mib/s&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1mib/s&lt;/td&gt; 
   &lt;td&gt;2.7mib/s&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
   &lt;td&gt;n/a&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance"&gt;TCP to TCP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;69.9mib/s&lt;/td&gt; 
   &lt;td&gt;5mib/s&lt;/td&gt; 
   &lt;td&gt;67.1mib/s&lt;/td&gt; 
   &lt;td&gt;3.9mib/s&lt;/td&gt; 
   &lt;td&gt;10mib/s&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;&lt;strong&gt;70.4mib/s&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;7.6mib/s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about our performance tests, please see the &lt;a href="https://github.com/vectordotdev/vector-test-harness/"&gt;Vector test harness&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Correctness&lt;/h3&gt; 
&lt;p&gt;The following correctness tests are not exhaustive, but they demonstrate fundamental differences in quality and attention to detail:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Test&lt;/th&gt; 
   &lt;th&gt;Vector&lt;/th&gt; 
   &lt;th&gt;Filebeat&lt;/th&gt; 
   &lt;th&gt;FluentBit&lt;/th&gt; 
   &lt;th&gt;FluentD&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;Splunk UF&lt;/th&gt; 
   &lt;th&gt;Splunk HF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness"&gt;Disk Buffer Persistence&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness"&gt;File Rotate (create)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness"&gt;File Rotate (copytruncate)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness"&gt;File Truncation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness"&gt;Process (SIGHUP)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness"&gt;JSON (wrapped)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about our correctness tests, please see the &lt;a href="https://github.com/vectordotdev/vector-test-harness/"&gt;Vector test harness&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;p&gt;Vector is an end-to-end, unified, open data platform.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Vector&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;Beats&lt;/th&gt; 
   &lt;th&gt;Fluentbit&lt;/th&gt; 
   &lt;th&gt;Fluentd&lt;/th&gt; 
   &lt;th&gt;Logstash&lt;/th&gt; 
   &lt;th&gt;Splunk UF&lt;/th&gt; 
   &lt;th&gt;Splunk HF&lt;/th&gt; 
   &lt;th&gt;Telegraf&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;End-to-end&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Aggregator&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Unified&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Logs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metrics&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;⚠&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traces&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Open-source&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vendor-neutral&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Reliability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory-safe&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delivery guarantees&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-core&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;✓&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
   &lt;td&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;⚠ = Not interoperable, metrics are represented as structured logs&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; Developed with ❤️ by &lt;strong&gt;&lt;a href="https://datadoghq.com"&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href="https://github.com/vectordotdev/vector/security/policy"&gt;Security Policy&lt;/a&gt; - &lt;a href="https://github.com/vectordotdev/vector/raw/master/PRIVACY.md"&gt;Privacy Policy&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This is the home of the &lt;strong&gt;Codex CLI&lt;/strong&gt;, which is a coding agent from OpenAI that runs locally on your computer. If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex [Web]&lt;/strong&gt;, see &lt;a href="https://chatgpt.com/codex"&gt;https://chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ![Codex demo GIF using: codex "explain this codebase to me"](./.github/demo.gif) --&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;!-- Begin ToC --&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#experimental-technology-disclaimer"&gt;Experimental technology disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quickstart"&gt;Quickstart&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#openai-api-users"&gt;OpenAI API Users&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#openai-pluspro-users"&gt;OpenAI Plus/Pro Users&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-open-source-models"&gt;Using Open Source Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#why-codex"&gt;Why Codex?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#security-model--permissions"&gt;Security model &amp;amp; permissions&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#platform-sandboxing-details"&gt;Platform sandboxing details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#system-requirements"&gt;System requirements&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#cli-reference"&gt;CLI reference&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#memory--project-docs"&gt;Memory &amp;amp; project docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#recipes"&gt;Recipes&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#installation"&gt;Installation&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#zero-data-retention-zdr-usage"&gt;Zero data retention (ZDR) usage&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#codex-open-source-fund"&gt;Codex open source fund&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;Development workflow&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#writing-high-impact-code-changes"&gt;Writing high-impact code changes&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#opening-a-pull-request"&gt;Opening a pull request&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#review-process"&gt;Review process&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#community-values"&gt;Community values&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#getting-help"&gt;Getting help&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributor-license-agreement-cla"&gt;Contributor license agreement (CLA)&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quick-fixes"&gt;Quick fixes&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#releasing-codex"&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#security--responsible-ai"&gt;Security &amp;amp; responsible AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- End ToC --&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Experimental technology disclaimer&lt;/h2&gt; 
&lt;p&gt;Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports&lt;/li&gt; 
 &lt;li&gt;Feature requests&lt;/li&gt; 
 &lt;li&gt;Pull requests&lt;/li&gt; 
 &lt;li&gt;Good vibes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Install globally with your preferred package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex  # Alternatively: `brew install codex`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/p&gt; 
&lt;h3&gt;OpenAI API Users&lt;/h3&gt; 
&lt;p&gt;Next, set your OpenAI API key as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This command sets the key only for your current terminal session. You can add the &lt;code&gt;export&lt;/code&gt; line to your shell's configuration file (e.g., &lt;code&gt;~/.zshrc&lt;/code&gt;), but we recommend setting it for the session.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;OpenAI Plus/Pro Users&lt;/h3&gt; 
&lt;p&gt;If you have a paid OpenAI account, run the following to start the login process:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;codex login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you complete the process successfully, you should have a &lt;code&gt;~/.codex/auth.json&lt;/code&gt; file that contains the credentials that Codex will use.&lt;/p&gt; 
&lt;p&gt;To verify whether you are currently logged in, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;codex login status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you encounter problems with the login flow, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;https://github.com/openai/codex/issues/1243&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Use &lt;code&gt;--profile&lt;/code&gt; to use other models&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Codex also allows you to use other providers that support the OpenAI Chat Completions (or Responses) API.&lt;/p&gt; 
 &lt;p&gt;To do so, you must first define custom &lt;a href="https://raw.githubusercontent.com/openai/codex/main/config.md#model_providers"&gt;providers&lt;/a&gt; in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For example, the provider for a standard Ollama setup would be defined as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.ollama]
name = "Ollama"
base_url = "http://localhost:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;base_url&lt;/code&gt; will have &lt;code&gt;/chat/completions&lt;/code&gt; appended to it to build the full URL for the request.&lt;/p&gt; 
 &lt;p&gt;For providers that also require an &lt;code&gt;Authorization&lt;/code&gt; header of the form &lt;code&gt;Bearer: SECRET&lt;/code&gt;, an &lt;code&gt;env_key&lt;/code&gt; can be specified, which indicates the environment variable to read to use as the value of &lt;code&gt;SECRET&lt;/code&gt; when making a request:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.openrouter]
name = "OpenRouter"
base_url = "https://openrouter.ai/api/v1"
env_key = "OPENROUTER_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Providers that speak the Responses API are also supported by adding &lt;code&gt;wire_api = "responses"&lt;/code&gt; as part of the definition. Accessing OpenAI models via Azure is an example of such a provider, though it also requires specifying additional &lt;code&gt;query_params&lt;/code&gt; that need to be appended to the request URL:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.azure]
name = "Azure"
# Make sure you set the appropriate subdomain for this URL.
base_url = "https://YOUR_PROJECT_NAME.openai.azure.com/openai"
env_key = "AZURE_OPENAI_API_KEY"  # Or "OPENAI_API_KEY", whichever you use.
# Newer versions appear to support the responses API, see https://github.com/openai/codex/pull/1321
query_params = { api-version = "2025-04-01-preview" }
wire_api = "responses"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Once you have defined a provider you wish to use, you can configure it as your default provider as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;model_provider = "azure"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP] If you find yourself experimenting with a variety of models and providers, then you likely want to invest in defining a &lt;em&gt;profile&lt;/em&gt; for each configuration like so:&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.o3]
model_provider = "azure"
model = "o3"

[profiles.mistral]
model_provider = "ollama"
model = "mistral"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This way, you can specify one command-line argument (.e.g., &lt;code&gt;--profile o3&lt;/code&gt;, &lt;code&gt;--profile mistral&lt;/code&gt;) to override multiple settings together.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;p&gt;Run interactively:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run with a prompt as input (and optionally in &lt;code&gt;Full Auto&lt;/code&gt; mode):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex "explain this codebase to me"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex --full-auto "create the fanciest todo-list app"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it - Codex will scaffold a file, run it inside a sandbox, install any missing dependencies, and show you the live result. Approve the changes and they'll be committed to your working directory.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Using Open Source Models&lt;/h2&gt; 
&lt;p&gt;Codex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the &lt;code&gt;--oss&lt;/code&gt; flag:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interactive UI: 
  &lt;ul&gt; 
   &lt;li&gt;codex --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Non-interactive (programmatic) mode: 
  &lt;ul&gt; 
   &lt;li&gt;echo "Refactor utils" | codex exec --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model selection when using &lt;code&gt;--oss&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you omit &lt;code&gt;-m/--model&lt;/code&gt;, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).&lt;/li&gt; 
 &lt;li&gt;To pick a different size, pass one of: 
  &lt;ul&gt; 
   &lt;li&gt;-m "gpt-oss:20b"&lt;/li&gt; 
   &lt;li&gt;-m "gpt-oss:120b"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Point Codex at your own OSS host:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;By default, &lt;code&gt;--oss&lt;/code&gt; talks to &lt;a href="http://localhost:11434/v1"&gt;http://localhost:11434/v1&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To use a different host, set one of these environment variables before running Codex: 
  &lt;ul&gt; 
   &lt;li&gt;CODEX_OSS_BASE_URL, for example: 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_BASE_URL="&lt;a href="http://my-ollama.example.com:11434/v1"&gt;http://my-ollama.example.com:11434/v1&lt;/a&gt;" codex --oss -m gpt-oss:20b&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;or CODEX_OSS_PORT (when the host is localhost): 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_PORT=11434 codex --oss&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Advanced: you can persist this in your config instead of environment variables by overriding the built-in &lt;code&gt;oss&lt;/code&gt; provider in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.oss]
name = "Open Source"
base_url = "http://my-ollama.example.com:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr&gt; 
&lt;h2&gt;Why Codex?&lt;/h2&gt; 
&lt;p&gt;Codex CLI is built for developers who already &lt;strong&gt;live in the terminal&lt;/strong&gt; and want ChatGPT-level reasoning &lt;strong&gt;plus&lt;/strong&gt; the power to actually run code, manipulate files, and iterate - all under version control. In short, it's &lt;em&gt;chat-driven development&lt;/em&gt; that understands and executes your repo.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero setup&lt;/strong&gt; - bring your OpenAI API key and it just works!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full auto-approval, while safe + secure&lt;/strong&gt; by running network-disabled and directory-sandboxed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal&lt;/strong&gt; - pass in screenshots or diagrams to implement features ✨&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it's &lt;strong&gt;fully open-source&lt;/strong&gt; so you can see and contribute to how it develops!&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Security model &amp;amp; permissions&lt;/h2&gt; 
&lt;p&gt;Codex lets you decide &lt;em&gt;how much autonomy&lt;/em&gt; you want to grant the agent. The following options can be configured independently:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#approval_policy"&gt;&lt;code&gt;approval_policy&lt;/code&gt;&lt;/a&gt; determines when you should be prompted to approve whether Codex can execute a command&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#sandbox"&gt;&lt;code&gt;sandbox&lt;/code&gt;&lt;/a&gt; determines the &lt;em&gt;sandbox policy&lt;/em&gt; that Codex uses to execute untrusted commands&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By default, Codex runs with &lt;code&gt;--ask-for-approval untrusted&lt;/code&gt; and &lt;code&gt;--sandbox read-only&lt;/code&gt;, which means that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The user is prompted to approve every command not on the set of "trusted" commands built into Codex (&lt;code&gt;cat&lt;/code&gt;, &lt;code&gt;ls&lt;/code&gt;, etc.)&lt;/li&gt; 
 &lt;li&gt;Approved commands are run outside of a sandbox because user approval implies "trust," in this case.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Running Codex with the &lt;code&gt;--full-auto&lt;/code&gt; convenience flag changes the configuration to &lt;code&gt;--ask-for-approval on-failure&lt;/code&gt; and &lt;code&gt;--sandbox workspace-write&lt;/code&gt;, which means that:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex does not initially ask for user approval before running an individual command.&lt;/li&gt; 
 &lt;li&gt;Though when it runs a command, it is run under a sandbox in which: 
  &lt;ul&gt; 
   &lt;li&gt;It can read any file on the system.&lt;/li&gt; 
   &lt;li&gt;It can only write files under the current directory (or the directory specified via &lt;code&gt;--cd&lt;/code&gt;).&lt;/li&gt; 
   &lt;li&gt;Network requests are completely disabled.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Only if the command exits with a non-zero exit code will it ask the user for approval. If granted, it will re-attempt the command outside of the sandbox. (A common case is when Codex cannot &lt;code&gt;npm install&lt;/code&gt; a dependency because that requires network access.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Again, these two options can be configured independently. For example, if you want Codex to perform an "exploration" where you are happy for it to read anything it wants but you never want to be prompted, you could run Codex with &lt;code&gt;--ask-for-approval never&lt;/code&gt; and &lt;code&gt;--sandbox read-only&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Platform sandboxing details&lt;/h3&gt; 
&lt;p&gt;The mechanism Codex uses to implement the sandbox policy depends on your OS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 12+&lt;/strong&gt; uses &lt;strong&gt;Apple Seatbelt&lt;/strong&gt; and runs commands using &lt;code&gt;sandbox-exec&lt;/code&gt; with a profile (&lt;code&gt;-p&lt;/code&gt;) that corresponds to the &lt;code&gt;--sandbox&lt;/code&gt; that was specified.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; uses a combination of Landlock/seccomp APIs to enforce the &lt;code&gt;sandbox&lt;/code&gt; configuration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that when running Linux in a containerized environment such as Docker, sandboxing may not work if the host/container configuration does not support the necessary Landlock/seccomp APIs. In such cases, we recommend configuring your Docker container so that it provides the sandbox guarantees you are looking for and then running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--sandbox danger-full-access&lt;/code&gt; (or, more simply, the &lt;code&gt;--dangerously-bypass-approvals-and-sandbox&lt;/code&gt; flag) within your container.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;System requirements&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Requirement&lt;/th&gt; 
   &lt;th&gt;Details&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating systems&lt;/td&gt; 
   &lt;td&gt;macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 &lt;strong&gt;via WSL2&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git (optional, recommended)&lt;/td&gt; 
   &lt;td&gt;2.23+ for built-in PR helpers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RAM&lt;/td&gt; 
   &lt;td&gt;4-GB minimum (8-GB recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;CLI reference&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "fix lint errors"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Non-interactive "automation mode"&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "explain utils.ts"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Key flags: &lt;code&gt;--model/-m&lt;/code&gt;, &lt;code&gt;--ask-for-approval/-a&lt;/code&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Memory &amp;amp; project docs&lt;/h2&gt; 
&lt;p&gt;You can give Codex extra instructions and guidance using &lt;code&gt;AGENTS.md&lt;/code&gt; files. Codex looks for &lt;code&gt;AGENTS.md&lt;/code&gt; files in the following places, and merges them top-down:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;~/.codex/AGENTS.md&lt;/code&gt; - personal global guidance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; at repo root - shared project notes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; in the current working directory - sub-folder/feature specifics&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr&gt; 
&lt;h2&gt;Non-interactive / CI mode&lt;/h2&gt; 
&lt;p&gt;Run Codex head-less in pipelines. Example GitHub Action step:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: Update changelog via Codex
  run: |
    npm install -g @openai/codex
    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
    codex exec --full-auto "update CHANGELOG for next release"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;The Codex CLI can be configured to leverage MCP servers by defining an &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#mcp_servers"&gt;&lt;code&gt;mcp_servers&lt;/code&gt;&lt;/a&gt; section in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. It is intended to mirror how tools such as Claude and Cursor define &lt;code&gt;mcpServers&lt;/code&gt; in their respective JSON config files, though the Codex format is slightly different since it uses TOML rather than JSON, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# IMPORTANT: the top-level key is `mcp_servers` rather than `mcpServers`.
[mcp_servers.server-name]
command = "npx"
args = ["-y", "mcp-server"]
env = { "API_KEY" = "value" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is somewhat experimental, but the Codex CLI can also be run as an MCP &lt;em&gt;server&lt;/em&gt; via &lt;code&gt;codex mcp&lt;/code&gt;. If you launch it with an MCP client such as &lt;code&gt;npx @modelcontextprotocol/inspector codex mcp&lt;/code&gt; and send it a &lt;code&gt;tools/list&lt;/code&gt; request, you will see that there is only one tool, &lt;code&gt;codex&lt;/code&gt;, that accepts a grab-bag of inputs, including a catch-all &lt;code&gt;config&lt;/code&gt; map for anything you might want to override. Feel free to play around with it and provide feedback via GitHub issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tracing / verbose logging&lt;/h2&gt; 
&lt;p&gt;Because Codex is written in Rust, it honors the &lt;code&gt;RUST_LOG&lt;/code&gt; environment variable to configure its logging behavior.&lt;/p&gt; 
&lt;p&gt;The TUI defaults to &lt;code&gt;RUST_LOG=codex_core=info,codex_tui=info&lt;/code&gt; and log messages are written to &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt;, so you can leave the following running in a separate terminal to monitor log messages as they are written:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;tail -F ~/.codex/log/codex-tui.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By comparison, the non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;) defaults to &lt;code&gt;RUST_LOG=error&lt;/code&gt;, but messages are printed inline, so there is no need to monitor a separate file.&lt;/p&gt; 
&lt;p&gt;See the Rust documentation on &lt;a href="https://docs.rs/env_logger/latest/env_logger/#enabling-logging"&gt;&lt;code&gt;RUST_LOG&lt;/code&gt;&lt;/a&gt; for more information on the configuration options.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Recipes&lt;/h2&gt; 
&lt;p&gt;Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the &lt;a href="https://github.com/openai/codex/raw/main/codex-cli/examples/prompting_guide.md"&gt;prompting guide&lt;/a&gt; for more tips and usage patterns.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;✨&lt;/th&gt; 
   &lt;th&gt;What you type&lt;/th&gt; 
   &lt;th&gt;What happens&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Refactor the Dashboard component to React Hooks"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Codex rewrites the class component, runs &lt;code&gt;npm test&lt;/code&gt;, and shows the diff.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Generate SQL migrations for adding a users table"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Infers your ORM, creates migration files, and runs them in a sandboxed DB.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Write unit tests for utils/date.ts"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generates tests, executes them, and iterates until they pass.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Bulk-rename *.jpeg -&amp;gt; *.jpg with git mv"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Safely renames files and updates imports/usages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Outputs a step-by-step human explanation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Suggests impactful PRs in the current codebase.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Look for vulnerabilities and create a security review report"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Finds and explains security bugs.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;strong&gt;Install Codex CLI using your preferred package manager.&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;From &lt;code&gt;brew&lt;/code&gt; (recommended, downloads only the binary for your platform):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;brew install codex
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;From &lt;code&gt;npm&lt;/code&gt; (generally more readily available, but downloads binaries for all supported platforms):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;npm i -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Or go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/p&gt; 
 &lt;p&gt;Admittedly, each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
 &lt;h3&gt;DotSlash&lt;/h3&gt; 
 &lt;p&gt;The GitHub Release also contains a &lt;a href="https://dotslash-cli.com/"&gt;DotSlash&lt;/a&gt; file for the Codex CLI named &lt;code&gt;codex&lt;/code&gt;. Using a DotSlash file makes it possible to make a lightweight commit to source control to ensure all contributors use the same version of an executable, regardless of what platform they use for development.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build from source&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository and navigate to the root of the Cargo workspace.
git clone https://github.com/openai/codex.git
cd codex/codex-rs

# Install the Rust toolchain, if necessary.
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"
rustup component add rustfmt
rustup component add clippy

# Build Codex.
cargo build

# Launch the TUI with a sample prompt.
cargo run --bin codex -- "explain this codebase to me"

# After making changes, ensure the code is clean.
cargo fmt -- --config imports_granularity=Item
cargo clippy --tests

# Run the tests.
cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Codex supports a rich set of configuration options documented in &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md"&gt;&lt;code&gt;codex-rs/config.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, Codex loads its configuration from &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Though &lt;code&gt;--config&lt;/code&gt; can be used to set/override ad-hoc config values for individual invocations of &lt;code&gt;codex&lt;/code&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenAI released a model called Codex in 2021 - is this related?&lt;/summary&gt; 
 &lt;p&gt;In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which models are supported?&lt;/summary&gt; 
 &lt;p&gt;Any model available with &lt;a href="https://platform.openai.com/docs/api-reference/responses"&gt;Responses API&lt;/a&gt;. The default is &lt;code&gt;o4-mini&lt;/code&gt;, but pass &lt;code&gt;--model gpt-4.1&lt;/code&gt; or set &lt;code&gt;model: gpt-4.1&lt;/code&gt; in your config file to override.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why does &lt;code&gt;o3&lt;/code&gt; or &lt;code&gt;o4-mini&lt;/code&gt; not work for me?&lt;/summary&gt; 
 &lt;p&gt;It's possible that your &lt;a href="https://help.openai.com/en/articles/10910291-api-organization-verification"&gt;API account needs to be verified&lt;/a&gt; in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I stop Codex from editing my files?&lt;/summary&gt; 
 &lt;p&gt;Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type &lt;strong&gt;n&lt;/strong&gt; to deny the command or give the model feedback.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Does it work on Windows?&lt;/summary&gt; 
 &lt;p&gt;Not directly. It requires &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;Windows Subsystem for Linux (WSL2)&lt;/a&gt; - Codex has been tested on macOS and Linux with Node 22.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Zero data retention (ZDR) usage&lt;/h2&gt; 
&lt;p&gt;Codex CLI &lt;strong&gt;does&lt;/strong&gt; support OpenAI organizations with &lt;a href="https://platform.openai.com/docs/guides/your-data#zero-data-retention"&gt;Zero Data Retention (ZDR)&lt;/a&gt; enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you are running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--config disable_response_storage=true&lt;/code&gt; or add this line to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; to avoid specifying the command line option each time:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;disable_response_storage = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#disable_response_storage"&gt;the configuration documentation on &lt;code&gt;disable_response_storage&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Codex open source fund&lt;/h2&gt; 
&lt;p&gt;We're excited to launch a &lt;strong&gt;$1 million initiative&lt;/strong&gt; supporting open source projects that use Codex CLI and other OpenAI models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grants are awarded up to &lt;strong&gt;$25,000&lt;/strong&gt; API credits.&lt;/li&gt; 
 &lt;li&gt;Applications are reviewed &lt;strong&gt;on a rolling basis&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Interested? &lt;a href="https://openai.com/form/codex-open-source-fund/"&gt;Apply here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!&lt;/p&gt; 
&lt;p&gt;More broadly we welcome contributions - whether you are opening your very first pull request or you're a seasoned maintainer. At the same time we care about reliability and long-term maintainability, so the bar for merging code is intentionally &lt;strong&gt;high&lt;/strong&gt;. The guidelines below spell out what "high-quality" means in practice and should make the whole process transparent and friendly.&lt;/p&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a &lt;em&gt;topic branch&lt;/em&gt; from &lt;code&gt;main&lt;/code&gt; - e.g. &lt;code&gt;feat/interactive-prompt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.&lt;/li&gt; 
 &lt;li&gt;Following the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;development setup&lt;/a&gt; instructions above, ensure your change is free of lint warnings and test failures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Writing high-impact code changes&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start with an issue.&lt;/strong&gt; Open a new one or comment on an existing discussion so we can agree on the solution before code is written.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add or update tests.&lt;/strong&gt; Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document behaviour.&lt;/strong&gt; If your change affects user-facing behaviour, update the README, inline help (&lt;code&gt;codex --help&lt;/code&gt;), or relevant example projects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keep commits atomic.&lt;/strong&gt; Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Opening a pull request&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fill in the PR template (or include similar information) - &lt;strong&gt;What? Why? How?&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;strong&gt;all&lt;/strong&gt; checks locally (&lt;code&gt;cargo test &amp;amp;&amp;amp; cargo clippy --tests &amp;amp;&amp;amp; cargo fmt -- --config imports_granularity=Item&lt;/code&gt;). CI failures that could have been caught locally slow down the process.&lt;/li&gt; 
 &lt;li&gt;Make sure your branch is up-to-date with &lt;code&gt;main&lt;/code&gt; and that you have resolved merge conflicts.&lt;/li&gt; 
 &lt;li&gt;Mark the PR as &lt;strong&gt;Ready for review&lt;/strong&gt; only when you believe it is in a merge-able state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Review process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;One maintainer will be assigned as a primary reviewer.&lt;/li&gt; 
 &lt;li&gt;We may ask for changes - please do not take this personally. We value the work, we just also value consistency and long-term maintainability.&lt;/li&gt; 
 &lt;li&gt;When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Community values&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Be kind and inclusive.&lt;/strong&gt; Treat others with respect; we follow the &lt;a href="https://www.contributor-covenant.org/"&gt;Contributor Covenant&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Assume good intent.&lt;/strong&gt; Written communication is hard - err on the side of generosity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teach &amp;amp; learn.&lt;/strong&gt; If you spot something confusing, open an issue or PR with improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting help&lt;/h3&gt; 
&lt;p&gt;If you run into problems setting up the project, would like feedback on an idea, or just want to say &lt;em&gt;hi&lt;/em&gt; - please open a Discussion or jump into the relevant issue. We are happy to help.&lt;/p&gt; 
&lt;p&gt;Together we can make Codex CLI an incredible tool. &lt;strong&gt;Happy hacking!&lt;/strong&gt; &lt;span&gt;🚀&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;Contributor license agreement (CLA)&lt;/h3&gt; 
&lt;p&gt;All contributors &lt;strong&gt;must&lt;/strong&gt; accept the CLA. The process is lightweight:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open your pull request.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Paste the following comment (or reply &lt;code&gt;recheck&lt;/code&gt; if you've signed before):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-text"&gt;I have read the CLA Document and I hereby sign the CLA
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The CLA-Assistant bot records your signature in the repo and marks the status check as passed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;No special Git commands, email attachments, or commit footers required.&lt;/p&gt; 
&lt;h4&gt;Quick fixes&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amend last commit&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git commit --amend -s --no-edit &amp;amp;&amp;amp; git push -f&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;strong&gt;DCO check&lt;/strong&gt; blocks merges until every commit in the PR carries the footer (with squash this is just the one).&lt;/p&gt; 
&lt;h3&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;For admins only.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Make sure you are on &lt;code&gt;main&lt;/code&gt; and have no local changes. Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;VERSION=0.2.0  # Can also be 0.2.0-alpha.1 or any valid Rust version.
./codex-rs/scripts/create_github_release.sh "$VERSION"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will make a local commit on top of &lt;code&gt;main&lt;/code&gt; with &lt;code&gt;version&lt;/code&gt; set to &lt;code&gt;$VERSION&lt;/code&gt; in &lt;code&gt;codex-rs/Cargo.toml&lt;/code&gt; (note that on &lt;code&gt;main&lt;/code&gt;, we leave the version as &lt;code&gt;version = "0.0.0"&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;This will push the commit using the tag &lt;code&gt;rust-v${VERSION}&lt;/code&gt;, which in turn kicks off &lt;a href="https://raw.githubusercontent.com/openai/codex/main/.github/workflows/rust-release.yml"&gt;the release workflow&lt;/a&gt;. This will create a new GitHub Release named &lt;code&gt;$VERSION&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If everything looks good in the generated GitHub Release, uncheck the &lt;strong&gt;pre-release&lt;/strong&gt; box so it is the latest release.&lt;/p&gt; 
&lt;p&gt;Create a PR to update &lt;a href="https://github.com/Homebrew/homebrew-core/raw/main/Formula/c/codex.rb"&gt;&lt;code&gt;Formula/c/codex.rb&lt;/code&gt;&lt;/a&gt; on Homebrew.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Security &amp;amp; responsible AI&lt;/h2&gt; 
&lt;p&gt;Have you discovered a vulnerability or have concerns about model output? Please e-mail &lt;strong&gt;&lt;a href="mailto:security@openai.com"&gt;security@openai.com&lt;/a&gt;&lt;/strong&gt; and we will respond promptly.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>