<rss version="2.0">
  <channel>
    <title>GitHub Go Weekly Trending</title>
    <description>Weekly Trending of Go in GitHub</description>
    <pubDate>Thu, 30 Oct 2025 01:46:02 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chaitin/SafeLine</title>
      <link>https://github.com/chaitin/SafeLine</link>
      <description>&lt;p&gt;SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/banner.png" width="400" /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; SafeLine - Make your web apps secure &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://ly.safepoint.cloud/laA8asp"&gt;üè† Website&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/w2AeHhb"&gt;üìñ Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/hSMd4SH"&gt;üîç Live Demo&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;üôã‚Äç‚ôÇÔ∏è Discord&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/README_CN.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üëã INTRODUCTION&lt;/h2&gt; 
&lt;p&gt;SafeLine is a self-hosted &lt;strong&gt;&lt;code&gt;WAF(Web Application Firewall)&lt;/code&gt;&lt;/strong&gt; to protect your web apps from attacks and exploits.&lt;/p&gt; 
&lt;p&gt;A web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;ldap injection&lt;/code&gt;, &lt;code&gt;xpath injection&lt;/code&gt;, &lt;code&gt;RCE&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt;, &lt;code&gt;backdoor&lt;/code&gt;, &lt;code&gt;bruteforce&lt;/code&gt;, &lt;code&gt;http-flood&lt;/code&gt;, &lt;code&gt;bot abused&lt;/code&gt;, among others.&lt;/p&gt; 
&lt;h4&gt;üí° How It Works&lt;/h4&gt; 
&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/how-it-works.png" width="800" /&gt; 
&lt;p&gt;By deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine‚Äôs identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.&lt;/p&gt; 
&lt;p&gt;A WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.&lt;/p&gt; 
&lt;p&gt;its core capabilities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Defenses for web attacks&lt;/li&gt; 
 &lt;li&gt;Proactive bot abused defense&lt;/li&gt; 
 &lt;li&gt;HTML &amp;amp; JS code encryption&lt;/li&gt; 
 &lt;li&gt;IP-based rate limiting&lt;/li&gt; 
 &lt;li&gt;Web Access Control List&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö°Ô∏è Screenshots&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-1.png" width="370" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-2.png" width="370" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-3.png" width="370" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-4.png" width="370" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Get &lt;a href="https://demo.waf.chaitin.com:9443/"&gt;Live Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üî• FEATURES&lt;/h2&gt; 
&lt;p&gt;List of the main features as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;It defenses for all of web attacks, such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt; and so on.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defend your web apps against &lt;code&gt;DoS attacks&lt;/code&gt;, &lt;code&gt;bruteforce attempts&lt;/code&gt;, &lt;code&gt;traffic surges&lt;/code&gt;, and other types of abuse by throttling traffic that exceeds defined limits.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anti-Bot challenges to protect your website from &lt;code&gt;bot attacks&lt;/code&gt;, humen users will be allowed, crawlers and bots will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Authentication Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Dynamic Protection&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üß© Showcases&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Legitimate User&lt;/th&gt; 
   &lt;th&gt;Malicious User&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-attack-detected.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-access-too-fast.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Auth Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;HTML Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;JS Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] ‰∏≠ÂõΩÂ§ßÈôÜÁî®Êà∑ÂÆâË£ÖÂõΩÈôÖÁâàÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËøûÊé•‰∫ëÊúçÂä°ÔºåËØ∑Êü•Áúã &lt;a href="https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0"&gt;‰∏≠ÊñáÁâàÂÆâË£ÖÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üì¶ Installing&lt;/h4&gt; 
&lt;p&gt;Information on how to install SafeLine can be found in the &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/Deploy"&gt;Install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;‚öôÔ∏è Protecting Web Apps&lt;/h4&gt; 
&lt;p&gt;to see &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/AddApplication"&gt;Configuration&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìã More Informations&lt;/h2&gt; 
&lt;h4&gt;Effect Evaluation&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;ModSecurity, Level 1&lt;/th&gt; 
   &lt;th&gt;CloudFlare, Free&lt;/th&gt; 
   &lt;th&gt;SafeLine, Balance&lt;/th&gt; 
   &lt;th&gt;SafeLine, Strict&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total Samples&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Detection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;69.74%&lt;/td&gt; 
   &lt;td&gt;10.70%&lt;/td&gt; 
   &lt;td&gt;71.65%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.17%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;False Positive&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;17.58%&lt;/td&gt; 
   &lt;td&gt;0.07%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.07%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;0.22%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;82.20%&lt;/td&gt; 
   &lt;td&gt;98.40%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;99.45%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;99.38%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Is SafeLine Production-Ready?&lt;/h4&gt; 
&lt;p&gt;Yes, SafeLine is production-ready.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Over 180,000 installations worldwide&lt;/li&gt; 
 &lt;li&gt;Protecting over 1,000,000 Websites&lt;/li&gt; 
 &lt;li&gt;Handling over 30,000,000,000 HTTP Requests Daily&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üôã‚Äç‚ôÇÔ∏è Community&lt;/h4&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/SVnZGzHFvn"&gt;Discord&lt;/a&gt; to get community support, the core team members are identified by the STAFF role in Discord.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243120292822253598"&gt;#feedback&lt;/a&gt;: for new features discussion.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1263761679619981413"&gt;#FAQ&lt;/a&gt;: for FAQ.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243115843919806486"&gt;#general&lt;/a&gt;: for any other questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Several contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://x.com/safeline_waf"&gt;&lt;img src="https://img.shields.io/badge/X.com-000000?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=flat&amp;amp;logo=wechat&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h4&gt;üí™ PRO Edition&lt;/h4&gt; 
&lt;p&gt;Coming soon!&lt;/p&gt; 
&lt;h4&gt;üìù License&lt;/h4&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/chaitin/SafeLine/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/"&gt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>rcourtman/Pulse</title>
      <link>https://github.com/rcourtman/Pulse</link>
      <description>&lt;p&gt;A responsive monitoring platform for Proxmox VE, PBS, and Docker with real-time metrics across nodes and containers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pulse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/rcourtman/Pulse" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;&lt;img src="https://img.shields.io/docker/pulls/rcourtman/pulse" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/rcourtman/Pulse" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Real-time monitoring for Proxmox VE, Proxmox Mail Gateway, PBS, and Docker infrastructure with alerts and webhooks.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Monitor your hybrid Proxmox and Docker estate from a single dashboard. Get instant alerts when nodes go down, containers misbehave, backups fail, or storage fills up. Supports email, Discord, Slack, Telegram, and more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.pulserelay.pro"&gt;Try the live demo ‚Üí&lt;/a&gt;&lt;/strong&gt; (read-only with mock data)&lt;/p&gt; 
&lt;img width="2872" height="1502" alt="image" src="https://github.com/user-attachments/assets/41ac125c-59e3-4bdc-bfd2-e300109aa1f7" /&gt; 
&lt;h2&gt;Support Pulse Development&lt;/h2&gt; 
&lt;p&gt;Pulse is built by a solo developer in evenings and weekends. Your support helps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keep me motivated to add new features&lt;/li&gt; 
 &lt;li&gt;Prioritize bug fixes and user requests&lt;/li&gt; 
 &lt;li&gt;Ensure Pulse stays 100% free and open-source forever&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/rcourtman"&gt;&lt;img src="https://img.shields.io/github/sponsors/rcourtman?style=social&amp;amp;label=Sponsor" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://ko-fi.com/rcourtman"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Not ready to sponsor?&lt;/strong&gt; Star the project or share it with your homelab community!&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Discovery&lt;/strong&gt;: Finds Proxmox nodes on your network, one-liner setup via generated scripts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cluster Support&lt;/strong&gt;: Configure one node, monitor entire cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest, masked in logs, never sent to frontend&lt;/li&gt; 
   &lt;li&gt;CSRF protection for all state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting (500 req/min general, 10 attempts/min for auth)&lt;/li&gt; 
   &lt;li&gt;Account lockout after failed login attempts&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Live monitoring of VMs, containers, nodes, storage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Alerts&lt;/strong&gt;: Email and webhooks (Discord, Slack, Telegram, Teams, ntfy.sh, Gotify) 
  &lt;ul&gt; 
   &lt;li&gt;Example: "VM 'webserver' is down on node 'pve1'"&lt;/li&gt; 
   &lt;li&gt;Example: "Storage 'local-lvm' at 85% capacity"&lt;/li&gt; 
   &lt;li&gt;Example: "VM 'database' is back online"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Thresholds&lt;/strong&gt;: Hysteresis-based trigger/clear levels, fractional network thresholds, per-metric search, reset-to-defaults, and Custom overrides with inline audit trail&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alert Timeline Analytics&lt;/strong&gt;: Rich history explorer with acknowledgement/clear markers, escalation breadcrumbs, and quick filters for noisy resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ceph Awareness&lt;/strong&gt;: Surface Ceph health, pool utilisation, and daemon status automatically when Proxmox exposes Ceph-backed storage&lt;/li&gt; 
 &lt;li&gt;Unified view of PBS backups, PVE backups, and snapshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Backup Explorer&lt;/strong&gt;: Cross-highlighted bar chart + grid with quick time-range pivots (24h/7d/30d/custom) and contextual tooltips for the busiest jobs&lt;/li&gt; 
 &lt;li&gt;Proxmox Mail Gateway analytics: mail volume, spam/virus trends, quarantine health, and cluster node status&lt;/li&gt; 
 &lt;li&gt;Optional Docker container monitoring via lightweight agent&lt;/li&gt; 
 &lt;li&gt;Config export/import with encryption and authentication&lt;/li&gt; 
 &lt;li&gt;Automatic stable updates with safe rollback (opt-in)&lt;/li&gt; 
 &lt;li&gt;Dark/light themes, responsive design&lt;/li&gt; 
 &lt;li&gt;Built with Go for minimal resource usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;Screenshots ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Privacy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Pulse respects your privacy:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No telemetry or analytics collection&lt;/li&gt; 
 &lt;li&gt;No phone-home functionality&lt;/li&gt; 
 &lt;li&gt;No external API calls (except for configured webhooks)&lt;/li&gt; 
 &lt;li&gt;All data stays on your server&lt;/li&gt; 
 &lt;li&gt;Open source - verify it yourself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your infrastructure data is yours alone.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Recommended: Official installer (auto-detects Proxmox and creates container)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Need to roll back to a previous release? Pass the tag you want
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.20.0

# Alternative: Docker
docker run -d -p 7655:7655 -v pulse_data:/data rcourtman/pulse:latest

# Testing: Install from main branch source (for testing latest fixes)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --source

# Alternative: Kubernetes (Helm)
helm registry login ghcr.io
helm install pulse oci://ghcr.io/rcourtman/pulse-chart \
  --version $(curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/VERSION) \
  --namespace pulse \
  --create-namespace
# Replace the VERSION lookup with a specific release if you need to pin. For local development, see docs/KUBERNETES.md.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proxmox users&lt;/strong&gt;: The installer detects PVE hosts and automatically creates an optimized LXC container. Choose Quick mode for one-minute setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/INSTALL.md"&gt;Advanced installation options ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Updating&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Automatic Updates (New!):&lt;/strong&gt; Enable during installation or via Settings UI to stay current automatically&lt;br /&gt; &lt;strong&gt;Standard Install:&lt;/strong&gt; Re-run the installer&lt;br /&gt; &lt;strong&gt;Docker:&lt;/strong&gt; &lt;code&gt;docker pull rcourtman/pulse:latest&lt;/code&gt; then recreate container&lt;/p&gt; 
&lt;h3&gt;Initial Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Interactive Setup (UI)&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;code&gt;http://&amp;lt;your-server&amp;gt;:7655&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete the mandatory security setup&lt;/strong&gt; (first-time only)&lt;/li&gt; 
 &lt;li&gt;Create your admin username and password&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;Settings ‚Üí Security ‚Üí API tokens&lt;/strong&gt; to mint dedicated tokens for automation (issue one token per integration so you can revoke credentials individually)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Automated Setup (No UI)&lt;/strong&gt; For automated deployments, configure authentication via environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start Pulse with auth pre-configured - skips setup screen
API_TOKENS="ansible-token,docker-agent-token" ./pulse

# Or use basic auth
PULSE_AUTH_USER=admin PULSE_AUTH_PASS=password ./pulse

# Plain text credentials are automatically hashed for security
# `API_TOKEN` is still accepted for back-compat, but `API_TOKENS` lets you manage multiple credentials
# You can also provide pre-hashed values if preferred
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md#automated-setup-skip-ui"&gt;Configuration Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Configure Nodes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Two authentication methods available:&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Method 1: Manual Setup (Recommended for interactive use)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;After login, go to Settings ‚Üí Nodes&lt;/li&gt; 
 &lt;li&gt;Discovered nodes appear automatically&lt;/li&gt; 
 &lt;li&gt;Click "Setup Script" next to any node&lt;/li&gt; 
 &lt;li&gt;Click "Generate Setup Code" button (creates a 6-character code valid for 5 minutes)&lt;/li&gt; 
 &lt;li&gt;Copy and run the provided one-liner on your Proxmox/PBS host&lt;/li&gt; 
 &lt;li&gt;Node is configured and monitoring starts automatically&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=ABC123" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Method 2: Automated Setup (For scripts/automation)&lt;/h4&gt; 
&lt;p&gt;Use your permanent API token directly in the URL for automation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Proxmox VE
curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=YOUR_API_TOKEN" | bash

# For Proxmox Backup Server
curl -sSL "http://pulse:7655/api/setup-script?type=pbs&amp;amp;host=https://pbs:8007&amp;amp;auth_token=YOUR_API_TOKEN" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: &lt;code&gt;pve&lt;/code&gt; for Proxmox VE, &lt;code&gt;pbs&lt;/code&gt; for Proxmox Backup Server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;host&lt;/code&gt;: Full URL of your Proxmox/PBS server (e.g., &lt;a href="https://192.168.1.100:8006"&gt;https://192.168.1.100:8006&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;auth_token&lt;/code&gt;: Either a 6-character setup code (expires in 5 min) or your permanent API token&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;backup_perms=true&lt;/code&gt; (optional): Add backup management permissions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pulse_url&lt;/code&gt; (optional): Pulse server URL if different from where script is downloaded&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script handles user creation, permissions, token generation, and registration automatically.&lt;/p&gt; 
&lt;h3&gt;Monitor Docker Containers (optional)&lt;/h3&gt; 
&lt;p&gt;Deploy the lightweight &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER_MONITORING.md"&gt;Pulse Docker agent&lt;/a&gt; on any host running Docker to stream container status and resource data back to Pulse. Install the agent alongside your stack, point it at your Pulse URL and API token, and the &lt;strong&gt;Docker&lt;/strong&gt; workspace lights up with host summaries, restart loop detection, per-container CPU/memory charts, and quick filters for stacks and unhealthy workloads.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Network Discovery&lt;/h3&gt; 
&lt;p&gt;Pulse automatically discovers Proxmox nodes on your network! By default, it scans:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;192.168.0.0/16 (home networks)&lt;/li&gt; 
 &lt;li&gt;10.0.0.0/8 (private networks)&lt;/li&gt; 
 &lt;li&gt;172.16.0.0/12 (Docker/internal networks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To scan a custom subnet instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e DISCOVERY_SUBNET="192.168.50.0/24" \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Automated Deployment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Deploy with authentication pre-configured
docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e API_TOKENS="ansible-token,docker-agent-token" \
  -e PULSE_AUTH_USER="admin" \
  -e PULSE_AUTH_PASS="your-password" \
  --restart unless-stopped \
  rcourtman/pulse:latest

# Plain text credentials are automatically hashed for security
# No setup required - API works immediately
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  pulse:
    image: rcourtman/pulse:latest
    container_name: pulse
    ports:
      - "7655:7655"
    volumes:
      - pulse_data:/data
    environment:
      # NOTE: Env vars override UI settings. Remove env var to allow UI configuration.
      
      # Network discovery (usually not needed - auto-scans common networks)
      # - DISCOVERY_SUBNET=192.168.50.0/24  # Only for non-standard networks
      
      # Ports
      # - PORT=7655                         # Backend port (default: 7655)
      # - FRONTEND_PORT=7655                # Frontend port (default: 7655)
      
      # Security (all optional - runs open by default)
      # - PULSE_AUTH_USER=admin             # Username for web UI login
      # - PULSE_AUTH_PASS=your-password     # Plain text or bcrypt hash (auto-hashed if plain)
      # - API_TOKENS=token-a,token-b        # Comma-separated tokens (plain or SHA3-256 hashed)
      # - API_TOKEN=legacy-token            # Optional single-token fallback
      # - ALLOW_UNPROTECTED_EXPORT=false    # Allow export without auth (default: false)
      
      # Security: Plain text credentials are automatically hashed
      # You can provide either:
      # 1. Plain text (auto-hashed): PULSE_AUTH_PASS=mypassword
      # 2. Pre-hashed (advanced): PULSE_AUTH_PASS='$$2a$$12$$...'
      #    Note: Escape $ as $$ in docker-compose.yml for pre-hashed values
      
      # Performance
      # - CONNECTION_TIMEOUT=10             # Connection timeout in seconds (default: 10)
      
      # CORS &amp;amp; logging
      # - ALLOWED_ORIGINS=https://app.example.com  # CORS origins (default: none, same-origin only)
      # - LOG_LEVEL=info                    # Log level: debug/info/warn/error (default: info)
    restart: unless-stopped

volumes:
  pulse_data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication required&lt;/strong&gt; - Protects your Proxmox infrastructure credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick setup wizard&lt;/strong&gt; - Secure your installation in under a minute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple auth methods&lt;/strong&gt;: Password authentication, API tokens, proxy auth (SSO), or combinations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy/SSO support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other authentication proxies (&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-grade protection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest (AES-256-GCM)&lt;/li&gt; 
   &lt;li&gt;CSRF tokens for state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting and account lockout protection&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security by design&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Frontend never receives node credentials&lt;/li&gt; 
   &lt;li&gt;API tokens visible only to authenticated users&lt;/li&gt; 
   &lt;li&gt;Export/import requires authentication when configured&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Documentation&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;h3&gt;Update Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse checks for updates and displays notifications in the UI when new versions are available. For security reasons, updates must be installed manually using the appropriate method for your deployment.&lt;/p&gt; 
&lt;h3&gt;Manual Installation (systemd)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update to latest stable
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Update to latest RC/pre-release  
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --rc

# Install specific version
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Updates&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Latest stable
docker pull rcourtman/pulse:latest

# Latest RC
docker pull rcourtman/pulse:rc

# Specific version
docker pull rcourtman/pulse:v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Quick start - most settings are in the web UI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Nodes&lt;/strong&gt;: Add/remove Proxmox instances&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí System&lt;/strong&gt;: Polling intervals, timeouts, update settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Security&lt;/strong&gt;: Authentication and API tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Thresholds and notifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apprise Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse can broadcast grouped alerts through &lt;a href="https://github.com/caronc/apprise"&gt;Apprise&lt;/a&gt; using either the local CLI or a remote Apprise API gateway. Configure everything under &lt;strong&gt;Alerts ‚Üí Notifications ‚Üí Apprise&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local CLI&lt;/strong&gt; ‚Äì Install Apprise on the Pulse host (for example &lt;code&gt;pip install apprise&lt;/code&gt;) and enter one Apprise URL per line in the delivery targets field. You can override the CLI path and timeout if the executable lives outside of &lt;code&gt;$PATH&lt;/code&gt;. Pulse skips CLI delivery automatically when no targets are configured.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote API&lt;/strong&gt; ‚Äì Point Pulse at an Apprise API server by providing the base URL (such as &lt;code&gt;https://apprise-api.local:8000&lt;/code&gt;). Optionally include a configuration key (for &lt;code&gt;/notify/{key}&lt;/code&gt; routes), an API key header/value pair, and allow self-signed certificates for lab deployments. Targets remain optional in API mode‚Äîleave the list empty to let the Apprise server use its stored defaults.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For both modes, delivery targets accept any Apprise URL (Discord, Slack, email, SMS, etc.). The timeout applies to the CLI process or HTTP request respectively.&lt;/p&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Pulse uses three separate configuration files with clear separation of concerns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - Authentication credentials only&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;system.json&lt;/code&gt; - Application settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nodes.enc&lt;/code&gt; - Encrypted node credentials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;docs/CONFIGURATION.md&lt;/a&gt; for detailed documentation on configuration structure and management.&lt;/p&gt; 
&lt;h3&gt;Email Alerts Configuration&lt;/h3&gt; 
&lt;p&gt;Configure email notifications in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Email Destinations&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Supported Providers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gmail/Google Workspace&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outlook/Office 365&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom SMTP&lt;/strong&gt;: Any SMTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Recommended Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Port 587 with STARTTLS&lt;/strong&gt; (recommended for most providers)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 465&lt;/strong&gt; for SSL/TLS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 25&lt;/strong&gt; for unencrypted (not recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Gmail Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable 2-factor authentication&lt;/li&gt; 
 &lt;li&gt;Generate app-specific password at &lt;a href="https://myaccount.google.com/apppasswords"&gt;https://myaccount.google.com/apppasswords&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp.gmail.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Outlook Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate app password at &lt;a href="https://account.microsoft.com/security"&gt;https://account.microsoft.com/security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp-mail.outlook.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Alert Configuration&lt;/h3&gt; 
&lt;p&gt;Pulse provides two complementary approaches for managing alerts:&lt;/p&gt; 
&lt;h4&gt;Custom Alert Rules (Permanent Policy)&lt;/h4&gt; 
&lt;p&gt;Configure persistent alert policies in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Custom Rules&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define thresholds for specific VMs/containers based on name patterns&lt;/li&gt; 
 &lt;li&gt;Set different thresholds for production vs development environments&lt;/li&gt; 
 &lt;li&gt;Create complex rules with AND/OR logic&lt;/li&gt; 
 &lt;li&gt;Manage all rules through the UI with priority ordering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Use for:&lt;/strong&gt; Long-term alert policies like "all database VMs should alert at 90%"&lt;/p&gt; 
&lt;h3&gt;HTTPS/TLS Configuration&lt;/h3&gt; 
&lt;p&gt;Enable HTTPS by setting these environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="HTTPS_ENABLED=true"
Environment="TLS_CERT_FILE=/etc/pulse/cert.pem"
Environment="TLS_KEY_FILE=/etc/pulse/key.pem"

# Docker
docker run -d -p 7655:7655 \
  -e HTTPS_ENABLED=true \
  -e TLS_CERT_FILE=/data/cert.pem \
  -e TLS_KEY_FILE=/data/key.pem \
  -v pulse_data:/data \
  -v /path/to/certs:/data/certs:ro \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For deployment overrides (ports, etc), use environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="FRONTEND_PORT=8080"

# Docker: -e FRONTEND_PORT=8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Full Configuration Guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Backup/Restore&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Via UI (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Settings ‚Üí Security ‚Üí Backup &amp;amp; Restore&lt;/li&gt; 
 &lt;li&gt;Export: Choose login password or custom passphrase for encryption&lt;/li&gt; 
 &lt;li&gt;Import: Upload backup file with passphrase&lt;/li&gt; 
 &lt;li&gt;Includes all settings, nodes, and custom console URLs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Via CLI:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Export (v4.0.3+)
pulse config export -o backup.enc

# Import
pulse config import -i backup.enc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Pulse shows when updates are available and provides deployment-specific instructions:&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull rcourtman/pulse:latest
docker stop pulse
docker rm pulse
# Run docker run command again with your settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The UI will detect your deployment type and show the appropriate update method when a new version is available.&lt;/p&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Status
curl http://localhost:7655/api/health

# Metrics (default time range: 1h)
curl http://localhost:7655/api/charts

# With authentication (if configured)
curl -H "X-API-Token: your-token" http://localhost:7655/api/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;Full API Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt; - Complete endpoint reference with examples&lt;/p&gt; 
&lt;h2&gt;Reverse Proxy &amp;amp; SSO&lt;/h2&gt; 
&lt;p&gt;Using Pulse behind a reverse proxy? &lt;strong&gt;WebSocket support is required for real-time updates.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NEW: Proxy Authentication Support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other SSO providers. See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Configuration Guide&lt;/a&gt; for nginx, Caddy, Apache, Traefik, HAProxy, and Cloudflare Tunnel configurations.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Authentication Issues&lt;/h3&gt; 
&lt;h4&gt;Cannot login after setting up security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Ensure bcrypt hash is exactly 60 characters and wrapped in single quotes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: MUST escape $ characters as $$ (e.g., &lt;code&gt;$$2a$$12$$...&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker run)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$2a$12$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker-compose.yml)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$$2a$$12$$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If hash is truncated or mangled, authentication will fail&lt;/li&gt; 
 &lt;li&gt;Use Quick Security Setup in the UI to avoid manual configuration errors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;.env file not created (Docker)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Expected behavior&lt;/strong&gt;: When using environment variables, no .env file is created in /data&lt;/li&gt; 
 &lt;li&gt;The .env file is only created when using Quick Security Setup or password changes&lt;/li&gt; 
 &lt;li&gt;If you provide credentials via environment variables, they take precedence&lt;/li&gt; 
 &lt;li&gt;To use Quick Security Setup: Start container WITHOUT auth environment variables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VM Disk Stats Show "-"&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;VMs require QEMU Guest Agent to report disk usage (Proxmox API returns 0 for VMs)&lt;/li&gt; 
 &lt;li&gt;Install guest agent in VM: &lt;code&gt;apt install qemu-guest-agent&lt;/code&gt; (Linux) or virtio-win tools (Windows)&lt;/li&gt; 
 &lt;li&gt;Enable in VM Options ‚Üí QEMU Guest Agent, then restart VM&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring Guide&lt;/a&gt; for setup&lt;/li&gt; 
 &lt;li&gt;Container (LXC) disk stats always work (no guest agent needed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check Proxmox API is accessible (port 8006/8007)&lt;/li&gt; 
 &lt;li&gt;Verify credentials have PVEAuditor role plus VM.GuestAgent.Audit (PVE 9) or VM.Monitor (PVE 8); the setup script applies these via the PulseMonitor role (adds Sys.Audit when available)&lt;/li&gt; 
 &lt;li&gt;For PBS: ensure API token has Datastore.Audit permission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High CPU/Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce polling interval in Settings&lt;/li&gt; 
 &lt;li&gt;Check number of monitored nodes&lt;/li&gt; 
 &lt;li&gt;Disable unused features (backups, snapshots)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker logs pulse

# Manual
journalctl -u pulse -f
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER.md"&gt;Docker Guide&lt;/a&gt; - Complete Docker deployment guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Configuration Guide&lt;/a&gt; - Complete setup and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring&lt;/a&gt; - Set up QEMU Guest Agent for accurate VM disk usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PORT_CONFIGURATION.md"&gt;Port Configuration&lt;/a&gt; - How to change the default port&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt; - Common issues and solutions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;API Reference&lt;/a&gt; - REST API endpoints and examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/WEBHOOKS.md"&gt;Webhook Guide&lt;/a&gt; - Setting up webhooks and custom payloads&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication&lt;/a&gt; - SSO integration with Authentik, Authelia, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Setup&lt;/a&gt; - nginx, Caddy, Apache, Traefik configs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security&lt;/a&gt; - Security features and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/FAQ.md"&gt;FAQ&lt;/a&gt; - Common questions and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/MIGRATION.md"&gt;Migration Guide&lt;/a&gt; - Backup and migration procedures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mandatory authentication&lt;/strong&gt; protects your infrastructure&lt;/li&gt; 
 &lt;li&gt;Credentials stored encrypted (AES-256-GCM)&lt;/li&gt; 
 &lt;li&gt;API token support for automation&lt;/li&gt; 
 &lt;li&gt;Export/import requires authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Setup script authentication&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Setup codes&lt;/strong&gt;: Temporary 6-character codes for manual setup (expire in 5 minutes)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API tokens&lt;/strong&gt;: Permanent tokens for automation and scripting&lt;/li&gt; 
   &lt;li&gt;Use setup codes when giving access to others without sharing your API token&lt;/li&gt; 
   &lt;li&gt;Use API tokens for your own automation or trusted environments&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Details ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Quick Start - Hot Reload (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch Vite + Go with automatic frontend proxying
make dev-hot
# Frontend HMR: http://127.0.0.1:5173
# Backend API:   http://127.0.0.1:7655 (served via the Go app)
# Ports come from FRONTEND_PORT/PULSE_DEV_API_PORT (loaded from .env*. Override there if you need a different port.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The backend now detects &lt;code&gt;FRONTEND_DEV_SERVER&lt;/code&gt; and proxies requests straight to the Vite dev server. Edit files under &lt;code&gt;frontend-modern/src/&lt;/code&gt; and the browser refreshes instantly‚Äîno manual rebuilds or service restarts required. Use &lt;code&gt;CTRL+C&lt;/code&gt; to stop both processes.&lt;/p&gt; 
&lt;h3&gt;Mock Mode - Develop Without Real Infrastructure&lt;/h3&gt; 
&lt;p&gt;Work on Pulse without needing Proxmox servers! Mock mode generates realistic test data and auto-reloads when toggled. The &lt;code&gt;mock.env&lt;/code&gt; configuration file is &lt;strong&gt;included in the repository&lt;/strong&gt;, so it works out of the box for all developers.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable mock mode with 7 nodes, ~90 guests
npm run mock:on

# Disable mock mode (use real infrastructure)
npm run mock:off

# Edit mock configuration
npm run mock:edit

# Create local overrides (not committed to git)
cp mock.env mock.env.local
# Edit mock.env.local with your personal preferences

# Data directories are isolated automatically:
# - Mock mode:   /opt/pulse/tmp/mock-data
# - Production:  /etc/pulse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Backend auto-reloads when mock.env changes - no manual restarts!&lt;/strong&gt; The toggle scripts keep mock data isolated from &lt;code&gt;/etc/pulse&lt;/code&gt; so your real credentials stay untouched.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/development/MOCK_MODE.md"&gt;docs/development/MOCK_MODE.md&lt;/a&gt; for full details.&lt;/p&gt; 
&lt;h3&gt;Production-like Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Watches files and rebuilds/embeds frontend into Go binary
./dev.sh
# Access at: http://localhost:7655
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Frontend only
cd frontend-modern
npm install
npm run dev

# Backend only
go build -o pulse ./cmd/pulse
./pulse

# Or use make for full rebuild
make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Visual Tour&lt;/h2&gt; 
&lt;p&gt;See Pulse in action with our &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;complete screenshot gallery ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dashboard&lt;/th&gt; 
   &lt;th&gt;Storage&lt;/th&gt; 
   &lt;th&gt;Backups&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/01-dashboard.png" alt="Dashboard" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/02-storage.png" alt="Storage" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/03-backups.png" alt="Backups" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Real-time monitoring of nodes, VMs &amp;amp; containers&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Storage pool usage across all nodes&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unified backup management &amp;amp; PBS integration&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Alerts &amp;amp; Configuration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alert Configuration&lt;/th&gt; 
   &lt;th&gt;Alert History&lt;/th&gt; 
   &lt;th&gt;Settings&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/04-alerts.png" alt="Alerts" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/05-alert-history.png" alt="Alert History" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/06-settings.png" alt="Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Configure thresholds &amp;amp; notifications&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Track patterns with visual timeline&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Manage nodes &amp;amp; authentication&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Mobile Experience&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mobile Dashboard&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/08-mobile.png" alt="Mobile" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Fully responsive interface for monitoring on the go&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;Docker Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT - See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juanfont/headscale</title>
      <link>https://github.com/juanfont/headscale</link>
      <description>&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juanfont/headscale/main/docs/logo/headscale3_header_stacked_left.png" alt="headscale logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/juanfont/headscale/actions/workflows/test.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, self-hosted implementation of the Tailscale control server.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/c84AZQhmpx"&gt;Discord server&lt;/a&gt; for a chat.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Always select the same GitHub tag as the released version you use to ensure you have the correct example configuration. The &lt;code&gt;main&lt;/code&gt; branch might contain unreleased changes. The documentation is available for stable and development versions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/stable/"&gt;Documentation for the stable version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://headscale.net/development/"&gt;Documentation for the development version&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Tailscale&lt;/h2&gt; 
&lt;p&gt;Tailscale is &lt;a href="https://tailscale.com/"&gt;a modern VPN&lt;/a&gt; built on top of &lt;a href="https://www.wireguard.com/"&gt;Wireguard&lt;/a&gt;. It &lt;a href="https://tailscale.com/blog/how-tailscale-works/"&gt;works like an overlay network&lt;/a&gt; between the computers of your networks - using &lt;a href="https://tailscale.com/blog/how-nat-traversal-works/"&gt;NAT traversal&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Everything in Tailscale is Open Source, except the GUI clients for proprietary OS (Windows and macOS/iOS), and the control server.&lt;/p&gt; 
&lt;p&gt;The control server works as an exchange point of Wireguard public keys for the nodes in the Tailscale network. It assigns the IP addresses of the clients, creates the boundaries between each user, enables sharing machines between users, and exposes the advertised routes of your nodes.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://tailscale.com/kb/1136/tailnet/"&gt;Tailscale network (tailnet)&lt;/a&gt; is private network which Tailscale assigns to a user in terms of private users or an organisation.&lt;/p&gt; 
&lt;h2&gt;Design goal&lt;/h2&gt; 
&lt;p&gt;Headscale aims to implement a self-hosted, open source alternative to the &lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; control server. Headscale's goal is to provide self-hosters and hobbyists with an open-source server they can use for their projects and labs. It implements a narrow scope, a &lt;em&gt;single&lt;/em&gt; Tailscale network (tailnet), suitable for a personal use, or a small open-source organisation.&lt;/p&gt; 
&lt;h2&gt;Supporting Headscale&lt;/h2&gt; 
&lt;p&gt;If you like &lt;code&gt;headscale&lt;/code&gt; and find it useful, there is a sponsorship and donation buttons available in the repo.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/features/"&gt;"Features" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Client OS support&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://headscale.net/stable/about/clients/"&gt;"Client and operating system support" in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running headscale&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Please note that we do not support nor encourage the use of reverse proxies and container to run Headscale.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Please have a look at the &lt;a href="https://headscale.net/stable/"&gt;&lt;code&gt;documentation&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Talks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fosdem 2023 (video): &lt;a href="https://fosdem.org/2023/schedule/event/goheadscale/"&gt;Headscale: How we are using integration testing to reimplement Tailscale&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;presented by Juan Font Alonso and Kristoffer Dalby&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is not associated with Tailscale Inc.&lt;/p&gt; 
&lt;p&gt;However, one of the active maintainers for Headscale &lt;a href="https://tailscale.com/blog/opensource"&gt;is employed by Tailscale&lt;/a&gt; and he is allowed to spend work hours contributing to the project. Contributions from this maintainer are reviewed by other maintainers.&lt;/p&gt; 
&lt;p&gt;The maintainers work together on setting the direction for the project. The underlying principle is to serve the community of self-hosters, enthusiasts and hobbyists - while having a sustainable project.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/juanfont/headscale/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;p&gt;To contribute to headscale you would need the latest version of &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; and &lt;a href="https://buf.build"&gt;Buf&lt;/a&gt; (Protobuf generator).&lt;/p&gt; 
&lt;p&gt;We recommend using &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt; to setup a development environment. This can be done with &lt;code&gt;nix develop&lt;/code&gt;, which will install the tools and give you a shell. This guarantees that you will have the same dev env as &lt;code&gt;headscale&lt;/code&gt; maintainers.&lt;/p&gt; 
&lt;h3&gt;Code style&lt;/h3&gt; 
&lt;p&gt;To ensure we have some consistency with a growing number of contributions, this project has adopted linting and style/formatting rules:&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Go&lt;/strong&gt; code is linted with &lt;a href="https://golangci-lint.run"&gt;&lt;code&gt;golangci-lint&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://github.com/segmentio/golines"&gt;&lt;code&gt;golines&lt;/code&gt;&lt;/a&gt; (width 88) and &lt;a href="https://github.com/mvdan/gofumpt"&gt;&lt;code&gt;gofumpt&lt;/code&gt;&lt;/a&gt;. Please configure your editor to run the tools while developing and make sure to run &lt;code&gt;make lint&lt;/code&gt; and &lt;code&gt;make fmt&lt;/code&gt; before committing any code.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;Proto&lt;/strong&gt; code is linted with &lt;a href="https://docs.buf.build/lint/overview"&gt;&lt;code&gt;buf&lt;/code&gt;&lt;/a&gt; and formatted with &lt;a href="https://clang.llvm.org/docs/ClangFormat.html"&gt;&lt;code&gt;clang-format&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;rest&lt;/strong&gt; (Markdown, YAML, etc) is formatted with &lt;a href="https://prettier.io"&gt;&lt;code&gt;prettier&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;code&gt;.golangci.yaml&lt;/code&gt; and &lt;code&gt;Makefile&lt;/code&gt; to see the specific configuration.&lt;/p&gt; 
&lt;h3&gt;Install development tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go&lt;/li&gt; 
 &lt;li&gt;Buf&lt;/li&gt; 
 &lt;li&gt;Protobuf tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Install and activate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing and building&lt;/h3&gt; 
&lt;p&gt;Some parts of the project require the generation of Go code from Protobuf (if changes are made in &lt;code&gt;proto/&lt;/code&gt;) and it must be (re-)generated with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please check in changes from &lt;code&gt;gen/&lt;/code&gt; in a separate commit to make it easier to review.&lt;/p&gt; 
&lt;p&gt;To run the tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;p&gt;We recommend using Nix for dependency management to ensure you have all required tools. If you prefer to manage dependencies yourself, you can use Make directly:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With Nix (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;nix develop
make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With your own dependencies:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
make build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Makefile will warn you if any required tools are missing and suggest running &lt;code&gt;nix develop&lt;/code&gt;. Run &lt;code&gt;make help&lt;/code&gt; to see all available targets.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/juanfont/headscale/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=juanfont/headscale" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>synctv-org/synctv</title>
      <link>https://github.com/synctv-org/synctv</link>
      <description>&lt;p&gt;Synchronized viewing, theater, live streaming, video&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/synctv-org/docs"&gt;&lt;img height="100px" alt="logo" src="https://cdn.jsdelivr.net/gh/synctv-org/docs@main/logo/logo.png" /&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;em&gt;üë´A program that allows you to watch movies/live broadcasts together remotelyüçø&lt;/em&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;a href="https://goreportcard.com/report/github.com/synctv-org/synctv"&gt; &lt;img src="https://goreportcard.com/badge/github.com/synctv-org/synctv" alt="latest version" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/synctv-org/synctv/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/synctv-org/synctv" alt="License" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/synctv-org/synctv/actions?query=workflow%3Arelease"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/synctv-org/synctv/release.yml?branch=main" alt="Release status" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/synctv-org/synctv/releases"&gt; &lt;img src="https://img.shields.io/github/release/synctv-org/synctv" alt="latest version" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div&gt; 
  &lt;a href="https://github.com/synctv-org/synctv/releases"&gt; &lt;img src="https://img.shields.io/github/downloads/synctv-org/synctv/total?color=%239F7AEA&amp;amp;logo=github" alt="Downloads" /&gt; &lt;/a&gt; 
  &lt;a href="https://hub.docker.com/r/synctvorg/synctv"&gt; &lt;img src="https://img.shields.io/docker/pulls/synctvorg/synctv?color=%2348BB78&amp;amp;logo=docker&amp;amp;label=pulls" alt="Downloads" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/synctv-org/synctv/main/README-CN.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;What is SyncTV?&lt;/h1&gt; 
&lt;p&gt;SyncTV is a program that allows you to watch movies and live broadcasts together remotely. It provides features such as synchronized viewing, live streaming, and chat. With SyncTV, you can watch videos and live broadcasts with friends and family, no matter where they are.&lt;/p&gt; 
&lt;p&gt;SyncTV's synchronized viewing feature ensures that everyone watching the video is at the same point. This means that you can pause, fast forward, rewind, change playback speed, and other operations, and everyone else will be synchronized to the same point.&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Synchronized viewing 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Videos Sync&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live streaming&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Theater 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Chat&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bullet chat&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Proxy 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Videos proxy&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Live proxy&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Proxy cache&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Parse video 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Alist&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bilibili&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Emby&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Parse live 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bilibili&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; WebRTC online call 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Audio&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Video&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Screen&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://demo.synctv.wiki"&gt;https://demo.synctv.wiki&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;h2&gt;Binary&lt;/h2&gt; 
&lt;p&gt;You can download the latest binary from &lt;a href="https://github.com/synctv-org/synctv/releases"&gt;release page&lt;/a&gt; and install it manually.&lt;/p&gt; 
&lt;h2&gt;Script&lt;/h2&gt; 
&lt;p&gt;You can use the script to install and run SyncTV.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo -v ; curl -fsSL https://raw.githubusercontent.com/synctv-org/synctv/main/script/install.sh | sudo bash -s -- -v latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;You can also use docker to install and run SyncTV.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name synctv -v /opt/synctv:/root/.synctv -p 8080:8080 synctvorg/synctv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker compose&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/synctv-org/synctv/main/script/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Helm&lt;/h2&gt; 
&lt;h3&gt;Helm Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm repo add synctv https://docs.synctv.wiki/helm-charts
helm repo update synctv
helm upgrade --install synctv synctv/synctv \
  -n synctv --create-namespace \
  --set ingress.enabled=true \
  --set ingress.className=nginx \
  --set 'ingress.hosts[0].host=&amp;lt;yourdomain.com&amp;gt;' \
  --set 'ingress.hosts[0].secretName=&amp;lt;yourdomain-secretName&amp;gt;'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helm Upgrade&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm repo update synctv
helm upgrade --install synctv synctv/synctv \
  -n synctv \
  --reuse-values
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;More Helm Values:&lt;a href="https://raw.githubusercontent.com/synctv-org/synctv/main/helm-values.md"&gt;helm-values&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Helm Uninstall&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;helm uninstall -n synctv synctv
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Run&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;synctv server&lt;/code&gt; to start the server&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;synctv server
# or
synctv server --data-dir ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Every time it starts, it will check for users with root permissions. If none are found, it will initialize a &lt;code&gt;root&lt;/code&gt; user with the password &lt;code&gt;root&lt;/code&gt;. Please change the username and password promptly.&lt;/p&gt; 
 &lt;p&gt;The user registration function requires the use of any &lt;code&gt;OAuth2&lt;/code&gt; service, such as &lt;code&gt;Google&lt;/code&gt;, &lt;code&gt;Github&lt;/code&gt;, etc. For specific configuration, please refer to &lt;a href="https://docs.synctv.wiki/#/oauth2"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.synctv.wiki"&gt;https://docs.synctv.wiki&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Special sponsors&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.asiayun.com"&gt;‰∫öÊ¥≤‰∫ë&lt;/a&gt; supports the server for the &lt;a href="https://demo.synctv.wiki"&gt;demo&lt;/a&gt; site.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://swarmcloud.net/"&gt;SwarmCloud&lt;/a&gt; ¬• 200 and provides video P2P acceleration. 
  &lt;ul&gt; 
   &lt;li&gt;When the server network bandwidth is insufficient, you can consider using P2P video acceleration technology.&lt;/li&gt; 
   &lt;li&gt;If you want to use P2P video acceleration technology for free, you can view the documentation &lt;a href="https://docs.synctv.wiki/#/p2p"&gt;P2P video acceleration&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LucasYuYu"&gt;LucasYuYu&lt;/a&gt; ¬• 18.88&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://afdian.com/u/48fa38ce0e0211ef944d5254001e7c00"&gt;Áà±ÂèëÁîµÁî®Êà∑_5vDc&lt;/a&gt; ¬• 228&lt;/li&gt; 
 &lt;li&gt;masha&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/T-rabbit"&gt;T-rabbit&lt;/a&gt; ¬• 5&lt;/li&gt; 
 &lt;li&gt;ÁüøÁ•ûSPKÊ∫ê ¬• 100&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;p&gt;Thanks goes to these wonderful people:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/synctv-org/synctv/graphs/contributors"&gt;&lt;img src="https://contrib.nn.ci/api?repo=synctv-org/synctv&amp;amp;repo=synctv-org/synctv-web&amp;amp;repo=synctv-org/docs" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;SyncTV&lt;/code&gt; is open-source software licensed under the AGPL-3.0 license.&lt;/p&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;This program is a free and open-source project. It aims to play video files on the internet, making it convenient for multiple people to watch videos and learn golang together.&lt;/li&gt; 
 &lt;li&gt;Please comply with relevant laws and regulations when using it, and do not abuse it.&lt;/li&gt; 
 &lt;li&gt;The program only plays video files/forwards traffic on the client-side and will not intercept, store, or tamper with any user data.&lt;/li&gt; 
 &lt;li&gt;Before using the program, you should understand and assume the corresponding risks, including but not limited to copyright disputes, legal restrictions, etc., which are not related to the program.&lt;/li&gt; 
 &lt;li&gt;If there is any infringement, please contact me via &lt;a href="mailto:pyh1670605849@gmail.com"&gt;email&lt;/a&gt;, and it will be dealt with promptly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Discussion&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://t.me/synctv"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>henrygd/beszel</title>
      <link>https://github.com/henrygd/beszel</link>
      <description>&lt;p&gt;Lightweight server monitoring hub with historical data, docker stats, and alerts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Beszel&lt;/h1&gt; 
&lt;p&gt;Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.&lt;/p&gt; 
&lt;p&gt;It has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/henrygd/beszel-agent"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&amp;amp;label=agent%20image%20size" alt="agent Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/henrygd/beszel"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&amp;amp;label=hub%20image%20size" alt="hub Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/henrygd/beszel/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/henrygd/beszel?color=%239944ee" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/beszel"&gt;&lt;img src="https://badges.crowdin.net/beszel/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png" alt="Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system." /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Smaller and less resource-intensive than leading solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy setup with little manual configuration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker stats&lt;/strong&gt;: Tracks CPU, memory, and network usage history for each container.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;: Users manage their own systems. Admins can share systems across users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OAuth / OIDC&lt;/strong&gt;: Supports many OAuth2 providers. Password auth can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic backups&lt;/strong&gt;: Save to and restore from disk or S3-compatible storage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - **REST API**: Use or update your data in your own scripts and applications. --&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Beszel consists of two main components: the &lt;strong&gt;hub&lt;/strong&gt; and the &lt;strong&gt;agent&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hub&lt;/strong&gt;: A web application built on &lt;a href="https://pocketbase.io/"&gt;PocketBase&lt;/a&gt; that provides a dashboard for viewing and managing connected systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: Runs on each system you want to monitor and communicates system metrics to the hub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://beszel.dev/guide/getting-started"&gt;quick start guide&lt;/a&gt; and other documentation is available on our website, &lt;a href="https://beszel.dev"&gt;beszel.dev&lt;/a&gt;. You'll be up and running in a few minutes.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://beszel.dev/image/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://beszel.dev/image/system-full.png" alt="System page" /&gt; &lt;img src="https://beszel.dev/image/settings-notifications.png" alt="Notification Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;Supported metrics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU usage&lt;/strong&gt; - Host system and Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory usage&lt;/strong&gt; - Host system and containers. Includes swap and ZFS ARC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk usage&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk I/O&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network usage&lt;/strong&gt; - Host system and containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Load average&lt;/strong&gt; - Host system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; - Host system sensors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU usage / power draw&lt;/strong&gt; - Nvidia, AMD, and Intel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt; - Host system battery charge.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Containers&lt;/strong&gt; - Status and metrics of all running Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S.M.A.R.T.&lt;/strong&gt; - Host system disk health.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Help and discussion&lt;/h2&gt; 
&lt;p&gt;Please search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.&lt;/p&gt; 
&lt;h4&gt;Bug reports and feature requests&lt;/h4&gt; 
&lt;p&gt;Bug reports and feature requests can be posted on &lt;a href="https://github.com/henrygd/beszel/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Support and general discussion&lt;/h4&gt; 
&lt;p&gt;Support requests and general discussion can be posted on &lt;a href="https://github.com/henrygd/beszel/discussions"&gt;GitHub discussions&lt;/a&gt; or the community-run &lt;a href="https://matrix.to/#/#beszel:matrix.org"&gt;Matrix room&lt;/a&gt;: &lt;code&gt;#beszel:matrix.org&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Beszel is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/henrygd/beszel/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uber-go/zap</title>
      <link>https://github.com/uber-go/zap</link>
      <description>&lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uber-go/zap/master/assets/logo.png" alt="Zap logo" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;&lt;img src="https://pkg.go.dev/badge/go.uber.org/zap" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uber-go/zap/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/uber-go/zap/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/uber-go/zap"&gt;&lt;img src="https://codecov.io/gh/uber-go/zap/branch/master/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;go get -u go.uber.org/zap&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note that zap only supports the two most recent minor versions of Go.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;In contexts where performance is nice, but not critical, use the &lt;code&gt;SugaredLogger&lt;/code&gt;. It's 4-10x faster than other structured logging packages and includes both structured and &lt;code&gt;printf&lt;/code&gt;-style APIs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync() // flushes buffer, if any
sugar := logger.Sugar()
sugar.Infow("failed to fetch URL",
  // Structured context as loosely typed key-value pairs.
  "url", url,
  "attempt", 3,
  "backoff", time.Second,
)
sugar.Infof("Failed to fetch URL: %s", url)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When performance and type safety are critical, use the &lt;code&gt;Logger&lt;/code&gt;. It's even faster than the &lt;code&gt;SugaredLogger&lt;/code&gt; and allocates far less, but it only supports structured logging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync()
logger.Info("failed to fetch URL",
  // Structured context as strongly typed Field values.
  zap.String("url", url),
  zap.Int("attempt", 3),
  zap.Duration("backoff", time.Second),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/FAQ.md"&gt;FAQ&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;For applications that log in the hot path, reflection-based serialization and string formatting are prohibitively expensive ‚Äî they're CPU-intensive and make many small allocations. Put differently, using &lt;code&gt;encoding/json&lt;/code&gt; and &lt;code&gt;fmt.Fprintf&lt;/code&gt; to log tons of &lt;code&gt;interface{}&lt;/code&gt;s makes your application slow.&lt;/p&gt; 
&lt;p&gt;Zap takes a different approach. It includes a reflection-free, zero-allocation JSON encoder, and the base &lt;code&gt;Logger&lt;/code&gt; strives to avoid serialization overhead and allocations wherever possible. By building the high-level &lt;code&gt;SugaredLogger&lt;/code&gt; on that foundation, zap lets users &lt;em&gt;choose&lt;/em&gt; when they need to count every allocation and when they'd prefer a more familiar, loosely typed API.&lt;/p&gt; 
&lt;p&gt;As measured by its own &lt;a href="https://github.com/uber-go/zap/tree/master/benchmarks"&gt;benchmarking suite&lt;/a&gt;, not only is zap more performant than comparable structured logging packages ‚Äî it's also faster than the standard library. Like all benchmarks, take these with a grain of salt.&lt;sup id="anchor-versions"&gt;&lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#footnote-versions"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Log a message and 10 fields:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;656 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;935 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+43%&lt;/td&gt; 
   &lt;td align="center"&gt;10 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;380 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-42%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2249 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+243%&lt;/td&gt; 
   &lt;td align="center"&gt;57 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;2479 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;40 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;2481 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;42 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9591 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1362%&lt;/td&gt; 
   &lt;td align="center"&gt;63 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;11393 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1637%&lt;/td&gt; 
   &lt;td align="center"&gt;75 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;11654 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1677%&lt;/td&gt; 
   &lt;td align="center"&gt;79 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a message with a logger that already has 10 fields of context:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;67 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;84 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+25%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;35 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-48%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;193 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+188%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+199%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2460 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3572%&lt;/td&gt; 
   &lt;td align="center"&gt;56 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;9038 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13390%&lt;/td&gt; 
   &lt;td align="center"&gt;70 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9068 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13434%&lt;/td&gt; 
   &lt;td align="center"&gt;53 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;10521 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+15603%&lt;/td&gt; 
   &lt;td align="center"&gt;68 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a static string, without any context or &lt;code&gt;printf&lt;/code&gt;-style templating:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;63 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;81 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+29%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;32 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-49%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;standard library&lt;/td&gt; 
   &lt;td align="center"&gt;124 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+97%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;196 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+211%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+217%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;213 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+238%&lt;/td&gt; 
   &lt;td align="center"&gt;9 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;771 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1124%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;1439 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+2184%&lt;/td&gt; 
   &lt;td align="center"&gt;23 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;2069 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3184%&lt;/td&gt; 
   &lt;td align="center"&gt;20 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Development Status: Stable&lt;/h2&gt; 
&lt;p&gt;All APIs are finalized, and no breaking changes will be made in the 1.x series of releases. Users of semver-aware dependency management systems should pin zap to &lt;code&gt;^1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and support an active, healthy community of contributors ‚Äî including you! Details are in the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;. The zap maintainers keep an eye on issues and pull requests, but you can also report any negative conduct to &lt;a href="mailto:oss-conduct@uber.com"&gt;oss-conduct@uber.com&lt;/a&gt;. That email list is a private, safe space; even the zap maintainers don't have access, so don't hesitate to hold us to a high standard.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Released under the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;sup id="footnote-versions"&gt;1&lt;/sup&gt; In particular, keep in mind that we may be benchmarking against slightly older versions of other packages. Versions are pinned in the &lt;a href="https://github.com/uber-go/zap/raw/master/benchmarks/go.mod"&gt;benchmarks/go.mod&lt;/a&gt; file. &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#anchor-versions"&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Notifuse/notifuse</title>
      <link>https://github.com/Notifuse/notifuse</link>
      <description>&lt;p&gt;Notifuse is an open-source &amp; modern emailing platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Notifuse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/Notifuse/notifuse"&gt;&lt;img src="https://img.shields.io/badge/go%20report-A+-brightgreen.svg?style=flat" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Notifuse/notifuse/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/Notifuse/notifuse/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Go" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/Notifuse/notifuse"&gt;&lt;img src="https://codecov.io/gh/Notifuse/notifuse/graph/badge.svg?token=VZ0HBEM9OZ" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;üéØ Try the Live Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The open-source alternative to Mailchimp, Brevo, Mailjet, Listmonk, Mailerlite, and Klaviyo, Loop.so, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Notifuse is a modern, self-hosted emailing platform that allows you to send newsletters and transactional emails at a fraction of the cost. Built with Go and React, it provides enterprise-grade features with the flexibility of open-source software.&lt;/p&gt; 
&lt;img src="https://www.notifuse.com/_astro/email_editor.CGyLoCOD.png" alt="Email Editor" /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;h3&gt;üìß Email Marketing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Email Builder&lt;/strong&gt;: Drag-and-drop editor with MJML components and real-time preview&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Management&lt;/strong&gt;: Create, schedule, and send targeted email campaigns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A/B Testing&lt;/strong&gt;: Optimize campaigns with built-in testing for subject lines, content, and send times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List Management&lt;/strong&gt;: Advanced subscriber segmentation and list organization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact Profiles&lt;/strong&gt;: Rich contact management with custom fields and detailed profiles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß Developer-Friendly&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Setup&lt;/strong&gt;: Interactive setup wizard for quick deployment and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transactional API&lt;/strong&gt;: Powerful REST API for automated email delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook Integration&lt;/strong&gt;: Real-time event notifications and integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Liquid Templating&lt;/strong&gt;: Dynamic content with variables like &lt;code&gt;{{ contact.first_name }}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Provider Support&lt;/strong&gt;: Connect with Amazon SES, Mailgun, Postmark, Mailjet, SparkPost, and SMTP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä Analytics &amp;amp; Insights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open &amp;amp; Click Tracking&lt;/strong&gt;: Detailed engagement metrics and campaign performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Analytics&lt;/strong&gt;: Monitor delivery rates, opens, clicks, and conversions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Reports&lt;/strong&gt;: Comprehensive reporting and analytics dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üé® Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;S3 File Manager&lt;/strong&gt;: Integrated file management with CDN delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Centralized notification system for your applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Templates&lt;/strong&gt;: Mobile-optimized email templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Fields&lt;/strong&gt;: Flexible contact data management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workspace Management&lt;/strong&gt;: Multi-tenant support for teams and agencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;Notifuse follows clean architecture principles with clear separation of concerns:&lt;/p&gt; 
&lt;h3&gt;Backend (Go)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Domain Layer&lt;/strong&gt;: Core business logic and entities (&lt;code&gt;internal/domain/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service Layer&lt;/strong&gt;: Business logic implementation (&lt;code&gt;internal/service/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository Layer&lt;/strong&gt;: Data access and storage (&lt;code&gt;internal/repository/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Layer&lt;/strong&gt;: API handlers and middleware (&lt;code&gt;internal/http/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Frontend (React)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Console&lt;/strong&gt;: Admin interface built with React, Ant Design, and TypeScript (&lt;code&gt;console/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Embeddable widget for customer notifications (&lt;code&gt;notification_center/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;: Primary data storage with Squirrel query builder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÅ Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;‚îú‚îÄ‚îÄ cmd/                    # Application entry points
‚îú‚îÄ‚îÄ internal/               # Private application code
‚îÇ   ‚îú‚îÄ‚îÄ domain/            # Business entities and logic
‚îÇ   ‚îú‚îÄ‚îÄ service/           # Business logic implementation
‚îÇ   ‚îú‚îÄ‚îÄ repository/        # Data access layer
‚îÇ   ‚îú‚îÄ‚îÄ http/              # HTTP handlers and middleware
‚îÇ   ‚îî‚îÄ‚îÄ database/          # Database configuration
‚îú‚îÄ‚îÄ console/               # React-based admin interface
‚îú‚îÄ‚îÄ notification_center/   # Embeddable notification widget
‚îú‚îÄ‚îÄ pkg/                   # Public packages
‚îî‚îÄ‚îÄ config/                # Configuration files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;One-click deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://railway.com/deploy/aBzOMu?referralCode=73Ps3m"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start with Docker Compose&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Notifuse/notifuse.git
cd notifuse
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure required environment variables&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env
# Edit .env with database credentials and SECRET_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Minimum required variables&lt;/strong&gt;: &lt;code&gt;DB_HOST&lt;/code&gt;, &lt;code&gt;DB_PORT&lt;/code&gt;, &lt;code&gt;DB_USER&lt;/code&gt;, &lt;code&gt;DB_PASSWORD&lt;/code&gt;, &lt;code&gt;SECRET_KEY&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the services&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the application and complete setup&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Open &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Follow the interactive &lt;strong&gt;Setup Wizard&lt;/strong&gt; to configure: 
    &lt;ul&gt; 
     &lt;li&gt;Root administrator email&lt;/li&gt; 
     &lt;li&gt;API endpoint&lt;/li&gt; 
     &lt;li&gt;SMTP settings&lt;/li&gt; 
     &lt;li&gt;PASETO keys (automatically generated)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Save the generated keys securely!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Alternative&lt;/strong&gt;: You can skip the setup wizard by pre-configuring all environment variables in your &lt;code&gt;.env&lt;/code&gt; file. Generate PASETO keys at &lt;a href="https://paseto.notifuse.com"&gt;paseto.notifuse.com&lt;/a&gt; or use &lt;code&gt;make keygen&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Environment Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important&lt;/strong&gt;: The included &lt;code&gt;docker-compose.yml&lt;/code&gt; is designed for &lt;strong&gt;testing and development only&lt;/strong&gt;. For production deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use a separate PostgreSQL database&lt;/strong&gt; (managed service recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure external storage&lt;/strong&gt; for file uploads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set up proper SSL/TLS termination&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use a reverse proxy&lt;/strong&gt; (nginx, Traefik, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development Setup&lt;/h4&gt; 
&lt;p&gt;The docker-compose includes a PostgreSQL container for quick testing. Simply run &lt;code&gt;docker-compose up -d&lt;/code&gt; to get started, then complete the setup wizard in your browser.&lt;/p&gt; 
&lt;h4&gt;Production Setup&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Required Environment Variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DB_HOST&lt;/code&gt;, &lt;code&gt;DB_PORT&lt;/code&gt;, &lt;code&gt;DB_USER&lt;/code&gt;, &lt;code&gt;DB_PASSWORD&lt;/code&gt; - External PostgreSQL database&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SECRET_KEY&lt;/code&gt; - Secret key for encrypting sensitive data (or &lt;code&gt;PASETO_PRIVATE_KEY&lt;/code&gt; as fallback)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DB_SSLMODE=require&lt;/code&gt; - For secure database connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Optional (can be configured via Setup Wizard or environment variables):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ROOT_EMAIL&lt;/code&gt; - Root administrator email&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API_ENDPOINT&lt;/code&gt; - Public API endpoint URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PASETO_PRIVATE_KEY&lt;/code&gt;, &lt;code&gt;PASETO_PUBLIC_KEY&lt;/code&gt; - Authentication keys (auto-generated in wizard)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SMTP_HOST&lt;/code&gt;, &lt;code&gt;SMTP_PORT&lt;/code&gt;, &lt;code&gt;SMTP_USERNAME&lt;/code&gt;, &lt;code&gt;SMTP_PASSWORD&lt;/code&gt; - Email provider settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SMTP_FROM_EMAIL&lt;/code&gt;, &lt;code&gt;SMTP_FROM_NAME&lt;/code&gt; - From address and name&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Environment variables always take precedence over database settings configured via the setup wizard.&lt;/p&gt; 
&lt;p&gt;For detailed installation instructions, configuration options, and setup guides, visit &lt;strong&gt;&lt;a href="https://docs.notifuse.com"&gt;docs.notifuse.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.notifuse.com"&gt;Complete Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes&lt;/li&gt; 
 &lt;li&gt;Add tests&lt;/li&gt; 
 &lt;li&gt;Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Notifuse is released under the &lt;a href="https://raw.githubusercontent.com/Notifuse/notifuse/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üÜò Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://docs.notifuse.com"&gt;docs.notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Email Support&lt;/strong&gt;: &lt;a href="mailto:hello@notifuse.com"&gt;hello@notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/Notifuse/notifuse/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Why Choose Notifuse?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üí∞ Cost-Effective&lt;/strong&gt;: Self-hosted solution with no per-email pricing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Privacy-First&lt;/strong&gt;: Your data stays on your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ†Ô∏è Customizable&lt;/strong&gt;: Open-source with extensive customization options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Scalable&lt;/strong&gt;: Built to handle millions of emails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Modern&lt;/strong&gt;: Built with modern technologies and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Developer-Friendly&lt;/strong&gt;: Comprehensive API and webhook support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to get started?&lt;/strong&gt; &lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;Try the live demo&lt;/a&gt; or &lt;a href="https://docs.notifuse.com"&gt;deploy your own instance&lt;/a&gt; in minutes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>putyy/res-downloader</title>
      <link>https://github.com/putyy/res-downloader</link>
      <description>&lt;p&gt;ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader"&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/build/appicon.png" width="120" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;res-downloader&lt;/h1&gt; 
 &lt;h4&gt;üìñ ‰∏≠Êñá | &lt;a href="https://github.com/putyy/res-downloader/raw/master/README-EN.md"&gt;English&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/putyy/res-downloader" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/fork"&gt;&lt;img src="https://img.shields.io/github/forks/putyy/res-downloader" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;&lt;img src="https://img.shields.io/github/release/putyy/res-downloader" alt="GitHub release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/putyy/res-downloader/total" alt="GitHub All Releases" /&gt; &lt;a href="https://github.com/putyy/res-downloader/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/putyy/res-downloader" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏ÄÊ¨æÂü∫‰∫é Go + &lt;a href="https://github.com/wailsapp/wails"&gt;Wails&lt;/a&gt; ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® ÂäüËÉΩÁâπËâ≤&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;ÁÆÄÂçïÊòìÁî®&lt;/strong&gt;ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Â§öÂπ≥Âè∞ÊîØÊåÅ&lt;/strong&gt;ÔºöWindows / macOS / Linux&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ&lt;/strong&gt;ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â&lt;/li&gt; 
 &lt;li&gt;üì± &lt;strong&gt;Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ&lt;/strong&gt;ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;‰ª£ÁêÜÊäìÂåÖ&lt;/strong&gt;ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö ÊñáÊ°£ &amp;amp; ÁâàÊú¨&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://res.putyy.com/"&gt;Âú®Á∫øÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp"&gt;Âä†ÂÖ•‰∫§ÊµÅÁæ§&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß© &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;ÊúÄÊñ∞Áâà&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/resd-mini"&gt;MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/res-downloader/tree/old"&gt;ElectronÊóßÁâà ÊîØÊåÅWin7&lt;/a&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;em&gt;Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° &lt;code&gt;AmorousWorld&lt;/code&gt;ÔºåËØ∑Â§áÊ≥®‚Äúgithub‚Äù&lt;/em&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© ‰∏ãËΩΩÂú∞ÂùÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üÜï &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;GitHub ‰∏ãËΩΩ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://wwjv.lanzoum.com/b04wgtfyb"&gt;ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö†Ô∏è &lt;em&gt;Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ &lt;code&gt;2.3.0&lt;/code&gt; ÁâàÊú¨&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üñºÔ∏è È¢ÑËßà&lt;/h2&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/docs/images/show.webp" alt="È¢ÑËßà" /&gt;&lt;/h2&gt; 
&lt;h2&gt;üöÄ ‰ΩøÁî®ÊñπÊ≥ï&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;ÂÆâË£ÖÊó∂Âä°ÂøÖ &lt;strong&gt;ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂&lt;/strong&gt; Âπ∂ &lt;strong&gt;ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª &lt;strong&gt;‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ&lt;/li&gt; 
 &lt;li&gt;Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ&lt;/li&gt; 
 &lt;li&gt;ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ùì Â∏∏ËßÅÈóÆÈ¢ò&lt;/h2&gt; 
&lt;h3&gt;üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®Á∫øÈ¢ÑËßàÔºö&lt;a href="https://m3u8play.com/"&gt;m3u8play&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ë‰∏ãËΩΩÔºö&lt;a href="https://m3u8-down.gowas.cn/"&gt;m3u8-down&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®Ëçê‰ΩøÁî® &lt;a href="https://obsproject.com/"&gt;OBS&lt;/a&gt; ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®ËçêÂ∑•ÂÖ∑Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.neatdownloadmanager.com/index.php/en/"&gt;Neat Download Manager&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://motrix.app/download"&gt;Motrix&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª &lt;code&gt;ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö&lt;br /&gt; Âú∞ÂùÄÔºö127.0.0.1 Á´ØÂè£Ôºö8899&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß† Êõ¥Â§öÈóÆÈ¢ò&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/putyy/res-downloader/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://s.gowas.cn/d/4089"&gt;Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° ÂÆûÁé∞ÂéüÁêÜ &amp;amp; ÂàùË°∑&lt;/h2&gt; 
&lt;p&gt;Êú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ&lt;br /&gt; Â¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>dstotijn/hetty</title>
      <link>https://github.com/dstotijn/hetty</link>
      <description>&lt;p&gt;An HTTP toolkit for security research.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/983924/156430531-6193e187-7400-436b-81c6-f86862783ea5.svg#gh-light-mode-only" width="240" /&gt; 
&lt;img src="https://user-images.githubusercontent.com/983924/156430660-9d5bd555-dcfd-47e2-ba70-54294c20c1b4.svg#gh-dark-mode-only" width="240" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dstotijn/hetty?color=25ae8f" alt="Latest GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dstotijn/hetty/actions/workflows/build-test.yml"&gt;&lt;img src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fdstotijn%2Fhetty%2Fbadge%3Fref%3Dmain&amp;amp;label=build&amp;amp;color=24ae8f" alt="Build Status" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/dstotijn/hetty/total?color=25ae8f" alt="GitHub download count" /&gt; &lt;a href="https://github.com/dstotijn/hetty/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/dstotijn/hetty?color=25ae8f" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://hetty.xyz/"&gt;&lt;img src="https://img.shields.io/badge/hetty-docs-25ae8f" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hetty&lt;/strong&gt; is an HTTP toolkit for security research. It aims to become an open source alternative to commercial software like Burp Suite Pro, with powerful features tailored to the needs of the infosec and bug bounty community.&lt;/p&gt; 
&lt;img src="https://hetty.xyz/img/hero.png" width="907" alt="Hetty proxy logs (screenshot)" /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Machine-in-the-middle (MITM) HTTP proxy, with logs and advanced search&lt;/li&gt; 
 &lt;li&gt;HTTP client for manually creating/editing requests, and replay proxied requests&lt;/li&gt; 
 &lt;li&gt;Intercept requests and responses for manual review (edit, send/receive, cancel)&lt;/li&gt; 
 &lt;li&gt;Scope support, to help keep work organized&lt;/li&gt; 
 &lt;li&gt;Easy-to-use web based admin interface&lt;/li&gt; 
 &lt;li&gt;Project based database storage, to help keep work organized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üë∑‚Äç‚ôÇÔ∏è Hetty is under active development. Check the &lt;a href="https://github.com/dstotijn/hetty/projects/1"&gt;backlog&lt;/a&gt; for the current status.&lt;/p&gt; 
&lt;p&gt;üì£ Are you pen testing professionaly in a team? I would love to hear your thoughts on tooling via &lt;a href="https://forms.gle/36jtgNc3TJ2imi5A8"&gt;this 5 minute survey&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;üí° The &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc has more detailed install and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The quickest way to install and update Hetty is via a package manager:&lt;/p&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install hettysoft/tap/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo snap install hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;scoop bucket add hettysoft https://github.com/hettysoft/scoop-bucket.git
scoop install hettysoft/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;Alternatively, you can &lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;download the latest release from GitHub&lt;/a&gt; for your OS and architecture, and move the binary to a directory in your &lt;code&gt;$PATH&lt;/code&gt;. If your OS is not available for one of the package managers or not listed in the GitHub releases, you can compile from source &lt;em&gt;(link coming soon)&lt;/em&gt;.&lt;/p&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Docker images are distributed via &lt;a href="https://github.com/dstotijn/hetty/pkgs/container/hetty"&gt;GitHub's Container registry&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/dstotijn/hetty"&gt;Docker Hub&lt;/a&gt;. To run Hetty via with a volume for database and certificate storage, and port 8080 forwarded:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -v $HOME/.hetty:/root/.hetty -p 8080:8080 \
  ghcr.io/dstotijn/hetty:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, start Hetty via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üí° Read the &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc for more details.&lt;/p&gt; 
&lt;p&gt;To list all available options, run: &lt;code&gt;hetty --help&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ hetty --help

Usage:
    hetty [flags] [subcommand] [flags]

Runs an HTTP server with (MITM) proxy, GraphQL service, and a web based admin interface.

Options:
    --cert         Path to root CA certificate. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_cert.pem")
    --key          Path to root CA private key. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_key.pem")
    --db           Database file path. Creates file if it doesn't exist. (Default: "~/.hetty/hetty.db")
    --addr         TCP address for HTTP server to listen on, in the form \"host:port\". (Default: ":8080")
    --chrome       Launch Chrome with proxy settings applied and certificate errors ignored. (Default: false)
    --verbose      Enable verbose logging.
    --json         Encode logs as JSON, instead of pretty/human readable output.
    --version, -v  Output version.
    --help, -h     Output this usage text.

Subcommands:
    - cert  Certificate management

Run `hetty &amp;lt;subcommand&amp;gt; --help` for subcommand specific usage instructions.

Visit https://hetty.xyz to learn more about Hetty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìñ &lt;a href="https://hetty.xyz/docs"&gt;Read the docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Use &lt;a href="https://github.com/dstotijn/hetty/issues"&gt;issues&lt;/a&gt; for bug reports and feature requests, and &lt;a href="https://github.com/dstotijn/hetty/discussions"&gt;discussions&lt;/a&gt; for questions and troubleshooting.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;üí¨ &lt;a href="https://discord.gg/3HVsj5pTFP"&gt;Join the Hetty Discord server&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Great! Please check the &lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to the &lt;a href="https://www.hacker101.com/discord"&gt;Hacker101 community on Discord&lt;/a&gt; for the encouragement and early feedback.&lt;/li&gt; 
 &lt;li&gt;The font used in the logo and admin interface is &lt;a href="https://www.jetbrains.com/lp/mono/"&gt;JetBrains Mono&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;üíñ Are you enjoying Hetty? You can &lt;a href="https://github.com/sponsors/dstotijn"&gt;sponsor me&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;¬© 2019‚Äì2025 Hetty Software&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>publicsuffix/list</title>
      <link>https://github.com/publicsuffix/list</link>
      <description>&lt;p&gt;The Public Suffix List&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Public Suffix List&lt;/h1&gt; 
&lt;p&gt;A "public suffix" is one under which Internet users can (or historically could) directly register names. Some examples of public suffixes are &lt;code&gt;com&lt;/code&gt;, &lt;code&gt;co.uk&lt;/code&gt; and &lt;code&gt;pvt.k12.ma.us&lt;/code&gt;. The Public Suffix List is a list of all known public suffixes.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://publicsuffix.org/"&gt;https://publicsuffix.org/&lt;/a&gt; and the &lt;a href="https://github.com/publicsuffix/list/wiki"&gt;Wiki&lt;/a&gt; link above for more information.&lt;/p&gt; 
&lt;h2&gt;Are you here to add or update something?&lt;/h2&gt; 
&lt;p&gt;All submissions must conform to the &lt;a href="https://github.com/publicsuffix/list/wiki/Guidelines#validation-and-non-acceptance-factors"&gt;validation and acceptance factors&lt;/a&gt; and provide sufficient rationale or basically be as complete as possible, and follow the &lt;a href="https://github.com/publicsuffix/list/wiki/Guidelines"&gt;Guidelines&lt;/a&gt;, especially as they relate to format and &lt;a href="https://github.com/publicsuffix/list/wiki/Guidelines#sort-your-submission-correctly-important"&gt;sorting&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The list is currently maintained by people who are volunteering their time towards universal acceptance and ensuring there is a bridge between the ICANN world of domain names and the crucial last mile - the world of developers and human users.&lt;/p&gt; 
&lt;p&gt;Iteration back and forth will delay PR review or inclusion. Be extremely thorough, and patient.&lt;/p&gt; 
&lt;h2&gt;Important Notices&lt;/h2&gt; 
&lt;h3&gt;2025-05-27&lt;/h3&gt; 
&lt;p&gt;Were you directed here to be able to add a subdomain to your &lt;strong&gt;Cloudflare&lt;/strong&gt; account? If so, please work directly with Cloudflare for these account limitations. The PSL is &lt;strong&gt;NOT&lt;/strong&gt; intended as a workaround for Cloudflare's subdomain restrictions.&lt;/p&gt; 
&lt;p&gt;Consult &lt;a href="https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/"&gt;Cloudflare's subdomain setup documentation&lt;/a&gt; or contact Cloudflare directly for subdomain setup questions. Only submit a request to the PSL if your domain truly meets our criteria outlined in &lt;a href="https://github.com/publicsuffix/list/wiki/Guidelines"&gt;Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;2024-07-26&lt;/h3&gt; 
&lt;p&gt;We are sending emails asking for confirmation if certain entries are still required or need updating.&lt;/p&gt; 
&lt;p&gt;Currently, this process is purely manual and extremely low volume but if you do get an email, please respond.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/publicsuffix/list/main/#email-communication-policy"&gt;Email Communication Policy&lt;/a&gt; to see how we will often communicate these changes.&lt;/p&gt; 
&lt;h3&gt;2023-02-20&lt;/h3&gt; 
&lt;p&gt;Did &lt;a href="https://support.google.com/adsense/answer/12170421"&gt;guidance from Google related to the changes that they are making to adsense subdomains&lt;/a&gt; bring you here? Work with Google Adsense &lt;a href="https://support.google.com/adsense/gethelp"&gt;Help Link&lt;/a&gt; with any support questions you have. The PSL is thinly resourced, and the volunteer maintainers are unable to answer questions about Adsense changes or support Adsense.&lt;/p&gt; 
&lt;p&gt;The PSL is volunteer-resourced and is absolutely not resourced to answer questions or support changes. Guidance is in the form of self-help (READ THE &lt;a href="https://github.com/publicsuffix/list/wiki"&gt;WIKI&lt;/a&gt;), THERE IS NO PSL CUSTOMER SERVICE RESOURCE TO ASSIST YOU. &lt;em&gt;Please work directly with Google to ensure your domain does in fact need an entry, and they should help you know what the benefits and consequences are. &lt;strong&gt;IT POSSIBLE TO HARM YOUR WEBSITE COOKIES BY REQUESTING A MALFORMED PSL ENTRY&lt;/strong&gt;. Also, understand what propagation delays and rollback processing entail before making requests.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;2021-04-23&lt;/h3&gt; 
&lt;p&gt;Did guidance related to an issue with Facebook or Apple bring you here? &lt;a href="https://github.com/publicsuffix/list/issues/1245"&gt;Read this before submitting requests&lt;/a&gt; We are not approving workaround requests per the validation and acceptance standards, but do have open discussion with Facebook on the matter.&lt;/p&gt; 
&lt;h2&gt;Email Communication Policy&lt;/h2&gt; 
&lt;p&gt;We tend to use the subject line tag "[PSL notification]" in all Public Suffix List communications. For effective spam filtering, you can create a case-insensitive filter to allow only emails with exact "[PSL notification]" in the subject line. If you choose to set up such a filter in your email application, please verify the filter is implemented correctly and test it thoroughly to ensure you don't accidentally miss important communications from us.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Your participation in the Public Suffix List project should follow the &lt;a href="https://www.mozilla.org/en-US/about/governance/policies/participation/" title="Mozilla Community Participation Guidelines"&gt;Mozilla Community Participation Guidelines&lt;/a&gt; as well as the &lt;a href="https://help.github.com/en/github/site-policy/github-community-guidelines" title="GitHub Community Participation Guidelines"&gt;GitHub Community Participation Guidelines&lt;/a&gt;. Behavior that falls into the areas forbidden by either document is unwelcome and will result in further escalation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juicedata/juicefs</title>
      <link>https://github.com/juicedata/juicefs</link>
      <description>&lt;p&gt;JuiceFS is a distributed POSIX file system built on top of Redis and S3.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/juicedata/juicefs"&gt;&lt;img alt="JuiceFS Logo" src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-logo-new.svg?sanitize=true" width="50%" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juicedata/juicefs/releases/latest"&gt;&lt;img alt="Latest Stable Release" src="https://img.shields.io/github/v/release/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/unittests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;amp;label=Unit%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;amp;label=Integration%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/juicedata/juicefs"&gt;&lt;img alt="Go Report" src="https://goreportcard.com/badge/github.com/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://juicefs.com/docs/community/introduction"&gt;&lt;img alt="English doc" src="https://img.shields.io/badge/docs-Doc%20Center-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://go.juicefs.com/slack"&gt;&lt;img alt="Join Slack" src="https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JuiceFS&lt;/strong&gt; is a high-performance &lt;a href="https://en.wikipedia.org/wiki/POSIX"&gt;POSIX&lt;/a&gt; file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage &lt;em&gt;(e.g. Amazon S3)&lt;/em&gt;, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.&lt;/p&gt; 
&lt;p&gt;With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;Document&lt;/strong&gt;: &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlighted Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fully POSIX-compatible&lt;/strong&gt;: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Hadoop-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt; is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt; provides an S3-compatible interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Native&lt;/strong&gt;: A &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;Kubernetes CSI Driver&lt;/a&gt; is provided for easily using JuiceFS in Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shareable&lt;/strong&gt;: JuiceFS is a shared file storage that can be read and written by thousands of clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;: The confirmed modification will be immediately visible on all the servers mounted with the same file system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outstanding Performance&lt;/strong&gt;: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly &lt;em&gt;(depending on the size of the Object Storage)&lt;/em&gt;. &lt;a href="https://juicefs.com/docs/community/benchmark"&gt;Test results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Supports data encryption in transit and at rest (please refer to &lt;a href="https://juicefs.com/docs/community/security/encrypt"&gt;the guide&lt;/a&gt; for more information).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global File Locks&lt;/strong&gt;: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;: JuiceFS supports &lt;a href="https://lz4.github.io/lz4"&gt;LZ4&lt;/a&gt; or &lt;a href="https://facebook.github.io/zstd"&gt;Zstandard&lt;/a&gt; to compress all your data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#architecture"&gt;Architecture&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#advanced-topics"&gt;Advanced Topics&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#posix-compatibility"&gt;POSIX Compatibility&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#performance-benchmark"&gt;Performance Benchmark&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#supported-object-storage"&gt;Supported Object Storage&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#who-is-using"&gt;Who is using&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#roadmap"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#reporting-issues"&gt;Reporting Issues&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#contributing"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;Community&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#usage-tracking"&gt;Usage Tracking&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#license"&gt;License&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#credits"&gt;Credits&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;JuiceFS consists of three parts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;JuiceFS Client&lt;/strong&gt;: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata Engine&lt;/strong&gt;: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-arch-new.png" alt="JuiceFS Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. &lt;a href="https://juicefs.com/docs/community/architecture"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/data-structure-diagram.svg?sanitize=true" alt="data-structure-diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Each file stored in JuiceFS is split into &lt;strong&gt;"Chunk"&lt;/strong&gt; s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more &lt;strong&gt;"Slice"&lt;/strong&gt;(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed &lt;strong&gt;"Block"&lt;/strong&gt; s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. &lt;a href="https://juicefs.com/docs/community/architecture/#how-juicefs-store-files"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/how-juicefs-stores-files.svg?sanitize=true" alt="How JuiceFS stores your files" /&gt;&lt;/p&gt; 
&lt;p&gt;When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don't panic! This is just the secret of the high-performance operation of JuiceFS!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Before you begin, make sure you have:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One supported metadata engine, see &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;How to Set Up Metadata Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;One supported Object Storage for storing data blocks, see &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;Supported Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation"&gt;JuiceFS Client&lt;/a&gt; downloaded and installed&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt; to start using JuiceFS right away!&lt;/p&gt; 
&lt;h3&gt;Command Reference&lt;/h3&gt; 
&lt;p&gt;Check out all the command line options in &lt;a href="https://juicefs.com/docs/community/command_reference"&gt;command reference&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Containers&lt;/h3&gt; 
&lt;p&gt;JuiceFS can be used as a persistent volume for Docker and Podman, please check &lt;a href="https://juicefs.com/docs/community/juicefs_on_docker"&gt;here&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Kubernetes&lt;/h3&gt; 
&lt;p&gt;It is also very easy to use JuiceFS on Kubernetes. Please find more information &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Hadoop Java SDK&lt;/h3&gt; 
&lt;p&gt;If you wanna use JuiceFS in Hadoop, check &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;Redis Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;How to Setup Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/cache"&gt;Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis"&gt;Fault Diagnosis and Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fuse_mount_options"&gt;FUSE Mount Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation#windows"&gt;Using JuiceFS on Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/introduction"&gt;JuiceFS Document Center&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;POSIX Compatibility&lt;/h2&gt; 
&lt;p&gt;JuiceFS has passed all of the compatibility tests (8813 in total) in the latest &lt;a href="https://github.com/pjd/pjdfstest"&gt;pjdfstest&lt;/a&gt; .&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Close-to-open consistency&lt;/strong&gt;. Once a file is written &lt;em&gt;and&lt;/em&gt; closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.&lt;/li&gt; 
 &lt;li&gt;Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.&lt;/li&gt; 
 &lt;li&gt;Opened files remain accessible after unlink from same mount point.&lt;/li&gt; 
 &lt;li&gt;Mmap (tested with FSx).&lt;/li&gt; 
 &lt;li&gt;Fallocate with punch hole support.&lt;/li&gt; 
 &lt;li&gt;Extended attributes (xattr).&lt;/li&gt; 
 &lt;li&gt;BSD locks (flock).&lt;/li&gt; 
 &lt;li&gt;POSIX record locks (fcntl).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance Benchmark&lt;/h2&gt; 
&lt;h3&gt;Basic benchmark&lt;/h3&gt; 
&lt;p&gt;JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-bench.png" alt="JuiceFS Bench" /&gt;&lt;/p&gt; 
&lt;h3&gt;Throughput&lt;/h3&gt; 
&lt;p&gt;A sequential read/write benchmark has also been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/sequential-read-write-benchmark.svg?sanitize=true" alt="Sequential Read Write Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see &lt;a href="https://juicefs.com/docs/community/fio"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Metadata IOPS&lt;/h3&gt; 
&lt;p&gt;A simple mdtest benchmark has been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/hpc/ior"&gt;mdtest&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/metadata-benchmark.svg?sanitize=true" alt="Metadata Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see &lt;a href="https://juicefs.com/docs/community/mdtest"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Analyze performance&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor"&gt;Real-Time Performance Monitoring&lt;/a&gt; if you encountered performance issues.&lt;/p&gt; 
&lt;h2&gt;Supported Object Storage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon S3 &lt;em&gt;(and other S3 compatible Object Storage services)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Google Cloud Storage&lt;/li&gt; 
 &lt;li&gt;Azure Blob Storage&lt;/li&gt; 
 &lt;li&gt;Alibaba Cloud Object Storage Service (OSS)&lt;/li&gt; 
 &lt;li&gt;Tencent Cloud Object Storage (COS)&lt;/li&gt; 
 &lt;li&gt;Qiniu Cloud Object Storage (Kodo)&lt;/li&gt; 
 &lt;li&gt;QingStor Object Storage&lt;/li&gt; 
 &lt;li&gt;Ceph RGW&lt;/li&gt; 
 &lt;li&gt;MinIO&lt;/li&gt; 
 &lt;li&gt;Local disk&lt;/li&gt; 
 &lt;li&gt;Redis&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;JuiceFS supports numerous Object Storage services. &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Who is using&lt;/h2&gt; 
&lt;p&gt;JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented &lt;a href="https://juicefs.com/docs/community/adopters"&gt;here&lt;/a&gt;. In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented &lt;a href="https://juicefs.com/docs/community/integrations"&gt;here&lt;/a&gt;. If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.&lt;/p&gt; 
&lt;p&gt;The storage format is stable, and will be supported by all future releases.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;User and group quotas&lt;/li&gt; 
 &lt;li&gt;Snapshots&lt;/li&gt; 
 &lt;li&gt;Write once read many (WORM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reporting Issues&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/juicedata/juicefs/issues"&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;contact&lt;/a&gt; the community for any questions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for your contribution! Please refer to the &lt;a href="https://juicefs.com/docs/community/development/contributing_guide"&gt;JuiceFS Contributing Guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Welcome to join the &lt;a href="https://github.com/juicedata/juicefs/discussions"&gt;Discussions&lt;/a&gt; and the &lt;a href="https://go.juicefs.com/slack"&gt;Slack channel&lt;/a&gt; to connect with JuiceFS team members and other users.&lt;/p&gt; 
&lt;h2&gt;Usage Tracking&lt;/h2&gt; 
&lt;p&gt;JuiceFS collects &lt;strong&gt;anonymous&lt;/strong&gt; usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/pkg/usage/usage.go"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You could also disable reporting easily by command line option &lt;code&gt;--no-usage-report&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;juicefs mount --no-usage-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;JuiceFS is open-sourced under Apache License 2.0, see &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The design of JuiceFS was inspired by &lt;a href="https://research.google/pubs/pub51"&gt;Google File System&lt;/a&gt;, &lt;a href="https://hadoop.apache.org"&gt;HDFS&lt;/a&gt; and &lt;a href="https://moosefs.com"&gt;MooseFS&lt;/a&gt;. Thanks for their great work!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why doesn't JuiceFS support XXX Object Storage?&lt;/h3&gt; 
&lt;p&gt;JuiceFS supports many Object Storage services. Please check out &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;this list&lt;/a&gt; first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.&lt;/p&gt; 
&lt;h3&gt;Can I use Redis Cluster as metadata engine?&lt;/h3&gt; 
&lt;p&gt;Yes. Since &lt;a href="https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3"&gt;v1.0.0 Beta3&lt;/a&gt; JuiceFS supports the use of &lt;a href="https://redis.io/docs/manual/scaling"&gt;Redis Cluster&lt;/a&gt; as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;"Redis Best Practices"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;What's the difference between JuiceFS and XXX?&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio"&gt;"Comparison with Others"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;For more FAQs, please see the &lt;a href="https://juicefs.com/docs/community/faq"&gt;full list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#juicedata/juicefs&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=juicedata/juicefs&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href="https://github.com/hashicorp/vault/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hashicorp/vault/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise"&gt;&lt;img src="https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000" alt="vault enterprise" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault's security and our users' trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/vault"&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href="https://groups.google.com/group/hashicorp-announce"&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href="https://discuss.hashicorp.com/c/vault"&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/vault/tutorials"&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href="https://developer.hashicorp.com/certifications/security-automation"&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation source: &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;https://github.com/hashicorp/web-unified-docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width="300" alt="Vault Logo" src="https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png" /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, &lt;a href="https://www.consul.io"&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're new to Vault and want to get started with security automation, please check out our &lt;a href="https://learn.hashicorp.com/collections/vault/getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/vault"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href="https://github.com/hashicorp/vault-examples"&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href="https://github.com/hashicorp/hello-vault-go"&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/collections/vault/certification"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href="https://pkg.go.dev/cmd/go#hdr-Environment_variables"&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for 'https://github.com'&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ git config --global --add url."git@github.com:".insteadOf "https://github.com/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/hashicorp/vault/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise"&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault", // or "hashicorp/vault-enterprise"
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault-enterprise",
    ImageTag:  "latest",
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn't become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>traefik/traefik</title>
      <link>https://github.com/traefik/traefik</link>
      <description>&lt;p&gt;The Cloud Native Application Proxy&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/content/assets/img/traefik.logo-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/content/assets/img/traefik.logo.png" /&gt; 
  &lt;img alt="Traefik" title="Traefik" src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik.logo.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://doc.traefik.io/traefik"&gt;&lt;img src="https://img.shields.io/badge/docs-current-brightgreen.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/traefik/traefik"&gt;&lt;img src="https://goreportcard.com/badge/traefik/traefik" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/traefik/traefik/raw/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the community support forum at https://community.traefik.io/" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=traefik"&gt;&lt;img src="https://img.shields.io/twitter/follow/traefik.svg?style=social" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Traefik (pronounced &lt;em&gt;traffic&lt;/em&gt;) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy. Traefik integrates with your existing infrastructure components (&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Swarm mode&lt;/a&gt;, &lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/"&gt;Etcd&lt;/a&gt;, &lt;a href="https://rancher.com"&gt;Rancher v2&lt;/a&gt;, &lt;a href="https://aws.amazon.com/ecs"&gt;Amazon ECS&lt;/a&gt;, ...) and configures itself automatically and dynamically. Pointing Traefik at your orchestrator should be the &lt;em&gt;only&lt;/em&gt; configuration step you need.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#features"&gt;Features&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#supported-backends"&gt;Supported backends&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#web-ui"&gt;Web UI&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#support"&gt;Support&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#release-cycle"&gt;Release cycle&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#maintainers"&gt;Maintainers&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#credits"&gt;Credits&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; When migrating to a new major version of Traefik, please refer to the &lt;a href="https://doc.traefik.io/traefik/migrate/v2-to-v3/"&gt;migration guide&lt;/a&gt; to ensure a smooth transition and to be aware of any breaking changes.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul). Now you want users to access these microservices, and you need a reverse proxy.&lt;/p&gt; 
&lt;p&gt;Traditional reverse-proxies require that you configure &lt;em&gt;each&lt;/em&gt; route that will connect paths and subdomains to &lt;em&gt;each&lt;/em&gt; microservice. In an environment where you add, remove, kill, upgrade, or scale your services &lt;em&gt;many&lt;/em&gt; times a day, the task of keeping the routes up to date becomes tedious.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This is when Traefik can help you!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Traefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run Traefik and let it do the work for you!&lt;/strong&gt; &lt;em&gt;(But if you'd rather configure some of your routes manually, Traefik supports that too!)&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik-architecture.png" alt="Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Continuously updates its configuration (No restarts!)&lt;/li&gt; 
 &lt;li&gt;Supports multiple load balancing algorithms&lt;/li&gt; 
 &lt;li&gt;Provides HTTPS to your microservices by leveraging &lt;a href="https://letsencrypt.org"&gt;Let's Encrypt&lt;/a&gt; (wildcard certificates support)&lt;/li&gt; 
 &lt;li&gt;Circuit breakers, retry&lt;/li&gt; 
 &lt;li&gt;See the magic through its clean web UI&lt;/li&gt; 
 &lt;li&gt;WebSocket, HTTP/2, gRPC ready&lt;/li&gt; 
 &lt;li&gt;Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)&lt;/li&gt; 
 &lt;li&gt;Keeps access logs (JSON, CLF)&lt;/li&gt; 
 &lt;li&gt;Fast&lt;/li&gt; 
 &lt;li&gt;Exposes a Rest API&lt;/li&gt; 
 &lt;li&gt;Packaged as a single binary file (made with &lt;span&gt;‚ù§Ô∏è&lt;/span&gt; with go) and available as an &lt;a href="https://hub.docker.com/r/_/traefik/"&gt;official&lt;/a&gt; docker image&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Backends&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Docker&lt;/a&gt; / &lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Swarm mode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/kubernetes-crd/"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/ecs/"&gt;ECS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/file/"&gt;File&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get your hands on Traefik, you can use the &lt;a href="https://doc.traefik.io/traefik/getting-started/quick-start/"&gt;5-Minute Quickstart&lt;/a&gt; in our documentation (you will need Docker).&lt;/p&gt; 
&lt;h2&gt;Web UI&lt;/h2&gt; 
&lt;p&gt;You can access the simple HTML frontend of Traefik.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/webui-dashboard.png" alt="Web UI Providers" /&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can find the complete documentation of Traefik v3 at &lt;a href="https://doc.traefik.io/traefik/"&gt;https://doc.traefik.io/traefik/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;To get community support, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;join the Traefik community forum: &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the chat at https://community.traefik.io/" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need commercial support, please contact &lt;a href="https://traefik.io"&gt;Traefik.io&lt;/a&gt; by mail: &lt;a href="mailto:support@traefik.io"&gt;mailto:support@traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grab the latest binary from the &lt;a href="https://github.com/traefik/traefik/releases"&gt;releases&lt;/a&gt; page and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./traefik --configFile=traefik.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or use the official tiny Docker image and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or get the sources:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/traefik/traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Introductory Videos&lt;/h2&gt; 
&lt;p&gt;You can find high level and deep dive videos on &lt;a href="https://videos.traefik.io"&gt;videos.traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;We are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey! This &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers-guidelines.md"&gt;document&lt;/a&gt; describes how to be part of the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers.md"&gt;maintainers' team&lt;/a&gt; as well as various responsibilities and guidelines for Traefik maintainers. You can also find more information on our process to review pull requests and manage issues &lt;a href="https://github.com/traefik/contributors-guide/raw/master/issue_triage.md"&gt;in this document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to contribute to the project, refer to the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CONTRIBUTING.md"&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;Release Cycle&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.&lt;/li&gt; 
 &lt;li&gt;Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).&lt;/li&gt; 
 &lt;li&gt;Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://semver.org/"&gt;Semantic Versioning&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Mailing Lists&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;General announcements, new releases: mail at &lt;a href="mailto:news+subscribe@traefik.io"&gt;news+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/news"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Security announcements: mail at &lt;a href="mailto:security+subscribe@traefik.io"&gt;security+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/security"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Kudos to &lt;a href="https://www.instagram.com/pierroks/"&gt;Peka&lt;/a&gt; for his awesome work on the gopher's logo!.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik was inspired by the gopher stickers made by &lt;a href="https://twitter.com/tenntenn"&gt;Takuya Ueda&lt;/a&gt;. The original Go gopher was designed by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renee French&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pocketbase/pocketbase</title>
      <link>https://github.com/pocketbase/pocketbase</link>
      <description>&lt;p&gt;Open Source realtime backend in 1 file&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://pocketbase.io" target="_blank" rel="noopener"&gt; &lt;img src="https://i.imgur.com/5qimnm5.png" alt="PocketBase - open source backend in 1 file" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml" target="_blank" rel="noopener"&gt;&lt;img src="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pocketbase/pocketbase/releases" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/github/release/pocketbase/pocketbase.svg?sanitize=true" alt="Latest releases" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/pocketbase/pocketbase" target="_blank" rel="noopener"&gt;&lt;img src="https://godoc.org/github.com/pocketbase/pocketbase?status.svg?sanitize=true" alt="Go package documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pocketbase.io"&gt;PocketBase&lt;/a&gt; is an open source Go backend that includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;embedded database (&lt;em&gt;SQLite&lt;/em&gt;) with &lt;strong&gt;realtime subscriptions&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;built-in &lt;strong&gt;files and users management&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;convenient &lt;strong&gt;Admin dashboard UI&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;and simple &lt;strong&gt;REST-ish API&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For documentation and examples, please visit &lt;a href="https://pocketbase.io/docs"&gt;https://pocketbase.io/docs&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Please keep in mind that PocketBase is still under active development and therefore full backward compatibility is not guaranteed before reaching v1.0.0.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;API SDK clients&lt;/h2&gt; 
&lt;p&gt;The easiest way to interact with the PocketBase Web APIs is to use one of the official SDK clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript - &lt;a href="https://github.com/pocketbase/js-sdk"&gt;pocketbase/js-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Browser, Node.js, React Native&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dart - &lt;a href="https://github.com/pocketbase/dart-sdk"&gt;pocketbase/dart-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Web, Mobile, Desktop, CLI&lt;/em&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You could also check the recommendations in &lt;a href="https://pocketbase.io/docs/how-to-use/"&gt;https://pocketbase.io/docs/how-to-use/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;h3&gt;Use as standalone app&lt;/h3&gt; 
&lt;p&gt;You could download the prebuilt executable for your platform from the &lt;a href="https://github.com/pocketbase/pocketbase/releases"&gt;Releases page&lt;/a&gt;. Once downloaded, extract the archive and run &lt;code&gt;./pocketbase serve&lt;/code&gt; in the extracted directory.&lt;/p&gt; 
&lt;p&gt;The prebuilt executables are based on the &lt;a href="https://github.com/pocketbase/pocketbase/raw/master/examples/base/main.go"&gt;&lt;code&gt;examples/base/main.go&lt;/code&gt; file&lt;/a&gt; and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (&lt;em&gt;for more details please refer to &lt;a href="https://pocketbase.io/docs/js-overview/"&gt;Extend with JavaScript&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt; 
&lt;h3&gt;Use as a Go framework/toolkit&lt;/h3&gt; 
&lt;p&gt;PocketBase is distributed as a regular Go library package which allows you to build your own custom app specific business logic and still have a single portable executable at the end.&lt;/p&gt; 
&lt;p&gt;Here is a minimal example:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a new project directory with the following &lt;code&gt;main.go&lt;/code&gt; file inside it:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "log"

    "github.com/pocketbase/pocketbase"
    "github.com/pocketbase/pocketbase/core"
)

func main() {
    app := pocketbase.New()

    app.OnServe().BindFunc(func(se *core.ServeEvent) error {
        // registers new "GET /hello" route
        se.Router.GET("/hello", func(re *core.RequestEvent) error {
            return re.String(200, "Hello world!")
        })

        return se.Next()
    })

    if err := app.Start(); err != nil {
        log.Fatal(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To init the dependencies, run &lt;code&gt;go mod init myapp &amp;amp;&amp;amp; go mod tidy&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To start the application, run &lt;code&gt;go run main.go serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To build a statically linked executable, you can run &lt;code&gt;CGO_ENABLED=0 go build&lt;/code&gt; and then start the created executable with &lt;code&gt;./myapp serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;For more details please refer to &lt;a href="https://pocketbase.io/docs/go-overview/"&gt;Extend with Go&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Building and running the repo main.go example&lt;/h3&gt; 
&lt;p&gt;To build the minimal standalone executable, like the prebuilt ones in the releases page, you can simply run &lt;code&gt;go build&lt;/code&gt; inside the &lt;code&gt;examples/base&lt;/code&gt; directory:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Clone/download the repo&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;examples/base&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build&lt;/code&gt; (&lt;em&gt;&lt;a href="https://go.dev/doc/install/source#environment"&gt;https://go.dev/doc/install/source#environment&lt;/a&gt;&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Start the created executable by running &lt;code&gt;./base serve&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note that the supported build targets by the pure Go SQLite driver at the moment are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;darwin  amd64
darwin  arm64
freebsd amd64
freebsd arm64
linux   386
linux   amd64
linux   arm
linux   arm64
linux   loong64
linux   ppc64le
linux   riscv64
linux   s390x
windows 386
windows amd64
windows arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;PocketBase comes with mixed bag of unit and integration tests. To run them, use the standard &lt;code&gt;go test&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go test ./...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check also the &lt;a href="http://pocketbase.io/docs/testing"&gt;Testing guide&lt;/a&gt; to learn how to write your own custom application tests.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you discover a security vulnerability within PocketBase, please send an e-mail to &lt;strong&gt;support at pocketbase.io&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;All reports will be promptly addressed and you'll be credited in the fix release notes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PocketBase is free and open source project licensed under the &lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/LICENSE.md"&gt;MIT License&lt;/a&gt;. You are free to do whatever you want with it, even offering it as a paid service.&lt;/p&gt; 
&lt;p&gt;You could help continuing its development by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/CONTRIBUTING.md"&gt;Contribute to the source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pocketbase/pocketbase/issues"&gt;Suggest new features and report issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.&lt;/p&gt; 
&lt;p&gt;But please refrain creating PRs for &lt;em&gt;new features&lt;/em&gt; without previously discussing the implementation details. PocketBase has a &lt;a href="https://github.com/orgs/pocketbase/projects/2"&gt;roadmap&lt;/a&gt; and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.&lt;/p&gt; 
&lt;p&gt;Don't get upset if I close your PR, even if it is well executed and tested. This doesn't mean that it will never be merged. Later we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don't worry you'll be credited in the release notes).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/redis/go-redis/actions"&gt;&lt;img src="https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build workflow" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/redis/go-redis/v9" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://redis.uptrace.dev/"&gt;&lt;img src="https://img.shields.io/badge/redis-documentation-informational" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/redis/go-redis/v9"&gt;&lt;img src="https://goreportcard.com/badge/github.com/redis/go-redis/v9" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/redis/go-redis"&gt;&lt;img src="https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;&lt;img src="https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.twitch.tv/redisinc"&gt;&lt;img src="https://img.shields.io/twitch/status/redisinc?style=social" alt="Twitch" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/redisinc"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/redisinc"&gt;&lt;img src="https://img.shields.io/twitter/follow/redisinc?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/go-redis"&gt;&lt;img src="https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow" alt="Stack Exchange questions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES"&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES"&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES"&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES"&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt;, &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://university.redis.com/"&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://launchpad.redis.com/"&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/try-free/"&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.redis.com/"&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/community/"&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/company/careers/jobs/"&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/zh/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/go-redis/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redismock"&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bsm/redislock"&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/cache"&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redis_rate"&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href="https://github.com/apache/incubator-kvrocks"&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority"&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pubsub.html"&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pipelines.html"&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/lua-scripting.html"&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-sentinel.html"&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-cluster.html"&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/ring.html"&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/redis-performance-monitoring.html"&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.io/docs/data-types/probabilistic/"&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes"&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "context"
    "fmt"

    "github.com/redis/go-redis/v9"
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     "localhost:6379",
        Password: "", // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, "key", "value", 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, "key").Result()
    if err != nil {
        panic(err)
    }
    fmt.Println("key", val)

    val2, err := rdb.Get(ctx, "key2").Result()
    if err == redis.Nil {
        fmt.Println("key2 does not exist")
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println("key2", val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href="https://github.com/redis/go-redis-entraid"&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis-entraid"
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "your-redis-server.redis.cache.windows.net:6380",
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return "user", "pass", nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return "user", "pass"
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Username: "user",
    Password: "pass",
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Password: "", // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href="https://github.com/redis/redis-specifications/tree/master/uri/redis.txt"&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
)

func ExampleClient() *redis.Client {
    url := "redis://user:password@localhost:6379/0?protocol=3"
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis/extra/redisotel/v9"
    "errors"
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is "fire and forget", meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    Password:        "",
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;res1, err := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		"idx:bicycle",
		"@pickup_zone:[CONTAINS $bike]",
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				"bike": "POINT(-0.1278 51.5074)",
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href="https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/"&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, "key", "value", 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, "key", "value", redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, "list", &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: "ASC"}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, "zset", &amp;amp;redis.ZRangeBy{
    Min: "-inf",
    Max: "+inf",
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, "out", &amp;amp;redis.ZStore{
    Keys: []string{"zset1", "zset2"},
    Weights: []int64{2, 3}
}).Result()

// EVAL "return {KEYS[1],ARGV[1]}" 1 "key" "hello"
vals, err := rdb.Eval(ctx, "return {KEYS[1],ARGV[1]}", []string{"key"}, "hello").Result()

// custom command
res, err := rdb.Do(ctx, "set", "key", "value").Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;Recommended to use Docker, just need to run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev"&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev/postgres/"&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bunrouter.uptrace.dev/"&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/uptrace/go-clickhouse"&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;‚≠ê&lt;/span&gt; &lt;a href="https://github.com/uptrace/uptrace"&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/redis/go-redis/tree/master/example/otel"&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/redis/go-redis/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=redis/go-redis" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>krillinai/KrillinAI</title>
      <link>https://github.com/krillinai/KrillinAI</link>
      <description>&lt;p&gt;Video translation and dubbing tool powered by LLMs. The video translator offers 100 language translations and one-click full-process deployment. The video translation output is optimized for platforms like YouTubeÔºåTikTok. AIËßÜÈ¢ëÁøªËØëÈÖçÈü≥Â∑•ÂÖ∑Ôºå100ÁßçËØ≠Ë®ÄÂèåÂêëÁøªËØëÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤ÂÖ®ÊµÅÁ®ãÔºåÂèØ‰ª•ÁîüÊäñÈü≥ÔºåÂ∞èÁ∫¢‰π¶ÔºåÂìîÂì©ÂìîÂì©ÔºåËßÜÈ¢ëÂè∑ÔºåTikTokÔºåYoutubeÁ≠âÂΩ¢ÊÄÅÁöÑÂÜÖÂÆπÊàêÈÄÇÈÖç&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/logo.jpg" alt="KrillinAI" height="90" /&gt; 
 &lt;h1&gt;Minimalist AI Video Translation and Dubbing Tool&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/13360" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13360" alt="KrillinAI%2FKrillinAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/README.md"&gt;English&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/zh/README.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/jp/README.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/kr/README.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/vi/README.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/fr/README.md"&gt;Fran√ßais&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/de/README.md"&gt;Deutsch&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/es/README.md"&gt;Espa√±ol&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/pt/README.md"&gt;Portugu√™s&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/rus/README.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;ÔΩú&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/ar/README.md"&gt;ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://x.com/KrillinAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-KrillinAI-orange?logo=twitter" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://jq.qq.com/?_wv=1027&amp;amp;k=754069680"&gt;&lt;img src="https://img.shields.io/badge/QQ%20%E7%BE%A4-754069680-green?logo=tencent-qq" alt="QQ Áæ§" /&gt;&lt;/a&gt; &lt;a href="https://space.bilibili.com/242124650"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?label=Bilibili&amp;amp;query=%24.data.follower&amp;amp;suffix=%E7%B2%89%E4%B8%9D&amp;amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Frelation%2Fstat%3Fvmid%3D242124650&amp;amp;logo=bilibili&amp;amp;color=00A1D6&amp;amp;labelColor=FE7398&amp;amp;logoColor=FFFFFF" alt="Bilibili" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/krillinai/KrillinAI"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Project Introduction (&lt;a href="https://www.klic.studio/"&gt;Try the online version now!&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/#-quick-start"&gt;&lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;KrillinAI is a versatile audio and video localization and enhancement solution developed by Krillin AI. This minimalist yet powerful tool integrates video translation, dubbing, and voice cloning, supporting both landscape and portrait formats to ensure perfect presentation on all major platforms (Bilibili, Xiaohongshu, Douyin, WeChat Video, Kuaishou, YouTube, TikTok, etc.). With an end-to-end workflow, you can transform raw materials into beautifully ready-to-use cross-platform content with just a few clicks.&lt;/p&gt; 
&lt;h2&gt;Key Features and Functions:&lt;/h2&gt; 
&lt;p&gt;üéØ &lt;strong&gt;One-click Start&lt;/strong&gt;: No complex environment configuration required, automatic dependency installation, ready to use immediately, with a new desktop version for easier access!&lt;/p&gt; 
&lt;p&gt;üì• &lt;strong&gt;Video Acquisition&lt;/strong&gt;: Supports yt-dlp downloads or local file uploads&lt;/p&gt; 
&lt;p&gt;üìú &lt;strong&gt;Accurate Recognition&lt;/strong&gt;: High-accuracy speech recognition based on Whisper&lt;/p&gt; 
&lt;p&gt;üß† &lt;strong&gt;Intelligent Segmentation&lt;/strong&gt;: Subtitle segmentation and alignment using LLM&lt;/p&gt; 
&lt;p&gt;üîÑ &lt;strong&gt;Terminology Replacement&lt;/strong&gt;: One-click replacement of professional vocabulary&lt;/p&gt; 
&lt;p&gt;üåç &lt;strong&gt;Professional Translation&lt;/strong&gt;: LLM translation with context to maintain natural semantics&lt;/p&gt; 
&lt;p&gt;üéôÔ∏è &lt;strong&gt;Voice Cloning&lt;/strong&gt;: Offers selected voice tones from CosyVoice or custom voice cloning&lt;/p&gt; 
&lt;p&gt;üé¨ &lt;strong&gt;Video Composition&lt;/strong&gt;: Automatically processes landscape and portrait videos and subtitle layout&lt;/p&gt; 
&lt;p&gt;üíª &lt;strong&gt;Cross-Platform&lt;/strong&gt;: Supports Windows, Linux, macOS, providing both desktop and server versions&lt;/p&gt; 
&lt;h2&gt;Effect Demonstration&lt;/h2&gt; 
&lt;p&gt;The image below shows the effect of the subtitle file generated after importing a 46-minute local video and executing it with one click, without any manual adjustments. There are no omissions or overlaps, the segmentation is natural, and the translation quality is very high. &lt;img src="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/alignment.png" alt="Alignment Effect" /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Subtitle Translation&lt;/h3&gt; 
    &lt;hr /&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339"&gt;https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Dubbing&lt;/h3&gt; 
    &lt;hr /&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385"&gt;https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="33%"&gt; &lt;h3&gt;Portrait Mode&lt;/h3&gt; 
    &lt;hr /&gt; &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71"&gt;https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üîç Supported Speech Recognition Services&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;All local models in the table below support automatic installation of executable files + model files; you just need to choose, and Klic will prepare everything for you.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service Source&lt;/th&gt; 
   &lt;th&gt;Supported Platforms&lt;/th&gt; 
   &lt;th&gt;Model Options&lt;/th&gt; 
   &lt;th&gt;Local/Cloud&lt;/th&gt; 
   &lt;th&gt;Remarks&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenAI Whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All Platforms&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Cloud&lt;/td&gt; 
   &lt;td&gt;Fast speed and good effect&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FasterWhisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;tiny&lt;/code&gt;/&lt;code&gt;medium&lt;/code&gt;/&lt;code&gt;large-v2&lt;/code&gt; (recommended medium+)&lt;/td&gt; 
   &lt;td&gt;Local&lt;/td&gt; 
   &lt;td&gt;Faster speed, no cloud service cost&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;WhisperKit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;macOS (M-series only)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;large-v2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Local&lt;/td&gt; 
   &lt;td&gt;Native optimization for Apple chips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;WhisperCpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All Platforms&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;large-v2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Local&lt;/td&gt; 
   &lt;td&gt;Supports all platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Alibaba Cloud ASR&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All Platforms&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Cloud&lt;/td&gt; 
   &lt;td&gt;Avoids network issues in mainland China&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Large Language Model Support&lt;/h2&gt; 
&lt;p&gt;‚úÖ Compatible with all cloud/local large language model services that comply with &lt;strong&gt;OpenAI API specifications&lt;/strong&gt;, including but not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Gemini&lt;/li&gt; 
 &lt;li&gt;DeepSeek&lt;/li&gt; 
 &lt;li&gt;Tongyi Qianwen&lt;/li&gt; 
 &lt;li&gt;Locally deployed open-source models&lt;/li&gt; 
 &lt;li&gt;Other API services compatible with OpenAI format&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üé§ TTS Text-to-Speech Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alibaba Cloud Voice Service&lt;/li&gt; 
 &lt;li&gt;OpenAI TTS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Language Support&lt;/h2&gt; 
&lt;p&gt;Input languages supported: Chinese, English, Japanese, German, Turkish, Korean, Russian, Malay (continuously increasing)&lt;/p&gt; 
&lt;p&gt;Translation languages supported: English, Chinese, Russian, Spanish, French, and 101 other languages&lt;/p&gt; 
&lt;h2&gt;Interface Preview&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/ui_desktop_light.png" alt="Interface Preview" /&gt; &lt;img src="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docs/images/ui_desktop_dark.png" alt="Interface Preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;You can ask questions on the &lt;a href="https://deepwiki.com/krillinai/KrillinAI"&gt;Deepwiki of KrillinAI&lt;/a&gt;. It indexes the files in the repository, so you can find answers quickly.&lt;/p&gt; 
&lt;h3&gt;Basic Steps&lt;/h3&gt; 
&lt;p&gt;First, download the executable file that matches your device system from the &lt;a href="https://github.com/KrillinAI/KrillinAI/releases"&gt;Release&lt;/a&gt;, then follow the tutorial below to choose between the desktop version or non-desktop version. Place the software download in an empty folder, as running it will generate some directories, and keeping it in an empty folder will make management easier.&lt;/p&gt; 
&lt;p&gt;„ÄêIf it is the desktop version, i.e., the release file with "desktop," see here„Äë &lt;em&gt;The desktop version is newly released to address the issues of new users struggling to edit configuration files correctly, and there are some bugs that are continuously being updated.&lt;/em&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Double-click the file to start using it (the desktop version also requires configuration within the software)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;„ÄêIf it is the non-desktop version, i.e., the release file without "desktop," see here„Äë &lt;em&gt;The non-desktop version is the initial version, which has a more complex configuration but is stable in functionality and suitable for server deployment, as it provides a UI in a web format.&lt;/em&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a &lt;code&gt;config&lt;/code&gt; folder within the folder, then create a &lt;code&gt;config.toml&lt;/code&gt; file in the &lt;code&gt;config&lt;/code&gt; folder. Copy the contents of the &lt;code&gt;config-example.toml&lt;/code&gt; file from the source code's &lt;code&gt;config&lt;/code&gt; directory into &lt;code&gt;config.toml&lt;/code&gt;, and fill in your configuration information according to the comments.&lt;/li&gt; 
 &lt;li&gt;Double-click or execute the executable file in the terminal to start the service&lt;/li&gt; 
 &lt;li&gt;Open your browser and enter &lt;code&gt;http://127.0.0.1:8888&lt;/code&gt; to start using it (replace 8888 with the port you specified in the configuration file)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;To: macOS Users&lt;/h3&gt; 
&lt;p&gt;„ÄêIf it is the desktop version, i.e., the release file with "desktop," see here„Äë Due to signing issues, the desktop version currently cannot be double-clicked to run or installed via dmg; you need to manually trust the application. The method is as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open the terminal in the directory where the executable file (assuming the file name is KrillinAI_1.0.0_desktop_macOS_arm64) is located&lt;/li&gt; 
 &lt;li&gt;Execute the following commands in order:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;sudo xattr -cr ./KrillinAI_1.0.0_desktop_macOS_arm64
sudo chmod +x ./KrillinAI_1.0.0_desktop_macOS_arm64 
./KrillinAI_1.0.0_desktop_macOS_arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;„ÄêIf it is the non-desktop version, i.e., the release file without "desktop," see here„Äë This software is not signed, so when running on macOS, after completing the file configuration in the "Basic Steps," you also need to manually trust the application. The method is as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open the terminal in the directory where the executable file (assuming the file name is KrillinAI_1.0.0_macOS_arm64) is located&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Execute the following commands in order:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo xattr -rd com.apple.quarantine ./KrillinAI_1.0.0_macOS_arm64
 sudo chmod +x ./KrillinAI_1.0.0_macOS_arm64
 ./KrillinAI_1.0.0_macOS_arm64
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will start the service&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Docker Deployment&lt;/h3&gt; 
&lt;p&gt;This project supports Docker deployment; please refer to the &lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/docker.md"&gt;Docker Deployment Instructions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Based on the provided configuration file, here is the updated "Configuration Help (Must Read)" section for your README file:&lt;/p&gt; 
&lt;h3&gt;Configuration Help (Must Read)&lt;/h3&gt; 
&lt;p&gt;The configuration file is divided into several sections: &lt;code&gt;[app]&lt;/code&gt;, &lt;code&gt;[server]&lt;/code&gt;, &lt;code&gt;[llm]&lt;/code&gt;, &lt;code&gt;[transcribe]&lt;/code&gt;, and &lt;code&gt;[tts]&lt;/code&gt;. A task is composed of speech recognition (&lt;code&gt;transcribe&lt;/code&gt;) + large model translation (&lt;code&gt;llm&lt;/code&gt;) + optional voice services (&lt;code&gt;tts&lt;/code&gt;). Understanding this will help you better grasp the configuration file.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easiest and Quickest Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For Subtitle Translation Only:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the &lt;code&gt;[transcribe]&lt;/code&gt; section, set &lt;code&gt;provider.name&lt;/code&gt; to &lt;code&gt;openai&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You will then only need to fill in your OpenAI API key in the &lt;code&gt;[llm]&lt;/code&gt; block to start performing subtitle translations. The &lt;code&gt;app.proxy&lt;/code&gt;, &lt;code&gt;model&lt;/code&gt;, and &lt;code&gt;openai.base_url&lt;/code&gt; can be filled in as needed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Balanced Cost, Speed, and Quality (Using Local Speech Recognition):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the &lt;code&gt;[transcribe]&lt;/code&gt; section, set &lt;code&gt;provider.name&lt;/code&gt; to &lt;code&gt;fasterwhisper&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;transcribe.fasterwhisper.model&lt;/code&gt; to &lt;code&gt;large-v2&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Fill in your large language model configuration in the &lt;code&gt;[llm]&lt;/code&gt; block.&lt;/li&gt; 
 &lt;li&gt;The required local model will be automatically downloaded and installed.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Text-to-Speech (TTS) Configuration (Optional):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;TTS configuration is optional.&lt;/li&gt; 
 &lt;li&gt;First, set the &lt;code&gt;provider.name&lt;/code&gt; under the &lt;code&gt;[tts]&lt;/code&gt; section (e.g., &lt;code&gt;aliyun&lt;/code&gt; or &lt;code&gt;openai&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Then, fill in the corresponding configuration block for the selected provider. For example, if you choose &lt;code&gt;aliyun&lt;/code&gt;, you must fill in the &lt;code&gt;[tts.aliyun]&lt;/code&gt; section.&lt;/li&gt; 
 &lt;li&gt;Voice codes in the user interface should be chosen based on the selected provider's documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you plan to use the voice cloning feature, you must select &lt;code&gt;aliyun&lt;/code&gt; as the TTS provider.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Alibaba Cloud Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For details on obtaining the necessary &lt;code&gt;AccessKey&lt;/code&gt;, &lt;code&gt;Bucket&lt;/code&gt;, and &lt;code&gt;AppKey&lt;/code&gt; for Alibaba Cloud services, please refer to the &lt;a href="https://www.google.com/search?q=./aliyun.md"&gt;Alibaba Cloud Configuration Instructions&lt;/a&gt;. The repeated fields for AccessKey, etc., are designed to maintain a clear configuration structure.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;p&gt;Please visit &lt;a href="https://raw.githubusercontent.com/krillinai/KrillinAI/master/faq.md"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contribution Guidelines&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Do not submit useless files, such as .vscode, .idea, etc.; please use .gitignore to filter them out.&lt;/li&gt; 
 &lt;li&gt;Do not submit config.toml; instead, submit config-example.toml.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Join our QQ group for questions: 754069680&lt;/li&gt; 
 &lt;li&gt;Follow our social media accounts, &lt;a href="https://space.bilibili.com/242124650"&gt;Bilibili&lt;/a&gt;, where we share quality content in the AI technology field every day.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#KrillinAI/KrillinAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=KrillinAI/KrillinAI&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tailscale/tailscale</title>
      <link>https://github.com/tailscale/tailscale</link>
      <description>&lt;p&gt;The easiest, most secure way to use WireGuard and 2FA.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tailscale&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com"&gt;https://tailscale.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Private WireGuard¬Æ networks made easy&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the majority of Tailscale's open source code. Notably, it includes the &lt;code&gt;tailscaled&lt;/code&gt; daemon and the &lt;code&gt;tailscale&lt;/code&gt; CLI tool. The &lt;code&gt;tailscaled&lt;/code&gt; daemon runs on Linux, Windows, &lt;a href="https://tailscale.com/kb/1065/macos-variants/"&gt;macOS&lt;/a&gt;, and to varying degrees on FreeBSD and OpenBSD. The Tailscale iOS and Android apps use this repo's code, but this repo doesn't contain the mobile GUI code.&lt;/p&gt; 
&lt;p&gt;Other &lt;a href="https://github.com/orgs/tailscale/repositories"&gt;Tailscale repos&lt;/a&gt; of note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the Android app is at &lt;a href="https://github.com/tailscale/tailscale-android"&gt;https://github.com/tailscale/tailscale-android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Synology package is at &lt;a href="https://github.com/tailscale/tailscale-synology"&gt;https://github.com/tailscale/tailscale-synology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the QNAP package is at &lt;a href="https://github.com/tailscale/tailscale-qpkg"&gt;https://github.com/tailscale/tailscale-qpkg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Chocolatey packaging is at &lt;a href="https://github.com/tailscale/tailscale-chocolatey"&gt;https://github.com/tailscale/tailscale-chocolatey&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For background on which parts of Tailscale are open source and why, see &lt;a href="https://tailscale.com/opensource/"&gt;https://tailscale.com/opensource/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Using&lt;/h2&gt; 
&lt;p&gt;We serve packages for a variety of distros and platforms at &lt;a href="https://pkgs.tailscale.com/"&gt;https://pkgs.tailscale.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Other clients&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://tailscale.com/download"&gt;macOS, iOS, and Windows clients&lt;/a&gt; use the code in this repository but additionally include small GUI wrappers. The GUI wrappers on non-open source platforms are themselves not open source.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;We always require the latest Go release, currently Go 1.25. (While we build releases with our &lt;a href="https://github.com/tailscale/go/"&gt;Go fork&lt;/a&gt;, its use is not required.)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install tailscale.com/cmd/tailscale{,d}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're packaging Tailscale for distribution, use &lt;code&gt;build_dist.sh&lt;/code&gt; instead, to burn commit IDs and version info into the binaries:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./build_dist.sh tailscale.com/cmd/tailscale
./build_dist.sh tailscale.com/cmd/tailscaled
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your distro has conventions that preclude the use of &lt;code&gt;build_dist.sh&lt;/code&gt;, please do the equivalent of what it does in your distro's way, so that bug reports contain useful version information.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Please file any issues about this code or the hosted service on &lt;a href="https://github.com/tailscale/tailscale/issues"&gt;the issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PRs welcome! But please file bugs. Commit messages should &lt;a href="https://docs.github.com/en/github/writing-on-github/autolinked-references-and-urls"&gt;reference bugs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We require &lt;a href="https://en.wikipedia.org/wiki/Developer_Certificate_of_Origin"&gt;Developer Certificate of Origin&lt;/a&gt; &lt;code&gt;Signed-off-by&lt;/code&gt; lines in commits.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tailscale/tailscale/main/docs/commit-messages.md"&gt;commit-messages.md&lt;/a&gt; (or skim &lt;code&gt;git log&lt;/code&gt;) for our commit message style.&lt;/p&gt; 
&lt;h2&gt;About Us&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; is primarily developed by the people at &lt;a href="https://github.com/orgs/tailscale/people"&gt;https://github.com/orgs/tailscale/people&lt;/a&gt;. For other contributors, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale/graphs/contributors"&gt;https://github.com/tailscale/tailscale/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale-android/graphs/contributors"&gt;https://github.com/tailscale/tailscale-android/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;WireGuard is a registered trademark of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>googleapis/genai-toolbox</title>
      <link>https://github.com/googleapis/genai-toolbox</link>
      <description>&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;MCP Toolbox for Databases&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;&lt;img src="https://img.shields.io/badge/docs-MCP_Toolbox-blue" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Dmm69peqjh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://medium.com/@mcp_toolbox"&gt;&lt;img src="https://img.shields.io/badge/Medium-12100E?style=flat&amp;amp;logo=medium&amp;amp;logoColor=white" alt="Medium" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/googleapis/genai-toolbox"&gt;&lt;img src="https://goreportcard.com/badge/github.com/googleapis/genai-toolbox" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MCP Toolbox for Databases is currently in beta, and may see breaking changes until the first stable release (v1.0).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases. It enables you to develop tools easier, faster, and more securely by handling the complexities such as connection pooling, authentication, and more.&lt;/p&gt; 
&lt;p&gt;This README provides a brief overview. For comprehensive details, see the &lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;full documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This solution was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as its initial development predated MCP, but was renamed to align with recently added MCP compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- TOC ignore:true --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- TOC --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#why-toolbox"&gt;Why Toolbox?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#general-architecture"&gt;General Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;Installing the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#running-the-server"&gt;Running the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#integrating-your-application"&gt;Integrating your application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#sources"&gt;Sources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#toolsets"&gt;Toolsets&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#versioning"&gt;Versioning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#pre-100-versioning"&gt;Pre-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#post-100-versioning"&gt;Post-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- /TOC --&gt; 
&lt;h2&gt;Why Toolbox?&lt;/h2&gt; 
&lt;p&gt;Toolbox helps you build Gen AI tools that let your agents access data in your database. Toolbox provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simplified development&lt;/strong&gt;: Integrate tools to your agent in less than 10 lines of code, reuse tools between multiple agents or frameworks, and deploy new versions of tools more easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt;: Best practices such as connection pooling, authentication, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced security&lt;/strong&gt;: Integrated auth for more secure access to your data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end observability&lt;/strong&gt;: Out of the box metrics and tracing with built-in support for OpenTelemetry.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;‚ö° Supercharge Your Workflow with an AI Database Assistant ‚ö°&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Stop context-switching and let your AI assistant become a true co-developer. By &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;connecting your IDE to your databases with MCP Toolbox&lt;/a&gt;, you can delegate complex and time-consuming database tasks, allowing you to build faster and focus on what matters. This isn't just about code completion; it's about giving your AI the context it needs to handle the entire development lifecycle.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how it will save you time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query in Plain English&lt;/strong&gt;: Interact with your data using natural language right from your IDE. Ask complex questions like, &lt;em&gt;"How many orders were delivered in 2024, and what items were in them?"&lt;/em&gt; without writing any SQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate Database Management&lt;/strong&gt;: Simply describe your data needs, and let the AI assistant manage your database for you. It can handle generating queries, creating tables, adding indexes, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generate Context-Aware Code&lt;/strong&gt;: Empower your AI assistant to generate application code and tests with a deep understanding of your real-time database schema. This accelerates the development cycle by ensuring the generated code is directly usable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Slash Development Overhead&lt;/strong&gt;: Radically reduce the time spent on manual setup and boilerplate. MCP Toolbox helps streamline lengthy database configurations, repetitive code, and error-prone schema migrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;how to connect your AI tools (IDEs) to Toolbox using MCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General Architecture&lt;/h2&gt; 
&lt;p&gt;Toolbox sits between your application's orchestration framework and your database, providing a control plane that is used to modify, distribute, or invoke tools. It simplifies the management of your tools by providing you with a centralized location to store and update tools, allowing you to share tools between agents and applications and update those tools without necessarily redeploying your application.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/docs/en/getting-started/introduction/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installing the server&lt;/h3&gt; 
&lt;p&gt;For the latest version, check the &lt;a href="https://github.com/googleapis/genai-toolbox/releases"&gt;releases page&lt;/a&gt; and use the following instructions for your OS and CPU architecture.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox as a binary:&lt;/p&gt; 
 &lt;!-- {x-release-please-start-version} --&gt; 
 &lt;blockquote&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Linux (AMD64)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Linux (AMD64):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.18.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Apple Silicon):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.18.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Intel)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Intel):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.18.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Windows (AMD64)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Windows (AMD64):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-powershell"&gt;# see releases page for other versions
$VERSION = "0.18.0"
Invoke-WebRequest -Uri "https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe" -OutFile "toolbox.exe"
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; You can also install Toolbox as a container: 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.18.0
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox using Homebrew on macOS or Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;brew install mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Compile from source&lt;/summary&gt; 
 &lt;p&gt;To install from source, ensure you have the latest version of &lt;a href="https://go.dev/doc/install"&gt;Go installed&lt;/a&gt;, and then run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/googleapis/genai-toolbox@v0.18.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- {x-release-please-end} --&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt; 
 &lt;p&gt;To install Gemini CLI Extensions for MCP Toolbox, run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Running the server&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configure&lt;/a&gt; a &lt;code&gt;tools.yaml&lt;/code&gt; to define your tools, and then execute &lt;code&gt;toolbox&lt;/code&gt; to start the server:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To run Toolbox from binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;./toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; Toolbox enables dynamic reloading by default. To disable, use the &lt;code&gt;--disable-reload&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; 
 &lt;p&gt;To run the server after pulling the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;container image&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export VERSION=0.11.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file "/app/tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; The &lt;code&gt;-v&lt;/code&gt; flag mounts your local &lt;code&gt;tools.yaml&lt;/code&gt; into the container, and &lt;code&gt;-p&lt;/code&gt; maps the container's port &lt;code&gt;5000&lt;/code&gt; to your host's port &lt;code&gt;5000&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Source&lt;/summary&gt; 
 &lt;p&gt;To run the server directly from source, navigate to the project root directory and run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; This command runs the project from source, and is more suitable for development and testing. It does &lt;strong&gt;not&lt;/strong&gt; compile a binary into your &lt;code&gt;$GOPATH&lt;/code&gt;. If you want to compile a binary instead, refer the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/DEVELOPER.md#building-the-binary"&gt;Developer Documentation&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;If you installed Toolbox using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;, the &lt;code&gt;toolbox&lt;/code&gt; binary is available in your system path. You can start the server with the same command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; 
 &lt;p&gt;Interact with your custom tools using natural language. Check &lt;a href="https://github.com/gemini-cli-extensions/mcp-toolbox"&gt;gemini-cli-extensions/mcp-toolbox&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;You can use &lt;code&gt;toolbox help&lt;/code&gt; for a full list of flags! To stop the server, send a terminate signal (&lt;code&gt;ctrl+c&lt;/code&gt; on most platforms).&lt;/p&gt; 
&lt;p&gt;For more detailed documentation on deploying to different environments, check out the resources in the &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/"&gt;How-to section&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Integrating your application&lt;/h3&gt; 
&lt;p&gt;Once your server is up and running, you can load the tools into your application. See below the list of Client SDKs for using various frameworks:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Python (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-core/"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_core import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = await client.load_toolset("toolset_name")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-langchain/"&gt;Toolbox LangChain SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-langchain
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_langchain import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox LangChain SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/raw/main/packages/toolbox-langchain/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LlamaIndex&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-llamaindex/"&gt;Toolbox Llamaindex SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-llamaindex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_llamaindex import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Llamaindex SDK, see the &lt;a href="https://github.com/googleapis/genai-toolbox-llamaindex-python/raw/main/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Javascript/Typescript (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const tools = await client.loadToolset('toolsetName');
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js/raw/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; tool(currTool, {
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
});

// Use these tools in your Langchain/Langraph applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';
import { genkit } from 'genkit';

// Initialise genkit
const ai = genkit({
    plugins: [
        googleAI({
            apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
        })
    ],
    model: googleAI.model('gemini-2.0-flash'),
});

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; ai.defineTool({
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
}, toolboxTool)

// Use these tools in your Genkit applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Go (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "context"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000";
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tools
  tools, err := client.LoadToolset("toolsetName", ctx)
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Go SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go/raw/main/core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/tmc/langchaingo/llms"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema map[string]any
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with LangChainGo
  langChainTool := llms.Tool{
    Type: "function",
    Function: &amp;amp;llms.FunctionDefinition{
      Name:        tool.Name(),
      Description: tool.Description(),
      Parameters:  paramsSchema,
    },
  }
}

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main
import (
  "context"
  "log"

  "github.com/firebase/genkit/go/genkit"
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()
  g := genkit.Init(ctx)

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Convert the tool using the tbgenkit package
  // Use this tool with Genkit Go
  genkitTool, err := tbgenkit.ToGenkitTool(tool, g)
  if err != nil {
    log.Fatalf("Failed to convert tool: %v\n", err)
  }
  log.Printf("Successfully converted tool: %s", genkitTool.Name())
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Go GenAI&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "google.golang.org/genai"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var schema *genai.Schema
  _ = json.Unmarshal(inputschema, &amp;amp;schema)

  funcDeclaration := &amp;amp;genai.FunctionDeclaration{
    Name:        tool.Name(),
    Description: tool.Description(),
    Parameters:  schema,
  }

  // Use this tool with Go GenAI
  genAITool := &amp;amp;genai.Tool{
    FunctionDeclarations: []*genai.FunctionDeclaration{funcDeclaration},
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;OpenAI Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  openai "github.com/openai/openai-go"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema openai.FunctionParameters
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with OpenAI Go
  openAITool := openai.ChatCompletionToolParam{
    Function: openai.FunctionDefinitionParam{
      Name:        tool.Name(),
      Description: openai.String(tool.Description()),
      Parameters:  paramsSchema,
    },
  }

}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;   
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The primary way to configure Toolbox is through the &lt;code&gt;tools.yaml&lt;/code&gt; file. If you have multiple files, you can tell toolbox which to load with the &lt;code&gt;--tools-file tools.yaml&lt;/code&gt; flag.&lt;/p&gt; 
&lt;p&gt;You can find more detailed reference documentation to all resource types in the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/"&gt;Resources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sources&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sources&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; defines what data sources your Toolbox should have access to. Most tools will have at least one source to execute against.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sources:
  my-pg-source:
    kind: postgres
    host: 127.0.0.1
    port: 5432
    database: toolbox_db
    user: toolbox_user
    password: my-password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of sources, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/sources"&gt;Sources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;tools&lt;/code&gt; section of a &lt;code&gt;tools.yaml&lt;/code&gt; define the actions an agent can take: what kind of tool it is, which source(s) it affects, what parameters it uses, etc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;tools:
  search-hotels-by-name:
    kind: postgres-sql
    source: my-pg-source
    description: Search for hotels based on name.
    parameters:
      - name: name
        type: string
        description: The name of the hotel.
    statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%';
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of tools, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/tools"&gt;Tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Toolsets&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;toolsets&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; allows you to define groups of tools that you want to be able to load together. This can be useful for defining different groups based on agent or application.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;toolsets:
    my_first_toolset:
        - my_first_tool
        - my_second_tool
    my_second_toolset:
        - my_second_tool
        - my_third_tool
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can load toolsets by name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# This will load all tools
all_tools = client.load_toolset()

# This will only load the tools listed in 'my_second_toolset'
my_second_toolset = client.load_toolset("my_second_toolset")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;This project uses &lt;a href="https://semver.org/"&gt;semantic versioning&lt;/a&gt; (&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;). Since the project is in a pre-release stage (version &lt;code&gt;0.x.y&lt;/code&gt;), we follow the standard conventions for initial development:&lt;/p&gt; 
&lt;h3&gt;Pre-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;While the major version is &lt;code&gt;0&lt;/code&gt;, the public API should be considered unstable. The version will be incremented as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;MINOR&lt;/strong&gt; version is incremented when we add new functionality or make breaking, incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;PATCH&lt;/strong&gt; version is incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Post-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;Once the project reaches a stable &lt;code&gt;1.0.0&lt;/code&gt; release, the versioning will follow the more common convention:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for new, backward-compatible functionality.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The public API that this applies to is the CLI associated with Toolbox, the interactions with official SDKs, and the definitions in the &lt;code&gt;tools.yaml&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome. Please, see the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. See &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/GQrFB3Ec3W"&gt;discord community&lt;/a&gt; to connect with our developers!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>