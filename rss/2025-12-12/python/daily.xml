<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Thu, 11 Dec 2025 01:37:50 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>datawhalechina/hello-agents</title>
      <link>https://github.com/datawhalechina/hello-agents</link>
      <description>&lt;p&gt;ğŸ“š ã€Šä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ã€‹â€”â€”ä»é›¶å¼€å§‹çš„æ™ºèƒ½ä½“åŸç†ä¸å®è·µæ•™ç¨‹&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/README_EN.md"&gt;English&lt;/a&gt; | ä¸­æ–‡ 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/hello-agents.png" alt="alt text" width="100%" /&gt; 
 &lt;h1&gt;Hello-Agents&lt;/h1&gt; 
 &lt;h3&gt;ğŸ¤– ã€Šä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ã€‹&lt;/h3&gt; 
 &lt;p&gt;&lt;em&gt;ä»åŸºç¡€ç†è®ºåˆ°å®é™…åº”ç”¨ï¼Œå…¨é¢æŒæ¡æ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°&lt;/em&gt;&lt;/p&gt; 
 &lt;img src="https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub stars" /&gt; 
 &lt;img src="https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;amp;logo=github" alt="GitHub forks" /&gt; 
 &lt;img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" /&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;amp;logo=github" alt="GitHub Project" /&gt;&lt;/a&gt; 
 &lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;&lt;img src="https://img.shields.io/badge/åœ¨çº¿é˜…è¯»-Online%20Reading-green?style=flat&amp;amp;logo=gitbook" alt="Online Reading" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¯ é¡¹ç›®ä»‹ç»&lt;/h2&gt; 
&lt;p&gt;â€ƒâ€ƒå¦‚æœè¯´ 2024 å¹´æ˜¯"ç™¾æ¨¡å¤§æˆ˜"çš„å…ƒå¹´ï¼Œé‚£ä¹ˆ 2025 å¹´æ— ç–‘å¼€å¯äº†"Agent å…ƒå¹´"ã€‚æŠ€æœ¯çš„ç„¦ç‚¹æ­£ä»è®­ç»ƒæ›´å¤§çš„åŸºç¡€æ¨¡å‹ï¼Œè½¬å‘æ„å»ºæ›´èªæ˜çš„æ™ºèƒ½ä½“åº”ç”¨ã€‚ç„¶è€Œï¼Œå½“å‰ç³»ç»Ÿæ€§ã€é‡å®è·µçš„æ•™ç¨‹å´æåº¦åŒ®ä¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘èµ·äº† Hello-Agents é¡¹ç›®ï¼Œå¸Œæœ›èƒ½ä¸ºç¤¾åŒºæä¾›ä¸€æœ¬ä»é›¶å¼€å§‹ã€ç†è®ºä¸å®æˆ˜å¹¶é‡çš„æ™ºèƒ½ä½“ç³»ç»Ÿæ„å»ºæŒ‡å—ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒHello-Agents æ˜¯ Datawhale ç¤¾åŒºçš„&lt;strong&gt;ç³»ç»Ÿæ€§æ™ºèƒ½ä½“å­¦ä¹ æ•™ç¨‹&lt;/strong&gt;ã€‚å¦‚ä»Š Agent æ„å»ºä¸»è¦åˆ†ä¸ºä¸¤æ´¾ï¼Œä¸€æ´¾æ˜¯ Difyï¼ŒCozeï¼Œn8n è¿™ç±»è½¯ä»¶å·¥ç¨‹ç±» Agentï¼Œå…¶æœ¬è´¨æ˜¯æµç¨‹é©±åŠ¨çš„è½¯ä»¶å¼€å‘ï¼ŒLLM ä½œä¸ºæ•°æ®å¤„ç†çš„åç«¯ï¼›å¦ä¸€æ´¾åˆ™æ˜¯ AI åŸç”Ÿçš„ Agentï¼Œå³çœŸæ­£ä»¥ AI é©±åŠ¨çš„ Agentã€‚æœ¬æ•™ç¨‹æ—¨åœ¨å¸¦é¢†å¤§å®¶æ·±å…¥ç†è§£å¹¶æ„å»ºåè€…â€”â€”çœŸæ­£çš„ AI Native Agentã€‚æ•™ç¨‹å°†å¸¦é¢†ä½ ç©¿é€æ¡†æ¶è¡¨è±¡ï¼Œä»æ™ºèƒ½ä½“çš„æ ¸å¿ƒåŸç†å‡ºå‘ï¼Œæ·±å…¥å…¶æ ¸å¿ƒæ¶æ„ï¼Œç†è§£å…¶ç»å…¸èŒƒå¼ï¼Œå¹¶æœ€ç»ˆäº²æ‰‹æ„å»ºèµ·å±äºè‡ªå·±çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ€å¥½çš„å­¦ä¹ æ–¹å¼å°±æ˜¯åŠ¨æ‰‹å®è·µã€‚å¸Œæœ›è¿™æœ¬æ•™ç¨‹èƒ½æˆä¸ºä½ æ¢ç´¢æ™ºèƒ½ä½“ä¸–ç•Œçš„èµ·ç‚¹ï¼Œèƒ½å¤Ÿä»ä¸€åå¤§è¯­è¨€æ¨¡å‹çš„"ä½¿ç”¨è€…"ï¼Œèœ•å˜ä¸ºä¸€åæ™ºèƒ½ä½“ç³»ç»Ÿçš„"æ„å»ºè€…"ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ“š å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;h3&gt;åœ¨çº¿é˜…è¯»&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://datawhalechina.github.io/hello-agents/"&gt;ğŸŒ ç‚¹å‡»è¿™é‡Œå¼€å§‹åœ¨çº¿é˜…è¯»&lt;/a&gt;&lt;/strong&gt; - æ— éœ€ä¸‹è½½ï¼Œéšæ—¶éšåœ°å­¦ä¹ &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://book.heterocat.com.cn/"&gt;ğŸ“– Cookbook(æµ‹è¯•ç‰ˆ)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;æœ¬åœ°é˜…è¯»&lt;/h3&gt; 
&lt;p&gt;å¦‚æœæ‚¨å¸Œæœ›åœ¨æœ¬åœ°é˜…è¯»æˆ–è´¡çŒ®å†…å®¹ï¼Œè¯·å‚è€ƒä¸‹æ–¹çš„å­¦ä¹ æŒ‡å—ã€‚&lt;/p&gt; 
&lt;h3&gt;âœ¨ ä½ å°†æ”¶è·ä»€ä¹ˆï¼Ÿ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Datawhale å¼€æºå…è´¹&lt;/strong&gt; å®Œå…¨å…è´¹å­¦ä¹ æœ¬é¡¹ç›®æ‰€æœ‰å†…å®¹ï¼Œä¸ç¤¾åŒºå…±åŒæˆé•¿&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;ç†è§£æ ¸å¿ƒåŸç†&lt;/strong&gt; æ·±å…¥ç†è§£æ™ºèƒ½ä½“çš„æ¦‚å¿µã€å†å²ä¸ç»å…¸èŒƒå¼&lt;/li&gt; 
 &lt;li&gt;ğŸ—ï¸ &lt;strong&gt;äº²æ‰‹å®ç°&lt;/strong&gt; æŒæ¡çƒ­é—¨ä½ä»£ç å¹³å°å’Œæ™ºèƒ½ä½“ä»£ç æ¡†æ¶çš„ä½¿ç”¨&lt;/li&gt; 
 &lt;li&gt;ğŸ› ï¸ &lt;strong&gt;è‡ªç ”æ¡†æ¶&lt;a href="https://github.com/jjyaoao/helloagents"&gt;HelloAgents&lt;/a&gt;&lt;/strong&gt; åŸºäº Openai åŸç”Ÿ API ä»é›¶æ„å»ºä¸€ä¸ªè‡ªå·±çš„æ™ºèƒ½ä½“æ¡†æ¶&lt;/li&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;æŒæ¡é«˜çº§æŠ€èƒ½&lt;/strong&gt; ä¸€æ­¥æ­¥å®ç°ä¸Šä¸‹æ–‡å·¥ç¨‹ã€Memoryã€åè®®ã€è¯„ä¼°ç­‰ç³»ç»Ÿæ€§æŠ€æœ¯&lt;/li&gt; 
 &lt;li&gt;ğŸ¤ &lt;strong&gt;æ¨¡å‹è®­ç»ƒ&lt;/strong&gt; æŒæ¡ Agentic RLï¼Œä» SFT åˆ° GRPO çš„å…¨æµç¨‹å®æˆ˜è®­ç»ƒ LLM&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;é©±åŠ¨çœŸå®æ¡ˆä¾‹&lt;/strong&gt; å®æˆ˜å¼€å‘æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€èµ›åšå°é•‡ç­‰ç»¼åˆé¡¹ç›®&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;æ±‚èŒé¢è¯•&lt;/strong&gt; å­¦ä¹ æ™ºèƒ½ä½“æ±‚èŒç›¸å…³é¢è¯•é—®é¢˜&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“– å†…å®¹å¯¼èˆª&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç« èŠ‚&lt;/th&gt; 
   &lt;th&gt;å…³é”®å†…å®¹&lt;/th&gt; 
   &lt;th&gt;çŠ¶æ€&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/%E5%89%8D%E8%A8%80.md"&gt;å‰è¨€&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;é¡¹ç›®çš„ç¼˜èµ·ã€èƒŒæ™¯åŠè¯»è€…å»ºè®®&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬ä¸€éƒ¨åˆ†ï¼šæ™ºèƒ½ä½“ä¸è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%88%9D%E8%AF%86%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;ç¬¬ä¸€ç«  åˆè¯†æ™ºèƒ½ä½“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ™ºèƒ½ä½“å®šä¹‰ã€ç±»å‹ã€èŒƒå¼ä¸åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter2/%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E5%8F%91%E5%B1%95%E5%8F%B2.md"&gt;ç¬¬äºŒç«  æ™ºèƒ½ä½“å‘å±•å²&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä»ç¬¦å·ä¸»ä¹‰åˆ° LLM é©±åŠ¨çš„æ™ºèƒ½ä½“æ¼”è¿›&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter3/%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md"&gt;ç¬¬ä¸‰ç«  å¤§è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Transformerã€æç¤ºã€ä¸»æµ LLM åŠå…¶å±€é™&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºä½ çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA.md"&gt;ç¬¬å››ç«  æ™ºèƒ½ä½“ç»å…¸èŒƒå¼æ„å»º&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ‰‹æŠŠæ‰‹å®ç° ReActã€Plan-and-Solveã€Reflection&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter5/%E7%AC%AC%E4%BA%94%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%E6%90%AD%E5%BB%BA.md"&gt;ç¬¬äº”ç«  åŸºäºä½ä»£ç å¹³å°çš„æ™ºèƒ½ä½“æ­å»º&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;äº†è§£ Cozeã€Difyã€n8n ç­‰ä½ä»£ç æ™ºèƒ½ä½“å¹³å°ä½¿ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter6/%E7%AC%AC%E5%85%AD%E7%AB%A0%20%E6%A1%86%E6%9E%B6%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5.md"&gt;ç¬¬å…­ç«  æ¡†æ¶å¼€å‘å®è·µ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AutoGenã€AgentScopeã€LangGraph ç­‰ä¸»æµæ¡†æ¶åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter7/%E7%AC%AC%E4%B8%83%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E4%BD%A0%E7%9A%84Agent%E6%A1%86%E6%9E%B6.md"&gt;ç¬¬ä¸ƒç«  æ„å»ºä½ çš„Agentæ¡†æ¶&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä» 0 å¼€å§‹æ„å»ºæ™ºèƒ½ä½“æ¡†æ¶&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§çŸ¥è¯†æ‰©å±•&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter8/%E7%AC%AC%E5%85%AB%E7%AB%A0%20%E8%AE%B0%E5%BF%86%E4%B8%8E%E6%A3%80%E7%B4%A2.md"&gt;ç¬¬å…«ç«  è®°å¿†ä¸æ£€ç´¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;è®°å¿†ç³»ç»Ÿï¼ŒRAGï¼Œå­˜å‚¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter9/%E7%AC%AC%E4%B9%9D%E7%AB%A0%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.md"&gt;ç¬¬ä¹ç«  ä¸Šä¸‹æ–‡å·¥ç¨‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æŒç»­äº¤äº’çš„"æƒ…å¢ƒç†è§£"&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter10/%E7%AC%AC%E5%8D%81%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE.md"&gt;ç¬¬åç«  æ™ºèƒ½ä½“é€šä¿¡åè®®&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCPã€A2Aã€ANP ç­‰åè®®è§£æ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter11/%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%20Agentic-RL.md"&gt;ç¬¬åä¸€ç«  Agentic-RL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä» SFT åˆ° GRPO çš„ LLM è®­ç»ƒå®æˆ˜&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter12/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0.md"&gt;ç¬¬åäºŒç«  æ™ºèƒ½ä½“æ€§èƒ½è¯„ä¼°&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ ¸å¿ƒæŒ‡æ ‡ã€åŸºå‡†æµ‹è¯•ä¸è¯„ä¼°æ¡†æ¶&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬å››éƒ¨åˆ†ï¼šç»¼åˆæ¡ˆä¾‹è¿›é˜¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter13/%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%20%E6%99%BA%E8%83%BD%E6%97%85%E8%A1%8C%E5%8A%A9%E6%89%8B.md"&gt;ç¬¬åä¸‰ç«  æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;MCP ä¸å¤šæ™ºèƒ½ä½“åä½œçš„çœŸå®ä¸–ç•Œåº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter14/%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%20%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A0%94%E7%A9%B6%E6%99%BA%E8%83%BD%E4%BD%93.md"&gt;ç¬¬åå››ç«  è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DeepResearch Agent å¤ç°ä¸è§£æ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter15/%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%20%E6%9E%84%E5%BB%BA%E8%B5%9B%E5%8D%9A%E5%B0%8F%E9%95%87.md"&gt;ç¬¬åäº”ç«  æ„å»ºèµ›åšå°é•‡&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent ä¸æ¸¸æˆçš„ç»“åˆï¼Œæ¨¡æ‹Ÿç¤¾ä¼šåŠ¨æ€&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ç¬¬äº”éƒ¨åˆ†ï¼šæ¯•ä¸šè®¾è®¡åŠæœªæ¥å±•æœ›&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/chapter16/%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%20%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1.md"&gt;ç¬¬åå…­ç«  æ¯•ä¸šè®¾è®¡&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;æ„å»ºå±äºä½ çš„å®Œæ•´å¤šæ™ºèƒ½ä½“åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ç¤¾åŒºè´¡çŒ®ç²¾é€‰ (Community Blog)&lt;/h3&gt; 
&lt;p&gt;â€ƒâ€ƒæ¬¢è¿å¤§å®¶å°†åœ¨å­¦ä¹  Hello-Agents æˆ– Agent ç›¸å…³æŠ€æœ¯ä¸­çš„ç‹¬åˆ°è§è§£ã€å®è·µæ€»ç»“ï¼Œä»¥ PR çš„å½¢å¼è´¡çŒ®åˆ°ç¤¾åŒºç²¾é€‰ã€‚å¦‚æœæ˜¯ç‹¬ç«‹äºæ­£æ–‡çš„å†…å®¹ï¼Œä¹Ÿå¯ä»¥æŠ•ç¨¿è‡³ Extra-Chapterï¼&lt;strong&gt;æœŸå¾…ä½ çš„ç¬¬ä¸€æ¬¡è´¡çŒ®ï¼&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ç¤¾åŒºç²¾é€‰&lt;/th&gt; 
   &lt;th&gt;å†…å®¹æ€»ç»“&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md"&gt;01-Agenté¢è¯•é¢˜æ€»ç»“&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Agent å²—ä½ç›¸å…³é¢è¯•é—®é¢˜&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md"&gt;01-Agenté¢è¯•é¢˜ç­”æ¡ˆ&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ç›¸å…³é¢è¯•é—®é¢˜ç­”æ¡ˆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra02-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86.md"&gt;02-ä¸Šä¸‹æ–‡å·¥ç¨‹å†…å®¹è¡¥å……&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ä¸Šä¸‹æ–‡å·¥ç¨‹å†…å®¹æ‰©å±•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra03-Dify%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%9B%E5%BB%BA%E4%BF%9D%E5%A7%86%E7%BA%A7%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B.md"&gt;03-Difyæ™ºèƒ½ä½“åˆ›å»ºä¿å§†çº§æ•™ç¨‹&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Difyæ™ºèƒ½ä½“åˆ›å»ºä¿å§†çº§æ•™ç¨‹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/datawhalechina/hello-agents/raw/main/Extra-Chapter/Extra04-DatawhaleFAQ.md"&gt;04-Hello-agentsè¯¾ç¨‹å¸¸è§é—®é¢˜&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Datawhaleè¯¾ç¨‹å¸¸è§é—®é¢˜&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;PDF ç‰ˆæœ¬ä¸‹è½½&lt;/h3&gt; 
&lt;p&gt;â€ƒâ€ƒ&lt;em&gt;&lt;strong&gt;æœ¬ Hello-Agents PDF æ•™ç¨‹å®Œå…¨å¼€æºå…è´¹ã€‚ä¸ºé˜²æ­¢å„ç±»è¥é”€å·åŠ æ°´å°åè´©å–ç»™å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåˆå­¦è€…ï¼Œæˆ‘ä»¬ç‰¹åœ°åœ¨ PDF æ–‡ä»¶ä¸­é¢„å…ˆæ·»åŠ äº†ä¸å½±å“é˜…è¯»çš„ Datawhale å¼€æºæ ‡å¿—æ°´å°ï¼Œæ•¬è¯·è°…è§£ï½&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Hello-Agents PDF : &lt;a href="https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0"&gt;https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0&lt;/a&gt;&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Hello-Agents PDF å›½å†…ä¸‹è½½åœ°å€ : &lt;a href="https://www.datawhale.cn/learn/summary/239"&gt;https://www.datawhale.cn/learn/summary/239&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ’¡ å¦‚ä½•å­¦ä¹ &lt;/h2&gt; 
&lt;p&gt;â€ƒâ€ƒæ¬¢è¿ä½ ï¼Œæœªæ¥çš„æ™ºèƒ½ç³»ç»Ÿæ„å»ºè€…ï¼åœ¨å¼€å¯è¿™æ®µæ¿€åŠ¨äººå¿ƒçš„æ—…ç¨‹ä¹‹å‰ï¼Œè¯·å…è®¸æˆ‘ä»¬ç»™ä½ ä¸€äº›æ¸…æ™°çš„æŒ‡å¼•ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒæœ¬é¡¹ç›®å†…å®¹å…¼é¡¾ç†è®ºä¸å®æˆ˜ï¼Œæ—¨åœ¨å¸®åŠ©ä½ ç³»ç»Ÿæ€§åœ°æŒæ¡ä»å•ä¸ªæ™ºèƒ½ä½“åˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡ä¸å¼€å‘å…¨æµç¨‹ã€‚å› æ­¤ï¼Œå°¤å…¶é€‚åˆæœ‰ä¸€å®šç¼–ç¨‹åŸºç¡€çš„ &lt;strong&gt;AI å¼€å‘è€…ã€è½¯ä»¶å·¥ç¨‹å¸ˆã€åœ¨æ ¡å­¦ç”Ÿ&lt;/strong&gt; ä»¥åŠå¯¹å‰æ²¿ AI æŠ€æœ¯æŠ±æœ‰æµ“åšå…´è¶£çš„ &lt;strong&gt;è‡ªå­¦è€…&lt;/strong&gt;ã€‚åœ¨å­¦ä¹ æœ¬é¡¹ç›®ä¹‹å‰ï¼Œæˆ‘ä»¬å¸Œæœ›ä½ å…·å¤‡åŸºç¡€çš„ Python ç¼–ç¨‹èƒ½åŠ›ï¼Œå¹¶å¯¹å¤§è¯­è¨€æ¨¡å‹æœ‰åŸºæœ¬çš„æ¦‚å¿µæ€§äº†è§£ï¼ˆä¾‹å¦‚ï¼ŒçŸ¥é“å¦‚ä½•é€šè¿‡ API è°ƒç”¨ä¸€ä¸ª LLMï¼‰ã€‚é¡¹ç›®çš„é‡ç‚¹æ˜¯åº”ç”¨ä¸æ„å»ºï¼Œå› æ­¤ä½ æ— éœ€å…·å¤‡æ·±åšçš„ç®—æ³•æˆ–æ¨¡å‹è®­ç»ƒèƒŒæ™¯ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒé¡¹ç›®åˆ†ä¸ºäº”å¤§éƒ¨åˆ†ï¼Œæ¯ä¸€éƒ¨åˆ†éƒ½æ˜¯é€šå¾€ä¸‹ä¸€é˜¶æ®µçš„åšå®é˜¶æ¢¯ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬ä¸€éƒ¨åˆ†ï¼šæ™ºèƒ½ä½“ä¸è¯­è¨€æ¨¡å‹åŸºç¡€&lt;/strong&gt;ï¼ˆç¬¬ä¸€ç« ï½ç¬¬ä¸‰ç« ï¼‰ï¼Œæˆ‘ä»¬å°†ä»æ™ºèƒ½ä½“çš„å®šä¹‰ã€ç±»å‹ä¸å‘å±•å†å²è®²èµ·ï¼Œä¸ºä½ æ¢³ç†"æ™ºèƒ½ä½“"è¿™ä¸€æ¦‚å¿µçš„æ¥é¾™å»è„‰ã€‚éšåï¼Œæˆ‘ä»¬ä¼šå¿«é€Ÿå·©å›ºå¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒçŸ¥è¯†ï¼Œä¸ºä½ çš„å®è·µä¹‹æ—…æ‰“ä¸‹åšå®çš„ç†è®ºåœ°åŸºã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬äºŒéƒ¨åˆ†ï¼šæ„å»ºä½ çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“&lt;/strong&gt;ï¼ˆç¬¬å››ç« ï½ç¬¬ä¸ƒç« ï¼‰ï¼Œè¿™æ˜¯ä½ åŠ¨æ‰‹å®è·µçš„èµ·ç‚¹ã€‚ä½ å°†äº²æ‰‹å®ç° ReAct ç­‰ç»å…¸èŒƒå¼ï¼Œä½“éªŒ Coze ç­‰ä½ä»£ç å¹³å°çš„ä¾¿æ·ï¼Œå¹¶æŒæ¡ Langgraph ç­‰ä¸»æµæ¡†æ¶çš„åº”ç”¨ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬è¿˜ä¼šå¸¦ä½ ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå±äºè‡ªå·±çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œè®©ä½ å…¼å…·â€œç”¨è½®å­â€ä¸â€œé€ è½®å­â€çš„èƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬ä¸‰éƒ¨åˆ†ï¼šé«˜çº§çŸ¥è¯†æ‰©å±•&lt;/strong&gt;ï¼ˆç¬¬å…«ç« ï½ç¬¬åäºŒç« ï¼‰ï¼Œåœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œä½ çš„æ™ºèƒ½ä½“å°†â€œå­¦ä¼šâ€æ€è€ƒä¸åä½œã€‚æˆ‘ä»¬å°†ä½¿ç”¨ç¬¬äºŒéƒ¨åˆ†çš„è‡ªç ”æ¡†æ¶ï¼Œæ·±å…¥æ¢ç´¢è®°å¿†ä¸æ£€ç´¢ã€ä¸Šä¸‹æ–‡å·¥ç¨‹ã€Agent è®­ç»ƒç­‰æ ¸å¿ƒæŠ€æœ¯ï¼Œå¹¶å­¦ä¹ å¤šæ™ºèƒ½ä½“é—´çš„é€šä¿¡åè®®ã€‚æœ€ç»ˆï¼Œä½ å°†æŒæ¡è¯„ä¼°æ™ºèƒ½ä½“ç³»ç»Ÿæ€§èƒ½çš„ä¸“ä¸šæ–¹æ³•ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬å››éƒ¨åˆ†ï¼šç»¼åˆæ¡ˆä¾‹è¿›é˜¶&lt;/strong&gt;ï¼ˆç¬¬åä¸‰ç« ï½ç¬¬åäº”ç« ï¼‰ï¼Œè¿™é‡Œæ˜¯ç†è®ºä¸å®è·µçš„äº¤æ±‡ç‚¹ã€‚ä½ å°†æŠŠæ‰€å­¦èä¼šè´¯é€šï¼Œäº²æ‰‹æ‰“é€ æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€è‡ªåŠ¨åŒ–æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ï¼Œä¹ƒè‡³ä¸€ä¸ªæ¨¡æ‹Ÿç¤¾ä¼šåŠ¨æ€çš„èµ›åšå°é•‡ï¼Œåœ¨çœŸå®æœ‰è¶£çš„é¡¹ç›®ä¸­æ·¬ç‚¼ä½ çš„æ„å»ºèƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ç¬¬äº”éƒ¨åˆ†ï¼šæ¯•ä¸šè®¾è®¡åŠæœªæ¥å±•æœ›&lt;/strong&gt;ï¼ˆç¬¬åå…­ç« ï¼‰ï¼Œåœ¨æ—…ç¨‹çš„ç»ˆç‚¹ï¼Œä½ å°†è¿æ¥ä¸€ä¸ªæ¯•ä¸šè®¾è®¡ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„ã€å±äºä½ è‡ªå·±çš„å¤šæ™ºèƒ½ä½“åº”ç”¨ï¼Œå…¨é¢æ£€éªŒä½ çš„å­¦ä¹ æˆæœã€‚æˆ‘ä»¬è¿˜å°†ä¸ä½ ä¸€åŒå±•æœ›æ™ºèƒ½ä½“çš„æœªæ¥ï¼Œæ¢ç´¢æ¿€åŠ¨äººå¿ƒçš„å‰æ²¿æ–¹å‘ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;â€ƒâ€ƒæ™ºèƒ½ä½“æ˜¯ä¸€ä¸ªé£é€Ÿå‘å±•ä¸”æåº¦ä¾èµ–å®è·µçš„é¢†åŸŸã€‚ä¸ºäº†è·å¾—æœ€ä½³çš„å­¦ä¹ æ•ˆæœï¼Œæˆ‘ä»¬åœ¨é¡¹ç›®çš„&lt;code&gt;code&lt;/code&gt;æ–‡ä»¶å¤¹å†…æä¾›äº†é…å¥—çš„å…¨éƒ¨ä»£ç ï¼Œå¼ºçƒˆå»ºè®®ä½ &lt;strong&gt;å°†ç†è®ºä¸å®è·µç›¸ç»“åˆ&lt;/strong&gt;ã€‚è¯·åŠ¡å¿…äº²æ‰‹è¿è¡Œã€è°ƒè¯•ç”šè‡³ä¿®æ”¹é¡¹ç›®é‡Œæä¾›çš„æ¯ä¸€ä»½ä»£ç ã€‚æ¬¢è¿ä½ éšæ—¶å…³æ³¨ Datawhale ä»¥åŠå…¶ä»– Agent ç›¸å…³ç¤¾åŒºï¼Œå½“é‡åˆ°é—®é¢˜æ—¶ï¼Œä½ å¯ä»¥éšæ—¶åœ¨æœ¬é¡¹ç›®çš„ issue åŒºæé—®ã€‚&lt;/p&gt; 
&lt;p&gt;â€ƒâ€ƒç°åœ¨ï¼Œå‡†å¤‡å¥½è¿›å…¥æ™ºèƒ½ä½“çš„å¥‡å¦™ä¸–ç•Œäº†å—ï¼Ÿè®©æˆ‘ä»¬å³åˆ»å¯ç¨‹ï¼&lt;/p&gt; 
&lt;h2&gt;ä¸‹ä¸€æ­¥è§„åˆ’&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[]è‹±æ–‡ç‰ˆæ•™ç¨‹&lt;/li&gt; 
 &lt;li&gt;[]åŒè¯­è§†é¢‘è¯¾ç¨‹[è‹±æ–‡+ä¸­æ–‡]ï¼ˆå°†ä¼šæ›´åŠ ç»†è‡´ï¼Œå®è·µè¯¾å¸¦é¢†å¤§å®¶ä»è®¾è®¡æ€è·¯åˆ°å®æ–½ï¼Œæˆäººä»¥é±¼ä¹Ÿæˆäººä»¥æ¸”ï¼‰&lt;/li&gt; 
 &lt;li&gt;[]å…±åˆ›ç¬¬16ç« ï¼ˆæ‰“é€ å„ç±»Agentåº”ç”¨,æ›´æ‰“é€ Agentç”Ÿæ€ï¼‰&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤ å¦‚ä½•è´¡çŒ®&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ˜¯ä¸€ä¸ªå¼€æ”¾çš„å¼€æºç¤¾åŒºï¼Œæ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;æŠ¥å‘Š Bug&lt;/strong&gt; - å‘ç°å†…å®¹æˆ–ä»£ç é—®é¢˜ï¼Œè¯·æäº¤ Issue&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;strong&gt;æå‡ºå»ºè®®&lt;/strong&gt; - å¯¹é¡¹ç›®æœ‰å¥½æƒ³æ³•ï¼Œæ¬¢è¿å‘èµ·è®¨è®º&lt;/li&gt; 
 &lt;li&gt;ğŸ“ &lt;strong&gt;å®Œå–„å†…å®¹&lt;/strong&gt; - å¸®åŠ©æ”¹è¿›æ•™ç¨‹ï¼Œæäº¤ä½ çš„ Pull Request&lt;/li&gt; 
 &lt;li&gt;âœï¸ &lt;strong&gt;åˆ†äº«å®è·µ&lt;/strong&gt; - åœ¨"ç¤¾åŒºè´¡çŒ®ç²¾é€‰"ä¸­åˆ†äº«ä½ çš„å­¦ä¹ ç¬”è®°å’Œé¡¹ç›®&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™ è‡´è°¢&lt;/h2&gt; 
&lt;h3&gt;æ ¸å¿ƒè´¡çŒ®è€…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;é™ˆæ€å·-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt; (Datawhale æˆå‘˜, å…¨æ–‡å†™ä½œå’Œæ ¡å¯¹)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fengju0213"&gt;å­™éŸ¬-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt; (Datawhale æˆå‘˜, ç¬¬ä¹ç« å†…å®¹å’Œæ ¡å¯¹)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;å§œèˆ’å‡¡-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt;ï¼ˆDatawhale æˆå‘˜, ç« èŠ‚ä¹ é¢˜è®¾è®¡å’Œæ ¡å¯¹ï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HeteroCat"&gt;é»„ä½©æ—-Datawhaleæ„å‘æˆå‘˜&lt;/a&gt; (Agent å¼€å‘å·¥ç¨‹å¸ˆ, ç¬¬äº”ç« å†…å®¹è´¡çŒ®è€…)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;æ›¾é‘«æ°‘-Agentå·¥ç¨‹å¸ˆ&lt;/a&gt; (ç‰›å®¢ç§‘æŠ€, ç¬¬åå››ç« æ¡ˆä¾‹å¼€å‘)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xinzhongzhu.github.io/"&gt;æœ±ä¿¡å¿ -æŒ‡å¯¼ä¸“å®¶&lt;/a&gt; (Datawhaleé¦–å¸­ç§‘å­¦å®¶-æµ™æ±Ÿå¸ˆèŒƒå¤§å­¦æ­å·äººå·¥æ™ºèƒ½ç ”ç©¶é™¢æ•™æˆ)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extra-Chapter è´¡çŒ®è€…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/WHQAQ11"&gt;WH&lt;/a&gt; (å†…å®¹è´¡çŒ®è€…)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thunderbolt-fire"&gt;å‘¨å¥¥æ°-DWè´¡çŒ®è€…å›¢é˜Ÿ&lt;/a&gt; (è¥¿å®‰äº¤é€šå¤§å­¦, Extra02 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tasselszcx"&gt;å¼ å®¸æ—­-ä¸ªäººå¼€å‘è€…&lt;/a&gt;(å¸å›½ç†å·¥å­¦é™¢, Extra03 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiaoMa-PM"&gt;é»„å®æ™—-DWè´¡çŒ®è€…å›¢é˜Ÿ&lt;/a&gt; (æ·±åœ³å¤§å­¦, Extra04 å†…å®¹è´¡çŒ®)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ç‰¹åˆ«æ„Ÿè°¢&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;æ„Ÿè°¢ &lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt; å¯¹æœ¬é¡¹ç›®çš„å¸®åŠ©ä¸æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ä»¬ â¤ï¸&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/Hello-Agents/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/Hello-Agents" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/star-history-2025128.png" alt="Datawhale" width="90%" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;å…³äº Datawhale&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/hello-agents/main/docs/images/datawhale.png" alt="Datawhale" width="30%" /&gt; 
 &lt;p&gt;æ‰«æäºŒç»´ç å…³æ³¨ Datawhale å…¬ä¼—å·ï¼Œè·å–æ›´å¤šä¼˜è´¨å¼€æºå†…å®¹&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“œ å¼€æºåè®®&lt;/h2&gt; 
&lt;p&gt;æœ¬ä½œå“é‡‡ç”¨&lt;a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®&lt;/a&gt;è¿›è¡Œè®¸å¯ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>srbhr/Resume-Matcher</title>
      <link>https://github.com/srbhr/Resume-Matcher</link>
      <description>&lt;p&gt;Improve your resumes with Resume Matcher. Get insights, keyword suggestions and tune your resumes to job descriptions.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.resumematcher.fyi"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/page_2.png" alt="Resume Matcher" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Resume Matcher&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;ğ™¹ğš˜ğš’ğš— ğ™³ğš’ğšœğšŒğš˜ğš›ğš&lt;/a&gt; âœ¦ &lt;a href="https://resumematcher.fyi"&gt;ğš†ğšğš‹ğšœğš’ğšğš&lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#how-to-install"&gt;ğ™·ğš˜ğš  ğšğš˜ ğ™¸ğš—ğšœğšğšŠğš•ğš•&lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#contributors"&gt;ğ™²ğš˜ğš—ğšğš›ğš’ğš‹ğšğšğš˜ğš›ğšœ&lt;/a&gt; âœ¦ &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/#support-the-development-by-donating"&gt;ğ™³ğš˜ğš—ğšŠğšğš&lt;/a&gt; âœ¦ &lt;a href="https://twitter.com/ssrbhr"&gt;ğšƒğš ğš’ğšğšğšğš›/ğš‡&lt;/a&gt; âœ¦ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;ğ™»ğš’ğš—ğš”ğšğšğ™¸ğš—&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Stop getting auto-rejected by ATS bots.&lt;/strong&gt; Resume Matcher is the AI-powered platform that reverse-engineers hiring algorithms to show you exactly how to tailor your resume. Get the keywords, formatting, and insights that actually get you past the first screen and into human hands.&lt;/p&gt; 
 &lt;p&gt;Hoping to make this, &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Stars" /&gt; &lt;img src="https://img.shields.io/github/license/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Apache 2.0" /&gt; &lt;img src="https://img.shields.io/github/forks/srbhr/Resume-Matcher?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Forks" /&gt; &lt;img src="https://img.shields.io/badge/Version-0.1%20Veridis%20Quo-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="version" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://img.shields.io/discord/1122069176962531400?labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=c20a71&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://resumematcher.fyi"&gt;&lt;img src="https://img.shields.io/badge/website-Resume%20Matcher-FFF?labelColor=black&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-Resume%20Matcher-FFF?labelColor=black&amp;amp;logo=LinkedIn&amp;amp;style=for-the-badge&amp;amp;color=c20a71" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/565" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/565" alt="srbhr%2FResume-Matcher | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://vercel.com/oss/program-badge.svg?sanitize=true" alt="Vercel OSS Program" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;This project is in active development. New features are being added continuously, and we welcome contributions from the community. There are some breaking changes on the &lt;code&gt;main&lt;/code&gt; branch. If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started with Resume Matcher&lt;/h2&gt; 
&lt;p&gt;Resume Matcher is designed to help you optimize your resume with the aim to highlight your skills and experience in a way that resonates with potential employers.&lt;/p&gt; 
&lt;p&gt;We're actively working on improving the platform, building towards a &lt;strong&gt;VS Code for making resumes&lt;/strong&gt;, and adding new features. The best way to stay updated is to join the Discord discussion and be part of the active development community.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Join our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; community ğŸ‘‡ &lt;a href="https://dsc.gg/resume-matcher"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_discord.png" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Follow us on &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;LinkedIn&lt;/a&gt; âœ¨ &lt;a href="https://www.linkedin.com/company/resume-matcher/"&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_linkedin.png" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â­ Star Resume Matcher to support the development and get updates on GitHub. &lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/star_resume_matcher.png" alt="Star Resume Matcher" /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/resume_matcher_features.png" alt="resume_matcher_features" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Works locally&lt;/strong&gt;: No need to upload your resume to a server. Everything runs on your machine with open source AI models by Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ATS Compatibility&lt;/strong&gt;: Get a detailed analysis of your resume's compatibility with ATS systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Match Score&lt;/strong&gt;: Upload resume &amp;amp; job description for a quick match score and key improvement areas.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keyword Optimizer&lt;/strong&gt;: Align your resume with job keywords and identify critical content gaps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guided Improvements&lt;/strong&gt;: Get clear suggestions to make your resume stand out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Roadmap&lt;/h3&gt; 
&lt;p&gt;If you have any suggestions or feature requests, please feel free to open an issue on GitHub. And discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visual keyword highlighting.&lt;/li&gt; 
 &lt;li&gt;AI Canvas, which can help to craft impactful, metric-driven resume content.&lt;/li&gt; 
 &lt;li&gt;Multi-job description optimization.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_install_resumematcher.png" alt="Installation" /&gt;&lt;/p&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/SETUP.md"&gt;SETUP.md&lt;/a&gt; file to set up the project locally. The setup script will install all the necessary dependencies and configure your environment.&lt;/p&gt; 
&lt;p&gt;The project is built using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FastAPI for the backend.&lt;/li&gt; 
 &lt;li&gt;Next.js for the frontend.&lt;/li&gt; 
 &lt;li&gt;Ollama for local AI model serving.&lt;/li&gt; 
 &lt;li&gt;Tailwind CSS for styling.&lt;/li&gt; 
 &lt;li&gt;SQLite for the database.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Technology&lt;/th&gt; 
   &lt;th&gt;Info/Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;3.12+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Next.js&lt;/td&gt; 
   &lt;td&gt;15+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;0.6.7&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Join Us and Contribute&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/how_to_contribute.png" alt="how to contribute" /&gt;&lt;/p&gt; 
&lt;p&gt;We welcome contributions from everyone! Whether you're a developer, designer, or just someone who wants to help out. All the contributors are listed in the &lt;a href="https://resumematcher.fyi/about"&gt;about page&lt;/a&gt; on our website and on the GitHub Readme here.&lt;/p&gt; 
&lt;p&gt;Check out the roadmap if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub and discuss it on our &lt;a href="https://dsc.gg/resume-matcher"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/contributors.png" alt="Contributors" /&gt;&lt;/p&gt; 
&lt;a href="https://github.com/srbhr/Resume-Matcher/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=srbhr/Resume-Matcher" /&gt; &lt;/a&gt; 
&lt;h2&gt;Support the Development by Donating&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/srbhr/Resume-Matcher/main/assets/supporting_resume_matcher.png" alt="donate" /&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to support the development of Resume Matcher, you can do so by donating. Your contributions will help us keep the project alive and continue adding new features.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GitHub&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sponsors/srbhr"&gt;&lt;img src="https://img.shields.io/github/sponsors/srbhr?style=for-the-badge&amp;amp;color=c20a71&amp;amp;labelColor=black&amp;amp;logo=github" alt="GitHub Sponsors" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Buy Me a Coffee&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.buymeacoffee.com/srbhr"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-ffdd00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;color=c20a72&amp;amp;logoColor=white" alt="BuyMeACoffee" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date" /&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=srbhr/resume-matcher&amp;amp;theme=dark&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;h2&gt;Resume Matcher is a part of &lt;a href="https://vercel.com/oss"&gt;Vercel Open Source Program&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://vercel.com/oss/program-badge.svg?sanitize=true" alt="Vercel OSS Program" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/cutile-python</title>
      <link>https://github.com/NVIDIA/cutile-python</link>
      <description>&lt;p&gt;cuTile is a programming model for writing parallel kernels for NVIDIA GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;cuTile Python&lt;/h1&gt; 
&lt;p&gt;cuTile Python is a programming language for NVIDIA GPUs. The official documentation can be found on &lt;a href="https://docs.nvidia.com/cuda/cutile-python"&gt;docs.nvidia.com&lt;/a&gt;, or built from source located in the &lt;a href="https://raw.githubusercontent.com/NVIDIA/cutile-python/main/docs/"&gt;docs&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# This examples uses CuPy which can be installed via `pip install cupy-cuda13x`
# Make sure cuda toolkit 13.1+ is installed: https://developer.nvidia.com/cuda-downloads

import cuda.tile as ct
import cupy

TILE_SIZE = 16

# cuTile kernel for adding two dense vectors. It runs in parallel on the GPU.
@ct.kernel
def vector_add_kernel(a, b, result):
    block_id = ct.bid(0)
    a_tile = ct.load(a, index=(block_id,), shape=(TILE_SIZE,))
    b_tile = ct.load(b, index=(block_id,), shape=(TILE_SIZE,))
    result_tile = a_tile + b_tile
    ct.store(result, index=(block_id,), tile=result_tile)

# Host-side function that launches the above kernel.
def vector_add(a: cupy.ndarray, b: cupy.ndarray, result: cupy.ndarray):
    assert a.shape == b.shape == result.shape
    grid = (ct.cdiv(a.shape[0], TILE_SIZE), 1, 1)
    ct.launch(cupy.cuda.get_current_stream(), grid, vector_add_kernel, (a, b, result))


import numpy as np

def test_vector_add():
    a = cupy.random.uniform(-5, 5, 128)
    b = cupy.random.uniform(-5, 5, 128)
    result = cupy.zeros_like(a)

    vector_add(a, b, result)

    a_np = cupy.asnumpy(a)
    b_np = cupy.asnumpy(b)
    result_np = cupy.asnumpy(result)

    expected = a_np + b_np
    np.testing.assert_array_almost_equal(result_np, expected)

test_vector_add()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;p&gt;cuTile Python generates kernels based on &lt;a href="https://docs.nvidia.com/cuda/tile-ir/"&gt;Tile IR&lt;/a&gt; which requries NVIDIA Driver r580 or later to run. Furthermore, the &lt;code&gt;tileiras&lt;/code&gt; compiler only supports Blackwell GPU with 13.1 release, but the restriction will be removed in the coming versions. Checkout the &lt;a href="https://docs.nvidia.com/cuda/cutile-python/quickstart.html#prerequisites"&gt;prerequisites&lt;/a&gt; for full list of requirements.&lt;/p&gt; 
&lt;h2&gt;Installing from PyPI&lt;/h2&gt; 
&lt;p&gt;cuTile Python is published on &lt;a href="https://pypi.org/"&gt;PyPI&lt;/a&gt; under the &lt;a href="https://pypi.org/project/cuda-tile/"&gt;cuda-tile&lt;/a&gt; package name and can be installed with &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install cuda-tile
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Currently, the &lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;CUDA Toolkit 13.1+&lt;/a&gt; is required and needs to be installed separately. On a Debian-based system, use &lt;code&gt;apt-get install cuda-tileiras-13.1 cuda-compiler-13.1&lt;/code&gt; instead of &lt;code&gt;apt-get install cuda-toolkit-13.1&lt;/code&gt; if you wish to avoid installing the full CUDA Toolkit.&lt;/p&gt; 
&lt;h2&gt;Building from Source&lt;/h2&gt; 
&lt;p&gt;cuTile is written mostly in Python, but includes a C++ extension which needs to be built. You will need:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A C++17-capable compiler, such as GNU C++ or MSVC;&lt;/li&gt; 
 &lt;li&gt;CMake 3.18+;&lt;/li&gt; 
 &lt;li&gt;GNU Make on Linux or msbuild on Windows;&lt;/li&gt; 
 &lt;li&gt;Python 3.10+ with development headers (&lt;code&gt;venv&lt;/code&gt; module is recommended but optional);&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.nvidia.com/cuda-downloads"&gt;CUDA Toolkit 13.1+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;On an Ubuntu system, the first four dependencies can be installed with APT:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install build-essential cmake python3-dev python3-venv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The CMakeLists.txt script will also automatically download the &lt;a href="https://github.com/dmlc/dlpack"&gt;DLPack&lt;/a&gt; dependency from GitHub. If you wish to disable this behavior and provide your own copy of DLPack, set the &lt;code&gt;CUDA_TILE_CMAKE_DLPACK_PATH&lt;/code&gt; environment variable to a local path to the DLPack source tree.&lt;/p&gt; 
&lt;p&gt;Unless you are already using a Python virtual environment, it is recommended to create one in order to avoid installing cuTile globally:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 -m venv env
source env/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the build dependencies are in place, the simplest way to build cuTile is to install it in editable mode by running the following command in the source root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create the &lt;code&gt;build&lt;/code&gt; directory and invoke the CMake-based build process. In editable mode, the compiled extension module will be placed in the build directory, and then a symbolic link to it will be created in the source directory. This makes sure that the &lt;code&gt;pip install -e .&lt;/code&gt; command above is needed only once, and recompiling the extension after making changes to the C++ code can be done with &lt;code&gt;make -C build&lt;/code&gt; which is much faster. This logic is defined in &lt;a href="https://raw.githubusercontent.com/NVIDIA/cutile-python/main/setup.py"&gt;setup.py&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running Tests&lt;/h2&gt; 
&lt;p&gt;cuTile uses the &lt;a href="https://pytest.org"&gt;pytest&lt;/a&gt; framework for testing. Tests have extra dependencies, such as PyTorch, which can be installed with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -r test/requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The tests are located in the &lt;a href="https://raw.githubusercontent.com/NVIDIA/cutile-python/main/test/"&gt;test/&lt;/a&gt; directory. To run a specific test file, for example &lt;code&gt;test_copy.py&lt;/code&gt;, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pytest test/test_copy.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copyright and License Information&lt;/h2&gt; 
&lt;p&gt;Copyright Â© 2025 NVIDIA CORPORATION &amp;amp; AFFILIATES. All rights reserved.&lt;/p&gt; 
&lt;p&gt;cuTile-Python is licensed under the Apache 2.0 license. See the &lt;a href="https://raw.githubusercontent.com/NVIDIA/cutile-python/main/LICENSES/"&gt;LICENSES&lt;/a&gt; folder for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;å¾®èˆ†ï¼šäººäººå¯ç”¨çš„å¤šAgentèˆ†æƒ…åˆ†æåŠ©æ‰‹ï¼Œæ‰“ç ´ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ï¼ä»0å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•æ¡†æ¶ã€‚&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;â€‚ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;â€‚ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="50" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;ä¸­æ–‡æ–‡æ¡£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;âš¡ é¡¹ç›®æ¦‚è¿°&lt;/h2&gt; 
&lt;p&gt;â€œ&lt;strong&gt;å¾®èˆ†&lt;/strong&gt;â€ æ˜¯ä¸€ä¸ªä»0å®ç°çš„åˆ›æ–°å‹ å¤šæ™ºèƒ½ä½“ èˆ†æƒ…åˆ†æç³»ç»Ÿï¼Œå¸®åŠ©å¤§å®¶ç ´é™¤ä¿¡æ¯èŒ§æˆ¿ï¼Œè¿˜åŸèˆ†æƒ…åŸè²Œï¼Œé¢„æµ‹æœªæ¥èµ°å‘ï¼Œè¾…åŠ©å†³ç­–ã€‚ç”¨æˆ·åªéœ€åƒèŠå¤©ä¸€æ ·æå‡ºåˆ†æéœ€æ±‚ï¼Œæ™ºèƒ½ä½“å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ å›½å†…å¤–30+ä¸»æµç¤¾åª’ ä¸ æ•°ç™¾ä¸‡æ¡å¤§ä¼—è¯„è®ºã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;â€œå¾®èˆ†â€è°éŸ³â€œå¾®é±¼â€ï¼ŒBettaFishæ˜¯ä¸€ç§ä½“å‹å¾ˆå°ä½†éå¸¸å¥½æ–—ã€æ¼‚äº®çš„é±¼ï¼Œå®ƒè±¡å¾ç€â€œå°è€Œå¼ºå¤§ï¼Œä¸ç•æŒ‘æˆ˜â€&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œç”Ÿæˆçš„ç ”ç©¶æŠ¥å‘Šï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;æŸ¥çœ‹ç³»ç»Ÿä»¥â€œæ­¦æ±‰å¤§å­¦èˆ†æƒ…â€ä¸ºä¾‹ï¼Œä¸€æ¬¡å®Œæ•´è¿è¡Œçš„è§†é¢‘ï¼š&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;è§†é¢‘-æ­¦æ±‰å¤§å­¦å“ç‰Œå£°èª‰æ·±åº¦åˆ†ææŠ¥å‘Š&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ä¸ä»…ä»…ä½“ç°åœ¨æŠ¥å‘Šè´¨é‡ä¸Šï¼Œç›¸æ¯”åŒç±»äº§å“ï¼Œæˆ‘ä»¬æ‹¥æœ‰ğŸš€å…­å¤§ä¼˜åŠ¿ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIé©±åŠ¨çš„å…¨åŸŸç›‘æ§&lt;/strong&gt;ï¼šAIçˆ¬è™«é›†ç¾¤7x24å°æ—¶ä¸é—´æ–­ä½œä¸šï¼Œå…¨é¢è¦†ç›–å¾®åšã€å°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ç­‰10+å›½å†…å¤–å…³é”®ç¤¾åª’ã€‚ä¸ä»…å®æ—¶æ•è·çƒ­ç‚¹å†…å®¹ï¼Œæ›´èƒ½ä¸‹é’»è‡³æµ·é‡ç”¨æˆ·è¯„è®ºï¼Œè®©æ‚¨å¬åˆ°æœ€çœŸå®ã€æœ€å¹¿æ³›çš„å¤§ä¼—å£°éŸ³ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è¶…è¶ŠLLMçš„å¤åˆåˆ†æå¼•æ“&lt;/strong&gt;ï¼šæˆ‘ä»¬ä¸ä»…ä¾èµ–è®¾è®¡çš„5ç±»ä¸“ä¸šAgentï¼Œæ›´èåˆäº†å¾®è°ƒæ¨¡å‹ã€ç»Ÿè®¡æ¨¡å‹ç­‰ä¸­é—´ä»¶ã€‚é€šè¿‡å¤šæ¨¡å‹ååŒå·¥ä½œï¼Œç¡®ä¿äº†åˆ†æç»“æœçš„æ·±åº¦ã€å‡†åº¦ä¸å¤šç»´è§†è§’ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›&lt;/strong&gt;ï¼šçªç ´å›¾æ–‡é™åˆ¶ï¼Œèƒ½æ·±åº¦è§£ææŠ–éŸ³ã€å¿«æ‰‹ç­‰çŸ­è§†é¢‘å†…å®¹ï¼Œå¹¶ç²¾å‡†æå–ç°ä»£æœç´¢å¼•æ“ä¸­çš„å¤©æ°”ã€æ—¥å†ã€è‚¡ç¥¨ç­‰ç»“æ„åŒ–å¤šæ¨¡æ€ä¿¡æ¯å¡ç‰‡ï¼Œè®©æ‚¨å…¨é¢æŒæ¡èˆ†æƒ…åŠ¨æ€ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agentâ€œè®ºå›â€åä½œæœºåˆ¶&lt;/strong&gt;ï¼šä¸ºä¸åŒAgentèµ‹äºˆç‹¬ç‰¹çš„å·¥å…·é›†ä¸æ€ç»´æ¨¡å¼ï¼Œå¼•å…¥è¾©è®ºä¸»æŒäººæ¨¡å‹ï¼Œé€šè¿‡â€œè®ºå›â€æœºåˆ¶è¿›è¡Œé“¾å¼æ€ç»´ç¢°æ’ä¸è¾©è®ºã€‚è¿™ä¸ä»…é¿å…äº†å•ä¸€æ¨¡å‹çš„æ€ç»´å±€é™ä¸äº¤æµå¯¼è‡´çš„åŒè´¨åŒ–ï¼Œæ›´å‚¬ç”Ÿå‡ºæ›´é«˜è´¨é‡çš„é›†ä½“æ™ºèƒ½ä¸å†³ç­–æ”¯æŒã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;å…¬ç§åŸŸæ•°æ®æ— ç¼èåˆ&lt;/strong&gt;ï¼šå¹³å°ä¸ä»…åˆ†æå…¬å¼€èˆ†æƒ…ï¼Œè¿˜æä¾›é«˜å®‰å…¨æ€§çš„æ¥å£ï¼Œæ”¯æŒæ‚¨å°†å†…éƒ¨ä¸šåŠ¡æ•°æ®åº“ä¸èˆ†æƒ…æ•°æ®æ— ç¼é›†æˆã€‚æ‰“é€šæ•°æ®å£å’ï¼Œä¸ºå‚ç›´ä¸šåŠ¡æä¾›â€œå¤–éƒ¨è¶‹åŠ¿+å†…éƒ¨æ´å¯Ÿâ€çš„å¼ºå¤§åˆ†æèƒ½åŠ›ã€‚&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è½»é‡åŒ–ä¸é«˜æ‰©å±•æ€§æ¡†æ¶&lt;/strong&gt;ï¼šåŸºäºçº¯Pythonæ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°è½»é‡åŒ–ã€ä¸€é”®å¼éƒ¨ç½²ã€‚ä»£ç ç»“æ„æ¸…æ™°ï¼Œå¼€å‘è€…å¯è½»æ¾é›†æˆè‡ªå®šä¹‰æ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘ï¼Œå®ç°å¹³å°çš„å¿«é€Ÿæ‰©å±•ä¸æ·±åº¦å®šåˆ¶ã€‚&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;å§‹äºèˆ†æƒ…ï¼Œè€Œä¸æ­¢äºèˆ†æƒ…&lt;/strong&gt;ã€‚â€œå¾®èˆ†â€çš„ç›®æ ‡ï¼Œæ˜¯æˆä¸ºé©±åŠ¨ä¸€åˆ‡ä¸šåŠ¡åœºæ™¯çš„ç®€æ´é€šç”¨çš„æ•°æ®åˆ†æå¼•æ“ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä¸¾ä¸ªä¾‹å­. ä½ åªéœ€ç®€å•ä¿®æ”¹Agentå·¥å…·é›†çš„apiå‚æ•°ä¸promptï¼Œå°±å¯ä»¥æŠŠä»–å˜æˆä¸€ä¸ªé‡‘èé¢†åŸŸçš„å¸‚åœºåˆ†æç³»ç»Ÿ&lt;/p&gt; 
 &lt;p&gt;é™„ä¸€ä¸ªæ¯”è¾ƒæ´»è·ƒçš„Lç«™é¡¹ç›®è®¨è®ºå¸–ï¼š&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;æŸ¥çœ‹Lç«™ä½¬å‹åšçš„æµ‹è¯„ &lt;a href="https://linux.do/t/topic/1148040"&gt;å¼€æºé¡¹ç›®(å¾®èˆ†)ä¸manus|minimax|ChatGPTå¯¹æ¯”&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;å‘Šåˆ«ä¼ ç»Ÿçš„æ•°æ®çœ‹æ¿ï¼Œåœ¨â€œå¾®èˆ†â€ï¼Œä¸€åˆ‡ç”±ä¸€ä¸ªç®€å•çš„é—®é¢˜å¼€å§‹ï¼Œæ‚¨åªéœ€åƒå¯¹è¯ä¸€æ ·ï¼Œæå‡ºæ‚¨çš„åˆ†æéœ€æ±‚&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸª„ èµåŠ©å•†&lt;/h2&gt; 
&lt;p&gt;LLMæ¨¡å‹APIèµåŠ©ï¼š&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;æœ‰èµåŠ©LLMç®—åŠ›ç¦åˆ©ï¼ç¼–ç¨‹æ‹¼è½¦codecodex.aiï¼›ç¼–ç¨‹ç®—åŠ›VibeCodingAPI.aiï¼š&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;æ‰€ç½—é—¨åšå®¢LionCC.aiå·²æ›´æ–°ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿ - LionCC API éƒ¨ç½²é…ç½®å®Œå…¨æŒ‡å—ã€‹æ­£åœ¨äºŒå¼€ä¼˜åŒ–ä¸€é”®éƒ¨ç½²å’Œäº‘æœåŠ¡å™¨è°ƒç”¨æ–¹æ¡ˆã€‚&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiç‹®å­ç®—åŠ›å¹³å°å·²ç»é€‚é…ã€ŠBettaFish å¾®èˆ†ç³»ç»Ÿã€‹æ‰€æœ‰LLMæ¨¡å‹å«claude codeå’Œopenai codexå’Œgemini cliç¼–ç¨‹å¼€å‘ä¸‰å·¨å¤´ç®—åŠ›ã€‚é¢åº¦ä»·æ ¼ï¼Œåªè¦ä¸€æ¯”ä¸€ï¼ˆ100å…ƒç­‰äº100ç¾åˆ€é¢åº¦ï¼‰&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiç‹®å­ç¼–ç¨‹æ‹¼è½¦ç³»ç»Ÿï¼Œå·²å®ç°æ— IPé—¨æ§›ç»•è¿‡claude codeå’Œopenai codexå°é”ï¼ŒæŒ‰å®˜æ–¹éƒ¨ç½²æ•™ç¨‹ååˆ‡æ¢BASE_URLè°ƒç”¨åœ°å€å’ŒToken keyè°ƒç”¨å¯†é’¥å³å¯ä½¿ç”¨æœ€å¼ºç¼–ç¨‹æ¨¡å‹ã€‚&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;æ‰€ç½—é—¨LionCCèµåŠ©BettaFish å¾®èˆ†ç¦åˆ©ï¼šæ‰“å¼€codecodex.aiç‹®å­ç¼–ç¨‹é¢‘é“æ‰«ç åŠ å…¥å¾®ä¿¡ç¤¾ç¾¤ï¼Œæ³¨å†ŒVibeCodingapi.aiç‹®å­ç®—åŠ›ï¼Œç»Ÿä¸€é€20åˆ€APIé¢åº¦ï¼ˆä»…é™å‰ä¸€åƒåï¼‰&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;æŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šå…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§åœ¨çº¿AIåº”ç”¨ï¼š&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIæ˜¯ä¸€ä¸ªæŒ‰ç”¨é‡ä»˜è´¹çš„ä¼ä¸šçº§AIèµ„æºå¹³å°ï¼Œæä¾›å¸‚åœºä¸Šæœ€æ–°ã€æœ€å…¨é¢çš„AIæ¨¡å‹å’ŒAPIï¼Œä»¥åŠå¤šç§å¼€ç®±å³ç”¨çš„åœ¨çº¿AIåº”ç”¨ã€‚ 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;AIè”ç½‘æœç´¢ã€æ–‡ä»¶è§£æåŠç½‘é¡µå†…å®¹æŠ“å–ç­‰æ™ºèƒ½ä½“æ ¸å¿ƒèƒ½åŠ›æä¾›å•†ï¼š&lt;span style="margin-left: 10px"&gt;&lt;a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="50" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; å®‰æ€æ´¾å¼€æ”¾å¹³å°(Anspire Open)æ˜¯é¢å‘æ™ºèƒ½ä½“æ—¶ä»£çš„é¢†å…ˆçš„åŸºç¡€è®¾æ–½æä¾›å•†ã€‚æˆ‘ä»¬ä¸ºå¼€å‘è€…æä¾›æ„å»ºå¼ºå¤§æ™ºèƒ½ä½“æ‰€éœ€çš„æ ¸å¿ƒèƒ½åŠ›æ ˆï¼Œç°å·²ä¸Šçº¿AIè”ç½‘æœç´¢ã€å¤šç‰ˆæœ¬ï¼Œæå…·ç«äº‰åŠ›çš„ä»·æ ¼ã€‘ã€æ–‡ä»¶è§£æã€é™å…ã€‘åŠç½‘é¡µå†…å®¹æŠ“å–ã€é™å…ã€‘ã€äº‘ç«¯æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆAnspire Browser Agentï¼‰ã€å†…æµ‹ã€‘ã€å¤šè½®æ”¹å†™ç­‰æœåŠ¡ï¼ŒæŒç»­ä¸ºæ™ºèƒ½ä½“è¿æ¥å¹¶æ“ä½œå¤æ‚çš„æ•°å­—ä¸–ç•Œæä¾›åšå®åŸºç¡€ã€‚å¯æ— ç¼é›†æˆè‡³Difyã€Cozeã€å…ƒå™¨ç­‰ä¸»æµæ™ºèƒ½ä½“å¹³å°ã€‚é€šè¿‡é€æ˜ç‚¹æ•°è®¡è´¹ä½“ç³»ä¸æ¨¡å—åŒ–è®¾è®¡ï¼Œä¸ºä¼ä¸šæä¾›é«˜æ•ˆã€ä½æˆæœ¬çš„å®šåˆ¶åŒ–æ”¯æŒï¼ŒåŠ é€Ÿæ™ºèƒ½åŒ–å‡çº§è¿›ç¨‹ã€‚ 
&lt;/details&gt; 
&lt;h2&gt;ğŸ—ï¸ ç³»ç»Ÿæ¶æ„&lt;/h2&gt; 
&lt;h3&gt;æ•´ä½“æ¶æ„å›¾&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ç§æœ‰æ•°æ®åº“æŒ–æ˜ï¼šç§æœ‰èˆ†æƒ…æ•°æ®åº“æ·±åº¦åˆ†æAIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; å¤šæ¨¡æ€å†…å®¹åˆ†æï¼šå…·å¤‡å¼ºå¤§å¤šæ¨¡æ€èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; ç²¾å‡†ä¿¡æ¯æœç´¢ï¼šå…·å¤‡å›½å†…å¤–ç½‘é¡µæœç´¢èƒ½åŠ›çš„AIä»£ç†&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆï¼šå†…ç½®æ¨¡æ¿çš„å¤šè½®æŠ¥å‘Šç”ŸæˆAIä»£ç†&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ä¸€æ¬¡å®Œæ•´åˆ†ææµç¨‹&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;æ­¥éª¤&lt;/th&gt; 
   &lt;th&gt;é˜¶æ®µåç§°&lt;/th&gt; 
   &lt;th&gt;ä¸»è¦æ“ä½œ&lt;/th&gt; 
   &lt;th&gt;å‚ä¸ç»„ä»¶&lt;/th&gt; 
   &lt;th&gt;å¾ªç¯ç‰¹æ€§&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;ç”¨æˆ·æé—®&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨æ¥æ”¶æŸ¥è¯¢&lt;/td&gt; 
   &lt;td&gt;Flaskä¸»åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;å¹¶è¡Œå¯åŠ¨&lt;/td&gt; 
   &lt;td&gt;ä¸‰ä¸ªAgentåŒæ—¶å¼€å§‹å·¥ä½œ&lt;/td&gt; 
   &lt;td&gt;Query Agentã€Media Agentã€Insight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;åˆæ­¥åˆ†æ&lt;/td&gt; 
   &lt;td&gt;å„Agentä½¿ç”¨ä¸“å±å·¥å…·è¿›è¡Œæ¦‚è§ˆæœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + ä¸“å±å·¥å…·é›†&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;ç­–ç•¥åˆ¶å®š&lt;/td&gt; 
   &lt;td&gt;åŸºäºåˆæ­¥ç»“æœåˆ¶å®šåˆ†å—ç ”ç©¶ç­–ç•¥&lt;/td&gt; 
   &lt;td&gt;å„Agentå†…éƒ¨å†³ç­–æ¨¡å—&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¾ªç¯é˜¶æ®µ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;è®ºå›åä½œ + æ·±åº¦ç ”ç©¶&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + æ‰€æœ‰Agent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;å¤šè½®å¾ªç¯&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;æ·±åº¦ç ”ç©¶&lt;/td&gt; 
   &lt;td&gt;å„AgentåŸºäºè®ºå›ä¸»æŒäººå¼•å¯¼è¿›è¡Œä¸“é¡¹æœç´¢&lt;/td&gt; 
   &lt;td&gt;å„Agent + åæ€æœºåˆ¶ + è®ºå›å¼•å¯¼&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;è®ºå›åä½œ&lt;/td&gt; 
   &lt;td&gt;ForumEngineç›‘æ§Agentå‘è¨€å¹¶ç”Ÿæˆä¸»æŒäººå¼•å¯¼&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLMä¸»æŒäºº&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;äº¤æµèåˆ&lt;/td&gt; 
   &lt;td&gt;å„Agentæ ¹æ®è®¨è®ºè°ƒæ•´ç ”ç©¶æ–¹å‘&lt;/td&gt; 
   &lt;td&gt;å„Agent + forum_readerå·¥å…·&lt;/td&gt; 
   &lt;td&gt;æ¯è½®å¾ªç¯&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ç»“æœæ•´åˆ&lt;/td&gt; 
   &lt;td&gt;Report Agentæ”¶é›†æ‰€æœ‰åˆ†æç»“æœå’Œè®ºå›å†…å®¹&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;IRä¸­é—´è¡¨ç¤º&lt;/td&gt; 
   &lt;td&gt;åŠ¨æ€é€‰æ‹©æ¨¡æ¿å’Œæ ·å¼ï¼Œå¤šè½®ç”Ÿæˆå…ƒæ•°æ®ï¼Œè£…è®¢ä¸ºIRä¸­é—´è¡¨ç¤º&lt;/td&gt; 
   &lt;td&gt;Report Agent + æ¨¡æ¿å¼•æ“&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+3&lt;/td&gt; 
   &lt;td&gt;æŠ¥å‘Šç”Ÿæˆ&lt;/td&gt; 
   &lt;td&gt;åˆ†å—è¿›è¡Œè´¨é‡æ£€æµ‹ï¼ŒåŸºäºIRæ¸²æŸ“æˆäº¤äº’å¼ HTML æŠ¥å‘Š&lt;/td&gt; 
   &lt;td&gt;Report Agent + è£…è®¢å¼•æ“&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;é¡¹ç›®ä»£ç ç»“æ„æ ‘&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
â”œâ”€â”€ QueryEngine/                            # å›½å†…å¤–æ–°é—»å¹¿åº¦æœç´¢Agent
â”‚   â”œâ”€â”€ agent.py                            # Agentä¸»é€»è¾‘ï¼Œåè°ƒæœç´¢ä¸åˆ†ææµç¨‹
â”‚   â”œâ”€â”€ llms/                               # LLMæ¥å£å°è£…
â”‚   â”œâ”€â”€ nodes/                              # å¤„ç†èŠ‚ç‚¹ï¼šæœç´¢ã€æ ¼å¼åŒ–ã€æ€»ç»“ç­‰
â”‚   â”œâ”€â”€ tools/                              # å›½å†…å¤–æ–°é—»æœç´¢å·¥å…·é›†
â”‚   â”œâ”€â”€ utils/                              # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ state/                              # çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ prompts/                            # æç¤ºè¯æ¨¡æ¿
â”‚   â””â”€â”€ ...
â”œâ”€â”€ MediaEngine/                            # å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£Agent
â”‚   â”œâ”€â”€ agent.py                            # Agentä¸»é€»è¾‘ï¼Œå¤„ç†è§†é¢‘/å›¾ç‰‡ç­‰å¤šæ¨¡æ€å†…å®¹
â”‚   â”œâ”€â”€ llms/                               # LLMæ¥å£å°è£…
â”‚   â”œâ”€â”€ nodes/                              # å¤„ç†èŠ‚ç‚¹ï¼šæœç´¢ã€æ ¼å¼åŒ–ã€æ€»ç»“ç­‰
â”‚   â”œâ”€â”€ tools/                              # å¤šæ¨¡æ€æœç´¢å·¥å…·é›†
â”‚   â”œâ”€â”€ utils/                              # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ state/                              # çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ prompts/                            # æç¤ºè¯æ¨¡æ¿
â”‚   â””â”€â”€ ...
â”œâ”€â”€ InsightEngine/                          # ç§æœ‰æ•°æ®åº“æŒ–æ˜Agent
â”‚   â”œâ”€â”€ agent.py                            # Agentä¸»é€»è¾‘ï¼Œåè°ƒæ•°æ®åº“æŸ¥è¯¢ä¸åˆ†æ
â”‚   â”œâ”€â”€ llms/                               # LLMæ¥å£å°è£…
â”‚   â”‚   â””â”€â”€ base.py                         # ç»Ÿä¸€çš„OpenAIå…¼å®¹å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ nodes/                              # å¤„ç†èŠ‚ç‚¹ï¼šæœç´¢ã€æ ¼å¼åŒ–ã€æ€»ç»“ç­‰
â”‚   â”‚   â”œâ”€â”€ base_node.py                    # åŸºç¡€èŠ‚ç‚¹ç±»
â”‚   â”‚   â”œâ”€â”€ search_node.py                  # æœç´¢èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ formatting_node.py              # æ ¼å¼åŒ–èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ report_structure_node.py        # æŠ¥å‘Šç»“æ„èŠ‚ç‚¹
â”‚   â”‚   â””â”€â”€ summary_node.py                 # æ€»ç»“èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tools/                              # æ•°æ®åº“æŸ¥è¯¢å’Œåˆ†æå·¥å…·é›†
â”‚   â”‚   â”œâ”€â”€ keyword_optimizer.py            # Qwenå…³é”®è¯ä¼˜åŒ–ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ search.py                       # æ•°æ®åº“æ“ä½œå·¥å…·é›†ï¼ˆè¯é¢˜æœç´¢ã€è¯„è®ºè·å–ç­‰ï¼‰
â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py           # æƒ…æ„Ÿåˆ†æé›†æˆå·¥å…·
â”‚   â”œâ”€â”€ utils/                              # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ config.py                       # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ db.py                           # SQLAlchemyå¼‚æ­¥å¼•æ“ä¸åªè¯»æŸ¥è¯¢å°è£…
â”‚   â”‚   â””â”€â”€ text_processing.py              # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ state/                              # çŠ¶æ€ç®¡ç†
â”‚   â”‚   â””â”€â”€ state.py                        # AgentçŠ¶æ€å®šä¹‰
â”‚   â”œâ”€â”€ prompts/                            # æç¤ºè¯æ¨¡æ¿
â”‚   â”‚   â””â”€â”€ prompts.py                      # å„ç±»æç¤ºè¯
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ReportEngine/                           # å¤šè½®æŠ¥å‘Šç”ŸæˆAgent
â”‚   â”œâ”€â”€ agent.py                            # æ€»è°ƒåº¦å™¨ï¼šæ¨¡æ¿é€‰æ‹©â†’å¸ƒå±€â†’ç¯‡å¹…â†’ç« èŠ‚â†’æ¸²æŸ“
â”‚   â”œâ”€â”€ flask_interface.py                  # Flask/SSEå…¥å£ï¼Œç®¡ç†ä»»åŠ¡æ’é˜Ÿä¸æµå¼äº‹ä»¶
â”‚   â”œâ”€â”€ llms/                               # OpenAIå…¼å®¹LLMå°è£…
â”‚   â”‚   â””â”€â”€ base.py                         # ç»Ÿä¸€çš„æµå¼/é‡è¯•å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ core/                               # æ ¸å¿ƒåŠŸèƒ½ï¼šæ¨¡æ¿è§£æã€ç« èŠ‚å­˜å‚¨ã€æ–‡æ¡£è£…è®¢
â”‚   â”‚   â”œâ”€â”€ template_parser.py              # Markdownæ¨¡æ¿åˆ‡ç‰‡ä¸slugç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ chapter_storage.py              # ç« èŠ‚runç›®å½•ã€manifestä¸rawæµå†™å…¥
â”‚   â”‚   â””â”€â”€ stitcher.py                     # Document IRè£…è®¢å™¨ï¼Œè¡¥é½é”šç‚¹/å…ƒæ•°æ®
â”‚   â”œâ”€â”€ ir/                                 # æŠ¥å‘Šä¸­é—´è¡¨ç¤ºï¼ˆIRï¼‰å¥‘çº¦ä¸æ ¡éªŒ
â”‚   â”‚   â”œâ”€â”€ schema.py                       # å—/æ ‡è®°Schemaå¸¸é‡å®šä¹‰
â”‚   â”‚   â””â”€â”€ validator.py                    # ç« èŠ‚JSONç»“æ„æ ¡éªŒå™¨
â”‚   â”œâ”€â”€ nodes/                              # å…¨æµç¨‹æ¨ç†èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ base_node.py                    # èŠ‚ç‚¹åŸºç±»+æ—¥å¿—/çŠ¶æ€é’©å­
â”‚   â”‚   â”œâ”€â”€ template_selection_node.py      # æ¨¡æ¿å€™é€‰æ”¶é›†ä¸LLMç­›é€‰
â”‚   â”‚   â”œâ”€â”€ document_layout_node.py         # æ ‡é¢˜/ç›®å½•/ä¸»é¢˜è®¾è®¡
â”‚   â”‚   â”œâ”€â”€ word_budget_node.py             # ç¯‡å¹…è§„åˆ’ä¸ç« èŠ‚æŒ‡ä»¤ç”Ÿæˆ
â”‚   â”‚   â””â”€â”€ chapter_generation_node.py      # ç« èŠ‚çº§JSONç”Ÿæˆ+æ ¡éªŒ
â”‚   â”œâ”€â”€ prompts/                            # æç¤ºè¯åº“ä¸Schemaè¯´æ˜
â”‚   â”‚   â””â”€â”€ prompts.py                      # æ¨¡æ¿é€‰æ‹©/å¸ƒå±€/ç¯‡å¹…/ç« èŠ‚æç¤ºè¯
â”‚   â”œâ”€â”€ renderers/                          # IRæ¸²æŸ“å™¨
â”‚   â”‚   â”œâ”€â”€ html_renderer.py                # Document IRâ†’äº¤äº’å¼HTML
â”‚   â”‚   â”œâ”€â”€ pdf_renderer.py                 # HTMLâ†’PDFå¯¼å‡ºï¼ˆWeasyPrintï¼‰
â”‚   â”‚   â”œâ”€â”€ pdf_layout_optimizer.py         # PDFå¸ƒå±€ä¼˜åŒ–å™¨
â”‚   â”‚   â””â”€â”€ chart_to_svg.py                 # å›¾è¡¨è½¬SVGå·¥å…·
â”‚   â”œâ”€â”€ state/                              # ä»»åŠ¡/å…ƒæ•°æ®çŠ¶æ€æ¨¡å‹
â”‚   â”‚   â””â”€â”€ state.py                        # ReportStateä¸åºåˆ—åŒ–å·¥å…·
â”‚   â”œâ”€â”€ utils/                              # é…ç½®ä¸è¾…åŠ©å·¥å…·
â”‚   â”‚   â”œâ”€â”€ config.py                       # Pydantic Settingsä¸æ‰“å°åŠ©æ‰‹
â”‚   â”‚   â”œâ”€â”€ dependency_check.py             # ä¾èµ–æ£€æŸ¥å·¥å…·
â”‚   â”‚   â”œâ”€â”€ json_parser.py                  # JSONè§£æå·¥å…·
â”‚   â”‚   â”œâ”€â”€ chart_validator.py              # å›¾è¡¨æ ¡éªŒå·¥å…·
â”‚   â”‚   â””â”€â”€ chart_repair_api.py             # å›¾è¡¨ä¿®å¤API
â”‚   â”œâ”€â”€ report_template/                    # Markdownæ¨¡æ¿åº“
â”‚   â”‚   â”œâ”€â”€ ä¼ä¸šå“ç‰Œå£°èª‰åˆ†ææŠ¥å‘Š.md
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ForumEngine/                            # è®ºå›å¼•æ“ï¼šAgentåä½œæœºåˆ¶
â”‚   â”œâ”€â”€ monitor.py                          # æ—¥å¿—ç›‘æ§å’Œè®ºå›ç®¡ç†æ ¸å¿ƒ
â”‚   â”œâ”€â”€ llm_host.py                         # è®ºå›ä¸»æŒäººLLMæ¨¡å—
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ MindSpider/                             # ç¤¾äº¤åª’ä½“çˆ¬è™«ç³»ç»Ÿ
â”‚   â”œâ”€â”€ main.py                             # çˆ¬è™«ä¸»ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ config.py                           # çˆ¬è™«é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ BroadTopicExtraction/               # è¯é¢˜æå–æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ main.py                         # è¯é¢˜æå–ä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ database_manager.py             # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ get_today_news.py               # ä»Šæ—¥æ–°é—»è·å–
â”‚   â”‚   â””â”€â”€ topic_extractor.py              # è¯é¢˜æå–å™¨
â”‚   â”œâ”€â”€ DeepSentimentCrawling/              # æ·±åº¦èˆ†æƒ…çˆ¬å–æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ main.py                         # æ·±åº¦çˆ¬å–ä¸»ç¨‹åº
â”‚   â”‚   â”œâ”€â”€ keyword_manager.py              # å…³é”®è¯ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ platform_crawler.py             # å¹³å°çˆ¬è™«ç®¡ç†
â”‚   â”‚   â””â”€â”€ MediaCrawler/                   # ç¤¾åª’çˆ¬è™«æ ¸å¿ƒ
â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚       â”œâ”€â”€ config/                     # å„å¹³å°é…ç½®
â”‚   â”‚       â”œâ”€â”€ media_platform/             # å„å¹³å°çˆ¬è™«å®ç°
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ schema/                             # æ•°æ®åº“ç»“æ„å®šä¹‰
â”‚       â”œâ”€â”€ db_manager.py                   # æ•°æ®åº“ç®¡ç†å™¨
â”‚       â”œâ”€â”€ init_database.py                # æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
â”‚       â”œâ”€â”€ mindspider_tables.sql           # æ•°æ®åº“è¡¨ç»“æ„SQL
â”‚       â”œâ”€â”€ models_bigdata.py               # å¤§è§„æ¨¡åª’ä½“èˆ†æƒ…è¡¨çš„SQLAlchemyæ˜ å°„
â”‚       â””â”€â”€ models_sa.py                    # DailyTopic/Taskç­‰æ‰©å±•è¡¨ORMæ¨¡å‹
â”œâ”€â”€ SentimentAnalysisModel/                 # æƒ…æ„Ÿåˆ†ææ¨¡å‹é›†åˆ
â”‚   â”œâ”€â”€ WeiboSentiment_Finetuned/           # å¾®è°ƒBERT/GPT-2æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ BertChinese-Lora/               # BERTä¸­æ–‡LoRAå¾®è°ƒ
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ GPT2-Lora/                      # GPT-2 LoRAå¾®è°ƒ
â”‚   â”‚       â”œâ”€â”€ train.py
â”‚   â”‚       â”œâ”€â”€ predict.py
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ WeiboMultilingualSentiment/         # å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ WeiboSentiment_SmallQwen/           # å°å‚æ•°Qwen3å¾®è°ƒ
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ predict_universal.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ WeiboSentiment_MachineLearning/     # ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•
â”‚       â”œâ”€â”€ train.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ SingleEngineApp/                        # å•ç‹¬Agentçš„Streamlitåº”ç”¨
â”‚   â”œâ”€â”€ query_engine_streamlit_app.py       # QueryEngineç‹¬ç«‹åº”ç”¨
â”‚   â”œâ”€â”€ media_engine_streamlit_app.py       # MediaEngineç‹¬ç«‹åº”ç”¨
â”‚   â””â”€â”€ insight_engine_streamlit_app.py     # InsightEngineç‹¬ç«‹åº”ç”¨
â”œâ”€â”€ query_engine_streamlit_reports/         # QueryEngineå•åº”ç”¨è¿è¡Œè¾“å‡º
â”œâ”€â”€ media_engine_streamlit_reports/         # MediaEngineå•åº”ç”¨è¿è¡Œè¾“å‡º
â”œâ”€â”€ insight_engine_streamlit_reports/       # InsightEngineå•åº”ç”¨è¿è¡Œè¾“å‡º
â”œâ”€â”€ templates/                              # Flaskå‰ç«¯æ¨¡æ¿
â”‚   â””â”€â”€ index.html                          # ä¸»ç•Œé¢HTML
â”œâ”€â”€ static/                                 # é™æ€èµ„æº
â”‚   â””â”€â”€ image/                              # å›¾ç‰‡èµ„æº
â”‚       â”œâ”€â”€ logo_compressed.png
â”‚       â”œâ”€â”€ framework.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ logs/                                   # è¿è¡Œæ—¥å¿—ç›®å½•
â”œâ”€â”€ final_reports/                          # æœ€ç»ˆç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶
â”‚   â”œâ”€â”€ ir/                                 # æŠ¥å‘ŠIR JSONæ–‡ä»¶
â”‚   â””â”€â”€ *.html                              # æœ€ç»ˆHTMLæŠ¥å‘Š
â”œâ”€â”€ utils/                                  # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ forum_reader.py                     # Agenté—´è®ºå›é€šä¿¡å·¥å…·
â”‚   â”œâ”€â”€ github_issues.py                    # ç»Ÿä¸€ç”ŸæˆGitHub Issueé“¾æ¥ä¸é”™è¯¯æç¤º
â”‚   â””â”€â”€ retry_helper.py                     # ç½‘ç»œè¯·æ±‚é‡è¯•æœºåˆ¶å·¥å…·
â”œâ”€â”€ tests/                                  # å•å…ƒæµ‹è¯•ä¸é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ run_tests.py                        # pytestå…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ test_monitor.py                     # ForumEngineç›‘æ§å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_report_engine_sanitization.py  # ReportEngineå®‰å…¨æ€§æµ‹è¯•
â”‚   â””â”€â”€ ...
â”œâ”€â”€ app.py                                  # Flaskä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ config.py                               # å…¨å±€é…ç½®æ–‡ä»¶
â”œâ”€â”€ .env.example                            # ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶
â”œâ”€â”€ docker-compose.yml                      # Dockerå¤šæœåŠ¡ç¼–æ’é…ç½®
â”œâ”€â”€ Dockerfile                              # Dockeré•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ requirements.txt                        # Pythonä¾èµ–åŒ…æ¸…å•
â”œâ”€â”€ regenerate_latest_pdf.py                # PDFé‡æ–°ç”Ÿæˆå·¥å…·è„šæœ¬
â”œâ”€â”€ report_engine_only.py                   # Report Engineå‘½ä»¤è¡Œç‰ˆæœ¬
â”œâ”€â”€ README.md                               # ä¸­æ–‡è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ README-EN.md                            # è‹±æ–‡è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ CONTRIBUTING.md                         # ä¸­æ–‡è´¡çŒ®æŒ‡å—
â”œâ”€â”€ CONTRIBUTING-EN.md                      # è‹±æ–‡è´¡çŒ®æŒ‡å—
â””â”€â”€ LICENSE                                 # GPL-2.0å¼€æºè®¸å¯è¯
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆDockerï¼‰&lt;/h2&gt; 
&lt;h3&gt;1. å¯åŠ¨é¡¹ç›®&lt;/h3&gt; 
&lt;p&gt;å¤åˆ¶ä¸€ä»½ &lt;code&gt;.env.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;.env&lt;/code&gt; ï¼Œå¹¶æŒ‰éœ€é…ç½® &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡&lt;/p&gt; 
&lt;p&gt;æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åœ¨åå°å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;æ³¨ï¼šé•œåƒæ‹‰å–é€Ÿåº¦æ…¢&lt;/strong&gt;ï¼Œåœ¨åŸ &lt;code&gt;docker-compose.yml&lt;/code&gt; æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬å·²ç»é€šè¿‡&lt;strong&gt;æ³¨é‡Š&lt;/strong&gt;çš„æ–¹å¼æä¾›äº†å¤‡ç”¨é•œåƒåœ°å€ä¾›æ‚¨æ›¿æ¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. é…ç½®è¯´æ˜&lt;/h3&gt; 
&lt;h4&gt;æ•°æ®åº“é…ç½®ï¼ˆPostgreSQLï¼‰&lt;/h4&gt; 
&lt;p&gt;è¯·æŒ‰ç…§ä»¥ä¸‹å‚æ•°é…ç½®æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼Œä¹Ÿæ”¯æŒMysqlå¯è‡ªè¡Œä¿®æ”¹ï¼š&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;é…ç½®é¡¹&lt;/th&gt; 
   &lt;th align="left"&gt;å¡«å†™å€¼&lt;/th&gt; 
   &lt;th align="left"&gt;è¯´æ˜&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“æœåŠ¡åç§° (å¯¹åº” &lt;code&gt;docker-compose.yml&lt;/code&gt; ä¸­çš„æœåŠ¡å)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;é»˜è®¤ PostgreSQL ç«¯å£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“ç”¨æˆ·å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“å¯†ç &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“åç§°&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;å…¶ä»–&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ä¿æŒé»˜è®¤&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;æ•°æ®åº“è¿æ¥æ± ç­‰å…¶ä»–å‚æ•°è¯·ä¿æŒé»˜è®¤è®¾ç½®ã€‚&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;å¤§æ¨¡å‹é…ç½®&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æˆ‘ä»¬æ‰€æœ‰ LLM è°ƒç”¨ä½¿ç”¨ OpenAI çš„ API æ¥å£æ ‡å‡†&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;åœ¨å®Œæˆæ•°æ®åº“é…ç½®åï¼Œè¯·æ­£å¸¸é…ç½®&lt;strong&gt;æ‰€æœ‰å¤§æ¨¡å‹ç›¸å…³çš„å‚æ•°&lt;/strong&gt;ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿè¿æ¥åˆ°æ‚¨é€‰æ‹©çš„å¤§æ¨¡å‹æœåŠ¡ã€‚&lt;/p&gt; 
&lt;p&gt;å®Œæˆä¸Šè¿°æ‰€æœ‰é…ç½®å¹¶ä¿å­˜åï¼Œç³»ç»Ÿå³å¯æ­£å¸¸è¿è¡Œã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ”§ æºç å¯åŠ¨æŒ‡å—&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¦‚æœä½ æ˜¯åˆæ¬¡å­¦ä¹ ä¸€ä¸ªAgentç³»ç»Ÿçš„æ­å»ºï¼Œå¯ä»¥ä»ä¸€ä¸ªéå¸¸ç®€å•çš„demoå¼€å§‹ï¼š&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ç¯å¢ƒè¦æ±‚&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;æ“ä½œç³»ç»Ÿ&lt;/strong&gt;: Windowsã€Linuxã€MacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pythonç‰ˆæœ¬&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: Anacondaæˆ–Miniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ•°æ®åº“&lt;/strong&gt;: PostgreSQLï¼ˆæ¨èï¼‰æˆ–MySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å†…å­˜&lt;/strong&gt;: å»ºè®®2GBä»¥ä¸Š&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. åˆ›å»ºç¯å¢ƒ&lt;/h3&gt; 
&lt;h4&gt;å¦‚æœä½¿ç”¨Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºcondaç¯å¢ƒ
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;å¦‚æœä½¿ç”¨uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åˆ›å»ºuvç¯å¢ƒ
uv venv --python 3.11 # åˆ›å»º3.11ç¯å¢ƒ
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. å®‰è£… PDF å¯¼å‡ºæ‰€éœ€ç³»ç»Ÿä¾èµ–ï¼ˆå¯é€‰ï¼‰&lt;/h3&gt; 
&lt;p&gt;è¿™éƒ¨åˆ†æœ‰è¯¦ç»†çš„é…ç½®è¯´æ˜ï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/Partial%20README%20for%20PDF%20Exporting/README.md"&gt;é…ç½®æ‰€éœ€ä¾èµ–&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. å®‰è£…ä¾èµ–åŒ…&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å¦‚æœè·³è¿‡äº†æ­¥éª¤2ï¼Œweasyprintåº“å¯èƒ½æ— æ³•å®‰è£…ï¼ŒPDFåŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸ä½¿ç”¨ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åŸºç¡€ä¾èµ–å®‰è£…
pip install -r requirements.txt

# uvç‰ˆæœ¬å‘½ä»¤ï¼ˆæ›´å¿«é€Ÿå®‰è£…ï¼‰
uv pip install -r requirements.txt
# å¦‚æœä¸æƒ³ä½¿ç”¨æœ¬åœ°æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆç®—åŠ›éœ€æ±‚å¾ˆå°ï¼Œé»˜è®¤å®‰è£…cpuç‰ˆæœ¬ï¼‰ï¼Œå¯ä»¥å°†è¯¥æ–‡ä»¶ä¸­çš„"æœºå™¨å­¦ä¹ "éƒ¨åˆ†æ³¨é‡Šæ‰å†æ‰§è¡ŒæŒ‡ä»¤
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. å®‰è£…Playwrightæµè§ˆå™¨é©±åŠ¨&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å®‰è£…æµè§ˆå™¨é©±åŠ¨ï¼ˆç”¨äºçˆ¬è™«åŠŸèƒ½ï¼‰
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;5. é…ç½®LLMä¸æ•°æ®åº“&lt;/h3&gt; 
&lt;p&gt;å¤åˆ¶ä¸€ä»½é¡¹ç›®æ ¹ç›®å½• &lt;code&gt;.env.example&lt;/code&gt; æ–‡ä»¶ï¼Œå‘½åä¸º &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ç¼–è¾‘ &lt;code&gt;.env&lt;/code&gt; æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥ï¼ˆæ‚¨ä¹Ÿå¯ä»¥é€‰æ‹©è‡ªå·±çš„æ¨¡å‹ã€æœç´¢ä»£ç†ï¼Œè¯¦æƒ…è§æ ¹ç›®å½•.env.exampleæ–‡ä»¶å†…æˆ–æ ¹ç›®å½•config.pyä¸­çš„è¯´æ˜ï¼‰ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== æ•°æ®åº“é…ç½® ======================
# æ•°æ®åº“ä¸»æœºï¼Œä¾‹å¦‚localhost æˆ– 127.0.0.1
DB_HOST=your_db_host
# æ•°æ®åº“ç«¯å£å·ï¼Œé»˜è®¤ä¸º3306
DB_PORT=3306
# æ•°æ®åº“ç”¨æˆ·å
DB_USER=your_db_user
# æ•°æ®åº“å¯†ç 
DB_PASSWORD=your_db_password
# æ•°æ®åº“åç§°
DB_NAME=your_db_name
# æ•°æ®åº“å­—ç¬¦é›†ï¼Œæ¨èutf8mb4ï¼Œå…¼å®¹emoji
DB_CHARSET=utf8mb4
# æ•°æ®åº“ç±»å‹postgresqlæˆ–mysql
DB_DIALECT=postgresql
# æ•°æ®åº“ä¸éœ€è¦åˆå§‹åŒ–ï¼Œæ‰§è¡Œapp.pyæ—¶ä¼šè‡ªåŠ¨æ£€æµ‹

# ====================== LLMé…ç½® ======================
# æ‚¨å¯ä»¥æ›´æ”¹æ¯ä¸ªéƒ¨åˆ†LLMä½¿ç”¨çš„APIï¼Œåªè¦å…¼å®¹OpenAIè¯·æ±‚æ ¼å¼éƒ½å¯ä»¥
# é…ç½®æ–‡ä»¶å†…éƒ¨ç»™äº†æ¯ä¸€ä¸ªAgentçš„æ¨èLLMï¼Œåˆæ¬¡éƒ¨ç½²è¯·å…ˆå‚è€ƒæ¨èè®¾ç½®

# Insight Agent
INSIGHT_ENGINE_API_KEY=
INSIGHT_ENGINE_BASE_URL=
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;6. å¯åŠ¨ç³»ç»Ÿ&lt;/h3&gt; 
&lt;h4&gt;6.1 å®Œæ•´ç³»ç»Ÿå¯åŠ¨ï¼ˆæ¨èï¼‰&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»condaç¯å¢ƒ
conda activate your_conda_name

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ç‰ˆæœ¬å¯åŠ¨å‘½ä»¤&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ¿€æ´»uvç¯å¢ƒ
.venv\Scripts\activate

# å¯åŠ¨ä¸»åº”ç”¨å³å¯
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨1ï¼šä¸€æ¬¡è¿è¡Œç»ˆæ­¢åï¼Œstreamlit appå¯èƒ½ç»“æŸå¼‚å¸¸ä»ç„¶å ç”¨ç«¯å£ï¼Œæ­¤æ—¶æœç´¢å ç”¨ç«¯å£çš„è¿›ç¨‹killæ‰å³å¯&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨2ï¼šæ•°æ®çˆ¬å–éœ€è¦å•ç‹¬æ“ä½œï¼Œè§6.3æŒ‡å¼•&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;è®¿é—® &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; å³å¯ä½¿ç”¨å®Œæ•´ç³»ç»Ÿ&lt;/p&gt; 
&lt;h4&gt;6.2 å•ç‹¬å¯åŠ¨æŸä¸ªAgent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# å¯åŠ¨QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# å¯åŠ¨MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# å¯åŠ¨InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6.3 çˆ¬è™«ç³»ç»Ÿå•ç‹¬ä½¿ç”¨&lt;/h4&gt; 
&lt;p&gt;è¿™éƒ¨åˆ†æœ‰è¯¦ç»†çš„é…ç½®æ–‡æ¡£ï¼š&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpiderä½¿ç”¨è¯´æ˜&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider è¿è¡Œç¤ºä¾‹&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# è¿›å…¥çˆ¬è™«ç›®å½•
cd MindSpider

# é¡¹ç›®åˆå§‹åŒ–
python main.py --setup

# è¿è¡Œè¯é¢˜æå–ï¼ˆè·å–çƒ­ç‚¹æ–°é—»å’Œå…³é”®è¯ï¼‰
python main.py --broad-topic

# è¿è¡Œå®Œæ•´çˆ¬è™«æµç¨‹
python main.py --complete --date 2024-01-20

# ä»…è¿è¡Œè¯é¢˜æå–
python main.py --broad-topic --date 2024-01-20

# ä»…è¿è¡Œæ·±åº¦çˆ¬å–
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6.4 å‘½ä»¤è¡ŒæŠ¥å‘Šç”Ÿæˆå·¥å…·&lt;/h4&gt; 
&lt;p&gt;è¯¥å·¥å…·ä¼šè·³è¿‡ä¸‰ä¸ªåˆ†æå¼•æ“çš„è¿è¡Œé˜¶æ®µï¼Œç›´æ¥è¯»å–å®ƒä»¬çš„æœ€æ–°æ—¥å¿—æ–‡ä»¶ï¼Œå¹¶åœ¨æ— éœ€ Web ç•Œé¢çš„æƒ…å†µä¸‹ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼ˆåŒæ—¶çœç•¥æ–‡ä»¶å¢é‡æ ¡éªŒæ­¥éª¤ï¼‰ã€‚é€šå¸¸ç”¨äºå¯¹æŠ¥å‘Šç”Ÿæˆç»“æœä¸æ»¡æ„ã€éœ€è¦å¿«é€Ÿé‡è¯•çš„åœºæ™¯ï¼Œæˆ–åœ¨è°ƒè¯• Report Engine æ—¶å¯ç”¨ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# åŸºæœ¬ä½¿ç”¨ï¼ˆè‡ªåŠ¨ä»æ–‡ä»¶åæå–ä¸»é¢˜ï¼‰
python report_engine_only.py

# æŒ‡å®šæŠ¥å‘Šä¸»é¢˜
python report_engine_only.py --query "åœŸæœ¨å·¥ç¨‹è¡Œä¸šåˆ†æ"

# è·³è¿‡PDFç”Ÿæˆï¼ˆå³ä½¿ç³»ç»Ÿæ”¯æŒï¼‰
python report_engine_only.py --skip-pdf

# æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
python report_engine_only.py --verbose

# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
python report_engine_only.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;åŠŸèƒ½è¯´æ˜ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;è‡ªåŠ¨æ£€æŸ¥ä¾èµ–&lt;/strong&gt;ï¼šç¨‹åºä¼šè‡ªåŠ¨æ£€æŸ¥PDFç”Ÿæˆæ‰€éœ€çš„ç³»ç»Ÿä¾èµ–ï¼Œå¦‚æœç¼ºå¤±ä¼šç»™å‡ºå®‰è£…æç¤º&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è·å–æœ€æ–°æ–‡ä»¶&lt;/strong&gt;ï¼šè‡ªåŠ¨ä»ä¸‰ä¸ªå¼•æ“ç›®å½•ï¼ˆ&lt;code&gt;insight_engine_streamlit_reports&lt;/code&gt;ã€&lt;code&gt;media_engine_streamlit_reports&lt;/code&gt;ã€&lt;code&gt;query_engine_streamlit_reports&lt;/code&gt;ï¼‰è·å–æœ€æ–°çš„åˆ†ææŠ¥å‘Š&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ–‡ä»¶ç¡®è®¤&lt;/strong&gt;ï¼šæ˜¾ç¤ºæ‰€æœ‰é€‰æ‹©çš„æ–‡ä»¶åã€è·¯å¾„å’Œä¿®æ”¹æ—¶é—´ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤ï¼ˆé»˜è®¤è¾“å…¥ &lt;code&gt;y&lt;/code&gt; ç»§ç»­ï¼Œè¾“å…¥ &lt;code&gt;n&lt;/code&gt; é€€å‡ºï¼‰&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ç›´æ¥ç”ŸæˆæŠ¥å‘Š&lt;/strong&gt;ï¼šè·³è¿‡æ–‡ä»¶å¢åŠ å®¡æ ¸ç¨‹åºï¼Œç›´æ¥è°ƒç”¨Report Engineç”Ÿæˆç»¼åˆæŠ¥å‘Š&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;è‡ªåŠ¨ä¿å­˜æ–‡ä»¶&lt;/strong&gt;ï¼š 
  &lt;ul&gt; 
   &lt;li&gt;HTMLæŠ¥å‘Šä¿å­˜åˆ° &lt;code&gt;final_reports/&lt;/code&gt; ç›®å½•&lt;/li&gt; 
   &lt;li&gt;PDFæŠ¥å‘Šï¼ˆå¦‚æœæœ‰ä¾èµ–ï¼‰ä¿å­˜åˆ° &lt;code&gt;final_reports/pdf/&lt;/code&gt; ç›®å½•&lt;/li&gt; 
   &lt;li&gt;æ–‡ä»¶å‘½åæ ¼å¼ï¼š&lt;code&gt;final_report_{ä¸»é¢˜}_{æ—¶é—´æˆ³}.html/pdf&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;æ³¨æ„äº‹é¡¹ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç¡®ä¿ä¸‰ä¸ªå¼•æ“ç›®å½•ä¸­è‡³å°‘æœ‰ä¸€ä¸ªåŒ…å«&lt;code&gt;.md&lt;/code&gt;æŠ¥å‘Šæ–‡ä»¶&lt;/li&gt; 
 &lt;li&gt;å‘½ä»¤è¡Œå·¥å…·ä¸Webç•Œé¢ç›¸äº’ç‹¬ç«‹ï¼Œä¸ä¼šç›¸äº’å½±å“&lt;/li&gt; 
 &lt;li&gt;PDFç”Ÿæˆéœ€è¦å®‰è£…ç³»ç»Ÿä¾èµ–ï¼Œè¯¦è§ä¸Šæ–‡"å®‰è£… PDF å¯¼å‡ºæ‰€éœ€ç³»ç»Ÿä¾èµ–"éƒ¨åˆ†&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš™ï¸ é«˜çº§é…ç½®ï¼ˆå·²è¿‡æ—¶ï¼Œå·²ç»ç»Ÿä¸€ä¸ºé¡¹ç›®æ ¹ç›®å½•.envæ–‡ä»¶ç®¡ç†ï¼Œå…¶ä»–å­agentè‡ªåŠ¨ç»§æ‰¿æ ¹ç›®å½•é…ç½®ï¼‰&lt;/h2&gt; 
&lt;h3&gt;ä¿®æ”¹å…³é”®å‚æ•°&lt;/h3&gt; 
&lt;h4&gt;Agenté…ç½®å‚æ•°&lt;/h4&gt; 
&lt;p&gt;æ¯ä¸ªAgentéƒ½æœ‰ä¸“é—¨çš„é…ç½®æ–‡ä»¶ï¼Œå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œä¸‹é¢æ˜¯éƒ¨åˆ†ç¤ºä¾‹ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # åæ€è½®æ¬¡
    max_search_results = 15       # æœ€å¤§æœç´¢ç»“æœæ•°
    max_content_length = 8000     # æœ€å¤§å†…å®¹é•¿åº¦
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ç»¼åˆæœç´¢é™åˆ¶
    web_search_limit = 15           # ç½‘é¡µæœç´¢é™åˆ¶
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # å…¨å±€æœç´¢é™åˆ¶
    default_get_comments_limit = 500             # è¯„è®ºè·å–é™åˆ¶
    max_search_results_for_llm = 50              # ä¼ ç»™LLMçš„æœ€å¤§ç»“æœæ•°
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;æƒ…æ„Ÿåˆ†ææ¨¡å‹é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # å¯é€‰: 'bert', 'multilingual', 'qwen'ç­‰
    'confidence_threshold': 0.8,      # ç½®ä¿¡åº¦é˜ˆå€¼
    'batch_size': 32,                 # æ‰¹å¤„ç†å¤§å°
    'max_sequence_length': 512,       # æœ€å¤§åºåˆ—é•¿åº¦
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥ä¸åŒçš„LLMæ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;æ”¯æŒä»»æ„openAIè°ƒç”¨æ ¼å¼çš„LLMæä¾›å•†ï¼Œåªéœ€è¦åœ¨/config.pyä¸­å¡«å†™å¯¹åº”çš„KEYã€BASE_URLã€MODEL_NAMEå³å¯ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ä»€ä¹ˆæ˜¯openAIè°ƒç”¨æ ¼å¼ï¼Ÿä¸‹é¢æä¾›ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼š&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "æ¨ç†æ¨¡å‹ä¼šç»™å¸‚åœºå¸¦æ¥å“ªäº›æ–°çš„æœºä¼š"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;æ›´æ”¹æƒ…æ„Ÿåˆ†ææ¨¡å‹&lt;/h3&gt; 
&lt;p&gt;ç³»ç»Ÿé›†æˆäº†å¤šç§æƒ…æ„Ÿåˆ†ææ–¹æ³•ï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š&lt;/p&gt; 
&lt;h4&gt;1. å¤šè¯­è¨€æƒ…æ„Ÿåˆ†æ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. å°å‚æ•°Qwen3å¾®è°ƒ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "è¿™æ¬¡æ´»åŠ¨åŠå¾—å¾ˆæˆåŠŸ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. åŸºäºBERTçš„å¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ä½¿ç”¨BERTä¸­æ–‡æ¨¡å‹
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "è¿™ä¸ªäº§å“çœŸçš„å¾ˆä¸é”™"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAå¾®è°ƒæ¨¡å‹&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "æœåŠ¡æ€åº¦éœ€è¦æ”¹è¿›"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;æ¥å…¥è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“&lt;/h3&gt; 
&lt;h4&gt;1. ä¿®æ”¹æ•°æ®åº“è¿æ¥é…ç½®&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ä¸­æ·»åŠ æ‚¨çš„ä¸šåŠ¡æ•°æ®åº“é…ç½®
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. åˆ›å»ºè‡ªå®šä¹‰æ•°æ®è®¿é—®å·¥å…·&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """è‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®åº“æŸ¥è¯¢å·¥å…·"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """æŸ¥è¯¢ä¸šåŠ¡æ•°æ®"""
        # å®ç°æ‚¨çš„ä¸šåŠ¡é€»è¾‘
        pass
    
    def get_customer_feedback(self, product_id: str):
        """è·å–å®¢æˆ·åé¦ˆæ•°æ®"""
        # å®ç°å®¢æˆ·åé¦ˆæŸ¥è¯¢é€»è¾‘
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. é›†æˆåˆ°InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ä¸­é›†æˆè‡ªå®šä¹‰å·¥å…·
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... å…¶ä»–åˆå§‹åŒ–ä»£ç 
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """æ‰§è¡Œè‡ªå®šä¹‰ä¸šåŠ¡æ•°æ®æœç´¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;è‡ªå®šä¹‰æŠ¥å‘Šæ¨¡æ¿&lt;/h3&gt; 
&lt;h4&gt;1. åœ¨Webç•Œé¢ä¸­ä¸Šä¼ &lt;/h4&gt; 
&lt;p&gt;ç³»ç»Ÿæ”¯æŒä¸Šä¼ è‡ªå®šä¹‰æ¨¡æ¿æ–‡ä»¶ï¼ˆ.mdæˆ–.txtæ ¼å¼ï¼‰ï¼Œå¯åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶é€‰æ‹©ä½¿ç”¨ã€‚&lt;/p&gt; 
&lt;h4&gt;2. åˆ›å»ºæ¨¡æ¿æ–‡ä»¶&lt;/h4&gt; 
&lt;p&gt;åœ¨ &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡æ¿ï¼Œæˆ‘ä»¬çš„Agentä¼šè‡ªè¡Œé€‰ç”¨æœ€åˆé€‚çš„æ¨¡æ¿ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ è´¡çŒ®æŒ‡å—&lt;/h2&gt; 
&lt;p&gt;æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;è¯·é˜…è¯»ä»¥ä¸‹è´¡çŒ®æŒ‡å—ï¼š&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¦– ä¸‹ä¸€æ­¥å¼€å‘è®¡åˆ’&lt;/h2&gt; 
&lt;p&gt;ç°åœ¨ç³»ç»Ÿåªå®Œæˆäº†"ä¸‰æ¿æ–§"ä¸­çš„å‰ä¸¤æ­¥ï¼Œå³ï¼šè¾“å…¥è¦æ±‚-&amp;gt;è¯¦ç»†åˆ†æï¼Œè¿˜ç¼ºå°‘ä¸€æ­¥é¢„æµ‹ï¼Œç›´æ¥å°†ä»–ç»§ç»­äº¤ç»™LLMæ˜¯ä¸å…·æœ‰è¯´æœåŠ›çš„ã€‚&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ç›®å‰æˆ‘ä»¬ç»è¿‡å¾ˆé•¿ä¸€æ®µæ—¶é—´çš„çˆ¬å–æ”¶é›†ï¼Œæ‹¥æœ‰äº†å¤§é‡å…¨ç½‘è¯é¢˜çƒ­åº¦éšæ—¶é—´ã€çˆ†ç‚¹ç­‰çš„å˜åŒ–è¶‹åŠ¿çƒ­åº¦æ•°æ®ï¼Œå·²ç»å…·å¤‡äº†å¯ä»¥å¼€å‘é¢„æµ‹æ¨¡å‹çš„æ¡ä»¶ã€‚æˆ‘ä»¬å›¢é˜Ÿå°†è¿ç”¨æ—¶åºæ¨¡å‹ã€å›¾ç¥ç»ç½‘ç»œã€å¤šæ¨¡æ€èåˆç­‰é¢„æµ‹æ¨¡å‹æŠ€æœ¯å‚¨å¤‡äºæ­¤ï¼Œå®ç°çœŸæ­£åŸºäºæ•°æ®é©±åŠ¨çš„èˆ†æƒ…é¢„æµ‹åŠŸèƒ½ã€‚&lt;/p&gt; 
&lt;h2&gt;âš ï¸ å…è´£å£°æ˜&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;é‡è¦æé†’ï¼šæœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;åˆè§„æ€§å£°æ˜&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®ä¸­çš„æ‰€æœ‰ä»£ç ã€å·¥å…·å’ŒåŠŸèƒ½å‡ä»…ä¾›å­¦ä¹ ã€å­¦æœ¯ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•å•†ä¸šç”¨é€”æˆ–ç›ˆåˆ©æ€§æ´»åŠ¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†æœ¬é¡¹ç›®ç”¨äºä»»ä½•è¿æ³•ã€è¿è§„æˆ–ä¾µçŠ¯ä»–äººæƒç›Šçš„è¡Œä¸º&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;çˆ¬è™«åŠŸèƒ½å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®ä¸­çš„çˆ¬è™«åŠŸèƒ½ä»…ç”¨äºæŠ€æœ¯å­¦ä¹ å’Œç ”ç©¶ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›®æ ‡ç½‘ç«™çš„robots.txtåè®®å’Œä½¿ç”¨æ¡æ¬¾&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…å¿…é¡»éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸å¾—è¿›è¡Œæ¶æ„çˆ¬å–æˆ–æ•°æ®æ»¥ç”¨&lt;/li&gt; 
   &lt;li&gt;å› ä½¿ç”¨çˆ¬è™«åŠŸèƒ½äº§ç”Ÿçš„ä»»ä½•æ³•å¾‹åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æ•°æ®ä½¿ç”¨å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;é¡¹ç›®æ¶‰åŠçš„æ•°æ®åˆ†æåŠŸèƒ½ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨&lt;/li&gt; 
   &lt;li&gt;ä¸¥ç¦å°†åˆ†æç»“æœç”¨äºå•†ä¸šå†³ç­–æˆ–ç›ˆåˆ©ç›®çš„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿æ‰€åˆ†ææ•°æ®çš„åˆæ³•æ€§å’Œåˆè§„æ€§&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;æŠ€æœ¯å…è´£&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;æœ¬é¡¹ç›®æŒ‰"ç°çŠ¶"æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯&lt;/li&gt; 
   &lt;li&gt;ä½œè€…ä¸å¯¹ä½¿ç”¨æœ¬é¡¹ç›®é€ æˆçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”è‡ªè¡Œè¯„ä¼°é¡¹ç›®çš„é€‚ç”¨æ€§å’Œé£é™©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;è´£ä»»é™åˆ¶&lt;/strong&gt;ï¼š&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰åº”å……åˆ†äº†è§£ç›¸å…³æ³•å¾‹æ³•è§„&lt;/li&gt; 
   &lt;li&gt;ä½¿ç”¨è€…åº”ç¡®ä¿å…¶ä½¿ç”¨è¡Œä¸ºç¬¦åˆå½“åœ°æ³•å¾‹æ³•è§„è¦æ±‚&lt;/li&gt; 
   &lt;li&gt;å› è¿åæ³•å¾‹æ³•è§„ä½¿ç”¨æœ¬é¡¹ç›®è€Œäº§ç”Ÿçš„ä»»ä½•åæœç”±ä½¿ç”¨è€…è‡ªè¡Œæ‰¿æ‹…&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;è¯·åœ¨ä½¿ç”¨æœ¬é¡¹ç›®å‰ä»”ç»†é˜…è¯»å¹¶ç†è§£ä¸Šè¿°å…è´£å£°æ˜ã€‚ä½¿ç”¨æœ¬é¡¹ç›®å³è¡¨ç¤ºæ‚¨å·²åŒæ„å¹¶æ¥å—ä¸Šè¿°æ‰€æœ‰æ¡æ¬¾ã€‚&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ è®¸å¯è¯&lt;/h2&gt; 
&lt;p&gt;æœ¬é¡¹ç›®é‡‡ç”¨ &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0è®¸å¯è¯&lt;/a&gt;ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚é˜…LICENSEæ–‡ä»¶ã€‚&lt;/p&gt; 
&lt;h2&gt;ğŸ‰ æ”¯æŒä¸è”ç³»&lt;/h2&gt; 
&lt;h3&gt;è·å–å¸®åŠ©&lt;/h3&gt; 
&lt;p&gt;å¸¸è§é—®é¢˜è§£ç­”ï¼š&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;é¡¹ç›®ä¸»é¡µ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHubä»“åº“&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;é—®é¢˜åé¦ˆ&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;Issuesé¡µé¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;åŠŸèƒ½å»ºè®®&lt;/strong&gt;ï¼š&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;Discussionsé¡µé¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;è”ç³»æ–¹å¼&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“§ &lt;strong&gt;é‚®ç®±&lt;/strong&gt;ï¼š&lt;a href="mailto:hangjiang@bupt.edu.cn"&gt;hangjiang@bupt.edu.cn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;å•†åŠ¡åˆä½œ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ä¼ä¸šå®šåˆ¶å¼€å‘&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å¤§æ•°æ®æœåŠ¡&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å­¦æœ¯åˆä½œ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æŠ€æœ¯åŸ¹è®­&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘¥ è´¡çŒ®è€…&lt;/h2&gt; 
&lt;p&gt;æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è´¡çŒ®è€…ä»¬ï¼š&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ åŠ å…¥å®˜æ–¹äº¤æµç¾¤&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;height=200&amp;amp;section=header&amp;amp;text=æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµQQç¾¤ï¼&amp;amp;fontSize=40&amp;amp;fontAlignY=35&amp;amp;desc=æ‰«æä¸‹æ–¹äºŒç»´ç åŠ å…¥ç¾¤èŠ&amp;amp;descAlignY=55" alt="æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµQQç¾¤ï¼" style="width:60%; max-width:900px; display:block; margin:0 auto;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/QQ_Light_Horizenal.png" alt="BettaFish æŠ€æœ¯äº¤æµç¾¤äºŒç»´ç " style="width:60%; max-width:360px; display:block; margin:20px auto 0;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/adk-samples</title>
      <link>https://github.com/google/adk-samples</link>
      <description>&lt;p&gt;A collection of sample agents built with Agent Development Kit (ADK)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agent Development Kit (ADK) Samples&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://github.com/google/adk-docs/raw/main/docs/assets/agent-development-kit.png" alt="Agent Development Kit Logo" width="150" /&gt; 
&lt;p&gt;Welcome to the ADK Sample Agents repository! This collection provides ready-to-use agents built on top of the &lt;a href="https://google.github.io/adk-docs/"&gt;Agent Development Kit&lt;/a&gt;, designed to accelerate your development process. These agents cover a range of common use cases and complexities, from simple conversational bots to complex multi-agent workflows.&lt;/p&gt; 
&lt;h2&gt;âœ¨ Getting Started&lt;/h2&gt; 
&lt;p&gt;This repo contains ADK sample agents for &lt;strong&gt;Python&lt;/strong&gt;, &lt;strong&gt;Go&lt;/strong&gt; and &lt;strong&gt;Java.&lt;/strong&gt; Navigate to the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/python/"&gt;Python&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/go/"&gt;Go&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google/adk-samples/main/java/"&gt;Java&lt;/a&gt;&lt;/strong&gt; subfolders to see language-specific setup instructions, and learn more about the available sample agents.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] The agents in this repository are built using the &lt;strong&gt;Agent Development Kit (ADK)&lt;/strong&gt;. Before you can run any of the samples, you must have the ADK installed. For instructions, please refer to the &lt;a href="https://google.github.io/adk-docs/get-started"&gt;&lt;strong&gt;ADK Installation Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To learn more, check out the &lt;a href="https://google.github.io/adk-docs/"&gt;ADK Documentation&lt;/a&gt;, and the GitHub repositories for each language:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-python"&gt;ADK Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-go"&gt;ADK Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-java"&gt;ADK Java&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸŒ³ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;â”œâ”€â”€ go
â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ agents
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ llm-auditor
â”‚&amp;nbsp;&amp;nbsp; â””â”€â”€ README.md
â”œâ”€â”€ java
â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ agents
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ software-bug-assistant
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â””â”€â”€ time-series-forecasting
â”‚&amp;nbsp;&amp;nbsp; â””â”€â”€ README.md
â”œâ”€â”€ python
â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ agents
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ academic-research
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ antom-payment
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ blog-writer
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ brand-search-optimization
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ camel
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ customer-service
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ data-engineering
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ data-science
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ financial-advisor
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ fomc-research
â”‚   â”‚   â”œâ”€â”€ gemini-fullstack
â”‚   â”‚   â”œâ”€â”€ deep-search
â”‚   â”‚   â”œâ”€â”€ google-trends-agent
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ image-scoring
â”‚   â”‚   â”œâ”€â”€ llm-auditor
â”‚   â”‚   â”œâ”€â”€ machine-learning-engineering
â”‚   â”‚   â”œâ”€â”€ marketing-agency
â”‚   â”‚   â”œâ”€â”€ medical-pre-authorization
â”‚   â”‚   â”œâ”€â”€ personalized-shopping
â”‚&amp;nbsp;&amp;nbsp; â”‚&amp;nbsp;&amp;nbsp; â”œâ”€â”€ plumber-data-engineering-assistant
â”‚   â”‚   â”œâ”€â”€ RAG
â”‚   â”‚   â”œâ”€â”€ realtime-conversational-agent
â”‚   â”‚   â”œâ”€â”€ safety-plugins
â”‚   â”‚   â”œâ”€â”€ short-movie-agents
â”‚   â”‚   â”œâ”€â”€ software-bug-assistant
â”‚   â”‚   â”œâ”€â”€ travel-concierge
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;â„¹ï¸ Getting help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or if you found any problems with this repository, please report through &lt;a href="https://github.com/google/adk-samples/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our &lt;a href="https://github.com/google/adk-samples/raw/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guidelines&lt;/strong&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://github.com/google/adk-samples/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;p&gt;This is not an officially supported Google product. This project is not eligible for the &lt;a href="https://bughunters.google.com/open-source-security"&gt;Google Open Source Software Vulnerability Rewards Program&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is intended for demonstration purposes only. It is not intended for use in a production environment.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>newren/git-filter-repo</title>
      <link>https://github.com/newren/git-filter-repo</link>
      <description>&lt;p&gt;Quickly rewrite git repository history (filter-branch replacement)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;git filter-repo is a versatile tool for rewriting history, which includes &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#design-rationale-behind-filter-repo"&gt;capabilities I have not found anywhere else&lt;/a&gt;. It roughly falls into the same space of tool as &lt;a href="https://git-scm.com/docs/git-filter-branch"&gt;git filter-branch&lt;/a&gt; but without the capitulation-inducing poor &lt;a href="https://public-inbox.org/git/CABPp-BGOz8nks0+Tdw5GyGqxeYR-3FF6FT5JcgVqZDYVRQ6qog@mail.gmail.com/"&gt;performance&lt;/a&gt;, with far more capabilities, and with a design that scales usability-wise beyond trivial rewriting cases. &lt;a href="https://git-scm.com/docs/git-filter-branch#_warning"&gt;git filter-repo is now recommended by the git project&lt;/a&gt; instead of git filter-branch.&lt;/p&gt; 
&lt;p&gt;While most users will probably just use filter-repo as a simple command line tool (and likely only use a few of its flags), at its core filter-repo contains a library for creating history rewriting tools. As such, users with specialized needs can leverage it to quickly create &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/contrib/filter-repo-demos"&gt;entirely new history rewriting tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#how-do-i-install-it"&gt;How do I install it?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#how-do-i-use-it"&gt;How do I use it?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#why-filter-repo-instead-of-other-alternatives"&gt;Why filter-repo instead of other alternatives?&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#filter-branch"&gt;filter-branch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#bfg-repo-cleaner"&gt;BFG Repo Cleaner&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#simple-example-with-comparisons"&gt;Simple example, with comparisons&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#solving-this-with-filter-repo"&gt;Solving this with filter-repo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#solving-this-with-bfg-repo-cleaner"&gt;Solving this with BFG Repo Cleaner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#solving-this-with-filter-branch"&gt;Solving this with filter-branch&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#solving-this-with-fast-exportfast-import"&gt;Solving this with fast-export/fast-import&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#design-rationale-behind-filter-repo"&gt;Design rationale behind filter-repo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#how-do-i-contribute"&gt;How do I contribute?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#is-there-a-code-of-conduct"&gt;Is there a Code of Conduct?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#upstream-improvements"&gt;Upstream Improvements&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Prerequisites&lt;/h1&gt; 
&lt;p&gt;filter-repo requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;git &amp;gt;= 2.36.0&lt;/li&gt; 
 &lt;li&gt;python3 &amp;gt;= 3.6&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;How do I install it?&lt;/h1&gt; 
&lt;p&gt;While the &lt;code&gt;git-filter-repo&lt;/code&gt; repository has many files, the main logic is all contained in a single-file python script named &lt;code&gt;git-filter-repo&lt;/code&gt;, which was done to make installation for basic use on many systems trivial: just place that one file into your $PATH.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/INSTALL.md"&gt;INSTALL.md&lt;/a&gt; for things beyond basic usage or special cases. The more involved instructions are only needed if one of the following apply:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you do not find the above comment about trivial installation intuitively obvious&lt;/li&gt; 
 &lt;li&gt;you are working with a python3 executable named something other than "python3"&lt;/li&gt; 
 &lt;li&gt;you want to install documentation (beyond the builtin docs shown with -h)&lt;/li&gt; 
 &lt;li&gt;you want to run some of the &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/contrib/filter-repo-demos/"&gt;contrib&lt;/a&gt; examples&lt;/li&gt; 
 &lt;li&gt;you want to create your own python filtering scripts using filter-repo as a module/library&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;How do I use it?&lt;/h1&gt; 
&lt;p&gt;For comprehensive documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;see the &lt;a href="https://htmlpreview.github.io/?https://github.com/newren/git-filter-repo/raw/docs/html/git-filter-repo.html"&gt;user manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;alternative formating of the user manual is available on various external sites (&lt;a href="https://www.mankier.com/1/git-filter-repo"&gt;example&lt;/a&gt;), for those that don't like the htmlpreview.github.io layout, though it may only be up-to-date as of the latest release&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you prefer learning from examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;there is a &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/converting-from-filter-branch.md#cheat-sheet-conversion-of-examples-from-the-filter-branch-manpage"&gt;cheat sheet for converting filter-branch commands&lt;/a&gt;, which covers every example from the filter-branch manual&lt;/li&gt; 
 &lt;li&gt;there is a &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/converting-from-bfg-repo-cleaner.md#cheat-sheet-conversion-of-examples-from-bfg"&gt;cheat sheet for converting BFG Repo Cleaner commands&lt;/a&gt;, which covers every example from the BFG website&lt;/li&gt; 
 &lt;li&gt;the &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#simple-example-with-comparisons"&gt;simple example&lt;/a&gt; below may be of interest&lt;/li&gt; 
 &lt;li&gt;the user manual has an extensive &lt;a href="https://htmlpreview.github.io/?https://github.com/newren/git-filter-repo/raw/docs/html/git-filter-repo.html#EXAMPLES"&gt;examples section&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;I have collected a set of &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/examples-from-user-filed-issues.md"&gt;example filterings based on user-filed issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In either case, you may also find the &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/FAQ.md"&gt;Frequently Answered Questions&lt;/a&gt; useful.&lt;/p&gt; 
&lt;h1&gt;Why filter-repo instead of other alternatives?&lt;/h1&gt; 
&lt;p&gt;This was covered in more detail in a &lt;a href="https://git.github.io/rev_news/2019/08/21/edition-54/#an-introduction-to-git-filter-repo--written-by-elijah-newren"&gt;Git Rev News article on filter-repo&lt;/a&gt;, but some highlights for the main competitors:&lt;/p&gt; 
&lt;h2&gt;filter-branch&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;filter-branch is &lt;a href="https://public-inbox.org/git/CABPp-BGOz8nks0+Tdw5GyGqxeYR-3FF6FT5JcgVqZDYVRQ6qog@mail.gmail.com/"&gt;extremely to unusably slow&lt;/a&gt; (&lt;a href="https://git-scm.com/docs/git-filter-branch#PERFORMANCE"&gt;multiple orders of magnitude slower than it should be&lt;/a&gt;) for non-trivial repositories.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://git-scm.com/docs/git-filter-branch#SAFETY"&gt;filter-branch is riddled with gotchas&lt;/a&gt; that can silently corrupt your rewrite or at least thwart your "cleanup" efforts by giving you something more problematic and messy than what you started with.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;filter-branch is &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/#simple-example-with-comparisons"&gt;very onerous&lt;/a&gt; &lt;a href="https://github.com/newren/git-filter-repo/raw/a6a6a1b0f62d365bbe2e76f823e1621857ec4dbd/contrib/filter-repo-demos/filter-lamely#L9-L61"&gt;to use&lt;/a&gt; for any rewrite which is even slightly non-trivial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;the git project has stated that the above issues with filter-branch cannot be backward compatibly fixed; they recommend that you &lt;a href="https://git-scm.com/docs/git-filter-branch#_warning"&gt;stop using filter-branch&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;die-hard fans of filter-branch may be interested in &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/contrib/filter-repo-demos/filter-lamely"&gt;filter-lamely&lt;/a&gt; (a.k.a. &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/contrib/filter-repo-demos/filter-branch-ish"&gt;filter-branch-ish&lt;/a&gt;), a reimplementation of filter-branch based on filter-repo which is more performant (though not nearly as fast or safe as filter-repo).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;a &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/converting-from-filter-branch.md#cheat-sheet-conversion-of-examples-from-the-filter-branch-manpage"&gt;cheat sheet&lt;/a&gt; is available showing how to convert example commands from the manual of filter-branch into filter-repo commands.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;BFG Repo Cleaner&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;great tool for its time, but while it makes some things simple, it is limited to a few kinds of rewrites.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;its architecture is not amenable to handling more types of rewrites.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;its architecture presents some shortcomings and bugs even for its intended usecase.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;fans of bfg may be interested in &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/contrib/filter-repo-demos/bfg-ish"&gt;bfg-ish&lt;/a&gt;, a reimplementation of bfg based on filter-repo which includes several new features and bugfixes relative to bfg.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;a &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/converting-from-bfg-repo-cleaner.md#cheat-sheet-conversion-of-examples-from-bfg"&gt;cheat sheet&lt;/a&gt; is available showing how to convert example commands from the manual of BFG Repo Cleaner into filter-repo commands.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Simple example, with comparisons&lt;/h1&gt; 
&lt;p&gt;Let's say that we want to extract a piece of a repository, with the intent on merging just that piece into some other bigger repo. For extraction, we want to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;extract the history of a single directory, src/. This means that only paths under src/ remain in the repo, and any commits that only touched paths outside this directory will be removed.&lt;/li&gt; 
 &lt;li&gt;rename all files to have a new leading directory, my-module/ (e.g. so that src/foo.c becomes my-module/src/foo.c)&lt;/li&gt; 
 &lt;li&gt;rename any tags in the extracted repository to have a 'my-module-' prefix (to avoid any conflicts when we later merge this repo into something else)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Solving this with filter-repo&lt;/h2&gt; 
&lt;p&gt;Doing this with filter-repo is as simple as the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;  git filter-repo --path src/ --to-subdirectory-filter my-module --tag-rename '':'my-module-'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(the single quotes are unnecessary, but make it clearer to a human that we are replacing the empty string as a prefix with &lt;code&gt;my-module-&lt;/code&gt;)&lt;/p&gt; 
&lt;h2&gt;Solving this with BFG Repo Cleaner&lt;/h2&gt; 
&lt;p&gt;BFG Repo Cleaner is not capable of this kind of rewrite; in fact, all three types of wanted changes are outside of its capabilities.&lt;/p&gt; 
&lt;h2&gt;Solving this with filter-branch&lt;/h2&gt; 
&lt;p&gt;filter-branch comes with a pile of caveats (more on that below) even once you figure out the necessary invocation(s):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;  git filter-branch \
      --tree-filter 'mkdir -p my-module &amp;amp;&amp;amp; \
                     git ls-files \
                         | grep -v ^src/ \
                         | xargs git rm -f -q &amp;amp;&amp;amp; \
                     ls -d * \
                         | grep -v my-module \
                         | xargs -I files mv files my-module/' \
          --tag-name-filter 'echo "my-module-$(cat)"' \
	  --prune-empty -- --all
  git clone file://$(pwd) newcopy
  cd newcopy
  git for-each-ref --format="delete %(refname)" refs/tags/ \
      | grep -v refs/tags/my-module- \
      | git update-ref --stdin
  git gc --prune=now
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Some might notice that the above filter-branch invocation will be really slow due to using --tree-filter; you could alternatively use the --index-filter option of filter-branch, changing the above commands to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;  git filter-branch \
      --index-filter 'git ls-files \
                          | grep -v ^src/ \
                          | xargs git rm -q --cached;
                      git ls-files -s \
                          | sed "s%$(printf \\t)%&amp;amp;my-module/%" \
                          | git update-index --index-info;
                      git ls-files \
                          | grep -v ^my-module/ \
                          | xargs git rm -q --cached' \
      --tag-name-filter 'echo "my-module-$(cat)"' \
      --prune-empty -- --all
  git clone file://$(pwd) newcopy
  cd newcopy
  git for-each-ref --format="delete %(refname)" refs/tags/ \
      | grep -v refs/tags/my-module- \
      | git update-ref --stdin
  git gc --prune=now
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, for either filter-branch command there are a pile of caveats. First, some may be wondering why I list five commands here for filter-branch. Despite the use of --all and --tag-name-filter, and filter-branch's manpage claiming that a clone is enough to get rid of old objects, the extra steps to delete the other tags and do another gc are still required to clean out the old objects and avoid mixing new and old history before pushing somewhere. Other caveats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Commit messages are not rewritten; so if some of your commit messages refer to prior commits by (abbreviated) sha1, after the rewrite those messages will now refer to commits that are no longer part of the history. It would be better to rewrite those (abbreviated) sha1 references to refer to the new commit ids.&lt;/li&gt; 
 &lt;li&gt;The --prune-empty flag sometimes misses commits that should be pruned, and it will also prune commits that &lt;em&gt;started&lt;/em&gt; empty rather than just ended empty due to filtering. For repositories that intentionally use empty commits for versioning and publishing related purposes, this can be detrimental.&lt;/li&gt; 
 &lt;li&gt;The commands above are OS-specific. GNU vs. BSD issues for sed, xargs, and other commands often trip up users; I think I failed to get most folks to use --index-filter since the only example in the filter-branch manpage that both uses it and shows how to move everything into a subdirectory is linux-specific, and it is not obvious to the reader that it has a portability issue since it silently misbehaves rather than failing loudly.&lt;/li&gt; 
 &lt;li&gt;The --index-filter version of the filter-branch command may be two to three times faster than the --tree-filter version, but both filter-branch commands are going to be multiple orders of magnitude slower than filter-repo.&lt;/li&gt; 
 &lt;li&gt;Both commands assume all filenames are composed entirely of ascii characters (even special ascii characters such as tabs or double quotes will wreak havoc and likely result in missing files or misnamed files)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Solving this with fast-export/fast-import&lt;/h2&gt; 
&lt;p&gt;One can kind of hack this together with something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;  git fast-export --no-data --reencode=yes --mark-tags --fake-missing-tagger \
      --signed-tags=strip --tag-of-filtered-object=rewrite --all \
      | grep -vP '^M [0-9]+ [0-9a-f]+ (?!src/)' \
      | grep -vP '^D (?!src/)' \
      | perl -pe 's%^(M [0-9]+ [0-9a-f]+ )(.*)$%\1my-module/\2%' \
      | perl -pe 's%^(D )(.*)$%\1my-module/\2%' \
      | perl -pe s%refs/tags/%refs/tags/my-module-% \
      | git -c core.ignorecase=false fast-import --date-format=raw-permissive \
            --force --quiet
  git for-each-ref --format="delete %(refname)" refs/tags/ \
      | grep -v refs/tags/my-module- \
      | git update-ref --stdin
  git reset --hard
  git reflog expire --expire=now --all
  git gc --prune=now
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;But this comes with some nasty caveats and limitations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The various greps and regex replacements operate on the entire fast-export stream and thus might accidentally corrupt unintended portions of it, such as commit messages. If you needed to edit file contents and thus dropped the --no-data flag, it could also end up corrupting file contents.&lt;/li&gt; 
 &lt;li&gt;This command assumes all filenames in the repository are composed entirely of ascii characters, and also exclude special characters such as tabs or double quotes. If such a special filename exists within the old src/ directory, it will be pruned even though it was intended to be kept. (In slightly different repository rewrites, this type of editing also risks corrupting filenames with special characters by adding extra double quotes near the end of the filename and in some leading directory name.)&lt;/li&gt; 
 &lt;li&gt;This command will leave behind huge numbers of useless empty commits, and has no realistic way of pruning them. (And if you tried to combine this technique with another tool to prune the empty commits, then you now have no way to distinguish between commits which were made empty by the filtering that you want to remove, and commits which were empty before the filtering process and which you thus may want to keep.)&lt;/li&gt; 
 &lt;li&gt;Commit messages which reference other commits by hash will now reference old commits that no longer exist. Attempting to edit the commit messages to update them is extraordinarily difficult to add to this kind of direct rewrite.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Design rationale behind filter-repo&lt;/h1&gt; 
&lt;p&gt;None of the existing repository filtering tools did what I wanted; they all came up short for my needs. No tool provided any of the first eight traits below I wanted, and no tool provided more than two of the last four traits either:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;[Starting report] Provide user an analysis of their repo to help them get started on what to prune or rename, instead of expecting them to guess or find other tools to figure it out. (Triggered, e.g. by running the first time with a special flag, such as --analyze.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Keep vs. remove] Instead of just providing a way for users to easily remove selected paths, also provide flags for users to only &lt;em&gt;keep&lt;/em&gt; certain paths. Sure, users could workaround this by specifying to remove all paths other than the ones they want to keep, but the need to specify all paths that &lt;em&gt;ever&lt;/em&gt; existed in &lt;strong&gt;any&lt;/strong&gt; version of the repository could sometimes be quite painful. For filter-branch, using pipelines like &lt;code&gt;git ls-files | grep -v ... | xargs -r git rm&lt;/code&gt; might be a reasonable workaround but can get unwieldy and isn't as straightforward for users; plus those commands are often operating-system specific (can you spot the GNUism in the snippet I provided?).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Renaming] It should be easy to rename paths. For example, in addition to allowing one to treat some subdirectory as the root of the repository, also provide options for users to make the root of the repository just become a subdirectory. And more generally allow files and directories to be easily renamed. Provide sanity checks if renaming causes multiple files to exist at the same path. (And add special handling so that if a commit merely copied oldname-&amp;gt;newname without modification, then filtering oldname-&amp;gt;newname doesn't trigger the sanity check and die on that commit.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[More intelligent safety] Writing copies of the original refs to a special namespace within the repo does not provide a user-friendly recovery mechanism. Many would struggle to recover using that. Almost everyone I've ever seen do a repository filtering operation has done so with a fresh clone, because wiping out the clone in case of error is a vastly easier recovery mechanism. Strongly encourage that workflow by &lt;a href="https://htmlpreview.github.io/?https://github.com/newren/git-filter-repo/raw/docs/html/git-filter-repo.html#FRESHCLONE"&gt;detecting and bailing if we're not in a fresh clone&lt;/a&gt;, unless the user overrides with --force.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Auto shrink] Automatically remove old cruft and repack the repository for the user after filtering (unless overridden); this simplifies things for the user, helps avoid mixing old and new history together, and avoids problems where the multi-step process for shrinking the repo documented in the manpage doesn't actually work in some cases. (I'm looking at you, filter-branch.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Clean separation] Avoid confusing users (and prevent accidental re-pushing of old stuff) due to mixing old repo and rewritten repo together. (This is particularly a problem with filter-branch when using the --tag-name-filter option, and sometimes also an issue when only filtering a subset of branches.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Versatility] Provide the user the ability to extend the tool or even write new tools that leverage existing capabilities, and provide this extensibility in a way that (a) avoids the need to fork separate processes (which would destroy performance), (b) avoids making the user specify OS-dependent shell commands (which would prevent users from sharing commands with each other), (c) takes advantage of rich data structures (because hashes, dicts, lists, and arrays are prohibitively difficult in shell) and (d) provides reasonable string manipulation capabilities (which are sorely lacking in shell).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Old commit references] Provide a way for users to use old commit IDs with the new repository (in particular via mapping from old to new hashes with refs/replace/ references).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Commit message consistency] If commit messages refer to other commits by ID (e.g. "this reverts commit 01234567890abcdef", "In commit 0013deadbeef9a..."), those commit messages should be rewritten to refer to the new commit IDs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Become-empty pruning] Commits which become empty due to filtering should be pruned. If the parent of a commit is pruned, the first non-pruned ancestor needs to become the new parent. If no non-pruned ancestor exists and the commit was not a merge, then it becomes a new root commit. If no non-pruned ancestor exists and the commit was a merge, then the merge will have one less parent (and thus make it likely to become a non-merge commit which would itself be pruned if it had no file changes of its own). One special thing to note here is that we prune commits which become empty, NOT commits which start empty. Some projects intentionally create empty commits for versioning or publishing reasons, and these should not be removed. (As a special case, commits which started empty but whose parent was pruned away will also be considered to have "become empty".)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Become-degenerate pruning] Pruning of commits which become empty can potentially cause topology changes, and there are lots of special cases. Normally, merge commits are not removed since they are needed to preserve the graph topology, but the pruning of parents and other ancestors can ultimately result in the loss of one or more parents. A simple case was already noted above: if a merge commit loses enough parents to become a non-merge commit and it has no file changes, then it too can be pruned. Merge commits can also have a topology that becomes degenerate: it could end up with the merge_base serving as both parents (if all intervening commits from the original repo were pruned), or it could end up with one parent which is an ancestor of its other parent. In such cases, if the merge has no file changes of its own, then the merge commit can also be pruned. However, much as we do with empty pruning we do not prune merge commits that started degenerate (which indicates it may have been intentional, such as with --no-ff merges) but only merge commits that become degenerate and have no file changes of their own.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;[Speed] Filtering should be reasonably fast&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;How do I contribute?&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/newren/git-filter-repo/main/Documentation/Contributing.md"&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Is there a Code of Conduct?&lt;/h1&gt; 
&lt;p&gt;Participants in the filter-repo community are expected to adhere to the same standards as for the git project, so the &lt;a href="https://git.kernel.org/pub/scm/git/git.git/tree/CODE_OF_CONDUCT.md"&gt;git Code of Conduct&lt;/a&gt; applies.&lt;/p&gt; 
&lt;h1&gt;Upstream Improvements&lt;/h1&gt; 
&lt;p&gt;Work on filter-repo and &lt;a href="https://public-inbox.org/git/51419b2c0904072035u1182b507o836a67ac308d32b9@mail.gmail.com/"&gt;its predecessor&lt;/a&gt; has also driven numerous improvements to fast-export and fast-import (and occasionally other commands) in core git, based on things filter-repo needs to do its work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;git-2.48.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=da91a90c2f"&gt;fast-import: disallow more path components&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=4a2790a257"&gt;fast-import: disallow "." and ".." path components&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=5e904f1a4a"&gt;fast-import: avoid making replace refs point to themselves&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.28.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=d42a2fb72f"&gt;fast-import: add new --date-format=raw-permissive format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.24.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=941790d7de"&gt;fast-export: handle nested tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=8d7d33c1ce"&gt;t9350: add tests for tags of things other than a commit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=a1638cfe12"&gt;fast-export: allow user to request tags be marked with --mark-tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=208d69246e"&gt;fast-export: add support for --import-marks-if-exists&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=b8f50e5b60"&gt;fast-import: add support for new 'alias' command&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=f73b2aba05"&gt;fast-import: allow tags to be identified by mark labels&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=3164e6bd24"&gt;fast-import: fix handling of deleted tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=af2abd870b"&gt;fast-export: fix exporting a tag and nothing else&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=d1387d3895"&gt;git-fast-import.txt: clarify that multiple merge commits are allowed&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.23.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=32615ce762"&gt;t9350: fix encoding test to actually test reencoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=3edfcc65fd"&gt;fast-import: support 'encoding' commit header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=ccbfc96dc4"&gt;fast-export: avoid stripping encoding header if we cannot reencode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=57a8be2cb0"&gt;fast-export: differentiate between explicitly UTF-8 and implicitly UTF-8&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=e80001f8fd"&gt;fast-export: do automatic reencoding of commit messages only if requested&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.22.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=d76ce4f734"&gt;log,diff-tree: add --combined-all-paths option&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=62edbec7de"&gt;t9300: demonstrate bug with get-mark and empty orphan commits&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=a63c54a019"&gt;git-fast-import.txt: fix wording about where ls command can appear&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=5056bb7646"&gt;fast-import: check most prominent commands first&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=7ffde293f2"&gt;fast-import: only allow cat-blob requests where it makes sense&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=cf7b857a77"&gt;fast-import: fix erroneous handling of get-mark with empty orphan commits&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=8e712ef6fc"&gt;Honor core.precomposeUnicode in more places&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.21.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=843b9e6d48"&gt;fast-export: convert sha1 to oid&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=f55c979b14"&gt;git-fast-import.txt: fix documentation for --quiet option&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=4532be7cba"&gt;git-fast-export.txt: clarify misleading documentation about rev-list args&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=b93b81e799"&gt;fast-export: use value from correct enum&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=1f30c904b3"&gt;fast-export: avoid dying when filtering by paths and old tags exist&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=f129c4275c"&gt;fast-export: move commit rewriting logic into a function for reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=cd13762d8f"&gt;fast-export: when using paths, avoid corrupt stream with non-existent mark&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=fdf31b6369"&gt;fast-export: ensure we export requested refs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=530ca19c02"&gt;fast-export: add --reference-excluded-parents option&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=25dd3e4889"&gt;fast-import: remove unmaintained duplicate documentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=a965bb3116"&gt;fast-export: add a --show-original-ids option to show original names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=bd8d6f0def"&gt;git-show-ref.txt: fix order of flags&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-2.20.0 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=e4c34855a2"&gt;update-ref: fix type of update_flags variable to match its usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=d345e9fbe7"&gt;update-ref: allow --no-deref with --stdin&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-1.7.3 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=4087a02e45"&gt;fast-export: Fix dropping of files with --import-marks and path limiting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=7f40ab0916"&gt;fast-export: Add a --full-tree option&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=060df62422"&gt;fast-export: Fix output order of D/F changes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=253fb5f889"&gt;fast-import: Improve robustness when D-&amp;gt;F changes provided in wrong order&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-1.6.4: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=668f3aa776"&gt;fast-export: Set revs.topo_order before calling setup_revisions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=02c48cd69b"&gt;fast-export: Omit tags that tag trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=2374502c6c"&gt;fast-export: Make sure we show actual ref names instead of "(null)"&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=32164131db"&gt;fast-export: Do parent rewriting to avoid dropping relevant commits&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=2d8ad46919"&gt;fast-export: Add a --tag-of-filtered-object option for newly dangling tags&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=25e0ca5dd6"&gt;Add new fast-export testcases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=8af15d282e"&gt;fast-export: Document the fact that git-rev-list arguments are accepted&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-1.6.3: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=d5b0c97d13"&gt;git-filter-branch: avoid collisions with variables in eval'ed commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=98e1a4186a"&gt;Correct missing SP characters in grammar comment at top of fast-import.c&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=ebeec7dbc5"&gt;fast-export: Avoid dropping files from commits&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;git-1.6.1.4: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://git.kernel.org/pub/scm/git/git.git/commit/?id=784f8affe4"&gt;fast-export: ensure we traverse commits in topological order&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-quickstarts</title>
      <link>https://github.com/anthropics/claude-quickstarts</link>
      <description>&lt;p&gt;A collection of projects designed to help developers quickly get started with building deployable applications using the Claude API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Quickstarts&lt;/h1&gt; 
&lt;p&gt;Claude Quickstarts is a collection of projects designed to help developers quickly get started with building applications using the Claude API. Each quickstart provides a foundation that you can easily build upon and customize for your specific needs.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To use these quickstarts, you'll need an Claude API key. If you don't have one yet, you can sign up for free at &lt;a href="https://console.anthropic.com"&gt;console.anthropic.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Available Quickstarts&lt;/h2&gt; 
&lt;h3&gt;Customer Support Agent&lt;/h3&gt; 
&lt;p&gt;A customer support agent powered by Claude. This project demonstrates how to leverage Claude's natural language understanding and generation capabilities to create an AI-assisted customer support system with access to a knowledge base.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/customer-support-agent"&gt;Go to Customer Support Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Financial Data Analyst&lt;/h3&gt; 
&lt;p&gt;A financial data analyst powered by Claude. This project demonstrates how to leverage Claude's capabilities with interactive data visualization to analyze financial data via chat.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/financial-data-analyst"&gt;Go to Financial Data Analyst Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Computer Use Demo&lt;/h3&gt; 
&lt;p&gt;An environment and tools that Claude can use to control a desktop computer. This project demonstrates how to leverage the computer use capabilities of Claude, including support for the latest &lt;code&gt;computer_use_20251124&lt;/code&gt; tool version with zoom actions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/computer-use-demo"&gt;Go to Computer Use Demo Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Autonomous Coding Agent&lt;/h3&gt; 
&lt;p&gt;An autonomous coding agent powered by the Claude Agent SDK. This project demonstrates a two-agent pattern (initializer + coding agent) that can build complete applications over multiple sessions, with progress persisted via git and a feature list that the agent works through incrementally.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/autonomous-coding"&gt;Go to Autonomous Coding Agent Quickstart&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;General Usage&lt;/h2&gt; 
&lt;p&gt;Each quickstart project comes with its own README and setup instructions. Generally, you'll follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone this repository&lt;/li&gt; 
 &lt;li&gt;Navigate to the specific quickstart directory&lt;/li&gt; 
 &lt;li&gt;Install the required dependencies&lt;/li&gt; 
 &lt;li&gt;Set up your Claude API key as an environment variable&lt;/li&gt; 
 &lt;li&gt;Run the quickstart application&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;p&gt;To deepen your understanding of working with Claude and the Claude API, check out these resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com"&gt;Claude API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-cookbooks"&gt;Claude Cookbooks&lt;/a&gt; - A collection of code snippets and guides for common tasks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals"&gt;Claude API Fundamentals Course&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Claude Quickstarts repository! If you have ideas for new quickstart projects or improvements to existing ones, please open an issue or submit a pull request.&lt;/p&gt; 
&lt;h2&gt;Community and Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://www.anthropic.com/discord"&gt;Anthropic Discord community&lt;/a&gt; for discussions and support&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://support.anthropic.com"&gt;Anthropic support documentation&lt;/a&gt; for additional help&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-quickstarts/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rany2/edge-tts</title>
      <link>https://github.com/rany2/edge-tts</link>
      <description>&lt;p&gt;Use Microsoft Edge's online text-to-speech service from Python WITHOUT needing Microsoft Edge or Windows or an API key&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;edge-tts&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;edge-tts&lt;/code&gt; is a Python module that allows you to use Microsoft Edge's online text-to-speech service from within your Python code or using the provided &lt;code&gt;edge-tts&lt;/code&gt; or &lt;code&gt;edge-playback&lt;/code&gt; command.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install it, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip install edge-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you only want to use the &lt;code&gt;edge-tts&lt;/code&gt; and &lt;code&gt;edge-playback&lt;/code&gt; commands, it would be better to use &lt;code&gt;pipx&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pipx install edge-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;p&gt;If you want to use the &lt;code&gt;edge-tts&lt;/code&gt; command, you can simply run it with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ edge-tts --text "Hello, world!" --write-media hello.mp3 --write-subtitles hello.srt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you wish to play it back immediately with subtitles, you could use the &lt;code&gt;edge-playback&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ edge-playback --text "Hello, world!"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;edge-playback&lt;/code&gt; requires the installation of the &lt;a href="https://mpv.io/"&gt;&lt;code&gt;mpv&lt;/code&gt; command line player&lt;/a&gt;, except on Windows.&lt;/p&gt; 
&lt;p&gt;All &lt;code&gt;edge-tts&lt;/code&gt; commands work with &lt;code&gt;edge-playback&lt;/code&gt; with the exception of the &lt;code&gt;--write-media&lt;/code&gt;, &lt;code&gt;--write-subtitles&lt;/code&gt; and &lt;code&gt;--list-voices&lt;/code&gt; options.&lt;/p&gt; 
&lt;h3&gt;Changing the voice&lt;/h3&gt; 
&lt;p&gt;You can change the voice used by the text-to-speech service by using the &lt;code&gt;--voice&lt;/code&gt; option. The &lt;code&gt;--list-voices&lt;/code&gt; option can be used to list all available voices.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ edge-tts --list-voices
Name                               Gender    ContentCategories      VoicePersonalities
---------------------------------  --------  ---------------------  --------------------------------------
af-ZA-AdriNeural                   Female    General                Friendly, Positive
af-ZA-WillemNeural                 Male      General                Friendly, Positive
am-ET-AmehaNeural                  Male      General                Friendly, Positive
am-ET-MekdesNeural                 Female    General                Friendly, Positive
ar-AE-FatimaNeural                 Female    General                Friendly, Positive
ar-AE-HamdanNeural                 Male      General                Friendly, Positive
ar-BH-AliNeural                    Male      General                Friendly, Positive
ar-BH-LailaNeural                  Female    General                Friendly, Positive
ar-DZ-AminaNeural                  Female    General                Friendly, Positive
ar-DZ-IsmaelNeural                 Male      General                Friendly, Positive
ar-EG-SalmaNeural                  Female    General                Friendly, Positive
...

$ edge-tts --voice ar-EG-SalmaNeural --text "Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ" --write-media hello_in_arabic.mp3 --write-subtitles hello_in_arabic.srt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Custom SSML&lt;/h3&gt; 
&lt;p&gt;Support for custom SSML was removed because Microsoft prevents the use of any SSML that could not be generated by Microsoft Edge itself. This means that all the cases where custom SSML would be useful cannot be supported as the service only permits a single &lt;code&gt;&amp;lt;voice&amp;gt;&lt;/code&gt; tag with a single &lt;code&gt;&amp;lt;prosody&amp;gt;&lt;/code&gt; tag inside it. Any available customization options that could be used in the &lt;code&gt;&amp;lt;prosody&amp;gt;&lt;/code&gt; tag are already available from the library or the command line itself.&lt;/p&gt; 
&lt;h3&gt;Changing rate, volume and pitch&lt;/h3&gt; 
&lt;p&gt;You can change the rate, volume and pitch of the generated speech by using the &lt;code&gt;--rate&lt;/code&gt;, &lt;code&gt;--volume&lt;/code&gt; and &lt;code&gt;--pitch&lt;/code&gt; options. When using a negative value, you will need to use &lt;code&gt;--[option]=-50%&lt;/code&gt; instead of &lt;code&gt;--[option] -50%&lt;/code&gt; to avoid the option being interpreted as a command line option.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ edge-tts --rate=-50% --text "Hello, world!" --write-media hello_with_rate_lowered.mp3 --write-subtitles hello_with_rate_lowered.srt
$ edge-tts --volume=-50% --text "Hello, world!" --write-media hello_with_volume_lowered.mp3 --write-subtitles hello_with_volume_lowered.srt
$ edge-tts --pitch=-50Hz --text "Hello, world!" --write-media hello_with_pitch_lowered.mp3 --write-subtitles hello_with_pitch_lowered.srt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Python module&lt;/h2&gt; 
&lt;p&gt;It is possible to use the &lt;code&gt;edge-tts&lt;/code&gt; module directly from Python. Examples from the project itself include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rany2/edge-tts/master/examples/"&gt;/examples/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rany2/edge-tts/master/src/edge_tts/util.py"&gt;/src/edge_tts/util.py&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other projects that use the &lt;code&gt;edge-tts&lt;/code&gt; module include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hasscc/hass-edge-tts/raw/main/custom_components/edge_tts/tts.py"&gt;hass-edge-tts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/souzatharsis/podcastfy/raw/main/podcastfy/tts/providers/edge.py"&gt;Podcastfy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaph/tts-samples/raw/main/bin/create_sound_samples.py"&gt;tts-samples&lt;/a&gt; - a collection of &lt;a href="https://github.com/yaph/tts-samples/tree/main/mp3"&gt;mp3 sound samples&lt;/a&gt; to facilitate picking a voice for your project.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>microsoft/VibeVoice</title>
      <link>https://github.com/microsoft/VibeVoice</link>
      <description>&lt;p&gt;Open-Source Frontier Voice AI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;ğŸ™ï¸ VibeVoice: Open-Source Frontier Voice AI&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://microsoft.github.io/VibeVoice"&gt;&lt;img src="https://img.shields.io/badge/Project-Page-blue?logo=microsoft" alt="Project Page" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f"&gt;&lt;img src="https://img.shields.io/badge/HuggingFace-Collection-orange?logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2508.19205"&gt;&lt;img src="https://img.shields.io/badge/Technical-Report-red?logo=adobeacrobatreader" alt="Technical Report" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="Figures/VibeVoice_logo_white.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice_logo.png" alt="VibeVoice Logo" width="300" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;h3&gt;ğŸ“° News&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/Status-New-brightgreen?style=flat" alt="New" /&gt; 
 &lt;img src="https://img.shields.io/badge/Feature-Realtime_TTS-blue?style=flat&amp;amp;logo=soundcharts" alt="Realtime TTS" /&gt; 
 &lt;p&gt;&lt;strong&gt;2025-12-03: ğŸ“£ We open-sourced &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;&lt;strong&gt;VibeVoiceâ€‘Realtimeâ€‘0.5B&lt;/strong&gt;&lt;/a&gt;, a realâ€‘time textâ€‘toâ€‘speech model that supports streaming text input and robust long-form speech generation. Try it on &lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb"&gt;Colab&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2025-12-09: ğŸ“£ Weâ€™ve added experimental speakers in nine languages (DE, FR, IT, JP, KR, NL, PL, PT, ES) for explorationâ€”welcome to try them out and share your feedback.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;To mitigate deepfake risks and ensure low latency for the first speech chunk, voice prompts are provided in an embedded format. For users requiring voice customization, please reach out to our team. We will also be expanding the range of available speakers. &lt;br /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc"&gt;https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc&lt;/a&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;(Launch your own realtime demo via the websocket example in &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md#usage-1-launch-real-time-websocket-demo"&gt;Usage&lt;/a&gt;).&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;p&gt;2025-09-05: VibeVoice is an open-source research framework intended to advance collaboration in the speech synthesis community. After release, we discovered instances where the tool was used in ways inconsistent with the stated intent. Since responsible use of AI is one of Microsoftâ€™s guiding principles, we have disabled this repo until we are confident that out-of-scope use is no longer possible.&lt;/p&gt; 
&lt;h3&gt;Overview&lt;/h3&gt; 
&lt;p&gt;VibeVoice is a novel framework designed for generating &lt;strong&gt;expressive&lt;/strong&gt;, &lt;strong&gt;long-form&lt;/strong&gt;, &lt;strong&gt;multi-speaker&lt;/strong&gt; conversational audio, such as podcasts, from text. It addresses significant challenges in traditional Text-to-Speech (TTS) systems, particularly in scalability, speaker consistency, and natural turn-taking.&lt;/p&gt; 
&lt;p&gt;VibeVoice currently includes two model variants:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Long-form multi-speaker model&lt;/strong&gt;: Synthesizes conversational/single-speaker speech up to &lt;strong&gt;90 minutes&lt;/strong&gt; with up to &lt;strong&gt;4 distinct speakers&lt;/strong&gt;, surpassing the typical 1â€“2 speaker limits of many prior models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;Realtime streaming TTS model&lt;/a&gt;&lt;/strong&gt;: Produces initial audible speech in ~&lt;strong&gt;300 ms&lt;/strong&gt; and supports &lt;strong&gt;streaming text input&lt;/strong&gt; for single-speaker &lt;strong&gt;real-time&lt;/strong&gt; speech generation; designed for low-latency generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;A core innovation of VibeVoice is its use of continuous speech tokenizers (Acoustic and Semantic) operating at an ultra-low frame rate of 7.5 Hz. These tokenizers efficiently preserve audio fidelity while significantly boosting computational efficiency for processing long sequences. VibeVoice employs a &lt;a href="https://arxiv.org/abs/2412.08635"&gt;next-token diffusion&lt;/a&gt; framework, leveraging a Large Language Model (LLM) to understand textual context and dialogue flow, and a diffusion head to generate high-fidelity acoustic details.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/MOS-preference.png" alt="MOS Preference Results" height="260px" /&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice.jpg" alt="VibeVoice Overview" height="250px" style="margin-right: 10px;" /&gt; &lt;/p&gt; 
&lt;h3&gt;ğŸµ Demo Examples&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Video Demo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We produced this video with &lt;a href="https://github.com/Wan-Video/Wan2.2"&gt;Wan2.2&lt;/a&gt;. We sincerely appreciate the Wan-Video team for their great work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784"&gt;https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Chinese&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f"&gt;https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Cross-Lingual&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722"&gt;https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Spontaneous Singing&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730"&gt;https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Long Conversation with 4 people&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727"&gt;https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;For more examples, see the &lt;a href="https://microsoft.github.io/VibeVoice"&gt;Project Page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Risks and limitations&lt;/h2&gt; 
&lt;p&gt;While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content.&lt;/p&gt; 
&lt;p&gt;English and Chinese only: Transcripts in languages other than English or Chinese may result in unexpected audio outputs.&lt;/p&gt; 
&lt;p&gt;Non-Speech Audio: The model focuses solely on speech synthesis and does not handle background noise, music, or other sound effects.&lt;/p&gt; 
&lt;p&gt;Overlapping Speech: The current model does not explicitly model or generate overlapping speech segments in conversations.&lt;/p&gt; 
&lt;p&gt;We do not recommend using VibeVoice in commercial or real-world applications without further testing and development. This model is intended for research and development purposes only. Please use responsibly.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://api.star-history.com/svg?repos=Microsoft/vibevoice&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>strands-agents/sdk-python</title>
      <link>https://github.com/strands-agents/sdk-python</link>
      <description>&lt;p&gt;A model-driven approach to building AI agents in just a few lines of code.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div&gt; 
  &lt;a href="https://strandsagents.com"&gt; &lt;img src="https://strandsagents.com/latest/assets/logo-github.svg?sanitize=true" alt="Strands Agents" width="55px" height="105px" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h1&gt; Strands Agents &lt;/h1&gt; 
 &lt;h2&gt; A model-driven approach to building AI agents in just a few lines of code. &lt;/h2&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/graphs/commit-activity"&gt;&lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/issues"&gt;&lt;img alt="GitHub open issues" src="https://img.shields.io/github/issues/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/pulls"&gt;&lt;img alt="GitHub open pull requests" src="https://img.shields.io/github/issues-pr/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://pypi.org/project/strands-agents/"&gt;&lt;img alt="PyPI version" src="https://img.shields.io/pypi/v/strands-agents" /&gt;&lt;/a&gt; 
  &lt;a href="https://python.org"&gt;&lt;img alt="Python versions" src="https://img.shields.io/pypi/pyversions/strands-agents" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt; &lt;a href="https://strandsagents.com/"&gt;Documentation&lt;/a&gt; â—† &lt;a href="https://github.com/strands-agents/samples"&gt;Samples&lt;/a&gt; â—† &lt;a href="https://github.com/strands-agents/sdk-python"&gt;Python SDK&lt;/a&gt; â—† &lt;a href="https://github.com/strands-agents/tools"&gt;Tools&lt;/a&gt; â—† &lt;a href="https://github.com/strands-agents/agent-builder"&gt;Agent Builder&lt;/a&gt; â—† &lt;a href="https://github.com/strands-agents/mcp-server"&gt;MCP Server&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Strands Agents is a simple yet powerful SDK that takes a model-driven approach to building and running AI agents. From simple conversational assistants to complex autonomous workflows, from local development to production deployment, Strands Agents scales with your needs.&lt;/p&gt; 
&lt;h2&gt;Feature Overview&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight &amp;amp; Flexible&lt;/strong&gt;: Simple agent loop that just works and is fully customizable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Support for Amazon Bedrock, Anthropic, Gemini, LiteLLM, Llama, Ollama, OpenAI, Writer, and custom providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Capabilities&lt;/strong&gt;: Multi-agent systems, autonomous agents, and streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in MCP&lt;/strong&gt;: Native support for Model Context Protocol (MCP) servers, enabling access to thousands of pre-built tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Strands Agents
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For the default Amazon Bedrock model provider, you'll need AWS credentials configured and model access enabled for Claude 4 Sonnet in the us-west-2 region. See the &lt;a href="https://strandsagents.com/"&gt;Quickstart Guide&lt;/a&gt; for details on configuring other model providers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Ensure you have Python 3.10+ installed, then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate

# Install Strands and tools
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features at a Glance&lt;/h2&gt; 
&lt;h3&gt;Python-Based Tools&lt;/h3&gt; 
&lt;p&gt;Easily build tools using Python decorators:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent, tool

@tool
def word_count(text: str) -&amp;gt; int:
    """Count words in text.

    This docstring is used by the LLM to understand the tool's purpose.
    """
    return len(text.split())

agent = Agent(tools=[word_count])
response = agent("How many words are in this sentence?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Hot Reloading from Directory:&lt;/strong&gt; Enable automatic tool loading and reloading from the &lt;code&gt;./tools/&lt;/code&gt; directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent

# Agent will watch ./tools/ directory for changes
agent = Agent(load_tools_from_directory=True)
response = agent("Use any tools you find in the tools directory")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP Support&lt;/h3&gt; 
&lt;p&gt;Seamlessly integrate Model Context Protocol (MCP) servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters

aws_docs_client = MCPClient(
    lambda: stdio_client(StdioServerParameters(command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"]))
)

with aws_docs_client:
   agent = Agent(tools=aws_docs_client.list_tools_sync())
   response = agent("Tell me about Amazon Bedrock and how to use it with Python")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiple Model Providers&lt;/h3&gt; 
&lt;p&gt;Support for various model providers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.models import BedrockModel
from strands.models.ollama import OllamaModel
from strands.models.llamaapi import LlamaAPIModel
from strands.models.gemini import GeminiModel
from strands.models.llamacpp import LlamaCppModel

# Bedrock
bedrock_model = BedrockModel(
  model_id="us.amazon.nova-pro-v1:0",
  temperature=0.3,
  streaming=True, # Enable/disable streaming
)
agent = Agent(model=bedrock_model)
agent("Tell me about Agentic AI")

# Google Gemini
gemini_model = GeminiModel(
  client_args={
    "api_key": "your_gemini_api_key",
  },
  model_id="gemini-2.5-flash",
  params={"temperature": 0.7}
)
agent = Agent(model=gemini_model)
agent("Tell me about Agentic AI")

# Ollama
ollama_model = OllamaModel(
  host="http://localhost:11434",
  model_id="llama3"
)
agent = Agent(model=ollama_model)
agent("Tell me about Agentic AI")

# Llama API
llama_model = LlamaAPIModel(
    model_id="Llama-4-Maverick-17B-128E-Instruct-FP8",
)
agent = Agent(model=llama_model)
response = agent("Tell me about Agentic AI")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Built-in providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/"&gt;Amazon Bedrock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/anthropic/"&gt;Anthropic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/gemini/"&gt;Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/cohere/"&gt;Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/litellm/"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamacpp/"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamaapi/"&gt;LlamaAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/mistral/"&gt;MistralAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/ollama/"&gt;Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/openai/"&gt;OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/sagemaker/"&gt;SageMaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/writer/"&gt;Writer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Custom providers can be implemented using &lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/custom_model_provider/"&gt;Custom Providers&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Example tools&lt;/h3&gt; 
&lt;p&gt;Strands offers an optional strands-agents-tools package with pre-built tools for quick experimentation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It's also available on GitHub via &lt;a href="https://github.com/strands-agents/tools"&gt;strands-agents/tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Bidirectional Streaming&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ Experimental Feature&lt;/strong&gt;: Bidirectional streaming is currently in experimental status. APIs may change in future releases as we refine the feature based on user feedback and evolving model capabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Build real-time voice and audio conversations with persistent streaming connections. Unlike traditional request-response patterns, bidirectional streaming maintains long-running conversations where users can interrupt, provide continuous input, and receive real-time audio responses. Get started with your first BidiAgent by following the &lt;a href="https://strandsagents.com/latest/documentation/docs/user-guide/concepts/experimental/bidirectional-streaming/quickstart"&gt;Quickstart&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Supported Model Providers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon Nova Sonic (&lt;code&gt;amazon.nova-sonic-v1:0&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Google Gemini Live (&lt;code&gt;gemini-2.5-flash-native-audio-preview-09-2025&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;OpenAI Realtime API (&lt;code&gt;gpt-realtime&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from strands.experimental.bidi import BidiAgent
from strands.experimental.bidi.models import BidiNovaSonicModel
from strands.experimental.bidi.io import BidiAudioIO, BidiTextIO
from strands.experimental.bidi.tools import stop_conversation
from strands_tools import calculator

async def main():
    # Create bidirectional agent with audio model
    model = BidiNovaSonicModel()
    agent = BidiAgent(model=model, tools=[calculator, stop_conversation])

    # Setup audio and text I/O
    audio_io = BidiAudioIO()
    text_io = BidiTextIO()

    # Run with real-time audio streaming
    # Say "stop conversation" to gracefully end the conversation
    await agent.run(
        inputs=[audio_io.input()],
        outputs=[audio_io.output(), text_io.output()]
    )

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Configuration Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Configure audio settings
model = BidiNovaSonicModel(
    provider_config={
        "audio": {
            "input_rate": 16000,
            "output_rate": 16000,
            "voice": "matthew"
        },
        "inference": {
            "max_tokens": 2048,
            "temperature": 0.7
        }
    }
)

# Configure I/O devices
audio_io = BidiAudioIO(
    input_device_index=0,  # Specific microphone
    output_device_index=1,  # Specific speaker
    input_buffer_size=10,
    output_buffer_size=10
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed guidance &amp;amp; examples, explore our documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/"&gt;User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/quickstart/"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/agents/agent-loop/"&gt;Agent Loop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/examples/"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/api-reference/agent/"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/deploy/operating-agents-in-production/"&gt;Production &amp;amp; Deployment Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing â¤ï¸&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See our &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reporting bugs &amp;amp; features&lt;/li&gt; 
 &lt;li&gt;Development setup&lt;/li&gt; 
 &lt;li&gt;Contributing via Pull Requests&lt;/li&gt; 
 &lt;li&gt;Code of Conduct&lt;/li&gt; 
 &lt;li&gt;Reporting of security issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md#security-issue-notifications"&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zhu-xlab/GlobalBuildingAtlas</title>
      <link>https://github.com/zhu-xlab/GlobalBuildingAtlas</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GlobalBuildingAtlas&lt;/h1&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;In this project, we provide the level of detail 1 (LoD1) data of buildings across the globe.&lt;/p&gt; 
&lt;p&gt;A overview of the dataset is illustrated bellow:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/zhu-xlab/GlobalBuildingAtlas/main/figures/overview.png" width="800" /&gt; 
&lt;h2&gt;Access to the Data&lt;/h2&gt; 
&lt;h3&gt;Web Feature Service (WFS)&lt;/h3&gt; 
&lt;p&gt;A WFS is provided so that one can access the data using other websites or GIS softwares such as QGIS and ArcGIS.&lt;/p&gt; 
&lt;p&gt;Url: &lt;code&gt;https://tubvsig-so2sat-vm1.srv.mwn.de/geoserver/ows?&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Web Viewer&lt;/h3&gt; 
&lt;p&gt;A web interface for viewing the data is available at: &lt;a href="https://tubvsig-so2sat-vm1.srv.mwn.de"&gt;website&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Note: Over the past few days, our web viewer has received nearly 280,000 access requests. Due to this unusually high traffic, some data may not load completely, which may result in a significant portion of buildings not being displayed.&lt;/p&gt; 
&lt;h3&gt;Full Data Download&lt;/h3&gt; 
&lt;p&gt;The full data can be downloaded from &lt;a href="https://mediatum.ub.tum.de/1782307"&gt;mediaTUM&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development Code&lt;/h2&gt; 
&lt;h3&gt;Global Building Polygon Generation using Satellite Data (Sec. 4.3)&lt;/h3&gt; 
&lt;p&gt;For codes related to building map extraction, regularization, polygonization, and simplification, i.e., generating building polygons from satellite images (Sec. 4.3.2, Sec. 4.3.3, and Sec. 4.3.4), please refer to &lt;code&gt;./im2bf&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Global Building Height Estimation (Sec. 4.4)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;For codes related to monocular height estimation using HTC-DC Net (Sec. 4.4.2), please refer to &lt;code&gt;./im2bh&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;For codes related to the global inference and uncertainty quantification (Sec. 4.4.3), please refer to &lt;code&gt;./infer_height&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Global LoD1 Building Model Generation (Sec. 4.5)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;For codes related to quality-guided building polygon fusion (Sec. 4.5.1), please refer to &lt;code&gt;./fuse_bf&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;For codes related to LoD1 building model generation (Sec. 4.5.2), please refer to &lt;code&gt;./make_lod1&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Visualization Code&lt;/h2&gt; 
&lt;p&gt;For codes to reproduce the plots in the manuscript, please refer to &lt;code&gt;./make_plots&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Code License&lt;/h2&gt; 
&lt;p&gt;MIT with Commons Clause (no commercial use allowed). See &lt;a href="https://github.com/zhu-xlab/GlobalBuildingAtlas/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How to cite&lt;/h2&gt; 
&lt;p&gt;If you find this dataset helpful in your work, please cite the following paper.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@Article{essd-17-6647-2025,
AUTHOR = {Zhu, X. X. and Chen, S. and Zhang, F. and Shi, Y. and Wang, Y.},
TITLE = {GlobalBuildingAtlas: an open global and complete dataset of building polygons, heights and LoD1 3D models},
JOURNAL = {Earth System Science Data},
VOLUME = {17},
YEAR = {2025},
NUMBER = {12},
PAGES = {6647--6668},
URL = {https://essd.copernicus.org/articles/17/6647/2025/},
DOI = {10.5194/essd-17-6647-2025}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>AsyncFuncAI/deepwiki-open</title>
      <link>https://github.com/AsyncFuncAI/deepwiki-open</link>
      <description>&lt;p&gt;Open Source DeepWiki: AI-Powered Wiki Generator for GitHub/Gitlab/Bitbucket Repositories. Join the discord: https://discord.gg/gMwThUMeme&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepWiki-Open&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/Deepwiki.png" alt="DeepWiki Banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DeepWiki&lt;/strong&gt; is my own implementation attempt of DeepWiki, automatically creates beautiful, interactive wikis for any GitHub, GitLab, or BitBucket repository! Just enter a repo name, and DeepWiki will:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Analyze the code structure&lt;/li&gt; 
 &lt;li&gt;Generate comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;Create visual diagrams to explain how everything works&lt;/li&gt; 
 &lt;li&gt;Organize it all into an easy-to-navigate wiki&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://buymeacoffee.com/sheing"&gt;&lt;img src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" alt="&amp;quot;Buy Me A Coffee&amp;quot;" /&gt;&lt;/a&gt; &lt;a href="https://tip.md/sng-asyncfunc"&gt;&lt;img src="https://tip.md/badge.svg?sanitize=true" alt="Tip in Crypto" /&gt;&lt;/a&gt; &lt;a href="https://x.com/sashimikun_void"&gt;&lt;img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Twitter/X" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/VQMBGR8u5v"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.zh.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.zh-tw.md"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.ja.md"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.es.md"&gt;EspaÃ±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.kr.md"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.vi.md"&gt;Tiáº¿ng Viá»‡t&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.pt-br.md"&gt;PortuguÃªs Brasileiro&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.fr.md"&gt;FranÃ§ais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.ru.md"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Documentation&lt;/strong&gt;: Turn any GitHub, GitLab or BitBucket repo into a wiki in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private Repository Support&lt;/strong&gt;: Securely access private repositories with personal access tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt;: AI-powered understanding of code structure and relationships&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Beautiful Diagrams&lt;/strong&gt;: Automatic Mermaid diagrams to visualize architecture and data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Navigation&lt;/strong&gt;: Simple, intuitive interface to explore the wiki&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ask Feature&lt;/strong&gt;: Chat with your repository using RAG-powered AI to get accurate answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepResearch&lt;/strong&gt;: Multi-turn research process that thoroughly investigates complex topics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Model Providers&lt;/strong&gt;: Support for Google Gemini, OpenAI, OpenRouter, and local Ollama models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Embeddings&lt;/strong&gt;: Choose between OpenAI, Google AI, or local Ollama embeddings for optimal performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Quick Start (Super Easy!)&lt;/h2&gt; 
&lt;h3&gt;Option 1: Using Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Create a .env file with your API keys
echo "GOOGLE_API_KEY=your_google_api_key" &amp;gt; .env
echo "OPENAI_API_KEY=your_openai_api_key" &amp;gt;&amp;gt; .env
# Optional: Use Google AI embeddings instead of OpenAI (recommended if using Google models)
echo "DEEPWIKI_EMBEDDER_TYPE=google" &amp;gt;&amp;gt; .env
# Optional: Add OpenRouter API key if you want to use OpenRouter models
echo "OPENROUTER_API_KEY=your_openrouter_api_key" &amp;gt;&amp;gt; .env
# Optional: Add Ollama host if not local. defaults to http://localhost:11434
echo "OLLAMA_HOST=your_ollama_host" &amp;gt;&amp;gt; .env
# Optional: Add Azure API key, endpoint and version if you want to use azure openai models
echo "AZURE_OPENAI_API_KEY=your_azure_openai_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_VERSION=your_azure_openai_version" &amp;gt;&amp;gt; .env
# Run with Docker Compose
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed instructions on using DeepWiki with Ollama and Docker, see &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/Ollama-instruction.md"&gt;Ollama Instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ &lt;strong&gt;Where to get these keys:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Get a Google API key from &lt;a href="https://makersuite.google.com/app/apikey"&gt;Google AI Studio&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Get an OpenAI API key from &lt;a href="https://platform.openai.com/api-keys"&gt;OpenAI Platform&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Get Azure OpenAI credentials from &lt;a href="https://portal.azure.com/"&gt;Azure Portal&lt;/a&gt; - create an Azure OpenAI resource and get the API key, endpoint, and API version&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Option 2: Manual Setup (Recommended)&lt;/h3&gt; 
&lt;h4&gt;Step 1: Set Up Your API Keys&lt;/h4&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the project root with these keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GOOGLE_API_KEY=your_google_api_key
OPENAI_API_KEY=your_openai_api_key
# Optional: Use Google AI embeddings (recommended if using Google models)
DEEPWIKI_EMBEDDER_TYPE=google
# Optional: Add this if you want to use OpenRouter models
OPENROUTER_API_KEY=your_openrouter_api_key
# Optional: Add this if you want to use Azure OpenAI models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
AZURE_OPENAI_VERSION=your_azure_openai_version
# Optional: Add Ollama host if not local. default: http://localhost:11434
OLLAMA_HOST=your_ollama_host
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Start the Backend&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python dependencies
python -m pip install poetry==1.8.2 &amp;amp;&amp;amp; poetry install -C api

# Start the API server
python -m api.main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 3: Start the Frontend&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install JavaScript dependencies
npm install
# or
yarn install

# Start the web app
npm run dev
# or
yarn dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 4: Use DeepWiki!&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser&lt;/li&gt; 
 &lt;li&gt;Enter a GitHub, GitLab, or Bitbucket repository (like &lt;code&gt;https://github.com/openai/codex&lt;/code&gt;, &lt;code&gt;https://github.com/microsoft/autogen&lt;/code&gt;, &lt;code&gt;https://gitlab.com/gitlab-org/gitlab&lt;/code&gt;, or &lt;code&gt;https://bitbucket.org/redradish/atlassian_app_versions&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;For private repositories, click "+ Add access tokens" and enter your GitHub or GitLab personal access token&lt;/li&gt; 
 &lt;li&gt;Click "Generate Wiki" and watch the magic happen!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ” How It Works&lt;/h2&gt; 
&lt;p&gt;DeepWiki uses AI to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and analyze the GitHub, GitLab, or Bitbucket repository (including private repos with token authentication)&lt;/li&gt; 
 &lt;li&gt;Create embeddings of the code for smart retrieval&lt;/li&gt; 
 &lt;li&gt;Generate documentation with context-aware AI (using Google Gemini, OpenAI, OpenRouter, Azure OpenAI, or local Ollama models)&lt;/li&gt; 
 &lt;li&gt;Create visual diagrams to explain code relationships&lt;/li&gt; 
 &lt;li&gt;Organize everything into a structured wiki&lt;/li&gt; 
 &lt;li&gt;Enable intelligent Q&amp;amp;A with the repository through the Ask feature&lt;/li&gt; 
 &lt;li&gt;Provide in-depth research capabilities with DeepResearch&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TD
    A[User inputs GitHub/GitLab/Bitbucket repo] --&amp;gt; AA{Private repo?}
    AA --&amp;gt;|Yes| AB[Add access token]
    AA --&amp;gt;|No| B[Clone Repository]
    AB --&amp;gt; B
    B --&amp;gt; C[Analyze Code Structure]
    C --&amp;gt; D[Create Code Embeddings]

    D --&amp;gt; M{Select Model Provider}
    M --&amp;gt;|Google Gemini| E1[Generate with Gemini]
    M --&amp;gt;|OpenAI| E2[Generate with OpenAI]
    M --&amp;gt;|OpenRouter| E3[Generate with OpenRouter]
    M --&amp;gt;|Local Ollama| E4[Generate with Ollama]
    M --&amp;gt;|Azure| E5[Generate with Azure]

    E1 --&amp;gt; E[Generate Documentation]
    E2 --&amp;gt; E
    E3 --&amp;gt; E
    E4 --&amp;gt; E
    E5 --&amp;gt; E

    D --&amp;gt; F[Create Visual Diagrams]
    E --&amp;gt; G[Organize as Wiki]
    F --&amp;gt; G
    G --&amp;gt; H[Interactive DeepWiki]

    classDef process stroke-width:2px;
    classDef data stroke-width:2px;
    classDef result stroke-width:2px;
    classDef decision stroke-width:2px;

    class A,D data;
    class AA,M decision;
    class B,C,E,F,G,AB,E1,E2,E3,E4,E5 process;
    class H result;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ› ï¸ Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;deepwiki/
â”œâ”€â”€ api/                  # Backend API server
â”‚   â”œâ”€â”€ main.py           # API entry point
â”‚   â”œâ”€â”€ api.py            # FastAPI implementation
â”‚   â”œâ”€â”€ rag.py            # Retrieval Augmented Generation
â”‚   â”œâ”€â”€ data_pipeline.py  # Data processing utilities
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”‚
â”œâ”€â”€ src/                  # Frontend Next.js app
â”‚   â”œâ”€â”€ app/              # Next.js app directory
â”‚   â”‚   â””â”€â”€ page.tsx      # Main application page
â”‚   â””â”€â”€ components/       # React components
â”‚       â””â”€â”€ Mermaid.tsx   # Mermaid diagram renderer
â”‚
â”œâ”€â”€ public/               # Static assets
â”œâ”€â”€ package.json          # JavaScript dependencies
â””â”€â”€ .env                  # Environment variables (create this)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ¤– Provider-Based Model Selection System&lt;/h2&gt; 
&lt;p&gt;DeepWiki now implements a flexible provider-based model selection system supporting multiple LLM providers:&lt;/p&gt; 
&lt;h3&gt;Supported Providers and Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Google&lt;/strong&gt;: Default &lt;code&gt;gemini-2.5-flash&lt;/code&gt;, also supports &lt;code&gt;gemini-2.5-flash-lite&lt;/code&gt;, &lt;code&gt;gemini-2.5-pro&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: Default &lt;code&gt;gpt-5-nano&lt;/code&gt;, also supports &lt;code&gt;gpt-5&lt;/code&gt;, &lt;code&gt;4o&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;: Access to multiple models via a unified API, including Claude, Llama, Mistral, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;: Default &lt;code&gt;gpt-4o&lt;/code&gt;, also supports &lt;code&gt;o4-mini&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Support for locally running open-source models like &lt;code&gt;llama3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Each provider requires its corresponding API key environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# API Keys
GOOGLE_API_KEY=your_google_api_key        # Required for Google Gemini models
OPENAI_API_KEY=your_openai_api_key        # Required for OpenAI models
OPENROUTER_API_KEY=your_openrouter_api_key # Required for OpenRouter models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key  #Required for Azure OpenAI models
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint  #Required for Azure OpenAI models
AZURE_OPENAI_VERSION=your_azure_openai_version  #Required for Azure OpenAI models

# OpenAI API Base URL Configuration
OPENAI_BASE_URL=https://custom-api-endpoint.com/v1  # Optional, for custom OpenAI API endpoints

# Ollama host
OLLAMA_HOST=your_ollama_host # Optional, if Ollama is not local. default: http://localhost:11434

# Configuration Directory
DEEPWIKI_CONFIG_DIR=/path/to/custom/config/dir  # Optional, for custom config file location
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;DeepWiki uses JSON configuration files to manage various aspects of the system:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;generator.json&lt;/code&gt;&lt;/strong&gt;: Configuration for text generation models&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defines available model providers (Google, OpenAI, OpenRouter, Azure, Ollama)&lt;/li&gt; 
   &lt;li&gt;Specifies default and available models for each provider&lt;/li&gt; 
   &lt;li&gt;Contains model-specific parameters like temperature and top_p&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;embedder.json&lt;/code&gt;&lt;/strong&gt;: Configuration for embedding models and text processing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defines embedding models for vector storage&lt;/li&gt; 
   &lt;li&gt;Contains retriever configuration for RAG&lt;/li&gt; 
   &lt;li&gt;Specifies text splitter settings for document chunking&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;repo.json&lt;/code&gt;&lt;/strong&gt;: Configuration for repository handling&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Contains file filters to exclude certain files and directories&lt;/li&gt; 
   &lt;li&gt;Defines repository size limits and processing rules&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default, these files are located in the &lt;code&gt;api/config/&lt;/code&gt; directory. You can customize their location using the &lt;code&gt;DEEPWIKI_CONFIG_DIR&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Custom Model Selection for Service Providers&lt;/h3&gt; 
&lt;p&gt;The custom model selection feature is specifically designed for service providers who need to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can offer multiple AI model choices to users within your organization&lt;/li&gt; 
 &lt;li&gt;You can quickly adapt to the rapidly evolving LLM landscape without code changes&lt;/li&gt; 
 &lt;li&gt;You can support specialized or fine-tuned models that aren't in the predefined list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Service providers can implement their model offerings by selecting from the predefined options or entering custom model identifiers in the frontend interface.&lt;/p&gt; 
&lt;h3&gt;Base URL Configuration for Enterprise Private Channels&lt;/h3&gt; 
&lt;p&gt;The OpenAI Client's base_url configuration is designed primarily for enterprise users with private API channels. This feature:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enables connection to private or enterprise-specific API endpoints&lt;/li&gt; 
 &lt;li&gt;Allows organizations to use their own self-hosted or custom-deployed LLM services&lt;/li&gt; 
 &lt;li&gt;Supports integration with third-party OpenAI API-compatible services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Coming Soon&lt;/strong&gt;: In future updates, DeepWiki will support a mode where users need to provide their own API keys in requests. This will allow enterprise customers with private channels to use their existing API arrangements without sharing credentials with the DeepWiki deployment.&lt;/p&gt; 
&lt;h2&gt;ğŸ§© Using OpenAI-Compatible Embedding Models (e.g., Alibaba Qwen)&lt;/h2&gt; 
&lt;p&gt;If you want to use embedding models compatible with the OpenAI API (such as Alibaba Qwen), follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Replace the contents of &lt;code&gt;api/config/embedder.json&lt;/code&gt; with those from &lt;code&gt;api/config/embedder_openai_compatible.json&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;In your project root &lt;code&gt;.env&lt;/code&gt; file, set the relevant environment variables, for example: &lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=your_api_key
OPENAI_BASE_URL=your_openai_compatible_endpoint
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;The program will automatically substitute placeholders in embedder.json with the values from your environment variables.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This allows you to seamlessly switch to any OpenAI-compatible embedding service without code changes.&lt;/p&gt; 
&lt;h2&gt;ğŸ§  Using Google AI Embeddings&lt;/h2&gt; 
&lt;p&gt;DeepWiki now supports Google AI's latest embedding models as an alternative to OpenAI embeddings. This provides better integration when you're already using Google Gemini models for text generation.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Latest Model&lt;/strong&gt;: Uses Google's &lt;code&gt;text-embedding-004&lt;/code&gt; model&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Same API Key&lt;/strong&gt;: Uses your existing &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt; (no additional setup required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Integration&lt;/strong&gt;: Optimized for use with Google Gemini text generation models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task-Specific&lt;/strong&gt;: Supports semantic similarity, retrieval, and classification tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Batch Processing&lt;/strong&gt;: Efficient processing of multiple texts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to Enable Google AI Embeddings&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Set the embedder type in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Your existing Google API key
GOOGLE_API_KEY=your_google_api_key

# Enable Google AI embeddings
DEEPWIKI_EMBEDDER_TYPE=google
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Docker Environment&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e DEEPWIKI_EMBEDDER_TYPE=google \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Docker Compose&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Add to your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GOOGLE_API_KEY=your_google_api_key
DEEPWIKI_EMBEDDER_TYPE=google
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Available Embedder Types&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;API Key Required&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openai&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI embeddings (default)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Uses &lt;code&gt;text-embedding-3-small&lt;/code&gt; model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;google&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google AI embeddings&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Uses &lt;code&gt;text-embedding-004&lt;/code&gt; model&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ollama&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Local Ollama embeddings&lt;/td&gt; 
   &lt;td&gt;None&lt;/td&gt; 
   &lt;td&gt;Requires local Ollama installation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Why Use Google AI Embeddings?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: If you're using Google Gemini for text generation, using Google embeddings provides better semantic consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Google's latest embedding model offers excellent performance for retrieval tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;: Competitive pricing compared to OpenAI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Additional Setup&lt;/strong&gt;: Uses the same API key as your text generation models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Switching Between Embedders&lt;/h3&gt; 
&lt;p&gt;You can easily switch between different embedding providers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use OpenAI embeddings (default)
export DEEPWIKI_EMBEDDER_TYPE=openai

# Use Google AI embeddings
export DEEPWIKI_EMBEDDER_TYPE=google

# Use local Ollama embeddings
export DEEPWIKI_EMBEDDER_TYPE=ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: When switching embedders, you may need to regenerate your repository embeddings as different models produce different vector spaces.&lt;/p&gt; 
&lt;h3&gt;Logging&lt;/h3&gt; 
&lt;p&gt;DeepWiki uses Python's built-in &lt;code&gt;logging&lt;/code&gt; module for diagnostic output. You can configure the verbosity and log file destination via environment variables:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).&lt;/td&gt; 
   &lt;td&gt;INFO&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LOG_FILE_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the log file. If set, logs will be written to this file.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;api/logs/application.log&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To enable debug logging and direct logs to a custom file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export LOG_LEVEL=DEBUG
export LOG_FILE_PATH=./debug.log
python -m api.main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or with Docker Compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LOG_LEVEL=DEBUG LOG_FILE_PATH=./debug.log docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker Compose, the container's &lt;code&gt;api/logs&lt;/code&gt; directory is bind-mounted to &lt;code&gt;./api/logs&lt;/code&gt; on your host (see the &lt;code&gt;volumes&lt;/code&gt; section in &lt;code&gt;docker-compose.yml&lt;/code&gt;), ensuring log files persist across restarts.&lt;/p&gt; 
&lt;p&gt;Alternatively, you can store these settings in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LOG_LEVEL=DEBUG
LOG_FILE_PATH=./debug.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Logging Path Security Considerations:&lt;/strong&gt; In production environments, ensure the &lt;code&gt;api/logs&lt;/code&gt; directory and any custom log file path are secured with appropriate filesystem permissions and access controls. The application enforces that &lt;code&gt;LOG_FILE_PATH&lt;/code&gt; resides within the project's &lt;code&gt;api/logs&lt;/code&gt; directory to prevent path traversal or unauthorized writes.&lt;/p&gt; 
&lt;h2&gt;ğŸ› ï¸ Advanced Setup&lt;/h2&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Gemini API key for AI generation and embeddings&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required for Google Gemini models and Google AI embeddings&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API key for embeddings and models&lt;/td&gt; 
   &lt;td&gt;Conditional&lt;/td&gt; 
   &lt;td&gt;Required if using OpenAI embeddings or models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key for alternative models&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use OpenRouter models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI API key&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI endpoint&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI version&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama Host (default: &lt;a href="http://localhost:11434"&gt;http://localhost:11434&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use external Ollama server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEEPWIKI_EMBEDDER_TYPE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Embedder type: &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;google&lt;/code&gt;, or &lt;code&gt;ollama&lt;/code&gt; (default: &lt;code&gt;openai&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Controls which embedding provider to use&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port for the API server (default: 8001)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;If you host API and frontend on the same machine, make sure change port of &lt;code&gt;SERVER_BASE_URL&lt;/code&gt; accordingly&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SERVER_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for the API server (default: &lt;a href="http://localhost:8001"&gt;http://localhost:8001&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Set to &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt; to enable authorization mode.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Defaults to &lt;code&gt;false&lt;/code&gt;. If enabled, &lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt; is required.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The secret code required for wiki generation when &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is enabled.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Only used if &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Key Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If using &lt;code&gt;DEEPWIKI_EMBEDDER_TYPE=openai&lt;/code&gt; (default): &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is required&lt;/li&gt; 
 &lt;li&gt;If using &lt;code&gt;DEEPWIKI_EMBEDDER_TYPE=google&lt;/code&gt;: &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt; is required&lt;/li&gt; 
 &lt;li&gt;If using &lt;code&gt;DEEPWIKI_EMBEDDER_TYPE=ollama&lt;/code&gt;: No API key required (local processing)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other API keys are only required when configuring and using models from the corresponding providers.&lt;/p&gt; 
&lt;h2&gt;Authorization Mode&lt;/h2&gt; 
&lt;p&gt;DeepWiki can be configured to run in an authorization mode, where wiki generation requires a valid authorization code. This is useful if you want to control who can use the generation feature. Restricts frontend initiation and protects cache deletion, but doesn't fully prevent backend generation if API endpoints are hit directly.&lt;/p&gt; 
&lt;p&gt;To enable authorization mode, set the following environment variables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt;: Set this to &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt;. When enabled, the frontend will display an input field for the authorization code.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt;: Set this to the desired secret code. Restricts frontend initiation and protects cache deletion, but doesn't fully prevent backend generation if API endpoints are hit directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is not set or is set to &lt;code&gt;false&lt;/code&gt; (or any other value than &lt;code&gt;true&lt;/code&gt;/&lt;code&gt;1&lt;/code&gt;), the authorization feature will be disabled, and no code will be required.&lt;/p&gt; 
&lt;h3&gt;Docker Setup&lt;/h3&gt; 
&lt;p&gt;You can use Docker to run DeepWiki:&lt;/p&gt; 
&lt;h4&gt;Running the Container&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pull the image from GitHub Container Registry
docker pull ghcr.io/asyncfuncai/deepwiki-open:latest

# Run the container with environment variables
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e OLLAMA_HOST=your_ollama_host \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \

  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command also mounts &lt;code&gt;~/.adalflow&lt;/code&gt; on your host to &lt;code&gt;/root/.adalflow&lt;/code&gt; in the container. This path is used to store:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cloned repositories (&lt;code&gt;~/.adalflow/repos/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Their embeddings and indexes (&lt;code&gt;~/.adalflow/databases/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Cached generated wiki content (&lt;code&gt;~/.adalflow/wikicache/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This ensures that your data persists even if the container is stopped or removed.&lt;/p&gt; 
&lt;p&gt;Or use the provided &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Edit the .env file with your API keys first
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(The &lt;code&gt;docker-compose.yml&lt;/code&gt; file is pre-configured to mount &lt;code&gt;~/.adalflow&lt;/code&gt; for data persistence, similar to the &lt;code&gt;docker run&lt;/code&gt; command above.)&lt;/p&gt; 
&lt;h4&gt;Using a .env file with Docker&lt;/h4&gt; 
&lt;p&gt;You can also mount a .env file to the container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a .env file with your API keys
echo "GOOGLE_API_KEY=your_google_api_key" &amp;gt; .env
echo "OPENAI_API_KEY=your_openai_api_key" &amp;gt;&amp;gt; .env
echo "OPENROUTER_API_KEY=your_openrouter_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_API_KEY=your_azure_openai_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_VERSION=your_azure_openai_version"  &amp;gt;&amp;gt;.env
echo "OLLAMA_HOST=your_ollama_host" &amp;gt;&amp;gt; .env

# Run the container with the .env file mounted
docker run -p 8001:8001 -p 3000:3000 \
  -v $(pwd)/.env:/app/.env \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command also mounts &lt;code&gt;~/.adalflow&lt;/code&gt; on your host to &lt;code&gt;/root/.adalflow&lt;/code&gt; in the container. This path is used to store:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cloned repositories (&lt;code&gt;~/.adalflow/repos/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Their embeddings and indexes (&lt;code&gt;~/.adalflow/databases/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Cached generated wiki content (&lt;code&gt;~/.adalflow/wikicache/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This ensures that your data persists even if the container is stopped or removed.&lt;/p&gt; 
&lt;h4&gt;Building the Docker image locally&lt;/h4&gt; 
&lt;p&gt;If you want to build the Docker image locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Build the Docker image
docker build -t deepwiki-open .

# Run the container
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \
  -e OLLAMA_HOST=your_ollama_host \
  deepwiki-open
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Self-Signed Certificates in Docker&lt;/h4&gt; 
&lt;p&gt;If you're in an environment that uses self-signed certificates, you can include them in the Docker build:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a directory for your certificates (default is &lt;code&gt;certs&lt;/code&gt; in your project root)&lt;/li&gt; 
 &lt;li&gt;Copy your &lt;code&gt;.crt&lt;/code&gt; or &lt;code&gt;.pem&lt;/code&gt; certificate files into this directory&lt;/li&gt; 
 &lt;li&gt;Build the Docker image:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build with default certificates directory (certs)
docker build .

# Or build with a custom certificates directory
docker build --build-arg CUSTOM_CERT_DIR=my-custom-certs .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;API Server Details&lt;/h3&gt; 
&lt;p&gt;The API server provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Repository cloning and indexing&lt;/li&gt; 
 &lt;li&gt;RAG (Retrieval Augmented Generation)&lt;/li&gt; 
 &lt;li&gt;Streaming chat completions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/api/README.md"&gt;API README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ”Œ OpenRouter Integration&lt;/h2&gt; 
&lt;p&gt;DeepWiki now supports &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; as a model provider, giving you access to hundreds of AI models through a single API:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Model Options&lt;/strong&gt;: Access models from OpenAI, Anthropic, Google, Meta, Mistral, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Configuration&lt;/strong&gt;: Just add your OpenRouter API key and select the model you want to use&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Efficiency&lt;/strong&gt;: Choose models that fit your budget and performance needs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Switching&lt;/strong&gt;: Toggle between different models without changing your code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to Use OpenRouter with DeepWiki&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Get an API Key&lt;/strong&gt;: Sign up at &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; and get your API key&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to Environment&lt;/strong&gt;: Add &lt;code&gt;OPENROUTER_API_KEY=your_key&lt;/code&gt; to your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enable in UI&lt;/strong&gt;: Check the "Use OpenRouter API" option on the homepage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Select Model&lt;/strong&gt;: Choose from popular models like GPT-4o, Claude 3.5 Sonnet, Gemini 2.0, and more&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;OpenRouter is particularly useful if you want to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try different models without signing up for multiple services&lt;/li&gt; 
 &lt;li&gt;Access models that might be restricted in your region&lt;/li&gt; 
 &lt;li&gt;Compare performance across different model providers&lt;/li&gt; 
 &lt;li&gt;Optimize for cost vs. performance based on your needs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤– Ask &amp;amp; DeepResearch Features&lt;/h2&gt; 
&lt;h3&gt;Ask Feature&lt;/h3&gt; 
&lt;p&gt;The Ask feature allows you to chat with your repository using Retrieval Augmented Generation (RAG):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context-Aware Responses&lt;/strong&gt;: Get accurate answers based on the actual code in your repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RAG-Powered&lt;/strong&gt;: The system retrieves relevant code snippets to provide grounded responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Streaming&lt;/strong&gt;: See responses as they're generated for a more interactive experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: The system maintains context between questions for more coherent interactions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DeepResearch Feature&lt;/h3&gt; 
&lt;p&gt;DeepResearch takes repository analysis to the next level with a multi-turn research process:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;In-Depth Investigation&lt;/strong&gt;: Thoroughly explores complex topics through multiple research iterations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Process&lt;/strong&gt;: Follows a clear research plan with updates and a comprehensive conclusion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Continuation&lt;/strong&gt;: The AI automatically continues research until reaching a conclusion (up to 5 iterations)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Stages&lt;/strong&gt;: 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;Research Plan&lt;/strong&gt;: Outlines the approach and initial findings&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Research Updates&lt;/strong&gt;: Builds on previous iterations with new insights&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Final Conclusion&lt;/strong&gt;: Provides a comprehensive answer based on all iterations&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use DeepResearch, simply toggle the "Deep Research" switch in the Ask interface before submitting your question.&lt;/p&gt; 
&lt;h2&gt;ğŸ“± Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/Interface.png" alt="DeepWiki Main Interface" /&gt; &lt;em&gt;The main interface of DeepWiki&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/privaterepo.png" alt="Private Repository Support" /&gt; &lt;em&gt;Access private repositories with personal access tokens&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/DeepResearch.png" alt="DeepResearch Feature" /&gt; &lt;em&gt;DeepResearch conducts multi-turn investigations for complex topics&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Demo Video&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/zGANs8US8B4"&gt;&lt;img src="https://img.youtube.com/vi/zGANs8US8B4/0.jpg" alt="DeepWiki Demo Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Watch DeepWiki in action!&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;â“ Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;API Key Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Missing environment variables"&lt;/strong&gt;: Make sure your &lt;code&gt;.env&lt;/code&gt; file is in the project root and contains the required API keys&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"API key not valid"&lt;/strong&gt;: Check that you've copied the full key correctly with no extra spaces&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"OpenRouter API error"&lt;/strong&gt;: Verify your OpenRouter API key is valid and has sufficient credits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Azure OpenAI API error"&lt;/strong&gt;: Verify your Azure OpenAI credentials (API key, endpoint, and version) are correct and the service is properly deployed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Problems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Cannot connect to API server"&lt;/strong&gt;: Make sure the API server is running on port 8001&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"CORS error"&lt;/strong&gt;: The API is configured to allow all origins, but if you're having issues, try running both frontend and backend on the same machine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Generation Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Error generating wiki"&lt;/strong&gt;: For very large repositories, try a smaller one first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Invalid repository format"&lt;/strong&gt;: Make sure you're using a valid GitHub, GitLab or Bitbucket URL format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Could not fetch repository structure"&lt;/strong&gt;: For private repositories, ensure you've entered a valid personal access token with appropriate permissions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Diagram rendering error"&lt;/strong&gt;: The app will automatically try to fix broken diagrams&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Solutions&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Restart both servers&lt;/strong&gt;: Sometimes a simple restart fixes most issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check console logs&lt;/strong&gt;: Open browser developer tools to see any JavaScript errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check API logs&lt;/strong&gt;: Look at the terminal where the API is running for Python errors&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Feel free to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open issues for bugs or feature requests&lt;/li&gt; 
 &lt;li&gt;Submit pull requests to improve the code&lt;/li&gt; 
 &lt;li&gt;Share your feedback and ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#AsyncFuncAI/deepwiki-open&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=AsyncFuncAI/deepwiki-open&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>infiniflow/ragflow</title>
      <link>https://github.com/infiniflow/ragflow</link>
      <description>&lt;p&gt;RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://demo.ragflow.io/"&gt; &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow/main/web/src/assets/logo-with-text.svg?sanitize=true" width="520" alt="ragflow logo" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-DBEDFA" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_zh.md"&gt;&lt;img alt="ç®€ä½“ä¸­æ–‡ç‰ˆè‡ªè¿°æ–‡ä»¶" src="https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_tzh.md"&gt;&lt;img alt="ç¹é«”ç‰ˆä¸­æ–‡è‡ªè¿°æ–‡ä»¶" src="https://img.shields.io/badge/ç¹é«”ä¸­æ–‡-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ja.md"&gt;&lt;img alt="æ—¥æœ¬èªã®README" src="https://img.shields.io/badge/æ—¥æœ¬èª-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_ko.md"&gt;&lt;img alt="í•œêµ­ì–´" src="https://img.shields.io/badge/í•œêµ­ì–´-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_id.md"&gt;&lt;img alt="Bahasa Indonesia" src="https://img.shields.io/badge/Bahasa Indonesia-DFE0E5" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/README_pt_br.md"&gt;&lt;img alt="PortuguÃªs(Brasil)" src="https://img.shields.io/badge/PortuguÃªs(Brasil)-DFE0E5" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://x.com/intent/follow?screen_name=infiniflowai" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;amp;color=%20%23f5f5f5" alt="follow on X(Twitter)" /&gt; &lt;/a&gt; &lt;a href="https://demo.ragflow.io" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/Online-Demo-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/infiniflow/ragflow" target="_blank"&gt; &lt;img src="https://img.shields.io/docker/pulls/infiniflow/ragflow?label=Docker%20Pulls&amp;amp;color=0db7ed&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="docker pull infiniflow/ragflow:v0.22.1" /&gt; &lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow/releases/latest"&gt; &lt;img src="https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;amp;label=Latest%20Release" alt="Latest Release" /&gt; &lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow/raw/main/LICENSE"&gt; &lt;img height="21" src="https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="license" /&gt; &lt;/a&gt; &lt;a href="https://deepwiki.com/infiniflow/ragflow"&gt; &lt;img alt="Ask DeepWiki" src="https://deepwiki.com/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://ragflow.io/docs/dev/"&gt;Document&lt;/a&gt; | &lt;a href="https://github.com/infiniflow/ragflow/issues/4214"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://twitter.com/infiniflowai"&gt;Twitter&lt;/a&gt; | &lt;a href="https://discord.gg/NjYzJD3GM3"&gt;Discord&lt;/a&gt; | &lt;a href="https://demo.ragflow.io"&gt;Demo&lt;/a&gt; &lt;/h4&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/ragflow-octoverse.png" width="1200" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/9064" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/9064" alt="infiniflow%2Fragflow | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;ğŸ“• Table of Contents&lt;/b&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ’¡ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-what-is-ragflow"&gt;What is RAGFlow?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ® &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-demo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“Œ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-latest-updates"&gt;Latest Updates&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸŒŸ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ” &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-system-architecture"&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ¬ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-get-started"&gt;Get Started&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”§ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-configurations"&gt;Configurations&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”§ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-build-a-docker-image"&gt;Build a Docker image&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ”¨ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-launch-service-from-source-for-development"&gt;Launch service from source for development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“š &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ“œ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ„ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ğŸ™Œ &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ’¡ What is RAGFlow?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ragflow.io/"&gt;RAGFlow&lt;/a&gt; is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs. It offers a streamlined RAG workflow adaptable to enterprises of any scale. Powered by a converged context engine and pre-built agent templates, RAGFlow enables developers to transform complex data into high-fidelity, production-ready AI systems with exceptional efficiency and precision.&lt;/p&gt; 
&lt;h2&gt;ğŸ® Demo&lt;/h2&gt; 
&lt;p&gt;Try our demo at &lt;a href="https://demo.ragflow.io"&gt;https://demo.ragflow.io&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/chunking.gif" width="1200" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/agentic-dark.gif" width="1200" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ”¥ Latest Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-11-19 Supports Gemini 3 Pro.&lt;/li&gt; 
 &lt;li&gt;2025-11-12 Supports data synchronization from Confluence, S3, Notion, Discord, Google Drive.&lt;/li&gt; 
 &lt;li&gt;2025-10-23 Supports MinerU &amp;amp; Docling as document parsing methods.&lt;/li&gt; 
 &lt;li&gt;2025-10-15 Supports orchestrable ingestion pipeline.&lt;/li&gt; 
 &lt;li&gt;2025-08-08 Supports OpenAI's latest GPT-5 series models.&lt;/li&gt; 
 &lt;li&gt;2025-08-01 Supports agentic workflow and MCP.&lt;/li&gt; 
 &lt;li&gt;2025-05-23 Adds a Python/JavaScript code executor component to Agent.&lt;/li&gt; 
 &lt;li&gt;2025-05-05 Supports cross-language query.&lt;/li&gt; 
 &lt;li&gt;2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‰ Stay Tuned&lt;/h2&gt; 
&lt;p&gt;â­ï¸ Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new releases! ğŸŒŸ&lt;/p&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba" width="1200" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒŸ Key Features&lt;/h2&gt; 
&lt;h3&gt;ğŸ­ &lt;strong&gt;"Quality in, quality out"&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/deepdoc/README.md"&gt;Deep document understanding&lt;/a&gt;-based knowledge extraction from unstructured data with complicated formats.&lt;/li&gt; 
 &lt;li&gt;Finds "needle in a data haystack" of literally unlimited tokens.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ± &lt;strong&gt;Template-based chunking&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Intelligent and explainable.&lt;/li&gt; 
 &lt;li&gt;Plenty of template options to choose from.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸŒ± &lt;strong&gt;Grounded citations with reduced hallucinations&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visualization of text chunking to allow human intervention.&lt;/li&gt; 
 &lt;li&gt;Quick view of the key references and traceable citations to support grounded answers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ” &lt;strong&gt;Compatibility with heterogeneous data sources&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ›€ &lt;strong&gt;Automated and effortless RAG workflow&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Streamlined RAG orchestration catered to both personal and large businesses.&lt;/li&gt; 
 &lt;li&gt;Configurable LLMs as well as embedding models.&lt;/li&gt; 
 &lt;li&gt;Multiple recall paired with fused re-ranking.&lt;/li&gt; 
 &lt;li&gt;Intuitive APIs for seamless integration with business.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ” System Architecture&lt;/h2&gt; 
&lt;div align="center" style="margin-top:20px;margin-bottom:20px;"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/31b0dd6f-ca4f-445a-9457-70cb44a381b2" width="1000" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ¬ Get Started&lt;/h2&gt; 
&lt;h3&gt;ğŸ“ Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU &amp;gt;= 4 cores&lt;/li&gt; 
 &lt;li&gt;RAM &amp;gt;= 16 GB&lt;/li&gt; 
 &lt;li&gt;Disk &amp;gt;= 50 GB&lt;/li&gt; 
 &lt;li&gt;Docker &amp;gt;= 24.0.0 &amp;amp; Docker Compose &amp;gt;= v2.26.1&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gvisor.dev/docs/user_guide/install/"&gt;gVisor&lt;/a&gt;: Required only if you intend to use the code executor (sandbox) feature of RAGFlow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you have not installed Docker on your local machine (Windows, Mac, or Linux), see &lt;a href="https://docs.docker.com/engine/install/"&gt;Install Docker Engine&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸš€ Start up the server&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure &lt;code&gt;vm.max_map_count&lt;/code&gt; &amp;gt;= 262144:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;To check the value of &lt;code&gt;vm.max_map_count&lt;/code&gt;:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;$ sysctl vm.max_map_count
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;Reset &lt;code&gt;vm.max_map_count&lt;/code&gt; to a value at least 262144 if it is not.&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# In this case, we set it to 262144:
$ sudo sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;This change will be reset after a system reboot. To ensure your change remains permanent, add or update the &lt;code&gt;vm.max_map_count&lt;/code&gt; value in &lt;strong&gt;/etc/sysctl.conf&lt;/strong&gt; accordingly:&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone https://github.com/infiniflow/ragflow.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start up the server using the pre-built Docker images:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] All Docker images are built for x86 platforms. We don't currently offer Docker images for ARM64. If you are on an ARM64 platform, follow &lt;a href="https://ragflow.io/docs/dev/build_docker_image"&gt;this guide&lt;/a&gt; to build a Docker image compatible with your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The command below downloads the &lt;code&gt;v0.22.1&lt;/code&gt; edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from &lt;code&gt;v0.22.1&lt;/code&gt;, update the &lt;code&gt;RAGFLOW_IMAGE&lt;/code&gt; variable accordingly in &lt;strong&gt;docker/.env&lt;/strong&gt; before using &lt;code&gt;docker compose&lt;/code&gt; to start the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;   $ cd ragflow/docker
  
   # git checkout v0.22.1
   # Optional: use a stable tag (see releases: https://github.com/infiniflow/ragflow/releases)
   # This step ensures the **entrypoint.sh** file in the code matches the Docker image version.
   
   # Use CPU for DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate DeepDoc tasks:
   # sed -i '1i DEVICE=gpu' .env
   # docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Prior to &lt;code&gt;v0.22.0&lt;/code&gt;, we provided both images with embedding models and slim images without embedding models. Details as follows:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RAGFlow image tag&lt;/th&gt; 
   &lt;th&gt;Image size (GB)&lt;/th&gt; 
   &lt;th&gt;Has embedding models?&lt;/th&gt; 
   &lt;th&gt;Stable?&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.21.1&lt;/td&gt; 
   &lt;td&gt;â‰ˆ9&lt;/td&gt; 
   &lt;td&gt;âœ”ï¸&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v0.21.1-slim&lt;/td&gt; 
   &lt;td&gt;â‰ˆ2&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;Stable release&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Starting with &lt;code&gt;v0.22.0&lt;/code&gt;, we ship only the slim edition and no longer append the &lt;strong&gt;-slim&lt;/strong&gt; suffix to the image tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt; &lt;p&gt;Check the server status after having the server up and running:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker logs -f docker-ragflow-cpu-1
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;
      ____   ___    ______ ______ __
     / __ \ /   |  / ____// ____// /____  _      __
    / /_/ // /| | / / __ / /_   / // __ \| | /| / /
   / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
  /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

 * Running on all addresses (0.0.0.0)
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a &lt;code&gt;network anormal&lt;/code&gt; error because, at that moment, your RAGFlow may not be fully initialized.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In your web browser, enter the IP address of your server and log in to RAGFlow.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;With the default settings, you only need to enter &lt;code&gt;http://IP_OF_YOUR_MACHINE&lt;/code&gt; (&lt;strong&gt;sans&lt;/strong&gt; port number) as the default HTTP serving port &lt;code&gt;80&lt;/code&gt; can be omitted when using the default configurations.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt;, select the desired LLM factory in &lt;code&gt;user_default_llm&lt;/code&gt; and update the &lt;code&gt;API_KEY&lt;/code&gt; field with the corresponding API key.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;See &lt;a href="https://ragflow.io/docs/dev/llm_api_key_setup"&gt;llm_api_key_setup&lt;/a&gt; for more information.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;em&gt;The show is on!&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ”§ Configurations&lt;/h2&gt; 
&lt;p&gt;When it comes to system configurations, you will need to manage the following files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/.env"&gt;.env&lt;/a&gt;: Keeps the fundamental setups for the system, such as &lt;code&gt;SVR_HTTP_PORT&lt;/code&gt;, &lt;code&gt;MYSQL_PASSWORD&lt;/code&gt;, and &lt;code&gt;MINIO_PASSWORD&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt;: Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;: The system relies on &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; to start up.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/README.md"&gt;./docker/README&lt;/a&gt; file provides a detailed description of the environment settings and service configurations which can be used as &lt;code&gt;${ENV_VARS}&lt;/code&gt; in the &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/service_conf.yaml.template"&gt;service_conf.yaml.template&lt;/a&gt; file.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To update the default HTTP serving port (80), go to &lt;a href="https://raw.githubusercontent.com/infiniflow/ragflow/main/docker/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; and change &lt;code&gt;80:80&lt;/code&gt; to &lt;code&gt;&amp;lt;YOUR_SERVING_PORT&amp;gt;:80&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Updates to the above configurations require a reboot of all containers to take effect:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Switch doc engine from Elasticsearch to Infinity&lt;/h3&gt; 
&lt;p&gt;RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to &lt;a href="https://github.com/infiniflow/infinity/"&gt;Infinity&lt;/a&gt;, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Stop all running containers:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker/docker-compose.yml down -v
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;code&gt;-v&lt;/code&gt; will delete the docker container volumes, and the existing data will be cleared.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;Set &lt;code&gt;DOC_ENGINE&lt;/code&gt; in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;infinity&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start the containers:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;$ docker compose -f docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Switching to Infinity on a Linux/arm64 machine is not yet officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ”§ Build a Docker image&lt;/h2&gt; 
&lt;p&gt;This image is approximately 2 GB in size and relies on external LLM and embedding services.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ”¨ Launch service from source for development&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;uv&lt;/code&gt; and &lt;code&gt;pre-commit&lt;/code&gt;, or skip this step if they are already installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pipx install uv pre-commit
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source code and install Python dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
uv sync --python 3.12 # install RAGFlow dependent python modules
uv run download_deps.py
pre-commit install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker/docker-compose-base.yml up -d
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the following line to &lt;code&gt;/etc/hosts&lt;/code&gt; to resolve all hosts specified in &lt;strong&gt;docker/.env&lt;/strong&gt; to &lt;code&gt;127.0.0.1&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;127.0.0.1       es01 infinity mysql minio redis sandbox-executor-manager
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you cannot access HuggingFace, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable to use a mirror site:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If your operating system does not have jemalloc, please install it as follows:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu
sudo apt-get install libjemalloc-dev
# CentOS
sudo yum install jemalloc
# OpenSUSE
sudo zypper install jemalloc
# macOS
sudo brew install jemalloc
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch backend service:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source .venv/bin/activate
export PYTHONPATH=$(pwd)
bash docker/launch_backend_service.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install frontend dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd web
npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch frontend service:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;The following output confirms a successful launch of the system:&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187" alt="" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Stop RAGFlow front-end and back-end service after development is complete:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pkill -f "ragflow_server.py|task_executor.py"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/configurations"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/release_notes"&gt;Release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/guides"&gt;User guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/developers"&gt;Developer guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/category/references"&gt;References&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ragflow.io/docs/dev/faq"&gt;FAQs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“œ Roadmap&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/infiniflow/ragflow/issues/4214"&gt;RAGFlow Roadmap 2025&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ„ Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/NjYzJD3GM3"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/infiniflowai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/infiniflow/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™Œ Contributing&lt;/h2&gt; 
&lt;p&gt;RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community. If you would like to be a part, review our &lt;a href="https://ragflow.io/docs/dev/contributing"&gt;Contribution Guidelines&lt;/a&gt; first.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png" /&gt; 
  &lt;img alt="vLLM" src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://docs.vllm.ai"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://blog.vllm.ai/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2309.06180"&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://x.com/vllm_project"&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Join us at the &lt;a href="https://events.linuxfoundation.org/pytorch-conference/"&gt;PyTorch Conference, October 22-23&lt;/a&gt; and &lt;a href="https://www.anyscale.com/ray-summit/2025"&gt;Ray Summit, November 3-5&lt;/a&gt; in San Francisco for our latest updates on vLLM and to meet the vLLM team! Register now for the largest vLLM community events of the year!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; ğŸ”¥&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/11] We hosted &lt;a href="https://luma.com/v0f647nv"&gt;vLLM Bangkok Meetup&lt;/a&gt;. We explored vLLM and LMCache inference and low-resource language adaptation with speakers from Embedded LLM, AMD, and Red Hat. Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1H0DS57F8HQ5q3kSOSoRmucPJWL3E0A_X?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/11] We hosted &lt;a href="https://luma.com/0gls27kb"&gt;the first vLLM Europe Meetup in Zurich&lt;/a&gt; focused on quantization, distributed inference, and reinforcement learning at scale with speakers from Mistral, IBM, and Red Hat. Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1UC9PTLCHYXQpOmJDSFg6Sljra3iVXzc09DeEI7dnxMc/edit?usp=sharing"&gt;here&lt;/a&gt; and recording &lt;a href="https://www.youtube.com/watch?v=6m6ZE6yVEDI"&gt;here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/11] We hosted &lt;a href="https://mp.weixin.qq.com/s/xSrYXjNgr1HbCP4ExYNG1w"&gt;vLLM Beijing Meetup&lt;/a&gt; focusing on distributed inference and diverse accelerator support with vLLM! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1nQJ8ZkLSjKxvu36sSHaceVXtttbLvvu-?usp=drive_link"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/10] We hosted &lt;a href="https://mp.weixin.qq.com/s/__xb4OyOsImz-9eAVrdlcg"&gt;vLLM Shanghai Meetup&lt;/a&gt; focused on hands-on vLLM inference optimization! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1KqwjsFJLfEsC8wlDugnrR61zsWHt94Q6"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/09] We hosted &lt;a href="https://luma.com/e80e0ymm"&gt;vLLM Toronto Meetup&lt;/a&gt; focused on tackling inference at scale and speculative decoding with speakers from NVIDIA and Red Hat! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1IYJYmJcu9fLpID5N5RbW_vO0XLo0CGOR14IXOjB61V8/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://mp.weixin.qq.com/s/k8ZBO1u2_2odgiKWH_GVTQ"&gt;vLLM Shenzhen Meetup&lt;/a&gt; focusing on the ecosystem around vLLM! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1Ua2SVKVSu-wp5vou_6ElraDt2bnKhiEA"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://www.sginnovate.com/event/vllm-sg-meet"&gt;vLLM Singapore Meetup&lt;/a&gt;. We shared V1 updates, disaggregated serving and MLLM speedups with speakers from Embedded LLM, AMD, WekaIO, and A*STAR. Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1ncf3GyqLdqFaB6IeB834E5TZJPLAOiXZ?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/08] We hosted &lt;a href="https://mp.weixin.qq.com/s/pDmAXHcN7Iqc8sUKgJgGtg"&gt;vLLM Shanghai Meetup&lt;/a&gt; focusing on building, developing, and integrating with vLLM! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1OvLx39wnCGy_WKq8SiVKf7YcxxYI3WCH"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] vLLM is now a hosted project under PyTorch Foundation! Please find the announcement &lt;a href="https://pytorch.org/blog/pytorch-foundation-welcomes-vllm/"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01] We are excited to announce the alpha release of vLLM V1: A major architectural upgrade with 1.7x speedup! Clean code, optimized execution loop, zero-overhead prefix caching, enhanced multimodal support, and more. Please check out our blog post &lt;a href="https://blog.vllm.ai/2025/01/27/v1-alpha-release.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/08] We hosted &lt;a href="https://luma.com/cgcgprmh"&gt;vLLM Korea Meetup&lt;/a&gt; with Red Hat and Rebellions! We shared the latest advancements in vLLM along with project spotlights from the vLLM Korea community. Please find the meetup slides &lt;a href="https://drive.google.com/file/d/1bcrrAE1rxUgx0mjIeOWT6hNe2RefC5Hm/view"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/08] We hosted &lt;a href="https://mp.weixin.qq.com/s/dgkWg1WFpWGO2jCdTqQHxA"&gt;vLLM Beijing Meetup&lt;/a&gt; focusing on large-scale LLM deployment! Please find the meetup slides &lt;a href="https://drive.google.com/drive/folders/1Pid6NSFLU43DZRi0EaTcPgXsAzDvbBqF"&gt;here&lt;/a&gt; and the recording &lt;a href="https://www.chaspark.com/#/live/1166916873711665152"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/05] We hosted &lt;a href="https://lu.ma/c1rqyf1f"&gt;NYC vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1_q_aW_ioMJWUImf1s1YM-ZhjXz8cUeL0IJvaquOYBeA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/04] We hosted &lt;a href="https://www.sginnovate.com/event/limited-availability-morning-evening-slots-remaining-inaugural-vllm-asia-developer-day"&gt;Asia Developer Day&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/19cp6Qu8u48ihB91A064XfaXruNYiBOUKrBxAmDOllOo/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/vllm-ollama"&gt;vLLM x Ollama Inference Night&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/16T2PDD1YwRnZ4Tu8Q5r6n53c5Lr5c73UV9Vd2_eBo4U/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg"&gt;the first vLLM China Meetup&lt;/a&gt;! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1REHvfQMKGnvz6p3Fd23HhSO4c8j5WPGZV0bKYLwnHyQ/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/7mu4k4xx"&gt;the East Coast vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1NHiv8EUFF1NLd3fEYODm56nDmL26lEeXCaDgyDlTsRs/edit#slide=id.g31441846c39_0_0"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/02] We hosted &lt;a href="https://lu.ma/h7g3kuj9"&gt;the ninth vLLM meetup&lt;/a&gt; with Meta! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1jzC_PZVXrVNSFVCW-V4cFXb6pn7zZ2CyP_Flwo05aqg/edit?usp=sharing"&gt;here&lt;/a&gt; and AMD &lt;a href="https://drive.google.com/file/d/1Zk5qEJIkTmlQ2eQcXQZlljAx3m9s7nwn/view?usp=sharing"&gt;here&lt;/a&gt;. The slides from Meta will not be posted.&lt;/li&gt; 
  &lt;li&gt;[2025/01] We hosted &lt;a href="https://lu.ma/zep56hui"&gt;the eighth vLLM meetup&lt;/a&gt; with Google Cloud! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1epVkt4Zu8Jz_S5OhEHPc798emsYh2BwYfRuDDVEF7u4/edit?usp=sharing"&gt;here&lt;/a&gt;, and Google Cloud team &lt;a href="https://drive.google.com/file/d/1h24pHewANyRL11xy5dXUbvRC9F9Kkjix/view?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/12] vLLM joins &lt;a href="https://pytorch.org/blog/vllm-joins-pytorch"&gt;pytorch ecosystem&lt;/a&gt;! Easy, Fast, and Cheap LLM Serving for Everyone!&lt;/li&gt; 
  &lt;li&gt;[2024/11] We hosted &lt;a href="https://lu.ma/h0qvrajz"&gt;the seventh vLLM meetup&lt;/a&gt; with Snowflake! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1e3CxQBV3JsfGp30SwyvS3eM_tW-ghOhJ9PAJGK6KR54/edit?usp=sharing"&gt;here&lt;/a&gt;, and Snowflake team &lt;a href="https://docs.google.com/presentation/d/1qF3RkDAbOULwz9WK5TOltt2fE9t6uIc_hVNLFAaQX6A/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/10] We have just created a developer slack (&lt;a href="https://slack.vllm.ai"&gt;slack.vllm.ai&lt;/a&gt;) focusing on coordinating contributions and discussing features. Please feel free to join us there!&lt;/li&gt; 
  &lt;li&gt;[2024/10] Ray Summit 2024 held a special track for vLLM! Please find the opening talk slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/1B_KQxpHBTRa_mDF-tR6i8rWdOU5QoTZNcEg2MKZxEHM/edit?usp=sharing"&gt;here&lt;/a&gt;. Learn more from the &lt;a href="https://www.youtube.com/playlist?list=PLzTswPQNepXl6AQwifuwUImLPFRVpksjR"&gt;talks&lt;/a&gt; from other vLLM contributors and users!&lt;/li&gt; 
  &lt;li&gt;[2024/09] We hosted &lt;a href="https://lu.ma/87q3nvnh"&gt;the sixth vLLM meetup&lt;/a&gt; with NVIDIA! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1wrLGwytQfaOTd5wCGSPNhoaW3nq0E-9wqyP7ny93xRs/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] We hosted &lt;a href="https://lu.ma/lp0gyjqr"&gt;the fifth vLLM meetup&lt;/a&gt; with AWS! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1RgUD8aCfcHocghoP3zmXzck9vX3RCI9yfUAB2Bbcl4Y/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] In partnership with Meta, vLLM officially supports Llama 3.1 with FP8 quantization and pipeline parallelism! Please check out our blog post &lt;a href="https://blog.vllm.ai/2024/07/23/llama31.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/06] We hosted &lt;a href="https://lu.ma/agivllm"&gt;the fourth vLLM meetup&lt;/a&gt; with Cloudflare and BentoML! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/04] We hosted &lt;a href="https://robloxandvllmmeetup2024.splashthat.com/"&gt;the third vLLM meetup&lt;/a&gt; with Roblox! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1A--47JAK4BJ39t954HyTkvtfwn0fkqtsL8NGFuslReM/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/01] We hosted &lt;a href="https://lu.ma/ygxbpzhl"&gt;the second vLLM meetup&lt;/a&gt; with IBM! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/12mI2sKABnUw5RBWXDYY-HtHth4iMSNcEoQ10jDQbxgA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/10] We hosted &lt;a href="https://lu.ma/first-vllm-meetup"&gt;the first vLLM meetup&lt;/a&gt; with a16z! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/08] We would like to express our sincere gratitude to &lt;a href="https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/"&gt;Andreessen Horowitz&lt;/a&gt; (a16z) for providing a generous grant to support the open-source development and research of vLLM.&lt;/li&gt; 
  &lt;li&gt;[2023/06] We officially released vLLM! FastChat-vLLM integration has powered &lt;a href="https://chat.lmsys.org"&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid-April. Check out our &lt;a href="https://vllm.ai"&gt;blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href="https://sky.cs.berkeley.edu"&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href="https://blog.vllm.ai/2023/06/20/vllm.html"&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2309.05516"&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support for NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, Arm CPUs, and TPU. Additionally, support for diverse hardware plugins such as Intel Gaudi, IBM Spyre and Huawei Ascend.&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source"&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.vllm.ai/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://docs.vllm.ai/en/latest/contributing/index.html"&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;vLLM is a community project. Our compute resources for development and testing are supported by the following organizations. Thank you for your support!&lt;/p&gt; 
&lt;!-- Note: Please sort them in alphabetical order. --&gt; 
&lt;!-- Note: Please keep these consistent with docs/community/sponsors.md --&gt; 
&lt;p&gt;Cash Donations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a16z&lt;/li&gt; 
 &lt;li&gt;Dropbox&lt;/li&gt; 
 &lt;li&gt;Sequoia Capital&lt;/li&gt; 
 &lt;li&gt;Skywork AI&lt;/li&gt; 
 &lt;li&gt;ZhenFund&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compute Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alibaba Cloud&lt;/li&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
 &lt;li&gt;Anyscale&lt;/li&gt; 
 &lt;li&gt;Arm&lt;/li&gt; 
 &lt;li&gt;AWS&lt;/li&gt; 
 &lt;li&gt;Crusoe Cloud&lt;/li&gt; 
 &lt;li&gt;Databricks&lt;/li&gt; 
 &lt;li&gt;DeepInfra&lt;/li&gt; 
 &lt;li&gt;Google Cloud&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Lambda Lab&lt;/li&gt; 
 &lt;li&gt;Nebius&lt;/li&gt; 
 &lt;li&gt;Novita AI&lt;/li&gt; 
 &lt;li&gt;NVIDIA&lt;/li&gt; 
 &lt;li&gt;Replicate&lt;/li&gt; 
 &lt;li&gt;Roblox&lt;/li&gt; 
 &lt;li&gt;RunPod&lt;/li&gt; 
 &lt;li&gt;Trainy&lt;/li&gt; 
 &lt;li&gt;UC Berkeley&lt;/li&gt; 
 &lt;li&gt;UC San Diego&lt;/li&gt; 
 &lt;li&gt;Volcengine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Slack Sponsor: Anyscale&lt;/p&gt; 
&lt;p&gt;We also have an official fundraising venue through &lt;a href="https://opencollective.com/vllm"&gt;OpenCollective&lt;/a&gt;. We plan to use the fund to support the development, maintenance, and adoption of vLLM.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href="https://arxiv.org/abs/2309.06180"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href="https://github.com/vllm-project/vllm/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href="https://discuss.vllm.ai"&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href="https://slack.vllm.ai"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub's &lt;a href="https://github.com/vllm-project/vllm/security/advisories"&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href="mailto:vllm-questions@lists.berkeley.edu"&gt;vllm-questions@lists.berkeley.edu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM's logo, please refer to &lt;a href="https://github.com/vllm-project/media-kit"&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>