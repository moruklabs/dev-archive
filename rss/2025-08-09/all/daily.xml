<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Fri, 08 Aug 2025 01:29:36 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png"&gt; 
  &lt;img alt="vLLM" src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png" width="55%"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://docs.vllm.ai"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://blog.vllm.ai/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2309.06180"&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://x.com/vllm_project"&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; 🔥&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/05] We hosted &lt;a href="https://lu.ma/c1rqyf1f"&gt;NYC vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1_q_aW_ioMJWUImf1s1YM-ZhjXz8cUeL0IJvaquOYBeA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] vLLM is now a hosted project under PyTorch Foundation! Please find the announcement &lt;a href="https://pytorch.org/blog/pytorch-foundation-welcomes-vllm/"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/04] We hosted &lt;a href="https://www.sginnovate.com/event/limited-availability-morning-evening-slots-remaining-inaugural-vllm-asia-developer-day"&gt;Asia Developer Day&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/19cp6Qu8u48ihB91A064XfaXruNYiBOUKrBxAmDOllOo/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01] We are excited to announce the alpha release of vLLM V1: A major architectural upgrade with 1.7x speedup! Clean code, optimized execution loop, zero-overhead prefix caching, enhanced multimodal support, and more. Please check out our blog post &lt;a href="https://blog.vllm.ai/2025/01/27/v1-alpha-release.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/vllm-ollama"&gt;vLLM x Ollama Inference Night&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/16T2PDD1YwRnZ4Tu8Q5r6n53c5Lr5c73UV9Vd2_eBo4U/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg"&gt;the first vLLM China Meetup&lt;/a&gt;! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1REHvfQMKGnvz6p3Fd23HhSO4c8j5WPGZV0bKYLwnHyQ/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/7mu4k4xx"&gt;the East Coast vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1NHiv8EUFF1NLd3fEYODm56nDmL26lEeXCaDgyDlTsRs/edit#slide=id.g31441846c39_0_0"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/02] We hosted &lt;a href="https://lu.ma/h7g3kuj9"&gt;the ninth vLLM meetup&lt;/a&gt; with Meta! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1jzC_PZVXrVNSFVCW-V4cFXb6pn7zZ2CyP_Flwo05aqg/edit?usp=sharing"&gt;here&lt;/a&gt; and AMD &lt;a href="https://drive.google.com/file/d/1Zk5qEJIkTmlQ2eQcXQZlljAx3m9s7nwn/view?usp=sharing"&gt;here&lt;/a&gt;. The slides from Meta will not be posted.&lt;/li&gt; 
  &lt;li&gt;[2025/01] We hosted &lt;a href="https://lu.ma/zep56hui"&gt;the eighth vLLM meetup&lt;/a&gt; with Google Cloud! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1epVkt4Zu8Jz_S5OhEHPc798emsYh2BwYfRuDDVEF7u4/edit?usp=sharing"&gt;here&lt;/a&gt;, and Google Cloud team &lt;a href="https://drive.google.com/file/d/1h24pHewANyRL11xy5dXUbvRC9F9Kkjix/view?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/12] vLLM joins &lt;a href="https://pytorch.org/blog/vllm-joins-pytorch"&gt;pytorch ecosystem&lt;/a&gt;! Easy, Fast, and Cheap LLM Serving for Everyone!&lt;/li&gt; 
  &lt;li&gt;[2024/11] We hosted &lt;a href="https://lu.ma/h0qvrajz"&gt;the seventh vLLM meetup&lt;/a&gt; with Snowflake! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1e3CxQBV3JsfGp30SwyvS3eM_tW-ghOhJ9PAJGK6KR54/edit?usp=sharing"&gt;here&lt;/a&gt;, and Snowflake team &lt;a href="https://docs.google.com/presentation/d/1qF3RkDAbOULwz9WK5TOltt2fE9t6uIc_hVNLFAaQX6A/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/10] We have just created a developer slack (&lt;a href="https://slack.vllm.ai"&gt;slack.vllm.ai&lt;/a&gt;) focusing on coordinating contributions and discussing features. Please feel free to join us there!&lt;/li&gt; 
  &lt;li&gt;[2024/10] Ray Summit 2024 held a special track for vLLM! Please find the opening talk slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/1B_KQxpHBTRa_mDF-tR6i8rWdOU5QoTZNcEg2MKZxEHM/edit?usp=sharing"&gt;here&lt;/a&gt;. Learn more from the &lt;a href="https://www.youtube.com/playlist?list=PLzTswPQNepXl6AQwifuwUImLPFRVpksjR"&gt;talks&lt;/a&gt; from other vLLM contributors and users!&lt;/li&gt; 
  &lt;li&gt;[2024/09] We hosted &lt;a href="https://lu.ma/87q3nvnh"&gt;the sixth vLLM meetup&lt;/a&gt; with NVIDIA! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1wrLGwytQfaOTd5wCGSPNhoaW3nq0E-9wqyP7ny93xRs/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] We hosted &lt;a href="https://lu.ma/lp0gyjqr"&gt;the fifth vLLM meetup&lt;/a&gt; with AWS! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1RgUD8aCfcHocghoP3zmXzck9vX3RCI9yfUAB2Bbcl4Y/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] In partnership with Meta, vLLM officially supports Llama 3.1 with FP8 quantization and pipeline parallelism! Please check out our blog post &lt;a href="https://blog.vllm.ai/2024/07/23/llama31.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/06] We hosted &lt;a href="https://lu.ma/agivllm"&gt;the fourth vLLM meetup&lt;/a&gt; with Cloudflare and BentoML! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/04] We hosted &lt;a href="https://robloxandvllmmeetup2024.splashthat.com/"&gt;the third vLLM meetup&lt;/a&gt; with Roblox! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1A--47JAK4BJ39t954HyTkvtfwn0fkqtsL8NGFuslReM/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/01] We hosted &lt;a href="https://lu.ma/ygxbpzhl"&gt;the second vLLM meetup&lt;/a&gt; with IBM! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/12mI2sKABnUw5RBWXDYY-HtHth4iMSNcEoQ10jDQbxgA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/10] We hosted &lt;a href="https://lu.ma/first-vllm-meetup"&gt;the first vLLM meetup&lt;/a&gt; with a16z! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/08] We would like to express our sincere gratitude to &lt;a href="https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/"&gt;Andreessen Horowitz&lt;/a&gt; (a16z) for providing a generous grant to support the open-source development and research of vLLM.&lt;/li&gt; 
  &lt;li&gt;[2023/06] We officially released vLLM! FastChat-vLLM integration has powered &lt;a href="https://chat.lmsys.org"&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid-April. Check out our &lt;a href="https://vllm.ai"&gt;blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href="https://sky.cs.berkeley.edu"&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href="https://blog.vllm.ai/2023/06/20/vllm.html"&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2309.05516"&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, TPU, and AWS Neuron&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source"&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.vllm.ai/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://docs.vllm.ai/en/latest/contributing/index.html"&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;vLLM is a community project. Our compute resources for development and testing are supported by the following organizations. Thank you for your support!&lt;/p&gt; 
&lt;!-- Note: Please sort them in alphabetical order. --&gt; 
&lt;!-- Note: Please keep these consistent with docs/community/sponsors.md --&gt; 
&lt;p&gt;Cash Donations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a16z&lt;/li&gt; 
 &lt;li&gt;Dropbox&lt;/li&gt; 
 &lt;li&gt;Sequoia Capital&lt;/li&gt; 
 &lt;li&gt;Skywork AI&lt;/li&gt; 
 &lt;li&gt;ZhenFund&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compute Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
 &lt;li&gt;Anyscale&lt;/li&gt; 
 &lt;li&gt;AWS&lt;/li&gt; 
 &lt;li&gt;Crusoe Cloud&lt;/li&gt; 
 &lt;li&gt;Databricks&lt;/li&gt; 
 &lt;li&gt;DeepInfra&lt;/li&gt; 
 &lt;li&gt;Google Cloud&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Lambda Lab&lt;/li&gt; 
 &lt;li&gt;Nebius&lt;/li&gt; 
 &lt;li&gt;Novita AI&lt;/li&gt; 
 &lt;li&gt;NVIDIA&lt;/li&gt; 
 &lt;li&gt;Replicate&lt;/li&gt; 
 &lt;li&gt;Roblox&lt;/li&gt; 
 &lt;li&gt;RunPod&lt;/li&gt; 
 &lt;li&gt;Trainy&lt;/li&gt; 
 &lt;li&gt;UC Berkeley&lt;/li&gt; 
 &lt;li&gt;UC San Diego&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Slack Sponsor: Anyscale&lt;/p&gt; 
&lt;p&gt;We also have an official fundraising venue through &lt;a href="https://opencollective.com/vllm"&gt;OpenCollective&lt;/a&gt;. We plan to use the fund to support the development, maintenance, and adoption of vLLM.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href="https://arxiv.org/abs/2309.06180"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href="https://github.com/vllm-project/vllm/issues"&gt;Issues&lt;/a&gt; or &lt;a href="https://github.com/vllm-project/vllm/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href="https://discuss.vllm.ai"&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href="https://slack.vllm.ai"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub's &lt;a href="https://github.com/vllm-project/vllm/security/advisories"&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href="mailto:vllm-questions@lists.berkeley.edu"&gt;vllm-questions@lists.berkeley.edu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM's logo, please refer to &lt;a href="https://github.com/vllm-project/media-kit"&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ollama/ollama</title>
      <link>https://github.com/ollama/ollama</link>
      <description>&lt;p&gt;Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
  &amp;nbsp; 
 &lt;a href="https://ollama.com"&gt; &lt;img alt="ollama" width="240" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;Ollama&lt;/h1&gt; 
&lt;p&gt;Get up and running with large language models.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/Ollama.dmg"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ollama.com/download/OllamaSetup.exe"&gt;Download&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -fsSL https://ollama.com/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/ollama/ollama/raw/main/docs/linux.md"&gt;Manual install instructions&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The official &lt;a href="https://hub.docker.com/r/ollama/ollama"&gt;Ollama Docker image&lt;/a&gt; &lt;code&gt;ollama/ollama&lt;/code&gt; is available on Docker Hub.&lt;/p&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-python"&gt;ollama-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama/ollama-js"&gt;ollama-js&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/ollama"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/ollama"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To run and chat with &lt;a href="https://ollama.com/library/gemma3"&gt;Gemma 3&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run gemma3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model library&lt;/h2&gt; 
&lt;p&gt;Ollama supports a list of models available on &lt;a href="https://ollama.com/library" title="ollama model library"&gt;ollama.com/library&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some example models that can be downloaded:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Parameters&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;815MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;4B&lt;/td&gt; 
   &lt;td&gt;3.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;12B&lt;/td&gt; 
   &lt;td&gt;8.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:12b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemma 3&lt;/td&gt; 
   &lt;td&gt;27B&lt;/td&gt; 
   &lt;td&gt;17GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run gemma3:27b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QwQ&lt;/td&gt; 
   &lt;td&gt;32B&lt;/td&gt; 
   &lt;td&gt;20GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run qwq&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1&lt;/td&gt; 
   &lt;td&gt;671B&lt;/td&gt; 
   &lt;td&gt;404GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run deepseek-r1:671b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;109B&lt;/td&gt; 
   &lt;td&gt;67GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:scout&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 4&lt;/td&gt; 
   &lt;td&gt;400B&lt;/td&gt; 
   &lt;td&gt;245GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama4:maverick&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3&lt;/td&gt; 
   &lt;td&gt;70B&lt;/td&gt; 
   &lt;td&gt;43GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;3B&lt;/td&gt; 
   &lt;td&gt;2.0GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2&lt;/td&gt; 
   &lt;td&gt;1B&lt;/td&gt; 
   &lt;td&gt;1.3GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2:1b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;11B&lt;/td&gt; 
   &lt;td&gt;7.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.2 Vision&lt;/td&gt; 
   &lt;td&gt;90B&lt;/td&gt; 
   &lt;td&gt;55GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.2-vision:90b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.7GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1&lt;/td&gt; 
   &lt;td&gt;405B&lt;/td&gt; 
   &lt;td&gt;231GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama3.1:405b&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4&lt;/td&gt; 
   &lt;td&gt;14B&lt;/td&gt; 
   &lt;td&gt;9.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phi 4 Mini&lt;/td&gt; 
   &lt;td&gt;3.8B&lt;/td&gt; 
   &lt;td&gt;2.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run phi4-mini&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run mistral&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Moondream 2&lt;/td&gt; 
   &lt;td&gt;1.4B&lt;/td&gt; 
   &lt;td&gt;829MB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run moondream&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Neural Chat&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run neural-chat&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Starling&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.1GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run starling-lm&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Llama&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run codellama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 2 Uncensored&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;3.8GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llama2-uncensored&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLaVA&lt;/td&gt; 
   &lt;td&gt;7B&lt;/td&gt; 
   &lt;td&gt;4.5GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run llava&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Granite-3.3&lt;/td&gt; 
   &lt;td&gt;8B&lt;/td&gt; 
   &lt;td&gt;4.9GB&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;ollama run granite3.3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Customize a model&lt;/h2&gt; 
&lt;h3&gt;Import from GGUF&lt;/h3&gt; 
&lt;p&gt;Ollama supports importing GGUF models in the Modelfile:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a file named &lt;code&gt;Modelfile&lt;/code&gt;, with a &lt;code&gt;FROM&lt;/code&gt; instruction with the local filepath to the model you want to import.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;FROM ./vicuna-33b.Q4_0.gguf
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the model in Ollama&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama create example -f Modelfile
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the model&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama run example
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Import from Safetensors&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/import.md"&gt;guide&lt;/a&gt; on importing models for more information.&lt;/p&gt; 
&lt;h3&gt;Customize a prompt&lt;/h3&gt; 
&lt;p&gt;Models from the Ollama library can be customized with a prompt. For example, to customize the &lt;code&gt;llama3.2&lt;/code&gt; model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a &lt;code&gt;Modelfile&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, create and run the model:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ollama create mario -f ./Modelfile
ollama run mario
&amp;gt;&amp;gt;&amp;gt; hi
Hello! It's your friend Mario.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on working with a Modelfile, see the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/modelfile.md"&gt;Modelfile&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;CLI Reference&lt;/h2&gt; 
&lt;h3&gt;Create a model&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama create&lt;/code&gt; is used to create a model from a Modelfile.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama create mymodel -f ./Modelfile
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pull a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This command can also be used to update a local model. Only the diff will be pulled.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Remove a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama rm llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Copy a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama cp llama3.2 my-model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiline input&lt;/h3&gt; 
&lt;p&gt;For multiline input, you can wrap text with &lt;code&gt;"""&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; """Hello,
... world!
... """
I'm a basic program that prints the famous "Hello, world!" message to the console.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multimodal models&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;ollama run llava "What's in this image? /Users/jmorgan/Desktop/smile.png"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: The image features a yellow smiley face, which is likely the central focus of the picture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Pass the prompt as an argument&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run llama3.2 "Summarize this file: $(cat README.md)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Show model information&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama show llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List models on your computer&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;List which models are currently loaded&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Stop a model which is currently running&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama stop llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;ollama serve&lt;/code&gt; is used when you want to start ollama without running the desktop application.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ollama/ollama/raw/main/docs/development.md"&gt;developer guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Running local builds&lt;/h3&gt; 
&lt;p&gt;Next, start the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, in a separate shell, run a model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ollama run llama3.2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;REST API&lt;/h2&gt; 
&lt;p&gt;Ollama has a REST API for running and managing models.&lt;/p&gt; 
&lt;h3&gt;Generate a response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt":"Why is the sky blue?"
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chat with a model&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [
    { "role": "user", "content": "why is the sky blue?" }
  ]
}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md"&gt;API documentation&lt;/a&gt; for all endpoints.&lt;/p&gt; 
&lt;h2&gt;Community Integrations&lt;/h2&gt; 
&lt;h3&gt;Web &amp;amp; Desktop&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-webui/open-webui"&gt;Open WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat (macOS with ReactNative)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted (macOS native)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fmaclen/hollama"&gt;Hollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParisNeo/lollms-webui"&gt;Lollms-Webui&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danny-avila/LibreChat"&gt;LibreChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bionic-gpt/bionic-gpt"&gt;Bionic GPT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rtcfirefly/ollama-ui"&gt;HTML UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jikkuatwork/saddle"&gt;Saddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tagspaces.org"&gt;TagSpaces&lt;/a&gt; (A platform for file-based apps, &lt;a href="https://docs.tagspaces.org/ai/"&gt;utilizing Ollama&lt;/a&gt; for the generation of tags and descriptions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivanfioravanti/chatbot-ollama"&gt;Chatbot UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mckaywrigley/chatbot-ui"&gt;Chatbot UI v2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file"&gt;Typescript UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richawo/minimal-llm-ui"&gt;Minimalistic React UI for Ollama Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/Ollamac"&gt;Ollamac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enricoros/big-AGI"&gt;big-AGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheshire-cat-ai/core"&gt;Cheshire Cat assistant framework&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;Amica&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BruceMacD/chatd"&gt;chatd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kghandour/Ollama-SwiftUI"&gt;Ollama-SwiftUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui"&gt;NextJS Web Interface for Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://msty.app"&gt;Msty&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bin-Huang/Chatbox"&gt;Chatbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot"&gt;WinForm Ollama Copilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web"&gt;NextChat&lt;/a&gt; with &lt;a href="https://docs.nextchat.dev/models/ollama"&gt;Get Started Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmo80/alpaca-webui"&gt;Alpaca WebUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enoch1118/ollamaGUI"&gt;OllamaGUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/InternLM/OpenAOE"&gt;OpenAOE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/leonid20000/OdinRunes"&gt;Odin Runes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mrdjohnson/llm-x"&gt;LLM-X&lt;/a&gt; (Progressive Web App)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mintplex-Labs/anything-llm"&gt;AnythingLLM (Docker + MacOs/Windows/Linux native app)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_basic_chat"&gt;Ollama Basic Chat: Uses HyperDiv Reactive UI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drazdra/ollama-chats"&gt;Ollama-chats RPG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://intellibar.app/"&gt;IntelliBar&lt;/a&gt; (AI-powered assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/jirapt"&gt;Jirapt&lt;/a&gt; (Jira Integration to generate issues, tasks, epics)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AliAhmedNada/ojira"&gt;ojira&lt;/a&gt; (Jira chrome plugin to easily generate descriptions for tasks)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/QA-Pilot"&gt;QA-Pilot&lt;/a&gt; (Interactive chat tool that can leverage Ollama models for rapid understanding and navigation of GitHub code repositories)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sugarforever/chat-ollama"&gt;ChatOllama&lt;/a&gt; (Open Source Chatbot based on Ollama with Knowledge Bases)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat"&gt;CRAG Ollama Chat&lt;/a&gt; (Simple Web Search with Corrective RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; (Open-source Retrieval-Augmented Generation engine based on deep document understanding)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold"&gt;StreamDeploy&lt;/a&gt; (LLM Application Scaffold)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/swuecho/chat"&gt;chat&lt;/a&gt; (chat web app for teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat"&gt;Lobe Chat&lt;/a&gt; with &lt;a href="https://lobehub.com/docs/self-hosting/examples/ollama"&gt;Integrating Doc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/datvodinh/rag-chatbot.git"&gt;Ollama RAG Chatbot&lt;/a&gt; (Local Chat with multiple PDFs using Ollama and RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt; (Flexible native client with RAG &amp;amp; multi-agent automation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Renset/macai"&gt;macai&lt;/a&gt; (macOS client for Ollama, ChatGPT, and other compatible API back-ends)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/RWKV-Runner"&gt;RWKV-Runner&lt;/a&gt; (RWKV offline LLM deployment tool, also usable as a client for ChatGPT and Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dezoito/ollama-grid-search"&gt;Ollama Grid Search&lt;/a&gt; (app to evaluate and compare models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Otacon/olpaka"&gt;Olpaka&lt;/a&gt; (User-friendly Flutter Web App for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://casibase.org"&gt;Casibase&lt;/a&gt; (An open source AI knowledge base and dialogue system combining the latest RAG, SSO, ollama support, and multiple large language models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CrazyNeil/OllamaSpring"&gt;OllamaSpring&lt;/a&gt; (Ollama Client for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kartikm7/llocal"&gt;LLocal.in&lt;/a&gt; (Easy to use Electron Desktop Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dcSpark/shinkai-apps"&gt;Shinkai Desktop&lt;/a&gt; (Two click install Local AI using Ollama + Files + RAG)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeyoyt/ailama"&gt;AiLama&lt;/a&gt; (A Discord User App that allows you to interact with Ollama anywhere in Discord)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_mesop/"&gt;Ollama with Google Mesop&lt;/a&gt; (Mesop Chat Client implementation with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SciPhi-AI/R2R"&gt;R2R&lt;/a&gt; (Open-source RAG engine)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elearningshow/ollama-kis"&gt;Ollama-Kis&lt;/a&gt; (A simple easy-to-use GUI with sample custom LLM for Drivers Education)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opengpa.org"&gt;OpenGPA&lt;/a&gt; (Open-source offline-first Enterprise Agentic Application)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateuszmigas/painting-droid"&gt;Painting Droid&lt;/a&gt; (Painting app with AI integrations)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.kerlig.com/"&gt;Kerlig AI&lt;/a&gt; (AI writing assistant for macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;AI Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyopak/sidellama"&gt;Sidellama&lt;/a&gt; (browser-based LLM client)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;LLMStack&lt;/a&gt; (No-code multi-agent framework to build LLM agents and workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boltai.com"&gt;BoltAI for Mac&lt;/a&gt; (AI Chat Client for Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/av/harbor"&gt;Harbor&lt;/a&gt; (Containerized LLM Toolkit with Ollama as default backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/szczyglis-dev/py-gpt"&gt;PyGPT&lt;/a&gt; (AI desktop assistant for Linux, Windows, and Mac)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jeffser/Alpaca"&gt;Alpaca&lt;/a&gt; (An Ollama client application for Linux and macOS made with GTK4 and Adwaita)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/docs/content/platform/ollama.md"&gt;AutoGPT&lt;/a&gt; (AutoGPT Ollama integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jonathanhecl.com/go-crew/"&gt;Go-CREW&lt;/a&gt; (Powerful Offline RAG in Golang)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvmp/partcad/"&gt;PartCAD&lt;/a&gt; (CAD model generation with OpenSCAD and CadQuery)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j-web-ui"&gt;Ollama4j Web UI&lt;/a&gt; - Java-based Web UI for Ollama built with Vaadin, Spring Boot, and Ollama4j&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kspviswa/pyOllaMx"&gt;PyOllaMx&lt;/a&gt; - macOS application capable of chatting with both Ollama and Apple MLX models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cline/cline"&gt;Cline&lt;/a&gt; - Formerly known as Claude Dev is a VSCode extension for multi-file/whole-repo coding&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kangfenmao/cherry-studio"&gt;Cherry Studio&lt;/a&gt; (Desktop client with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nickthecook/archyve"&gt;Archyve&lt;/a&gt; (RAG-enabling document library)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama-crew-mesop"&gt;crewAI with Mesop&lt;/a&gt; (Mesop Web Interface to run crewAI with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chyok/ollama-gui"&gt;Tkinter-based client&lt;/a&gt; (Python tkinter-based Client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trendy-design/llmchat"&gt;LLMChat&lt;/a&gt; (Privacy focused, 100% local, intuitive all-in-one chat interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat"&gt;Local Multimodal AI Chat&lt;/a&gt; (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xark-argo/argo"&gt;ARGO&lt;/a&gt; (Locally download and run Ollama and Huggingface models with RAG and deep research on Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EliasPereirah/OrionChat"&gt;OrionChat&lt;/a&gt; - OrionChat is a web interface for chatting with different AI providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bklieger-groq/g1"&gt;G1&lt;/a&gt; (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lemonit-eric-mao/ollama-web-management"&gt;Web management&lt;/a&gt; (Web management page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/promptery/promptery"&gt;Promptery&lt;/a&gt; (desktop client for Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/annilq/chat-ollama"&gt;chat-ollama&lt;/a&gt; (a React Native client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/spacellama"&gt;SpaceLlama&lt;/a&gt; (Firefox and Chrome extension to quickly summarize web pages with ollama in a sidebar)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/youlama"&gt;YouLama&lt;/a&gt; (Webapp to quickly summarize any YouTube video, supporting Invidious as well)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tcsenpai/dualmind"&gt;DualMind&lt;/a&gt; (Experimental app allowing two models to talk to each other in the terminal or in a web interface)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix"&gt;ollamarama-matrix&lt;/a&gt; (Ollama chatbot for the Matrix chat protocol)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anan1213095357/ollama-chat-app"&gt;ollama-chat-app&lt;/a&gt; (Flutter-based chat app)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.perfectmemory.ai/"&gt;Perfect Memory AI&lt;/a&gt; (Productivity AI assists personalized by what you have seen on your screen, heard, and said in the meetings)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hexastack/hexabot"&gt;Hexabot&lt;/a&gt; (A conversational AI builder)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/reddit_analyzer"&gt;Reddit Rate&lt;/a&gt; (Search and Rate Reddit topics with a weighted summation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/OpenTalkGpt"&gt;OpenTalkGpt&lt;/a&gt; (Chrome Extension to manage open-source models supported by Ollama, create custom models, and chat with models from a user-friendly UI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vinhnx/vt.ai"&gt;VT&lt;/a&gt; (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nosia-ai/nosia"&gt;Nosia&lt;/a&gt; (Easy to install and use RAG platform based on Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/witsy"&gt;Witsy&lt;/a&gt; (An AI Desktop application available for Mac/Windows/Linux)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/US-Artificial-Intelligence/abbey"&gt;Abbey&lt;/a&gt; (A configurable AI interface server with notebooks, document storage, and YouTube support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmayboroda/minima"&gt;Minima&lt;/a&gt; (RAG with on-premises or fully local workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AidfulAI/aidful-ollama-model-delete"&gt;aidful-ollama-model-delete&lt;/a&gt; (User interface for simplified model cleanup)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ItzCrazyKns/Perplexica"&gt;Perplexica&lt;/a&gt; (An AI-powered search engine &amp;amp; an open-source alternative to Perplexity AI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oslook/ollama-webui"&gt;Ollama Chat WebUI for Docker &lt;/a&gt; (Support for local docker deployment, lightweight ollama webui)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-tooklit/ollama-docs"&gt;AI Toolkit for Visual Studio Code&lt;/a&gt; (Microsoft-official VSCode extension to chat, test, evaluate models with Ollama support, and use them in your AI applications.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anilkay/MinimalNextOllamaChat"&gt;MinimalNextOllamaChat&lt;/a&gt; (Minimal Web UI for Chat and Model Control)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TilmanGriesel/chipper"&gt;Chipper&lt;/a&gt; AI interface for tinkerers (Ollama, Haystack RAG, Python)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CosmicEventHorizon/ChibiChat"&gt;ChibiChat&lt;/a&gt; (Kotlin-based Android app to chat with Ollama and Koboldcpp API endpoints)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qusaismael/localllm"&gt;LocalLLM&lt;/a&gt; (Minimal Web-App to run ollama models on it with a GUI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/buiducnhat/ollamazing"&gt;Ollamazing&lt;/a&gt; (Web extension to run Ollama models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/benhaotang/OpenDeepResearcher-via-searxng"&gt;OpenDeepResearcher-via-searxng&lt;/a&gt; (A Deep Research equivalent endpoint with Ollama support for running locally)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AIDotNet/AntSK"&gt;AntSK&lt;/a&gt; (Out-of-the-box &amp;amp; Adaptable RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; (Ready-to-use &amp;amp; flexible RAG Chatbot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielekp/yla"&gt;yla&lt;/a&gt; (Web interface to freely interact with your customized models)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RockChinQ/LangBot"&gt;LangBot&lt;/a&gt; (LLM-based instant messaging bots platform, with Agents, RAG features, supports multiple platforms)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/1Panel/"&gt;1Panel&lt;/a&gt; (Web-based Linux Server Management Tool)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Soulter/AstrBot/"&gt;AstrBot&lt;/a&gt; (User-friendly LLM-based multi-platform chatbot with a WebUI, supporting RAG, LLM agents, and plugins integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aharon-Bensadoun/Flufy"&gt;Flufy&lt;/a&gt; (A beautiful chat interface for interacting with Ollama's API. Built with React, TypeScript, and Material-UI.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeozeozeo/ellama"&gt;Ellama&lt;/a&gt; (Friendly native app to chat with an Ollama instance)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/screenpipe"&gt;screenpipe&lt;/a&gt; Build agents powered by your screen history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hengkysteen/ollamb"&gt;Ollamb&lt;/a&gt; (Simple yet rich in features, cross-platform built with Flutter and designed for Ollama. Try the &lt;a href="https://hengkysteen.github.io/demo/ollamb/"&gt;web demo&lt;/a&gt;.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Writeopia/Writeopia"&gt;Writeopia&lt;/a&gt; (Text editor with integration with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AppFlowy-IO/AppFlowy"&gt;AppFlowy&lt;/a&gt; (AI collaborative workspace with Ollama, cross-platform and self-hostable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cushydigit/lumina.git"&gt;Lumina&lt;/a&gt; (A lightweight, minimal React.js frontend for interacting with Ollama servers)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tiny-notepad"&gt;Tiny Notepad&lt;/a&gt; (A lightweight, notepad-like interface to chat with ollama available on PyPI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hellotunamayo/macLlama"&gt;macLlama (macOS native)&lt;/a&gt; (A native macOS GUI application for interacting with Ollama models, featuring a chat interface.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philberndt/GPTranslate"&gt;GPTranslate&lt;/a&gt; (A fast and lightweight, AI powered desktop translation application written with Rust and Tauri. Features real-time translation with OpenAI/Azure/Ollama.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NGC13009/ollama-launcher"&gt;ollama launcher&lt;/a&gt; (A launcher for Ollama, aiming to provide users with convenient functions such as ollama server launching, management, or configuration.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aj-Seven/ai-hub"&gt;ai-hub&lt;/a&gt; (AI Hub supports multiple models via API keys and Chat support via Ollama API.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/mayan-edms/mayan-edms"&gt;Mayan EDMS&lt;/a&gt; (Open source document management system to organize, tag, search, and automate your files with powerful Ollama driven workflows.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama"&gt;Google Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/docs/python/do-more/add-ollama/"&gt;Fly.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.koyeb.com/deploy/ollama"&gt;Koyeb&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Terminal&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggozad/oterm"&gt;oterm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/s-kostyaev/ellama"&gt;Ellama Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zweifisch/ollama"&gt;Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paradoxical-dev/neollama"&gt;neollama&lt;/a&gt; UI client for interacting with models from within Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/David-Kunz/gen.nvim"&gt;gen.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nomnivore/ollama.nvim"&gt;ollama.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marco-souza/ollero.nvim"&gt;ollero.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gerazov/ollama-chat.nvim"&gt;ollama-chat.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huynle/ogpt.nvim"&gt;ogpt.nvim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karthink/gptel"&gt;gptel Emacs client&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dustinblackman/oatmeal"&gt;Oatmeal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pgibler/cmdh"&gt;cmdh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/npahlfer/ooo"&gt;ooo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reid41/shell-pilot"&gt;shell-pilot&lt;/a&gt;(Interact with models via pure shell scripts on Linux or macOS)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;tenere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taketwo/llm-ollama"&gt;llm-ollama&lt;/a&gt; for &lt;a href="https://llm.datasette.io/en/stable/"&gt;Datasette's LLM CLI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anaisbetts/typechat-cli"&gt;typechat-cli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djcopley/ShellOracle"&gt;ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusufcanb/tlm"&gt;tlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericcurtin/podman-ollama"&gt;podman-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/gollama"&gt;gollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulrobello/parllama"&gt;ParLlama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cognitivetech/ollama-ebook-summary/"&gt;Ollama eBook Summary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_moe"&gt;Ollama Mixture of Experts (MOE) in 50 lines of code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepo-ec/vim-intelligence-bridge"&gt;vim-intelligence-bridge&lt;/a&gt; Simple interaction of "Ollama" with the Vim editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x-cmd.com/mod/ollama"&gt;x-cmd ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/drunkwcodes/bb7"&gt;bb7&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;SwollamaCLI&lt;/a&gt; bundled with the Swollama Swift package. &lt;a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigoden/aichat"&gt;aichat&lt;/a&gt; All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp;amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rrg92/powershai"&gt;PowershAI&lt;/a&gt; PowerShell module that brings AI to terminal on Windows, including support for Ollama&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abyss-c0re/deepshell"&gt;DeepShell&lt;/a&gt; Your self-hosted AI assistant. Interactive Shell, Files and Folders analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/orbiton"&gt;orbiton&lt;/a&gt; Configuration-free text editor and IDE with support for tab completion with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/molbal/orca-cli"&gt;orca-cli&lt;/a&gt; Ollama Registry CLI Application - Browse, pull, and download models from Ollama Registry in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gguf-to-ollama"&gt;GGUF-to-Ollama&lt;/a&gt; - Importing GGUF to Ollama made easy (multiplatform)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapidarchitect/ollama_strands"&gt;AWS-Strands-With-Ollama&lt;/a&gt; - AWS Strands Agents with Ollama Examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-multirun"&gt;ollama-multirun&lt;/a&gt; - A bash shell script to run a single prompt against any or all of your locally installed ollama models, saving the output and performance statistics as easily navigable web pages. (&lt;a href="https://attogram.github.io/ai_test_zone/"&gt;Demo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/attogram/ollama-bash-toolshed"&gt;ollama-bash-toolshed&lt;/a&gt; - Bash scripts to chat with tool using models. Add new tools to your shed with ease. Runs on Ollama.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apple Vision Pro&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Cross-platform AI chat app supporting Apple Vision Pro via "Designed for iPad")&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timescale/pgai"&gt;pgai&lt;/a&gt; - PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/timescale/pgai/raw/main/docs/vectorizer-quick-start.md"&gt;Get started guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mindsdb/mindsdb/raw/staging/mindsdb/integrations/handlers/ollama_handler/README.md"&gt;MindsDB&lt;/a&gt; (Connects Ollama models with nearly 200 data platforms and apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philippgille/chromem-go/raw/v0.5.0/embed_ollama.go"&gt;chromem-go&lt;/a&gt; with &lt;a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbkangaroo/kangaroo"&gt;Kangaroo&lt;/a&gt; (AI-powered SQL client and admin tool for popular databases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Package managers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/ollama/"&gt;Pacman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://formulae.brew.sh/formula/ollama"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://artifacthub.io/packages/helm/ollama-helm/ollama"&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeberg.org/tusharhero/ollama-guix"&gt;Guix channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?show=ollama&amp;amp;from=0&amp;amp;size=50&amp;amp;sort=relevance&amp;amp;type=packages&amp;amp;query=ollama"&gt;Nix package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev/blog/ollama-part-one"&gt;Flox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Libraries&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain&lt;/a&gt; and &lt;a href="https://js.langchain.com/docs/integrations/chat/ollama/"&gt;LangChain.js&lt;/a&gt; with &lt;a href="https://js.langchain.com/docs/tutorials/local_rag/"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://firebase.google.com/docs/genkit/plugins/ollama"&gt;Firebase Genkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;crewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://remembersoftwares.github.io/yacana/"&gt;Yacana&lt;/a&gt; (User-friendly multi-agent framework for brainstorming and executing predetermined flows with built-in tool integration)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spring-projects/spring-ai"&gt;Spring AI&lt;/a&gt; with &lt;a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html"&gt;reference&lt;/a&gt; and &lt;a href="https://github.com/tzolov/ollama-tools"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tmc/langchaingo/"&gt;LangChainGo&lt;/a&gt; with &lt;a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain4j/langchain4j"&gt;LangChain4j&lt;/a&gt; with &lt;a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Abraxas-365/langchain-rust"&gt;LangChainRust&lt;/a&gt; with &lt;a href="https://github.com/Abraxas-365/langchain-rust/raw/main/examples/llm_ollama.rs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tryAGI/LangChain"&gt;LangChain for .NET&lt;/a&gt; with &lt;a href="https://github.com/tryAGI/LangChain/raw/main/examples/LangChain.Samples.OpenAI/Program.cs"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama"&gt;LLPhant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"&gt;LlamaIndex&lt;/a&gt; and &lt;a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama"&gt;LlamaIndexTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BerriAI/litellm"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/presbrey/ollamafarm"&gt;OllamaFarm for Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/awaescher/OllamaSharp"&gt;OllamaSharp for .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbaptista/ollama-ai"&gt;Ollama for Ruby&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pepperoni21/ollama-rs"&gt;Ollama-rs for Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmont-dev/ollama-hpp"&gt;Ollama-hpp for C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ollama4j/ollama4j"&gt;Ollama4j for Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelfusion.dev/integration/model-provider/ollama"&gt;ModelFusion Typescript Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinhermawan/OllamaKit"&gt;OllamaKit for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/breitburg/dart-ollama"&gt;Ollama for Dart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudstudio/ollama-laravel"&gt;Ollama for Laravel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davidmigloz/langchain_dart"&gt;LangChainDart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama"&gt;Semantic Kernel - Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepset-ai/haystack-integrations/raw/main/integrations/ollama.md"&gt;Haystack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brainlid/langchain"&gt;Elixir LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JBGruber/rollama"&gt;Ollama for R - rollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hauselin/ollama-r"&gt;Ollama for R - ollama-r&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lebrunel/ollama-ex"&gt;Ollama-ex for Elixir&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/b-tocs/abap_btocs_ollama"&gt;Ollama Connector for SAP ABAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://testcontainers.com/modules/ollama/"&gt;Testcontainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://portkey.ai/docs/welcome/integration-guides/ollama"&gt;Portkey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/svilupp/PromptingTools.jl"&gt;PromptingTools.jl&lt;/a&gt; with an &lt;a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Project-Llama/llamascript"&gt;LlamaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emirsahin1/llm-axe"&gt;llm-axe&lt;/a&gt; (Python Toolkit for Building LLM Powered Apps)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.gollm.co/examples/ollama-example"&gt;Gollm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonathanhecl/gollama"&gt;Gollama for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xyproto/ollamaclient"&gt;Ollamaclient for Golang&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/tozd/go/fun"&gt;High-level function abstraction in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArdaGnsrn/ollama-php"&gt;Ollama PHP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/agents-flex/agents-flex"&gt;Agents-Flex for Java&lt;/a&gt; with &lt;a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama"&gt;example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parakeet-nest/parakeet"&gt;Parakeet&lt;/a&gt; is a GoLang library, made to simplify the development of small generative AI applications with Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andygill/haverscript"&gt;Haverscript&lt;/a&gt; with &lt;a href="https://github.com/andygill/haverscript/tree/main/examples"&gt;examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattt/ollama-swift"&gt;Ollama for Swift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcusziade/Swollama"&gt;Swollama for Swift&lt;/a&gt; with &lt;a href="https://marcusziade.github.io/Swollama/documentation/swollama/"&gt;DocC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prasad89/golamify"&gt;GoLamify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharad/ollama-haskell"&gt;Ollama for Haskell&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nbonamy/multi-llm-ts"&gt;multi-llm-ts&lt;/a&gt; (A Typescript/JavaScript library allowing access to different LLM in a unified API)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lofcz/llmtornado"&gt;LlmTornado&lt;/a&gt; (C# library providing a unified interface for major FOSS &amp;amp; Commercial inference APIs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dravenk/ollama-zig"&gt;Ollama for Zig&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lunary-ai/abso"&gt;Abso&lt;/a&gt; (OpenAI-compatible TypeScript SDK for any LLM provider)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/goodreasonai/nichey"&gt;Nichey&lt;/a&gt; is a Python package for generating custom wikis for your research topic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kassane/ollama-d"&gt;Ollama for D&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/OllamaPlusPlus"&gt;OllamaPlusPlus&lt;/a&gt; (Very simple C++ library for Ollama)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mobile&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/swift-chat"&gt;SwiftChat&lt;/a&gt; (Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AugustDev/enchanted"&gt;Enchanted&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Maid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JHubi1/ollama-app"&gt;Ollama App&lt;/a&gt; (Modern and easy-to-use multi-platform client for Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1runeberg/confichat"&gt;ConfiChat&lt;/a&gt; (Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sunshine0523/OllamaServer"&gt;Ollama Android Chat&lt;/a&gt; (No need for Termux, start the Ollama service with one click on an Android device)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibrahimcetin/reins"&gt;Reins&lt;/a&gt; (Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Extensions &amp;amp; Plugins&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MassimilianoPasquini97/raycast_ollama"&gt;Raycast extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mxyng/discollama"&gt;Discollama&lt;/a&gt; (Discord bot inside the Ollama discord channel)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;Continue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thewh1teagle/vibe"&gt;Vibe&lt;/a&gt; (Transcribe and analyze meetings with Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hinterdupfinger/obsidian-ollama"&gt;Obsidian Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omagdy7/ollama-logseq"&gt;Logseq Ollama plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andersrex/notesollama"&gt;NotesOllama&lt;/a&gt; (Apple Notes Ollama plugin)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samalba/dagger-chatbot"&gt;Dagger Chatbot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mekb-turtle/discord-ai-bot"&gt;Discord AI Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruecat/ollama-telegram"&gt;Ollama Telegram Bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ej52/hass-ollama-conversation"&gt;Hass Ollama Conversation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abrenneke/rivet-plugin-ollama"&gt;Rivet plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/longy2k/obsidian-bmo-chatbot"&gt;Obsidian BMO Chatbot plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/herval/cliobot"&gt;Cliobot&lt;/a&gt; (Telegram bot with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logancyang/obsidian-copilot"&gt;Copilot for Obsidian plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pfrankov/obsidian-local-gpt"&gt;Obsidian Local GPT plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama"&gt;Open Interpreter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ex3ndr/llama-coder"&gt;Llama Coder&lt;/a&gt; (Copilot alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bernardo-bruning/ollama-copilot"&gt;Ollama Copilot&lt;/a&gt; (Proxy that allows you to use Ollama as a copilot like GitHub Copilot)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rjmacarthy/twinny"&gt;twinny&lt;/a&gt; (Copilot and Copilot chat alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/RussellCanfield/wingman-ai"&gt;Wingman-AI&lt;/a&gt; (Copilot code and chat alternative using Ollama and Hugging Face)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n4ze3m/page-assist"&gt;Page Assist&lt;/a&gt; (Chrome Extension)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imoize/plasmoid-ollamacontrol"&gt;Plasmoid Ollama Control&lt;/a&gt; (KDE Plasma extension that allows you to quickly manage/control Ollama model)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tusharhero/aitelegrambot"&gt;AI Telegram Bot&lt;/a&gt; (Telegram bot using Ollama in backend)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI ST Completion&lt;/a&gt; (Sublime Text 4 AI assistant plugin with Ollama support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kevinthedang/discord-ollama"&gt;Discord-Ollama Chat Bot&lt;/a&gt; (Generalized TypeScript Discord Bot w/ Tuning Documentation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/josStorer/chatGPTBox"&gt;ChatGPTBox: All in one browser extension&lt;/a&gt; with &lt;a href="https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467"&gt;Integrating Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rapmd73/Companion"&gt;Discord AI chat/moderation bot&lt;/a&gt; Chat/moderation bot written in python. Uses Ollama to create personalities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nischalj10/headless-ollama"&gt;Headless Ollama&lt;/a&gt; (Scripts to automatically install ollama client &amp;amp; models on any OS for apps that depend on ollama server)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm"&gt;Terraform AWS Ollama &amp;amp; Open WebUI&lt;/a&gt; (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama"&gt;node-red-contrib-ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ivostoykov/localAI"&gt;Local AI Helper&lt;/a&gt; (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jake83741/vnc-lm"&gt;vnc-lm&lt;/a&gt; (Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SilasMarvin/lsp-ai"&gt;LSP-AI&lt;/a&gt; (Open-source language server for AI-powered functionality)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Palm1r/QodeAssist"&gt;QodeAssist&lt;/a&gt; (AI-powered coding assistant plugin for Qt Creator)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ECuiDev/obsidian-quiz-generator"&gt;Obsidian Quiz Generator plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/philffm/ai-summary-helper"&gt;AI Summmary Helper plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/suncloudsmoon/TextCraft"&gt;TextCraft&lt;/a&gt; (Copilot in Word alternative using Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zeitlings/alfred-ollama"&gt;Alfred Ollama&lt;/a&gt; (Alfred Workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/adarshM84/TextLLaMA"&gt;TextLLaMA&lt;/a&gt; A Chrome Extension that helps you write emails, correct grammar, and translate into any language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zyphixor/simple-discord-ai"&gt;Simple-Discord-AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/innightwolfsleep/llm_telegram_bot"&gt;LLM Telegram Bot&lt;/a&gt; (telegram bot, primary for RP. Oobabooga-like buttons, &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;A1111&lt;/a&gt; API integration e.t.c)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sammcj/mcp-llm"&gt;mcp-llm&lt;/a&gt; (MCP Server to allow LLMs to call other LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/SimpleOllamaUnity"&gt;SimpleOllamaUnity&lt;/a&gt; (Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HardCodeDev777/UnityCodeLama"&gt;UnityCodeLama&lt;/a&gt; (Unity Edtior tool to analyze scripts via Ollama)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NativeMindBrowser/NativeMindExtension"&gt;NativeMind&lt;/a&gt; (Private, on-device AI Assistant, no cloud dependencies)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gmai.premex.se/"&gt;GMAI - Gradle Managed AI&lt;/a&gt; (Gradle plugin for automated Ollama lifecycle management during build phases)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported backends&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp&lt;/a&gt; project founded by Georgi Gerganov.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Observability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.comet.com/docs/opik/cookbook/ollama"&gt;Opik&lt;/a&gt; is an open-source platform to debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards. Opik supports native intergration to Ollama.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lunary.ai/docs/integrations/ollama"&gt;Lunary&lt;/a&gt; is the leading open-source LLM observability platform. It provides a variety of enterprise-grade features such as real-time analytics, prompt templates management, PII masking, and comprehensive agent tracing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT&lt;/a&gt; is an OpenTelemetry-native tool for monitoring Ollama Applications &amp;amp; GPUs using traces and metrics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.honeyhive.ai/integrations/ollama"&gt;HoneyHive&lt;/a&gt; is an AI observability and evaluation platform for AI agents. Use HoneyHive to evaluate agent performance, interrogate failures, and monitor quality in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/docs/integrations/ollama"&gt;Langfuse&lt;/a&gt; is an open source LLM observability platform that enables teams to collaboratively monitor, evaluate and debug AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing"&gt;MLflow Tracing&lt;/a&gt; is an open source LLM observability tool with a convenient API to log and visualize traces, making it easy to debug and evaluate GenAI applications.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>browserbase/stagehand</title>
      <link>https://github.com/browserbase/stagehand</link>
      <description>&lt;p&gt;The AI Browser Automation Framework&lt;/p&gt;&lt;hr&gt;&lt;div id="toc" align="center" style="margin-bottom: 0;"&gt; 
 &lt;ul style="list-style: none; margin: 0; padding: 0;"&gt; 
  &lt;a href="https://stagehand.dev"&gt; 
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_logo.png"&gt; 
    &lt;img alt="Stagehand" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_logo.png" width="200" style="margin-right: 30px;"&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt;The AI Browser Automation Framework&lt;/strong&gt;&lt;br&gt; &lt;a href="https://docs.stagehand.dev"&gt;Read the Docs&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_license.svg"&gt; 
   &lt;img alt="MIT License" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_license.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_slack.svg"&gt; 
   &lt;img alt="Slack Community" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_slack.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/12122" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12122" alt="browserbase%2Fstagehand | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; If you're looking for the Python implementation, you can find it &lt;a href="https://github.com/browserbase/stagehand-python"&gt; here&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center" style="display: flex; align-items: center; justify-content: center; gap: 4px; margin-bottom: 0;"&gt; 
 &lt;b&gt;Vibe code&lt;/b&gt; 
 &lt;span style="font-size: 1.05em;"&gt; Stagehand with &lt;/span&gt; 
 &lt;a href="https://director.ai" style="display: flex; align-items: center;"&gt; &lt;span&gt;Director&lt;/span&gt; &lt;/a&gt; 
 &lt;span&gt; &lt;/span&gt; 
 &lt;picture&gt; 
  &lt;img alt="Director" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/director_icon.svg?sanitize=true" width="25"&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;h2&gt;Why Stagehand?&lt;/h2&gt; 
&lt;p&gt;Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Choose when to write code vs. natural language&lt;/strong&gt;: use AI when you want to navigate unfamiliar pages, and use code (&lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;) when you know exactly what you want to do.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preview and cache actions&lt;/strong&gt;: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Computer use models with one line of code&lt;/strong&gt;: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;Here's how to build a sample browser automation with Stagehand:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="max-width:300px;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/github_demo.gif" alt="See Stagehand in Action"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto("https://github.com/browserbase");

// Use act() to execute individual actions
await page.act("click on the stagehand repo");

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: "openai",
    model: "computer-use-preview",
});
await agent.execute("Get to the latest PR");

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: "extract the author and title of the PR",
  schema: z.object({
    author: z.string().describe("The username of the PR author"),
    title: z.string().describe("The title of the PR"),
  }),
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://docs.stagehand.dev"&gt;docs.stagehand.dev&lt;/a&gt; to view the full documentation.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Start with Stagehand with one line of code, or check out our &lt;a href="https://docs.stagehand.dev/get_started/quickstart"&gt;Quickstart Guide&lt;/a&gt; for more information:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx create-browser-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt; &lt;/a&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;img style="max-width:300px;" src="https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Build and Run from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/browserbase/stagehand.git
cd stagehand
pnpm install
pnpm playwright install
pnpm run build
pnpm run example # run the blank script at ./examples/example.ts
pnpm run example 2048 # run the 2048 example at ./examples/2048.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
nano .env # Edit the .env file to add API keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br&gt; We highly value contributions to Stagehand! For questions or support, please join our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;At a high level, we're focused on improving reliability, speed, and cost in that order of priority. If you're interested in contributing, we strongly recommend reaching out to &lt;a href="https://x.com/miguel_gonzf"&gt;Miguel Gonzalez&lt;/a&gt; or &lt;a href="https://x.com/pk_iv"&gt;Paul Klein&lt;/a&gt; in our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt; before starting to ensure that your contribution aligns with our goals.&lt;/p&gt; 
&lt;p&gt;For more information, please see our &lt;a href="https://docs.stagehand.dev/examples/contributing"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project heavily relies on &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by &lt;a href="https://github.com/reworkd/tarsier"&gt;tarsier&lt;/a&gt;, &lt;a href="https://github.com/jbeoris/gemini-zod"&gt;gemini-zod&lt;/a&gt;, and &lt;a href="https://github.com/normal-computing/fuji-web"&gt;fuji-web&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We'd like to thank the following people for their major contributions to Stagehand:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pkiv"&gt;Paul Klein&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kamath"&gt;Anirudh Kamath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seanmcguire12"&gt;Sean McGuire&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miguelg719"&gt;Miguel Gonzalez&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sameelarif"&gt;Sameel Arif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/filip-michalsky"&gt;Filip Michalsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/jeremypress"&gt;Jeremy Press&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/navidpour"&gt;Navid Pour&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the MIT License.&lt;/p&gt; 
&lt;p&gt;Copyright 2025 Browserbase, Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lvgl/lvgl</title>
      <link>https://github.com/lvgl/lvgl</link>
      <description>&lt;p&gt;Embedded graphics library to create beautiful UIs for any MCU, MPU and display type.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/sponsors/lvgl" target="_blank"&gt;&lt;img align="left" src="https://lvgl.io/github-assets/sponsor.png" height="32px"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="right"&gt; &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/lvgl/lvgl/master/docs/README_zh.md"&gt;中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/lvgl/lvgl/master/docs/README_pt_BR.md"&gt;Português do Brasil&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/lvgl/lvgl/master/docs/README_jp.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/lvgl/lvgl/master/docs/README_he.md"&gt;עברית&lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &amp;nbsp; &lt;img src="https://lvgl.io/github-assets/logo-colored.png" width="300px"&gt; &lt;/p&gt; 
&lt;p&gt;&amp;nbsp; &lt;/p&gt;
&lt;h1 align="center"&gt;Light and Versatile Graphics Library&lt;/h1&gt; &amp;nbsp; 
&lt;br&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://lvgl.io/github-assets/smartwatch-demo.gif"&gt; &amp;nbsp; &amp;nbsp; 
 &lt;img border="1px" src="https://lvgl.io/github-assets/widgets-demo.gif"&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;a href="https://lvgl.io" title="Homepage of LVGL"&gt;Website &lt;/a&gt; | &lt;a href="https://docs.lvgl.io/" title="Detailed documentation with 100+ examples"&gt;Docs&lt;/a&gt; | &lt;a href="https://forum.lvgl.io" title="Get help and help others"&gt;Forum&lt;/a&gt; | &lt;a href="https://lvgl.io/demos" title="Demos running in your browser"&gt;Demos&lt;/a&gt; | &lt;a href="https://lvgl.io/services" title="Graphics design, UI implementation and consulting"&gt;Services&lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;&lt;span&gt;📒&lt;/span&gt; Overview&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Mature and Well-known&lt;/strong&gt;&lt;br&gt; LVGL is the most popular free and open source embedded graphics library to create beautiful UIs for any MCU, MPU and display type. It's supported by industry leading vendors and projects like &amp;nbsp;Arm, STM32, NXP, Espressif, Nuvoton, Arduino, RT-Thread, Zephyr, NuttX, Adafruit and many more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Feature Rich&lt;/strong&gt;&lt;br&gt; It has all the features to create modern and beautiful GUIs: 30+ built-in widgets, a powerful style system, web inspired layout managers, and a typography system supporting many languages. To integrate LVGL into your platform, all you need is at least 32kB RAM and 128 kB Flash, a C compiler, a frame buffer, and at least an 1/10 screen sized buffer for rendering.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Services&lt;/strong&gt;&lt;br&gt; Our team is ready to help you with graphics design, UI implementation and consulting services. Contact us if you need some support during the development of your next GUI project.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🚀&lt;/span&gt; Features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Free and Portable&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A fully portable C (C++ compatible) library with no external dependencies.&lt;/li&gt; 
 &lt;li&gt;Can be compiled to any MCU or MPU, with any (RT)OS.&lt;/li&gt; 
 &lt;li&gt;Supports monochrome, ePaper, OLED or TFT displays, or even monitors. &lt;a href="https://docs.lvgl.io/master/details/main-modules/display/index.html"&gt;Displays&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Distributed under the MIT license, so you can easily use it in commercial projects too.&lt;/li&gt; 
 &lt;li&gt;Needs only 32kB RAM and 128 kB Flash, a frame buffer, and at least an 1/10 screen sized buffer for rendering.&lt;/li&gt; 
 &lt;li&gt;OS, External memory and GPU are supported but not required.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Widgets, Styles, Layouts and more&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;30+ built-in &lt;a href="https://docs.lvgl.io/master/details/widgets/index.html"&gt;Widgets&lt;/a&gt;: &amp;nbsp;Button, Label, Slider, Chart, Keyboard, Meter, Arc, Table and many more.&lt;/li&gt; 
 &lt;li&gt;Flexible &lt;a href="https://docs.lvgl.io/master/details/common-widget-features/styles/index.html"&gt;Style system&lt;/a&gt; with &amp;nbsp;~100 style properties to customize any part of the widgets in any state.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/common-widget-features/layouts/flex.html"&gt;Flexbox&lt;/a&gt; and &lt;a href="https://docs.lvgl.io/master/details/common-widget-features/layouts/grid.html"&gt;Grid&lt;/a&gt;-like layouts engines to automatically size and position the widgets in a responsive way.&lt;/li&gt; 
 &lt;li&gt;Texts are rendered with UTF-8 encoding supporting CJK, Thai, Hindi, Arabic, Persian writing systems.&lt;/li&gt; 
 &lt;li&gt;Word wrapping, kerning, text scrolling, sub-pixel rendering, Pinyin-IME Chinese input, Emojis in texts.&lt;/li&gt; 
 &lt;li&gt;Rendering engine supporting animations, anti-aliasing, opacity, smooth scrolling, shadows, image transformation, etc &amp;nbsp;&lt;/li&gt; 
 &lt;li&gt;Supports Mouse, Touchpad, Keypad, Keyboard, External buttons, Encoder &lt;a href="https://docs.lvgl.io/master/details/main-modules/indev.html"&gt;Input devices&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/main-modules/display/overview.html#how-many-displays-can-lvgl-use"&gt;Multiple display&lt;/a&gt; support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Binding and Build Support&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.lvgl.io/2019-02-20/micropython-bindings"&gt;MicroPython Binding&lt;/a&gt; exposes LVGL API&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.lvgl.io/2022-08-24/pikascript-and-lvgl"&gt;PikaScript Binding&lt;/a&gt; python on MCU lighter and easier.&lt;/li&gt; 
 &lt;li&gt;No custom build system is used. You can build LVGL as you build the other files of your project.&lt;/li&gt; 
 &lt;li&gt;Support for Make and &lt;a href="https://docs.lvgl.io/master/details/integration/building/cmake.html"&gt;CMake&lt;/a&gt; is included out of the box.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/integration/ide/pc-simulator.html"&gt;Develop on PC&lt;/a&gt; and use the same UI code on embedded hardware.&lt;/li&gt; 
 &lt;li&gt;Convert the C UI code to HTML file with our &lt;a href="https://github.com/lvgl/lv_web_emscripten"&gt;Emscripten port&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Docs, Tools, and Services&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detailed &lt;a href="https://docs.lvgl.io/"&gt;Documentation&lt;/a&gt; with &lt;a href="https://docs.lvgl.io/master/examples.html"&gt;100+ simple examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lvgl.io/services"&gt;Services&lt;/a&gt; such as User interface design, Implementation and Consulting to make UI development simpler and faster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;❤️&lt;/span&gt; Sponsor&lt;/h2&gt; 
&lt;p&gt;If LVGL saved you a lot of time and money or you just had fun using it, consider &lt;a href="https://github.com/sponsors/lvgl"&gt;Supporting its Development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How do we spend the donations?&lt;/strong&gt;&lt;br&gt; Our goal is to provide financial compensation for people who do the most for LVGL. It means not only the maintainers but anyone who implements a great feature should get a payment from the accumulated money. We use the donations to cover our operational costs like servers and related services.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How to donate?&lt;/strong&gt;&lt;br&gt; We use &lt;a href="https://github.com/sponsors/lvgl"&gt;GitHub Sponsors&lt;/a&gt; where you can easily send one time or recurring donations. You can also see all of our expenses in a transparent way.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How to get paid for your contribution?&lt;/strong&gt;&lt;br&gt; If someone implements or fixes an issue labeled as &lt;a href="https://github.com/lvgl/lvgl/labels/Sponsored"&gt;Sponsored&lt;/a&gt; he or she will get a payment for that work. We estimate the required time, complexity and importance of the issue and set a price accordingly. To jump in just comment on a &lt;a href="https://github.com/lvgl/lvgl/labels/Sponsored"&gt;Sponsored&lt;/a&gt; issue saying "Hi, I'd like to deal with it. This is how I'm planning to fix/implement it...". A work is considered ready when it's approved and merged by a maintainer. After that you can submit and expense at &lt;a href="https://opencollective.com/lvgl"&gt;opencollective.com&lt;/a&gt; and you will receive the payment in a few days.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Organizations supporting LVGL&lt;/strong&gt;&lt;br&gt; &lt;a href="https://opencollective.com/lvgl"&gt;&lt;img src="https://opencollective.com/lvgl/organizations.svg?width=600" alt="Sponsors of LVGL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Individuals supporting LVGL&lt;/strong&gt;&lt;br&gt; &lt;a href="https://opencollective.com/lvgl"&gt;&lt;img src="https://contrib.rocks/image?repo=lvgl/lvgl&amp;amp;max=48" alt="Backers of LVGL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;📦&lt;/span&gt; Packages&lt;/h2&gt; 
&lt;p&gt;LVGL is available as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/integration/framework/arduino.html"&gt;Arduino library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://registry.platformio.org/libraries/lvgl/lvgl"&gt;PlatformIO package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/integration/os/zephyr.html"&gt;Zephyr library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://components.espressif.com/components/lvgl/lvgl"&gt;ESP-IDF(ESP32) component&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nxp.com/design/software/embedded-software/lvgl-open-source-graphics-library:LITTLEVGL-OPEN-SOURCE-GRAPHICS-LIBRARY"&gt;NXP MCUXpresso component&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/integration/os/nuttx.html"&gt;NuttX library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.lvgl.io/master/details/integration/os/rt-thread.html"&gt;RT-Thread RTOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CMSIS-Pack&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.riot-os.org/group__pkg__lvgl.html#details"&gt;RIOT OS package&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;🤖&lt;/span&gt; Examples&lt;/h2&gt; 
&lt;p&gt;See some examples of creating widgets, using layouts and applying styles. You will find C and MicroPython code, and links to try out or edit the examples in an online MicroPython editor.&lt;/p&gt; 
&lt;p&gt;For more examples check out the &lt;a href="https://github.com/lvgl/lvgl/tree/master/examples"&gt;Examples&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Hello world label&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/kisvegabor/test/raw/master/readme_example_1.png" alt="Simple Hello world label example in LVGL"&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;C code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-c"&gt;/*Change the active screen's background color*/
lv_obj_set_style_bg_color(lv_screen_active(), lv_color_hex(0x003a57), LV_PART_MAIN);

/*Create a white label, set its text and align it to the center*/
lv_obj_t * label = lv_label_create(lv_screen_active());
lv_label_set_text(label, "Hello world");
lv_obj_set_style_text_color(label, lv_color_hex(0xffffff), LV_PART_MAIN);
lv_obj_align(label, LV_ALIGN_CENTER, 0, 0);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MicroPython code | &lt;a href="https://sim.lvgl.io/v8.3/micropython/ports/javascript/index.html?script_direct=4ab7c40c35b0dc349aa2f0c3b00938d7d8e8ac9f" target="_blank"&gt;Online Simulator&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Change the active screen's background color
scr = lv.screen_active()
scr.set_style_bg_color(lv.color_hex(0x003a57), lv.PART.MAIN)

# Create a white label, set its text and align it to the center
label = lv.label(lv.screen_active())
label.set_text("Hello world")
label.set_style_text_color(lv.color_hex(0xffffff), lv.PART.MAIN)
label.align(lv.ALIGN.CENTER, 0, 0)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;Button with Click Event&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/kisvegabor/test/raw/master/readme_example_2.gif" alt="LVGL button with label example"&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;C code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-c"&gt;lv_obj_t * button = lv_button_create(lv_screen_active()); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; /*Add a button to the current screen*/
lv_obj_center(button); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;         /*Set its position*/
lv_obj_set_size(button, 100, 50); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/*Set its size*/
lv_obj_add_event_cb(button, button_event_cb, LV_EVENT_CLICKED, NULL); /*Assign a callback to the button*/

lv_obj_t * label = lv_label_create(button); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;/*Add a label to the button*/
lv_label_set_text(label, "Button"); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; /*Set the labels text*/
lv_obj_center(label); &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; /*Align the label to the center*/
...

void button_event_cb(lv_event_t * e)
{
&amp;nbsp; printf("Clicked\n");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MicroPython code | &lt;a href="https://sim.lvgl.io/v8.3/micropython/ports/javascript/index.html?script_startup=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/header.py&amp;amp;script=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/widgets/slider/lv_example_slider_2.py&amp;amp;script_direct=926bde43ec7af0146c486de470c53f11f167491e" target="_blank"&gt;Online Simulator&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def button_event_cb(e):
&amp;nbsp; print("Clicked")

# Create a Button and a Label
button = lv.button(lv.screen_active())
button.center()
button.set_size(100, 50)
button.add_event_cb(button_event_cb, lv.EVENT.CLICKED, None)

label = lv.label(button)
label.set_text("Button")
label.center()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;Checkboxes with Layout&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/kisvegabor/test/raw/master/readme_example_3.gif" alt="Checkboxes with layout in LVGL"&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;C code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-c"&gt;
lv_obj_set_flex_flow(lv_screen_active(), LV_FLEX_FLOW_COLUMN);
lv_obj_set_flex_align(lv_screen_active(), LV_FLEX_ALIGN_CENTER, LV_FLEX_ALIGN_START, LV_FLEX_ALIGN_CENTER);

lv_obj_t * cb;
cb = lv_checkbox_create(lv_screen_active());
lv_checkbox_set_text(cb, "Apple");
lv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);

cb = lv_checkbox_create(lv_screen_active());
lv_checkbox_set_text(cb, "Banana");
lv_obj_add_state(cb, LV_STATE_CHECKED);
lv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);

cb = lv_checkbox_create(lv_screen_active());
lv_checkbox_set_text(cb, "Lemon");
lv_obj_add_state(cb, LV_STATE_DISABLED);
lv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);

cb = lv_checkbox_create(lv_screen_active());
lv_obj_add_state(cb, LV_STATE_CHECKED);
lv_obj_add_state(cb, LV_STATE_DISABLED);
lv_checkbox_set_text(cb, "Melon\nand a new line");
lv_obj_add_event_cb(cb, event_handler, LV_EVENT_ALL, NULL);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MicroPython code | &lt;a href="https://sim.lvgl.io/v8.3/micropython/ports/javascript/index.html?script_startup=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/header.py&amp;amp;script=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/widgets/slider/lv_example_slider_2.py&amp;amp;script_direct=311d37e5f70daf1cb0d2cad24c7f72751b5f1792" target="_blank"&gt;Online Simulator&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;def event_handler(e):
    code = e.get_code()
    obj = e.get_target_obj()
    if code == lv.EVENT.VALUE_CHANGED:
        txt = obj.get_text()
        if obj.get_state() &amp;amp; lv.STATE.CHECKED:
            state = "Checked"
        else:
            state = "Unchecked"
        print(txt + ":" + state)


lv.screen_active().set_flex_flow(lv.FLEX_FLOW.COLUMN)
lv.screen_active().set_flex_align(lv.FLEX_ALIGN.CENTER, lv.FLEX_ALIGN.START, lv.FLEX_ALIGN.CENTER)

cb = lv.checkbox(lv.screen_active())
cb.set_text("Apple")
cb.add_event_cb(event_handler, lv.EVENT.ALL, None)

cb = lv.checkbox(lv.screen_active())
cb.set_text("Banana")
cb.add_state(lv.STATE.CHECKED)
cb.add_event_cb(event_handler, lv.EVENT.ALL, None)

cb = lv.checkbox(lv.screen_active())
cb.set_text("Lemon")
cb.add_state(lv.STATE.DISABLED)
cb.add_event_cb(event_handler, lv.EVENT.ALL, None)

cb = lv.checkbox(lv.screen_active())
cb.add_state(lv.STATE.CHECKED | lv.STATE.DISABLED)
cb.set_text("Melon")
cb.add_event_cb(event_handler, lv.EVENT.ALL, None)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;Styling a Slider&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/kisvegabor/test/raw/master/readme_example_4.gif" alt="Styling a slider with LVGL"&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;C code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-c"&gt;lv_obj_t * slider = lv_slider_create(lv_screen_active());
lv_slider_set_value(slider, 70, LV_ANIM_OFF);
lv_obj_set_size(slider, 300, 20);
lv_obj_center(slider);

/*Add local styles to MAIN part (background rectangle)*/
lv_obj_set_style_bg_color(slider, lv_color_hex(0x0F1215), LV_PART_MAIN);
lv_obj_set_style_bg_opa(slider, 255, LV_PART_MAIN);
lv_obj_set_style_border_color(slider, lv_color_hex(0x333943), LV_PART_MAIN);
lv_obj_set_style_border_width(slider, 5, LV_PART_MAIN);
lv_obj_set_style_pad_all(slider, 5, LV_PART_MAIN);

/*Create a reusable style sheet for the INDICATOR part*/
static lv_style_t style_indicator;
lv_style_init(&amp;amp;style_indicator);
lv_style_set_bg_color(&amp;amp;style_indicator, lv_color_hex(0x37B9F5));
lv_style_set_bg_grad_color(&amp;amp;style_indicator, lv_color_hex(0x1464F0));
lv_style_set_bg_grad_dir(&amp;amp;style_indicator, LV_GRAD_DIR_HOR);
lv_style_set_shadow_color(&amp;amp;style_indicator, lv_color_hex(0x37B9F5));
lv_style_set_shadow_width(&amp;amp;style_indicator, 15);
lv_style_set_shadow_spread(&amp;amp;style_indicator, 5);
4
/*Add the style sheet to the slider's INDICATOR part*/
lv_obj_add_style(slider, &amp;amp;style_indicator, LV_PART_INDICATOR);

/*Add the same style to the KNOB part too and locally overwrite some properties*/
lv_obj_add_style(slider, &amp;amp;style_indicator, LV_PART_KNOB);

lv_obj_set_style_outline_color(slider, lv_color_hex(0x0096FF), LV_PART_KNOB);
lv_obj_set_style_outline_width(slider, 3, LV_PART_KNOB);
lv_obj_set_style_outline_pad(slider, -5, LV_PART_KNOB);
lv_obj_set_style_shadow_spread(slider, 2, LV_PART_KNOB);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MicroPython code | &lt;a href="https://sim.lvgl.io/v8.3/micropython/ports/javascript/index.html?script_startup=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/header.py&amp;amp;script=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/widgets/slider/lv_example_slider_2.py&amp;amp;script_direct=c431c7b4dfd2cc0dd9c392b74365d5af6ea986f0" target="_blank"&gt;Online Simulator&lt;/a&gt; &lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Create a slider and add the style
slider = lv.slider(lv.screen_active())
slider.set_value(70, lv.ANIM.OFF)
slider.set_size(300, 20)
slider.center()

# Add local styles to MAIN part (background rectangle)
slider.set_style_bg_color(lv.color_hex(0x0F1215), lv.PART.MAIN)
slider.set_style_bg_opa(255, lv.PART.MAIN)
slider.set_style_border_color(lv.color_hex(0x333943), lv.PART.MAIN)
slider.set_style_border_width(5, lv.PART.MAIN)
slider.set_style_pad_all(5, lv.PART.MAIN)

# Create a reusable style sheet for the INDICATOR part
style_indicator = lv.style_t()
style_indicator.init()
style_indicator.set_bg_color(lv.color_hex(0x37B9F5))
style_indicator.set_bg_grad_color(lv.color_hex(0x1464F0))
style_indicator.set_bg_grad_dir(lv.GRAD_DIR.HOR)
style_indicator.set_shadow_color(lv.color_hex(0x37B9F5))
style_indicator.set_shadow_width(15)
style_indicator.set_shadow_spread(5)

# Add the style sheet to the slider's INDICATOR part
slider.add_style(style_indicator, lv.PART.INDICATOR)
slider.add_style(style_indicator, lv.PART.KNOB)

# Add the same style to the KNOB part too and locally overwrite some properties
slider.set_style_outline_color(lv.color_hex(0x0096FF), lv.PART.KNOB)
slider.set_style_outline_width(3, lv.PART.KNOB)
slider.set_style_outline_pad(-5, lv.PART.KNOB)
slider.set_style_shadow_spread(2, lv.PART.KNOB)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;English, Hebrew (mixed LTR-RTL) and Chinese texts&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://github.com/kisvegabor/test/raw/master/readme_example_5.png" alt="English, Hebrew and Chinese texts with LVGL"&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;C code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-c"&gt;lv_obj_t * ltr_label = lv_label_create(lv_screen_active());
lv_label_set_text(ltr_label, "In modern terminology, a microcontroller is similar to a system on a chip (SoC).");
lv_obj_set_style_text_font(ltr_label, &amp;amp;lv_font_montserrat_16, 0);
lv_obj_set_width(ltr_label, 310);
lv_obj_align(ltr_label, LV_ALIGN_TOP_LEFT, 5, 5);

lv_obj_t * rtl_label = lv_label_create(lv_screen_active());
lv_label_set_text(rtl_label,"מעבד, או בשמו המלא יחידת עיבוד מרכזית (באנגלית: CPU - Central Processing Unit).");
lv_obj_set_style_base_dir(rtl_label, LV_BASE_DIR_RTL, 0);
lv_obj_set_style_text_font(rtl_label, &amp;amp;lv_font_dejavu_16_persian_hebrew, 0);
lv_obj_set_width(rtl_label, 310);
lv_obj_align(rtl_label, LV_ALIGN_LEFT_MID, 5, 0);

lv_obj_t * cz_label = lv_label_create(lv_screen_active());
lv_label_set_text(cz_label,
                  "嵌入式系统（Embedded System），\n是一种嵌入机械或电气系统内部、具有专一功能和实时计算性能的计算机系统。");
lv_obj_set_style_text_font(cz_label, &amp;amp;lv_font_source_han_sans_sc_16_cjk, 0);
lv_obj_set_width(cz_label, 310);
lv_obj_align(cz_label, LV_ALIGN_BOTTOM_LEFT, 5, -5);
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;MicroPython code | &lt;a href="https://sim.lvgl.io/v8.3/micropython/ports/javascript/index.html?script_startup=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/header.py&amp;amp;script=https://raw.githubusercontent.com/lvgl/lvgl/0d9ab4ee0e591aad1970e3c9164fd7c544ecce70/examples/widgets/slider/lv_example_slider_2.py&amp;amp;script_direct=18bb38200a64e10ead1aa17a65c977fc18131842" target="_blank"&gt;Online Simulator&lt;/a&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;ltr_label = lv.label(lv.screen_active())
ltr_label.set_text("In modern terminology, a microcontroller is similar to a system on a chip (SoC).")
ltr_label.set_style_text_font(lv.font_montserrat_16, 0);

ltr_label.set_width(310)
ltr_label.align(lv.ALIGN.TOP_LEFT, 5, 5)

rtl_label = lv.label(lv.screen_active())
rtl_label.set_text("מעבד, או בשמו המלא יחידת עיבוד מרכזית (באנגלית: CPU - Central Processing Unit).")
rtl_label.set_style_base_dir(lv.BASE_DIR.RTL, 0)
rtl_label.set_style_text_font(lv.font_dejavu_16_persian_hebrew, 0)
rtl_label.set_width(310)
rtl_label.align(lv.ALIGN.LEFT_MID, 5, 0)

font_hans_sans_16_cjk = lv.font_load("S:../../assets/font/lv_font_source_han_sans_sc_16_cjk.fnt")

cz_label = lv.label(lv.screen_active())
cz_label.set_style_text_font(font_hans_sans_16_cjk, 0)
cz_label.set_text("嵌入式系统（Embedded System），\n是一种嵌入机械或电气系统内部、具有专一功能和实时计算性能的计算机系统。")
cz_label.set_width(310)
cz_label.align(lv.ALIGN.BOTTOM_LEFT, 5, -5)

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;span&gt;▶&lt;/span&gt; Get started&lt;/h2&gt; 
&lt;p&gt;This list will guide you to get started with LVGL step-by-step.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Get Familiar with LVGL&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check the &lt;a href="https://lvgl.io/demos"&gt;Online demos&lt;/a&gt; to see LVGL in action (3 minutes).&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://docs.lvgl.io/master/intro/introduction/index.html"&gt;Introduction&lt;/a&gt; page of the documentation (5 minutes).&lt;/li&gt; 
 &lt;li&gt;Get familiar with the basics on the &lt;a href="https://docs.lvgl.io/master/intro/getting_started/learn_the_basics.html"&gt;Quick overview&lt;/a&gt; page (15 minutes).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Start to Use LVGL&lt;/strong&gt;&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up a &lt;a href="https://docs.lvgl.io/master/details/integration/ide/pc-simulator.html#simulator"&gt;Simulator&lt;/a&gt; (10 minutes).&lt;/li&gt; 
 &lt;li&gt;Try out some &lt;a href="https://github.com/lvgl/lvgl/tree/master/examples"&gt;Examples&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Port LVGL to a board. See the &lt;a href="https://docs.lvgl.io/master/details/integration/adding-lvgl-to-your-project/index.html"&gt;Porting&lt;/a&gt; guide or check out the ready-to-use &lt;a href="https://github.com/lvgl?q=lv_port_"&gt;Projects&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Become a Pro&lt;/strong&gt;&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;Read the &lt;a href="https://docs.lvgl.io/master/details/main-modules/index.html"&gt;Main-Modules&lt;/a&gt; page to get a better understanding of the library (2-3 hours)&lt;/li&gt; 
 &lt;li&gt;Check the documentation of the &lt;a href="https://docs.lvgl.io/master/details/widgets/index.html"&gt;Widgets&lt;/a&gt; to see their features and usage&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Get Help and Help Others&lt;/strong&gt;&lt;/p&gt; 
&lt;ol start="9"&gt; 
 &lt;li&gt;If you have questions go to the &lt;a href="http://forum.lvgl.io/"&gt;Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://docs.lvgl.io/master/contributing/index.html"&gt;Contributing&lt;/a&gt; guide to see how you can help to improve LVGL (15 minutes)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;span&gt;🤝&lt;/span&gt; Services&lt;/h2&gt; 
&lt;p&gt;LVGL LLC was established to provide a solid background for LVGL library and to offer several type of services to help you in UI development. With 15+ years of experience in the user interface and graphics industry we can help you the bring your UI to the next level.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graphics design&lt;/strong&gt; Our in-house graphics designers are experts in creating beautiful modern designs which fit to your product and the resources of your hardware.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI implementation&lt;/strong&gt; We can also implement your UI based on the design you or we have created. You can be sure that we will make the most out of your hardware and LVGL. If a feature or widget is missing from LVGL, don't worry, we will implement it for you.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consulting and Support&lt;/strong&gt; We can support you with consulting as well to avoid pricey and time consuming mistakes during the UI development.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Board certification&lt;/strong&gt; For companies who are offering development boards, or production ready kits we do board certification which shows how board can run LVGL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our &lt;a href="https://lvgl.io/demos"&gt;Demos&lt;/a&gt; as reference. For more information take look at the &lt;a href="https://lvgl.io/services"&gt;Services page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lvgl.io/#contact"&gt;Contact us&lt;/a&gt; and tell how we can help.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🌟&lt;/span&gt; Contributing&lt;/h2&gt; 
&lt;p&gt;LVGL is an open project and contribution is very welcome. There are many ways to contribute from simply speaking about your project, through writing examples, improving the documentation, fixing bugs or even hosting your own project under the LVGL organization.&lt;/p&gt; 
&lt;p&gt;For a detailed description of contribution opportunities visit the &lt;a href="https://docs.lvgl.io/master/contributing/index.html"&gt;Contributing&lt;/a&gt; section of the documentation.&lt;/p&gt; 
&lt;p&gt;More than 300 people already left their fingerprint in LVGL. Be one them! See you here! &lt;span&gt;🙂&lt;/span&gt;&lt;/p&gt; 
&lt;a href="https://github.com/lvgl/lvgl/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=lvgl/lvgl&amp;amp;max=48"&gt; &lt;/a&gt; 
&lt;p&gt;... and many other.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Sim is an open-source AI agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/sim.png" alt="Sim Logo" width="500"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://github.com/simstudioai/sim/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs welcome"&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-visit%20documentation-blue.svg?sanitize=true" alt="Documentation"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Sim&lt;/strong&gt; is a lightweight, user-friendly platform for building AI agent workflows. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/demo.gif" alt="Sim Demo" width="800"&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use our &lt;a href="https://sim.ai"&gt;cloud-hosted version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Self-host using one of the methods below&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Self-Hosting Options&lt;/h2&gt; 
&lt;h3&gt;Option 1: NPM Package (Simplest)&lt;/h3&gt; 
&lt;p&gt;The easiest way to run Sim locally is using our &lt;a href="https://www.npmjs.com/package/simstudio?activeTab=readme"&gt;NPM package&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After running these commands, open &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;: Specify the port to run Sim on (default: 3000)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-pull&lt;/code&gt;: Skip pulling the latest Docker images&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Requirements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker must be installed and running on your machine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Option 2: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 3: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 4: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bunx drizzle-kit migrate 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ❤️ by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nautechsystems/nautilus_trader</title>
      <link>https://github.com/nautechsystems/nautilus_trader</link>
      <description>&lt;p&gt;A high-performance algorithmic trading platform and event-driven backtester&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png" width="500"&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codecov.io/gh/nautechsystems/nautilus_trader"&gt;&lt;img src="https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H" alt="codecov"&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/nautechsystems/nautilus_trader"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="codspeed"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/nautilus_trader" alt="pythons"&gt; &lt;img src="https://img.shields.io/pypi/v/nautilus_trader" alt="pypi-version"&gt; &lt;img src="https://img.shields.io/pypi/format/nautilus_trader?color=blue" alt="pypi-format"&gt; &lt;a href="https://pepy.tech/project/nautilus-trader"&gt;&lt;img src="https://pepy.tech/badge/nautilus-trader" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NautilusTrader"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Branch&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json" alt="version"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop" alt="build"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Rust&lt;/th&gt; 
   &lt;th align="left"&gt;Python&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.88.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.11-3.13*&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;* Windows builds are currently pinned to CPython 3.13.2, see &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/docs/getting_started/installation.md"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://nautilustrader.io/docs/"&gt;https://nautilustrader.io/docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: &lt;a href="mailto:support@nautilustrader.io"&gt;support@nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.&lt;/p&gt; 
&lt;p&gt;The platform is &lt;em&gt;AI-first&lt;/em&gt;, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.&lt;/p&gt; 
&lt;p&gt;NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.&lt;/p&gt; 
&lt;p&gt;The platform is also universal, and asset-class-agnostic — with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png" alt="nautilus-trader" title="nautilus-trader"&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Core is written in Rust with asynchronous networking using &lt;a href="https://crates.io/crates/tokio"&gt;tokio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Modular adapters mean any REST API or WebSocket feed can be integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Time in force &lt;code&gt;IOC&lt;/code&gt;, &lt;code&gt;FOK&lt;/code&gt;, &lt;code&gt;GTC&lt;/code&gt;, &lt;code&gt;GTD&lt;/code&gt;, &lt;code&gt;DAY&lt;/code&gt;, &lt;code&gt;AT_THE_OPEN&lt;/code&gt;, &lt;code&gt;AT_THE_CLOSE&lt;/code&gt;, advanced order types and conditional triggers. Execution instructions &lt;code&gt;post-only&lt;/code&gt;, &lt;code&gt;reduce-only&lt;/code&gt;, and icebergs. Contingency orders including &lt;code&gt;OCO&lt;/code&gt;, &lt;code&gt;OUO&lt;/code&gt;, &lt;code&gt;OTO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Add user-defined custom components, or assemble entire systems from scratch leveraging the &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; and &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting&lt;/strong&gt;: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live&lt;/strong&gt;: Use identical strategy implementations between backtesting and live deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-venue&lt;/strong&gt;: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Training&lt;/strong&gt;: Backtest engine fast enough to be used to train AI trading agents (RL/ES).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png" alt="Alt text" title="nautilus"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;nautilus - from ancient Greek 'sailor' and naus 'ship'.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why NautilusTrader?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant event-driven Python&lt;/strong&gt;: Native binary core components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parity between backtesting and live trading&lt;/strong&gt;: Identical strategy code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduced operational risk&lt;/strong&gt;: Enhanced risk management functionality, logical accuracy, and type safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly extendable&lt;/strong&gt;: Message bus, custom components and actors, custom data, custom adapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.&lt;/p&gt; 
&lt;p&gt;One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; or &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt;. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.&lt;/p&gt; 
&lt;h2&gt;Why Python?&lt;/h2&gt; 
&lt;p&gt;Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the &lt;em&gt;de facto lingua franca&lt;/em&gt; of data science, machine learning, and artificial intelligence.&lt;/p&gt; 
&lt;p&gt;developer/user communities. However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python's rich ecosystem of libraries and communities.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is "blazingly fast" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.&lt;/p&gt; 
&lt;p&gt;Rust’s rich type system and ownership model guarantees memory-safety and thread-safety deterministically — eliminating many classes of bugs at compile-time.&lt;/p&gt; 
&lt;p&gt;The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and &lt;a href="https://pyo3.rs"&gt;PyO3&lt;/a&gt;—no Rust toolchain is required at install time.&lt;/p&gt; 
&lt;p&gt;This project makes the &lt;a href="https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html"&gt;Soundness Pledge&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;“The intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.”&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is modularly designed to work with &lt;em&gt;adapters&lt;/em&gt;, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.&lt;/p&gt; 
&lt;p&gt;The following integrations are currently supported; see &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;docs/integrations/&lt;/a&gt; for details:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;ID&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://betfair.com"&gt;Betfair&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BETFAIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sports Betting Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.com"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.us"&gt;Binance US&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.binance.com/en/futures"&gt;Binance Futures&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bybit.com"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BYBIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinbase.com/en/international-exchange"&gt;Coinbase International&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;COINBASE_INTX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://databento.com"&gt;Databento&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABENTO&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DYDX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hyperliquid.xyz"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HYPERLIQUID&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/building-orange" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.interactivebrokers.com"&gt;Interactive Brokers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;INTERACTIVE_BROKERS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brokerage (multi-venue)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://okx.com"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OKX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/beta-yellow" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://polymarket.com"&gt;Polymarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;POLYMARKET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prediction Market (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tardis.dev"&gt;Tardis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TARDIS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt;: The default client ID for the integrations adapter clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: The type of integration (often the venue type).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;building&lt;/code&gt;: Under construction and likely not in a usable state.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;beta&lt;/code&gt;: Completed to a minimally working state and in a beta testing phase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt;: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/integrations/index.html"&gt;Integrations&lt;/a&gt; documentation for further details.&lt;/p&gt; 
&lt;h2&gt;Versioning and releases&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;NautilusTrader is still under active development&lt;/strong&gt;. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a &lt;strong&gt;best-effort basis&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;We aim to follow a &lt;strong&gt;bi-weekly release schedule&lt;/strong&gt;, though experimental or larger features may cause delays.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;p&gt;We aim to maintain a stable, passing build across all branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;master&lt;/code&gt;: Reflects the source code for the latest released version; recommended for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt;: Daily snapshots of the &lt;code&gt;develop&lt;/code&gt; branch for early testing; merged at &lt;strong&gt;14:00 UTC&lt;/strong&gt; or on demand.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt;: Active development branch for contributors and feature work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md"&gt;roadmap&lt;/a&gt; aims to achieve a &lt;strong&gt;stable API for version 2.x&lt;/strong&gt; (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Precision mode&lt;/h2&gt; 
&lt;p&gt;NautilusTrader supports two precision modes for its core value types (&lt;code&gt;Price&lt;/code&gt;, &lt;code&gt;Quantity&lt;/code&gt;, &lt;code&gt;Money&lt;/code&gt;), which differ in their internal bit-width and maximum decimal precision.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-precision&lt;/strong&gt;: 128-bit integers with up to 16 decimals of precision, and a larger value range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard-precision&lt;/strong&gt;: 64-bit integers with up to 9 decimals of precision, and a smaller value range.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;By default, the official Python wheels &lt;strong&gt;ship&lt;/strong&gt; in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support. For the Rust crates, the default is standard-precision unless you explicitly enable the &lt;code&gt;high-precision&lt;/code&gt; feature flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust feature flag&lt;/strong&gt;: To enable high-precision mode in Rust, add the &lt;code&gt;high-precision&lt;/code&gt; feature to your Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
nautilus_model = { version = "*", features = ["high-precision"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using the latest supported version of Python and installing &lt;a href="https://pypi.org/project/nautilus_trader/"&gt;nautilus_trader&lt;/a&gt; inside a virtual environment to isolate dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are two supported ways to install&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pre-built binary wheel from PyPI &lt;em&gt;or&lt;/em&gt; the Nautech Systems package index.&lt;/li&gt; 
 &lt;li&gt;Build from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We highly recommend installing using the &lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt; package manager with a "vanilla" CPython.&lt;/p&gt; 
 &lt;p&gt;Conda and other Python distributions &lt;em&gt;may&lt;/em&gt; work but aren’t officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;p&gt;To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From the Nautech Systems package index&lt;/h3&gt; 
&lt;p&gt;The Nautech Systems package index (&lt;code&gt;packages.nautechsystems.io&lt;/code&gt;) complies with &lt;a href="https://peps.python.org/pep-0503/"&gt;PEP-503&lt;/a&gt; and hosts both stable and development binary wheels for &lt;code&gt;nautilus_trader&lt;/code&gt;. This enables users to install either the latest stable release or pre-release versions for testing.&lt;/p&gt; 
&lt;h4&gt;Stable wheels&lt;/h4&gt; 
&lt;p&gt;Stable wheels correspond to official releases of &lt;code&gt;nautilus_trader&lt;/code&gt; on PyPI, and use standard versioning.&lt;/p&gt; 
&lt;p&gt;To install the latest stable release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Development wheels&lt;/h4&gt; 
&lt;p&gt;Development wheels are published from both the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; branches, allowing users to test features and fixes ahead of stable releases.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Wheels from the &lt;code&gt;develop&lt;/code&gt; branch are only built for the Linux x86_64 platform to save time and compute resources, while &lt;code&gt;nightly&lt;/code&gt; wheels support additional platforms as shown below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Nightly&lt;/th&gt; 
   &lt;th align="left"&gt;Develop&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;✓&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines, while adhering to &lt;a href="https://peps.python.org/pep-0440/"&gt;PEP-440&lt;/a&gt; versioning standards:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; wheels use the version format &lt;code&gt;dev{date}+{build_number}&lt;/code&gt; (e.g., &lt;code&gt;1.208.0.dev20241212+7001&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; wheels use the version format &lt;code&gt;a{date}&lt;/code&gt; (alpha) (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;We do not recommend using development wheels in production environments, such as live trading controlling real capital.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation commands&lt;/h4&gt; 
&lt;p&gt;By default, pip will install the latest stable release. Adding the &lt;code&gt;--pre&lt;/code&gt; flag ensures that pre-release versions, including development wheels, are considered.&lt;/p&gt; 
&lt;p&gt;To install the latest available pre-release (including development wheels):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific development wheel (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt; for December 12, 2024):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available versions&lt;/h4&gt; 
&lt;p&gt;You can view all available versions of &lt;code&gt;nautilus_trader&lt;/code&gt; on the &lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;package index&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To programmatically fetch and list available versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&amp;lt;=&amp;lt;a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Branch updates&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): Build and publish continuously with every merged commit.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): Build and publish daily when we automatically merge the &lt;code&gt;develop&lt;/code&gt; branch at &lt;strong&gt;14:00 UTC&lt;/strong&gt; (if there are changes).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Retention policies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): We retain only the most recent wheel build.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): We retain only the 10 most recent wheel builds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;It's possible to install from source using pip if you first install the build dependencies as specified in the &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; (the Rust toolchain installer):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl https://sh.rustup.rs -sSf | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Download and install &lt;a href="https://win.rustup.rs/x86_64"&gt;&lt;code&gt;rustup-init.exe&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Install "Desktop development with C++" with &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;rustc --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;cargo&lt;/code&gt; in the current shell:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Start a new PowerShell&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://clang.llvm.org/"&gt;clang&lt;/a&gt; (a C language frontend for LLVM):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install clang
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p&gt;Add Clang to your &lt;a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;amp;rel=16"&gt;Build Tools for Visual Studio 2019&lt;/a&gt;:&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (12.0.0 - x64…) = checked | Modify&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;clang&lt;/code&gt; in the current shell:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;[System.Environment]::SetEnvironmentVariable('path', "C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;clang --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install uv (see the &lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv installation guide&lt;/a&gt; for more details):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source with &lt;code&gt;git&lt;/code&gt;, and install from the project's root directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;--depth 1&lt;/code&gt; flag fetches just the latest commit for a faster, lightweight clone.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt; &lt;p&gt;Set environment variables for PyO3 compilation (Linux and macOS only):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Adjust the Python version and architecture in the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; to match your system. Use &lt;code&gt;uv python list&lt;/code&gt; to find the exact path for your Python installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for other options and further details.&lt;/p&gt; 
&lt;h2&gt;Redis&lt;/h2&gt; 
&lt;p&gt;Using &lt;a href="https://redis.io"&gt;Redis&lt;/a&gt; with NautilusTrader is &lt;strong&gt;optional&lt;/strong&gt; and only required if configured as the backend for a &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; database or &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;. See the &lt;strong&gt;Redis&lt;/strong&gt; section of the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation#redis"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Makefile&lt;/h2&gt; 
&lt;p&gt;A &lt;code&gt;Makefile&lt;/code&gt; is provided to automate most installation and build tasks for development. Some of the targets include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make install&lt;/code&gt;: Installs in &lt;code&gt;release&lt;/code&gt; build mode with all dependency groups and extras.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-debug&lt;/code&gt;: Same as &lt;code&gt;make install&lt;/code&gt; but with &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-just-deps&lt;/code&gt;: Installs just the &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt; dependencies (does not install package).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;: Runs the build script in &lt;code&gt;release&lt;/code&gt; build mode (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-debug&lt;/code&gt;: Runs the build script in &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;release&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel-debug&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;debug&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make cargo-test&lt;/code&gt;: Runs all Rust crate tests using &lt;code&gt;cargo-nextest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;: Deletes all build results, such as &lt;code&gt;.so&lt;/code&gt; or &lt;code&gt;.dll&lt;/code&gt; files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt;: &lt;strong&gt;CAUTION&lt;/strong&gt; Removes all artifacts not in the git index from the repository. This includes source files which have not been &lt;code&gt;git add&lt;/code&gt;ed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make docs&lt;/code&gt;: Builds the documentation HTML using Sphinx.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pre-commit&lt;/code&gt;: Runs the pre-commit checks over all files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make ruff&lt;/code&gt;: Runs ruff over all files using the &lt;code&gt;pyproject.toml&lt;/code&gt; config (with autofix).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pytest&lt;/code&gt;: Runs all tests with &lt;code&gt;pytest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test-performance&lt;/code&gt;: Runs performance tests with &lt;a href="https://codspeed.io"&gt;codspeed&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make help&lt;/code&gt; for documentation on all available make targets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md"&gt;crates/infrastructure/TESTS.md&lt;/a&gt; file for running the infrastructure integration tests.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py"&gt;indicator&lt;/a&gt; example written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/"&gt;indicator&lt;/a&gt; examples written in Cython.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/"&gt;strategy&lt;/a&gt; examples written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/"&gt;backtest&lt;/a&gt; examples using a &lt;code&gt;BacktestEngine&lt;/code&gt; directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;Docker containers are built using the base image &lt;code&gt;python:3.12-slim&lt;/code&gt; with the following variant tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:latest&lt;/code&gt; has the latest release version installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:latest&lt;/code&gt; has the latest release version installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can pull the container images as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/&amp;lt;image_variant_tag&amp;gt; --platform linux/amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can launch the backtest example container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64
docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open your browser at the following address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;http://127.0.0.1:8888/lab
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the &lt;code&gt;log_level&lt;/code&gt; to &lt;code&gt;ERROR&lt;/code&gt; in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jupyterlab/jupyterlab/issues/12845"&gt;https://github.com/jupyterlab/jupyterlab/issues/12845&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/deshaw/jupyterlab-limit-output"&gt;https://github.com/deshaw/jupyterlab-limit-output&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the &lt;a href="https://nautilustrader.io/docs/latest/developer_guide/index.html"&gt;Developer Guide&lt;/a&gt; for helpful information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make build-debug&lt;/code&gt; to compile after changes to Rust or Cython code for the most efficient development workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Testing with Rust&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://nexte.st"&gt;cargo-nextest&lt;/a&gt; is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.&lt;/p&gt; 
&lt;p&gt;You can install cargo-nextest by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-nextest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run Rust tests with &lt;code&gt;make cargo-test&lt;/code&gt;, which uses &lt;strong&gt;cargo-nextest&lt;/strong&gt; with an efficient profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an &lt;a href="https://github.com/nautechsystems/nautilus_trader/issues"&gt;issue&lt;/a&gt; on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.&lt;/p&gt; 
&lt;p&gt;Before getting started, be sure to review the &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope"&gt;open-source scope&lt;/a&gt; outlined in the project’s roadmap to understand what’s in and out of scope.&lt;/p&gt; 
&lt;p&gt;Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Pull requests should target the &lt;code&gt;develop&lt;/code&gt; branch (the default branch). This is where new features and improvements are integrated before release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community of users and contributors on &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord&lt;/a&gt; to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.&lt;/p&gt; 
 &lt;p&gt;All official updates and communications from NautilusTrader will be shared exclusively through &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;, our &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord server&lt;/a&gt;, or our X (Twitter) account: &lt;a href="https://x.com/NautilusTrader"&gt;@NautilusTrader&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;If you encounter any suspicious activity, please report it to the appropriate platform and contact us at &lt;a href="mailto:info@nautechsystems.io"&gt;info@nautechsystems.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code for NautilusTrader is available on GitHub under the &lt;a href="https://www.gnu.org/licenses/lgpl-3.0.en.html"&gt;GNU Lesser General Public License v3.0&lt;/a&gt;. Contributions to the project are welcome and require the completion of a standard &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md"&gt;Contributor License Agreement (CLA)&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;NautilusTrader™ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png" alt="nautechsystems" title="nautechsystems"&gt; &lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png" width="128"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/openai-cookbook</title>
      <link>https://github.com/openai/openai-cookbook</link>
      <description>&lt;p&gt;Examples and guides for using the OpenAI API&lt;/p&gt;&lt;hr&gt;&lt;a href="https://cookbook.openai.com" target="_blank"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="/images/openai-cookbook-white.png" style="max-width: 100%; width: 400px; margin-bottom: 20px"&gt; 
  &lt;img alt="OpenAI Cookbook Logo" src="https://raw.githubusercontent.com/openai/openai-cookbook/main/images/openai-cookbook.png" width="400px"&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✨ Navigate at &lt;a href="https://cookbook.openai.com"&gt;cookbook.openai.com&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Example code and guides for accomplishing common tasks with the &lt;a href="https://platform.openai.com/docs/introduction"&gt;OpenAI API&lt;/a&gt;. To run these examples, you'll need an OpenAI account and associated API key (&lt;a href="https://platform.openai.com/signup"&gt;create a free account here&lt;/a&gt;). Set an environment variable called &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; with your API key. Alternatively, in most IDEs such as Visual Studio Code, you can create an &lt;code&gt;.env&lt;/code&gt; file at the root of your repo containing &lt;code&gt;OPENAI_API_KEY=&amp;lt;your API key&amp;gt;&lt;/code&gt;, which will be picked up by the notebooks.&lt;/p&gt; 
&lt;p&gt;Most code examples are written in Python, though the concepts can be applied in any language.&lt;/p&gt; 
&lt;p&gt;For other useful tools, guides and courses, check out these &lt;a href="https://cookbook.openai.com/related_resources"&gt;related resources from around the web&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dotnet/efcore</title>
      <link>https://github.com/dotnet/efcore</link>
      <description>&lt;p&gt;EF Core is a modern object-database mapper for .NET. It supports LINQ queries, change tracking, updates, and schema migrations.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Repository&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://dev.azure.com/dnceng-public/public/_build?definitionId=17"&gt;&lt;img src="https://img.shields.io/azure-devops/build/dnceng-public/public/17/main" alt="build status"&gt;&lt;/a&gt; &lt;a href="https://dev.azure.com/dnceng-public/public/_build?definitionId=17"&gt;&lt;img src="https://img.shields.io/azure-devops/tests/dnceng-public/public/17/main" alt="test results"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository is home to the following &lt;a href="https://dotnetfoundation.org/"&gt;.NET Foundation&lt;/a&gt; projects. These projects are maintained by &lt;a href="https://github.com/microsoft"&gt;Microsoft&lt;/a&gt; and licensed under the &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/LICENSE.txt"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/#entity-framework-core"&gt;Entity Framework Core&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/#microsoftdatasqlite"&gt;Microsoft.Data.Sqlite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;img alt="EF" src="https://raw.githubusercontent.com/dotnet/efcore/main/logo/ef-logo.png" width="32"&gt; Entity Framework Core&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.nuget.org/packages/Microsoft.EntityFrameworkCore"&gt;&lt;img src="https://img.shields.io/nuget/v/Microsoft.EntityFrameworkCore" alt="latest version"&gt;&lt;/a&gt; &lt;a href="https://www.nuget.org/packages/Microsoft.EntityFrameworkCore/absoluteLatest"&gt;&lt;img src="https://img.shields.io/nuget/vpre/Microsoft.EntityFrameworkCore" alt="preview version"&gt;&lt;/a&gt; &lt;a href="https://www.nuget.org/packages/Microsoft.EntityFrameworkCore"&gt;&lt;img src="https://img.shields.io/nuget/dt/Microsoft.EntityFrameworkCore" alt="downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;EF Core is a modern object-database mapper for .NET. It supports LINQ queries, change tracking, updates, and schema migrations. EF Core works with SQL Server, Azure SQL Database, SQLite, Azure Cosmos DB, MariaDB, MySQL, PostgreSQL, and other databases through a provider plugin API.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;EF Core is available on &lt;a href="https://www.nuget.org/packages/Microsoft.EntityFrameworkCore"&gt;NuGet&lt;/a&gt;. Install the provider package corresponding to your target database. See the &lt;a href="https://docs.microsoft.com/ef/core/providers/"&gt;list of providers&lt;/a&gt; in the docs for additional databases.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;dotnet add package Microsoft.EntityFrameworkCore.SqlServer
dotnet add package Microsoft.EntityFrameworkCore.Sqlite
dotnet add package Microsoft.EntityFrameworkCore.Cosmos
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the &lt;code&gt;--version&lt;/code&gt; option to specify a &lt;a href="https://www.nuget.org/packages/Microsoft.EntityFrameworkCore/absoluteLatest"&gt;preview version&lt;/a&gt; to install.&lt;/p&gt; 
&lt;h3&gt;Daily builds&lt;/h3&gt; 
&lt;p&gt;We recommend using the &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/docs/DailyBuilds.md"&gt;daily builds&lt;/a&gt; to get the latest code and provide feedback on EF Core. These builds contain latest features and bug fixes; previews and official releases lag significantly behind.&lt;/p&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;p&gt;The following code demonstrates basic usage of EF Core. For a full tutorial configuring the &lt;code&gt;DbContext&lt;/code&gt;, defining the model, and creating the database, see &lt;a href="https://docs.microsoft.com/ef/core/get-started/"&gt;getting started&lt;/a&gt; in the docs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-cs"&gt;using var db = new BloggingContext();

// Inserting data into the database
db.Add(new Blog { Url = "http://blogs.msdn.com/adonet" });
db.SaveChanges();

// Querying
var blog = db.Blogs
    .OrderBy(b =&amp;gt; b.BlogId)
    .First();

// Updating
blog.Url = "https://devblogs.microsoft.com/dotnet";
blog.Posts.Add(
    new Post
    {
        Title = "Hello World",
        Content = "I wrote an app using EF Core!"
    });
db.SaveChanges();

// Deleting
db.Remove(blog);
db.SaveChanges();
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;p&gt;Most people use EF Core by installing pre-built NuGet packages, as shown above. Alternatively, &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/docs/getting-and-building-the-code.md"&gt;the code can be built and packages can be created directly on your development machine&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome community pull requests for bug fixes, enhancements, and documentation. See &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/.github/CONTRIBUTING.md"&gt;How to contribute&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Getting support&lt;/h3&gt; 
&lt;p&gt;If you have a specific question about using these projects, we encourage you to &lt;a href="https://stackoverflow.com/questions/tagged/entity-framework-core*?tab=Votes"&gt;ask it on Stack Overflow&lt;/a&gt;. If you encounter a bug or would like to request a feature, &lt;a href="https://github.com/dotnet/efcore/issues/new/choose"&gt;submit an issue&lt;/a&gt;. For more details, see &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/.github/SUPPORT.md"&gt;getting support&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Microsoft.Data.Sqlite&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.nuget.org/packages/Microsoft.Data.Sqlite"&gt;&lt;img src="https://img.shields.io/nuget/v/Microsoft.Data.Sqlite" alt="latest version"&gt;&lt;/a&gt; &lt;a href="https://www.nuget.org/packages/Microsoft.Data.Sqlite/absoluteLatest"&gt;&lt;img src="https://img.shields.io/nuget/vpre/Microsoft.Data.Sqlite" alt="preview version"&gt;&lt;/a&gt; &lt;a href="https://www.nuget.org/packages/Microsoft.Data.Sqlite"&gt;&lt;img src="https://img.shields.io/nuget/dt/Microsoft.Data.Sqlite.Core" alt="downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Microsoft.Data.Sqlite is a lightweight ADO.NET provider for SQLite. The EF Core provider for SQLite is built on top of this library. However, it can also be used independently or with other data access libraries.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The latest stable version is available on &lt;a href="https://www.nuget.org/packages/Microsoft.Data.Sqlite"&gt;NuGet&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;dotnet add package Microsoft.Data.Sqlite
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use the &lt;code&gt;--version&lt;/code&gt; option to specify a &lt;a href="https://www.nuget.org/packages/Microsoft.Data.Sqlite/absoluteLatest"&gt;preview version&lt;/a&gt; to install.&lt;/p&gt; 
&lt;h3&gt;Daily builds&lt;/h3&gt; 
&lt;p&gt;We recommend using the &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/docs/DailyBuilds.md"&gt;daily builds&lt;/a&gt; to get the latest code and provide feedback on Microsoft.Data.Sqlite. These builds contain the latest features and bug fixes; previews and official releases lag significantly behind.&lt;/p&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;p&gt;This library implements the common &lt;a href="https://docs.microsoft.com/dotnet/framework/data/adonet/"&gt;ADO.NET&lt;/a&gt; abstractions for connections, commands, data readers, and so on. For more information, see &lt;a href="https://docs.microsoft.com/dotnet/standard/data/sqlite/"&gt;Microsoft.Data.Sqlite&lt;/a&gt; on Microsoft Docs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-cs"&gt;using var connection = new SqliteConnection("Data Source=Blogs.db");
connection.Open();

using var command = connection.CreateCommand();
command.CommandText = "SELECT Url FROM Blogs";

using var reader = command.ExecuteReader();
while (reader.Read())
{
    var url = reader.GetString(0);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;p&gt;Most people use Microsoft.Data.Sqlite by installing pre-built NuGet packages, as shown above. Alternatively, &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/docs/getting-and-building-the-code.md"&gt;the code can be built and packages can be created directly on your development machine&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome community pull requests for bug fixes, enhancements, and documentation. See &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/.github/CONTRIBUTING.md"&gt;How to contribute&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Getting support&lt;/h3&gt; 
&lt;p&gt;If you have a specific question about using these projects, we encourage you to &lt;a href="https://stackoverflow.com/questions/tagged/microsoft.data.sqlite"&gt;ask it on Stack Overflow&lt;/a&gt;. If you encounter a bug or would like to request a feature, &lt;a href="https://github.com/dotnet/efcore/issues/new/choose"&gt;submit an issue&lt;/a&gt;. For more details, see &lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/.github/SUPPORT.md"&gt;getting support&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.microsoft.com/ef/core/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.microsoft.com/ef/core/what-is-new/roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dotnet/efcore/issues/23884"&gt;Weekly status updates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.microsoft.com/ef/core/what-is-new/release-planning"&gt;Release planning process&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.microsoft.com/ef/core/providers/writing-a-provider"&gt;How to write an EF Core provider&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/docs/security.md"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/efcore/main/.github/CODE_OF_CONDUCT.md"&gt;Code of conduct&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>xiaoyaocz/dart_simple_live</title>
      <link>https://github.com/xiaoyaocz/dart_simple_live</link>
      <description>&lt;p&gt;简简单单的看直播&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;h3&gt;⚠ 本项目不提供Release安装包，请自行编译后运行测试。&lt;/h3&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img width="128" src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/logo.png" alt="Simple Live logo"&gt; &lt;/p&gt; 
&lt;h2 align="center"&gt;Simple Live&lt;/h2&gt; 
&lt;p align="center"&gt; 简简单单的看直播 &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/screenshot_light.jpg" alt="浅色模式"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/screenshot_dark.jpg" alt="深色模式"&gt;&lt;/p&gt; 
&lt;h2&gt;支持直播平台：&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;虎牙直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;斗鱼直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;哔哩哔哩直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抖音直播&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;APP支持平台&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Android&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; iOS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Windows &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; MacOS &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Linux &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Android TV &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;项目结构&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_core&lt;/code&gt; 项目核心库，实现获取各个网站的信息及弹幕。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_console&lt;/code&gt; 基于simple_live_core的控制台程序。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_app&lt;/code&gt; 基于核心库实现的Flutter APP客户端。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_tv_app&lt;/code&gt; 基于核心库实现的Flutter Android TV客户端。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;环境&lt;/h2&gt; 
&lt;p&gt;Flutter : &lt;code&gt;3.22&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;参考及引用&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/xiaoyaocz/AllLive"&gt;AllLive&lt;/a&gt; &lt;code&gt;本项目的C#版，有兴趣可以看看&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/xiaoyaocz/dart_tars_protocol.git"&gt;dart_tars_protocol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/wbt5/real-url"&gt;wbt5/real-url&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lovelyyoshino/Bilibili-Live-API/raw/master/API.WebSocket.md"&gt;lovelyyoshino/Bilibili-Live-API&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/IsoaSFlus/danmaku"&gt;IsoaSFlus/danmaku&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/BacooTang/huya-danmu"&gt;BacooTang/huya-danmu&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/TarsCloud/Tars"&gt;TarsCloud/Tars&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/YunzhiYike/douyin-live"&gt;YunzhiYike/douyin-live&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/5ime/Tiktok_Signature"&gt;5ime/Tiktok_Signature&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;声明&lt;/h2&gt; 
&lt;p&gt;本项目的所有功能都是基于互联网上公开的资料开发，无任何破解、逆向工程等行为。&lt;/p&gt; 
&lt;p&gt;本项目仅用于学习交流编程技术，严禁将本项目用于商业目的。如有任何商业行为，均与本项目无关。&lt;/p&gt; 
&lt;p&gt;如果本项目存在侵犯您的合法权益的情况，请及时与开发者联系，开发者将会及时删除有关内容。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png"&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status"&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack"&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community%20forum-@netbird-red.svg?logo=discourse"&gt; &lt;/a&gt; &lt;br&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br&gt; &lt;/strong&gt; &lt;br&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;img width="1188" alt="centralized-network-management 1" src="https://github.com/user-attachments/assets/c28cc8e4-15d2-4d2f-bb97-a6433db39d56"&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png" width="700"&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)"&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuard®&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ethereum/solidity</title>
      <link>https://github.com/ethereum/solidity</link>
      <description>&lt;p&gt;Solidity, the Smart Contract Programming Language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Solidity Contract-Oriented Programming Language&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://matrix.to/#/%23ethereum_solidity:gitter.im"&gt;&lt;img src="https://img.shields.io/badge/Matrix%20-chat-brightgreen?style=plastic&amp;amp;logo=matrix" alt="Matrix Chat"&gt;&lt;/a&gt; &lt;a href="https://gitter.im/ethereum/solidity"&gt;&lt;img src="https://img.shields.io/badge/Gitter%20-chat-brightgreen?style=plastic&amp;amp;logo=gitter" alt="Gitter Chat"&gt;&lt;/a&gt; &lt;a href="https://forum.soliditylang.org/"&gt;&lt;img src="https://img.shields.io/badge/Solidity_Forum%20-discuss-brightgreen?style=plastic&amp;amp;logo=discourse" alt="Solidity&amp;nbsp;Forum"&gt;&lt;/a&gt; &lt;a href="https://X.com/solidity_lang"&gt;&lt;img src="https://img.shields.io/twitter/follow/solidity_lang?style=plastic&amp;amp;logo=x" alt="X Follow"&gt;&lt;/a&gt; &lt;a href="https://fosstodon.org/@solidity"&gt;&lt;img src="https://img.shields.io/mastodon/follow/000335908?domain=https%3A%2F%2Ffosstodon.org%2F&amp;amp;logo=mastodon&amp;amp;style=plastic" alt="Mastodon Follow"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can talk to us on Gitter and Matrix, tweet at us on X (previously Twitter) or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome!&lt;/p&gt; 
&lt;p&gt;Solidity is a statically-typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform.&lt;/p&gt; 
&lt;p&gt;For a good overview and starting point, please check out the official &lt;a href="https://soliditylang.org"&gt;Solidity Language Portal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#background"&gt;Background&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#build-and-install"&gt;Build and Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#example"&gt;Example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#development"&gt;Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#maintainers"&gt;Maintainers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Background&lt;/h2&gt; 
&lt;p&gt;Solidity is a statically-typed curly-braces programming language designed for developing smart contracts that run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer network where nobody has special authority over the execution, and thus they allow anyone to implement tokens of value, ownership, voting, and other kinds of logic.&lt;/p&gt; 
&lt;p&gt;When deploying contracts, you should use the latest released version of Solidity. This is because breaking changes, as well as new features and bug fixes, are introduced regularly. We currently use a 0.x version number &lt;a href="https://semver.org/#spec-item-4"&gt;to indicate this fast pace of change&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Build and Install&lt;/h2&gt; 
&lt;p&gt;Instructions about how to build and install the Solidity compiler can be found in the &lt;a href="https://docs.soliditylang.org/en/latest/installing-solidity.html#building-from-source"&gt;Solidity documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A "Hello World" program in Solidity is of even less use than in other languages, but still:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-solidity"&gt;// SPDX-License-Identifier: MIT
pragma solidity &amp;gt;=0.6.0 &amp;lt;0.9.0;

contract HelloWorld {
    function helloWorld() external pure returns (string memory) {
        return "Hello, World!";
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get started with Solidity, you can use &lt;a href="https://remix.ethereum.org/"&gt;Remix&lt;/a&gt;, which is a browser-based IDE. Here are some example contracts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.soliditylang.org/en/latest/solidity-by-example.html#voting"&gt;Voting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.soliditylang.org/en/latest/solidity-by-example.html#blind-auction"&gt;Blind Auction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.soliditylang.org/en/latest/solidity-by-example.html#safe-remote-purchase"&gt;Safe remote purchase&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.soliditylang.org/en/latest/solidity-by-example.html#micropayment-channel"&gt;Micropayment Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The Solidity documentation is hosted using &lt;a href="https://docs.soliditylang.org"&gt;Read the Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Solidity is still under development. Contributions are always welcome! Please follow the &lt;a href="https://docs.soliditylang.org/en/latest/contributing.html"&gt;Developer's Guide&lt;/a&gt; if you want to help.&lt;/p&gt; 
&lt;p&gt;You can find our current feature and bug priorities for forthcoming releases in the &lt;a href="https://github.com/ethereum/solidity/projects"&gt;projects section&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;The Solidity programming language and compiler are open-source community projects governed by a core team. The core team is sponsored by the &lt;a href="https://ethereum.foundation/"&gt;Ethereum Foundation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Solidity is licensed under &lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/LICENSE.txt"&gt;GNU General Public License v3.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some third-party code has its &lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/cmake/templates/license.h.in"&gt;own licensing terms&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;The security policy may be &lt;a href="https://raw.githubusercontent.com/ethereum/solidity/develop/SECURITY.md"&gt;found here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jesseduffield/lazygit</title>
      <link>https://github.com/jesseduffield/lazygit</link>
      <description>&lt;p&gt;simple terminal UI for git commands&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;a href="https://www.warp.dev/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=lazygit_20231023"&gt; 
  &lt;div&gt; 
   &lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/warp.png" width="330" alt="Warp"&gt; 
  &lt;/div&gt; &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt; &lt;br&gt; &lt;b&gt;Available for MacOS and Linux&lt;/b&gt; &lt;br&gt; 
  &lt;div&gt; 
   &lt;sup&gt;Visit&amp;nbsp;warp.dev&amp;nbsp;to learn more.&lt;/sup&gt; 
  &lt;/div&gt; &lt;/a&gt; 
 &lt;br&gt; 
 &lt;hr&gt; 
 &lt;a href="https://www.subble.com"&gt; 
  &lt;div&gt; 
   &lt;img src="https://subble-marketing-portal-media-storage.s3.amazonaws.com/images/subble-black-name-logo.svg?sanitize=true" width="230" alt="Subble"&gt; 
  &lt;/div&gt; &lt;b&gt;I (Jesse) co-founded Subble to save your company time and money by helping you manage its software subscriptions. Check it out!&lt;/b&gt; &lt;/a&gt; 
 &lt;br&gt; 
 &lt;hr&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img width="536" src="https://user-images.githubusercontent.com/8456633/174470852-339b5011-5800-4bb9-a628-ff230aa8cd4e.png"&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;A simple terminal UI for git commands &lt;br&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/jesseduffield/lazygit/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/jesseduffield/lazygit/total" alt="GitHub Releases"&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/jesseduffield/lazygit"&gt;&lt;img src="https://goreportcard.com/badge/github.com/jesseduffield/lazygit" alt="Go Report Card"&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_grade"&gt;&lt;img src="https://app.codacy.com/project/badge/Grade/f46416b715d74622895657935fcada21" alt="Codacy Badge"&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_coverage"&gt;&lt;img src="https://app.codacy.com/project/badge/Coverage/f46416b715d74622895657935fcada21" alt="Codacy Badge"&gt;&lt;/a&gt; &lt;a href="https://golangci.com"&gt;&lt;img src="https://golangci.com/badges/github.com/jesseduffield/lazygit.svg?sanitize=true" alt="GolangCI"&gt;&lt;/a&gt; &lt;a href="https://github.com/jesseduffield/lazygit/releases/latest"&gt;&lt;img src="https://img.shields.io/github/tag/jesseduffield/lazygit.svg?sanitize=true" alt="GitHub tag"&gt;&lt;/a&gt; &lt;a href="https://github.com/Homebrew/homebrew-core/raw/master/Formula/lazygit.rb"&gt;&lt;img src="https://img.shields.io/homebrew/v/lazygit" alt="homebrew"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/commit_and_push-compressed.gif" alt="commit_and_push"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt; Maintenance of this project is made possible by all the &lt;a href="https://github.com/jesseduffield/lazygit/graphs/contributors"&gt;contributors&lt;/a&gt; and &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsors&lt;/a&gt;. If you'd like to sponsor this project and have your avatar or company logo appear below &lt;a href="https://github.com/sponsors/jesseduffield"&gt;click here&lt;/a&gt;. 💙 &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- sponsors --&gt;&lt;a href="https://github.com/intabulas"&gt;&lt;img src="https://github.com/intabulas.png" width="60px" alt="Mark Lussier"&gt;&lt;/a&gt;&lt;a href="https://github.com/peppy"&gt;&lt;img src="https://github.com/peppy.png" width="60px" alt="Dean Herbert"&gt;&lt;/a&gt;&lt;a href="https://github.com/piot"&gt;&lt;img src="https://github.com/piot.png" width="60px" alt="Peter Bjorklund"&gt;&lt;/a&gt;&lt;a href="https://github.com/rgwood"&gt;&lt;img src="https://github.com/rgwood.png" width="60px" alt="Reilly Wood"&gt;&lt;/a&gt;&lt;a href="https://github.com/oliverguenther"&gt;&lt;img src="https://github.com/oliverguenther.png" width="60px" alt="Oliver Günther"&gt;&lt;/a&gt;&lt;a href="https://github.com/pawanjay176"&gt;&lt;img src="https://github.com/pawanjay176.png" width="60px" alt="Pawan Dhananjay"&gt;&lt;/a&gt;&lt;a href="https://github.com/bdach"&gt;&lt;img src="https://github.com/bdach.png" width="60px" alt="Bartłomiej Dach"&gt;&lt;/a&gt;&lt;a href="https://github.com/carstengehling"&gt;&lt;img src="https://github.com/carstengehling.png" width="60px" alt="Carsten Gehling"&gt;&lt;/a&gt;&lt;a href="https://github.com/ceuk"&gt;&lt;img src="https://github.com/ceuk.png" width="60px" alt="CEUK"&gt;&lt;/a&gt;&lt;a href="https://github.com/Xetera"&gt;&lt;img src="https://github.com/Xetera.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/HoldenLucas"&gt;&lt;img src="https://github.com/HoldenLucas.png" width="60px" alt="Holden Lucas"&gt;&lt;/a&gt;&lt;a href="https://github.com/nartc"&gt;&lt;img src="https://github.com/nartc.png" width="60px" alt="Chau Tran"&gt;&lt;/a&gt;&lt;a href="https://github.com/matejcik"&gt;&lt;img src="https://github.com/matejcik.png" width="60px" alt="matejcik"&gt;&lt;/a&gt;&lt;a href="https://github.com/lucatume"&gt;&lt;img src="https://github.com/lucatume.png" width="60px" alt="theAverageDev (Luca Tumedei)"&gt;&lt;/a&gt;&lt;a href="https://github.com/IvanZuy"&gt;&lt;img src="https://github.com/IvanZuy.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/nicholascloud"&gt;&lt;img src="https://github.com/nicholascloud.png" width="60px" alt="Nicholas Cloud"&gt;&lt;/a&gt;&lt;a href="https://github.com/ava1ar"&gt;&lt;img src="https://github.com/ava1ar.png" width="60px" alt="Aliaksandr Stelmachonak"&gt;&lt;/a&gt;&lt;a href="https://github.com/minidfx"&gt;&lt;img src="https://github.com/minidfx.png" width="60px" alt="Burgy Benjamin"&gt;&lt;/a&gt;&lt;a href="https://github.com/JoeKlemmer"&gt;&lt;img src="https://github.com/JoeKlemmer.png" width="60px" alt="Joe Klemmer"&gt;&lt;/a&gt;&lt;a href="https://github.com/tobi"&gt;&lt;img src="https://github.com/tobi.png" width="60px" alt="Tobias Lütke"&gt;&lt;/a&gt;&lt;a href="https://github.com/benbfortis"&gt;&lt;img src="https://github.com/benbfortis.png" width="60px" alt="Ben Beaumont"&gt;&lt;/a&gt;&lt;a href="https://github.com/jakewarren"&gt;&lt;img src="https://github.com/jakewarren.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/tgpholly"&gt;&lt;img src="https://github.com/tgpholly.png" width="60px" alt="Holly"&gt;&lt;/a&gt;&lt;a href="https://github.com/socketbox"&gt;&lt;img src="https://github.com/socketbox.png" width="60px" alt="Casey Boettcher"&gt;&lt;/a&gt;&lt;a href="https://github.com/bitprophet"&gt;&lt;img src="https://github.com/bitprophet.png" width="60px" alt="Jeff Forcier"&gt;&lt;/a&gt;&lt;a href="https://github.com/tayleighr"&gt;&lt;img src="https://github.com/tayleighr.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/Novakov"&gt;&lt;img src="https://github.com/Novakov.png" width="60px" alt="Maciej T. Nowak"&gt;&lt;/a&gt;&lt;a href="https://github.com/nekhaevskiy"&gt;&lt;img src="https://github.com/nekhaevskiy.png" width="60px" alt="Yury"&gt;&lt;/a&gt;&lt;a href="https://github.com/reivilibre"&gt;&lt;img src="https://github.com/reivilibre.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/andreaskurth"&gt;&lt;img src="https://github.com/andreaskurth.png" width="60px" alt="Andreas Kurth"&gt;&lt;/a&gt;&lt;a href="https://github.com/BSteffaniak"&gt;&lt;img src="https://github.com/BSteffaniak.png" width="60px" alt="Braden Steffaniak"&gt;&lt;/a&gt;&lt;a href="https://github.com/jordan-gillard"&gt;&lt;img src="https://github.com/jordan-gillard.png" width="60px" alt="Jordan Gillard"&gt;&lt;/a&gt;&lt;a href="https://github.com/smangels"&gt;&lt;img src="https://github.com/smangels.png" width="60px" alt="Sebastian"&gt;&lt;/a&gt;&lt;a href="https://github.com/amslezak"&gt;&lt;img src="https://github.com/amslezak.png" width="60px" alt="Andy Slezak"&gt;&lt;/a&gt;&lt;a href="https://github.com/mkock"&gt;&lt;img src="https://github.com/mkock.png" width="60px" alt="Martin Kock"&gt;&lt;/a&gt;&lt;a href="https://github.com/jessealama"&gt;&lt;img src="https://github.com/jessealama.png" width="60px" alt="Jesse Alama"&gt;&lt;/a&gt;&lt;a href="https://github.com/danielkokott"&gt;&lt;img src="https://github.com/danielkokott.png" width="60px" alt="Daniel Kokott"&gt;&lt;/a&gt;&lt;a href="https://github.com/heijmans"&gt;&lt;img src="https://github.com/heijmans.png" width="60px" alt="Jan Heijmans"&gt;&lt;/a&gt;&lt;a href="https://github.com/knowald"&gt;&lt;img src="https://github.com/knowald.png" width="60px" alt="Kevin Nowald"&gt;&lt;/a&gt;&lt;a href="https://github.com/omarluq"&gt;&lt;img src="https://github.com/omarluq.png" width="60px" alt="Omar Luq"&gt;&lt;/a&gt;&lt;a href="https://github.com/ethanjli"&gt;&lt;img src="https://github.com/ethanjli.png" width="60px" alt="Ethan Li"&gt;&lt;/a&gt;&lt;a href="https://github.com/phubaba"&gt;&lt;img src="https://github.com/phubaba.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/canhazcodez"&gt;&lt;img src="https://github.com/canhazcodez.png" width="60px" alt="Maxi"&gt;&lt;/a&gt;&lt;a href="https://github.com/neunkasulle"&gt;&lt;img src="https://github.com/neunkasulle.png" width="60px" alt="Jan Zenkner"&gt;&lt;/a&gt;&lt;a href="https://github.com/RVxLab"&gt;&lt;img src="https://github.com/RVxLab.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/FrederickGeek8"&gt;&lt;img src="https://github.com/FrederickGeek8.png" width="60px" alt="Frederick Morlock"&gt;&lt;/a&gt;&lt;a href="https://github.com/ezdac"&gt;&lt;img src="https://github.com/ezdac.png" width="60px" alt="Maximilian Langenfeld"&gt;&lt;/a&gt;&lt;a href="https://github.com/dbuls"&gt;&lt;img src="https://github.com/dbuls.png" width="60px" alt="Davis Buls"&gt;&lt;/a&gt;&lt;a href="https://github.com/lppassos"&gt;&lt;img src="https://github.com/lppassos.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/neilcode"&gt;&lt;img src="https://github.com/neilcode.png" width="60px" alt="Neil Lambert"&gt;&lt;/a&gt;&lt;a href="https://github.com/dhh"&gt;&lt;img src="https://github.com/dhh.png" width="60px" alt="David Heinemeier Hansson"&gt;&lt;/a&gt;&lt;a href="https://github.com/ethanfischer"&gt;&lt;img src="https://github.com/ethanfischer.png" width="60px" alt="Ethan Fischer"&gt;&lt;/a&gt;&lt;a href="https://github.com/poshboytl"&gt;&lt;img src="https://github.com/poshboytl.png" width="60px" alt="Terry Tai"&gt;&lt;/a&gt;&lt;a href="https://github.com/roesnera"&gt;&lt;img src="https://github.com/roesnera.png" width="60px" alt="Adam Roesner"&gt;&lt;/a&gt;&lt;a href="https://github.com/seven1m"&gt;&lt;img src="https://github.com/seven1m.png" width="60px" alt="Tim Morgan"&gt;&lt;/a&gt;&lt;a href="https://github.com/sgoridotla1"&gt;&lt;img src="https://github.com/sgoridotla1.png" width="60px" alt="Max Shypulniak"&gt;&lt;/a&gt;&lt;a href="https://github.com/ADIX7"&gt;&lt;img src="https://github.com/ADIX7.png" width="60px" alt="Kovács Ádám"&gt;&lt;/a&gt;&lt;a href="https://github.com/slowdub"&gt;&lt;img src="https://github.com/slowdub.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/serranomorante"&gt;&lt;img src="https://github.com/serranomorante.png" width="60px" alt="Patricio Serrano"&gt;&lt;/a&gt;&lt;a href="https://github.com/kiriDevs"&gt;&lt;img src="https://github.com/kiriDevs.png" width="60px" alt="Kiri"&gt;&lt;/a&gt;&lt;a href="https://github.com/Bparsons0904"&gt;&lt;img src="https://github.com/Bparsons0904.png" width="60px" alt="Bob Parsons"&gt;&lt;/a&gt;&lt;a href="https://github.com/bjornevik"&gt;&lt;img src="https://github.com/bjornevik.png" width="60px" alt="John Even Bjørnevik"&gt;&lt;/a&gt;&lt;a href="https://github.com/moberst"&gt;&lt;img src="https://github.com/moberst.png" width="60px" alt="Michael Oberst"&gt;&lt;/a&gt;&lt;a href="https://github.com/stianh"&gt;&lt;img src="https://github.com/stianh.png" width="60px" alt="Stian Hegglund"&gt;&lt;/a&gt;&lt;a href="https://github.com/adam-e-trepanier"&gt;&lt;img src="https://github.com/adam-e-trepanier.png" width="60px" alt="Adam Trepanier"&gt;&lt;/a&gt;&lt;a href="https://github.com/arkalon76"&gt;&lt;img src="https://github.com/arkalon76.png" width="60px" alt="Kenth Fagerlund"&gt;&lt;/a&gt;&lt;a href="https://github.com/Djuuu"&gt;&lt;img src="https://github.com/Djuuu.png" width="60px" alt="Julien Tardot"&gt;&lt;/a&gt;&lt;a href="https://github.com/antikytheraton"&gt;&lt;img src="https://github.com/antikytheraton.png" width="60px" alt="Aaron Arredondo"&gt;&lt;/a&gt;&lt;a href="https://github.com/ellord"&gt;&lt;img src="https://github.com/ellord.png" width="60px" alt="Ellord Tayag"&gt;&lt;/a&gt;&lt;a href="https://github.com/EdgarPost"&gt;&lt;img src="https://github.com/EdgarPost.png" width="60px" alt="Edgar Post-Buijs"&gt;&lt;/a&gt;&lt;a href="https://github.com/sbc64"&gt;&lt;img src="https://github.com/sbc64.png" width="60px" alt="sbc64"&gt;&lt;/a&gt;&lt;a href="https://github.com/caillou"&gt;&lt;img src="https://github.com/caillou.png" width="60px" alt="Pierre Spring"&gt;&lt;/a&gt;&lt;a href="https://github.com/mebezac"&gt;&lt;img src="https://github.com/mebezac.png" width="60px" alt="Zac Clay"&gt;&lt;/a&gt;&lt;a href="https://github.com/Tom94"&gt;&lt;img src="https://github.com/Tom94.png" width="60px" alt="Thomas Müller"&gt;&lt;/a&gt;&lt;a href="https://github.com/ccssmnn"&gt;&lt;img src="https://github.com/ccssmnn.png" width="60px" alt="Carl Assmann"&gt;&lt;/a&gt;&lt;a href="https://github.com/ognevsd"&gt;&lt;img src="https://github.com/ognevsd.png" width="60px" alt="Sergey Ognev"&gt;&lt;/a&gt;&lt;a href="https://github.com/moodyhunter"&gt;&lt;img src="https://github.com/moodyhunter.png" width="60px" alt="Moody Liu"&gt;&lt;/a&gt;&lt;a href="https://github.com/code-hunger"&gt;&lt;img src="https://github.com/code-hunger.png" width="60px" alt="Alex G"&gt;&lt;/a&gt;&lt;a href="https://github.com/elithper"&gt;&lt;img src="https://github.com/elithper.png" width="60px" alt="Michael Howard"&gt;&lt;/a&gt;&lt;a href="https://github.com/LasseBloch"&gt;&lt;img src="https://github.com/LasseBloch.png" width="60px" alt="Lasse Bloch Lauritsen"&gt;&lt;/a&gt;&lt;a href="https://github.com/lmarburger"&gt;&lt;img src="https://github.com/lmarburger.png" width="60px" alt="Larry Marburger"&gt;&lt;/a&gt;&lt;a href="https://github.com/dbrockman"&gt;&lt;img src="https://github.com/dbrockman.png" width="60px" alt="David Brockman"&gt;&lt;/a&gt;&lt;a href="https://github.com/slavshik"&gt;&lt;img src="https://github.com/slavshik.png" width="60px" alt="Alexander Slavschik"&gt;&lt;/a&gt;&lt;a href="https://github.com/aidalgol"&gt;&lt;img src="https://github.com/aidalgol.png" width="60px" alt="Aidan Gauland"&gt;&lt;/a&gt;&lt;a href="https://github.com/mbienkowsk"&gt;&lt;img src="https://github.com/mbienkowsk.png" width="60px" alt="Maksym Bieńkowski"&gt;&lt;/a&gt;&lt;a href="https://github.com/joshuawootonn"&gt;&lt;img src="https://github.com/joshuawootonn.png" width="60px" alt="Joshua Wootonn"&gt;&lt;/a&gt;&lt;a href="https://github.com/I4nJ"&gt;&lt;img src="https://github.com/I4nJ.png" width="60px" alt=""&gt;&lt;/a&gt;&lt;a href="https://github.com/gurbindersingh"&gt;&lt;img src="https://github.com/gurbindersingh.png" width="60px" alt="Gurbinder Singh"&gt;&lt;/a&gt;&lt;a href="https://github.com/sandviklee"&gt;&lt;img src="https://github.com/sandviklee.png" width="60px" alt="Simon Sandvik Lee"&gt;&lt;/a&gt;&lt;a href="https://github.com/glagnar"&gt;&lt;img src="https://github.com/glagnar.png" width="60px" alt="Thomas Gilbert"&gt;&lt;/a&gt;&lt;a href="https://github.com/skrzepto"&gt;&lt;img src="https://github.com/skrzepto.png" width="60px" alt="Szymon Mucha"&gt;&lt;/a&gt;&lt;a href="https://github.com/TimShilov"&gt;&lt;img src="https://github.com/TimShilov.png" width="60px" alt="Tim Shilov"&gt;&lt;/a&gt;&lt;a href="https://github.com/unnawut"&gt;&lt;img src="https://github.com/unnawut.png" width="60px" alt="Unnawut Leepaisalsuwanna"&gt;&lt;/a&gt;&lt;a href="https://github.com/wortmanb"&gt;&lt;img src="https://github.com/wortmanb.png" width="60px" alt="Bret Wortman"&gt;&lt;/a&gt;&lt;a href="https://github.com/andre-lameirinhas"&gt;&lt;img src="https://github.com/andre-lameirinhas.png" width="60px" alt="André Lameirinhas"&gt;&lt;/a&gt;&lt;a href="https://github.com/SVappsLAB"&gt;&lt;img src="https://github.com/SVappsLAB.png" width="60px" alt="Scott Velez"&gt;&lt;/a&gt;&lt;a href="https://github.com/ooojustin"&gt;&lt;img src="https://github.com/ooojustin.png" width="60px" alt="justin"&gt;&lt;/a&gt;&lt;a href="https://github.com/TakodaS"&gt;&lt;img src="https://github.com/TakodaS.png" width="60px" alt="Austen Bolitho"&gt;&lt;/a&gt;&lt;a href="https://github.com/mantzu132"&gt;&lt;img src="https://github.com/mantzu132.png" width="60px" alt="Mantas"&gt;&lt;/a&gt;&lt;a href="https://github.com/mayfieldiv"&gt;&lt;img src="https://github.com/mayfieldiv.png" width="60px" alt="Mayfield"&gt;&lt;/a&gt;
 &lt;!-- sponsors --&gt; &lt;/p&gt; 
&lt;h2&gt;Elevator Pitch&lt;/h2&gt; 
&lt;p&gt;Rant time: You've heard it before, git is &lt;em&gt;powerful&lt;/em&gt;, but what good is that power when everything is so damn hard to do? Interactive rebasing requires you to edit a goddamn TODO file in your editor? &lt;em&gt;Are you kidding me?&lt;/em&gt; To stage part of a file you need to use a command line program to step through each hunk and if a hunk can't be split down any further but contains code you don't want to stage, you have to edit an arcane patch file &lt;em&gt;by hand&lt;/em&gt;? &lt;em&gt;Are you KIDDING me?!&lt;/em&gt; Sometimes you get asked to stash your changes when switching branches only to realise that after you switch and unstash that there weren't even any conflicts and it would have been fine to just checkout the branch directly? &lt;em&gt;YOU HAVE GOT TO BE KIDDING ME!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;If you're a mere mortal like me and you're tired of hearing how powerful git is when in your daily life it's a powerful pain in your ass, lazygit might be for you.&lt;/p&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#sponsors"&gt;Sponsors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#elevator-pitch"&gt;Elevator Pitch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#table-of-contents"&gt;Table of contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#stage-individual-lines"&gt;Stage individual lines&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#interactive-rebase"&gt;Interactive Rebase&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#cherry-pick"&gt;Cherry-pick&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#bisect"&gt;Bisect&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#nuke-the-working-tree"&gt;Nuke the working tree&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#amend-an-old-commit"&gt;Amend an old commit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#filter"&gt;Filter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#invoke-a-custom-command"&gt;Invoke a custom command&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#worktrees"&gt;Worktrees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#rebase-magic-custom-patches"&gt;Rebase magic (custom patches)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#rebase-from-marked-base-commit"&gt;Rebase from marked base commit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#undo"&gt;Undo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#commit-graph"&gt;Commit graph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#compare-two-commits"&gt;Compare two commits&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#binary-releases"&gt;Binary Releases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#homebrew"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#macports"&gt;MacPorts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#void-linux"&gt;Void Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#scoop-windows"&gt;Scoop (Windows)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#arch-linux"&gt;Arch Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#fedora-and-rhel"&gt;Fedora and RHEL&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#solus-linux"&gt;Solus Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#debian-and-ubuntu"&gt;Debian and Ubuntu&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#funtoo-linux"&gt;Funtoo Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#gentoo-linux"&gt;Gentoo Linux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#freebsd"&gt;FreeBSD&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#termux"&gt;Termux&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#conda"&gt;Conda&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#chocolatey-windows"&gt;Chocolatey (Windows)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#winget-windows-10-1709-or-later"&gt;Winget (Windows 10 1709 or later)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#usage"&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#keybindings"&gt;Keybindings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#changing-directory-on-exit"&gt;Changing Directory On Exit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#undoredo"&gt;Undo/Redo&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#custom-pagers"&gt;Custom Pagers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#custom-commands"&gt;Custom Commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#git-flow-support"&gt;Git flow support&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#contributing"&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#debugging-locally"&gt;Debugging Locally&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#donate"&gt;Donate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#faq"&gt;FAQ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#what-do-the-commit-colors-represent"&gt;What do the commit colors represent?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#shameless-plug"&gt;Shameless Plug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/#alternatives"&gt;Alternatives&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Lazygit is not my fulltime job but it is a hefty part time job so if you want to support the project please consider &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsoring me&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Stage individual lines&lt;/h3&gt; 
&lt;p&gt;Press space on the selected line to stage it, or press &lt;code&gt;v&lt;/code&gt; to start selecting a range of lines. You can also press &lt;code&gt;a&lt;/code&gt; to select the entirety of the current hunk.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/stage_lines-compressed.gif" alt="stage_lines"&gt;&lt;/p&gt; 
&lt;h3&gt;Interactive Rebase&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;i&lt;/code&gt; to start an interactive rebase. Then squash (&lt;code&gt;s&lt;/code&gt;), fixup (&lt;code&gt;f&lt;/code&gt;), drop (&lt;code&gt;d&lt;/code&gt;), edit (&lt;code&gt;e&lt;/code&gt;), move up (&lt;code&gt;ctrl+k&lt;/code&gt;) or move down (&lt;code&gt;ctrl+j&lt;/code&gt;) any of TODO commits, before continuing the rebase by bringing up the rebase options menu with &lt;code&gt;m&lt;/code&gt; and then selecting &lt;code&gt;continue&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also perform any these actions as a once-off (e.g. pressing &lt;code&gt;s&lt;/code&gt; on a commit to squash it) without explicitly starting a rebase.&lt;/p&gt; 
&lt;p&gt;This demo also uses shift+down to select a range of commits to move and fixup.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/interactive_rebase-compressed.gif" alt="interactive_rebase"&gt;&lt;/p&gt; 
&lt;h3&gt;Cherry-pick&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;shift+c&lt;/code&gt; on a commit to copy it and press &lt;code&gt;shift+v&lt;/code&gt; to paste (cherry-pick) it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/cherry_pick-compressed.gif" alt="cherry_pick"&gt;&lt;/p&gt; 
&lt;h3&gt;Bisect&lt;/h3&gt; 
&lt;p&gt;Press &lt;code&gt;b&lt;/code&gt; in the commits view to mark a commit as good/bad in order to begin a git bisect.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/bisect-compressed.gif" alt="bisect"&gt;&lt;/p&gt; 
&lt;h3&gt;Nuke the working tree&lt;/h3&gt; 
&lt;p&gt;For when you really want to just get rid of anything that shows up when you run &lt;code&gt;git status&lt;/code&gt; (and yes that includes dirty submodules) &lt;a href="https://www.youtube.com/watch?v=N4E2B_k2Bss"&gt;kidpix style&lt;/a&gt;, press &lt;code&gt;shift+d&lt;/code&gt; to bring up the reset options menu and then select the 'nuke' option.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/nuke_working_tree-compressed.gif" alt="Nuke working tree"&gt;&lt;/p&gt; 
&lt;h3&gt;Amend an old commit&lt;/h3&gt; 
&lt;p&gt;Pressing &lt;code&gt;shift+a&lt;/code&gt; on any commit will amend that commit with the currently staged changes (running an interactive rebase in the background).&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/amend_old_commit-compressed.gif" alt="amend_old_commit"&gt;&lt;/p&gt; 
&lt;h3&gt;Filter&lt;/h3&gt; 
&lt;p&gt;You can filter a view with &lt;code&gt;/&lt;/code&gt;. Here we filter down our branches view and then hit &lt;code&gt;enter&lt;/code&gt; to view its commits.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/filter-compressed.gif" alt="filter"&gt;&lt;/p&gt; 
&lt;h3&gt;Invoke a custom command&lt;/h3&gt; 
&lt;p&gt;Lazygit has a very flexible &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Command_Keybindings.md"&gt;custom command system&lt;/a&gt;. In this example a custom command is defined which emulates the built-in branch checkout action.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/custom_command-compressed.gif" alt="custom_command"&gt;&lt;/p&gt; 
&lt;h3&gt;Worktrees&lt;/h3&gt; 
&lt;p&gt;You can create worktrees to have multiple branches going at once without the need for stashing or creating WIP commits when switching between them. Press &lt;code&gt;w&lt;/code&gt; in the branches view to create a worktree from the selected branch and switch to it.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/worktree_create_from_branches-compressed.gif" alt="worktree_create_from_branches"&gt;&lt;/p&gt; 
&lt;h3&gt;Rebase magic (custom patches)&lt;/h3&gt; 
&lt;p&gt;You can build a custom patch from an old commit and then remove the patch from the commit, split out a new commit, apply the patch in reverse to the index, and more.&lt;/p&gt; 
&lt;p&gt;In this example we have a redundant comment that we want to remove from an old commit. We hit &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; on the commit to view its files, then &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; on a file to focus the patch, then &lt;code&gt;&amp;lt;space&amp;gt;&lt;/code&gt; to add the comment line to our custom patch, and then &lt;code&gt;ctrl+p&lt;/code&gt; to view the custom patch options; selecting to remove the patch from the current commit.&lt;/p&gt; 
&lt;p&gt;Learn more in the &lt;a href="https://youtu.be/4XaToVut_hs"&gt;Rebase magic Youtube tutorial&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/custom_patch-compressed.gif" alt="custom_patch"&gt;&lt;/p&gt; 
&lt;h3&gt;Rebase from marked base commit&lt;/h3&gt; 
&lt;p&gt;Say you're on a feature branch that was itself branched off of the develop branch, and you've decided you'd rather be branching off the master branch. You need a way to rebase only the commits from your feature branch. In this demo we check to see which was the last commit on the develop branch, then press &lt;code&gt;shift+b&lt;/code&gt; to mark that commit as our base commit, then press &lt;code&gt;r&lt;/code&gt; on the master branch to rebase onto it, only bringing across the commits from our feature branch. Then we push our changes with &lt;code&gt;shift+p&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/rebase_onto-compressed.gif" alt="rebase_onto"&gt;&lt;/p&gt; 
&lt;h3&gt;Undo&lt;/h3&gt; 
&lt;p&gt;You can undo the last action by pressing &lt;code&gt;z&lt;/code&gt; and redo with &lt;code&gt;ctrl+z&lt;/code&gt;. Here we drop a couple of commits and then undo the actions. Undo uses the reflog which is specific to commits and branches so we can't undo changes to the working tree or stash.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Undoing.md"&gt;More info&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/undo-compressed.gif" alt="undo"&gt;&lt;/p&gt; 
&lt;h3&gt;Commit graph&lt;/h3&gt; 
&lt;p&gt;When viewing the commit graph in an enlarged window (use &lt;code&gt;+&lt;/code&gt; and &lt;code&gt;_&lt;/code&gt; to cycle screen modes), the commit graph is shown. Colours correspond to the commit authors, and as you navigate down the graph, the parent commits of the selected commit are highlighted.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/commit_graph-compressed.gif" alt="commit_graph"&gt;&lt;/p&gt; 
&lt;h3&gt;Compare two commits&lt;/h3&gt; 
&lt;p&gt;If you press &lt;code&gt;shift+w&lt;/code&gt; on a commit (or branch/ref) a menu will open that allows you to mark that commit so that any other commit you select will be diffed against it. Once you've selected the second commit, you'll see the diff in the main view and if you press &lt;code&gt;&amp;lt;enter&amp;gt;&lt;/code&gt; you'll see the files of the diff. You can press &lt;code&gt;shift+w&lt;/code&gt; to view the diff menu again to see options like reversing the diff direction or exiting diff mode. You can also exit diff mode by pressing &lt;code&gt;&amp;lt;escape&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/demo/diff_commits-compressed.gif" alt="diff_commits"&gt;&lt;/p&gt; 
&lt;h2&gt;Tutorials&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/CPLdltN7wgE"&gt;&lt;img src="https://i.imgur.com/sVEktDn.png"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/CPLdltN7wgE"&gt;15 Lazygit Features in 15 Minutes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/VDXvbHZYeKY"&gt;Basics Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/4XaToVut_hs"&gt;Rebase Magic Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/lazygit/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/lazygit.svg?columns=3" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Most of the above packages are maintained by third parties so be sure to vet them yourself and confirm that the maintainer is a trustworthy looking person who attends local sports games and gives back to their communities with barbeque fundraisers etc&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Binary Releases&lt;/h3&gt; 
&lt;p&gt;For Windows, Mac OS(10.12+) or Linux, you can download a binary release &lt;a href="https://raw.githubusercontent.com/jesseduffield/releases"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;p&gt;It works with Linux, too.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MacPorts&lt;/h3&gt; 
&lt;p&gt;Latest version built from github releases. Tap:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo port install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Void Linux&lt;/h3&gt; 
&lt;p&gt;Packages for Void Linux are available in the distro repo&lt;/p&gt; 
&lt;p&gt;They follow upstream latest releases&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo xbps-install -S lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt;. It's in the &lt;code&gt;extras&lt;/code&gt; bucket:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Add the extras bucket
scoop bucket add extras

# Install lazygit
scoop install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch Linux&lt;/h3&gt; 
&lt;p&gt;Packages for Arch Linux are available via pacman and AUR (Arch User Repository).&lt;/p&gt; 
&lt;p&gt;There are two packages. The stable one which is built with the latest release and the git version which builds from the most recent commit.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable: &lt;code&gt;sudo pacman -S lazygit&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Development: &lt;a href="https://aur.archlinux.org/packages/lazygit-git/"&gt;https://aur.archlinux.org/packages/lazygit-git/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Instruction of how to install AUR content can be found here: &lt;a href="https://wiki.archlinux.org/index.php/Arch_User_Repository"&gt;https://wiki.archlinux.org/index.php/Arch_User_Repository&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Fedora / Amazon Linux 2023 / CentOS Stream&lt;/h3&gt; 
&lt;p&gt;Packages for Fedora, Amazon Linux 2023 and CentOS Stream are available via &lt;a href="https://copr.fedorainfracloud.org/coprs/dejan/lazygit/"&gt;Copr&lt;/a&gt; (Cool Other Package Repo).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo dnf copr enable dejan/lazygit
sudo dnf install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These packages are built using the RPM spec file located here: &lt;a href="https://codeberg.org/dejan/rpm-lazygit"&gt;https://codeberg.org/dejan/rpm-lazygit&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You should be able to build RPMs for Fedora 41 or older, and other Fedora derivatives using the SRPM (Source RPM) file that you can grab from the latest COPR build.&lt;/p&gt; 
&lt;h3&gt;Solus Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo eopkg install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debian and Ubuntu&lt;/h3&gt; 
&lt;p&gt;For &lt;strong&gt;Debian 13 "Trixie", Sid&lt;/strong&gt;, and later, or &lt;strong&gt;Ubuntu 25.10 "Questing Quokka"&lt;/strong&gt; and later:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For &lt;strong&gt;Debian 12 "Bookworm", Ubuntu 25.04 "Plucky Puffin"&lt;/strong&gt; and earlier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;LAZYGIT_VERSION=$(curl -s "https://api.github.com/repos/jesseduffield/lazygit/releases/latest" | \grep -Po '"tag_name": *"v\K[^"]*')
curl -Lo lazygit.tar.gz "https://github.com/jesseduffield/lazygit/releases/download/v${LAZYGIT_VERSION}/lazygit_${LAZYGIT_VERSION}_Linux_x86_64.tar.gz"
tar xf lazygit.tar.gz lazygit
sudo install lazygit -D -t /usr/local/bin/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Verify the correct installation of lazygit:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;lazygit --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Funtoo Linux&lt;/h3&gt; 
&lt;p&gt;Funtoo Linux has an autogenerated lazygit package in &lt;a href="https://github.com/funtoo/dev-kit/tree/1.4-release/dev-vcs/lazygit"&gt;dev-kit&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo emerge dev-vcs/lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Gentoo Linux&lt;/h3&gt; 
&lt;p&gt;Lazygit is not (yet) in main Gentoo portage, however an ebuild is available in &lt;a href="https://github.com/gentoo-mirror/guru/tree/master/dev-vcs/lazygit"&gt;GURU overlay&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can either add the overlay to your system and install lazygit as usual:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo eselect repository enable guru
sudo emaint sync -r guru
sudo emerge dev-vcs/lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE&lt;/h3&gt; 
&lt;p&gt;The lazygit package is currently built in &lt;a href="https://build.opensuse.org/package/show/devel:languages:go/lazygit"&gt;devel:languages:go/lazygit&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To install lazygit on openSUSE Tumbleweed run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper ar https://download.opensuse.org/repositories/devel:/languages:/go/openSUSE_Factory/devel:languages:go.repo
sudo zypper ref &amp;amp;&amp;amp; sudo zypper in lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install lazygit on openSUSE Leap run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;source /etc/os-release
sudo zypper ar https://download.opensuse.org/repositories/devel:/languages:/go/$VERSION_ID/devel:languages:go.repo
sudo zypper ref &amp;amp;&amp;amp; sudo zypper in lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NixOs&lt;/h3&gt; 
&lt;p&gt;On NixOs lazygit is packaged with nix and distributed via nixpkgs. You can try the lazygit without installing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;nix-shell -p lazygit
# or with flakes enabled
nix run nixpkgs#lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or you can add lazygit to you &lt;code&gt;configuration.nix&lt;/code&gt; using the &lt;code&gt;environment.systemPackages&lt;/code&gt; option. More details can be found via NixOs search &lt;a href="https://search.nixos.org/"&gt;page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Flox&lt;/h3&gt; 
&lt;p&gt;Lazygit can be installed into a Flox environment as follows.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;flox install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about Flox can be found on &lt;a href="https://flox.dev/"&gt;their website&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;FreeBSD&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pkg install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;apt install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Conda&lt;/h3&gt; 
&lt;p&gt;Released versions are available for different platforms, see &lt;a href="https://anaconda.org/conda-forge/lazygit"&gt;https://anaconda.org/conda-forge/lazygit&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/jesseduffield/lazygit@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please note: If you get an error claiming that lazygit cannot be found or is not defined, you may need to add &lt;code&gt;~/go/bin&lt;/code&gt; to your $PATH (MacOS/Linux), or &lt;code&gt;%HOME%\go\bin&lt;/code&gt; (Windows). Not to be mistaken for &lt;code&gt;C:\Go\bin&lt;/code&gt; (which is for Go's own binaries, not apps like lazygit).&lt;/p&gt; 
&lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;choco install lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Winget (Windows 10 1709 or later)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazygit&lt;/code&gt; using the &lt;code&gt;winget&lt;/code&gt; command in the Windows Terminal with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install -e --id=JesseDuffield.lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual&lt;/h3&gt; 
&lt;p&gt;You'll need to &lt;a href="https://golang.org/doc/install"&gt;install Go&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jesseduffield/lazygit.git
cd lazygit
go install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;go run main.go&lt;/code&gt; to compile and run in one go (pun definitely intended)&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Call &lt;code&gt;lazygit&lt;/code&gt; in your terminal inside a git repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ lazygit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want, you can also add an alias for this with &lt;code&gt;echo "alias lg='lazygit'" &amp;gt;&amp;gt; ~/.zshrc&lt;/code&gt; (or whichever rc file you're using).&lt;/p&gt; 
&lt;h3&gt;Keybindings&lt;/h3&gt; 
&lt;p&gt;You can check out the list of keybindings &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/keybindings"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Changing Directory On Exit&lt;/h3&gt; 
&lt;p&gt;If you change repos in lazygit and want your shell to change directory into that repo on exiting lazygit, add this to your &lt;code&gt;~/.zshrc&lt;/code&gt; (or other rc file):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;lg()
{
    export LAZYGIT_NEW_DIR_FILE=~/.lazygit/newdir

    lazygit "$@"

    if [ -f $LAZYGIT_NEW_DIR_FILE ]; then
            cd "$(cat $LAZYGIT_NEW_DIR_FILE)"
            rm -f $LAZYGIT_NEW_DIR_FILE &amp;gt; /dev/null
    fi
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;code&gt;source ~/.zshrc&lt;/code&gt; and from now on when you call &lt;code&gt;lg&lt;/code&gt; and exit you'll switch directories to whatever you were in inside lazygit. To override this behaviour you can exit using &lt;code&gt;shift+Q&lt;/code&gt; rather than just &lt;code&gt;q&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Undo/Redo&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Undoing.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Config.md"&gt;configuration docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Custom Pagers&lt;/h3&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Pagers.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Commands&lt;/h3&gt; 
&lt;p&gt;If lazygit is missing a feature, there's a good chance you can implement it yourself with a custom command!&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/docs/Custom_Command_Keybindings.md"&gt;docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Git flow support&lt;/h3&gt; 
&lt;p&gt;Lazygit supports &lt;a href="https://github.com/nvie/gitflow"&gt;Gitflow&lt;/a&gt; if you have it installed. To understand how the Gitflow model works check out Vincent Driessen's original &lt;a href="https://nvie.com/posts/a-successful-git-branching-model/"&gt;post&lt;/a&gt; explaining it. To view Gitflow options from within Lazygit, press &lt;code&gt;i&lt;/code&gt; from within the branches view.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love your input! Please check out the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazygit/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;. For contributor discussion about things not better discussed here in the repo, join the &lt;a href="https://discord.gg/ehwFt2t4wt"&gt;discord channel&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/ehwFt2t4wt"&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazygit/assets/discord.png" width="75"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out this &lt;a href="https://www.youtube.com/watch?v=kNavnhzZHtk"&gt;video&lt;/a&gt; walking through the creation of a small feature in lazygit if you want an idea of where to get started.&lt;/p&gt; 
&lt;h3&gt;Debugging Locally&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;lazygit --debug&lt;/code&gt; in one terminal tab and &lt;code&gt;lazygit --logs&lt;/code&gt; in another to view the program and its log output side by side&lt;/p&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;If you would like to support the development of lazygit, consider &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsoring me&lt;/a&gt; (github is matching all donations dollar-for-dollar for 12 months)&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;What do the commit colors represent?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Green: the commit is included in the master branch&lt;/li&gt; 
 &lt;li&gt;Yellow: the commit is not included in the master branch&lt;/li&gt; 
 &lt;li&gt;Red: the commit has not been pushed to the upstream branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Shameless Plug&lt;/h2&gt; 
&lt;p&gt;If you want to see what I (Jesse) am up to in terms of development, follow me on &lt;a href="https://twitter.com/DuffieldJesse"&gt;twitter&lt;/a&gt; or check out my &lt;a href="https://jesseduffield.com/"&gt;blog&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;p&gt;If you find that lazygit doesn't quite satisfy your requirements, these may be a better fit:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Extrawurst/gitui"&gt;GitUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jonas/tig"&gt;tig&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>datawhalechina/self-llm</title>
      <link>https://github.com/datawhalechina/self-llm</link>
      <description>&lt;p&gt;《开源大模型食用指南》针对中国宝宝量身打造的基于Linux环境快速微调（全参数/Lora）、部署国内外开源大模型（LLM）/多模态大模型（MLLM）教程&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/self-llm/master/images/head-img.png"&gt; 
 &lt;h1&gt;开源大模型食用指南&lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;中文 | &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;  本项目是一个围绕开源大模型、针对国内初学者、基于 Linux 平台的中国宝宝专属大模型教程，针对各类开源大模型提供包括环境配置、本地部署、高效微调等技能在内的全流程指导，简化开源大模型的部署、使用和应用流程，让更多的普通学生、研究者更好地使用开源大模型，帮助开源、自由的大模型更快融入到普通学习者的生活中。&lt;/p&gt; 
&lt;p&gt;  本项目的主要内容包括：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;基于 Linux 平台的开源 LLM 环境配置指南，针对不同模型要求提供不同的详细环境配置步骤；&lt;/li&gt; 
 &lt;li&gt;针对国内外主流开源 LLM 的部署使用教程，包括 LLaMA、ChatGLM、InternLM 等；&lt;/li&gt; 
 &lt;li&gt;开源 LLM 的部署应用指导，包括命令行调用、在线 Demo 部署、LangChain 框架集成等；&lt;/li&gt; 
 &lt;li&gt;开源 LLM 的全量微调、高效微调方法，包括分布式全量微调、LoRA、ptuning 等。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;  &lt;strong&gt;项目的主要内容就是教程，让更多的学生和未来的从业者了解和熟悉开源大模型的食用方法！任何人都可以提出issue或是提交PR，共同构建维护这个项目。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;  想要深度参与的同学可以联系我们，我们会将你加入到项目的维护者中。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;  &lt;em&gt;&lt;strong&gt;学习建议：本项目的学习建议是，先学习环境配置，然后再学习模型的部署使用，最后再学习微调。因为环境配置是基础，模型的部署使用是基础，微调是进阶。初学者可以选择Qwen1.5，InternLM2，MiniCPM等模型优先学习。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;  &lt;strong&gt;进阶学习推荐&lt;/strong&gt; ：如果您在学习完本项目后，希望更深入地理解大语言模型的核心原理，并渴望亲手从零开始训练属于自己的大模型，我们强烈推荐关注 Datawhale 的另一个开源项目—— &lt;a href="https://github.com/datawhalechina/happy-llm"&gt;Happy-LLM 从零开始的大语言模型原理与实践教程&lt;/a&gt; 。该项目将带您深入探索大模型的底层机制，掌握完整的训练流程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：如果有同学希望了解大模型的模型构成，以及从零手写RAG、Agent和Eval等任务，可以学习Datawhale的另一个项目&lt;a href="https://github.com/datawhalechina/tiny-universe"&gt;Tiny-Universe&lt;/a&gt;，大模型是当下深度学习领域的热点，但现有的大部分大模型教程只在于教给大家如何调用api完成大模型的应用，而很少有人能够从原理层面讲清楚模型结构、RAG、Agent 以及 Eval。所以该仓库会提供全部手写，不采用调用api的形式，完成大模型的 RAG 、 Agent 、Eval 任务。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：考虑到有同学希望在学习本项目之前，希望学习大模型的理论部分，如果想要进一步深入学习 LLM 的理论基础，并在理论的基础上进一步认识、应用 LLM，可以参考 Datawhale 的 &lt;a href="https://github.com/datawhalechina/so-large-lm.git"&gt;so-large-llm&lt;/a&gt;课程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：如果有同学在学习本课程之后，想要自己动手开发大模型应用。同学们可以参考 Datawhale 的 &lt;a href="https://github.com/datawhalechina/llm-universe"&gt;动手学大模型应用开发&lt;/a&gt; 课程，该项目是一个面向小白开发者的大模型应用开发教程，旨在基于阿里云服务器，结合个人知识库助手项目，向同学们完整的呈现大模型应用开发流程。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;项目意义&lt;/h2&gt; 
&lt;p&gt;  什么是大模型？&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;大模型（LLM）狭义上指基于深度学习算法进行训练的自然语言处理（NLP）模型，主要应用于自然语言理解和生成等领域，广义上还包括机器视觉（CV）大模型、多模态大模型和科学计算大模型等。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;  百模大战正值火热，开源 LLM 层出不穷。如今国内外已经涌现了众多优秀开源 LLM，国外如 LLaMA、Alpaca，国内如 ChatGLM、BaiChuan、InternLM（书生·浦语）等。开源 LLM 支持用户本地部署、私域微调，每一个人都可以在开源 LLM 的基础上打造专属于自己的独特大模型。&lt;/p&gt; 
&lt;p&gt;  然而，当前普通学生和用户想要使用这些大模型，需要具备一定的技术能力，才能完成模型的部署和使用。对于层出不穷又各有特色的开源 LLM，想要快速掌握一个开源 LLM 的应用方法，是一项比较有挑战的任务。&lt;/p&gt; 
&lt;p&gt;  本项目旨在首先基于核心贡献者的经验，实现国内外主流开源 LLM 的部署、使用与微调教程；在实现主流 LLM 的相关部分之后，我们希望充分聚集共创者，一起丰富这个开源 LLM 的世界，打造更多、更全面特色 LLM 的教程。星火点点，汇聚成海。&lt;/p&gt; 
&lt;p&gt;  &lt;em&gt;&lt;strong&gt;我们希望成为 LLM 与普罗大众的阶梯，以自由、平等的开源精神，拥抱更恢弘而辽阔的 LLM 世界。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;项目受众&lt;/h2&gt; 
&lt;p&gt;  本项目适合以下学习者：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;想要使用或体验 LLM，但无条件获得或使用相关 API；&lt;/li&gt; 
 &lt;li&gt;希望长期、低成本、大量应用 LLM；&lt;/li&gt; 
 &lt;li&gt;对开源 LLM 感兴趣，想要亲自上手开源 LLM；&lt;/li&gt; 
 &lt;li&gt;NLP 在学，希望进一步学习 LLM；&lt;/li&gt; 
 &lt;li&gt;希望结合开源 LLM，打造领域特色的私域 LLM；&lt;/li&gt; 
 &lt;li&gt;以及最广大、最普通的学生群体。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;项目规划及进展&lt;/h2&gt; 
&lt;p&gt;   本项目拟围绕开源 LLM 应用全流程组织，包括环境配置及使用、部署应用、微调等，每个部分覆盖主流及特点开源 LLM：&lt;/p&gt; 
&lt;h3&gt;Example 系列&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/Chat-%E5%AC%9B%E5%AC%9B/readme.md"&gt;Chat-嬛嬛&lt;/a&gt;： Chat-甄嬛是利用《甄嬛传》剧本中所有关于甄嬛的台词和语句，基于LLM进行LoRA微调得到的模仿甄嬛语气的聊天语言模型。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/Tianji-%E5%A4%A9%E6%9C%BA/readme.md"&gt;Tianji-天机&lt;/a&gt;：天机是一款基于人情世故社交场景，涵盖提示词工程 、智能体制作、 数据获取与模型微调、RAG 数据清洗与使用等全流程的大语言模型系统应用教程。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/AMchat-%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/readme.md"&gt;AMChat&lt;/a&gt;: AM (Advanced Mathematics) chat 是一个集成了数学知识和高等数学习题及其解答的大语言模型。该模型使用 Math 和高等数学习题及其解析融合的数据集，基于 InternLM2-Math-7B 模型，通过 xtuner 微调，专门设计用于解答高等数学问题。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/examples/%E6%95%B0%E5%AD%97%E7%94%9F%E5%91%BD/readme.md"&gt;数字生命&lt;/a&gt;: 本项目将以我为原型，利用特制的数据集对大语言模型进行微调，致力于创造一个能够真正反映我的个性特征的AI数字人——包括但不限于我的语气、表达方式和思维模式等等，因此无论是日常聊天还是分享心情，它都以一种既熟悉又舒适的方式交流，仿佛我在他们身边一样。整个流程是可迁移复制的，亮点是数据集的制作。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;已支持模型&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/zai-org/GLM-4.1V-Thinking"&gt;GLM-4.1-Thinking&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.1V-Thinking/01-GLM-4%201V-Thinking%20vLLM%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;GLM-4.1V-Thinking vLLM 部署调用&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.1V-Thinking/02-GLM-4%201V-Thinking%20Gradio%E9%83%A8%E7%BD%B2.md"&gt;GLM-4.1V-Thinking Gradio部署&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.1V-Thinking/03-GLM-4%201V-Thinking%20LoRA%20%E5%8F%8A%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;GLM-4.1V-Thinking Lora 微调及 SwanLab 可视化记录&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/GLM4.1V-Thinking-lora"&gt;GLM-4.1V-Thinking Docker 镜像&lt;/a&gt; @林恒宇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/zai-org/GLM-4.5"&gt;GLM-4.5-Air&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.5-Air/01-GLM-4.5-Air-vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;GLM-4.5-Air vLLM 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.5-Air/02-GLM-4.5-Air%20EvalScope%20%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95.md"&gt;GLM-4.5-Air EvalScope 智商情商 &amp;amp;&amp;amp; 并发评测&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4.5-Air/03-GLM-4.5-Air-Lora%20%E5%8F%8A%20Swanlab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E5%BE%AE%E8%B0%83.md"&gt;GLM-4.5-Air Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.compshare.cn/images/lUQhKDCeCdZW?referral_code=ELukJdQS3vvCwYIfgsQf2C&amp;amp;ytag=GPU_yy_github_selfllm"&gt;GLM-4.5-Air Ucloud Docker 镜像&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/baidu/ERNIE-4.5-0.3B-PT"&gt;ERNIE-4.5&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ERNIE-4.5/01-ERNIE-4.5-0.3B-PT%20Lora%20%E5%BE%AE%E8%B0%83%E5%8F%8A%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;ERNIE-4.5-0.3B-PT Lora 微调及 SwanLab 可视化记录&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/ERNIE-4.5-lora"&gt;ERNIE-4.5-0.3B-PT Lora Docker 镜像&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Tencent-Hunyuan/Hunyuan-A13B"&gt;Hunyuan-A13B-Instruct&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan-A13B-Instruct/01-Hunyuan-A13B-Instruct%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E8%A7%A3%E6%9E%90%20Blog.md"&gt;Hunyuan-A13B-Instruct 模型架构解析 Blog&lt;/a&gt; @卓堂越&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan-A13B-Instruct/03-Hunyuan-A13B-Instruct-SGLang%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Hunyuan-A13B-Instruct SGLang 部署调用&lt;/a&gt; @fancy&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan-A13B-Instruct/05-Hunyuan-A13B-Instruct-LoRA%E5%8F%8ASwanLab%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;Hunyuan-A13B-Instruct Lora SwanLab 可视化微调&lt;/a&gt; @谢好冉&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/Hunyuan-A13B-Instruct-lora"&gt;Hunyuan-A13B-Instruct Lora Docker 镜像&lt;/a&gt; @谢好冉&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen3"&gt;Qwen3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/01-Qwen3-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90-Blog.md"&gt;Qwen3 模型结构解析 Blog&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/02-Qwen3-8B-vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen3-8B vllm 部署调用&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/03-Qwen3-7B-Instruct%20Windows%20LMStudio%20%E9%83%A8%E7%BD%B2.md"&gt;Qwen3-8B Windows LMStudio 部署调用&lt;/a&gt; @王熠明&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/04-Qwen3-8B%20EvalScope%E6%99%BA%E5%95%86%E6%83%85%E5%95%86%E8%AF%84%E6%B5%8B.md"&gt;Qwen3-8B Evalscope 智商情商评测&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/05-Qwen3-8B-LoRA%E5%8F%8ASwanLab%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;Qwen3-8B Lora 微调及SwanLab 可视化记录&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/06-Qwen3-30B-A3B%20%E5%BE%AE%E8%B0%83%E5%8F%8A%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;Qwen3-30B-A3B 微调及SwanLab 可视化记录&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/07-Qwen3-Think-%E8%A7%A3%E5%AF%86-Blog.md"&gt;Qwen3 Think 解密 Blog&lt;/a&gt; @樊奇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/Qwen3"&gt;Qwen3-8B Docker 镜像&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models//Qwen3/08-Qwen3_0_6B%E7%9A%84%E5%B0%8F%E6%A8%A1%E5%9E%8B%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8.md"&gt;Qwen3-0.6B 的小模型有什么用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/09-Qwen3-1.7B-%E5%8C%BB%E5%AD%A6%E6%8E%A8%E7%90%86%E5%BC%8F%E5%AF%B9%E8%AF%9D%E5%BE%AE%E8%B0%83%20%E5%8F%8A%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md"&gt;Qwen3-1.7B 医学推理式对话微调 及 SwanLab 可视化记录&lt;/a&gt; @林泽毅&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen3/10-Qwen3-8B%20GRPO%E5%BE%AE%E8%B0%83%E5%8F%8A%E9%80%9A%E8%BF%87swanlab%E5%8F%AF%E8%A7%86%E5%8C%96.md"&gt;Qwen3-8B GRPO微调及通过swanlab可视化&lt;/a&gt; @郭宣伯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/MoonshotAI/Kimi-VL"&gt;Kimi&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Kimi-VL/02-Kimi-VL-%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A%E8%A7%A3%E8%AF%BB.md"&gt;Kimi-VL-A3B 技术报告解读&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Kimi-VL/01-Kimi-VL-%E5%AF%B9%E8%AF%9D%E5%8A%A9%E6%89%8B.md"&gt;Kimi-VL-A3B-Thinking WebDemo 部署（网页对话助手）&lt;/a&gt; @姜舒凡&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct"&gt;Llama4&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama4/01-Llama4-%E5%AF%B9%E8%AF%9D%E5%8A%A9%E6%89%8B/01-Llama4-%E5%AF%B9%E8%AF%9D%E5%8A%A9%E6%89%8B.md"&gt;Llama4 对话助手&lt;/a&gt; @姜舒凡&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/manycore-research/SpatialLM"&gt;SpatialLM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/SpatialLM/readme.md"&gt;SpatialLM 3D点云理解与目标检测模型部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/tencent/Hunyuan3D-2"&gt;Hunyuan3D-2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan3D-2/01-Hunyuan3D-2%20%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2.md"&gt;Hunyuan3D-2 系列模型部署&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan3D-2/02-Hunyuan3D-2%20%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%B0%83%E7%94%A8.md"&gt;Hunyuan3D-2 系列模型代码调用&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan3D-2/03-Hunyuan3D-2%20%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8BGradio%E9%83%A8%E7%BD%B2.md"&gt;Hunyuan3D-2 系列模型Gradio部署&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Hunyuan3D-2/04-Hunyuan3D-2%20%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8BAPI%20Server.md"&gt;Hunyuan3D-2 系列模型API Server&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/Hunyuan3D-2"&gt;Hunyuan3D-2 Docker 镜像&lt;/a&gt; @林恒宇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/google/gemma-3-4b-it"&gt;Gemma3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma3/01-gemma-3-4b-it%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;gemma-3-4b-it FastApi 部署调用&lt;/a&gt; @杜森&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma3/03-gemma-3-4b-it-ollama%20+%20open-webui%E9%83%A8%E7%BD%B2.md"&gt;gemma-3-4b-it ollama + open-webui部署&lt;/a&gt; @孙超&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma3/04-Gemma3-4b%20%20evalscope%E6%99%BA%E5%95%86%E6%83%85%E5%95%86%E8%AF%84%E6%B5%8B.md"&gt;gemma-3-4b-it evalscope 智商情商评测&lt;/a&gt; @张龙斐&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma3/05-gemma-3-4b-it%20LoRA.md"&gt;gemma-3-4b-it Lora 微调&lt;/a&gt; @荞麦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://www.codewithgpu.com/i/datawhalechina/self-llm/self-llm-gemma3"&gt;gemma-3-4b-it Docker 镜像&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma3/6-gemma3-4B-itGRPO%E5%BE%AE%E8%B0%83%E5%8F%8A%E9%80%9A%E8%BF%87swanlab%E5%8F%AF%E8%A7%86%E5%8C%96.md"&gt;gemma-3-4b-it GRPO微调及通过swanlab可视化&lt;/a&gt; @郭宣伯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.modelscope.cn/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"&gt;DeepSeek-R1-Distill&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/01-DeepSeek-R1-Distill-Qwen-7B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;DeepSeek-R1-Distill-Qwen-7B FastApi 部署调用&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/02-DeepSeek-R1-Distill-Qwen-7B%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;DeepSeek-R1-Distill-Qwen-7B Langchain 接入&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/03-DeepSeek-R1-Distill-Qwen-7B%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;DeepSeek-R1-Distill-Qwen-7B WebDemo 部署&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/04-DeepSeek-R1-Distill-Qwen-7B%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;DeepSeek-R1-Distill-Qwen-7B vLLM 部署调用&lt;/a&gt; @骆秀韬&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-R1-Distill-Qwen/05-DeepSeek-R1-0528-Qwen3-8B-GRPO%E5%8F%8Aswanlab%E5%8F%AF%E8%A7%86%E5%8C%96.md"&gt;DeepSeek-R1-0528-Qwen3-8B-GRPO及swanlab可视化&lt;/a&gt; @郭宣伯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/OpenBMB/MiniCPM-o"&gt;MiniCPM-o-2_6&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/01MiniCPM-o%202%206%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8%20.md"&gt;minicpm-o-2.6 FastApi 部署调用&lt;/a&gt; @林恒宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/02minicpm-o-2.6WebDemo_streamlit.py"&gt;minicpm-o-2.6 WebDemo 部署&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/03-MiniCPM-o-2.6%20%E5%A4%9A%E6%A8%A1%E6%80%81%E8%AF%AD%E9%9F%B3%E8%83%BD%E5%8A%9B.md"&gt;minicpm-o-2.6 多模态语音能力&lt;/a&gt; @邓恺俊&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM-o/04-MiniCPM-0-2.6%20Lora%E5%BE%AE%E8%B0%83.md"&gt;minicpm-o-2.6 可视化 LaTeX_OCR Lora 微调&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/InternLM/InternLM"&gt;InternLM3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/01-InternLM3-8B-Instruct%20FastAPI.md"&gt;internlm3-8b-instruct FastApi 部署调用&lt;/a&gt; @苏向标&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/02-internlm3-8b-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;internlm3-8b-instruct Langchian接入&lt;/a&gt; @赵文恺&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/03-InternLM3-8B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;internlm3-8b-instruct WebDemo 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/04-InternLM3-8B-Instruct%20LoRA.md"&gt;internlm3-8b-instruct Lora 微调&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM3/05-internlm3-8b-instruct%20%E4%B8%8Eo1%20.md"&gt;internlm3-8b-instruct o1-like推理链实现&lt;/a&gt; @陈睿&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/microsoft/phi-4"&gt;phi4&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/01-Phi-4%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;phi4 FastApi 部署调用&lt;/a&gt; @杜森&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/02-Phi-4-Langchain%E6%8E%A5%E5%85%A5.md"&gt;phi4 langchain 接入&lt;/a&gt; @小罗&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/03-Phi-4%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;phi4 WebDemo 部署&lt;/a&gt; @杜森&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/04-Phi-4-Lora%20%E5%BE%AE%E8%B0%83.md"&gt;phi4 Lora 微调&lt;/a&gt; @郑远婧&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/05-Phi-4-Lora%20%E5%BE%AE%E8%B0%83%20%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.md"&gt;phi4 Lora 微调 NER任务 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi4/06-Phi-4-GRPO%E5%8F%8Aswanlab%E5%8F%AF%E8%A7%86%E5%8C%96.md"&gt;phi4 GRPO微调及通过swanlab可视化&lt;/a&gt; @郭宣伯&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen2.5-Coder"&gt;Qwen2.5-Coder&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/01-Qwen2.5-Coder-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2.5-Coder-7B-Instruct FastApi部署调用&lt;/a&gt; @赵文恺&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/02-Qwen2.5-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Qwen2.5-Coder-7B-Instruct Langchian接入&lt;/a&gt; @杨晨旭&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/03-Qwen2.5-Coder-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Qwen2.5-Coder-7B-Instruct WebDemo 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/04-Qwen2.5-Coder-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2.5-Coder-7B-Instruct vLLM 部署&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/Qwen2.5-Coder-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen2.5-Coder-7B-Instruct Lora 微调&lt;/a&gt; @荞麦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5-Coder/05-Qwen2.5-Coder-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md"&gt;Qwen2.5-Coder-7B-Instruct Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @杨卓&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen2-VL"&gt;Qwen2-vl&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/01-Qwen2-VL-2B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2-vl-2B FastApi 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/02-Qwen2-VL-2B-Instruct%20Web%20Demo%E9%83%A8%E7%BD%B2.md"&gt;Qwen2-vl-2B WebDemo 部署&lt;/a&gt; @赵伟&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/03-Qwen2-VL-2B-Instruct%20vLLM%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2-vl-2B vLLM 部署&lt;/a&gt; @荞麦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/04-Qwen2-VL-2B%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen2-vl-2B Lora 微调&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/05-Qwen2-VL-2B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md"&gt;Qwen2-vl-2B Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2-VL/06-Qwen2-VL-2B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%E6%A1%88%E4%BE%8B%20-%20LaTexOCR.md"&gt;Qwen2-vl-2B Lora 微调案例 - LaTexOCR&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen2.5"&gt;Qwen2.5&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/01-Qwen2.5-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2.5-7B-Instruct FastApi 部署调用&lt;/a&gt; @娄天奥&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/02-Qwen2.5-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Qwen2.5-7B-Instruct langchain 接入&lt;/a&gt; @娄天奥&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/03-Qwen2.5-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2.5-7B-Instruct vLLM 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/04-Qwen2_5-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Qwen2.5-7B-Instruct WebDemo 部署&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/05-Qwen2.5-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen2.5-7B-Instruct Lora 微调&lt;/a&gt; @左春生&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/06-Qwen2.5-7B-Instruct%20o1-like%20%E6%8E%A8%E7%90%86%E9%93%BE%E5%AE%9E%E7%8E%B0.md"&gt;Qwen2.5-7B-Instruct o1-like 推理链实现&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2.5/07-Qwen2.5-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83%20SwanLab%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95%E7%89%88.md"&gt;Qwen2.5-7B-Instruct Lora 微调 SwanLab 可视化记录版&lt;/a&gt; @林泽毅&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://machinelearning.apple.com/research/openelm"&gt;Apple OpenELM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/OpenELM/01-OpenELM-3B-Instruct%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;OpenELM-3B-Instruct FastApi 部署调用&lt;/a&gt; @王泽宇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/OpenELM/02-OpenELM-3B-Instruct%20Lora%E5%BE%AE%E8%B0%83.md"&gt;OpenELM-3B-Instruct Lora 微调&lt;/a&gt; @王泽宇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct"&gt;Llama3_1-8B-Instruct&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/01-Llama3_1-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Llama3_1-8B-Instruct FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/02-Llama3_1-8B-Instruct%20langchain%E6%8E%A5%E5%85%A5.md"&gt;Llama3_1-8B-Instruct langchain 接入&lt;/a&gt; @张晋&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/03-Llama3_1-8B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Llama3_1-8B-Instruct WebDemo 部署&lt;/a&gt; @张晋&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/04-Llama3_1-8B--Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Llama3_1-8B-Instruct Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Llama3_1/%E5%8A%A8%E6%89%8B%E8%BD%AC%E6%8D%A2GGUF%E6%A8%A1%E5%9E%8B%E5%B9%B6%E4%BD%BF%E7%94%A8Ollama%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2.md"&gt;动手转换GGUF模型并使用Ollama本地部署&lt;/a&gt; @Gaoboy&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/google/gemma-2-9b-it"&gt;Gemma-2-9b-it&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/01-Gemma-2-9b-it%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Gemma-2-9b-it FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/02-Gemma-2-9b-it%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Gemma-2-9b-it langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/03-Gemma-2-9b-it%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;Gemma-2-9b-it WebDemo 部署&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma2/04-Gemma-2-9b-it%20peft%20lora%E5%BE%AE%E8%B0%83.md"&gt;Gemma-2-9b-it Peft Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/IEIT-Yuan/Yuan-2.0"&gt;Yuan2.0&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/01-Yuan2.0-2B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Yuan2.0-2B FastApi 部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/02-Yuan2.0-2B%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Yuan2.0-2B Langchain 接入&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/03-Yuan2.0-2B%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Yuan2.0-2B WebDemo部署&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/04-Yuan2.0-2B%20vLLM%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Yuan2.0-2B vLLM部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0/05-Yuan2.0-2B%20Lora%E5%BE%AE%E8%B0%83.md"&gt;Yuan2.0-2B Lora微调&lt;/a&gt; @张帆&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/IEIT-Yuan/Yuan2.0-M32"&gt;Yuan2.0-M32&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/01-Yuan2.0-M32%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Yuan2.0-M32 FastApi 部署调用&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/02-Yuan2.0-M32%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Yuan2.0-M32 Langchain 接入&lt;/a&gt; @张帆&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yuan2.0-M32/03-Yuan2.0-M32%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Yuan2.0-M32 WebDemo部署&lt;/a&gt; @张帆&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/deepseek-ai/DeepSeek-Coder-V2"&gt;DeepSeek-Coder-V2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/01-DeepSeek-Coder-V2-Lite-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;DeepSeek-Coder-V2-Lite-Instruct FastApi 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/02-DeepSeek-Coder-V2-Lite-Instruct%20%E6%8E%A5%E5%85%A5%20LangChain.md"&gt;DeepSeek-Coder-V2-Lite-Instruct langchain 接入&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/03-DeepSeek-Coder-V2-Lite-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;DeepSeek-Coder-V2-Lite-Instruct WebDemo 部署&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek-Coder-V2/04-DeepSeek-Coder-V2-Lite-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;DeepSeek-Coder-V2-Lite-Instruct Lora 微调&lt;/a&gt; @余洋&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/bilibili/Index-1.9B"&gt;哔哩哔哩 Index-1.9B&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/01-Index-1.9B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Index-1.9B-Chat FastApi 部署调用&lt;/a&gt; @邓恺俊&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/02-Index-1.9B-Chat%20%E6%8E%A5%E5%85%A5%20LangChain.md"&gt;Index-1.9B-Chat langchain 接入&lt;/a&gt; @张友东&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/03-Index-1.9B-chat%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Index-1.9B-Chat WebDemo 部署&lt;/a&gt; @程宏&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/bilibili_Index-1.9B/04-Index-1.9B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Index-1.9B-Chat Lora 微调&lt;/a&gt; @姜舒凡&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen2"&gt;Qwen2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/01-Qwen2-7B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2-7B-Instruct FastApi 部署调用&lt;/a&gt; @康婧淇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/02-Qwen2-7B-Instruct%20Langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Qwen2-7B-Instruct langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/03-Qwen2-7B-Instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Qwen2-7B-Instruct WebDemo 部署&lt;/a&gt; @三水&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/04-Qwen2-7B-Instruct%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen2-7B-Instruct vLLM 部署调用&lt;/a&gt; @姜舒凡&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen2/05-Qwen2-7B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen2-7B-Instruct Lora 微调&lt;/a&gt; @散步&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/THUDM/GLM-4.git"&gt;GLM-4&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/01-GLM-4-9B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;GLM-4-9B-chat FastApi 部署调用&lt;/a&gt; @张友东&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/02-GLM-4-9B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;GLM-4-9B-chat langchain 接入&lt;/a&gt; @谭逸珂&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/03-GLM-4-9B-Chat%20WebDemo.md"&gt;GLM-4-9B-chat WebDemo 部署&lt;/a&gt; @何至轩&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/04-GLM-4-9B-Chat%20vLLM%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;GLM-4-9B-chat vLLM 部署&lt;/a&gt; @王熠明&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/05-GLM-4-9B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;GLM-4-9B-chat Lora 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/GLM-4/05-GLM-4-9B-chat-hf%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;GLM-4-9B-chat-hf Lora 微调&lt;/a&gt; @付志远&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen1.5.git"&gt;Qwen 1.5&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/01-Qwen1.5-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen1.5-7B-chat FastApi 部署调用&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/02-Qwen1.5-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;Qwen1.5-7B-chat langchain 接入&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/03-Qwen1.5-7B-Chat%20WebDemo.md"&gt;Qwen1.5-7B-chat WebDemo 部署&lt;/a&gt; @颜鑫&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/04-Qwen1.5-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen1.5-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/05-Qwen1.5-7B-Chat-GPTQ-Int4%20%20WebDemo.md"&gt;Qwen1.5-72B-chat-GPTQ-Int4 部署环境&lt;/a&gt; @byx020119&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/06-Qwen1.5-MoE-A2.7B.md"&gt;Qwen1.5-MoE-chat Transformers 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/07-Qwen1.5-7B-Chat%20vLLM%20%E6%8E%A8%E7%90%86%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen1.5-7B-chat vLLM推理部署&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen1.5/08-Qwen1.5-7B-chat%20LoRA%E5%BE%AE%E8%B0%83%E6%8E%A5%E5%85%A5%E5%AE%9E%E9%AA%8C%E7%AE%A1%E7%90%86.md"&gt;Qwen1.5-7B-chat Lora 微调 接入SwanLab实验管理平台&lt;/a&gt; @黄柏特&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/google/gemma-7b-it"&gt;谷歌-Gemma&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/01-Gemma-2B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;gemma-2b-it FastApi 部署调用 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/02-Gemma-2B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;gemma-2b-it langchain 接入 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/03-Gemma-2B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;gemma-2b-it WebDemo 部署 &lt;/a&gt; @东东&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Gemma/04-Gemma-2B-Instruct%20Lora%E5%BE%AE%E8%B0%83.md"&gt;gemma-2b-it Peft Lora 微调 &lt;/a&gt; @东东&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"&gt;phi-3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/01-Phi-3-mini-4k-instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Phi-3-mini-4k-instruct FastApi 部署调用&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/02-Phi-3-mini-4k-instruct%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;Phi-3-mini-4k-instruct langchain 接入&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/03-Phi-3-mini-4k-instruct%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;Phi-3-mini-4k-instruct WebDemo 部署&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/phi-3/04-Phi-3-mini-4k-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Phi-3-mini-4k-instruct Lora 微调&lt;/a&gt; @丁悦&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/thu-coai/CharacterGLM-6B"&gt;CharacterGLM-6B&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/01-CharacterGLM-6B%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;CharacterGLM-6B Transformers 部署调用&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/02-CharacterGLM-6B%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;CharacterGLM-6B FastApi 部署调用&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/03-CharacterGLM-6B-chat.md"&gt;CharacterGLM-6B webdemo 部署&lt;/a&gt; @孙健壮&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/CharacterGLM/04-CharacterGLM-6B%20Lora%E5%BE%AE%E8%B0%83.md"&gt;CharacterGLM-6B Lora 微调&lt;/a&gt; @孙健壮&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/meta-llama/llama3.git"&gt;LLaMA3-8B-Instruct&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/01-LLaMA3-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;LLaMA3-8B-Instruct FastApi 部署调用&lt;/a&gt; @高立业&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/02-LLaMA3-8B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;LLaMA3-8B-Instruct langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/03-LLaMA3-8B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;LLaMA3-8B-Instruct WebDemo 部署&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/LLaMA3/04-LLaMA3-8B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;LLaMA3-8B-Instruct Lora 微调&lt;/a&gt; @高立业&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://modelscope.cn/models/xverse/XVERSE-7B-Chat/summary"&gt;XVERSE-7B-Chat&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/01-XVERSE-7B-chat%20Transformers%E6%8E%A8%E7%90%86.md"&gt;XVERSE-7B-Chat transformers 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/02-XVERSE-7B-chat%20FastAPI%E9%83%A8%E7%BD%B2.md"&gt;XVERSE-7B-Chat FastApi 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/03-XVERSE-7B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;XVERSE-7B-Chat langchain 接入&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/04-XVERSE-7B-chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;XVERSE-7B-Chat WebDemo 部署&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/XVERSE/05-XVERSE-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;XVERSE-7B-Chat Lora 微调&lt;/a&gt; @郭志航&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/OpenNLPLab/TransnormerLLM.git"&gt;TransNormerLLM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/01-TransNormer-7B%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;TransNormerLLM-7B-Chat FastApi 部署调用&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/02-TransNormer-7B%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;TransNormerLLM-7B-Chat langchain 接入&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/03-TransNormer-7B%20WebDemo.md"&gt;TransNormerLLM-7B-Chat WebDemo 部署&lt;/a&gt; @王茂霖&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/TransNormer/04-TrasnNormer-7B%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;TransNormerLLM-7B-Chat Lora 微调&lt;/a&gt; @王茂霖&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vivo-ai-lab/BlueLM.git"&gt;BlueLM Vivo 蓝心大模型&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/01-BlueLM-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2.md"&gt;BlueLM-7B-Chat FatApi 部署调用&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/02-BlueLM-7B-Chat%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;BlueLM-7B-Chat langchain 接入&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/03-BlueLM-7B-Chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;BlueLM-7B-Chat WebDemo 部署&lt;/a&gt; @郭志航&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BlueLM/04-BlueLM-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;BlueLM-7B-Chat Lora 微调&lt;/a&gt; @郭志航&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/InternLM/InternLM"&gt;InternLM2&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/01-InternLM2-7B-chat%20FastAPI%E9%83%A8%E7%BD%B2.md"&gt;InternLM2-7B-chat FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/02-InternLM2-7B-chat%20langchain%20%E6%8E%A5%E5%85%A5.md"&gt;InternLM2-7B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/03-InternLM2-7B-chat%20WebDemo%20%E9%83%A8%E7%BD%B2.md"&gt;InternLM2-7B-chat WebDemo 部署&lt;/a&gt; @郑皓桦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM2/04-InternLM2-7B-chat%20Xtuner%20Qlora%20%E5%BE%AE%E8%B0%83.md"&gt;InternLM2-7B-chat Xtuner Qlora 微调&lt;/a&gt; @郑皓桦&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/deepseek-ai/DeepSeek-LLM"&gt;DeepSeek 深度求索&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/01-DeepSeek-7B-chat%20FastApi.md"&gt;DeepSeek-7B-chat FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/02-DeepSeek-7B-chat%20langchain.md"&gt;DeepSeek-7B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/03-DeepSeek-7B-chat%20WebDemo.md"&gt;DeepSeek-7B-chat WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/04-DeepSeek-7B-chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;DeepSeek-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/05-DeepSeek-7B-chat%204bits%E9%87%8F%E5%8C%96%20Qlora%20%E5%BE%AE%E8%B0%83.md"&gt;DeepSeek-7B-chat 4bits量化 Qlora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/06-DeepSeek-MoE-16b-chat%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;DeepSeek-MoE-16b-chat Transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/06-DeepSeek-MoE-16b-chat%20FastApi.md"&gt;DeepSeek-MoE-16b-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/07-deepseek_fine_tune.ipynb"&gt;DeepSeek-coder-6.7b finetune colab&lt;/a&gt; @Swiftie&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/DeepSeek/08-deepseek_web_demo.ipynb"&gt;Deepseek-coder-6.7b webdemo colab&lt;/a&gt; @Swiftie&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/OpenBMB/MiniCPM.git"&gt;MiniCPM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;MiniCPM-2B-chat transformers 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;MiniCPM-2B-chat FastApi 部署调用&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20langchain%E6%8E%A5%E5%85%A5.md"&gt;MiniCPM-2B-chat langchain 接入&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20WebDemo%E9%83%A8%E7%BD%B2.md"&gt;MiniCPM-2B-chat webdemo 部署&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/MiniCPM/MiniCPM-2B-chat%20Lora%20&amp;amp;&amp;amp;%20Full%20%E5%BE%AE%E8%B0%83.md"&gt;MiniCPM-2B-chat Lora &amp;amp;&amp;amp; Full 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 官方友情链接：&lt;a href="https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg"&gt;面壁小钢炮MiniCPM教程&lt;/a&gt; @OpenBMB&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 官方友情链接：&lt;a href="https://github.com/OpenBMB/MiniCPM-CookBook"&gt;MiniCPM-Cookbook&lt;/a&gt; @OpenBMB&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen-Audio.git"&gt;Qwen-Audio&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen-Audio/01-Qwen-Audio-chat%20FastApi.md"&gt;Qwen-Audio FastApi 部署调用&lt;/a&gt; @陈思州&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen-Audio/02-Qwen-Audio-chat%20WebDemo.md"&gt;Qwen-Audio WebDemo&lt;/a&gt; @陈思州&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/QwenLM/Qwen.git"&gt;Qwen&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/01-Qwen-7B-Chat%20Transformers%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen-7B-chat Transformers 部署调用&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/02-Qwen-7B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Qwen-7B-chat FastApi 部署调用&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/03-Qwen-7B-Chat%20WebDemo.md"&gt;Qwen-7B-chat WebDemo&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/04-Qwen-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen-7B-chat Lora 微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/05-Qwen-7B-Chat%20Ptuning%20%E5%BE%AE%E8%B0%83.md"&gt;Qwen-7B-chat ptuning 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/06-Qwen-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md"&gt;Qwen-7B-chat 全量微调&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/07-Qwen-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;Qwen-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @李娇娇&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/08-Qwen-7B-Chat%20Lora%20%E4%BD%8E%E7%B2%BE%E5%BA%A6%E5%BE%AE%E8%B0%83.md"&gt;Qwen-7B-chat 低精度训练&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Qwen/09-Qwen-1_8B-chat%20CPU%20%E9%83%A8%E7%BD%B2%20.md"&gt;Qwen-1_8B-chat CPU 部署&lt;/a&gt; @散步&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/01-ai/Yi.git"&gt;Yi 零一万物&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/01-Yi-6B-Chat%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Yi-6B-chat FastApi 部署调用&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/02-Yi-6B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;Yi-6B-chat langchain接入&lt;/a&gt; @李柯辰&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/03-Yi-6B-chat%20WebDemo.md"&gt;Yi-6B-chat WebDemo&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Yi/04-Yi-6B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Yi-6B-chat Lora 微调&lt;/a&gt; @李娇娇&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.baichuan-ai.com/home"&gt;Baichuan 百川智能&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/BaiChuan/01-Baichuan2-7B-chat%2BFastApi%2B%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;Baichuan2-7B-chat FastApi 部署调用&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/02-Baichuan-7B-chat%2BWebDemo.md"&gt;Baichuan2-7B-chat WebDemo&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/03-Baichuan2-7B-chat%E6%8E%A5%E5%85%A5LangChain%E6%A1%86%E6%9E%B6.md"&gt;Baichuan2-7B-chat 接入 LangChain 框架&lt;/a&gt; @惠佳豪&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/BaiChuan/04-Baichuan2-7B-chat%2Blora%2B%E5%BE%AE%E8%B0%83.md"&gt;Baichuan2-7B-chat Lora 微调&lt;/a&gt; @惠佳豪&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/InternLM/InternLM.git"&gt;InternLM&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/01-InternLM-Chat-7B%20Transformers%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;InternLM-Chat-7B Transformers 部署调用&lt;/a&gt; @小罗&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/02-internLM-Chat-7B%20FastApi.md"&gt;InternLM-Chat-7B FastApi 部署调用&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/03-InternLM-Chat-7B.md"&gt;InternLM-Chat-7B WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/04-Lagent+InternLM-Chat-7B-V1.1.md"&gt;Lagent+InternLM-Chat-7B-V1.1 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/05-%E6%B5%A6%E8%AF%AD%E7%81%B5%E7%AC%94%E5%9B%BE%E6%96%87%E7%90%86%E8%A7%A3&amp;amp;%E5%88%9B%E4%BD%9C.md"&gt;浦语灵笔图文理解&amp;amp;创作 WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/InternLM/06-InternLM%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;InternLM-Chat-7B 接入 LangChain 框架&lt;/a&gt; @Logan Zou&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://hf-mirror.com/FlagAlpha/Atom-7B-Chat"&gt;Atom (llama2)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/01-Atom-7B-chat-WebDemo.md"&gt;Atom-7B-chat WebDemo&lt;/a&gt; @Kailigithub&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/02-Atom-7B-Chat%20Lora%20%E5%BE%AE%E8%B0%83.md"&gt;Atom-7B-chat Lora 微调&lt;/a&gt; @Logan Zou&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/03-Atom-7B-Chat%20%E6%8E%A5%E5%85%A5langchain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;Atom-7B-Chat 接入langchain搭建知识库助手&lt;/a&gt; @陈思州&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/Atom/04-Atom-7B-chat%20%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83.md"&gt;Atom-7B-chat 全量微调&lt;/a&gt; @Logan Zou&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/THUDM/ChatGLM3.git"&gt;ChatGLM3&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/01-ChatGLM3-6B%20Transformer%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;ChatGLM3-6B Transformers 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/02-ChatGLM3-6B%20FastApi%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md"&gt;ChatGLM3-6B FastApi 部署调用&lt;/a&gt; @丁悦&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/03-ChatGLM3-6B-chat.md"&gt;ChatGLM3-6B chat WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/04-ChatGLM3-6B-Code-Interpreter.md"&gt;ChatGLM3-6B Code Interpreter WebDemo&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/05-ChatGLM3-6B%E6%8E%A5%E5%85%A5LangChain%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93%E5%8A%A9%E6%89%8B.md"&gt;ChatGLM3-6B 接入 LangChain 框架&lt;/a&gt; @Logan Zou&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/ChatGLM/06-ChatGLM3-6B-Lora%E5%BE%AE%E8%B0%83.md"&gt;ChatGLM3-6B Lora 微调&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;通用环境配置&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/01-pip%E3%80%81conda%E6%8D%A2%E6%BA%90.md"&gt;pip、conda 换源&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/02-AutoDL%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3.md"&gt;AutoDL 开放端口&lt;/a&gt; @不要葱姜蒜&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;模型下载&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md"&gt;hugging face&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md"&gt;hugging face&lt;/a&gt; 镜像下载 @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md"&gt;modelscope&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md"&gt;git-lfs&lt;/a&gt; @不要葱姜蒜&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/03-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD.md"&gt;Openxlab&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Issue &amp;amp;&amp;amp; PR&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md"&gt;Issue 提交&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md"&gt;PR 提交&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; &lt;a href="https://raw.githubusercontent.com/datawhalechina/self-llm/master/models/General-Setting/04-Issue&amp;amp;PR&amp;amp;update.md"&gt;fork更新&lt;/a&gt; @肖鸿儒&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;致谢&lt;/h2&gt; 
&lt;h3&gt;核心贡献者&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KMnO4-zx"&gt;宋志学(不要葱姜蒜)-项目负责人&lt;/a&gt; （Datawhale成员-中国矿业大学(北京)）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/logan-zou"&gt;邹雨衡-项目负责人&lt;/a&gt; （Datawhale成员-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Tsumugii24"&gt;姜舒凡&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Hongru0306"&gt;肖鸿儒&lt;/a&gt; （Datawhale成员-同济大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/acwwt"&gt;郭志航&lt;/a&gt;（内容创作者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Zeyi-Lin"&gt;林泽毅&lt;/a&gt;（内容创作者-SwanLab产品负责人）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhangfanTJU"&gt;张帆&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/moyitech"&gt;王泽宇&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aphasia0515"&gt;李娇娇&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0-yy-0"&gt;高立业&lt;/a&gt;（内容创作者-DataWhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dingyue772"&gt;丁悦&lt;/a&gt; （Datawhale-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LINHYYY"&gt;林恒宇&lt;/a&gt;（内容创作者-清华大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/L4HeyXiao"&gt;惠佳豪&lt;/a&gt; （Datawhale-宣传大使）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mlw67"&gt;王茂霖&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Caleb-Sun-jz"&gt;孙健壮&lt;/a&gt;（内容创作者-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LucaChen"&gt;东东&lt;/a&gt;（内容创作者-谷歌开发者机器学习技术专家）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yeyeyeyeeeee"&gt;荞麦&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Kailigithub"&gt;Kailigithub&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BaiYu96"&gt;郑皓桦&lt;/a&gt; （内容创作者）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Joe-2002"&gt;李柯辰&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chg0901"&gt;程宏&lt;/a&gt;（内容创作者-Datawhale意向成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anine09"&gt;骆秀韬&lt;/a&gt;（内容创作者-Datawhale成员-似然实验室）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Twosugar666"&gt;郭宣伯&lt;/a&gt;（内容创作者-北京航空航天大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ilovexsir"&gt;谢好冉&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jjyaoao"&gt;陈思州&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sanbuphy"&gt;散步&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thomas-yanxin"&gt;颜鑫&lt;/a&gt; （Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/study520ai520"&gt;杜森&lt;/a&gt;（内容创作者-Datawhale成员-南阳理工学院）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cswangxiaowei"&gt;Swiftie&lt;/a&gt; （小米NLP算法工程师）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KashiwaByte"&gt;黄柏特&lt;/a&gt;（内容创作者-西安电子科技大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AXYZdong"&gt;张友东&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YangYu-NUAA"&gt;余洋&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jin-Zhang-Yaoguang"&gt;张晋&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lta155"&gt;娄天奥&lt;/a&gt;（内容创作者-中国科学院大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LinChentang"&gt;左春生&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/little1d"&gt;杨卓&lt;/a&gt;（内容创作者-西安电子科技大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lyj11111111"&gt;小罗&lt;/a&gt; （内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Kedreamix"&gt;邓恺俊&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/XiLinky"&gt;赵文恺&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/comfzy"&gt;付志远&lt;/a&gt;（内容创作者-海南大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/isaacahahah"&gt;郑远婧&lt;/a&gt;（内容创作者-鲸英助教-福州大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Bald0Wang"&gt;王熠明&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LikeGiver"&gt;谭逸珂&lt;/a&gt;（内容创作者-对外经济贸易大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pod2c"&gt;何至轩&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jodie-kang"&gt;康婧淇&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sssanssss"&gt;三水&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langlibai66"&gt;杨晨旭&lt;/a&gt;（内容创作者-太原理工大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/2710932616"&gt;赵伟&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gzhuuser"&gt;苏向标&lt;/a&gt;（内容创作者-广州大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/riannyway"&gt;陈睿&lt;/a&gt;（内容创作者-西交利物浦大学-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Feimike09"&gt;张龙斐&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anarchysaiko"&gt;孙超&lt;/a&gt;（内容创作者-Datawhale成员）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fanqiNO1"&gt;樊奇&lt;/a&gt;（内容创作者-上海交通大学）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nusakom"&gt;卓堂越&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fancyboi999"&gt;fancy&lt;/a&gt;（内容创作者-鲸英助教）&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注：排名根据贡献程度排序&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;其他&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;特别感谢&lt;a href="https://github.com/Sm1les"&gt;@Sm1les&lt;/a&gt;对本项目的帮助与支持&lt;/li&gt; 
 &lt;li&gt;部分lora代码和讲解参考仓库：&lt;a href="https://github.com/zyds/transformers-code.git"&gt;https://github.com/zyds/transformers-code.git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;如果有任何想法可以联系我们 DataWhale 也欢迎大家多多提出 issue&lt;/li&gt; 
 &lt;li&gt;特别感谢以下为教程做出贡献的同学！&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;a href="https://github.com/datawhalechina/self-llm/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=datawhalechina/self-llm"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Star History&lt;/h3&gt; 
&lt;div align="center" style="margin-top: 30px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/datawhalechina/self-llm/master/images/star-history-202572.png"&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>prisma/prisma</title>
      <link>https://github.com/prisma/prisma</link>
      <description>&lt;p&gt;Next-generation ORM for Node.js &amp; TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://i.imgur.com/h6UIYTu.png" alt="Prisma"&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Prisma&lt;/h1&gt; 
 &lt;a href="https://www.npmjs.com/package/prisma"&gt;&lt;img src="https://img.shields.io/npm/v/prisma.svg?style=flat"&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/prisma/prisma/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true"&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/prisma/prisma/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202-blue"&gt;&lt;/a&gt; 
 &lt;a href="https://pris.ly/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/937751382725886062?label=Discord"&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;a href="https://www.prisma.io/docs/getting-started/quickstart"&gt;Quickstart&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/"&gt;Website&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/docs/"&gt;Docs&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://github.com/prisma/prisma-examples/"&gt;Examples&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/blog"&gt;Blog&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/discord?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Discord&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/x?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Twitter&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/youtube?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Youtube&lt;/a&gt; 
 &lt;br&gt; 
 &lt;hr&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Prisma?&lt;/h2&gt; 
&lt;p&gt;Prisma ORM is a &lt;strong&gt;next-generation ORM&lt;/strong&gt; that consists of these tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client"&gt;&lt;strong&gt;Prisma Client&lt;/strong&gt;&lt;/a&gt;: Auto-generated and type-safe query builder for Node.js &amp;amp; TypeScript&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/concepts/components/prisma-migrate"&gt;&lt;strong&gt;Prisma Migrate&lt;/strong&gt;&lt;/a&gt;: Declarative data modeling &amp;amp; migration system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prisma/studio"&gt;&lt;strong&gt;Prisma Studio&lt;/strong&gt;&lt;/a&gt;: GUI to view and edit data in your database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Prisma Client can be used in &lt;em&gt;any&lt;/em&gt; Node.js or TypeScript backend application (including serverless applications and microservices). This can be a &lt;a href="https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/rest"&gt;REST API&lt;/a&gt;, a &lt;a href="https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/graphql"&gt;GraphQL API&lt;/a&gt;, a gRPC API, or anything else that needs a database.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you need a database to use with Prisma ORM, check out &lt;a href="https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres?utm_source=github&amp;amp;utm_medium=prisma-readme"&gt;Prisma Postgres&lt;/a&gt; or if you are looking for our MCP Server, head &lt;a href="https://github.com/prisma/mcp"&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Quickstart (5min)&lt;/h3&gt; 
&lt;p&gt;The fastest way to get started with Prisma is by following the quickstart guides. You can choose either of two databases:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres"&gt;Prisma Postgres&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/quickstart-sqlite"&gt;SQLite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bring your own database&lt;/h3&gt; 
&lt;p&gt;If you already have your own database, you can follow these guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/setup-prisma/add-to-existing-project/relational-databases-typescript-postgresql"&gt;Add Prisma to an existing project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/setup-prisma/start-from-scratch/relational-databases-typescript-postgresql"&gt;Set up a new project with Prisma from scratch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How Prisma ORM works&lt;/h2&gt; 
&lt;p&gt;This section provides a high-level overview of how Prisma ORM works and its most important technical components. For a more thorough introduction, visit the &lt;a href="https://www.prisma.io/docs/"&gt;Prisma documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;The Prisma schema&lt;/h3&gt; 
&lt;p&gt;Every project that uses a tool from the Prisma toolkit starts with a &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-schema"&gt;Prisma schema file&lt;/a&gt;. The Prisma schema allows developers to define their &lt;em&gt;application models&lt;/em&gt; in an intuitive data modeling language. It also contains the connection to a database and defines a &lt;em&gt;generator&lt;/em&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-prisma"&gt;// Data source
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

// Generator
generator client {
  provider = "prisma-client-js"
}

// Data model
model Post {
  id        Int     @id @default(autoincrement())
  title     String
  content   String?
  published Boolean @default(false)
  author    User?   @relation(fields:  [authorId], references: [id])
  authorId  Int?
}

model User {
  id    Int     @id @default(autoincrement())
  email String  @unique
  name  String?
  posts Post[]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this schema, you configure three things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data source&lt;/strong&gt;: Specifies your database connection (via an environment variable)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generator&lt;/strong&gt;: Indicates that you want to generate Prisma Client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data model&lt;/strong&gt;: Defines your application models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;The Prisma data model&lt;/h3&gt; 
&lt;p&gt;On this page, the focus is on the data model. You can learn more about &lt;a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/data-sources"&gt;Data sources&lt;/a&gt; and &lt;a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/generators"&gt;Generators&lt;/a&gt; on the respective docs pages.&lt;/p&gt; 
&lt;h4&gt;Functions of Prisma models&lt;/h4&gt; 
&lt;p&gt;The data model is a collection of &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-schema/data-model#defining-models"&gt;models&lt;/a&gt;. A model has two major functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Represent a table in the underlying database&lt;/li&gt; 
 &lt;li&gt;Provide the foundation for the queries in the Prisma Client API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Getting a data model&lt;/h4&gt; 
&lt;p&gt;There are two major workflows for "getting" a data model into your Prisma schema:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate the data model from &lt;a href="https://www.prisma.io/docs/concepts/components/introspection"&gt;introspecting&lt;/a&gt; a database&lt;/li&gt; 
 &lt;li&gt;Manually writing the data model and mapping it to the database with &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-migrate"&gt;Prisma Migrate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once the data model is defined, you can &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client"&gt;generate Prisma Client&lt;/a&gt; which will expose CRUD and more queries for the defined models. If you're using TypeScript, you'll get full type-safety for all queries (even when only retrieving the subsets of a model's fields).&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Accessing your database with Prisma Client&lt;/h3&gt; 
&lt;h4&gt;Generating Prisma Client&lt;/h4&gt; 
&lt;p&gt;The first step when using Prisma Client is installing its npm package:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm install @prisma/client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the installation of this package invokes the &lt;code&gt;prisma generate&lt;/code&gt; command which reads your Prisma schema and &lt;em&gt;generates&lt;/em&gt; the Prisma Client code. The code will be located in &lt;code&gt;node_modules/.prisma/client&lt;/code&gt;, which is exported by &lt;code&gt;node_modules/@prisma/client/index.d.ts&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;After you change your data model, you'll need to manually re-generate Prisma Client to ensure the code inside &lt;code&gt;node_modules/.prisma/client&lt;/code&gt; gets updated:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npx prisma generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to the documentation for more information about &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client"&gt;"generating the Prisma client"&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Using Prisma Client to send queries to your database&lt;/h4&gt; 
&lt;p&gt;Once the Prisma Client is generated, you can import it in your code and send queries to your database. This is what the setup code looks like.&lt;/p&gt; 
&lt;h5&gt;Import and instantiate Prisma Client&lt;/h5&gt; 
&lt;p&gt;You can import and instantiate Prisma Client as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;const { PrismaClient } = require('@prisma/client')

const prisma = new PrismaClient()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can start sending queries via the generated Prisma Client API, here are a few sample queries. Note that all Prisma Client queries return &lt;em&gt;plain old JavaScript objects&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about the available operations in the &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client"&gt;Prisma Client docs&lt;/a&gt; or watch this &lt;a href="https://www.youtube.com/watch?v=LggrE5kJ75I&amp;amp;list=PLn2e1F9Rfr6k9PnR_figWOcSHgc_erDr5&amp;amp;index=4"&gt;demo video&lt;/a&gt; (2 min).&lt;/p&gt; 
&lt;h5&gt;Retrieve all &lt;code&gt;User&lt;/code&gt; records from the database&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const allUsers = await prisma.user.findMany()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Include the &lt;code&gt;posts&lt;/code&gt; relation on each returned &lt;code&gt;User&lt;/code&gt; object&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const allUsers = await prisma.user.findMany({
  include: { posts: true },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Filter all &lt;code&gt;Post&lt;/code&gt; records that contain &lt;code&gt;"prisma"&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const filteredPosts = await prisma.post.findMany({
  where: {
    OR: [{ title: { contains: 'prisma' } }, { content: { contains: 'prisma' } }],
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Create a new &lt;code&gt;User&lt;/code&gt; and a new &lt;code&gt;Post&lt;/code&gt; record in the same query&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const user = await prisma.user.create({
  data: {
    name: 'Alice',
    email: 'alice@prisma.io',
    posts: {
      create: { title: 'Join us for Prisma Day 2021' },
    },
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Update an existing &lt;code&gt;Post&lt;/code&gt; record&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const post = await prisma.post.update({
  where: { id: 42 },
  data: { published: true },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Usage with TypeScript&lt;/h4&gt; 
&lt;p&gt;Note that when using TypeScript, the result of this query will be &lt;em&gt;statically typed&lt;/em&gt; so that you can't accidentally access a property that doesn't exist (and any typos are caught at compile-time). Learn more about leveraging Prisma Client's generated types on the &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/advanced-usage-of-generated-types"&gt;Advanced usage of generated types&lt;/a&gt; page in the docs.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Prisma has a large and supportive &lt;a href="https://www.prisma.io/community"&gt;community&lt;/a&gt; of enthusiastic application developers. You can join us on &lt;a href="https://pris.ly/discord"&gt;Discord&lt;/a&gt; and here on &lt;a href="https://github.com/prisma/prisma/discussions"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Badges&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://prisma.io"&gt;&lt;img src="http://made-with.prisma.io/dark.svg?sanitize=true" alt="Made with Prisma"&gt;&lt;/a&gt; &lt;a href="https://prisma.io"&gt;&lt;img src="http://made-with.prisma.io/indigo.svg?sanitize=true" alt="Made with Prisma"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Built something awesome with Prisma? 🌟 Show it off with these &lt;a href="https://github.com/prisma/presskit?tab=readme-ov-file#badges"&gt;badges&lt;/a&gt;, perfect for your readme or website.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;[![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you have a security issue to report, please contact us at &lt;a href="mailto:security@prisma.io?subject=%5BGitHub%5D%20Prisma%202%20Security%20Report%20"&gt;security@prisma.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;h3&gt;Ask a question about Prisma&lt;/h3&gt; 
&lt;p&gt;You can ask questions and initiate &lt;a href="https://github.com/prisma/prisma/discussions/"&gt;discussions&lt;/a&gt; about Prisma-related topics in the &lt;code&gt;prisma&lt;/code&gt; repository on GitHub.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://github.com/prisma/prisma/discussions/new"&gt;&lt;strong&gt;Ask a question&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Create a bug report for Prisma&lt;/h3&gt; 
&lt;p&gt;If you see an error message or run into an issue, please make sure to create a bug report! You can find &lt;a href="https://www.prisma.io/docs/guides/other/troubleshooting-orm/creating-bug-reports"&gt;best practices for creating bug reports&lt;/a&gt; (like including additional debugging output) in the docs.&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://pris.ly/prisma-prisma-bug-report"&gt;&lt;strong&gt;Create bug report&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Submit a feature request&lt;/h3&gt; 
&lt;p&gt;If Prisma currently doesn't have a certain feature, be sure to check out the &lt;a href="https://www.prisma.io/docs/more/roadmap"&gt;roadmap&lt;/a&gt; to see if this is already planned for the future.&lt;/p&gt; 
&lt;p&gt;If the feature on the roadmap is linked to a GitHub issue, please make sure to leave a 👍 reaction on the issue and ideally a comment with your thoughts about the feature!&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://github.com/prisma/prisma/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature_request.md&amp;amp;title="&gt;&lt;strong&gt;Submit feature request&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/prisma/prisma/raw/main/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt; and &lt;a href="https://github.com/prisma/prisma/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct for contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Tests Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prisma Tests Status: &lt;a href="https://github.com/prisma/prisma/actions/workflows/test.yml?query=branch%3Amain"&gt;&lt;img src="https://github.com/prisma/prisma/workflows/CI/badge.svg?sanitize=true" alt="Prisma Tests Status"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ecosystem Tests Status: &lt;a href="https://github.com/prisma/ecosystem-tests/actions/workflows/test.yaml?query=branch%3Adev"&gt;&lt;img src="https://github.com/prisma/ecosystem-tests/workflows/test/badge.svg?sanitize=true" alt="Ecosystem Tests Status"&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>