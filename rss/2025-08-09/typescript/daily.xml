<rss version="2.0">
  <channel>
    <title>GitHub TypeScript Daily Trending</title>
    <description>Daily Trending of TypeScript in GitHub</description>
    <pubDate>Fri, 08 Aug 2025 01:36:50 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dzhng/deep-research</title>
      <link>https://github.com/dzhng/deep-research</link>
      <description>&lt;p&gt;An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models. The goal of this repo is to provide the simplest implementation of a deep research agent - e.g. an agent that can refine its research direction overtime and deep dive into a topic.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Deep Research&lt;/h1&gt; 
&lt;p&gt;An AI-powered research assistant that performs iterative, deep research on any topic by combining search engines, web scraping, and large language models.&lt;/p&gt; 
&lt;p&gt;The goal of this repo is to provide the simplest implementation of a deep research agent - e.g. an agent that can refine its research direction over time and deep dive into a topic. Goal is to keep the repo size at &amp;lt;500 LoC so it is easy to understand and build on top of.&lt;/p&gt; 
&lt;p&gt;If you like this project, please consider starring it and giving me a follow on &lt;a href="https://x.com/dzhng"&gt;X/Twitter&lt;/a&gt;. This project is sponsored by &lt;a href="https://aomni.com"&gt;Aomni&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    subgraph Input
        Q[User Query]
        B[Breadth Parameter]
        D[Depth Parameter]
    end

    DR[Deep Research] --&amp;gt;
    SQ[SERP Queries] --&amp;gt;
    PR[Process Results]

    subgraph Results[Results]
        direction TB
        NL((Learnings))
        ND((Directions))
    end

    PR --&amp;gt; NL
    PR --&amp;gt; ND

    DP{depth &amp;gt; 0?}

    RD["Next Direction:
    - Prior Goals
    - New Questions
    - Learnings"]

    MR[Markdown Report]

    %% Main Flow
    Q &amp;amp; B &amp;amp; D --&amp;gt; DR

    %% Results to Decision
    NL &amp;amp; ND --&amp;gt; DP

    %% Circular Flow
    DP --&amp;gt;|Yes| RD
    RD --&amp;gt;|New Context| DR

    %% Final Output
    DP --&amp;gt;|No| MR

    %% Styling
    classDef input fill:#7bed9f,stroke:#2ed573,color:black
    classDef process fill:#70a1ff,stroke:#1e90ff,color:black
    classDef recursive fill:#ffa502,stroke:#ff7f50,color:black
    classDef output fill:#ff4757,stroke:#ff6b81,color:black
    classDef results fill:#a8e6cf,stroke:#3b7a57,color:black

    class Q,B,D input
    class DR,SQ,PR process
    class DP,RD recursive
    class MR output
    class NL,ND results
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Iterative Research&lt;/strong&gt;: Performs deep research by iteratively generating search queries, processing results, and diving deeper based on findings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Query Generation&lt;/strong&gt;: Uses LLMs to generate targeted search queries based on research goals and previous findings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Depth &amp;amp; Breadth Control&lt;/strong&gt;: Configurable parameters to control how wide (breadth) and deep (depth) the research goes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Follow-up&lt;/strong&gt;: Generates follow-up questions to better understand research needs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Reports&lt;/strong&gt;: Produces detailed markdown reports with findings and sources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Concurrent Processing&lt;/strong&gt;: Handles multiple searches and result processing in parallel for efficiency&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js environment&lt;/li&gt; 
 &lt;li&gt;API keys for: 
  &lt;ul&gt; 
   &lt;li&gt;Firecrawl API (for web search and content extraction)&lt;/li&gt; 
   &lt;li&gt;OpenAI API (for o3 mini model)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;Node.js&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment variables in a &lt;code&gt;.env.local&lt;/code&gt; file:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;FIRECRAWL_KEY="your_firecrawl_key"
# If you want to use your self-hosted Firecrawl, add the following below:
# FIRECRAWL_BASE_URL="http://localhost:3002"

OPENAI_KEY="your_openai_key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use local LLM, comment out &lt;code&gt;OPENAI_KEY&lt;/code&gt; and instead uncomment &lt;code&gt;OPENAI_ENDPOINT&lt;/code&gt; and &lt;code&gt;OPENAI_MODEL&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set &lt;code&gt;OPENAI_ENDPOINT&lt;/code&gt; to the address of your local server (eg."&lt;a href="http://localhost:1234/v1"&gt;http://localhost:1234/v1&lt;/a&gt;")&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;OPENAI_MODEL&lt;/code&gt; to the name of the model loaded in your local server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repository&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rename &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env.local&lt;/code&gt; and set your API keys&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run &lt;code&gt;docker build -f Dockerfile&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the Docker image:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Execute &lt;code&gt;npm run docker&lt;/code&gt; in the docker service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it deep-research npm run docker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Run the research assistant:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You'll be prompted to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enter your research query&lt;/li&gt; 
 &lt;li&gt;Specify research breadth (recommended: 3-10, default: 4)&lt;/li&gt; 
 &lt;li&gt;Specify research depth (recommended: 1-5, default: 2)&lt;/li&gt; 
 &lt;li&gt;Answer follow-up questions to refine the research direction&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The system will then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate and execute search queries&lt;/li&gt; 
 &lt;li&gt;Process and analyze search results&lt;/li&gt; 
 &lt;li&gt;Recursively explore deeper based on findings&lt;/li&gt; 
 &lt;li&gt;Generate a comprehensive markdown report&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The final report will be saved as &lt;code&gt;report.md&lt;/code&gt; or &lt;code&gt;answer.md&lt;/code&gt; in your working directory, depending on which modes you selected.&lt;/p&gt; 
&lt;h3&gt;Concurrency&lt;/h3&gt; 
&lt;p&gt;If you have a paid version of Firecrawl or a local version, feel free to increase the &lt;code&gt;ConcurrencyLimit&lt;/code&gt; by setting the &lt;code&gt;CONCURRENCY_LIMIT&lt;/code&gt; environment variable so it runs faster.&lt;/p&gt; 
&lt;p&gt;If you have a free version, you may sometimes run into rate limit errors, you can reduce the limit to 1 (but it will run a lot slower).&lt;/p&gt; 
&lt;h3&gt;DeepSeek R1&lt;/h3&gt; 
&lt;p&gt;Deep research performs great on R1! We use &lt;a href="http://fireworks.ai"&gt;Fireworks&lt;/a&gt; as the main provider for the R1 model. To use R1, simply set a Fireworks API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;FIREWORKS_KEY="api_key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The system will automatically switch over to use R1 instead of &lt;code&gt;o3-mini&lt;/code&gt; when the key is detected.&lt;/p&gt; 
&lt;h3&gt;Custom endpoints and models&lt;/h3&gt; 
&lt;p&gt;There are 2 other optional env vars that lets you tweak the endpoint (for other OpenAI compatible APIs like OpenRouter or Gemini) as well as the model string.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_ENDPOINT="custom_endpoint"
CUSTOM_MODEL="custom_model"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Initial Setup&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Takes user query and research parameters (breadth &amp;amp; depth)&lt;/li&gt; 
   &lt;li&gt;Generates follow-up questions to understand research needs better&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Research Process&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Generates multiple SERP queries based on research goals&lt;/li&gt; 
   &lt;li&gt;Processes search results to extract key learnings&lt;/li&gt; 
   &lt;li&gt;Generates follow-up research directions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recursive Exploration&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If depth &amp;gt; 0, takes new research directions and continues exploration&lt;/li&gt; 
   &lt;li&gt;Each iteration builds on previous learnings&lt;/li&gt; 
   &lt;li&gt;Maintains context of research goals and findings&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Report Generation&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Compiles all findings into a comprehensive markdown report&lt;/li&gt; 
   &lt;li&gt;Includes all sources and references&lt;/li&gt; 
   &lt;li&gt;Organizes information in a clear, readable format&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - feel free to use and modify as needed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>devlikeapro/waha</title>
      <link>https://github.com/devlikeapro/waha</link>
      <description>&lt;p&gt;WAHA - WhatsApp HTTP API (REST API) that you can configure in a click! 3 engines: WEBJS (browser based), NOWEB (websocket nodejs), GOWS (websocket go)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WAHA&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/devlikeapro/waha/core/logo.png" style="border-radius: 50%" width="150"&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WAHA&lt;/strong&gt; - &lt;strong&gt;W&lt;/strong&gt;hats&lt;strong&gt;A&lt;/strong&gt;pp &lt;strong&gt;H&lt;/strong&gt;TTP &lt;strong&gt;A&lt;/strong&gt;PI (REST API) that you can install on your own server and run in less than 5 minutes!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/devlikeapro/waha"&gt;&lt;img src="https://img.shields.io/docker/pulls/devlikeapro/waha" alt="Docker Pulls"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://waha.devlike.pro/"&gt;https://waha.devlike.pro/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dashboard Example: &lt;a href="https://waha.devlike.pro/dashboard"&gt;https://waha.devlike.pro/dashboard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Swagger Example: &lt;a href="https://waha.devlike.pro/swagger"&gt;https://waha.devlike.pro/swagger&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Tables of Contents&lt;/h1&gt; 
&lt;!-- toc --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#quick-start"&gt;Quick start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#send-your-first-message"&gt;Send your first message&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#1-download-image"&gt;1. Download image&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#2-run-whatsapp-http-api"&gt;2. Run WhatsApp HTTP API&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#3-start-a-new-session"&gt;3. Start a new session&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#4-get-and-scan-qr"&gt;4. Get and scan QR&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#5-get-the-screenshot"&gt;5. Get the screenshot&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#6-send-a-text-message"&gt;6. Send a text message&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#what-is-next"&gt;What is next?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#development"&gt;Development&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#start-the-project"&gt;Start the project&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- tocstop --&gt; 
&lt;h1&gt;Quick start&lt;/h1&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;Only thing that you must have - installed docker. Please follow the original instruction &lt;a href="https://docs.docker.com/get-docker/" target="_blank" rel="noopener"&gt;how to install docker -&amp;gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you are ready - come back and follows the below steps to send the first text message to WhatsApp via HTTP API!&lt;/p&gt; 
&lt;h2&gt;Send your first message&lt;/h2&gt; 
&lt;p&gt;Let's go over steps that allow you to send your first text message via WhatsApp HTTP API!&lt;/p&gt; 
&lt;h3&gt;1. Download image&lt;/h3&gt; 
&lt;p&gt;Assuming you have installed &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;, let's download the image.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull devlikeapro/waha
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker login -u devlikeapro -p {KEY}
docker pull devlikeapro/waha-plus
docker logout
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about how to get &lt;code&gt;PASSWORD&lt;/code&gt; for &lt;a href="https://waha.devlike.pro/docs/how-to/waha-plus/"&gt;&lt;strong&gt;‚ûï WAHA Plus&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Run WhatsApp HTTP API&lt;/h3&gt; 
&lt;p&gt;Run WhatsApp HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --rm -p 3000:3000/tcp --name waha devlikeapro/waha

# It prints logs and the last line must be
# WhatsApp HTTP API is running on: http://[::1]:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open the link in your browser &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt; and you'll see API documentation (Swagger).&lt;/p&gt; 
&lt;h3&gt;3. Start a new session&lt;/h3&gt; 
&lt;p&gt;To start a new session you should have your mobile phone with installed WhatsApp application close to you.&lt;/p&gt; 
&lt;p&gt;Please go and read how what we'll need to a bit later: &lt;a href="https://faq.whatsapp.com/381777293328336/?helpref=hc_fnav" target="_blank"&gt; How to log in - the instruction on WhatsApp site &lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;When your ready - find &lt;code&gt;POST /api/sessions&lt;/code&gt;, click on &lt;strong&gt;Try it out&lt;/strong&gt;, then &lt;strong&gt;Execute&lt;/strong&gt; a bit below.&lt;/p&gt; 
&lt;p&gt;The example payload:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "default"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By using the request with &lt;code&gt;name&lt;/code&gt; values you can start multiple session (WhatsApp accounts) inside the single docker container in Plus&lt;/p&gt; 
&lt;h3&gt;4. Get and scan QR&lt;/h3&gt; 
&lt;p&gt;Find &lt;code&gt;GET /api/screenshot&lt;/code&gt; and execute it, it shows you QR code.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Scan the QR with your cell phone's WhatsApp app.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;5. Get the screenshot&lt;/h3&gt; 
&lt;p&gt;Execute &lt;code&gt;GET /api/screenshot&lt;/code&gt; after a few seconds after scanning the QR - it'll show you the screenshot of you Whatsapp instance. If you can get the actual screenshot - then you're ready to start sending messages!&lt;/p&gt; 
&lt;h3&gt;6. Send a text message&lt;/h3&gt; 
&lt;p&gt;Let's send a text message - find &lt;code&gt;POST /api/sendText&lt;/code&gt; in &lt;a href="http://localhost:3000/"&gt;swagger&lt;/a&gt; and change &lt;code&gt;chatId&lt;/code&gt; this way: use a phone international phone number without &lt;code&gt;+&lt;/code&gt; symbol and add &lt;code&gt;@c.us&lt;/code&gt; at the end.&lt;/p&gt; 
&lt;p&gt;For phone number &lt;code&gt;12132132131&lt;/code&gt; the &lt;code&gt;chatId&lt;/code&gt; is &lt;code&gt;12132132131@c.us&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The example payload:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "chatId": "12132132130@c.us",
  "text": "Hi there!",
  "session": "default"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also, you can use &lt;code&gt;curl&lt;/code&gt; and send POST request like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Phone without +
export PHONE=12132132130
curl -d "{\"chatId\": \"${PHONE}@c.us\", \"text\": \"Hello from WhatsApp HTTP API\" }" -H "Content-Type: application/json" -X POST http://localhost:3000/api/sendText
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What is next?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://waha.devlike.pro/docs/overview/introduction/"&gt;Go and read the full documentation!&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;h2&gt;Start the project&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
 &lt;li&gt;Make sure you're using node&amp;gt;=22 (check &lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/.nvmrc"&gt;.nvmrc&lt;/a&gt; to get the version)&lt;/li&gt; 
 &lt;li&gt;Run the following commands:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
yarn install
# Fetch and compile proto files
yarn gows:proto
# Run
yarn start
# open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>nuxt/nuxt</title>
      <link>https://github.com/nuxt/nuxt</link>
      <description>&lt;p&gt;The Intuitive Vue Framework.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://nuxt.com"&gt;&lt;img src="https://raw.githubusercontent.com/nuxt/nuxt/main/.github/assets/banner.svg?sanitize=true" alt="Nuxt banner"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Nuxt&lt;/h1&gt; 
&lt;p&gt; &lt;a href="https://www.npmjs.com/package/nuxt"&gt;&lt;img src="https://img.shields.io/npm/v/nuxt.svg?style=flat&amp;amp;colorA=18181B&amp;amp;colorB=28CF8D" alt="Version"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/nuxt"&gt;&lt;img src="https://img.shields.io/npm/dm/nuxt.svg?style=flat&amp;amp;colorA=18181B&amp;amp;colorB=28CF8D" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/nuxt/nuxt/tree/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/nuxt/nuxt.svg?style=flat&amp;amp;colorA=18181B&amp;amp;colorB=28CF8D" alt="License"&gt;&lt;/a&gt; &lt;a href="https://nuxt.com"&gt;&lt;img src="https://img.shields.io/badge/Nuxt%20Docs-18181B?logo=nuxt" alt="Website"&gt;&lt;/a&gt; &lt;a href="https://chat.nuxt.dev"&gt;&lt;img src="https://img.shields.io/badge/Nuxt%20Discord-18181B?logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/nuxt/nuxt/badge" alt="Nuxt openssf scorecard score"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Nuxt is a free and open-source framework with an intuitive and extendable way to create type-safe, performant and production-grade full-stack web applications and websites with Vue.js.&lt;/p&gt; 
&lt;p&gt;It provides a number of features that make it easy to build fast, SEO-friendly, and scalable web applications, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Server-side rendering, Static Site Generation, Hybrid Rendering and Edge-Side Rendering&lt;/li&gt; 
 &lt;li&gt;Automatic routing with code-splitting and pre-fetching&lt;/li&gt; 
 &lt;li&gt;Data fetching and state management&lt;/li&gt; 
 &lt;li&gt;SEO Optimization and Meta tags definition&lt;/li&gt; 
 &lt;li&gt;Auto imports of components, composables and utils&lt;/li&gt; 
 &lt;li&gt;TypeScript with zero configuration&lt;/li&gt; 
 &lt;li&gt;Go fullstack with our server/ directory&lt;/li&gt; 
 &lt;li&gt;Extensible with &lt;a href="https://nuxt.com/modules"&gt;200+ modules&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Deployment to a variety of &lt;a href="https://nuxt.com/deploy"&gt;hosting platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;...&lt;a href="https://nuxt.com"&gt;and much more&lt;/a&gt; üöÄ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Table of Contents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üíª &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#vue-development"&gt; Vue Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß© &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#modules"&gt;Modules&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ù§Ô∏è &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#contribute"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üè† &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#local-development"&gt;Local Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üõü &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#professional-support"&gt;Professional Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîó &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#follow-us"&gt;Follow Us&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚öñÔ∏è &lt;a href="https://raw.githubusercontent.com/nuxt/nuxt/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;&lt;a name="getting-started"&gt;üöÄ Getting Started&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Use the following command to create a new starter project. This will create a starter project with all the necessary files and dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm create nuxt@latest &amp;lt;my-project&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Discover also &lt;a href="https://nuxt.new"&gt;nuxt.new&lt;/a&gt;: Open a Nuxt starter on CodeSandbox, StackBlitz or locally to get up and running in a few seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a name="vue-development"&gt;üíª Vue Development&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Simple, intuitive and powerful, Nuxt lets you write Vue components in a way that makes sense. Every repetitive task is automated, so you can focus on writing your full-stack Vue application with confidence.&lt;/p&gt; 
&lt;p&gt;Example of an &lt;code&gt;app.vue&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-vue"&gt;&amp;lt;script setup lang="ts"&amp;gt;
useSeoMeta({
  title: 'Meet Nuxt',
  description: 'The Intuitive Vue Framework.'
})
&amp;lt;/script&amp;gt;

&amp;lt;template&amp;gt;
  &amp;lt;div id="app"&amp;gt;
    &amp;lt;AppHeader /&amp;gt;
    &amp;lt;NuxtPage /&amp;gt;
    &amp;lt;AppFooter /&amp;gt;
  &amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;

&amp;lt;style scoped&amp;gt;
#app {
  background-color: #020420;
  color: #00DC82;
}
&amp;lt;/style&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;a name="documentation"&gt;üìñ Documentation&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;We highly recommend you take a look at the &lt;a href="https://nuxt.com/docs"&gt;Nuxt documentation&lt;/a&gt; to level up. It‚Äôs a great resource for learning more about the framework. It covers everything from getting started to advanced topics.&lt;/p&gt; 
&lt;h2&gt;&lt;a name="modules"&gt;üß© Modules&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Discover our &lt;a href="https://nuxt.com/modules"&gt;list of modules&lt;/a&gt; to supercharge your Nuxt project, created by the Nuxt team and community.&lt;/p&gt; 
&lt;h2&gt;&lt;a name="contribute"&gt;‚ù§Ô∏è Contribute&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;We invite you to contribute and help improve Nuxt üíö&lt;/p&gt; 
&lt;p&gt;Here are a few ways you can get involved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reporting Bugs:&lt;/strong&gt; If you come across any bugs or issues, please check out the &lt;a href="https://nuxt.com/docs/community/reporting-bugs"&gt;reporting bugs guide&lt;/a&gt; to learn how to submit a bug report.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Suggestions:&lt;/strong&gt; Have ideas to enhance Nuxt? We'd love to hear them! Check out the &lt;a href="https://nuxt.com/docs/community/contribution"&gt;contribution guide&lt;/a&gt; to share your suggestions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Questions:&lt;/strong&gt; If you have questions or need assistance, the &lt;a href="https://nuxt.com/docs/community/getting-help"&gt;getting help guide&lt;/a&gt; provides resources to help you out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a name="local-development"&gt;üè† Local Development&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Follow the docs to &lt;a href="https://nuxt.com/docs/community/framework-contribution#setup"&gt;Set Up Your Local Development Environment&lt;/a&gt; to contribute to the framework and documentation.&lt;/p&gt; 
&lt;h2&gt;&lt;a name="professional-support"&gt;üõü Professional Support&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Technical audit &amp;amp; consulting: &lt;a href="https://nuxt.com/enterprise/support"&gt;Nuxt Experts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Custom development &amp;amp; more: &lt;a href="https://nuxt.com/enterprise/agencies"&gt;Nuxt Agencies Partners&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a name="follow-us"&gt;üîó Follow Us&lt;/a&gt;&lt;/h2&gt; 
&lt;p valign="center"&gt; &lt;a href="https://go.nuxt.com/discord"&gt;&lt;img width="20px" src="https://raw.githubusercontent.com/nuxt/nuxt/main/.github/assets/discord.svg?sanitize=true" alt="Discord"&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://go.nuxt.com/x"&gt;&lt;img width="20px" src="https://raw.githubusercontent.com/nuxt/nuxt/main/.github/assets/twitter.svg?sanitize=true" alt="Twitter"&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://go.nuxt.com/github"&gt;&lt;img width="20px" src="https://raw.githubusercontent.com/nuxt/nuxt/main/.github/assets/github.svg?sanitize=true" alt="GitHub"&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://go.nuxt.com/bluesky"&gt;&lt;img width="20px" src="https://raw.githubusercontent.com/nuxt/nuxt/main/.github/assets/bluesky.svg?sanitize=true" alt="Bluesky"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;&lt;a name="license"&gt;‚öñÔ∏è License&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/nuxt/nuxt/tree/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/workers-oauth-provider</title>
      <link>https://github.com/cloudflare/workers-oauth-provider</link>
      <description>&lt;p&gt;OAuth provider library for Cloudflare Workers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OAuth 2.1 Provider Framework for Cloudflare Workers&lt;/h1&gt; 
&lt;p&gt;This is a TypeScript library that implements the provider side of the OAuth 2.1 protocol with PKCE support. The library is intended to be used on Cloudflare Workers.&lt;/p&gt; 
&lt;h2&gt;Benefits of this library&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The library acts as a wrapper around your Worker code, which adds authorization for your API endpoints.&lt;/li&gt; 
 &lt;li&gt;All token management is handled automatically.&lt;/li&gt; 
 &lt;li&gt;Your API handler is written like a regular fetch handler, but receives the already-authenticated user details as a parameter. No need to perform any checks of your own.&lt;/li&gt; 
 &lt;li&gt;The library is agnostic to how you manage and authenticate users.&lt;/li&gt; 
 &lt;li&gt;The library is agnostic to how you build your UI. Your authorization flow can be implemented using whatever UI framework you use for everything else.&lt;/li&gt; 
 &lt;li&gt;The library's storage does not store any secrets, only hashes of them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;A Worker that uses the library might look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { OAuthProvider } from "@cloudflare/workers-oauth-provider";
import { WorkerEntrypoint } from "cloudflare:workers";

// We export the OAuthProvider instance as the entrypoint to our Worker. This means it
// implements the `fetch()` handler, receiving all HTTP requests.
export default new OAuthProvider({
  // Configure API routes. Any requests whose URL starts with any of these prefixes will be
  // considered API requests. The OAuth provider will check the access token on these requests,
  // and then, if the token is valid, send the request to the API handler.
  // You can provide:
  // - A single route (string) or multiple routes (array)
  // - Full URLs (which will match the hostname) or just paths (which will match any hostname)
  apiRoute: [
    "/api/", // Path only - will match any hostname
    "https://api.example.com/" // Full URL - will check hostname
  ],

  // When the OAuth system receives an API request with a valid access token, it passes the request
  // to this handler object's fetch method.
  // You can provide either an object with a fetch method (ExportedHandler)
  // or a class extending WorkerEntrypoint.
  apiHandler: ApiHandler, // Using a WorkerEntrypoint class
  
  // For multi-handler setups, you can use apiHandlers instead of apiRoute+apiHandler.
  // This allows you to use different handlers for different API routes.
  // Note: You must use either apiRoute+apiHandler (single-handler) OR apiHandlers (multi-handler), not both.
  // Example:
  // apiHandlers: {
  //   "/api/users/": UsersApiHandler,
  //   "/api/documents/": DocumentsApiHandler,
  //   "https://api.example.com/": ExternalApiHandler,
  // },

  // Any requests which aren't API request will be passed to the default handler instead.
  // Again, this can be either an object or a WorkerEntrypoint.
  defaultHandler: defaultHandler, // Using an object with a fetch method

  // This specifies the URL of the OAuth authorization flow UI. This UI is NOT implemented by
  // the OAuthProvider. It is up to the application to implement a UI here. The only reason why
  // this URL is given to the OAuthProvider is so that it can implement the RFC-8414 metadata
  // discovery endpoint, i.e. `.well-known/oauth-authorization-server`.
  // Can also be specified as just a path (e.g., "/authorize").
  authorizeEndpoint: "https://example.com/authorize",

  // This specifies the OAuth 2 token exchange endpoint. The OAuthProvider will implement this
  // endpoint (by directly responding to requests with a matching URL).
  // Can also be specified as just a path (e.g., "/oauth/token").
  tokenEndpoint: "https://example.com/oauth/token",

  // This specifies the RFC-7591 dynamic client registration endpoint. This setting is optional,
  // but if provided, the OAuthProvider will implement this endpoint to allow dynamic client
  // registration.
  // Can also be specified as just a path (e.g., "/oauth/register").
  clientRegistrationEndpoint: "https://example.com/oauth/register",

  // Optional list of scopes supported by this OAuth provider.
  // If provided, this will be included in the RFC 8414 metadata as 'scopes_supported'.
  // If not provided, the 'scopes_supported' field will be omitted from the metadata.
  scopesSupported: ["document.read", "document.write", "profile"],

  // Optional: Controls whether the OAuth implicit flow is allowed.
  // The implicit flow is discouraged in OAuth 2.1 but may be needed for some clients.
  // Defaults to false.
  allowImplicitFlow: false,

  // Optional: Controls whether public clients (clients without a secret, like SPAs)
  // can register via the dynamic client registration endpoint.
  // When true, only confidential clients can register.
  // Note: Creating public clients via the OAuthHelpers.createClient() method
  // is always allowed regardless of this setting.
  // Defaults to false.
  disallowPublicClientRegistration: false
});

// The default handler object - the OAuthProvider will pass through HTTP requests to this object's fetch method
// if they aren't API requests or do not have a valid access token
const defaultHandler = {
  // This fetch method works just like a standard Cloudflare Workers fetch handler
  //
  // The `request`, `env`, and `ctx` parameters are the same as for a normal Cloudflare Workers fetch
  // handler, and are exactly the objects that the `OAuthProvider` itself received from the Workers
  // runtime.
  //
  // The `env.OAUTH_PROVIDER` provides an API by which the application can call back to the
  // OAuthProvider.
  async fetch(request: Request, env, ctx) {
    let url = new URL(request.url);

    if (url.pathname == "/authorize") {
      // This is a request for our OAuth authorization flow UI. It is up to the application to
      // implement this. However, the OAuthProvider library provides some helpers to assist.

      // `env.OAUTH_PROVIDER.parseAuthRequest()` parses the OAuth authorization request to extract the parameters
      // required by the OAuth 2 standard, namely response_type, client_id, redirect_uri, scope, and
      // state. It returns an object containing all these (using idiomatic camelCase naming).
      let oauthReqInfo = await env.OAUTH_PROVIDER.parseAuthRequest(request);

      // `env.OAUTH_PROVIDER.lookupClient()` looks up metadata about the client, as definetd by RFC-7591. This
      // includes things like redirect_uris, client_name, logo_uri, etc.
      let clientInfo = await env.OAUTH_PROVIDER.lookupClient(oauthReqInfo.clientId);

      // At this point, the application should use `oauthReqInfo` and `clientInfo` to render an
      // authorization consent UI to the user. The details of this are up to the app so are not
      // shown here.

      // After the user has granted consent, the application calls `env.OAUTH_PROVIDER.completeAuthorization()` to
      // grant the authorization.
      let {redirectTo} = await env.OAUTH_PROVIDER.completeAuthorization({
        // The application passes back the original OAuth request info that was returned by
        // `parseAuthRequest()` earlier.
        request: oauthReqInfo,

        // The application must specify the user's ID, which is some sort of string. This is needed
        // so that the application can later query the OAuthProvider to enumerate all grants
        // belonging to a particular user, e.g. to implement an audit and revocation UI.
        userId: "1234",

        // The application can specify some arbitary metadata which describes this grant. The
        // metadata can contain any JSON-serializable content. This metadata is not used by the
        // OAuthProvider, but the application can read back the metadata attached to specific
        // grants when enumerating them later, again e.g. to implement an udit and revocation UI.
        metadata: {label: "foo"},

        // The application specifies the list of OAuth scope identifiers that were granted. This
        // may or may not be the same as was requested in `oauthReqInfo.scope`.
        scope: ["document.read", "document.write"],

        // `props` is an arbitrary JSON-serializable object which will be passed back to the API
        // handler for every request authorized by this grant.
        props: {
          userId: 1234,
          username: "Bob"
        }
      });

      // `completeAuthorization()` will have returned the URL to which the user should be redirected
      // in order to complete the authorization flow. This is the requesting client's OAuth
      // redirect_uri with the appropriate query parameters added to complete the flow and obtain
      // tokens.
      return Response.redirect(redirectTo, 302);
    }

    // ... the application can implement other non-API HTTP endpoints here ...

    return new Response("Not found", {status: 404});
  }
};

// The API handler object - the OAuthProivder will pass authorized API requests to this object's fetch method
// (because we provided it as the `apiHandler` setting, above). This is ONLY called for API requests
// that had a valid access token.
class ApiHandler extends WorkerEntrypoint {
  // This fetch method works just like any other WorkerEntrypoint fetch method. The `request` is
  // passed as a parameter, while `env` and `ctx` are available as `this.env` and `this.ctx`.
  //
  // The `this.env.OAUTH_PROVIDER` is available just like in the default handler.
  //
  // The `this.ctx.props` property contains the `props` value that was passed to
  // `env.OAUTH_PROVIDER.completeAuthorization()` during the authorization flow that authorized this client.
  fetch(request: Request) {
    // The application can implement its API endpoints like normal. This app implements a single
    // endpoint, `/api/whoami`, which returns the user's authenticated identity.

    let url = new URL(request.url);
    if (url.pathname == "/api/whoami") {
      // Since the username is embedded in `ctx.props`, which came from the access token that the
      // OAuthProivder already verified, we don't need to do any other authentication steps.
      return new Response(`You are authenticated as: ${this.ctx.props.username}`);
    }

    return new Response("Not found", {status: 404});
  }
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This implementation requires that your worker is configured with a Workers KV namespace binding called &lt;code&gt;OAUTH_KV&lt;/code&gt;, which is used to store token information. See the file &lt;code&gt;storage-schema.md&lt;/code&gt; for details on the schema of this namespace.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;env.OAUTH_PROVIDER&lt;/code&gt; object available to the fetch handlers provides some methods to query the storage, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create, list, modify, and delete client_id registrations (in addition to &lt;code&gt;lookupClient()&lt;/code&gt;, already shown in the example code).&lt;/li&gt; 
 &lt;li&gt;List all active authorization grants for a particular user.&lt;/li&gt; 
 &lt;li&gt;Revoke (delete) an authorization grant.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;code&gt;OAuthHelpers&lt;/code&gt; interface definition for full API details.&lt;/p&gt; 
&lt;h2&gt;Token Exchange Callback&lt;/h2&gt; 
&lt;p&gt;This library allows you to update the &lt;code&gt;props&lt;/code&gt; value during token exchanges by configuring a callback function. This is useful for scenarios where the application needs to perform additional processing when tokens are issued or refreshed.&lt;/p&gt; 
&lt;p&gt;For example, if your application is also a client to some other OAuth API, you might want to perform an equivalent upstream token exchange and store the result in the &lt;code&gt;props&lt;/code&gt;. The callback can be used to update the props for both the grant record and specific access tokens.&lt;/p&gt; 
&lt;p&gt;To use this feature, provide a &lt;code&gt;tokenExchangeCallback&lt;/code&gt; in your OAuthProvider options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;new OAuthProvider({
  // ... other options ...
  tokenExchangeCallback: async (options) =&amp;gt; {
    // options.grantType is either 'authorization_code' or 'refresh_token'
    // options.props contains the current props
    // options.clientId, options.userId, and options.scope are also available

    if (options.grantType === 'authorization_code') {
      // For authorization code exchange, might want to obtain upstream tokens
      const upstreamTokens = await exchangeUpstreamToken(options.props.someCode);

      return {
        // Update the props stored in the access token
        accessTokenProps: {
          ...options.props,
          upstreamAccessToken: upstreamTokens.access_token
        },
        // Update the props stored in the grant (for future token refreshes)
        newProps: {
          ...options.props,
          upstreamRefreshToken: upstreamTokens.refresh_token
        }
      };
    }

    if (options.grantType === 'refresh_token') {
      // For refresh token exchanges, might want to refresh upstream tokens too
      const upstreamTokens = await refreshUpstreamToken(options.props.upstreamRefreshToken);

      return {
        accessTokenProps: {
          ...options.props,
          upstreamAccessToken: upstreamTokens.access_token
        },
        newProps: {
          ...options.props,
          upstreamRefreshToken: upstreamTokens.refresh_token || options.props.upstreamRefreshToken
        },
        // Optionally override the default access token TTL to match the upstream token
        accessTokenTTL: upstreamTokens.expires_in
      };
    }
  }
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The callback can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Return both &lt;code&gt;accessTokenProps&lt;/code&gt; and &lt;code&gt;newProps&lt;/code&gt; to update both&lt;/li&gt; 
 &lt;li&gt;Return only &lt;code&gt;accessTokenProps&lt;/code&gt; to update just the current access token&lt;/li&gt; 
 &lt;li&gt;Return only &lt;code&gt;newProps&lt;/code&gt; to update both the grant and access token (the access token inherits these props)&lt;/li&gt; 
 &lt;li&gt;Return &lt;code&gt;accessTokenTTL&lt;/code&gt; to override the default TTL for this specific access token&lt;/li&gt; 
 &lt;li&gt;Return nothing to keep the original props unchanged&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;accessTokenTTL&lt;/code&gt; override is particularly useful when the application is also an OAuth client to another service and wants to match its access token TTL to the upstream access token TTL. This helps prevent situations where the downstream token is still valid but the upstream token has expired.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;props&lt;/code&gt; values are end-to-end encrypted, so they can safely contain sensitive information.&lt;/p&gt; 
&lt;h2&gt;Custom Error Responses&lt;/h2&gt; 
&lt;p&gt;By using the &lt;code&gt;onError&lt;/code&gt; option, you can emit notifications or take other actions when an error response was to be emitted:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;new OAuthProvider({
  // ... other options ...
  onError({ code, description, status, headers }) {
    Sentry.captureMessage(/* ... */)
  }
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By returning a &lt;code&gt;Response&lt;/code&gt; you can also override what the OAuthProvider returns to your users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;new OAuthProvider({
  // ... other options ...
  onError({ code, description, status, headers }) {
    if (code === 'unsupported_grant_type') {
      return new Response('...', { status, headers })
    }
    // returning undefined (i.e. void) uses the default Response generation
  }
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, the &lt;code&gt;onError&lt;/code&gt; callback is set to &lt;code&gt;({ status, code, description }) =&amp;gt; console.warn(`OAuth error response: ${status} ${code} - ${description}`)&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Implementation Notes&lt;/h2&gt; 
&lt;h3&gt;End-to-end encryption&lt;/h3&gt; 
&lt;p&gt;This library stores records about authorization tokens in KV. The storage schema is carefully designed such that a complete leak of the storage only reveals mundane metadata about what has been granted. In particular:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Secrets (including access tokens, refresh tokens, authorization codes, and client secrets) are stored only by hash. Hence, such secrets cannot be derived from the storage alone.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;props&lt;/code&gt; associated with a grant (which are passed back to the application when API requests are performed) are stored encrypted with the secret token as key material. Hence, the contents of &lt;code&gt;props&lt;/code&gt; are impossible to derive from storage unless a valid token is provided.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that the &lt;code&gt;userId&lt;/code&gt; and the &lt;code&gt;metadata&lt;/code&gt; associated with each grant are not encrypted, because the purpose of these values is to allow grants to be enumerated for audit and revocation purposes. However, these values are completely opaque to the library. An application is free to omit them or apply its own encryption to them before passing them into the library, if it desires.&lt;/p&gt; 
&lt;h3&gt;Single-use refresh tokens?&lt;/h3&gt; 
&lt;p&gt;OAuth 2.1 requires that refresh tokens are either "cryptographically bound" to the client, or are single-use. This library currently does not implement any cryptographic binding, thus seemingly requiring single-use tokens. Under this requirement, every token refresh request invalidates the old refresh token and issues a new one.&lt;/p&gt; 
&lt;p&gt;This requirement is seemingly fundamentally flawed as it assumes that every refresh request will complete with no errors. In the real world, a transient network error, machine failure, or software fault could mean that the client fails to store the new refresh token after a refresh request. In this case, the client would be permanently unable to make any further requests, as the only token it has is no longer valid.&lt;/p&gt; 
&lt;p&gt;This library implements a compromise: At any particular time, a grant may have two valid refresh tokens. When the client uses one of them, the other one is invalidated, and a new one is generated and returned. Thus, if the client correctly uses the new refresh token each time, then older refresh tokens are continuously invalidated. But if a transient failure prevents the client from updating its token, it can always retry the request with the token it used previously.&lt;/p&gt; 
&lt;h2&gt;Written using Claude&lt;/h2&gt; 
&lt;p&gt;This library (including the schema documentation) was largely written with the help of &lt;a href="https://claude.ai"&gt;Claude&lt;/a&gt;, the AI model by Anthropic. Claude's output was thoroughly reviewed by Cloudflare engineers with careful attention paid to security and compliance with standards. Many improvements were made on the initial output, mostly again by prompting Claude (and reviewing the results). Check out the commit history to see how Claude was prompted and what code it produced.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;"NOOOOOOOO!!!! You can't just use an LLM to write an auth library!"&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;"haha gpus go brrr"&lt;/p&gt; 
&lt;p&gt;In all seriousness, two months ago (January 2025), I (&lt;a href="https://github.com/kentonv"&gt;@kentonv&lt;/a&gt;) would have agreed. I was an AI skeptic. I thought LLMs were glorified Markov chain generators that didn't actually understand code and couldn't produce anything novel. I started this project on a lark, fully expecting the AI to produce terrible code for me to laugh at. And then, uh... the code actually looked pretty good. Not perfect, but I just told the AI to fix things, and it did. I was shocked.&lt;/p&gt; 
&lt;p&gt;To emphasize, &lt;strong&gt;this is not "vibe coded"&lt;/strong&gt;. Every line was thoroughly reviewed and cross-referenced with relevant RFCs, by security experts with previous experience with those RFCs. I was &lt;em&gt;trying&lt;/em&gt; to validate my skepticism. I ended up proving myself wrong.&lt;/p&gt; 
&lt;p&gt;Again, please check out the commit history -- especially early commits -- to understand how this went.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dyad-sh/dyad</title>
      <link>https://github.com/dyad-sh/dyad</link>
      <description>&lt;p&gt;Free, local, open-source AI app builder ‚ú® v0 / lovable / Bolt alternative üåü Star if you like it!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dyad&lt;/h1&gt; 
&lt;p&gt;Dyad is a local, open-source AI app builder. It's fast, private, and fully under your control ‚Äî like Lovable, v0, or Bolt, but running right on your machine.&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://dyad.sh/"&gt;&lt;img src="https://github.com/user-attachments/assets/f6c83dfc-6ffd-4d32-93dd-4b9c46d17790" alt="Image"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;More info at: &lt;a href="http://dyad.sh/"&gt;http://dyad.sh/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;strong&gt;Local&lt;/strong&gt;: Fast, private and no lock-in.&lt;/li&gt; 
 &lt;li&gt;üõ† &lt;strong&gt;Bring your own keys&lt;/strong&gt;: Use your own AI API keys ‚Äî no vendor lock-in.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Cross-platform&lt;/strong&gt;: Easy to run on Mac or Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Download&lt;/h2&gt; 
&lt;p&gt;No sign-up required. Just download and go.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://www.dyad.sh/#download"&gt;üëâ Download for your platform&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Dyad&lt;/strong&gt; is open-source (Apache 2.0 licensed).&lt;/p&gt; 
&lt;p&gt;If you're interested in contributing to dyad, please read our &lt;a href="https://raw.githubusercontent.com/dyad-sh/dyad/main/CONTRIBUTING.md"&gt;contributing&lt;/a&gt; doc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>browserbase/stagehand</title>
      <link>https://github.com/browserbase/stagehand</link>
      <description>&lt;p&gt;The AI Browser Automation Framework&lt;/p&gt;&lt;hr&gt;&lt;div id="toc" align="center" style="margin-bottom: 0;"&gt; 
 &lt;ul style="list-style: none; margin: 0; padding: 0;"&gt; 
  &lt;a href="https://stagehand.dev"&gt; 
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_logo.png"&gt; 
    &lt;img alt="Stagehand" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_logo.png" width="200" style="margin-right: 30px;"&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt;The AI Browser Automation Framework&lt;/strong&gt;&lt;br&gt; &lt;a href="https://docs.stagehand.dev"&gt;Read the Docs&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/browserbase/stagehand/tree/main?tab=MIT-1-ov-file#MIT-1-ov-file"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_license.svg"&gt; 
   &lt;img alt="MIT License" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_license.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="media/dark_slack.svg"&gt; 
   &lt;img alt="Slack Community" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/light_slack.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/12122" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12122" alt="browserbase%2Fstagehand | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; If you're looking for the Python implementation, you can find it &lt;a href="https://github.com/browserbase/stagehand-python"&gt; here&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center" style="display: flex; align-items: center; justify-content: center; gap: 4px; margin-bottom: 0;"&gt; 
 &lt;b&gt;Vibe code&lt;/b&gt; 
 &lt;span style="font-size: 1.05em;"&gt; Stagehand with &lt;/span&gt; 
 &lt;a href="https://director.ai" style="display: flex; align-items: center;"&gt; &lt;span&gt;Director&lt;/span&gt; &lt;/a&gt; 
 &lt;span&gt; &lt;/span&gt; 
 &lt;picture&gt; 
  &lt;img alt="Director" src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/director_icon.svg?sanitize=true" width="25"&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;h2&gt;Why Stagehand?&lt;/h2&gt; 
&lt;p&gt;Most existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Choose when to write code vs. natural language&lt;/strong&gt;: use AI when you want to navigate unfamiliar pages, and use code (&lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;) when you know exactly what you want to do.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preview and cache actions&lt;/strong&gt;: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Computer use models with one line of code&lt;/strong&gt;: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;Here's how to build a sample browser automation with Stagehand:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="max-width:300px;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/browserbase/stagehand/main/media/github_demo.gif" alt="See Stagehand in Action"&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Use Playwright functions on the page object
const page = stagehand.page;
await page.goto("https://github.com/browserbase");

// Use act() to execute individual actions
await page.act("click on the stagehand repo");

// Use Computer Use agents for larger actions
const agent = stagehand.agent({
    provider: "openai",
    model: "computer-use-preview",
});
await agent.execute("Get to the latest PR");

// Use extract() to read data from the page
const { author, title } = await page.extract({
  instruction: "extract the author and title of the PR",
  schema: z.object({
    author: z.string().describe("The username of the PR author"),
    title: z.string().describe("The title of the PR"),
  }),
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://docs.stagehand.dev"&gt;docs.stagehand.dev&lt;/a&gt; to view the full documentation.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Start with Stagehand with one line of code, or check out our &lt;a href="https://docs.stagehand.dev/get_started/quickstart"&gt;Quickstart Guide&lt;/a&gt; for more information:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx create-browser-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;p&gt;Watch Anirudh demo create-browser-app to create a Stagehand project!&lt;/p&gt; &lt;/a&gt; 
 &lt;a href="https://www.loom.com/share/f5107f86d8c94fa0a8b4b1e89740f7a7"&gt; &lt;img style="max-width:300px;" src="https://cdn.loom.com/sessions/thumbnails/f5107f86d8c94fa0a8b4b1e89740f7a7-ec3f428b6775ceeb-full-play.gif"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Build and Run from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/browserbase/stagehand.git
cd stagehand
pnpm install
pnpm playwright install
pnpm run build
pnpm run example # run the blank script at ./examples/example.ts
pnpm run example 2048 # run the 2048 example at ./examples/2048.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Stagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
nano .env # Edit the .env file to add API keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;br&gt; We highly value contributions to Stagehand! For questions or support, please join our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;At a high level, we're focused on improving reliability, speed, and cost in that order of priority. If you're interested in contributing, we strongly recommend reaching out to &lt;a href="https://x.com/miguel_gonzf"&gt;Miguel Gonzalez&lt;/a&gt; or &lt;a href="https://x.com/pk_iv"&gt;Paul Klein&lt;/a&gt; in our &lt;a href="https://join.slack.com/t/stagehand-dev/shared_invite/zt-38khc8iv5-T2acb50_0OILUaX7lxeBOg"&gt;Slack community&lt;/a&gt; before starting to ensure that your contribution aligns with our goals.&lt;/p&gt; 
&lt;p&gt;For more information, please see our &lt;a href="https://docs.stagehand.dev/examples/contributing"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project heavily relies on &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt; as a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by &lt;a href="https://github.com/reworkd/tarsier"&gt;tarsier&lt;/a&gt;, &lt;a href="https://github.com/jbeoris/gemini-zod"&gt;gemini-zod&lt;/a&gt;, and &lt;a href="https://github.com/normal-computing/fuji-web"&gt;fuji-web&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We'd like to thank the following people for their major contributions to Stagehand:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pkiv"&gt;Paul Klein&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kamath"&gt;Anirudh Kamath&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seanmcguire12"&gt;Sean McGuire&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/miguelg719"&gt;Miguel Gonzalez&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sameelarif"&gt;Sameel Arif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/filip-michalsky"&gt;Filip Michalsky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/jeremypress"&gt;Jeremy Press&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/navidpour"&gt;Navid Pour&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the MIT License.&lt;/p&gt; 
&lt;p&gt;Copyright 2025 Browserbase, Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mui/material-ui</title>
      <link>https://github.com/mui/material-ui</link>
      <description>&lt;p&gt;Material UI: Comprehensive React component library that implements Google's Material Design. Free forever.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://mui.com/core/" rel="noopener" target="_blank"&gt;&lt;img width="150" height="133" src="https://mui.com/static/logo.svg?sanitize=true" alt="Material&amp;nbsp;UI logo"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Material&amp;nbsp;UI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/mui/material-ui/raw/HEAD/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="license"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@mui/material"&gt;&lt;img src="https://img.shields.io/npm/v/@mui/material/latest.svg?sanitize=true" alt="npm latest package"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@mui/material"&gt;&lt;img src="https://img.shields.io/npm/v/@mui/material/next.svg?sanitize=true" alt="npm next package"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@mui/material"&gt;&lt;img src="https://img.shields.io/npm/dm/@mui/material.svg?sanitize=true" alt="npm downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/mui/material-ui/commits/HEAD/"&gt;&lt;img src="https://img.shields.io/github/checks-status/mui/material-ui/HEAD" alt="GitHub branch status"&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/mui/material-ui/"&gt;&lt;img src="https://img.shields.io/codecov/c/github/mui/material-ui.svg?sanitize=true" alt="Coverage Status"&gt;&lt;/a&gt; &lt;a href="https://x.com/MaterialUI"&gt;&lt;img src="https://img.shields.io/twitter/follow/MaterialUI.svg?label=follow+Material+UI" alt="Follow on X"&gt;&lt;/a&gt; &lt;a href="https://github.com/mui/material-ui/issues/27062"&gt;&lt;img src="https://img.shields.io/badge/renovate-enabled-brightgreen.svg?sanitize=true" alt="Renovate status"&gt;&lt;/a&gt; &lt;a href="https://isitmaintained.com/project/mui/material-ui" title="Average time to resolve an issue"&gt;&lt;img src="https://isitmaintained.com/badge/resolution/mui/material-ui.svg?sanitize=true" alt="Average time to resolve an issue"&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/mui-org"&gt;&lt;img src="https://img.shields.io/opencollective/all/mui-org" alt="Open&amp;nbsp;Collective backers and sponsors"&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/1320"&gt;&lt;img src="https://www.bestpractices.dev/projects/1320/badge" alt="OpenSSF Best Practices"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://mui.com/material-ui/"&gt;Material&amp;nbsp;UI&lt;/a&gt; is a comprehensive library of React components that features our independent implementation of Google's &lt;a href="https://m2.material.io/design/introduction/"&gt;Material Design&lt;/a&gt; system. It's trusted by some of the world's greatest product teams because it's been rigorously battle-tested through more than a decade of development by thousands of open-source contributors.&lt;/p&gt; 
&lt;p&gt;Material&amp;nbsp;UI's core functionality is extended by &lt;a href="https://github.com/mui/mui-x"&gt;MUI&amp;nbsp;X&lt;/a&gt;, a suite of complex components for advanced use cases. &lt;a href="https://github.com/mui/toolpad"&gt;Toolpad&lt;/a&gt; builds on top of Material&amp;nbsp;UI to provide full-stack components and a low-code internal tool builder.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Get started in the &lt;a href="https://mui.com/material-ui/getting-started/"&gt;Material&amp;nbsp;UI documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Older versions&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://v5.mui.com/"&gt;v5.x&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://mui.com/material-ui/migration/upgrade-to-v6/"&gt;Upgrading from v5 to v6&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://v4.mui.com/"&gt;v4.x&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://mui.com/material-ui/migration/migration-v4/"&gt;Upgrading from v4 to v5&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://v3.mui.com/"&gt;v3.x&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://mui.com/material-ui/migration/migration-v3/"&gt;Upgrading from v3 to v4&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://v0.mui.com/"&gt;v0.x&lt;/a&gt;&lt;/strong&gt; (&lt;a href="https://mui.com/material-ui/migration/migration-v0x/"&gt;Upgrading to v1&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;code&gt;@next&lt;/code&gt; points to pre-releases. Use &lt;code&gt;@latest&lt;/code&gt; for the latest stable release.&lt;/p&gt; 
&lt;h2&gt;Joy UI&lt;/h2&gt; 
&lt;p&gt;This repository also contains Joy UI, an experimental component library that implements our own in-house Joy Design. Joy UI is in beta and &lt;em&gt;development is currently on hold&lt;/em&gt;. When starting a new project from scratch, we recommend Material&amp;nbsp;UI over Joy UI because we can guarantee ongoing support.&lt;/p&gt; 
&lt;p&gt;Keep in mind that the maintainers are primarily focused on other projects and may not be able to respond in a timely manner to issues or pull requests related to Joy UI.&lt;/p&gt; 
&lt;p&gt;View the &lt;a href="https://mui.com/joy-ui/getting-started/"&gt;Joy UI documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;Diamond üíé&lt;/h3&gt; 
&lt;p&gt; &lt;a href="https://www.doit.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="128" width="128" src="https://mui.com/static/sponsors/doit-square.svg?sanitize=true" alt="doit" title="Management Platform for Google Cloud and AWS" loading="lazy"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Diamond sponsors are those who have pledged $1,500/month or more to MUI.&lt;/p&gt; 
&lt;h3&gt;Gold üèÜ&lt;/h3&gt; 
&lt;p&gt;via &lt;a href="https://opencollective.com/mui-org"&gt;Open&amp;nbsp;Collective&lt;/a&gt; or via &lt;a href="https://www.patreon.com/oliviertassinari"&gt;Patreon&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt; &lt;a href="https://tidelift.com/?utm_source=npm-material-ui&amp;amp;utm_medium=referral&amp;amp;utm_campaign=homepage" rel="noopener sponsored" target="_blank"&gt;&lt;img height="96" width="96" src="https://avatars.githubusercontent.com/u/30204434?s=288" alt="tidelift.com" title="Tidelift: Enterprise-ready open-source software." loading="lazy"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.text-em-all.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1262264?s=288" alt="text-em-all.com" title="Text-em-all: Mass text messaging and automated calling." height="96" width="96" loading="lazy"&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.dialmycalls.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="96" width="96" src="https://images.opencollective.com/dialmycalls/f5ae9ab/avatar/288.png" alt="dialmycalls.com" title="DialMyCalls: Send text messages, calls, and emails." loading="lazy"&gt;&lt;/a&gt; &amp;nbsp; &lt;/p&gt; 
&lt;p&gt; &lt;a href="https://goread.io/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="23" src="https://images.opencollective.com/goread_io/eb6337d/logo/78.png" alt="goread.io" title="Goread.io: Instagram followers, likes, views, and comments." loading="lazy"&gt;Goread.io&lt;/a&gt; &amp;nbsp; &lt;a href="https://buzzoid.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="26" src="https://images.opencollective.com/buzzoidz/d23d9bb/logo/78.png" alt="buzzoid.com" title="Buzzoid: Instant delivery Instagram followers." loading="lazy"&gt;Buzzoid&lt;/a&gt; &amp;nbsp; &lt;a href="https://twicsy.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="30" src="https://images.opencollective.com/twicsy/7af290f/logo/78.png" alt="twicsy.com" title="Twicsy: Instant delivery Instagram followers." loading="lazy"&gt;Twicsy&lt;/a&gt; &amp;nbsp; &lt;a href="https://views4you.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="26" src="https://images.opencollective.com/buy-instagram-followers-v4y/6364714/logo/78.png" alt="views4you.com" title="Views4you: Social media growth services." loading="lazy"&gt;Views4You&lt;/a&gt; &amp;nbsp; &lt;a href="https://poprey.com/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="26" src="https://images.opencollective.com/instagram-likes/2a72a03/logo/78.png" alt="poprey.com" title="Poprey: Buy Instagram likes with crypto." loading="lazy"&gt;Poprey&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.socialwick.com/instagram/followers/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="26" src="https://images.opencollective.com/instagram-followers-socialwick/ac6033a/logo/256.png" alt="socialwick.com/instagram/followers" title="SocialWick: Buy Instagram followers." loading="lazy"&gt;SocialWick&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.follower24.de/?utm_source=mui.com&amp;amp;utm_medium=referral&amp;amp;utm_content=readme" rel="noopener sponsored" target="_blank"&gt;&lt;img height="26" width="26" src="https://mui.com/static/sponsors/follower24-square.svg?sanitize=true" alt="follower24.de" title="Follower24: Social media success." loading="lazy"&gt;Follower24&lt;/a&gt; &amp;nbsp; &lt;/p&gt; 
&lt;p&gt;Gold sponsors are those who have pledged $500/month or more to MUI.&lt;/p&gt; 
&lt;h3&gt;More backers&lt;/h3&gt; 
&lt;p&gt;See the full list of &lt;a href="https://mui.com/material-ui/discover-more/backers/"&gt;our backers&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Questions&lt;/h2&gt; 
&lt;p&gt;For how-to questions that don't involve making changes to the code base, please use &lt;a href="https://stackoverflow.com/questions/"&gt;Stack&amp;nbsp;Overflow&lt;/a&gt; instead of GitHub issues.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;!-- #target-branch-reference --&gt; 
&lt;p&gt;Our documentation features &lt;a href="https://github.com/mui/material-ui/tree/master/examples"&gt;a collection of example projects&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Premium templates&lt;/h2&gt; 
&lt;p&gt;You can find complete templates and themes in the &lt;a href="https://mui.com/store/?utm_source=docs&amp;amp;utm_medium=referral&amp;amp;utm_campaign=readme-store"&gt;MUI&amp;nbsp;Store&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/mui/material-ui/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.&lt;/p&gt; 
&lt;p&gt;Contributing is about more than just issues and pull requests! There are many other ways to &lt;a href="https://mui.com/material-ui/getting-started/faq/#mui-is-an-awesome-organization-how-can-i-support-it"&gt;support Material&amp;nbsp;UI&lt;/a&gt; beyond contributing to the code base.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/mui/material-ui/releases"&gt;changelog&lt;/a&gt; is regularly updated to reflect what's changed in each new release.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Future plans and high-priority features and enhancements can be found in the &lt;a href="https://mui.com/material-ui/discover-more/roadmap/"&gt;roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the terms of the &lt;a href="https://raw.githubusercontent.com/mui/material-ui/master/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;For details on supported versions and contact information for reporting security issues, please refer to the &lt;a href="https://github.com/mui/material-ui/security/policy"&gt;security policy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsoring services&lt;/h2&gt; 
&lt;p&gt;These great services sponsor MUI's core infrastructure:&lt;/p&gt; 
&lt;div&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://mui.com/static/readme/github-darkmode.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://mui.com/static/readme/github-lightmode.svg"&gt; 
  &lt;img alt="GitHub logo" src="https://mui.com/static/readme/github-lightmode.svg?sanitize=true" width="80" height="43"&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt; lets us host the Git repository and coordinate contributions.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://mui.com/static/readme/netlify-darkmode.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://mui.com/static/readme/netlify-lightmode.svg"&gt; 
  &lt;img alt="Netlify logo" src="https://mui.com/static/readme/netlify-lightmode.svg?sanitize=true" width="100" height="27"&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt; lets us distribute the documentation.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://mui.com/static/readme/browserstack-darkmode.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://mui.com/static/readme/browserstack-lightmode.svg"&gt; 
  &lt;img alt="BrowserStack logo" src="https://mui.com/static/readme/browserstack-lightmode.svg?sanitize=true" width="140" height="25"&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://www.browserstack.com/"&gt;BrowserStack&lt;/a&gt; lets us test in real browsers.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;img loading="lazy" alt="CodeCov logo" src="https://avatars.githubusercontent.com/u/8226205?s=105" width="35" height="35"&gt; 
 &lt;p&gt;&lt;a href="https://about.codecov.io/"&gt;CodeCov&lt;/a&gt; lets us monitor test coverage.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Sim is an open-source AI agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/sim.png" alt="Sim Logo" width="500"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-7289DA?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://github.com/simstudioai/sim/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs welcome"&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai"&gt;&lt;img src="https://img.shields.io/badge/Docs-visit%20documentation-blue.svg?sanitize=true" alt="Documentation"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Sim&lt;/strong&gt; is a lightweight, user-friendly platform for building AI agent workflows. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/demo.gif" alt="Sim Demo" width="800"&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use our &lt;a href="https://sim.ai"&gt;cloud-hosted version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Self-host using one of the methods below&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Self-Hosting Options&lt;/h2&gt; 
&lt;h3&gt;Option 1: NPM Package (Simplest)&lt;/h3&gt; 
&lt;p&gt;The easiest way to run Sim locally is using our &lt;a href="https://www.npmjs.com/package/simstudio?activeTab=readme"&gt;NPM package&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After running these commands, open &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;: Specify the port to run Sim on (default: 3000)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-pull&lt;/code&gt;: Skip pulling the latest Docker images&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Requirements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker must be installed and running on your machine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Option 2: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 3: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Option 4: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bunx drizzle-kit migrate 
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with ‚ù§Ô∏è by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AsyncFuncAI/deepwiki-open</title>
      <link>https://github.com/AsyncFuncAI/deepwiki-open</link>
      <description>&lt;p&gt;Open Source DeepWiki: AI-Powered Wiki Generator for GitHub/Gitlab/Bitbucket Repositories. Join the discord: https://discord.gg/gMwThUMeme&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepWiki-Open&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/Deepwiki.png" alt="DeepWiki Banner"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DeepWiki&lt;/strong&gt; is my own implementation attempt of DeepWiki, automatically creates beautiful, interactive wikis for any GitHub, GitLab, or BitBucket repository! Just enter a repo name, and DeepWiki will:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Analyze the code structure&lt;/li&gt; 
 &lt;li&gt;Generate comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;Create visual diagrams to explain how everything works&lt;/li&gt; 
 &lt;li&gt;Organize it all into an easy-to-navigate wiki&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://buymeacoffee.com/sheing"&gt;&lt;img src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" alt="&amp;quot;Buy Me A Coffee&amp;quot;"&gt;&lt;/a&gt; &lt;a href="https://tip.md/sng-asyncfunc"&gt;&lt;img src="https://tip.md/badge.svg?sanitize=true" alt="Tip in Crypto"&gt;&lt;/a&gt; &lt;a href="https://x.com/sashimikun_void"&gt;&lt;img src="https://img.shields.io/badge/Twitter-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Twitter/X"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/VQMBGR8u5v"&gt;&lt;img src="https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.zh-tw.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.kr.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.vi.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.pt-br.md"&gt;Portugu√™s Brasileiro&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.fr.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/README.ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Documentation&lt;/strong&gt;: Turn any GitHub, GitLab or BitBucket repo into a wiki in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private Repository Support&lt;/strong&gt;: Securely access private repositories with personal access tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt;: AI-powered understanding of code structure and relationships&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Beautiful Diagrams&lt;/strong&gt;: Automatic Mermaid diagrams to visualize architecture and data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Navigation&lt;/strong&gt;: Simple, intuitive interface to explore the wiki&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ask Feature&lt;/strong&gt;: Chat with your repository using RAG-powered AI to get accurate answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepResearch&lt;/strong&gt;: Multi-turn research process that thoroughly investigates complex topics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Model Providers&lt;/strong&gt;: Support for Google Gemini, OpenAI, OpenRouter, and local Ollama models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start (Super Easy!)&lt;/h2&gt; 
&lt;h3&gt;Option 1: Using Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Create a .env file with your API keys
echo "GOOGLE_API_KEY=your_google_api_key" &amp;gt; .env
echo "OPENAI_API_KEY=your_openai_api_key" &amp;gt;&amp;gt; .env
# Optional: Add OpenRouter API key if you want to use OpenRouter models
echo "OPENROUTER_API_KEY=your_openrouter_api_key" &amp;gt;&amp;gt; .env
# Optional: Add Ollama host if not local. defaults to http://localhost:11434
echo "OLLAMA_HOST=your_ollama_host" &amp;gt;&amp;gt; .env
# Optional: Add Azure API key, endpoint and version if you want to use azure openai models
echo "AZURE_OPENAI_API_KEY=your_azure_openai_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_VERSION=your_azure_openai_version" &amp;gt;&amp;gt; .env
# Run with Docker Compose
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed instructions on using DeepWiki with Ollama and Docker, see &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/Ollama-instruction.md"&gt;Ollama Instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° &lt;strong&gt;Where to get these keys:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Get a Google API key from &lt;a href="https://makersuite.google.com/app/apikey"&gt;Google AI Studio&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Get an OpenAI API key from &lt;a href="https://platform.openai.com/api-keys"&gt;OpenAI Platform&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Get Azure OpenAI credentials from &lt;a href="https://portal.azure.com/"&gt;Azure Portal&lt;/a&gt; - create an Azure OpenAI resource and get the API key, endpoint, and API version&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Option 2: Manual Setup (Recommended)&lt;/h3&gt; 
&lt;h4&gt;Step 1: Set Up Your API Keys&lt;/h4&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the project root with these keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GOOGLE_API_KEY=your_google_api_key
OPENAI_API_KEY=your_openai_api_key
# Optional: Add this if you want to use OpenRouter models
OPENROUTER_API_KEY=your_openrouter_api_key
# Optional: Add this if you want to use Azure OpenAI models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
AZURE_OPENAI_VERSION=your_azure_openai_version
# Optional: Add Ollama host if not local. default: http://localhost:11434
OLLAMA_HOST=your_ollama_host
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Start the Backend&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python dependencies
pip install -r api/requirements.txt

# Start the API server
python -m api.main
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 3: Start the Frontend&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install JavaScript dependencies
npm install
# or
yarn install

# Start the web app
npm run dev
# or
yarn dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 4: Use DeepWiki!&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser&lt;/li&gt; 
 &lt;li&gt;Enter a GitHub, GitLab, or Bitbucket repository (like &lt;code&gt;https://github.com/openai/codex&lt;/code&gt;, &lt;code&gt;https://github.com/microsoft/autogen&lt;/code&gt;, &lt;code&gt;https://gitlab.com/gitlab-org/gitlab&lt;/code&gt;, or &lt;code&gt;https://bitbucket.org/redradish/atlassian_app_versions&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;For private repositories, click "+ Add access tokens" and enter your GitHub or GitLab personal access token&lt;/li&gt; 
 &lt;li&gt;Click "Generate Wiki" and watch the magic happen!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîç How It Works&lt;/h2&gt; 
&lt;p&gt;DeepWiki uses AI to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and analyze the GitHub, GitLab, or Bitbucket repository (including private repos with token authentication)&lt;/li&gt; 
 &lt;li&gt;Create embeddings of the code for smart retrieval&lt;/li&gt; 
 &lt;li&gt;Generate documentation with context-aware AI (using Google Gemini, OpenAI, OpenRouter, Azure OpenAI, or local Ollama models)&lt;/li&gt; 
 &lt;li&gt;Create visual diagrams to explain code relationships&lt;/li&gt; 
 &lt;li&gt;Organize everything into a structured wiki&lt;/li&gt; 
 &lt;li&gt;Enable intelligent Q&amp;amp;A with the repository through the Ask feature&lt;/li&gt; 
 &lt;li&gt;Provide in-depth research capabilities with DeepResearch&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TD
    A[User inputs GitHub/GitLab/Bitbucket repo] --&amp;gt; AA{Private repo?}
    AA --&amp;gt;|Yes| AB[Add access token]
    AA --&amp;gt;|No| B[Clone Repository]
    AB --&amp;gt; B
    B --&amp;gt; C[Analyze Code Structure]
    C --&amp;gt; D[Create Code Embeddings]

    D --&amp;gt; M{Select Model Provider}
    M --&amp;gt;|Google Gemini| E1[Generate with Gemini]
    M --&amp;gt;|OpenAI| E2[Generate with OpenAI]
    M --&amp;gt;|OpenRouter| E3[Generate with OpenRouter]
    M --&amp;gt;|Local Ollama| E4[Generate with Ollama]
    M --&amp;gt;|Azure| E5[Generate with Azure]

    E1 --&amp;gt; E[Generate Documentation]
    E2 --&amp;gt; E
    E3 --&amp;gt; E
    E4 --&amp;gt; E
    E5 --&amp;gt; E

    D --&amp;gt; F[Create Visual Diagrams]
    E --&amp;gt; G[Organize as Wiki]
    F --&amp;gt; G
    G --&amp;gt; H[Interactive DeepWiki]

    classDef process stroke-width:2px;
    classDef data stroke-width:2px;
    classDef result stroke-width:2px;
    classDef decision stroke-width:2px;

    class A,D data;
    class AA,M decision;
    class B,C,E,F,G,AB,E1,E2,E3,E4,E5 process;
    class H result;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üõ†Ô∏è Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;deepwiki/
‚îú‚îÄ‚îÄ api/                  # Backend API server
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # API entry point
‚îÇ   ‚îú‚îÄ‚îÄ api.py            # FastAPI implementation
‚îÇ   ‚îú‚îÄ‚îÄ rag.py            # Retrieval Augmented Generation
‚îÇ   ‚îú‚îÄ‚îÄ data_pipeline.py  # Data processing utilities
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt  # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ src/                  # Frontend Next.js app
‚îÇ   ‚îú‚îÄ‚îÄ app/              # Next.js app directory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx      # Main application page
‚îÇ   ‚îî‚îÄ‚îÄ components/       # React components
‚îÇ       ‚îî‚îÄ‚îÄ Mermaid.tsx   # Mermaid diagram renderer
‚îÇ
‚îú‚îÄ‚îÄ public/               # Static assets
‚îú‚îÄ‚îÄ package.json          # JavaScript dependencies
‚îî‚îÄ‚îÄ .env                  # Environment variables (create this)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ Provider-Based Model Selection System&lt;/h2&gt; 
&lt;p&gt;DeepWiki now implements a flexible provider-based model selection system supporting multiple LLM providers:&lt;/p&gt; 
&lt;h3&gt;Supported Providers and Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Google&lt;/strong&gt;: Default &lt;code&gt;gemini-2.0-flash&lt;/code&gt;, also supports &lt;code&gt;gemini-1.5-flash&lt;/code&gt;, &lt;code&gt;gemini-1.0-pro&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;: Default &lt;code&gt;gpt-4o&lt;/code&gt;, also supports &lt;code&gt;o4-mini&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;: Access to multiple models via a unified API, including Claude, Llama, Mistral, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;: Default &lt;code&gt;gpt-4o&lt;/code&gt;, also supports &lt;code&gt;o4-mini&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Support for locally running open-source models like &lt;code&gt;llama3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Each provider requires its corresponding API key environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# API Keys
GOOGLE_API_KEY=your_google_api_key        # Required for Google Gemini models
OPENAI_API_KEY=your_openai_api_key        # Required for OpenAI models
OPENROUTER_API_KEY=your_openrouter_api_key # Required for OpenRouter models
AZURE_OPENAI_API_KEY=your_azure_openai_api_key  #Required for Azure OpenAI models
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint  #Required for Azure OpenAI models
AZURE_OPENAI_VERSION=your_azure_openai_version  #Required for Azure OpenAI models

# OpenAI API Base URL Configuration
OPENAI_BASE_URL=https://custom-api-endpoint.com/v1  # Optional, for custom OpenAI API endpoints

# Ollama host
OLLAMA_HOST=your_ollama_host # Optional, if Ollama is not local. default: http://localhost:11434

# Configuration Directory
DEEPWIKI_CONFIG_DIR=/path/to/custom/config/dir  # Optional, for custom config file location
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;DeepWiki uses JSON configuration files to manage various aspects of the system:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;generator.json&lt;/code&gt;&lt;/strong&gt;: Configuration for text generation models&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defines available model providers (Google, OpenAI, OpenRouter, Azure, Ollama)&lt;/li&gt; 
   &lt;li&gt;Specifies default and available models for each provider&lt;/li&gt; 
   &lt;li&gt;Contains model-specific parameters like temperature and top_p&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;embedder.json&lt;/code&gt;&lt;/strong&gt;: Configuration for embedding models and text processing&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defines embedding models for vector storage&lt;/li&gt; 
   &lt;li&gt;Contains retriever configuration for RAG&lt;/li&gt; 
   &lt;li&gt;Specifies text splitter settings for document chunking&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;repo.json&lt;/code&gt;&lt;/strong&gt;: Configuration for repository handling&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Contains file filters to exclude certain files and directories&lt;/li&gt; 
   &lt;li&gt;Defines repository size limits and processing rules&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default, these files are located in the &lt;code&gt;api/config/&lt;/code&gt; directory. You can customize their location using the &lt;code&gt;DEEPWIKI_CONFIG_DIR&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Custom Model Selection for Service Providers&lt;/h3&gt; 
&lt;p&gt;The custom model selection feature is specifically designed for service providers who need to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can offer multiple AI model choices to users within your organization&lt;/li&gt; 
 &lt;li&gt;You can quickly adapt to the rapidly evolving LLM landscape without code changes&lt;/li&gt; 
 &lt;li&gt;You can support specialized or fine-tuned models that aren't in the predefined list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Service providers can implement their model offerings by selecting from the predefined options or entering custom model identifiers in the frontend interface.&lt;/p&gt; 
&lt;h3&gt;Base URL Configuration for Enterprise Private Channels&lt;/h3&gt; 
&lt;p&gt;The OpenAI Client's base_url configuration is designed primarily for enterprise users with private API channels. This feature:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enables connection to private or enterprise-specific API endpoints&lt;/li&gt; 
 &lt;li&gt;Allows organizations to use their own self-hosted or custom-deployed LLM services&lt;/li&gt; 
 &lt;li&gt;Supports integration with third-party OpenAI API-compatible services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Coming Soon&lt;/strong&gt;: In future updates, DeepWiki will support a mode where users need to provide their own API keys in requests. This will allow enterprise customers with private channels to use their existing API arrangements without sharing credentials with the DeepWiki deployment.&lt;/p&gt; 
&lt;h2&gt;üß© Using OpenAI-Compatible Embedding Models (e.g., Alibaba Qwen)&lt;/h2&gt; 
&lt;p&gt;If you want to use embedding models compatible with the OpenAI API (such as Alibaba Qwen), follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Replace the contents of &lt;code&gt;api/config/embedder.json&lt;/code&gt; with those from &lt;code&gt;api/config/embedder_openai_compatible.json&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;In your project root &lt;code&gt;.env&lt;/code&gt; file, set the relevant environment variables, for example: &lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=your_api_key
OPENAI_BASE_URL=your_openai_compatible_endpoint
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;The program will automatically substitute placeholders in embedder.json with the values from your environment variables.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This allows you to seamlessly switch to any OpenAI-compatible embedding service without code changes.&lt;/p&gt; 
&lt;h3&gt;Logging&lt;/h3&gt; 
&lt;p&gt;DeepWiki uses Python's built-in &lt;code&gt;logging&lt;/code&gt; module for diagnostic output. You can configure the verbosity and log file destination via environment variables:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LOG_LEVEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).&lt;/td&gt; 
   &lt;td&gt;INFO&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LOG_FILE_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to the log file. If set, logs will be written to this file.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;api/logs/application.log&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To enable debug logging and direct logs to a custom file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export LOG_LEVEL=DEBUG
export LOG_FILE_PATH=./debug.log
python -m api.main
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or with Docker Compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LOG_LEVEL=DEBUG LOG_FILE_PATH=./debug.log docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker Compose, the container's &lt;code&gt;api/logs&lt;/code&gt; directory is bind-mounted to &lt;code&gt;./api/logs&lt;/code&gt; on your host (see the &lt;code&gt;volumes&lt;/code&gt; section in &lt;code&gt;docker-compose.yml&lt;/code&gt;), ensuring log files persist across restarts.&lt;/p&gt; 
&lt;p&gt;Alternatively, you can store these settings in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;LOG_LEVEL=DEBUG
LOG_FILE_PATH=./debug.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Logging Path Security Considerations:&lt;/strong&gt; In production environments, ensure the &lt;code&gt;api/logs&lt;/code&gt; directory and any custom log file path are secured with appropriate filesystem permissions and access controls. The application enforces that &lt;code&gt;LOG_FILE_PATH&lt;/code&gt; resides within the project's &lt;code&gt;api/logs&lt;/code&gt; directory to prevent path traversal or unauthorized writes.&lt;/p&gt; 
&lt;h2&gt;üõ†Ô∏è Advanced Setup&lt;/h2&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Gemini API key for AI generation&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Google Gemini models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API key for embeddings&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Note: This is required even if you're not using OpenAI models, as it's used for embeddings.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key for alternative models&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use OpenRouter models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI API key&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI endpoint&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI version&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama Host (default: &lt;a href="http://localhost:11434"&gt;http://localhost:11434&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Required only if you want to use external Ollama server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port for the API server (default: 8001)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;If you host API and frontend on the same machine, make sure change port of &lt;code&gt;SERVER_BASE_URL&lt;/code&gt; accordingly&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SERVER_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for the API server (default: &lt;a href="http://localhost:8001"&gt;http://localhost:8001&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Set to &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt; to enable authorization mode.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Defaults to &lt;code&gt;false&lt;/code&gt;. If enabled, &lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt; is required.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The secret code required for wiki generation when &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is enabled.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Only used if &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;If you're not using ollama mode, you need to configure an OpenAI API key for embeddings. Other API keys are only required when configuring and using models from the corresponding providers.&lt;/p&gt; 
&lt;h2&gt;Authorization Mode&lt;/h2&gt; 
&lt;p&gt;DeepWiki can be configured to run in an authorization mode, where wiki generation requires a valid authorization code. This is useful if you want to control who can use the generation feature. Restricts frontend initiation and protects cache deletion, but doesn't fully prevent backend generation if API endpoints are hit directly.&lt;/p&gt; 
&lt;p&gt;To enable authorization mode, set the following environment variables:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt;: Set this to &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;1&lt;/code&gt;. When enabled, the frontend will display an input field for the authorization code.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DEEPWIKI_AUTH_CODE&lt;/code&gt;: Set this to the desired secret code. Restricts frontend initiation and protects cache deletion, but doesn't fully prevent backend generation if API endpoints are hit directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If &lt;code&gt;DEEPWIKI_AUTH_MODE&lt;/code&gt; is not set or is set to &lt;code&gt;false&lt;/code&gt; (or any other value than &lt;code&gt;true&lt;/code&gt;/&lt;code&gt;1&lt;/code&gt;), the authorization feature will be disabled, and no code will be required.&lt;/p&gt; 
&lt;h3&gt;Docker Setup&lt;/h3&gt; 
&lt;p&gt;You can use Docker to run DeepWiki:&lt;/p&gt; 
&lt;h4&gt;Running the Container&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pull the image from GitHub Container Registry
docker pull ghcr.io/asyncfuncai/deepwiki-open:latest

# Run the container with environment variables
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e OLLAMA_HOST=your_ollama_host \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \

  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command also mounts &lt;code&gt;~/.adalflow&lt;/code&gt; on your host to &lt;code&gt;/root/.adalflow&lt;/code&gt; in the container. This path is used to store:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cloned repositories (&lt;code&gt;~/.adalflow/repos/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Their embeddings and indexes (&lt;code&gt;~/.adalflow/databases/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Cached generated wiki content (&lt;code&gt;~/.adalflow/wikicache/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This ensures that your data persists even if the container is stopped or removed.&lt;/p&gt; 
&lt;p&gt;Or use the provided &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Edit the .env file with your API keys first
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(The &lt;code&gt;docker-compose.yml&lt;/code&gt; file is pre-configured to mount &lt;code&gt;~/.adalflow&lt;/code&gt; for data persistence, similar to the &lt;code&gt;docker run&lt;/code&gt; command above.)&lt;/p&gt; 
&lt;h4&gt;Using a .env file with Docker&lt;/h4&gt; 
&lt;p&gt;You can also mount a .env file to the container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a .env file with your API keys
echo "GOOGLE_API_KEY=your_google_api_key" &amp;gt; .env
echo "OPENAI_API_KEY=your_openai_api_key" &amp;gt;&amp;gt; .env
echo "OPENROUTER_API_KEY=your_openrouter_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_API_KEY=your_azure_openai_api_key" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint" &amp;gt;&amp;gt; .env
echo "AZURE_OPENAI_VERSION=your_azure_openai_version"  &amp;gt;&amp;gt;.env
echo "OLLAMA_HOST=your_ollama_host" &amp;gt;&amp;gt; .env

# Run the container with the .env file mounted
docker run -p 8001:8001 -p 3000:3000 \
  -v $(pwd)/.env:/app/.env \
  -v ~/.adalflow:/root/.adalflow \
  ghcr.io/asyncfuncai/deepwiki-open:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command also mounts &lt;code&gt;~/.adalflow&lt;/code&gt; on your host to &lt;code&gt;/root/.adalflow&lt;/code&gt; in the container. This path is used to store:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cloned repositories (&lt;code&gt;~/.adalflow/repos/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Their embeddings and indexes (&lt;code&gt;~/.adalflow/databases/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Cached generated wiki content (&lt;code&gt;~/.adalflow/wikicache/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This ensures that your data persists even if the container is stopped or removed.&lt;/p&gt; 
&lt;h4&gt;Building the Docker image locally&lt;/h4&gt; 
&lt;p&gt;If you want to build the Docker image locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/AsyncFuncAI/deepwiki-open.git
cd deepwiki-open

# Build the Docker image
docker build -t deepwiki-open .

# Run the container
docker run -p 8001:8001 -p 3000:3000 \
  -e GOOGLE_API_KEY=your_google_api_key \
  -e OPENAI_API_KEY=your_openai_api_key \
  -e OPENROUTER_API_KEY=your_openrouter_api_key \
  -e AZURE_OPENAI_API_KEY=your_azure_openai_api_key \
  -e AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint \
  -e AZURE_OPENAI_VERSION=your_azure_openai_version \
  -e OLLAMA_HOST=your_ollama_host \
  deepwiki-open
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Self-Signed Certificates in Docker&lt;/h4&gt; 
&lt;p&gt;If you're in an environment that uses self-signed certificates, you can include them in the Docker build:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a directory for your certificates (default is &lt;code&gt;certs&lt;/code&gt; in your project root)&lt;/li&gt; 
 &lt;li&gt;Copy your &lt;code&gt;.crt&lt;/code&gt; or &lt;code&gt;.pem&lt;/code&gt; certificate files into this directory&lt;/li&gt; 
 &lt;li&gt;Build the Docker image:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build with default certificates directory (certs)
docker build .

# Or build with a custom certificates directory
docker build --build-arg CUSTOM_CERT_DIR=my-custom-certs .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;API Server Details&lt;/h3&gt; 
&lt;p&gt;The API server provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Repository cloning and indexing&lt;/li&gt; 
 &lt;li&gt;RAG (Retrieval Augmented Generation)&lt;/li&gt; 
 &lt;li&gt;Streaming chat completions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/api/README.md"&gt;API README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîå OpenRouter Integration&lt;/h2&gt; 
&lt;p&gt;DeepWiki now supports &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; as a model provider, giving you access to hundreds of AI models through a single API:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Model Options&lt;/strong&gt;: Access models from OpenAI, Anthropic, Google, Meta, Mistral, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Configuration&lt;/strong&gt;: Just add your OpenRouter API key and select the model you want to use&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost Efficiency&lt;/strong&gt;: Choose models that fit your budget and performance needs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Switching&lt;/strong&gt;: Toggle between different models without changing your code&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to Use OpenRouter with DeepWiki&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Get an API Key&lt;/strong&gt;: Sign up at &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; and get your API key&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to Environment&lt;/strong&gt;: Add &lt;code&gt;OPENROUTER_API_KEY=your_key&lt;/code&gt; to your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enable in UI&lt;/strong&gt;: Check the "Use OpenRouter API" option on the homepage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Select Model&lt;/strong&gt;: Choose from popular models like GPT-4o, Claude 3.5 Sonnet, Gemini 2.0, and more&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;OpenRouter is particularly useful if you want to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try different models without signing up for multiple services&lt;/li&gt; 
 &lt;li&gt;Access models that might be restricted in your region&lt;/li&gt; 
 &lt;li&gt;Compare performance across different model providers&lt;/li&gt; 
 &lt;li&gt;Optimize for cost vs. performance based on your needs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ñ Ask &amp;amp; DeepResearch Features&lt;/h2&gt; 
&lt;h3&gt;Ask Feature&lt;/h3&gt; 
&lt;p&gt;The Ask feature allows you to chat with your repository using Retrieval Augmented Generation (RAG):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context-Aware Responses&lt;/strong&gt;: Get accurate answers based on the actual code in your repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RAG-Powered&lt;/strong&gt;: The system retrieves relevant code snippets to provide grounded responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Streaming&lt;/strong&gt;: See responses as they're generated for a more interactive experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: The system maintains context between questions for more coherent interactions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DeepResearch Feature&lt;/h3&gt; 
&lt;p&gt;DeepResearch takes repository analysis to the next level with a multi-turn research process:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;In-Depth Investigation&lt;/strong&gt;: Thoroughly explores complex topics through multiple research iterations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Process&lt;/strong&gt;: Follows a clear research plan with updates and a comprehensive conclusion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Continuation&lt;/strong&gt;: The AI automatically continues research until reaching a conclusion (up to 5 iterations)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Stages&lt;/strong&gt;: 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;Research Plan&lt;/strong&gt;: Outlines the approach and initial findings&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Research Updates&lt;/strong&gt;: Builds on previous iterations with new insights&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Final Conclusion&lt;/strong&gt;: Provides a comprehensive answer based on all iterations&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use DeepResearch, simply toggle the "Deep Research" switch in the Ask interface before submitting your question.&lt;/p&gt; 
&lt;h2&gt;üì± Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/Interface.png" alt="DeepWiki Main Interface"&gt; &lt;em&gt;The main interface of DeepWiki&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/privaterepo.png" alt="Private Repository Support"&gt; &lt;em&gt;Access private repositories with personal access tokens&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/screenshots/DeepResearch.png" alt="DeepResearch Feature"&gt; &lt;em&gt;DeepResearch conducts multi-turn investigations for complex topics&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Demo Video&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/zGANs8US8B4"&gt;&lt;img src="https://img.youtube.com/vi/zGANs8US8B4/0.jpg" alt="DeepWiki Demo Video"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Watch DeepWiki in action!&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;‚ùì Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;API Key Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Missing environment variables"&lt;/strong&gt;: Make sure your &lt;code&gt;.env&lt;/code&gt; file is in the project root and contains the required API keys&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"API key not valid"&lt;/strong&gt;: Check that you've copied the full key correctly with no extra spaces&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"OpenRouter API error"&lt;/strong&gt;: Verify your OpenRouter API key is valid and has sufficient credits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Azure OpenAI API error"&lt;/strong&gt;: Verify your Azure OpenAI credentials (API key, endpoint, and version) are correct and the service is properly deployed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Problems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Cannot connect to API server"&lt;/strong&gt;: Make sure the API server is running on port 8001&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"CORS error"&lt;/strong&gt;: The API is configured to allow all origins, but if you're having issues, try running both frontend and backend on the same machine&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Generation Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;"Error generating wiki"&lt;/strong&gt;: For very large repositories, try a smaller one first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Invalid repository format"&lt;/strong&gt;: Make sure you're using a valid GitHub, GitLab or Bitbucket URL format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Could not fetch repository structure"&lt;/strong&gt;: For private repositories, ensure you've entered a valid personal access token with appropriate permissions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;"Diagram rendering error"&lt;/strong&gt;: The app will automatically try to fix broken diagrams&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Common Solutions&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Restart both servers&lt;/strong&gt;: Sometimes a simple restart fixes most issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check console logs&lt;/strong&gt;: Open browser developer tools to see any JavaScript errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check API logs&lt;/strong&gt;: Look at the terminal where the API is running for Python errors&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Feel free to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open issues for bugs or feature requests&lt;/li&gt; 
 &lt;li&gt;Submit pull requests to improve the code&lt;/li&gt; 
 &lt;li&gt;Share your feedback and ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/AsyncFuncAI/deepwiki-open/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#AsyncFuncAI/deepwiki-open&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=AsyncFuncAI/deepwiki-open&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thewh1teagle/vibe</title>
      <link>https://github.com/thewh1teagle/vibe</link>
      <description>&lt;p&gt;Transcribe on your own!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a target="blank" href="https://github.com/thewh1teagle/vibe"&gt; &lt;img width="96px" alt="Vibe logo" src="https://raw.githubusercontent.com/thewh1teagle/vibe/main/design/logo.png"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Vibe - Transcribe on your own!&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;strong&gt;‚å®Ô∏è Transcribe audio / video offline using OpenAI Whisper&lt;/strong&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://thewh1teagle.github.io/vibe/"&gt; üîó Download Vibe &lt;/a&gt; &amp;nbsp; | &amp;nbsp; Give it a Star ‚≠ê | &amp;nbsp; &lt;a target="_blank" href="https://thewh1teagle.github.io/vibe/?action=support-vibe"&gt;Support the project ü§ù&lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://thewh1teagle.github.io/vibe/"&gt; &lt;img width="600" src="https://github.com/thewh1teagle/vibe/assets/61390950/22779ac6-9e49-4c21-b528-29647f039da2"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Features üåü&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåç Transcribe almost every language&lt;/li&gt; 
 &lt;li&gt;üîí Ultimate privacy: fully offline transcription, no data ever leaves your device&lt;/li&gt; 
 &lt;li&gt;üé® User friendly design&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è Transcribe audio / video&lt;/li&gt; 
 &lt;li&gt;üé∂ Option to transcribe audio from popular websites (YouTube, Vimeo, Facebook, Twitter and more!)&lt;/li&gt; 
 &lt;li&gt;üìÇ Batch transcribe multiple files!&lt;/li&gt; 
 &lt;li&gt;üìù Support &lt;code&gt;SRT&lt;/code&gt;, &lt;code&gt;VTT&lt;/code&gt;, &lt;code&gt;TXT&lt;/code&gt;, &lt;code&gt;HTML&lt;/code&gt;, &lt;code&gt;PDF&lt;/code&gt;, &lt;code&gt;JSON&lt;/code&gt;, &lt;code&gt;DOCX&lt;/code&gt; formats&lt;/li&gt; 
 &lt;li&gt;üëÄ Realtime preview&lt;/li&gt; 
 &lt;li&gt;‚ú® Summarize transcripts: Get quick, multilingual summaries using the Claude API&lt;/li&gt; 
 &lt;li&gt;üß† Ollama support: Do local AI analysis and batch summaries with Ollama&lt;/li&gt; 
 &lt;li&gt;üåê Translate to English from any language&lt;/li&gt; 
 &lt;li&gt;üñ®Ô∏è Print transcript directly to any printer&lt;/li&gt; 
 &lt;li&gt;üîÑ Automatic updates&lt;/li&gt; 
 &lt;li&gt;üíª Optimized for &lt;code&gt;GPU&lt;/code&gt; (&lt;code&gt;macOS&lt;/code&gt;, &lt;code&gt;Windows&lt;/code&gt;, &lt;code&gt;Linux&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üéÆ Optimized for &lt;code&gt;Nvidia&lt;/code&gt; / &lt;code&gt;AMD&lt;/code&gt; / &lt;code&gt;Intel&lt;/code&gt; GPUs! (&lt;code&gt;Vulkan&lt;/code&gt;/&lt;code&gt;CoreML&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üîß Total Freedom: Customize Models Easily via Settings&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è Model arguments for advanced users&lt;/li&gt; 
 &lt;li&gt;‚è≥ Transcribe system audio&lt;/li&gt; 
 &lt;li&gt;üé§ Transcribe from microphone&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è CLI support: Use Vibe directly from the command line interface! (see &lt;code&gt;--help&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üë• Speaker diarization&lt;/li&gt; 
 &lt;li&gt;üì± &lt;del&gt;iOS &amp;amp; Android support&lt;/del&gt; (coming soon)&lt;/li&gt; 
 &lt;li&gt;üì• Integrate custom models from your own site: Use &lt;code&gt;vibe://download/?url=&amp;lt;model url&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üìπ Choose caption length optimized for videos / reels&lt;/li&gt; 
 &lt;li&gt;‚ö° HTTP API with Swagger docs! (use &lt;code&gt;--server&lt;/code&gt; and open &lt;code&gt;http://&amp;lt;host&amp;gt;:3022/docs&lt;/code&gt; for docs)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Supported platforms üñ•Ô∏è&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;MacOS&lt;/code&gt; &lt;code&gt;Windows&lt;/code&gt; &lt;code&gt;Linux&lt;/code&gt;&lt;/p&gt; 
&lt;h1&gt;Contribute ü§ù&lt;/h1&gt; 
&lt;p&gt;PRs are welcomed! In addition, you're welcome to add translations.&lt;/p&gt; 
&lt;p&gt;We would like to express our sincere gratitude to all the contributors.&lt;/p&gt; 
&lt;a href="https://github.com/thewh1teagle/vibe/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=thewh1teagle/vibe"&gt; &lt;/a&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/EcxWSstQN8"&gt;&lt;img src="https://img.shields.io/badge/chat-discord-7289da.svg?sanitize=true" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Roadmap üõ£Ô∏è&lt;/h1&gt; 
&lt;p&gt;You can see the roadmap in &lt;a href="https://github.com/users/thewh1teagle/projects/5/views/1"&gt;Vibe-Roadmap&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Add translation üåê&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy &lt;code&gt;en&lt;/code&gt; from &lt;code&gt;desktop/src-tauri/locales&lt;/code&gt; folder to new directory eg &lt;code&gt;pt-BR&lt;/code&gt; (use &lt;a href="https://gist.github.com/thewh1teagle/c8877e5c4c5e2780754ddd065ae2592e"&gt;bcp47 language code&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Change every value in the files there, to the new language and keep the keys as is&lt;/li&gt; 
 &lt;li&gt;create PR / issue in Github&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;In addition you can add translation to &lt;a href="https://thewh1teagle.github.io/vibe/"&gt;Vibe website&lt;/a&gt; by creating new files in the &lt;code&gt;landing/static/locales&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Docs üìÑ&lt;/h1&gt; 
&lt;p&gt;see &lt;a href="https://github.com/thewh1teagle/vibe/tree/main/docs"&gt;Vibe Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;I want to know more!&lt;/h1&gt; 
&lt;p&gt;Medium &lt;a href="https://medium.com/@thewh1teagle/creating-vibe-multilingual-audio-transcription-872ab6d9dbb0"&gt;post&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Issue report&lt;/h1&gt; 
&lt;p&gt;You can open &lt;a href="https://github.com/thewh1teagle/vibe/issues/new?assignees=octocat&amp;amp;labels=bug&amp;amp;projects=&amp;amp;template=bug_report.yaml&amp;amp;title=%5BShort+title%5D"&gt;new issue&lt;/a&gt; and it's recommend to check &lt;a href="https://raw.githubusercontent.com/thewh1teagle/vibe/main/docs/debug.md"&gt;debug.md&lt;/a&gt; first.&lt;/p&gt; 
&lt;h1&gt;Privacy Policy üîí&lt;/h1&gt; 
&lt;p&gt;Your privacy is important to us. Please review our &lt;a href="http://thewh1teagle.github.io/vibe/?action=open-privacy-policy"&gt;Privacy Policy&lt;/a&gt; to understand how we handle your data.&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks for &lt;a href="https://tauri.app/"&gt;tauri.app&lt;/a&gt; for making the best apps framework I ever seen&lt;/p&gt; 
&lt;p&gt;Thanks for &lt;a href="https://github.com/wang-bin/avbuild"&gt;wang-bin/avbuild&lt;/a&gt; for pre built &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Thanks for &lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;github.com/whisper.cpp&lt;/a&gt; for outstanding interface for the AI model.&lt;/p&gt; 
&lt;p&gt;Thanks for &lt;a href="https://openai.com/"&gt;openai.com&lt;/a&gt; for their amazing &lt;a href="https://openai.com/research/whisper"&gt;Whisper model&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Thanks for &lt;a href="https://github.com/"&gt;github.com&lt;/a&gt; for their support in open source projects, providing infastructure completely free.&lt;/p&gt; 
&lt;p&gt;And for all the amazing open source frameworks and libraries which this project uses...&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>n8n-io/n8n</title>
      <link>https://github.com/n8n-io/n8n</link>
      <description>&lt;p&gt;Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/10284570/173569848-c624317f-42b1-45a6-ab09-f0ea3c247648.png" alt="Banner image"&gt;&lt;/p&gt; 
&lt;h1&gt;n8n - Secure Workflow Automation for Technical Teams&lt;/h1&gt; 
&lt;p&gt;n8n is a workflow automation platform that gives technical teams the flexibility of code with the speed of no-code. With 400+ integrations, native AI capabilities, and a fair-code license, n8n lets you build powerful automations while maintaining full control over your data and deployments.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/n8n-io/n8n/master/assets/n8n-screenshot-readme.png" alt="n8n.io - Screenshot"&gt;&lt;/p&gt; 
&lt;h2&gt;Key Capabilities&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code When You Need It&lt;/strong&gt;: Write JavaScript/Python, add npm packages, or use the visual interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Native Platform&lt;/strong&gt;: Build AI agent workflows based on LangChain with your own data and models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Control&lt;/strong&gt;: Self-host with our fair-code license or use our &lt;a href="https://app.n8n.cloud/login"&gt;cloud offering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-Ready&lt;/strong&gt;: Advanced permissions, SSO, and air-gapped deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Community&lt;/strong&gt;: 400+ integrations and 900+ ready-to-use &lt;a href="https://n8n.io/workflows"&gt;templates&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Try n8n instantly with &lt;a href="https://docs.n8n.io/hosting/installation/npm/"&gt;npx&lt;/a&gt; (requires &lt;a href="https://nodejs.org/en/"&gt;Node.js&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npx n8n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or deploy with &lt;a href="https://docs.n8n.io/hosting/installation/docker/"&gt;Docker&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker volume create n8n_data
docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the editor at &lt;a href="http://localhost:5678"&gt;http://localhost:5678&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìö &lt;a href="https://docs.n8n.io"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://n8n.io/integrations"&gt;400+ Integrations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://n8n.io/workflows"&gt;Example Workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;a href="https://docs.n8n.io/langchain/"&gt;AI &amp;amp; LangChain Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üë• &lt;a href="https://community.n8n.io"&gt;Community Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://community.n8n.io/c/tutorials/28"&gt;Community Tutorials&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Need help? Our community forum is the place to get support and connect with other users: &lt;a href="https://community.n8n.io"&gt;community.n8n.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;n8n is &lt;a href="https://faircode.io"&gt;fair-code&lt;/a&gt; distributed under the &lt;a href="https://github.com/n8n-io/n8n/raw/master/LICENSE.md"&gt;Sustainable Use License&lt;/a&gt; and &lt;a href="https://github.com/n8n-io/n8n/raw/master/LICENSE_EE.md"&gt;n8n Enterprise License&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Source Available&lt;/strong&gt;: Always visible source code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-Hostable&lt;/strong&gt;: Deploy anywhere&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Add your own nodes and functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="mailto:license@n8n.io"&gt;Enterprise licenses&lt;/a&gt; available for additional features and support.&lt;/p&gt; 
&lt;p&gt;Additional information about the license model can be found in the &lt;a href="https://docs.n8n.io/reference/license/"&gt;docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Found a bug üêõ or have a feature idea ‚ú®? Check our &lt;a href="https://github.com/n8n-io/n8n/raw/master/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Join the Team&lt;/h2&gt; 
&lt;p&gt;Want to shape the future of automation? Check out our &lt;a href="https://n8n.io/careers"&gt;job posts&lt;/a&gt; and join our team!&lt;/p&gt; 
&lt;h2&gt;What does n8n mean?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Short answer:&lt;/strong&gt; It means "nodemation" and is pronounced as n-eight-n.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Long answer:&lt;/strong&gt; "I get that question quite often (more often than I expected) so I decided it is probably best to answer it here. While looking for a good name for the project with a free domain I realized very quickly that all the good ones I could think of were already taken. So, in the end, I chose nodemation. 'node-' in the sense that it uses a Node-View and that it uses Node.js and '-mation' for 'automation' which is what the project is supposed to help with. However, I did not like how long the name was and I could not imagine writing something that long every time in the CLI. That is when I then ended up on 'n8n'." - &lt;strong&gt;Jan Oberhauser, Founder and CEO, n8n.io&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>actualbudget/actual</title>
      <link>https://github.com/actualbudget/actual</link>
      <description>&lt;p&gt;A local-first personal finance app&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/actualbudget/actual/master/demo.png" alt="Actualbudget"&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Actual is a local-first personal finance tool. It is 100% free and open-source, written in NodeJS, it has a synchronization element so that all your changes can move between devices without any heavy lifting.&lt;/p&gt; 
&lt;p&gt;If you are interested in contributing, or want to know how development works, see our &lt;a href="https://actualbudget.org/docs/contributing/"&gt;contributing&lt;/a&gt; document we would love to have you.&lt;/p&gt; 
&lt;p&gt;Want to say thanks? Click the ‚≠ê at the top of the page.&lt;/p&gt; 
&lt;h2&gt;Key Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Actual &lt;a href="https://discord.gg/pRYNYr4W5A"&gt;discord&lt;/a&gt; community.&lt;/li&gt; 
 &lt;li&gt;Actual &lt;a href="https://actualbudget.org/docs"&gt;Community Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://actualbudget.org/docs/faq"&gt;Frequently asked questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are four ways to deploy Actual:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One-click deployment &lt;a href="https://www.pikapods.com/pods?run=actual"&gt;via PikaPods&lt;/a&gt; (~1.40 $/month) - recommended for non-technical users&lt;/li&gt; 
 &lt;li&gt;Managed hosting &lt;a href="https://actualbudget.org/docs/install/fly"&gt;via Fly.io&lt;/a&gt; (~1.50 $/month)&lt;/li&gt; 
 &lt;li&gt;Self-hosted by using &lt;a href="https://actualbudget.org/docs/install/docker"&gt;a Docker image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local-only apps - &lt;a href="https://actualbudget.org/download/"&gt;downloadable Windows, Mac and Linux apps&lt;/a&gt; you can run on your device&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Learn more in the &lt;a href="https://actualbudget.org/docs/install/"&gt;installation instructions docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Ready to Start Budgeting?&lt;/h2&gt; 
&lt;p&gt;Read about &lt;a href="https://actualbudget.org/docs/getting-started/envelope-budgeting"&gt;Envelope budgeting&lt;/a&gt; to know more about the idea behind Actual Budget.&lt;/p&gt; 
&lt;h3&gt;Are you new to budgeting or want to start fresh?&lt;/h3&gt; 
&lt;p&gt;Check out the community's &lt;a href="https://actualbudget.org/docs/getting-started/starting-fresh"&gt;Starting Fresh&lt;/a&gt; guide so you can quickly get up and running!&lt;/p&gt; 
&lt;h3&gt;Are you migrating from other budgeting apps?&lt;/h3&gt; 
&lt;p&gt;Check out the community's &lt;a href="https://actualbudget.org/docs/migration/"&gt;Migration&lt;/a&gt; guide to start jumping on the Actual Budget train!&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;We have a wide range of documentation on how to use Actual, this is all available in our &lt;a href="https://actualbudget.org/docs"&gt;Community Documentation&lt;/a&gt;, this includes topics on Budgeting, Account Management, Tips &amp;amp; Tricks and some documentation for developers.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Actual is a community driven product. Learn more about &lt;a href="https://actualbudget.org/docs/contributing/"&gt;contributing to Actual&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Code structure&lt;/h3&gt; 
&lt;p&gt;The Actual app is split up into a few packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;loot-core - The core application that runs on any platform&lt;/li&gt; 
 &lt;li&gt;desktop-client - The desktop UI&lt;/li&gt; 
 &lt;li&gt;desktop-electron - The desktop app&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More information on the project structure is available in our &lt;a href="https://actualbudget.org/docs/contributing/project-details"&gt;community documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Feature Requests&lt;/h3&gt; 
&lt;p&gt;Current feature requests can be seen &lt;a href="https://github.com/actualbudget/actual/issues?q=is%3Aissue+label%3A%22needs+votes%22+sort%3Areactions-%2B1-desc"&gt;here&lt;/a&gt;. Vote for your favorite requests by reacting &lt;span&gt;üëç&lt;/span&gt; to the top comment of the request.&lt;/p&gt; 
&lt;p&gt;To add new feature requests, open a new Issue of the "Feature Request" type.&lt;/p&gt; 
&lt;h3&gt;Translation&lt;/h3&gt; 
&lt;p&gt;Make Actual Budget accessible to more people by helping with the &lt;a href="https://actualbudget.org/docs/contributing/i18n/"&gt;Internationalization&lt;/a&gt; of Actual. We are using a crowd sourcing tool to manage the translations, see our &lt;a href="https://hosted.weblate.org/projects/actualbudget/"&gt;Weblate Project&lt;/a&gt;. Weblate proudly supports open-source software projects through their &lt;a href="https://weblate.org/en/hosting/#libre"&gt;Libre plan&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/actualbudget/"&gt; &lt;img src="https://hosted.weblate.org/widget/actualbudget/actual/287x66-grey.png" alt="Translation status"&gt; &lt;/a&gt; 
&lt;h2&gt;Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e20537dd8b74956f86736726ccfbc6f0565bec22.svg?sanitize=true" alt="Alt" title="Repobeats analytics image"&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Thanks to our wonderful sponsors who make Actual Budget possible!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.netlify.com"&gt; &lt;img src="https://www.netlify.com/v3/img/components/netlify-color-accent.svg?sanitize=true" alt="Deploys by Netlify"&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apache/echarts</title>
      <link>https://github.com/apache/echarts</link>
      <description>&lt;p&gt;Apache ECharts is a powerful, interactive charting and data visualization library for browser&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache ECharts&lt;/h1&gt; 
&lt;a href="https://echarts.apache.org/"&gt; &lt;img style="vertical-align: top;" src="https://raw.githubusercontent.com/apache/echarts/master/asset/logo.png?raw=true" alt="logo" height="50px"&gt; &lt;/a&gt; 
&lt;p&gt;Apache ECharts is a free, powerful charting and visualization library offering easy ways to add intuitive, interactive, and highly customizable charts to your commercial products. It is written in pure JavaScript and based on &lt;a href="https://github.com/ecomfe/zrender"&gt;zrender&lt;/a&gt;, which is a whole new lightweight canvas library.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://echarts.apache.org/zh/index.html"&gt;‰∏≠ÊñáÂÆòÁΩë&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://echarts.apache.org/en/index.html"&gt;ENGLISH HOMEPAGE&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/apache/echarts/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/npm/l/echarts?color=5470c6" alt="License"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/echarts"&gt;&lt;img src="https://img.shields.io/npm/v/echarts?color=91cc75" alt="Latest npm release"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/echarts"&gt;&lt;img src="https://img.shields.io/npm/dm/echarts.svg?label=npm%20downloads&amp;amp;style=flat&amp;amp;color=fac858" alt="NPM downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/apache/echarts/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/apache/echarts?color=3ba272" alt="Contributors"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/apache/echarts/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/apache/echarts/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Apache ECharts&lt;/h2&gt; 
&lt;p&gt;You may choose one of the following methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download from the &lt;a href="https://echarts.apache.org/download.html"&gt;official website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm install echarts --save&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;CDN: &lt;a href="https://www.jsdelivr.com/package/npm/echarts?path=dist"&gt;jsDelivr CDN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://echarts.apache.org/handbook"&gt;Get Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://echarts.apache.org/api.html"&gt;API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://echarts.apache.org/option.html"&gt;Option Manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://echarts.apache.org/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Help&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/echarts/issues"&gt;GitHub Issues&lt;/a&gt; for bug report and feature requests&lt;/li&gt; 
 &lt;li&gt;Email &lt;a href="mailto:dev@echarts.apache.org"&gt;dev@echarts.apache.org&lt;/a&gt; for general questions&lt;/li&gt; 
 &lt;li&gt;Subscribe to the &lt;a href="https://echarts.apache.org/maillist.html"&gt;mailing list&lt;/a&gt; to get updated with the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build&lt;/h2&gt; 
&lt;p&gt;Build echarts source code:&lt;/p&gt; 
&lt;p&gt;Execute the instructions in the root directory of the echarts: (&lt;a href="https://nodejs.org"&gt;Node.js&lt;/a&gt; is required)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Install the dependencies from NPM:
npm install

# Rebuild source code immediately in watch mode when changing the source code.
# It opens the `./test` directory, and you may open `-cases.html` to get the list
# of all test cases.
# If you wish to create a test case, run `npm run mktest:help` to learn more.
npm run dev

# Check the correctness of TypeScript code.
npm run checktype

# If intending to build and get all types of the "production" files:
npm run release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then the "production" files are generated in the &lt;code&gt;dist&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://github.com/apache/echarts/raw/master/CONTRIBUTING.md"&gt;contributing&lt;/a&gt; document if you wish to debug locally or make pull requests.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;Awesome ECharts&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ecomfe/awesome-echarts"&gt;https://github.com/ecomfe/awesome-echarts&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ecomfe/echarts-gl"&gt;ECharts GL&lt;/a&gt; An extension pack of ECharts, which provides 3D plots, globe visualization, and WebGL acceleration.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ecomfe/echarts-liquidfill"&gt;Liquidfill Ê∞¥ÁêÉÂõæ&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ecomfe/echarts-wordcloud"&gt;Wordcloud Â≠óÁ¨¶‰∫ë&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/apache/echarts/tree/master/extension-src/bmap"&gt;Extension for Baidu Map ÁôæÂ∫¶Âú∞ÂõæÊâ©Â±ï&lt;/a&gt; An extension provides a wrapper of Baidu Map Service SDK.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ecomfe/vue-echarts"&gt;vue-echarts&lt;/a&gt; ECharts component for Vue.js&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/ecomfe/echarts-stat"&gt;echarts-stat&lt;/a&gt; Statistics tool for ECharts&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;ECharts is available under the Apache License V2.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://www.apache.org/foundation/policies/conduct.html"&gt;Apache Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Paper&lt;/h2&gt; 
&lt;p&gt;Deqing Li, Honghui Mei, Yi Shen, Shuang Su, Wenli Zhang, Junting Wang, Ming Zu, Wei Chen. &lt;a href="https://www.sciencedirect.com/science/article/pii/S2468502X18300068"&gt;ECharts: A Declarative Framework for Rapid Construction of Web-based Visualization&lt;/a&gt;. Visual Informatics, 2018.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>musistudio/claude-code-router</title>
      <link>https://github.com/musistudio/claude-code-router</link>
      <description>&lt;p&gt;Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code Router&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/musistudio/claude-code-router/main/README_zh.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A powerful tool to route Claude Code requests to different models and customize any request.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/images/claude-code.png" alt=""&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Model Routing&lt;/strong&gt;: Route requests to different models based on your needs (e.g., background tasks, thinking, long context).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Provider Support&lt;/strong&gt;: Supports various model providers like OpenRouter, DeepSeek, Ollama, Gemini, Volcengine, and SiliconFlow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Request/Response Transformation&lt;/strong&gt;: Customize requests and responses for different providers using transformers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Model Switching&lt;/strong&gt;: Switch models on-the-fly within Claude Code using the &lt;code&gt;/model&lt;/code&gt; command.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Actions Integration&lt;/strong&gt;: Trigger Claude Code tasks in your GitHub workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt;: Extend functionality with custom transformers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;1. Installation&lt;/h3&gt; 
&lt;p&gt;First, ensure you have &lt;a href="https://docs.anthropic.com/en/docs/claude-code/quickstart"&gt;Claude Code&lt;/a&gt; installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, install Claude Code Router:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @musistudio/claude-code-router
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Configuration&lt;/h3&gt; 
&lt;p&gt;Create and configure your &lt;code&gt;~/.claude-code-router/config.json&lt;/code&gt; file. For more details, you can refer to &lt;code&gt;config.example.json&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;config.json&lt;/code&gt; file has several key sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;PROXY_URL&lt;/code&gt;&lt;/strong&gt; (optional): You can set a proxy for API requests, for example: &lt;code&gt;"PROXY_URL": "http://127.0.0.1:7890"&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;LOG&lt;/code&gt;&lt;/strong&gt; (optional): You can enable logging by setting it to &lt;code&gt;true&lt;/code&gt;. The log file will be located at &lt;code&gt;$HOME/.claude-code-router.log&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;APIKEY&lt;/code&gt;&lt;/strong&gt; (optional): You can set a secret key to authenticate requests. When set, clients must provide this key in the &lt;code&gt;Authorization&lt;/code&gt; header (e.g., &lt;code&gt;Bearer your-secret-key&lt;/code&gt;) or the &lt;code&gt;x-api-key&lt;/code&gt; header. Example: &lt;code&gt;"APIKEY": "your-secret-key"&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/strong&gt; (optional): You can set the host address for the server. If &lt;code&gt;APIKEY&lt;/code&gt; is not set, the host will be forced to &lt;code&gt;127.0.0.1&lt;/code&gt; for security reasons to prevent unauthorized access. Example: &lt;code&gt;"HOST": "0.0.0.0"&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;NON_INTERACTIVE_MODE&lt;/code&gt;&lt;/strong&gt; (optional): When set to &lt;code&gt;true&lt;/code&gt;, enables compatibility with non-interactive environments like GitHub Actions, Docker containers, or other CI/CD systems. This sets appropriate environment variables (&lt;code&gt;CI=true&lt;/code&gt;, &lt;code&gt;FORCE_COLOR=0&lt;/code&gt;, etc.) and configures stdin handling to prevent the process from hanging in automated environments. Example: &lt;code&gt;"NON_INTERACTIVE_MODE": true&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;Providers&lt;/code&gt;&lt;/strong&gt;: Used to configure different model providers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;Router&lt;/code&gt;&lt;/strong&gt;: Used to set up routing rules. &lt;code&gt;default&lt;/code&gt; specifies the default model, which will be used for all requests if no other route is configured.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;API_TIMEOUT_MS&lt;/code&gt;&lt;/strong&gt;: Specifies the timeout for API calls in milliseconds.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here is a comprehensive example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "APIKEY": "your-secret-key",
  "PROXY_URL": "http://127.0.0.1:7890",
  "LOG": true,
  "API_TIMEOUT_MS": 600000,
  "NON_INTERACTIVE_MODE": false,
  "Providers": [
    {
      "name": "openrouter",
      "api_base_url": "https://openrouter.ai/api/v1/chat/completions",
      "api_key": "sk-xxx",
      "models": [
        "google/gemini-2.5-pro-preview",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-3.7-sonnet:thinking"
      ],
      "transformer": {
        "use": ["openrouter"]
      }
    },
    {
      "name": "deepseek",
      "api_base_url": "https://api.deepseek.com/chat/completions",
      "api_key": "sk-xxx",
      "models": ["deepseek-chat", "deepseek-reasoner"],
      "transformer": {
        "use": ["deepseek"],
        "deepseek-chat": {
          "use": ["tooluse"]
        }
      }
    },
    {
      "name": "ollama",
      "api_base_url": "http://localhost:11434/v1/chat/completions",
      "api_key": "ollama",
      "models": ["qwen2.5-coder:latest"]
    },
    {
      "name": "gemini",
      "api_base_url": "https://generativelanguage.googleapis.com/v1beta/models/",
      "api_key": "sk-xxx",
      "models": ["gemini-2.5-flash", "gemini-2.5-pro"],
      "transformer": {
        "use": ["gemini"]
      }
    },
    {
      "name": "volcengine",
      "api_base_url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
      "api_key": "sk-xxx",
      "models": ["deepseek-v3-250324", "deepseek-r1-250528"],
      "transformer": {
        "use": ["deepseek"]
      }
    },
    {
      "name": "modelscope",
      "api_base_url": "https://api-inference.modelscope.cn/v1/chat/completions",
      "api_key": "",
      "models": ["Qwen/Qwen3-Coder-480B-A35B-Instruct", "Qwen/Qwen3-235B-A22B-Thinking-2507"],
      "transformer": {
        "use": [
          [
            "maxtoken",
            {
              "max_tokens": 65536
            }
          ],
          "enhancetool"
        ],
        "Qwen/Qwen3-235B-A22B-Thinking-2507": {
          "use": ["reasoning"]
        }
      }
    },
    {
      "name": "dashscope",
      "api_base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
      "api_key": "",
      "models": ["qwen3-coder-plus"],
      "transformer": {
        "use": [
          [
            "maxtoken",
            {
              "max_tokens": 65536
            }
          ],
          "enhancetool"
        ]
      }
    },
    {
      "name": "aihubmix",
      "api_base_url": "https://aihubmix.com/v1/chat/completions",
      "api_key": "sk-",
      "models": [
        "Z/glm-4.5",
        "claude-opus-4-20250514",
        "gemini-2.5-pro"
      ]
    }
  ],
  "Router": {
    "default": "deepseek,deepseek-chat",
    "background": "ollama,qwen2.5-coder:latest",
    "think": "deepseek,deepseek-reasoner",
    "longContext": "openrouter,google/gemini-2.5-pro-preview",
    "longContextThreshold": 60000,
    "webSearch": "gemini,gemini-2.5-flash"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Running Claude Code with the Router&lt;/h3&gt; 
&lt;p&gt;Start Claude Code using the router:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ccr code
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: After modifying the configuration file, you need to restart the service for the changes to take effect:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;ccr restart
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;4. UI Mode (Beta)&lt;/h3&gt; 
&lt;p&gt;For a more intuitive experience, you can use the UI mode to manage your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ccr ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will open a web-based interface where you can easily view and edit your &lt;code&gt;config.json&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/images/ui.png" alt="UI"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The UI mode is currently in beta. 100% vibe coding: including project initialization, I just created a folder and a project.md document, and all code was generated by ccr + qwen3-coder + gemini(webSearch). If you encounter any issues, please submit an issue on GitHub.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Providers&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;Providers&lt;/code&gt; array is where you define the different model providers you want to use. Each provider object requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: A unique name for the provider.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;api_base_url&lt;/code&gt;: The full API endpoint for chat completions.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;api_key&lt;/code&gt;: Your API key for the provider.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;models&lt;/code&gt;: A list of model names available from this provider.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;transformer&lt;/code&gt; (optional): Specifies transformers to process requests and responses.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Transformers&lt;/h4&gt; 
&lt;p&gt;Transformers allow you to modify the request and response payloads to ensure compatibility with different provider APIs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Global Transformer&lt;/strong&gt;: Apply a transformer to all models from a provider. In this example, the &lt;code&gt;openrouter&lt;/code&gt; transformer is applied to all models under the &lt;code&gt;openrouter&lt;/code&gt; provider.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "openrouter",
  "api_base_url": "https://openrouter.ai/api/v1/chat/completions",
  "api_key": "sk-xxx",
  "models": [
    "google/gemini-2.5-pro-preview",
    "anthropic/claude-sonnet-4",
    "anthropic/claude-3.5-sonnet"
  ],
  "transformer": { "use": ["openrouter"] }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model-Specific Transformer&lt;/strong&gt;: Apply a transformer to a specific model. In this example, the &lt;code&gt;deepseek&lt;/code&gt; transformer is applied to all models, and an additional &lt;code&gt;tooluse&lt;/code&gt; transformer is applied only to the &lt;code&gt;deepseek-chat&lt;/code&gt; model.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "deepseek",
  "api_base_url": "https://api.deepseek.com/chat/completions",
  "api_key": "sk-xxx",
  "models": ["deepseek-chat", "deepseek-reasoner"],
  "transformer": {
    "use": ["deepseek"],
    "deepseek-chat": { "use": ["tooluse"] }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Passing Options to a Transformer&lt;/strong&gt;: Some transformers, like &lt;code&gt;maxtoken&lt;/code&gt;, accept options. To pass options, use a nested array where the first element is the transformer name and the second is an options object.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "siliconflow",
  "api_base_url": "https://api.siliconflow.cn/v1/chat/completions",
  "api_key": "sk-xxx",
  "models": ["moonshotai/Kimi-K2-Instruct"],
  "transformer": {
    "use": [
      [
        "maxtoken",
        {
          "max_tokens": 16384
        }
      ]
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Available Built-in Transformers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Anthropic&lt;/code&gt;:If you use only the &lt;code&gt;Anthropic&lt;/code&gt; transformer, it will preserve the original request and response parameters(you can use it to connect directly to an Anthropic endpoint).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;deepseek&lt;/code&gt;: Adapts requests/responses for DeepSeek API.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;gemini&lt;/code&gt;: Adapts requests/responses for Gemini API.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;openrouter&lt;/code&gt;: Adapts requests/responses for OpenRouter API. It can also accept a &lt;code&gt;provider&lt;/code&gt; routing parameter to specify which underlying providers OpenRouter should use. For more details, refer to the &lt;a href="https://openrouter.ai/docs/features/provider-routing"&gt;OpenRouter documentation&lt;/a&gt;. See an example below: &lt;pre&gt;&lt;code class="language-json"&gt;  "transformer": {
    "use": ["openrouter"],
    "moonshotai/kimi-k2": {
      "use": [
        [
          "openrouter",
          {
            "provider": {
              "only": ["moonshotai/fp8"]
            }
          }
        ]
      ]
    }
  }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;groq&lt;/code&gt;: Adapts requests/responses for groq API.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;maxtoken&lt;/code&gt;: Sets a specific &lt;code&gt;max_tokens&lt;/code&gt; value.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tooluse&lt;/code&gt;: Optimizes tool usage for certain models via &lt;code&gt;tool_choice&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;gemini-cli&lt;/code&gt; (experimental): Unofficial support for Gemini via Gemini CLI &lt;a href="https://gist.github.com/musistudio/1c13a65f35916a7ab690649d3df8d1cd"&gt;gemini-cli.js&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;reasoning&lt;/code&gt;: Used to process the &lt;code&gt;reasoning_content&lt;/code&gt; field.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sampling&lt;/code&gt;: Used to process sampling information fields such as &lt;code&gt;temperature&lt;/code&gt;, &lt;code&gt;top_p&lt;/code&gt;, &lt;code&gt;top_k&lt;/code&gt;, and &lt;code&gt;repetition_penalty&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;enhancetool&lt;/code&gt;: Adds a layer of error tolerance to the tool call parameters returned by the LLM (this will cause the tool call information to no longer be streamed).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cleancache&lt;/code&gt;: Clears the &lt;code&gt;cache_control&lt;/code&gt; field from requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vertex-gemini&lt;/code&gt;: Handles the Gemini API using Vertex authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Custom Transformers:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can also create your own transformers and load them via the &lt;code&gt;transformers&lt;/code&gt; field in &lt;code&gt;config.json&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "transformers": [
    {
      "path": "$HOME/.claude-code-router/plugins/gemini-cli.js",
      "options": {
        "project": "xxx"
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Router&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;Router&lt;/code&gt; object defines which model to use for different scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;default&lt;/code&gt;: The default model for general tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;background&lt;/code&gt;: A model for background tasks. This can be a smaller, local model to save costs.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;think&lt;/code&gt;: A model for reasoning-heavy tasks, like Plan Mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;longContext&lt;/code&gt;: A model for handling long contexts (e.g., &amp;gt; 60K tokens).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;longContextThreshold&lt;/code&gt; (optional): The token count threshold for triggering the long context model. Defaults to 60000 if not specified.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webSearch&lt;/code&gt;: Used for handling web search tasks and this requires the model itself to support the feature. If you're using openrouter, you need to add the &lt;code&gt;:online&lt;/code&gt; suffix after the model name.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also switch models dynamically in Claude Code with the &lt;code&gt;/model&lt;/code&gt; command: &lt;code&gt;/model provider_name,model_name&lt;/code&gt; Example: &lt;code&gt;/model openrouter,anthropic/claude-3.5-sonnet&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Custom Router&lt;/h4&gt; 
&lt;p&gt;For more advanced routing logic, you can specify a custom router script via the &lt;code&gt;CUSTOM_ROUTER_PATH&lt;/code&gt; in your &lt;code&gt;config.json&lt;/code&gt;. This allows you to implement complex routing rules beyond the default scenarios.&lt;/p&gt; 
&lt;p&gt;In your &lt;code&gt;config.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "CUSTOM_ROUTER_PATH": "$HOME/.claude-code-router/custom-router.js"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The custom router file must be a JavaScript module that exports an &lt;code&gt;async&lt;/code&gt; function. This function receives the request object and the config object as arguments and should return the provider and model name as a string (e.g., &lt;code&gt;"provider_name,model_name"&lt;/code&gt;), or &lt;code&gt;null&lt;/code&gt; to fall back to the default router.&lt;/p&gt; 
&lt;p&gt;Here is an example of a &lt;code&gt;custom-router.js&lt;/code&gt; based on &lt;code&gt;custom-router.example.js&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// $HOME/.claude-code-router/custom-router.js

/**
 * A custom router function to determine which model to use based on the request.
 *
 * @param {object} req - The request object from Claude Code, containing the request body.
 * @param {object} config - The application's config object.
 * @returns {Promise&amp;lt;string|null&amp;gt;} - A promise that resolves to the "provider,model_name" string, or null to use the default router.
 */
module.exports = async function router(req, config) {
  const userMessage = req.body.messages.find((m) =&amp;gt; m.role === "user")?.content;

  if (userMessage &amp;amp;&amp;amp; userMessage.includes("explain this code")) {
    // Use a powerful model for code explanation
    return "openrouter,anthropic/claude-3.5-sonnet";
  }

  // Fallback to the default router configuration
  return null;
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Subagent Routing&lt;/h5&gt; 
&lt;p&gt;For routing within subagents, you must specify a particular provider and model by including &lt;code&gt;&amp;lt;CCR-SUBAGENT-MODEL&amp;gt;provider,model&amp;lt;/CCR-SUBAGENT-MODEL&amp;gt;&lt;/code&gt; at the &lt;strong&gt;beginning&lt;/strong&gt; of the subagent's prompt. This allows you to direct specific subagent tasks to designated models.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;CCR-SUBAGENT-MODEL&amp;gt;openrouter,anthropic/claude-3.5-sonnet&amp;lt;/CCR-SUBAGENT-MODEL&amp;gt;
Please help me analyze this code snippet for potential optimizations...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ GitHub Actions&lt;/h2&gt; 
&lt;p&gt;Integrate Claude Code Router into your CI/CD pipeline. After setting up &lt;a href="https://docs.anthropic.com/en/docs/claude-code/github-actions"&gt;Claude Code Actions&lt;/a&gt;, modify your &lt;code&gt;.github/workflows/claude.yaml&lt;/code&gt; to use the router:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: Claude Code

on:
  issue_comment:
    types: [created]
  # ... other triggers

jobs:
  claude:
    if: |
      (github.event_name == 'issue_comment' &amp;amp;&amp;amp; contains(github.event.comment.body, '@claude')) ||
      # ... other conditions
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
      issues: read
      id-token: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Prepare Environment
        run: |
          curl -fsSL https://bun.sh/install | bash
          mkdir -p $HOME/.claude-code-router
          cat &amp;lt;&amp;lt; 'EOF' &amp;gt; $HOME/.claude-code-router/config.json
          {
            "log": true,
            "NON_INTERACTIVE_MODE": true,
            "OPENAI_API_KEY": "${{ secrets.OPENAI_API_KEY }}",
            "OPENAI_BASE_URL": "https://api.deepseek.com",
            "OPENAI_MODEL": "deepseek-chat"
          }
          EOF
        shell: bash

      - name: Start Claude Code Router
        run: |
          nohup ~/.bun/bin/bunx @musistudio/claude-code-router@1.0.8 start &amp;amp;
        shell: bash

      - name: Run Claude Code
        id: claude
        uses: anthropics/claude-code-action@beta
        env:
          ANTHROPIC_BASE_URL: http://localhost:3456
        with:
          anthropic_api_key: "any-string-is-ok"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: When running in GitHub Actions or other automation environments, make sure to set &lt;code&gt;"NON_INTERACTIVE_MODE": true&lt;/code&gt; in your configuration to prevent the process from hanging due to stdin handling issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This setup allows for interesting automations, like running tasks during off-peak hours to reduce API costs.&lt;/p&gt; 
&lt;h2&gt;üìù Further Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/en/project-motivation-and-how-it-works.md"&gt;Project Motivation and How It Works&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/en/maybe-we-can-do-more-with-the-route.md"&gt;Maybe We Can Do More with the Router&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ù§Ô∏è Support &amp;amp; Sponsoring&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, please consider sponsoring its development. Your support is greatly appreciated!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/F1F31GN2GM"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://paypal.me/musistudio1999"&gt;Paypal&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/images/alipay.jpg" width="200" alt="Alipay"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/musistudio/claude-code-router/main/blog/images/wechat.jpg" width="200" alt="WeChat Pay"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Our Sponsors&lt;/h3&gt; 
&lt;p&gt;A huge thank you to all our sponsors for their generous support!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aihubmix.com/"&gt;AIHubmix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@Simon Leischnig&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duanshuaimin"&gt;@duanshuaimin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vrgitadmin"&gt;@vrgitadmin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*o&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ceilwoo"&gt;@ceilwoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*ËØ¥&lt;/li&gt; 
 &lt;li&gt;@*Êõ¥&lt;/li&gt; 
 &lt;li&gt;@K*g&lt;/li&gt; 
 &lt;li&gt;@R*R&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bobleer"&gt;@bobleer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*Ëãó&lt;/li&gt; 
 &lt;li&gt;@*Âàí&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Clarence-pan"&gt;@Clarence-pan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carter003"&gt;@carter003&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@S*r&lt;/li&gt; 
 &lt;li&gt;@*Êôñ&lt;/li&gt; 
 &lt;li&gt;@*Êïè&lt;/li&gt; 
 &lt;li&gt;@Z*z&lt;/li&gt; 
 &lt;li&gt;@*ÁÑ∂&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cluic"&gt;@cluic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*Ëãó&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PromptExpert"&gt;@PromptExpert&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*Â∫î&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusnake"&gt;@yusnake&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*È£û&lt;/li&gt; 
 &lt;li&gt;@Ëë£*&lt;/li&gt; 
 &lt;li&gt;@*Ê±Ä&lt;/li&gt; 
 &lt;li&gt;@*Ê∂Ø&lt;/li&gt; 
 &lt;li&gt;@*:-Ôºâ&lt;/li&gt; 
 &lt;li&gt;@**Á£ä&lt;/li&gt; 
 &lt;li&gt;@*Áê¢&lt;/li&gt; 
 &lt;li&gt;@*Êàê&lt;/li&gt; 
 &lt;li&gt;@Z*o&lt;/li&gt; 
 &lt;li&gt;@*Áê®&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/congzhangzh"&gt;@congzhangzh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@*_&lt;/li&gt; 
 &lt;li&gt;@Z*m&lt;/li&gt; 
 &lt;li&gt;@*Èë´&lt;/li&gt; 
 &lt;li&gt;@c*y&lt;/li&gt; 
 &lt;li&gt;@*Êòï&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/witsice"&gt;@witsice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;@b*g&lt;/li&gt; 
 &lt;li&gt;@*‰∫ø&lt;/li&gt; 
 &lt;li&gt;@*Ëæâ&lt;/li&gt; 
 &lt;li&gt;@JACK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(If your name is masked, please contact me via my homepage email to update it with your GitHub username.)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prisma/prisma</title>
      <link>https://github.com/prisma/prisma</link>
      <description>&lt;p&gt;Next-generation ORM for Node.js &amp; TypeScript | PostgreSQL, MySQL, MariaDB, SQL Server, SQLite, MongoDB and CockroachDB&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://i.imgur.com/h6UIYTu.png" alt="Prisma"&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Prisma&lt;/h1&gt; 
 &lt;a href="https://www.npmjs.com/package/prisma"&gt;&lt;img src="https://img.shields.io/npm/v/prisma.svg?style=flat"&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/prisma/prisma/raw/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true"&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/prisma/prisma/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202-blue"&gt;&lt;/a&gt; 
 &lt;a href="https://pris.ly/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/937751382725886062?label=Discord"&gt;&lt;/a&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;a href="https://www.prisma.io/docs/getting-started/quickstart"&gt;Quickstart&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/"&gt;Website&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/docs/"&gt;Docs&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://github.com/prisma/prisma-examples/"&gt;Examples&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://www.prisma.io/blog"&gt;Blog&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/discord?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Discord&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/x?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Twitter&lt;/a&gt; 
 &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt; 
 &lt;a href="https://pris.ly/youtube?utm_source=github&amp;amp;utm_medium=prisma&amp;amp;utm_content=repo_readme"&gt;Youtube&lt;/a&gt; 
 &lt;br&gt; 
 &lt;hr&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Prisma?&lt;/h2&gt; 
&lt;p&gt;Prisma ORM is a &lt;strong&gt;next-generation ORM&lt;/strong&gt; that consists of these tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client"&gt;&lt;strong&gt;Prisma Client&lt;/strong&gt;&lt;/a&gt;: Auto-generated and type-safe query builder for Node.js &amp;amp; TypeScript&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/concepts/components/prisma-migrate"&gt;&lt;strong&gt;Prisma Migrate&lt;/strong&gt;&lt;/a&gt;: Declarative data modeling &amp;amp; migration system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prisma/studio"&gt;&lt;strong&gt;Prisma Studio&lt;/strong&gt;&lt;/a&gt;: GUI to view and edit data in your database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Prisma Client can be used in &lt;em&gt;any&lt;/em&gt; Node.js or TypeScript backend application (including serverless applications and microservices). This can be a &lt;a href="https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/rest"&gt;REST API&lt;/a&gt;, a &lt;a href="https://www.prisma.io/docs/concepts/overview/prisma-in-your-stack/graphql"&gt;GraphQL API&lt;/a&gt;, a gRPC API, or anything else that needs a database.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you need a database to use with Prisma ORM, check out &lt;a href="https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres?utm_source=github&amp;amp;utm_medium=prisma-readme"&gt;Prisma Postgres&lt;/a&gt; or if you are looking for our MCP Server, head &lt;a href="https://github.com/prisma/mcp"&gt;here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Quickstart (5min)&lt;/h3&gt; 
&lt;p&gt;The fastest way to get started with Prisma is by following the quickstart guides. You can choose either of two databases:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/quickstart-prismaPostgres"&gt;Prisma Postgres&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/quickstart-sqlite"&gt;SQLite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Bring your own database&lt;/h3&gt; 
&lt;p&gt;If you already have your own database, you can follow these guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/setup-prisma/add-to-existing-project/relational-databases-typescript-postgresql"&gt;Add Prisma to an existing project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.prisma.io/docs/getting-started/setup-prisma/start-from-scratch/relational-databases-typescript-postgresql"&gt;Set up a new project with Prisma from scratch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How Prisma ORM works&lt;/h2&gt; 
&lt;p&gt;This section provides a high-level overview of how Prisma ORM works and its most important technical components. For a more thorough introduction, visit the &lt;a href="https://www.prisma.io/docs/"&gt;Prisma documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;The Prisma schema&lt;/h3&gt; 
&lt;p&gt;Every project that uses a tool from the Prisma toolkit starts with a &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-schema"&gt;Prisma schema file&lt;/a&gt;. The Prisma schema allows developers to define their &lt;em&gt;application models&lt;/em&gt; in an intuitive data modeling language. It also contains the connection to a database and defines a &lt;em&gt;generator&lt;/em&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-prisma"&gt;// Data source
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

// Generator
generator client {
  provider = "prisma-client-js"
}

// Data model
model Post {
  id        Int     @id @default(autoincrement())
  title     String
  content   String?
  published Boolean @default(false)
  author    User?   @relation(fields:  [authorId], references: [id])
  authorId  Int?
}

model User {
  id    Int     @id @default(autoincrement())
  email String  @unique
  name  String?
  posts Post[]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this schema, you configure three things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data source&lt;/strong&gt;: Specifies your database connection (via an environment variable)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generator&lt;/strong&gt;: Indicates that you want to generate Prisma Client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data model&lt;/strong&gt;: Defines your application models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h3&gt;The Prisma data model&lt;/h3&gt; 
&lt;p&gt;On this page, the focus is on the data model. You can learn more about &lt;a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/data-sources"&gt;Data sources&lt;/a&gt; and &lt;a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema/generators"&gt;Generators&lt;/a&gt; on the respective docs pages.&lt;/p&gt; 
&lt;h4&gt;Functions of Prisma models&lt;/h4&gt; 
&lt;p&gt;The data model is a collection of &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-schema/data-model#defining-models"&gt;models&lt;/a&gt;. A model has two major functions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Represent a table in the underlying database&lt;/li&gt; 
 &lt;li&gt;Provide the foundation for the queries in the Prisma Client API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Getting a data model&lt;/h4&gt; 
&lt;p&gt;There are two major workflows for "getting" a data model into your Prisma schema:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate the data model from &lt;a href="https://www.prisma.io/docs/concepts/components/introspection"&gt;introspecting&lt;/a&gt; a database&lt;/li&gt; 
 &lt;li&gt;Manually writing the data model and mapping it to the database with &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-migrate"&gt;Prisma Migrate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once the data model is defined, you can &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client"&gt;generate Prisma Client&lt;/a&gt; which will expose CRUD and more queries for the defined models. If you're using TypeScript, you'll get full type-safety for all queries (even when only retrieving the subsets of a model's fields).&lt;/p&gt; 
&lt;hr&gt; 
&lt;h3&gt;Accessing your database with Prisma Client&lt;/h3&gt; 
&lt;h4&gt;Generating Prisma Client&lt;/h4&gt; 
&lt;p&gt;The first step when using Prisma Client is installing its npm package:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm install @prisma/client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the installation of this package invokes the &lt;code&gt;prisma generate&lt;/code&gt; command which reads your Prisma schema and &lt;em&gt;generates&lt;/em&gt; the Prisma Client code. The code will be located in &lt;code&gt;node_modules/.prisma/client&lt;/code&gt;, which is exported by &lt;code&gt;node_modules/@prisma/client/index.d.ts&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;After you change your data model, you'll need to manually re-generate Prisma Client to ensure the code inside &lt;code&gt;node_modules/.prisma/client&lt;/code&gt; gets updated:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npx prisma generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to the documentation for more information about &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/generating-prisma-client"&gt;"generating the Prisma client"&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Using Prisma Client to send queries to your database&lt;/h4&gt; 
&lt;p&gt;Once the Prisma Client is generated, you can import it in your code and send queries to your database. This is what the setup code looks like.&lt;/p&gt; 
&lt;h5&gt;Import and instantiate Prisma Client&lt;/h5&gt; 
&lt;p&gt;You can import and instantiate Prisma Client as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;const { PrismaClient } = require('@prisma/client')

const prisma = new PrismaClient()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can start sending queries via the generated Prisma Client API, here are a few sample queries. Note that all Prisma Client queries return &lt;em&gt;plain old JavaScript objects&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about the available operations in the &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client"&gt;Prisma Client docs&lt;/a&gt; or watch this &lt;a href="https://www.youtube.com/watch?v=LggrE5kJ75I&amp;amp;list=PLn2e1F9Rfr6k9PnR_figWOcSHgc_erDr5&amp;amp;index=4"&gt;demo video&lt;/a&gt; (2 min).&lt;/p&gt; 
&lt;h5&gt;Retrieve all &lt;code&gt;User&lt;/code&gt; records from the database&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const allUsers = await prisma.user.findMany()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Include the &lt;code&gt;posts&lt;/code&gt; relation on each returned &lt;code&gt;User&lt;/code&gt; object&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const allUsers = await prisma.user.findMany({
  include: { posts: true },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Filter all &lt;code&gt;Post&lt;/code&gt; records that contain &lt;code&gt;"prisma"&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const filteredPosts = await prisma.post.findMany({
  where: {
    OR: [{ title: { contains: 'prisma' } }, { content: { contains: 'prisma' } }],
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Create a new &lt;code&gt;User&lt;/code&gt; and a new &lt;code&gt;Post&lt;/code&gt; record in the same query&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const user = await prisma.user.create({
  data: {
    name: 'Alice',
    email: 'alice@prisma.io',
    posts: {
      create: { title: 'Join us for Prisma Day 2021' },
    },
  },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Update an existing &lt;code&gt;Post&lt;/code&gt; record&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;const post = await prisma.post.update({
  where: { id: 42 },
  data: { published: true },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Usage with TypeScript&lt;/h4&gt; 
&lt;p&gt;Note that when using TypeScript, the result of this query will be &lt;em&gt;statically typed&lt;/em&gt; so that you can't accidentally access a property that doesn't exist (and any typos are caught at compile-time). Learn more about leveraging Prisma Client's generated types on the &lt;a href="https://www.prisma.io/docs/concepts/components/prisma-client/advanced-usage-of-generated-types"&gt;Advanced usage of generated types&lt;/a&gt; page in the docs.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Prisma has a large and supportive &lt;a href="https://www.prisma.io/community"&gt;community&lt;/a&gt; of enthusiastic application developers. You can join us on &lt;a href="https://pris.ly/discord"&gt;Discord&lt;/a&gt; and here on &lt;a href="https://github.com/prisma/prisma/discussions"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Badges&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://prisma.io"&gt;&lt;img src="http://made-with.prisma.io/dark.svg?sanitize=true" alt="Made with Prisma"&gt;&lt;/a&gt; &lt;a href="https://prisma.io"&gt;&lt;img src="http://made-with.prisma.io/indigo.svg?sanitize=true" alt="Made with Prisma"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Built something awesome with Prisma? üåü Show it off with these &lt;a href="https://github.com/prisma/presskit?tab=readme-ov-file#badges"&gt;badges&lt;/a&gt;, perfect for your readme or website.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[![Made with Prisma](http://made-with.prisma.io/dark.svg)](https://prisma.io)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;[![Made with Prisma](http://made-with.prisma.io/indigo.svg)](https://prisma.io)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you have a security issue to report, please contact us at &lt;a href="mailto:security@prisma.io?subject=%5BGitHub%5D%20Prisma%202%20Security%20Report%20"&gt;security@prisma.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;h3&gt;Ask a question about Prisma&lt;/h3&gt; 
&lt;p&gt;You can ask questions and initiate &lt;a href="https://github.com/prisma/prisma/discussions/"&gt;discussions&lt;/a&gt; about Prisma-related topics in the &lt;code&gt;prisma&lt;/code&gt; repository on GitHub.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://github.com/prisma/prisma/discussions/new"&gt;&lt;strong&gt;Ask a question&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Create a bug report for Prisma&lt;/h3&gt; 
&lt;p&gt;If you see an error message or run into an issue, please make sure to create a bug report! You can find &lt;a href="https://www.prisma.io/docs/guides/other/troubleshooting-orm/creating-bug-reports"&gt;best practices for creating bug reports&lt;/a&gt; (like including additional debugging output) in the docs.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://pris.ly/prisma-prisma-bug-report"&gt;&lt;strong&gt;Create bug report&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Submit a feature request&lt;/h3&gt; 
&lt;p&gt;If Prisma currently doesn't have a certain feature, be sure to check out the &lt;a href="https://www.prisma.io/docs/more/roadmap"&gt;roadmap&lt;/a&gt; to see if this is already planned for the future.&lt;/p&gt; 
&lt;p&gt;If the feature on the roadmap is linked to a GitHub issue, please make sure to leave a üëç reaction on the issue and ideally a comment with your thoughts about the feature!&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://github.com/prisma/prisma/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature_request.md&amp;amp;title="&gt;&lt;strong&gt;Submit feature request&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/prisma/prisma/raw/main/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt; and &lt;a href="https://github.com/prisma/prisma/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct for contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Tests Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prisma Tests Status: &lt;a href="https://github.com/prisma/prisma/actions/workflows/test.yml?query=branch%3Amain"&gt;&lt;img src="https://github.com/prisma/prisma/workflows/CI/badge.svg?sanitize=true" alt="Prisma Tests Status"&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ecosystem Tests Status: &lt;a href="https://github.com/prisma/ecosystem-tests/actions/workflows/test.yaml?query=branch%3Adev"&gt;&lt;img src="https://github.com/prisma/ecosystem-tests/workflows/test/badge.svg?sanitize=true" alt="Ecosystem Tests Status"&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>google-gemini/gemini-cli</title>
      <link>https://github.com/google-gemini/gemini-cli</link>
      <description>&lt;p&gt;An open-source AI agent that brings the power of Gemini directly into your terminal.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gemini CLI&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Gemini CLI CI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/assets/gemini-screenshot.png" alt="Gemini CLI Screenshot"&gt;&lt;/p&gt; 
&lt;p&gt;This repository contains the Gemini CLI, a command-line AI workflow tool that connects to your tools, understands your code and accelerates your workflows.&lt;/p&gt; 
&lt;p&gt;With the Gemini CLI you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Query and edit large codebases in and beyond Gemini's 1M token context window.&lt;/li&gt; 
 &lt;li&gt;Generate new apps from PDFs or sketches, using Gemini's multimodal capabilities.&lt;/li&gt; 
 &lt;li&gt;Automate operational tasks, like querying pull requests or handling complex rebases.&lt;/li&gt; 
 &lt;li&gt;Integrate with GitHub: Use the &lt;a href="https://github.com/google-github-actions/run-gemini-cli"&gt;Gemini CLI GitHub Action&lt;/a&gt; for automated PR reviews, issue triage, and on-demand AI assistance directly in your repositories.&lt;/li&gt; 
 &lt;li&gt;Use tools and MCP servers to connect new capabilities, including &lt;a href="https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia"&gt;media generation with Imagen, Veo or Lyria&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ground your queries with the &lt;a href="https://ai.google.dev/gemini-api/docs/grounding"&gt;Google Search&lt;/a&gt; tool, built into Gemini.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;You have two options to install Gemini CLI.&lt;/p&gt; 
&lt;h3&gt;With Node&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Ensure you have &lt;a href="https://nodejs.org/en/download"&gt;Node.js version 20&lt;/a&gt; or higher installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the CLI:&lt;/strong&gt; Execute the following command in your terminal:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx https://github.com/google-gemini/gemini-cli
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or install it with:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @google/gemini-cli
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, run the CLI from anywhere:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;gemini
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;With Homebrew&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Ensure you have &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt; installed.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the CLI:&lt;/strong&gt; Execute the following command in your terminal:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install gemini-cli
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, run the CLI from anywhere:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;gemini
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Common Configuration steps&lt;/h3&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Pick a color theme&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authenticate:&lt;/strong&gt; When prompted, sign in with your personal Google account. This will grant you up to 60 model requests per minute and 1,000 model requests per day using Gemini.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You are now ready to use the Gemini CLI!&lt;/p&gt; 
&lt;h3&gt;Use a Gemini API key:&lt;/h3&gt; 
&lt;p&gt;The Gemini API provides a free tier with &lt;a href="https://ai.google.dev/gemini-api/docs/rate-limits#free-tier"&gt;100 requests per day&lt;/a&gt; using Gemini 2.5 Pro, control over which model you use, and access to higher rate limits (with a paid plan):&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Generate a key from &lt;a href="https://aistudio.google.com/apikey"&gt;Google AI Studio&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set it as an environment variable in your terminal. Replace &lt;code&gt;YOUR_API_KEY&lt;/code&gt; with your generated key.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export GEMINI_API_KEY="YOUR_API_KEY"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optionally) Upgrade your Gemini API project to a paid plan on the API key page (will automatically unlock &lt;a href="https://ai.google.dev/gemini-api/docs/rate-limits#tier-1"&gt;Tier 1 rate limits&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Use a Vertex AI API key:&lt;/h3&gt; 
&lt;p&gt;The Vertex AI API provides a &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview"&gt;free tier&lt;/a&gt; using express mode for Gemini 2.5 Pro, control over which model you use, and access to higher rate limits with a billing account:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Generate a key from &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/start/api-keys"&gt;Google Cloud&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set it as an environment variable in your terminal. Replace &lt;code&gt;YOUR_API_KEY&lt;/code&gt; with your generated key and set GOOGLE_GENAI_USE_VERTEXAI to true&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export GOOGLE_API_KEY="YOUR_API_KEY"
export GOOGLE_GENAI_USE_VERTEXAI=true
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optionally) Add a billing account on your project to get access to &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/quotas"&gt;higher usage limits&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For other authentication methods, including Google Workspace accounts, see the &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/authentication.md"&gt;authentication&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Once the CLI is running, you can start interacting with Gemini from your shell.&lt;/p&gt; 
&lt;p&gt;You can start a project from a new directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd new-project/
gemini
&amp;gt; Write me a Gemini Discord bot that answers questions using a FAQ.md file I will provide
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or work with an existing project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/google-gemini/gemini-cli
cd gemini-cli
gemini
&amp;gt; Give me a summary of all of the changes that went in yesterday
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Learn how to &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/CONTRIBUTING.md"&gt;contribute to or build from the source&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Explore the available &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/cli/commands.md"&gt;CLI Commands&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you encounter any issues, review the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/troubleshooting.md"&gt;troubleshooting guide&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;For more comprehensive documentation, see the &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/index.md"&gt;full documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Take a look at some &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/#popular-tasks"&gt;popular tasks&lt;/a&gt; for more inspiration.&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/ROADMAP.md"&gt;Official Roadmap&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;Head over to the &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/troubleshooting.md"&gt;troubleshooting guide&lt;/a&gt; if you're having issues.&lt;/p&gt; 
&lt;h2&gt;GitHub Integration&lt;/h2&gt; 
&lt;p&gt;Integrate Gemini CLI directly into your GitHub workflows with the &lt;a href="https://github.com/google-github-actions/run-gemini-cli"&gt;&lt;strong&gt;Gemini CLI GitHub Action&lt;/strong&gt;&lt;/a&gt;. Key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pull Request Reviews&lt;/strong&gt;: Automatically review pull requests when they're opened.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issue Triage&lt;/strong&gt;: Automatically triage and label GitHub issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-demand Collaboration&lt;/strong&gt;: Mention &lt;code&gt;@gemini-cli&lt;/code&gt; in issues and pull requests for assistance and task delegation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Workflows&lt;/strong&gt;: Set up your own scheduled tasks and event-driven automations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Popular tasks&lt;/h2&gt; 
&lt;h3&gt;Explore a new codebase&lt;/h3&gt; 
&lt;p&gt;Start by &lt;code&gt;cd&lt;/code&gt;ing into an existing or newly-cloned repository and running &lt;code&gt;gemini&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Describe the main pieces of this system's architecture.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; What security mechanisms are in place?
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Provide a step-by-step dev onboarding doc for developers new to the codebase.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Summarize this codebase and highlight the most interesting patterns or techniques I could learn from.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Identify potential areas for improvement or refactoring in this codebase, highlighting parts that appear fragile, complex, or hard to maintain.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Which parts of this codebase might be challenging to scale or debug?
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Generate a README section for the [module name] module explaining what it does and how to use it.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; What kind of error handling and logging strategies does the project use?
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Which tools, libraries, and dependencies are used in this project?
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Work with your existing code&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Implement a first draft for GitHub issue #123.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Help me migrate this codebase to the latest version of Java. Start with a plan.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Automate your workflows&lt;/h3&gt; 
&lt;p&gt;Use MCP servers to integrate your local system tools with your enterprise collaboration suite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Make me a slide deck showing the git history from the last 7 days, grouped by feature and team member.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Make a full-screen web app for a wall display to show our most interacted-with GitHub issues.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interact with your system&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Convert all the images in this directory to png, and rename them to use dates from the exif data.
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;gt; Organize my PDF invoices by month of expenditure.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Uninstall&lt;/h3&gt; 
&lt;p&gt;Head over to the &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/Uninstall.md"&gt;Uninstall&lt;/a&gt; guide for uninstallation instructions.&lt;/p&gt; 
&lt;h2&gt;Terms of Service and Privacy Notice&lt;/h2&gt; 
&lt;p&gt;For details on the terms of service and privacy notice applicable to your use of Gemini CLI, see the &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/docs/tos-privacy.md"&gt;Terms of Service and Privacy Notice&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security Disclosures&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/google-gemini/gemini-cli/main/SECURITY.md"&gt;security disclosure process&lt;/a&gt;. All &lt;a href="https://github.com/google-gemini/gemini-cli/security/advisories"&gt;security advisories&lt;/a&gt; are managed on Github.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mui/mui-x</title>
      <link>https://github.com/mui/mui-x</link>
      <description>&lt;p&gt;MUI X: Build complex and data-rich applications using a growing list of advanced React components, like the Data Grid, Date and Time Pickers, Charts, and more!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://mui.com/x/" rel="noopener" target="_blank"&gt;&lt;img width="150" height="133" src="https://mui.com/static/logo.svg?sanitize=true" alt="MUI&amp;nbsp;X logo"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;MUI&amp;nbsp;X&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/mui/mui-x/raw/HEAD/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@mui/x-data-grid"&gt;&lt;img src="https://img.shields.io/npm/v/@mui/x-data-grid/latest.svg?sanitize=true" alt="npm latest package"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@mui/x-data-grid"&gt;&lt;img src="https://img.shields.io/npm/dm/@mui/x-data-grid.svg?sanitize=true" alt="npm downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/mui/mui-x/commits/HEAD/"&gt;&lt;img src="https://img.shields.io/github/checks-status/mui/mui-x/HEAD" alt="GitHub branch status"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/mui/mui-x/"&gt;&lt;img src="https://img.shields.io/codecov/c/github/mui/mui-x.svg?sanitize=true" alt="Coverage status"&gt;&lt;/a&gt; &lt;a href="https://x.com/MUI_X_"&gt;&lt;img src="https://img.shields.io/twitter/follow/MUI_X_.svg?label=follow+MUI+X" alt="Follow on X"&gt;&lt;/a&gt; &lt;a href="https://github.com/mui/mui-x/issues/2081"&gt;&lt;img src="https://img.shields.io/badge/renovate-enabled-brightgreen.svg?sanitize=true" alt="Renovate status"&gt;&lt;/a&gt; &lt;a href="https://isitmaintained.com/project/mui/mui-x" title="Average time to resolve an issue"&gt;&lt;img src="https://isitmaintained.com/badge/resolution/mui/mui-x.svg?sanitize=true" alt="Average time to resolve an issue"&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/mui-org"&gt;&lt;img src="https://img.shields.io/opencollective/all/mui-org" alt="Open&amp;nbsp;Collective backers and sponsors"&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/6293"&gt;&lt;img src="https://www.bestpractices.dev/projects/6293/badge" alt="OpenSSF Best Practices"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://mui.com/x/"&gt;MUI&amp;nbsp;X&lt;/a&gt; is a suite of advanced React UI components for a wide range of complex use cases. Each component provides best-in-class UX and DX, with sophisticated UX workflows for data-rich applications. Components include the Data Grid, Date and Time Pickers, Charts, and Tree&amp;nbsp;View.&lt;/p&gt; 
&lt;p&gt;MUI&amp;nbsp;X extends the core functionality of &lt;a href="https://github.com/mui/material-ui/"&gt;Material&amp;nbsp;UI&lt;/a&gt;, but the advanced components also stand on their own and can be fully customized to meet the needs of any design system.&lt;/p&gt; 
&lt;p&gt;MUI&amp;nbsp;X is &lt;strong&gt;open-core&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/mui/mui-x/master/#community-plan"&gt;Community&lt;/a&gt; components are MIT-licensed and free forever, while more advanced features and components require a &lt;a href="https://raw.githubusercontent.com/mui/mui-x/master/#pro-plan"&gt;Pro&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/mui/mui-x/master/#premium-plan"&gt;Premium&lt;/a&gt; commercial license. See &lt;a href="https://raw.githubusercontent.com/mui/mui-x/master/#licensing"&gt;Licensing&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Get started in the &lt;a href="https://mui.com/x/introduction/"&gt;MUI&amp;nbsp;X documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-data-grid/"&gt;Data Grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-date-pickers/"&gt;Date and Time Pickers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-charts/"&gt;Charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-tree-view/"&gt;Tree View&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-data-grid/quickstart/#installation"&gt;Data Grid installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-date-pickers/quickstart/#installation"&gt;Date and Time Pickers installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-charts/quickstart/#installation"&gt;Charts installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mui.com/x/react-tree-view/quickstart/#installation"&gt;Tree View installation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;The MUI&amp;nbsp;X team has been building MIT-licensed React components since 2014, starting with Material&amp;nbsp;UI, and we're committed to the continued advancement of our open-source libraries. Anything we release under an MIT license will remain MIT-licensed forever. Learn more about &lt;a href="https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd"&gt;our stewardship ethos&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We offer commercial licenses to developers who need the most advanced components and features that can't reasonably be maintained by the open-source community alone. These licenses make it possible for us to support a full-time staff of engineers.&lt;/p&gt; 
&lt;p&gt;Rest assured that when we release features commercially, it's only because we believe you won't find a better MIT-licensed alternative anywhere else.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://mui.com/x/introduction/licensing/"&gt;Licensing page&lt;/a&gt; for complete details.&lt;/p&gt; 
&lt;h3&gt;Plans&lt;/h3&gt; 
&lt;h4&gt;Community plan&lt;/h4&gt; 
&lt;p&gt;The free Community version of MUI&amp;nbsp;X contains components and features that we believe are maintainable by contributions from the open-source community. It's published under an &lt;a href="https://www.tldrlegal.com/license/mit-license"&gt;MIT license&lt;/a&gt; and it's &lt;a href="https://mui-org.notion.site/Stewardship-542a2226043d4f4a96dfb429d16cf5bd#20f609acab4441cf9346614119fbbac1"&gt;free forever&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-data-grid"&gt;&lt;code&gt;@mui/x-data-grid&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-date-pickers"&gt;&lt;code&gt;@mui/x-date-pickers&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-charts"&gt;&lt;code&gt;@mui/x-charts&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-tree-view"&gt;&lt;code&gt;@mui/x-tree-view&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Pro plan&lt;/h4&gt; 
&lt;p&gt;MUI&amp;nbsp;X Pro expands on the Community version with more advanced features and functionality. The Data Grid Pro comes with multi-filtering, multi-sorting, column resizing, and column pinning; you also gain access to the Date and Time Range Picker components, advanced Charts, and drag-and-drop reordering for the Tree View.&lt;/p&gt; 
&lt;p&gt;The Pro version is available under a commercial license‚Äîvisit the &lt;a href="https://mui.com/pricing/"&gt;Pricing page&lt;/a&gt; for details.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-data-grid-pro"&gt;&lt;code&gt;@mui/x-data-grid-pro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-date-pickers-pro"&gt;&lt;code&gt;@mui/x-date-pickers-pro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-charts-pro"&gt;&lt;code&gt;@mui/x-charts-pro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-tree-view-pro"&gt;&lt;code&gt;@mui/x-tree-view-pro&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Premium plan&lt;/h4&gt; 
&lt;p&gt;MUI&amp;nbsp;X Premium unlocks the most advanced features of the Data Grid, including row grouping and Excel exporting, as well as everything offered in the Pro plan.&lt;/p&gt; 
&lt;p&gt;The Premium version is available under a commercial license‚Äîvisit the &lt;a href="https://mui.com/pricing/"&gt;Pricing page&lt;/a&gt; for details.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/@mui/x-data-grid-premium"&gt;&lt;code&gt;@mui/x-data-grid-premium&lt;/code&gt;&lt;/a&gt; 
  &lt;!-- TODO: CHARTS-PREMIUM: uncomment when ready --&gt; 
  &lt;!-- - [`@mui/x-charts-premium`](https://www.npmjs.com/package/@mui/x-charts-premium) --&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;From community guidance to critical business support, we're here to help. Read the &lt;a href="https://mui.com/x/introduction/support/"&gt;Support guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/mui/mui-x/master/CONTRIBUTING.md"&gt;Contributing guide&lt;/a&gt; to learn about our development process, how to propose bug fixes and improvements, and how to build and test your changes.&lt;/p&gt; 
&lt;p&gt;Contributing to MUI&amp;nbsp;X is about more than just issues and pull requests! There are many other ways to &lt;a href="https://mui.com/material-ui/getting-started/faq/#mui-is-an-awesome-organization-how-can-i-support-it"&gt;support MUI&amp;nbsp;X&lt;/a&gt; beyond contributing to the code base.&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/mui/mui-x/releases"&gt;changelog&lt;/a&gt; is regularly updated to reflect what's changed in each new release.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Future plans and high-priority features and enhancements can be found in the &lt;a href="https://mui.com/x/introduction/roadmap/"&gt;roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;For details on supported versions and contact information for reporting security issues, please refer to the &lt;a href="https://github.com/mui/mui-x/security/policy"&gt;security policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>