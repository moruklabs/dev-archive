<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Tue, 03 Feb 2026 01:41:35 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>karpathy/nanochat</title>
      <link>https://github.com/karpathy/nanochat</link>
      <description>&lt;p&gt;The best ChatGPT that $100 can buy.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nanochat&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/nanochat/master/dev/nanochat.png" alt="nanochat logo" /&gt; &lt;img src="https://raw.githubusercontent.com/karpathy/nanochat/master/dev/scaling_laws_jan26.png" alt="scaling laws" /&gt;&lt;/p&gt; 
&lt;p&gt;nanochat is the simplest experimental harness for training LLMs. It is designed to run on a single GPU node, the code is minimal/hackable, and it covers all major LLM stages including tokenization, pretraining, finetuning, evaluation, inference, and a chat UI. For example, you can train your own GPT-2 capability LLM (which cost ~$50,000 to train in 2019) for only $73 (3 hours of 8XH100 GPU node) and then talk to it in a familiar ChatGPT-like web UI.&lt;/p&gt; 
&lt;p&gt;For questions about the repo, I recommend either using &lt;a href="https://deepwiki.com/karpathy/nanochat"&gt;DeepWiki&lt;/a&gt; from Devin/Cognition to ask questions about the repo, or use the &lt;a href="https://github.com/karpathy/nanochat/discussions"&gt;Discussions tab&lt;/a&gt;, or come by the &lt;a href="https://discord.com/channels/1020383067459821711/1427295580895314031"&gt;#nanochat&lt;/a&gt; channel on Discord.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;(Jan 31 2026) Major revamp of all scripts/README ongoing, deleting midtraining stage, might be a bit messy briefly...&lt;/li&gt; 
 &lt;li&gt;(Jan 30 2026) With all the latest improvements we're able to train GPT-2 grade LLM in about $73. The &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/speedrun.sh"&gt;runs/speedrun.sh&lt;/a&gt; script will become the refernece way to train GPT-2 grade model and talk to it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Leaderboard&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Record time&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Commit&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;3.04 hours&lt;/td&gt; 
   &lt;td&gt;d24 baseline, slightly overtrained&lt;/td&gt; 
   &lt;td&gt;Jan 29 2026&lt;/td&gt; 
   &lt;td&gt;348fbb3&lt;/td&gt; 
   &lt;td&gt;@karpathy&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The primary metric we care about is "time to GPT-2" - the wall clock time needed to outperform the GPT-2 (1.6B) CORE metric on an 8XH100 GPU node. In 2019, the training of GPT-2 cost approximately $50,000 so it is incredible that due to many advances over 7 years across the stack, we can now do so in 3 hours or less, for ~$73 and below. Once your repo is set up (see the &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/speedrun.sh"&gt;runs/speedrun.sh&lt;/a&gt; script for reference), e.g. the way I kicked off the jan29 run is as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OMP_NUM_THREADS=1 torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- \
    --depth=24 \
    --run=d24-jan29 \
    --model-tag=d24_jan29 \
    --device-batch-size=16 \
    --sample-every=-1 \
    --save-every=-1 \
    --core-metric-max-per-task=-1 \
    --core-metric-every=3000 \
    --target-param-data-ratio=12
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After 3 hours we get output like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;...
wandb: Run summary:
wandb:          core_metric 0.25851
wandb:                 step 16704
wandb: total_training_flops 4.330784131228946e+19
wandb:  total_training_time 10949.46713
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The GPT-2 CORE score (i.e. the target to beat) is 0.256525. So we see that this d24 CORE score is higher (0.25851). Then we look at the &lt;code&gt;total_training_time&lt;/code&gt;, which is the time of the training iterations alone, excluding all the evaluations and logging, in seconds. We get: &lt;code&gt;10949/60/60 ~= 3.04&lt;/code&gt; hours, the current record.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Reproduce and talk to GPT-2&lt;/h3&gt; 
&lt;p&gt;The most fun you can have is to train your own GPT-2 and talk to it. The entire pipeline to do so is contained in the single file &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/speedrun.sh"&gt;runs/speedrun.sh&lt;/a&gt;, which is designed to be run on an 8XH100 GPU node. Currently, at ~$24/hour for these nodes, pretraining GPT-2 grade model takes approximately 3 hours and will set you back about $75. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like &lt;a href="https://lambda.ai/service/gpu-cloud"&gt;Lambda&lt;/a&gt;), and kick off the training script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash runs/speedrun.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You mish to do so in a screen session as this will take ~3 hours to run. Once it's done, you can talk to it via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run &lt;code&gt;source .venv/bin/activate&lt;/code&gt;), and serve it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m scripts.chat_web
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example &lt;a href="http://209.20.xxx.xxx:8000/"&gt;http://209.20.xxx.xxx:8000/&lt;/a&gt;, etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;img width="2672" height="1520" alt="image" src="https://github.com/user-attachments/assets/ed39ddf8-2370-437a-bedc-0f39781e76b5" /&gt; 
&lt;hr /&gt; 
&lt;p&gt;A few more notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.&lt;/li&gt; 
 &lt;li&gt;All code will run just fine on even a single GPU by omitting &lt;code&gt;torchrun&lt;/code&gt;, and will produce ~identical results (code will automatically switch to gradient accumulation), but you'll have to wait 8 times longer.&lt;/li&gt; 
 &lt;li&gt;If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for &lt;code&gt;--device_batch_size&lt;/code&gt; in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you'll have to know a bit more what you're doing and get more creative.&lt;/li&gt; 
 &lt;li&gt;Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven't personally exercised all of these code paths so there might be sharp edges.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Research&lt;/h2&gt; 
&lt;p&gt;If you are a researcher and wish to help improve nanochat, two scripts of interest are &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/scaling_laws.sh"&gt;runs/scaling_laws.sh&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/miniseries.sh"&gt;runs/miniseries.sh&lt;/a&gt;. See &lt;a href="https://github.com/karpathy/nanochat/discussions/420"&gt;Jan 7 miniseries v1&lt;/a&gt; for related documentation. For quick experimentation (~5 min pretraining runs) my favorite scale is to train a 12-layer model (GPT-1 sized), e.g. like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OMP_NUM_THREADS=1 torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- \
    --depth=12 \
    --run="d12" \
    --model-tag="d12" \
    --core-metric-every=999999 \
    --sample-every=-1 \
    --save-every=-1 \
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This uses wandb (run name "d12"), only runs the CORE metric on last step, and it doesn't sample and save intermediate checkpoints. I like to change something in the code, re-run a d12 (or a d16 etc) and see if it helped, in an iteration loop.&lt;/p&gt; 
&lt;p&gt;The overall approach is to treat the depth of the model as the single dial of complexity. By sweeping out the depth, we get increasingly more powerful models. We determine the scaling laws, set the data budget to a compute optimal setting, train a whole miniseries of models of increasing sizes, and compare them to the GPT-2 and GPT-3 miniseries. Right now, beating GPT-2 specifically faster and faster is the most interesting target.&lt;/p&gt; 
&lt;h2&gt;Running on CPU / MPS&lt;/h2&gt; 
&lt;p&gt;The script &lt;a href="https://raw.githubusercontent.com/karpathy/nanochat/master/runs/runcpu.sh"&gt;runs/runcpu.sh&lt;/a&gt; shows a very simple example of running on CPU or Apple Silicon. It dramatically shrinks the LLM tha tis being trained to make things fit into a reasonable time interval of a few ten minutes of training. You will not get strong results in this way.&lt;/p&gt; 
&lt;h2&gt;Guides&lt;/h2&gt; 
&lt;p&gt;I've published a number of guides that might contain helpful information:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karpathy/nanochat/discussions/1"&gt;Oct 13 2025 original nanochat post&lt;/a&gt; introducing nanochat, though now it contains some deprecated information and the model is a lot older (with worse results) than current master.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/karpathy/nanochat/discussions/420"&gt;Jan 7 miniseries v1&lt;/a&gt; documents the first nanochat miniseries of models.&lt;/li&gt; 
 &lt;li&gt;To customize your nanochat, see &lt;a href="https://github.com/karpathy/nanochat/discussions/139"&gt;Guide: infusing identity to your nanochat&lt;/a&gt; in Discussions, which describes how you can tune your nanochat's personality through synthetic data generation and mixing that data into the SFT stage.&lt;/li&gt; 
 &lt;li&gt;To add new abilities to nanochat, see &lt;a href="https://github.com/karpathy/nanochat/discussions/164"&gt;Guide: counting r in strawberry (and how to add abilities generally)&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;File structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;.
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dev
‚îÇ   ‚îú‚îÄ‚îÄ gen_synthetic_data.py       # Example synthetic data for identity
‚îÇ   ‚îú‚îÄ‚îÄ generate_logo.html
‚îÇ   ‚îú‚îÄ‚îÄ nanochat.png
‚îÇ   ‚îî‚îÄ‚îÄ repackage_data_reference.py # Pretraining data shard generation
‚îú‚îÄ‚îÄ nanochat
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # empty
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_manager.py       # Save/Load model checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # Misc small utilities, quality of life
‚îÇ   ‚îú‚îÄ‚îÄ core_eval.py                # Evaluates base model CORE score (DCLM paper)
‚îÇ   ‚îú‚îÄ‚îÄ dataloader.py               # Tokenizing Distributed Data Loader
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                  # Download/read utils for pretraining data
‚îÇ   ‚îú‚îÄ‚îÄ engine.py                   # Efficient model inference with KV Cache
‚îÇ   ‚îú‚îÄ‚îÄ execution.py                # Allows the LLM to execute Python code as tool
‚îÇ   ‚îú‚îÄ‚îÄ gpt.py                      # The GPT nn.Module Transformer
‚îÇ   ‚îú‚îÄ‚îÄ logo.svg
‚îÇ   ‚îú‚îÄ‚îÄ loss_eval.py                # Evaluate bits per byte (instead of loss)
‚îÇ   ‚îú‚îÄ‚îÄ optim.py                    # AdamW + Muon optimizer, 1GPU and distributed
‚îÇ   ‚îú‚îÄ‚îÄ report.py                   # Utilities for writing the nanochat Report
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py                # BPE Tokenizer wrapper in style of GPT-4
‚îÇ   ‚îî‚îÄ‚îÄ ui.html                     # HTML/CSS/JS for nanochat frontend
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ runs
‚îÇ   ‚îú‚îÄ‚îÄ miniseries.sh               # Miniseries training script
‚îÇ   ‚îú‚îÄ‚îÄ runcpu.sh                   # Small example of how to run on CPU/MPS
‚îÇ   ‚îú‚îÄ‚îÄ scaling_laws.sh             # Scaling laws experiments
‚îÇ   ‚îî‚îÄ‚îÄ speedrun.sh                 # Train the ~$100 nanochat d20
‚îú‚îÄ‚îÄ scripts
‚îÇ   ‚îú‚îÄ‚îÄ base_eval.py                # Base model: CORE score, bits per byte, samples
‚îÇ   ‚îú‚îÄ‚îÄ base_train.py               # Base model: train
‚îÇ   ‚îú‚îÄ‚îÄ chat_cli.py                 # Chat model: talk to over CLI
‚îÇ   ‚îú‚îÄ‚îÄ chat_eval.py                # Chat model: eval tasks
‚îÇ   ‚îú‚îÄ‚îÄ chat_rl.py                  # Chat model: reinforcement learning
‚îÇ   ‚îú‚îÄ‚îÄ chat_sft.py                 # Chat model: train SFT
‚îÇ   ‚îú‚îÄ‚îÄ chat_web.py                 # Chat model: talk to over WebUI
‚îÇ   ‚îú‚îÄ‚îÄ tok_eval.py                 # Tokenizer: evaluate compression rate
‚îÇ   ‚îî‚îÄ‚îÄ tok_train.py                # Tokenizer: train it
‚îú‚îÄ‚îÄ tasks
‚îÇ   ‚îú‚îÄ‚îÄ arc.py                      # Multiple choice science questions
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # TaskMixture | TaskSequence
‚îÇ   ‚îú‚îÄ‚îÄ customjson.py               # Make Task from arbitrary jsonl convos
‚îÇ   ‚îú‚îÄ‚îÄ gsm8k.py                    # 8K Grade School Math questions
‚îÇ   ‚îú‚îÄ‚îÄ humaneval.py                # Misnomer; Simple Python coding task
‚îÇ   ‚îú‚îÄ‚îÄ mmlu.py                     # Multiple choice questions, broad topics
‚îÇ   ‚îú‚îÄ‚îÄ smoltalk.py                 # Conglomerate dataset of SmolTalk from HF
‚îÇ   ‚îî‚îÄ‚îÄ spellingbee.py              # Task teaching model to spell/count letters
‚îú‚îÄ‚îÄ tests
‚îÇ   ‚îî‚îÄ‚îÄ test_engine.py
‚îî‚îÄ‚îÄ uv.lock
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The goal of nanochat is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &amp;lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM "framework"; there are no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable "strong baseline" codebase designed to run start to end and produce a ChatGPT model you can talk to. Currently, the most interesting part personally is speeding up the latency to GPT-2 (i.e. getting a CORE score above 0.256525). Currently this takes ~3 hours, but by improving the pretraining stage we can improve this further.&lt;/p&gt; 
&lt;p&gt;Current AI policy: disclosure. When submitting a PR, please declare any parts that had substantial LLM contribution and that you have not written or that you do not fully understand.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The name (nanochat) derives from my earlier project &lt;a href="https://github.com/karpathy/nanoGPT"&gt;nanoGPT&lt;/a&gt;, which only covered pretraining.&lt;/li&gt; 
 &lt;li&gt;nanochat is also inspired by &lt;a href="https://github.com/KellerJordan/modded-nanogpt"&gt;modded-nanoGPT&lt;/a&gt;, which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.&lt;/li&gt; 
 &lt;li&gt;Thank you to &lt;a href="https://huggingface.co/"&gt;HuggingFace&lt;/a&gt; for fineweb and smoltalk.&lt;/li&gt; 
 &lt;li&gt;Thank you &lt;a href="https://lambda.ai/service/gpu-cloud"&gt;Lambda&lt;/a&gt; for the compute used in developing this project.&lt;/li&gt; 
 &lt;li&gt;Thank you to chief LLM whisperer üßô‚Äç‚ôÇÔ∏è Alec Radford for advice/guidance.&lt;/li&gt; 
 &lt;li&gt;Thank you to the repo czar Sofie &lt;a href="https://github.com/svlandeg"&gt;@svlandeg&lt;/a&gt; for help with managing issues, pull requests and discussions of nanochat.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cite&lt;/h2&gt; 
&lt;p&gt;If you find nanochat helpful in your research cite simply as:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that \$100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kovidgoyal/calibre</title>
      <link>https://github.com/kovidgoyal/calibre</link>
      <description>&lt;p&gt;The official source code repository for the calibre ebook manager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;calibre&lt;/h1&gt; 
&lt;img align="left" src="https://raw.githubusercontent.com/kovidgoyal/calibre/master/resources/images/lt.png" height="200" width="200" /&gt; 
&lt;p&gt;calibre is an e-book manager. It can view, convert, edit and catalog e-books in all of the major e-book formats. It can also talk to e-book reader devices. It can go out to the internet and fetch metadata for your books. It can download newspapers and convert them into e-books for convenient reading. It is cross platform, running on Linux, Windows and macOS.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://calibre-ebook.com/about"&gt;calibre About page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kovidgoyal/calibre/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/kovidgoyal/calibre/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://calibre-ebook.com/demo"&gt;Screenshots page&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://manual.calibre-ebook.com"&gt;User Manual&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://manual.calibre-ebook.com/develop.html"&gt;Setting up a development environment for calibre&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://calibre-ebook.com/dist/src"&gt;tarball of the source code&lt;/a&gt; for the current calibre release.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Bug reports and feature requests should be made in the calibre bug tracker at &lt;a href="https://bugs.launchpad.net/calibre"&gt;Launchpad&lt;/a&gt;. GitHub is only used for code hosting and pull requests.&lt;/p&gt; 
&lt;h2&gt;Support calibre&lt;/h2&gt; 
&lt;p&gt;calibre is a result of the efforts of many volunteers from all over the world. If you find it useful, please consider contributing to support its development. &lt;a href="https://calibre-ebook.com/donate"&gt;Donate to support calibre development&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Building calibre binaries&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/kovidgoyal/calibre/master/bypy/README.rst"&gt;Build instructions&lt;/a&gt; for instructions on how to build the calibre binaries and installers for all the platforms calibre supports.&lt;/p&gt; 
&lt;h2&gt;calibre package versions in various repositories&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/calibre/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/calibre.svg?columns=3&amp;amp;header=calibre" alt="Packaging Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lllyasviel/Fooocus</title>
      <link>https://github.com/lllyasviel/Fooocus</link>
      <description>&lt;p&gt;Focus on prompting and generating&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/483fb86d-c9a2-4c20-997c-46dafc124f25" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Fooocus&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#download"&gt;&amp;gt;&amp;gt;&amp;gt; Click Here to Install Fooocus &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Fooocus is an image generating software (based on &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; &lt;a href="https://github.com/gradio-app/gradio"&gt;&lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Fooocus presents a rethinking of image generator designs. The software is offline, open source, and free, while at the same time, similar to many online image generators like Midjourney, the manual tweaking is not needed, and users only need to focus on the prompts and images. Fooocus has also simplified the installation: between pressing "download" and generating the first image, the number of needed mouse clicks is strictly limited to less than 3. Minimal GPU memory requirement is 4GB (Nvidia).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Recently many fake websites exist on Google when you search ‚Äúfooocus‚Äù. Do not trust those ‚Äì here is the only official source of Fooocus.&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Project Status: Limited Long-Term Support (LTS) with Bug Fixes Only&lt;/h1&gt; 
&lt;p&gt;The Fooocus project, built entirely on the &lt;strong&gt;Stable Diffusion XL&lt;/strong&gt; architecture, is now in a state of limited long-term support (LTS) with bug fixes only. As the existing functionalities are considered as nearly free of programmartic issues (Thanks to &lt;a href="https://github.com/mashb1t"&gt;mashb1t&lt;/a&gt;'s huge efforts), future updates will focus exclusively on addressing any bugs that may arise.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are no current plans to migrate to or incorporate newer model architectures.&lt;/strong&gt; However, this may change during time with the development of open-source community. For example, if the community converge to one single dominant method for image generation (which may really happen in half or one years given the current status), Fooocus may also migrate to that exact method.&lt;/p&gt; 
&lt;p&gt;For those interested in utilizing newer models such as &lt;strong&gt;Flux&lt;/strong&gt;, we recommend exploring alternative platforms such as &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge"&gt;WebUI Forge&lt;/a&gt; (also from us), &lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI/SwarmUI&lt;/a&gt;. Additionally, several &lt;a href="https://github.com/lllyasviel/Fooocus?tab=readme-ov-file#forks"&gt;excellent forks of Fooocus&lt;/a&gt; are available for experimentation.&lt;/p&gt; 
&lt;p&gt;Again, recently many fake websites exist on Google when you search ‚Äúfooocus‚Äù. Do &lt;strong&gt;NOT&lt;/strong&gt; get Fooocus from those websites ‚Äì this page is the only official source of Fooocus. We never have any website like such as ‚Äúfooocus.com‚Äù, ‚Äúfooocus.net‚Äù, ‚Äúfooocus.co‚Äù, ‚Äúfooocus.ai‚Äù, ‚Äúfooocus.org‚Äù, ‚Äúfooocus.pro‚Äù, ‚Äúfooocus.one‚Äù. Those websites are ALL FAKE. &lt;strong&gt;They have ABSOLUTLY no relationship to us. Fooocus is a 100% non-commercial offline open-source software.&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;p&gt;Below is a quick list using Midjourney's examples:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Midjourney&lt;/th&gt; 
   &lt;th&gt;Fooocus&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High-quality text-to-image without needing much prompt engineering or parameter tuning. &lt;br /&gt; (Unknown method)&lt;/td&gt; 
   &lt;td&gt;High-quality text-to-image without needing much prompt engineering or parameter tuning. &lt;br /&gt; (Fooocus has an offline GPT-2 based prompt processing engine and lots of sampling improvements so that results are always beautiful, no matter if your prompt is as short as ‚Äúhouse in garden‚Äù or as long as 1000 words)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;V1 V2 V3 V4&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Upscale or Variation -&amp;gt; Vary (Subtle) / Vary (Strong)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;U1 U2 U3 U4&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Upscale or Variation -&amp;gt; Upscale (1.5x) / Upscale (2x)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Inpaint / Up / Down / Left / Right (Pan)&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Inpaint or Outpaint -&amp;gt; Inpaint / Up / Down / Left / Right &lt;br /&gt; (Fooocus uses its own inpaint algorithm and inpaint models so that results are more satisfying than all other software that uses standard SDXL inpaint method/model)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Image Prompt&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt &lt;br /&gt; (Fooocus uses its own image prompt algorithm so that result quality and prompt understanding are more satisfying than all other software that uses standard SDXL methods like standard IP-Adapters or Revisions)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--style&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Style&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--stylize&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Advanced -&amp;gt; Guidance&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--niji&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/discussions/679"&gt;Multiple launchers: "run.bat", "run_anime.bat", and "run_realistic.bat".&lt;/a&gt; &lt;br /&gt; Fooocus support SDXL models on Civitai &lt;br /&gt; (You can google search ‚ÄúCivitai‚Äù if you do not know about it)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--quality&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Quality&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--repeat&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Image Number&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi Prompts (::)&lt;/td&gt; 
   &lt;td&gt;Just use multiple lines of prompts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prompt Weights&lt;/td&gt; 
   &lt;td&gt;You can use " I am (happy:1.5)". &lt;br /&gt; Fooocus uses A1111's reweighting algorithm so that results are better than ComfyUI if users directly copy prompts from Civitai. (Because if prompts are written in ComfyUI's reweighting, users are less likely to copy prompt texts as they prefer dragging files) &lt;br /&gt; To use embedding, you can use "(embedding:file_name:1.1)"&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--no&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Negative Prompt&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;--ar&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Aspect Ratios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;InsightFace&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt -&amp;gt; Advanced -&amp;gt; FaceSwap&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Describe&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Describe&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Below is a quick list using LeonardoAI's examples:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;LeonardoAI&lt;/th&gt; 
   &lt;th&gt;Fooocus&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prompt Magic&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Style -&amp;gt; Fooocus V2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Advanced Sampler Parameters (like Contrast/Sharpness/etc)&lt;/td&gt; 
   &lt;td&gt;Advanced -&amp;gt; Advanced -&amp;gt; Sampling Sharpness / etc&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User-friendly ControlNets&lt;/td&gt; 
   &lt;td&gt;Input Image -&amp;gt; Image Prompt -&amp;gt; Advanced&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Also, &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117"&gt;click here to browse the advanced features.&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Download&lt;/h1&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;You can directly download Fooocus with:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/releases/download/v2.5.0/Fooocus_win64_2-5-0.7z"&gt;&amp;gt;&amp;gt;&amp;gt; Click here to download &amp;lt;&amp;lt;&amp;lt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;After you download the file, please uncompress it and then run the "run.bat".&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/c49269c4-c274-4893-b368-047c401cc58c" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;The first time you launch the software, it will automatically download models:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;It will download &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#models"&gt;default models&lt;/a&gt; to the folder "Fooocus\models\checkpoints" given different presets. You can download them in advance if you do not want automatic download.&lt;/li&gt; 
 &lt;li&gt;Note that if you use inpaint, at the first time you inpaint an image, it will download &lt;a href="https://huggingface.co/lllyasviel/fooocus_inpaint/resolve/main/inpaint_v26.fooocus.patch"&gt;Fooocus's own inpaint control model from here&lt;/a&gt; as the file "Fooocus\models\inpaint\inpaint_v26.fooocus.patch" (the size of this file is 1.28GB).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After Fooocus 2.1.60, you will also have &lt;code&gt;run_anime.bat&lt;/code&gt; and &lt;code&gt;run_realistic.bat&lt;/code&gt;. They are different model presets (and require different models, but they will be automatically downloaded). &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/679"&gt;Check here for more details&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After Fooocus 2.3.0 you can also switch presets directly in the browser. Keep in mind to add these arguments if you want to change the default behavior:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;--disable-preset-selection&lt;/code&gt; to disable preset selection in the browser.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--always-download-new-model&lt;/code&gt; to download missing models on preset switch. Default is fallback to &lt;code&gt;previous_default_models&lt;/code&gt; defined in the corresponding preset, also see terminal output.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/d386f817-4bd7-490c-ad89-c1e228c23447" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;If you already have these files, you can copy them to the above locations to speed up installation.&lt;/p&gt; 
&lt;p&gt;Note that if you see &lt;strong&gt;"MetadataIncompleteBuffer" or "PytorchStreamReader"&lt;/strong&gt;, then your model files are corrupted. Please download models again.&lt;/p&gt; 
&lt;p&gt;Below is a test on a relatively low-end laptop with &lt;strong&gt;16GB System RAM&lt;/strong&gt; and &lt;strong&gt;6GB VRAM&lt;/strong&gt; (Nvidia 3060 laptop). The speed on this machine is about 1.35 seconds per iteration. Pretty impressive ‚Äì nowadays laptops with 3060 are usually at very acceptable price.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/938737a5-b105-4f19-b051-81356cb7c495" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;Besides, recently many other software report that Nvidia driver above 532 is sometimes 10x slower than Nvidia driver 531. If your generation time is very long, consider download &lt;a href="https://www.nvidia.com/download/driverResults.aspx/199991/en-us/"&gt;Nvidia Driver 531 Laptop&lt;/a&gt; or &lt;a href="https://www.nvidia.com/download/driverResults.aspx/199990/en-us/"&gt;Nvidia Driver 531 Desktop&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Note that the minimal requirement is &lt;strong&gt;4GB Nvidia GPU memory (4GB VRAM)&lt;/strong&gt; and &lt;strong&gt;8GB system memory (8GB RAM)&lt;/strong&gt;. This requires using Microsoft‚Äôs Virtual Swap technique, which is automatically enabled by your Windows installation in most cases, so you often do not need to do anything about it. However, if you are not sure, or if you manually turned it off (would anyone really do that?), or &lt;strong&gt;if you see any "RuntimeError: CPUAllocator"&lt;/strong&gt;, you can enable it here:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click here to see the image instructions. &lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://github.com/lllyasviel/Fooocus/assets/19834515/2a06b130-fe9b-4504-94f1-2763be4476e9" alt="image" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;And make sure that you have at least 40GB free space on each drive if you still see "RuntimeError: CPUAllocator" !&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Please open an issue if you use similar devices but still cannot achieve acceptable performances.&lt;/p&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;See also the common problems and troubleshoots &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Colab&lt;/h3&gt; 
&lt;p&gt;(Last tested - 2024 Aug 12 by &lt;a href="https://github.com/mashb1t"&gt;mashb1t&lt;/a&gt;)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Colab&lt;/th&gt; 
   &lt;th&gt;Info&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Fooocus Official&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;In Colab, you can modify the last line to &lt;code&gt;!python entry_with_update.py --share --always-high-vram&lt;/code&gt; or &lt;code&gt;!python entry_with_update.py --share --always-high-vram --preset anime&lt;/code&gt; or &lt;code&gt;!python entry_with_update.py --share --always-high-vram --preset realistic&lt;/code&gt; for Fooocus Default/Anime/Realistic Edition.&lt;/p&gt; 
&lt;p&gt;You can also change the preset in the UI. Please be aware that this may lead to timeouts after 60 seconds. If this is the case, please wait until the download has finished, change the preset to initial and back to the one you've selected or reload the page.&lt;/p&gt; 
&lt;p&gt;Note that this Colab will disable refiner by default because Colab free's resources are relatively limited (and some "big" features like image prompt may cause free-tier Colab to disconnect). We make sure that basic text-to-image is always working on free-tier Colab.&lt;/p&gt; 
&lt;p&gt;Using &lt;code&gt;--always-high-vram&lt;/code&gt; shifts resource allocation from RAM to VRAM and achieves the overall best balance between performance, flexibility and stability on the default T4 instance. Please find more information &lt;a href="https://github.com/lllyasviel/Fooocus/pull/1710#issuecomment-1989185346"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/camenduru"&gt;camenduru&lt;/a&gt; for the template!&lt;/p&gt; 
&lt;h3&gt;Linux (Using Anaconda)&lt;/h3&gt; 
&lt;p&gt;If you want to use Anaconda/Miniconda, you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
conda env create -f environment.yaml
conda activate fooocus
pip install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then download the models: download &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#models"&gt;default models&lt;/a&gt; to the folder "Fooocus\models\checkpoints". &lt;strong&gt;Or let Fooocus automatically download the models&lt;/strong&gt; using the launcher:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda activate fooocus
python entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;conda activate fooocus
python entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (Using Python Venv)&lt;/h3&gt; 
&lt;p&gt;Your Linux needs to have &lt;strong&gt;Python 3.10&lt;/strong&gt; installed, and let's say your Python can be called with the command &lt;strong&gt;python3&lt;/strong&gt; with your venv system working; you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
python3 -m venv fooocus_env
source fooocus_env/bin/activate
pip install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the above sections for model downloads. You can launch the software with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source fooocus_env/bin/activate
python entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;source fooocus_env/bin/activate
python entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (Using native system Python)&lt;/h3&gt; 
&lt;p&gt;If you know what you are doing, and your Linux already has &lt;strong&gt;Python 3.10&lt;/strong&gt; installed, and your Python can be called with the command &lt;strong&gt;python3&lt;/strong&gt; (and Pip with &lt;strong&gt;pip3&lt;/strong&gt;), you can&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git
cd Fooocus
pip3 install -r requirements_versions.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the above sections for model downloads. You can launch the software with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 entry_with_update.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you want to open a remote port, use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 entry_with_update.py --listen
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Linux (AMD GPUs)&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Same with the above instructions. You need to change torch to the AMD version&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip uninstall torch torchvision torchaudio torchtext functorch xformers 
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;AMD is not intensively tested, however. The AMD support is in beta.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Windows (AMD GPUs)&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Same with Windows. Download the software and edit the content of &lt;code&gt;run.bat&lt;/code&gt; as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -m pip uninstall torch torchvision torchaudio torchtext functorch xformers -y
.\python_embeded\python.exe -m pip install torch-directml
.\python_embeded\python.exe -s Fooocus\entry_with_update.py --directml
pause
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the &lt;code&gt;run.bat&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;AMD is not intensively tested, however. The AMD support is in beta.&lt;/p&gt; 
&lt;p&gt;For AMD, use &lt;code&gt;.\python_embeded\python.exe Fooocus\entry_with_update.py --directml --preset anime&lt;/code&gt; or &lt;code&gt;.\python_embeded\python.exe Fooocus\entry_with_update.py --directml --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Mac&lt;/h3&gt; 
&lt;p&gt;Note that the &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/#minimal-requirement"&gt;minimal requirement&lt;/a&gt; for different platforms is different.&lt;/p&gt; 
&lt;p&gt;Mac is not intensively tested. Below is an unofficial guideline for using Mac. You can discuss problems &lt;a href="https://github.com/lllyasviel/Fooocus/pull/129"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can install Fooocus on Apple Mac silicon (M1 or M2) with macOS 'Catalina' or a newer version. Fooocus runs on Apple silicon computers via &lt;a href="https://pytorch.org/get-started/locally/"&gt;PyTorch&lt;/a&gt; MPS device acceleration. Mac Silicon computers don't come with a dedicated graphics card, resulting in significantly longer image processing times compared to computers with dedicated graphics cards.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the conda package manager and pytorch nightly. Read the &lt;a href="https://developer.apple.com/metal/pytorch/"&gt;Accelerated PyTorch training on Mac&lt;/a&gt; Apple Developer guide for instructions. Make sure pytorch recognizes your MPS device.&lt;/li&gt; 
 &lt;li&gt;Open the macOS Terminal app and clone this repository with &lt;code&gt;git clone https://github.com/lllyasviel/Fooocus.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Change to the new Fooocus directory, &lt;code&gt;cd Fooocus&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Create a new conda environment, &lt;code&gt;conda env create -f environment.yaml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Activate your new conda environment, &lt;code&gt;conda activate fooocus&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install the packages required by Fooocus, &lt;code&gt;pip install -r requirements_versions.txt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Launch Fooocus by running &lt;code&gt;python entry_with_update.py&lt;/code&gt;. (Some Mac M2 users may need &lt;code&gt;python entry_with_update.py --disable-offload-from-vram&lt;/code&gt; to speed up model loading/unloading.) The first time you run Fooocus, it will automatically download the Stable Diffusion SDXL models and will take a significant amount of time, depending on your internet connection.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Use &lt;code&gt;python entry_with_update.py --preset anime&lt;/code&gt; or &lt;code&gt;python entry_with_update.py --preset realistic&lt;/code&gt; for Fooocus Anime/Realistic Edition.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/docker.md"&gt;docker.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Download Previous Version&lt;/h3&gt; 
&lt;p&gt;See the guidelines &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/1405"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Minimal Requirement&lt;/h2&gt; 
&lt;p&gt;Below is the minimal requirement for running Fooocus locally. If your device capability is lower than this spec, you may not be able to use Fooocus locally. (Please let us know, in any case, if your device capability is lower but Fooocus still works.)&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;GPU&lt;/th&gt; 
   &lt;th&gt;Minimal GPU Memory&lt;/th&gt; 
   &lt;th&gt;Minimal System Memory&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;System Swap&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 4XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;fastest&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 3XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;usually faster than RTX 2XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia RTX 2XXX&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;usually faster than GTX 1XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX 1XXX&lt;/td&gt; 
   &lt;td&gt;8GB (* 6GB uncertain)&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;only marginally faster than CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX 9XX&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;faster or slower than CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux&lt;/td&gt; 
   &lt;td&gt;Nvidia GTX &amp;lt; 9XX&lt;/td&gt; 
   &lt;td&gt;Not supported&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;/&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
   &lt;td&gt;8GB (updated 2023 Dec 30)&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;via DirectML (* ROCm is on hold), about 3x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;8GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;via ROCm, about 1.5x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mac&lt;/td&gt; 
   &lt;td&gt;M1/M2 MPS&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;Shared&lt;/td&gt; 
   &lt;td&gt;about 9x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/Linux/Mac&lt;/td&gt; 
   &lt;td&gt;only use CPU&lt;/td&gt; 
   &lt;td&gt;0GB&lt;/td&gt; 
   &lt;td&gt;32GB&lt;/td&gt; 
   &lt;td&gt;Required&lt;/td&gt; 
   &lt;td&gt;about 17x slower than Nvidia RTX 3XXX&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;* AMD GPU ROCm (on hold): The AMD is still working on supporting ROCm on Windows.&lt;/p&gt; 
&lt;p&gt;* Nvidia GTX 1XXX 6GB uncertain: Some people report 6GB success on GTX 10XX, but some other people report failure cases.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note that Fooocus is only for extremely high quality image generating. We will not support smaller models to reduce the requirement and sacrifice result quality.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Troubleshoot&lt;/h2&gt; 
&lt;p&gt;See the common problems &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/troubleshoot.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Default Models&lt;/h2&gt; 
&lt;p&gt;&lt;a name="models"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Given different goals, the default models and configs of Fooocus are different:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;Linux args&lt;/th&gt; 
   &lt;th&gt;Main Model&lt;/th&gt; 
   &lt;th&gt;Refiner&lt;/th&gt; 
   &lt;th&gt;Config&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;General&lt;/td&gt; 
   &lt;td&gt;run.bat&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;juggernautXL_v8Rundiffusion&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/default.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Realistic&lt;/td&gt; 
   &lt;td&gt;run_realistic.bat&lt;/td&gt; 
   &lt;td&gt;--preset realistic&lt;/td&gt; 
   &lt;td&gt;realisticStockPhoto_v20&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/realistic.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anime&lt;/td&gt; 
   &lt;td&gt;run_anime.bat&lt;/td&gt; 
   &lt;td&gt;--preset anime&lt;/td&gt; 
   &lt;td&gt;animaPencilXL_v500&lt;/td&gt; 
   &lt;td&gt;not used&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/raw/main/presets/anime.json"&gt;here&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Note that the download is &lt;strong&gt;automatic&lt;/strong&gt; - you do not need to do anything if the internet connection is okay. However, you can download them manually if you (or move them from somewhere else) have your own preparation.&lt;/p&gt; 
&lt;h2&gt;UI Access and Authentication&lt;/h2&gt; 
&lt;p&gt;In addition to running on localhost, Fooocus can also expose its UI in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local UI listener: use &lt;code&gt;--listen&lt;/code&gt; (specify port e.g. with &lt;code&gt;--port 8888&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;API access: use &lt;code&gt;--share&lt;/code&gt; (registers an endpoint at &lt;code&gt;.gradio.live&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In both ways the access is unauthenticated by default. You can add basic authentication by creating a file called &lt;code&gt;auth.json&lt;/code&gt; in the main directory, which contains a list of JSON objects with the keys &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;pass&lt;/code&gt; (see example in &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/auth-example.json"&gt;auth-example.json&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;List of "Hidden" Tricks&lt;/h2&gt; 
&lt;p&gt;&lt;a name="tech_list"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to see a list of tricks. Those are based on SDXL and are not very up-to-date with latest models.&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;GPT2-based &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117#raw"&gt;prompt expansion as a dynamic style "Fooocus V2".&lt;/a&gt; (similar to Midjourney's hidden pre-processing and "raw" mode, or the LeonardoAI's Prompt Magic).&lt;/li&gt; 
  &lt;li&gt;Native refiner swap inside one single k-sampler. The advantage is that the refiner model can now reuse the base model's momentum (or ODE's history parameters) collected from k-sampling to achieve more coherent sampling. In Automatic1111's high-res fix and ComfyUI's node system, the base model and refiner use two independent k-samplers, which means the momentum is largely wasted, and the sampling continuity is broken. Fooocus uses its own advanced k-diffusion sampling that ensures seamless, native, and continuous swap in a refiner setup. (Update Aug 13: Actually, I discussed this with Automatic1111 several days ago, and it seems that the ‚Äúnative refiner swap inside one single k-sampler‚Äù is &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/12371"&gt;merged&lt;/a&gt; into the dev branch of webui. Great!)&lt;/li&gt; 
  &lt;li&gt;Negative ADM guidance. Because the highest resolution level of XL Base does not have cross attentions, the positive and negative signals for XL's highest resolution level cannot receive enough contrasts during the CFG sampling, causing the results to look a bit plastic or overly smooth in certain cases. Fortunately, since the XL's highest resolution level is still conditioned on image aspect ratios (ADM), we can modify the adm on the positive/negative side to compensate for the lack of CFG contrast in the highest resolution level. (Update Aug 16, the IOS App &lt;a href="https://apps.apple.com/us/app/draw-things-ai-generation/id6444050820"&gt;Draw Things&lt;/a&gt; will support Negative ADM Guidance. Great!)&lt;/li&gt; 
  &lt;li&gt;We implemented a carefully tuned variation of Section 5.1 of &lt;a href="https://arxiv.org/pdf/2210.00939.pdf"&gt;"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance"&lt;/a&gt;. The weight is set to very low, but this is Fooocus's final guarantee to make sure that the XL will never yield an overly smooth or plastic appearance (examples &lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117#sharpness"&gt;here&lt;/a&gt;). This can almost eliminate all cases for which XL still occasionally produces overly smooth results, even with negative ADM guidance. (Update 2023 Aug 18, the Gaussian kernel of SAG is changed to an anisotropic kernel for better structure preservation and fewer artifacts.)&lt;/li&gt; 
  &lt;li&gt;We modified the style templates a bit and added the "cinematic-default".&lt;/li&gt; 
  &lt;li&gt;We tested the "sd_xl_offset_example-lora_1.0.safetensors" and it seems that when the lora weight is below 0.5, the results are always better than XL without lora.&lt;/li&gt; 
  &lt;li&gt;The parameters of samplers are carefully tuned.&lt;/li&gt; 
  &lt;li&gt;Because XL uses positional encoding for generation resolution, images generated by several fixed resolutions look a bit better than those from arbitrary resolutions (because the positional encoding is not very good at handling int numbers that are unseen during training). This suggests that the resolutions in UI may be hard coded for best results.&lt;/li&gt; 
  &lt;li&gt;Separated prompts for two different text encoders seem unnecessary. Separated prompts for the base model and refiner may work, but the effects are random, and we refrain from implementing this.&lt;/li&gt; 
  &lt;li&gt;The DPM family seems well-suited for XL since XL sometimes generates overly smooth texture, but the DPM family sometimes generates overly dense detail in texture. Their joint effect looks neutral and appealing to human perception.&lt;/li&gt; 
  &lt;li&gt;A carefully designed system for balancing multiple styles as well as prompt expansion.&lt;/li&gt; 
  &lt;li&gt;Using automatic1111's method to normalize prompt emphasizing. This significantly improves results when users directly copy prompts from civitai.&lt;/li&gt; 
  &lt;li&gt;The joint swap system of the refiner now also supports img2img and upscale in a seamless way.&lt;/li&gt; 
  &lt;li&gt;CFG Scale and TSNR correction (tuned for SDXL) when CFG is bigger than 10.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;Customization&lt;/h2&gt; 
&lt;p&gt;After the first time you run Fooocus, a config file will be generated at &lt;code&gt;Fooocus\config.txt&lt;/code&gt;. This file can be edited to change the model path or default parameters.&lt;/p&gt; 
&lt;p&gt;For example, an edited &lt;code&gt;Fooocus\config.txt&lt;/code&gt; (this file will be generated after the first launch) may look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "path_checkpoints": "D:\\Fooocus\\models\\checkpoints",
    "path_loras": "D:\\Fooocus\\models\\loras",
    "path_embeddings": "D:\\Fooocus\\models\\embeddings",
    "path_vae_approx": "D:\\Fooocus\\models\\vae_approx",
    "path_upscale_models": "D:\\Fooocus\\models\\upscale_models",
    "path_inpaint": "D:\\Fooocus\\models\\inpaint",
    "path_controlnet": "D:\\Fooocus\\models\\controlnet",
    "path_clip_vision": "D:\\Fooocus\\models\\clip_vision",
    "path_fooocus_expansion": "D:\\Fooocus\\models\\prompt_expansion\\fooocus_expansion",
    "path_outputs": "D:\\Fooocus\\outputs",
    "default_model": "realisticStockPhoto_v10.safetensors",
    "default_refiner": "",
    "default_loras": [["lora_filename_1.safetensors", 0.5], ["lora_filename_2.safetensors", 0.5]],
    "default_cfg_scale": 3.0,
    "default_sampler": "dpmpp_2m",
    "default_scheduler": "karras",
    "default_negative_prompt": "low quality",
    "default_positive_prompt": "",
    "default_styles": [
        "Fooocus V2",
        "Fooocus Photograph",
        "Fooocus Negative"
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Many other keys, formats, and examples are in &lt;code&gt;Fooocus\config_modification_tutorial.txt&lt;/code&gt; (this file will be generated after the first launch).&lt;/p&gt; 
&lt;p&gt;Consider twice before you really change the config. If you find yourself breaking things, just delete &lt;code&gt;Fooocus\config.txt&lt;/code&gt;. Fooocus will go back to default.&lt;/p&gt; 
&lt;p&gt;A safer way is just to try "run_anime.bat" or "run_realistic.bat" - they should already be good enough for different tasks.&lt;/p&gt; 
&lt;p&gt;&lt;del&gt;Note that &lt;code&gt;user_path_config.txt&lt;/code&gt; is deprecated and will be removed soon.&lt;/del&gt; (Edit: it is already removed.)&lt;/p&gt; 
&lt;h3&gt;All CMD Flags&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;entry_with_update.py  [-h] [--listen [IP]] [--port PORT]
                      [--disable-header-check [ORIGIN]]
                      [--web-upload-size WEB_UPLOAD_SIZE]
                      [--hf-mirror HF_MIRROR]
                      [--external-working-path PATH [PATH ...]]
                      [--output-path OUTPUT_PATH]
                      [--temp-path TEMP_PATH] [--cache-path CACHE_PATH]
                      [--in-browser] [--disable-in-browser]
                      [--gpu-device-id DEVICE_ID]
                      [--async-cuda-allocation | --disable-async-cuda-allocation]
                      [--disable-attention-upcast]
                      [--all-in-fp32 | --all-in-fp16]
                      [--unet-in-bf16 | --unet-in-fp16 | --unet-in-fp8-e4m3fn | --unet-in-fp8-e5m2]
                      [--vae-in-fp16 | --vae-in-fp32 | --vae-in-bf16]
                      [--vae-in-cpu]
                      [--clip-in-fp8-e4m3fn | --clip-in-fp8-e5m2 | --clip-in-fp16 | --clip-in-fp32]
                      [--directml [DIRECTML_DEVICE]]
                      [--disable-ipex-hijack]
                      [--preview-option [none,auto,fast,taesd]]
                      [--attention-split | --attention-quad | --attention-pytorch]
                      [--disable-xformers]
                      [--always-gpu | --always-high-vram | --always-normal-vram | --always-low-vram | --always-no-vram | --always-cpu [CPU_NUM_THREADS]]
                      [--always-offload-from-vram]
                      [--pytorch-deterministic] [--disable-server-log]
                      [--debug-mode] [--is-windows-embedded-python]
                      [--disable-server-info] [--multi-user] [--share]
                      [--preset PRESET] [--disable-preset-selection]
                      [--language LANGUAGE]
                      [--disable-offload-from-vram] [--theme THEME]
                      [--disable-image-log] [--disable-analytics]
                      [--disable-metadata] [--disable-preset-download]
                      [--disable-enhance-output-sorting]
                      [--enable-auto-describe-image]
                      [--always-download-new-model]
                      [--rebuild-hash-cache [CPU_NUM_THREADS]]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Inline Prompt Features&lt;/h2&gt; 
&lt;h3&gt;Wildcards&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;__color__ flower&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed for positive and negative prompt.&lt;/p&gt; 
&lt;p&gt;Selects a random wildcard from a predefined list of options, in this case the &lt;code&gt;wildcards/color.txt&lt;/code&gt; file. The wildcard will be replaced with a random color (randomness based on seed). You can also disable randomness and process a wildcard file from top to bottom by enabling the checkbox &lt;code&gt;Read wildcards in order&lt;/code&gt; in Developer Debug Mode.&lt;/p&gt; 
&lt;p&gt;Wildcards can be nested and combined, and multiple wildcards can be used in the same prompt (example see &lt;code&gt;wildcards/color_flower.txt&lt;/code&gt;).&lt;/p&gt; 
&lt;h3&gt;Array Processing&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;[[red, green, blue]] flower&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed only for positive prompt.&lt;/p&gt; 
&lt;p&gt;Processes the array from left to right, generating a separate image for each element in the array. In this case 3 images would be generated, one for each color. Increase the image number to 3 to generate all 3 variants.&lt;/p&gt; 
&lt;p&gt;Arrays can not be nested, but multiple arrays can be used in the same prompt. Does support inline LoRAs as array elements!&lt;/p&gt; 
&lt;h3&gt;Inline LoRAs&lt;/h3&gt; 
&lt;p&gt;Example prompt: &lt;code&gt;flower &amp;lt;lora:sunflowers:1.2&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Processed only for positive prompt.&lt;/p&gt; 
&lt;p&gt;Applies a LoRA to the prompt. The LoRA file must be located in the &lt;code&gt;models/loras&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/lllyasviel/Fooocus/discussions/117"&gt;Click here to browse the advanced features.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Forks&lt;/h2&gt; 
&lt;p&gt;Below are some Forks to Fooocus:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Fooocus' forks&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fenneishi/Fooocus-Control"&gt;fenneishi/Fooocus-Control&lt;/a&gt; &lt;br /&gt;&lt;a href="https://github.com/runew0lf/RuinedFooocus"&gt;runew0lf/RuinedFooocus&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/MoonRide303/Fooocus-MRE"&gt;MoonRide303/Fooocus-MRE&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/mashb1t/Fooocus"&gt;mashb1t/Fooocus&lt;/a&gt; &lt;br /&gt; and so on ...&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Many thanks to &lt;a href="https://github.com/twri"&gt;twri&lt;/a&gt; and &lt;a href="https://github.com/3Diva"&gt;3Diva&lt;/a&gt; and &lt;a href="https://github.com/K3nt3L"&gt;Marc K3nt3L&lt;/a&gt; for creating additional SDXL styles available in Fooocus.&lt;/p&gt; 
&lt;p&gt;The project starts from a mixture of &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"&gt;Stable Diffusion WebUI&lt;/a&gt; and &lt;a href="https://github.com/comfyanonymous/ComfyUI"&gt;ComfyUI&lt;/a&gt; codebases.&lt;/p&gt; 
&lt;p&gt;Also, thanks &lt;a href="https://github.com/daswer123"&gt;daswer123&lt;/a&gt; for contributing the Canvas Zoom!&lt;/p&gt; 
&lt;h2&gt;Update Log&lt;/h2&gt; 
&lt;p&gt;The log is &lt;a href="https://raw.githubusercontent.com/lllyasviel/Fooocus/main/update_log.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Localization/Translation/I18N&lt;/h2&gt; 
&lt;p&gt;You can put json files in the &lt;code&gt;language&lt;/code&gt; folder to translate the user interface.&lt;/p&gt; 
&lt;p&gt;For example, below is the content of &lt;code&gt;Fooocus/language/example.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "Generate": "ÁîüÊàê",
  "Input Image": "ÂÖ•ÂäõÁîªÂÉè",
  "Advanced": "Í≥†Í∏â",
  "SAI 3D Model": "SAI 3D Mod√®le"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you add &lt;code&gt;--language example&lt;/code&gt; arg, Fooocus will read &lt;code&gt;Fooocus/language/example.json&lt;/code&gt; to translate the UI.&lt;/p&gt; 
&lt;p&gt;For example, you can edit the ending line of Windows &lt;code&gt;run.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or &lt;code&gt;run_anime.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset anime
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or &lt;code&gt;run_realistic.bat&lt;/code&gt; as&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;.\python_embeded\python.exe -s Fooocus\entry_with_update.py --language example --preset realistic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For practical translation, you may create your own file like &lt;code&gt;Fooocus/language/jp.json&lt;/code&gt; or &lt;code&gt;Fooocus/language/cn.json&lt;/code&gt; and then use flag &lt;code&gt;--language jp&lt;/code&gt; or &lt;code&gt;--language cn&lt;/code&gt;. Apparently, these files do not exist now. &lt;strong&gt;We need your help to create these files!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Note that if no &lt;code&gt;--language&lt;/code&gt; is given and at the same time &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; exists, Fooocus will always load &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; for translation. By default, the file &lt;code&gt;Fooocus/language/default.json&lt;/code&gt; does not exist.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>VectifyAI/PageIndex</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <description>&lt;p&gt;üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://vectify.ai/pageindex" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d" alt="PageIndex Banner" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14736" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14736" alt="VectifyAI%2FPageIndex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;h1&gt;PageIndex: Vectorless, Reasoning-based RAG&lt;/h1&gt; 
 &lt;p align="center"&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt; 
 &lt;h4 align="center"&gt; &lt;a href="https://vectify.ai"&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://chat.pageindex.ai"&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://pageindex.ai/mcp"&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://docs.pageindex.ai"&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;üî• Releases:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://chat.pageindex.ai"&gt;&lt;strong&gt;PageIndex Chat&lt;/strong&gt;&lt;/a&gt;: The first human-like document-analysis agent &lt;a href="https://chat.pageindex.ai"&gt;platform&lt;/a&gt; built for professional long documents. Can also be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt; (beta).&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex's advanced long-document intelligence directly into your applications and workflows. --&gt; 
 &lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Articles:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;&lt;strong&gt;PageIndex Framework&lt;/strong&gt;&lt;/a&gt;: Introduces the PageIndex framework ‚Äî an &lt;em&gt;agentic, in-context&lt;/em&gt; &lt;em&gt;tree index&lt;/em&gt; that enables LLMs to perform &lt;em&gt;reasoning-based&lt;/em&gt;, &lt;em&gt;human-like retrieval&lt;/em&gt; over long documents, without vector DB or chunking.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt; 
 &lt;p&gt;&lt;strong&gt;üß™ Cookbooks:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Vectorless RAG&lt;/a&gt;: A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vision-rag-pageindex"&gt;Vision-based Vectorless RAG&lt;/a&gt;: OCR-free, vision-only RAG with PageIndex's reasoning-native retrieval workflow that works directly over PDF page images.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìë Introduction to PageIndex&lt;/h1&gt; 
&lt;p&gt;Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic &lt;em&gt;similarity&lt;/em&gt; rather than true &lt;em&gt;relevance&lt;/em&gt;. But &lt;strong&gt;similarity ‚â† relevance&lt;/strong&gt; ‚Äî what we truly need in retrieval is &lt;strong&gt;relevance&lt;/strong&gt;, and that requires &lt;strong&gt;reasoning&lt;/strong&gt;. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.&lt;/p&gt; 
&lt;p&gt;Inspired by AlphaGo, we propose &lt;strong&gt;&lt;a href="https://vectify.ai/pageindex"&gt;PageIndex&lt;/a&gt;&lt;/strong&gt; ‚Äî a &lt;strong&gt;vectorless&lt;/strong&gt;, &lt;strong&gt;reasoning-based RAG&lt;/strong&gt; system that builds a &lt;strong&gt;hierarchical tree index&lt;/strong&gt; from long documents and uses LLMs to &lt;strong&gt;reason&lt;/strong&gt; &lt;em&gt;over that index&lt;/em&gt; for &lt;strong&gt;agentic, context-aware retrieval&lt;/strong&gt;. It simulates how &lt;em&gt;human experts&lt;/em&gt; navigate and extract knowledge from complex documents through &lt;em&gt;tree search&lt;/em&gt;, enabling LLMs to &lt;em&gt;think&lt;/em&gt; and &lt;em&gt;reason&lt;/em&gt; their way to the most relevant document sections. PageIndex performs retrieval in two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate a ‚ÄúTable-of-Contents‚Äù &lt;strong&gt;tree structure index&lt;/strong&gt; of documents&lt;/li&gt; 
 &lt;li&gt;Perform reasoning-based retrieval through &lt;strong&gt;tree search&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pageindex.ai/blog/pageindex-intro" target="_blank" title="The PageIndex Framework"&gt; &lt;img src="https://docs.pageindex.ai/images/cookbook/vectorless-rag.png" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Core Features&lt;/h3&gt; 
&lt;p&gt;Compared to traditional vector-based RAG, &lt;strong&gt;PageIndex&lt;/strong&gt; features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No Vector DB&lt;/strong&gt;: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Chunking&lt;/strong&gt;: Documents are organized into natural sections, not artificial chunks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human-like Retrieval&lt;/strong&gt;: Simulates how human experts navigate and extract knowledge from complex documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Explainability and Traceability&lt;/strong&gt;: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PageIndex powers a reasoning-based RAG system that achieved &lt;strong&gt;state-of-the-art&lt;/strong&gt; &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;98.7% accuracy&lt;/a&gt; on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for details).&lt;/p&gt; 
&lt;h3&gt;üìç Explore PageIndex&lt;/h3&gt; 
&lt;p&gt;To learn more, please see a detailed introduction of the &lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;PageIndex framework&lt;/a&gt;. Check out this GitHub repo for open-source code, and the &lt;a href="https://docs.pageindex.ai/cookbook"&gt;cookbooks&lt;/a&gt;, &lt;a href="https://docs.pageindex.ai/tutorials"&gt;tutorials&lt;/a&gt;, and &lt;a href="https://pageindex.ai/blog"&gt;blog&lt;/a&gt; for additional usage guides and examples.&lt;/p&gt; 
&lt;p&gt;The PageIndex service is available as a ChatGPT-style &lt;a href="https://chat.pageindex.ai"&gt;chat platform&lt;/a&gt;, or can be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üõ†Ô∏è Deployment Options&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Self-host ‚Äî run locally with this open-source repo.&lt;/li&gt; 
 &lt;li&gt;Cloud Service ‚Äî try instantly with our &lt;a href="https://chat.pageindex.ai/"&gt;Chat Platform&lt;/a&gt;, or integrate with &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Enterprise&lt;/em&gt; ‚Äî private or on-prem deployment. &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;Contact us&lt;/a&gt; or &lt;a href="https://calendly.com/pageindex/meet"&gt;book a demo&lt;/a&gt; for more details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß™ Quick Hands-on&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try the &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;strong&gt;Vectorless RAG&lt;/strong&gt;&lt;/a&gt; notebook ‚Äî a &lt;em&gt;minimal&lt;/em&gt;, hands-on example of reasoning-based RAG using PageIndex.&lt;/li&gt; 
 &lt;li&gt;Experiment with &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/vision_RAG_pageindex.ipynb"&gt;&lt;em&gt;Vision-based Vectorless RAG&lt;/em&gt;&lt;/a&gt; ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vectorless RAG" /&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vision RAG" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üå≤ PageIndex Tree Structure&lt;/h1&gt; 
&lt;p&gt;PageIndex can transform lengthy PDF documents into a semantic &lt;strong&gt;tree structure&lt;/strong&gt;, similar to a &lt;em&gt;"table of contents"&lt;/em&gt; but optimized for use with Large Language Models (LLMs). It's ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.&lt;/p&gt; 
&lt;p&gt;Below is an example PageIndex tree structure. Also see more example &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs"&gt;documents&lt;/a&gt; and generated &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/results"&gt;tree structures&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;...
{
  "title": "Financial Stability",
  "node_id": "0006",
  "start_index": 21,
  "end_index": 22,
  "summary": "The Federal Reserve ...",
  "nodes": [
    {
      "title": "Monitoring Financial Vulnerabilities",
      "node_id": "0007",
      "start_index": 22,
      "end_index": 28,
      "summary": "The Federal Reserve's monitoring ..."
    },
    {
      "title": "Domestic and International Cooperation and Coordination",
      "node_id": "0008",
      "start_index": 28,
      "end_index": 31,
      "summary": "In 2023, the Federal Reserve collaborated ..."
    }
  ]
}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can generate the PageIndex tree structure with this open-source repo, or use our &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚öôÔ∏è Package Usage&lt;/h1&gt; 
&lt;p&gt;You can follow these steps to generate a PageIndex tree from a PDF document.&lt;/p&gt; 
&lt;h3&gt;1. Install dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set your OpenAI API key&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CHATGPT_API_KEY=your_openai_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run PageIndex on your PDF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; You can customize the processing with additional optional arguments: 
 &lt;pre&gt;&lt;code&gt;--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file. 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --md_path /path/to/your/document.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Note: in this function, we use "#" to determine node heading and their levels. For example, "##" is level 2, "###" is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don't recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our &lt;a href="https://pageindex.ai/blog/ocr"&gt;PageIndex OCR&lt;/a&gt;, which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align="center"&gt;
  &lt;img src="https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732" width="80%"&gt;
&lt;/p&gt;
--&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìà Case Study: PageIndex Leads Finance QA Benchmark&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://vectify.ai/mafin"&gt;Mafin 2.5&lt;/a&gt; is a reasoning-based RAG system for financial document analysis, powered by &lt;strong&gt;PageIndex&lt;/strong&gt;. It achieved a state-of-the-art &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;&lt;strong&gt;98.7% accuracy&lt;/strong&gt;&lt;/a&gt; on the &lt;a href="https://arxiv.org/abs/2311.11944"&gt;FinanceBench&lt;/a&gt; benchmark, significantly outperforming traditional vector-based RAG systems.&lt;/p&gt; 
&lt;p&gt;PageIndex's hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.&lt;/p&gt; 
&lt;p&gt;Explore the full &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;benchmark results&lt;/a&gt; and our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for detailed comparisons and performance metrics.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt; &lt;img src="https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üß≠ Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß™ &lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Cookbooks&lt;/a&gt;: hands-on, runnable examples and advanced use cases.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.pageindex.ai/doc-search"&gt;Tutorials&lt;/a&gt;: practical guides and strategies, including &lt;em&gt;Document Search&lt;/em&gt; and &lt;em&gt;Tree Search&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://pageindex.ai/blog"&gt;Blog&lt;/a&gt;: technical articles, research insights, and product updates.&lt;/li&gt; 
 &lt;li&gt;üîå &lt;a href="https://pageindex.ai/mcp#quick-setup"&gt;MCP setup&lt;/a&gt; &amp;amp; &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API docs&lt;/a&gt;: integration details and configuration options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚≠ê Support Us&lt;/h1&gt; 
&lt;p&gt;Leave us a star üåü if you like our project. Thank you!&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794" width="80%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Connect with Us&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://x.com/PageIndexAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://www.linkedin.com/company/vectify-ai/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;&lt;img src="https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;amp;logo=envelope&amp;amp;logoColor=white" alt="Contact Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2025 &lt;a href="https://vectify.ai"&gt;Vectify AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EbookFoundation/free-programming-books</title>
      <link>https://github.com/EbookFoundation/free-programming-books</link>
      <description>&lt;p&gt;üìö Freely available programming books&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of Free Learning Resources In Many Languages&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;&lt;img src="https://img.shields.io/github/license/EbookFoundation/free-programming-books" alt="License: CC BY 4.0" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31"&gt;&lt;img src="https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025" alt="Hacktoberfest 2025 stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Search the list at &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;https://ebookfoundation.github.io/free-programming-books-search/&lt;/a&gt; &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Dynamic%20search%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" alt="https://ebookfoundation.github.io/free-programming-books-search/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This page is available as an easy-to-read website. Access it by clicking on &lt;a href="https://ebookfoundation.github.io/free-programming-books/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Static%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" alt="https://ebookfoundation.github.io/free-programming-books/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;form action="https://ebookfoundation.github.io/free-programming-books-search"&gt; 
  &lt;input type="text" id="fpbSearch" name="search" required placeholder="Search Book or Author" /&gt; 
  &lt;label for="submit"&gt; &lt;/label&gt; 
  &lt;input type="submit" id="submit" name="submit" value="Search" /&gt; 
 &lt;/form&gt; 
&lt;/div&gt; 
&lt;h2&gt;Intro&lt;/h2&gt; 
&lt;p&gt;This list was originally a clone of &lt;a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926"&gt;StackOverflow - List of Freely Available Programming Books&lt;/a&gt; with contributions from Karan Bhangui and George Stocker.&lt;/p&gt; 
&lt;p&gt;The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of &lt;a href="https://octoverse.github.com/"&gt;GitHub's most popular repositories&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/network"&gt;&lt;img src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks" alt="GitHub repo forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars" alt="GitHub repo stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Contributors" alt="GitHub repo contributors" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/EbookFoundation"&gt;&lt;img src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Sponsors" alt="GitHub org sponsors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers" alt="GitHub repo watchers" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"&gt;&lt;img src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size" alt="GitHub repo size" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;a href="https://ebookfoundation.org"&gt;Free Ebook Foundation&lt;/a&gt; now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. &lt;a href="https://ebookfoundation.org/contributions.html"&gt;Donations&lt;/a&gt; to the Free Ebook Foundation are tax-deductible in the US.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;. If you're new to GitHub, &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;welcome&lt;/a&gt;! Remember to abide by our adapted from &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" alt="Contributor Covenant 1.3" /&gt; &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; too (&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations"&gt;translations&lt;/a&gt; also available).&lt;/p&gt; 
&lt;p&gt;Click on these badges to see how you might be able to help:&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/issues"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=red&amp;amp;label=Issues" alt="GitHub repo Issues" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Good%20First%20issues" alt="GitHub repo Good Issues for newbies" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20issues" alt="GitHub Help Wanted issues" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=orange&amp;amp;label=PRs" alt="GitHub repo PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"&gt;&lt;img src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Merged%20PRs&amp;amp;query=is%3Amerged" alt="GitHub repo Merged PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20PRs" alt="GitHub Help Wanted PRs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;How To Share&lt;/h2&gt; 
&lt;div align="left" markdown="1"&gt; 
 &lt;a href="https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;amp;p%5Bimages%5D%5B0%5D=&amp;amp;p%5Btitle%5D=Free%20Programming%20Books&amp;amp;p%5Bsummary%5D="&gt;Share on Facebook&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on LinkedIn&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Mastodon/Fediverse&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Telegram&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books"&gt;Share on ùïè (Twitter)&lt;/a&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;This project lists books and other resources grouped by genres:&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md"&gt;English, By Programming Language&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md"&gt;English, By Subject&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Other Languages&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md"&gt;Armenian / ’Ä’°’µ’•÷Ä’•’∂&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md"&gt;Azerbaijani / –ê–∑”ô—Ä–±–∞—ò“π–∞–Ω –¥–∏–ª–∏ / ÿ¢ÿ∞ÿ±ÿ®ÿßŸäÿ¨ÿßŸÜÿ¨ÿß ÿØŸäŸÑŸä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md"&gt;Catalan / catalan / catal√†&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md"&gt;Danish / dansk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md"&gt;Estonian / eesti keel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md"&gt;Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md"&gt;Hungarian / magyar / magyar nyelv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md"&gt;Latvian / Latvie≈°u&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md"&gt;Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md"&gt;Serbian / —Å—Ä–ø—Å–∫–∏ —ò–µ–∑–∏–∫ / srpski jezik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md"&gt;Slovak / slovenƒçina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sl.md"&gt;Slovenian / Sloven≈°ƒçina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md"&gt;Thai / ‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ur.md"&gt;Urdu / ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheat Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md"&gt;All Languages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Online Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md"&gt;Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md"&gt;Kannada / ‡≤ï‡≤®‡≥ç‡≤®‡≤°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md"&gt;Kazakh / “õ–∞–∑–∞“õ—à–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md"&gt;Khmer / ·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md"&gt;Marathi / ‡§Æ‡§∞‡§æ‡§†‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md"&gt;Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pa.md"&gt;Punjabi / ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä / ŸæŸÜÿ¨ÿßÿ®€å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ro.md"&gt;Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md"&gt;Swedish / svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md"&gt;Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md"&gt;Urdu / ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Interactive Programming Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Sets and Competitive Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md"&gt;Problem Sets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Podcast - Screencast&lt;/h3&gt; 
&lt;p&gt;Free Podcasts and Screencasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md"&gt;Arabic / al Arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md"&gt;Finnish / Suomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Playgrounds&lt;/h3&gt; 
&lt;p&gt;Write, compile, and run your code within a browser. Try it out!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;English 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;How-to&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;... &lt;em&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;More languages&lt;/a&gt;&lt;/em&gt; ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might notice that there are &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;some missing translations here&lt;/a&gt; - perhaps you would like to help out by &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation"&gt;contributing a translation&lt;/a&gt;?&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Each file included in this repository is licensed under the &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE"&gt;CC BY License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightning‚ö°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;‚ö° Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! üí§&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ü§ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. üéØ&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ü§ó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the latest nightly build (cutting-edge features), you can install from Test PyPI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --pre agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö° Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;12/17/2025 &lt;a href="https://agent-lightning.github.io/posts/trajectory_level_aggregation/"&gt;Adopting the Trajectory Level Aggregation for Faster Training&lt;/a&gt; Agent-lightning blog.&lt;/li&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker ‚úï Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; ‚Äî A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; ‚Äî A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TencentCloudADP/Youtu-agent"&gt;Youtu-Agent&lt;/a&gt; ‚Äî Youtu-Agent lets you build and train your agent with ease. Built with &lt;a href="https://github.com/microsoft/agent-lightning/tree/contrib/youtu-agent-lightning"&gt;a modified branch&lt;/a&gt; of Agent Lightning, Youtu-Agent has verified up to 128 GPUs RL training on maths/code and search capabilities with steady convergence. Also check &lt;a href="https://github.com/TencentCloudADP/youtu-agent/tree/rl/agl"&gt;the recipe&lt;/a&gt; and their blog &lt;a href="https://spotted-coconut-df8.notion.site/Stop-Wrestling-with-Your-Agent-RL-How-Youtu-Agent-Achieved-Stable-128-GPU-Scaling-Without-Breaking-2ca5e8f089ba80539a98c582b65e0233"&gt;&lt;em&gt;Stop Wrestling with Your Agent RL: How Youtu-Agent Achieved Stable, 128-GPU Scaling Without Breaking a Sweat&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-unit.yml/badge.svg?sanitize=true" alt="tests summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UI Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/dashboard.yml/badge.svg?sanitize=true" alt="UI Tests" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-compat.yml/badge.svg?sanitize=true" alt="compat summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ö° Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for recommended contribution points, environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;‚ö° Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;‚ö° Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;‚ö° License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>happycola233/tchMaterial-parser</title>
      <link>https://github.com/happycola233/tchMaterial-parser</link>
      <description>&lt;p&gt;ÂõΩÂÆ∂‰∏≠Â∞èÂ≠¶Êô∫ÊÖßÊïôËÇ≤Âπ≥Âè∞ ÁîµÂ≠êËØæÊú¨‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÂ∏ÆÂä©ÊÇ®‰ªéÊô∫ÊÖßÊïôËÇ≤Âπ≥Âè∞‰∏≠Ëé∑ÂèñÁîµÂ≠êËØæÊú¨ÁöÑ PDF Êñá‰ª∂ÁΩëÂùÄÂπ∂ËøõË°å‰∏ãËΩΩÔºåËÆ©ÊÇ®Êõ¥Êñπ‰æøÂú∞Ëé∑ÂèñËØæÊú¨ÂÜÖÂÆπ„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://basic.smartedu.cn/tchMaterial/"&gt;ÂõΩÂÆ∂‰∏≠Â∞èÂ≠¶Êô∫ÊÖßÊïôËÇ≤Âπ≥Âè∞ ÁîµÂ≠êËØæÊú¨&lt;/a&gt;‰∏ãËΩΩÂ∑•ÂÖ∑&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Python-3.x-blue.svg?sanitize=true" alt="Python Version" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License" /&gt; &lt;img src="https://img.shields.io/badge/Made_With-%E2%9D%A4-red.svg?sanitize=true" alt="Made With Love‚ù§Ô∏è" /&gt;&lt;/p&gt; 
&lt;p&gt;Êú¨Â∑•ÂÖ∑ÂèØ‰ª•Â∏ÆÂä©ÊÇ®‰ªé&lt;a href="https://basic.smartedu.cn/"&gt;&lt;strong&gt;ÂõΩÂÆ∂‰∏≠Â∞èÂ≠¶Êô∫ÊÖßÊïôËÇ≤Âπ≥Âè∞&lt;/strong&gt;&lt;/a&gt;Ëé∑ÂèñÁîµÂ≠êËØæÊú¨ÁöÑ PDF Êñá‰ª∂ÁΩëÂùÄÂπ∂ËøõË°å‰∏ãËΩΩÔºåËÆ©ÊÇ®Êõ¥Êñπ‰æøÂú∞Ëé∑ÂèñËØæÊú¨ÂÜÖÂÆπ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚ú® Â∑•ÂÖ∑ÁâπÁÇπ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìö&lt;strong&gt;ÊîØÊåÅÊâπÈáè‰∏ãËΩΩ&lt;/strong&gt;Ôºö‰∏ÄÊ¨°ËæìÂÖ•Â§ö‰∏™ÁîµÂ≠êËØæÊú¨È¢ÑËßàÈ°µÈù¢ÁΩëÂùÄÔºåÂç≥ÂèØÊâπÈáè‰∏ãËΩΩ PDF ËØæÊú¨Êñá‰ª∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;üìÇ&lt;strong&gt;Ëá™Âä®ÂëΩÂêçÊñá‰ª∂&lt;/strong&gt;ÔºöÂ∑•ÂÖ∑‰ºöËá™Âä®‰ΩøÁî®ÁîµÂ≠êËØæÊú¨ÁöÑÂêçÁß∞‰Ωú‰∏∫ÈªòËÆ§Êñá‰ª∂ÂêçÔºåÊñπ‰æøÁÆ°ÁêÜ‰∏ãËΩΩÁöÑËØæÊú¨Êñá‰ª∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;üîñ&lt;strong&gt;Ëá™Âä®Ê∑ªÂä†‰π¶Á≠æ&lt;/strong&gt;ÔºöËã•ÂãæÈÄâ‰∫Ü ‚ÄúÊ∑ªÂä†‰π¶Á≠æ‚Äù ÈÄâÈ°πÔºåÂàô‰ºöÂú®‰∏ãËΩΩÂÆåÊàêÂêé‰∏∫ÁîµÂ≠êËØæÊú¨Ê∑ªÂä†‰π¶Á≠æÔºåÂú®Êü•Áúã PDF Êó∂ÂèØÊõ¥Êñπ‰æøÂú∞Ë∑≥ËΩ¨Âà∞ÊåáÂÆö‰ΩçÁΩÆ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;üîë&lt;strong&gt;ÊîØÊåÅ Access Token&lt;/strong&gt;ÔºöÊîØÊåÅÁî®Êà∑&lt;a href="https://raw.githubusercontent.com/happycola233/tchMaterial-parser/main/#2--%E8%AE%BE%E7%BD%AE-access-token%E5%8F%AF%E9%80%89"&gt;ÊâãÂä®ËæìÂÖ• Access Token&lt;/a&gt; Âπ∂Ëá™Âä®‰øùÂ≠òÔºå‰∏ãÊ¨°ÂêØÂä®ÂèØËá™Âä®Âä†ËΩΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è&lt;strong&gt;È´ò DPI ÈÄÇÈÖç&lt;/strong&gt;Ôºö‰ºòÂåñ UI ‰ª•ÈÄÇÈÖçÈ´òÂàÜËæ®ÁéáÂ±èÂπïÔºåÈÅøÂÖçÁïåÈù¢Ê®°Á≥äÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
 &lt;li&gt;üíª&lt;strong&gt;Ë∑®Âπ≥Âè∞ÊîØÊåÅ&lt;/strong&gt;ÔºöÊîØÊåÅ Windows„ÄÅLinux„ÄÅmacOS Á≠âÊìç‰ΩúÁ≥ªÁªüÔºàÈúÄË¶ÅÂõæÂΩ¢ÁïåÈù¢Ôºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/happycola233/tchMaterial-parser/main/res/main.png" alt="Â∑•ÂÖ∑Êà™Âõæ" /&gt;&lt;/p&gt; 
&lt;h2&gt;üì• ‰∏ãËΩΩ‰∏éÂÆâË£ÖÊñπÊ≥ï&lt;/h2&gt; 
&lt;h3&gt;GitHub Releases&lt;/h3&gt; 
&lt;p&gt;Êú¨È°πÁõÆÁöÑ &lt;a href="https://github.com/happycola233/tchMaterial-parser/releases"&gt;GitHub Releases È°µÈù¢&lt;/a&gt;‰ºöÂèëÂ∏É&lt;strong&gt;ÈÄÇÁî®‰∫é Windows„ÄÅLinux ÁöÑ x86_64 Êû∂ÊûÑ&lt;/strong&gt;‰∏é&lt;strong&gt;ÈÄÇÁî®‰∫é Linux„ÄÅmacOS ÁöÑ Arm64 Êû∂ÊûÑ&lt;/strong&gt;ÁöÑÁ®ãÂ∫è„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰∏ãËΩΩÂÆåÊàê‰πãÂêé‰∏çÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÂÆâË£ÖÊ≠•È™§„ÄÇWindows Âíå Linux ÂèØÁõ¥Êé•ËøêË°åÊú¨Á®ãÂ∫è„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Âú® macOS Êìç‰ΩúÁ≥ªÁªü‰∏≠ÔºåÁî±‰∫éÊ≤°ÊúâÁ≠æÂêçÔºåÁ≥ªÁªü‰ºöÊä•ÂëäÊñá‰ª∂Â∑≤Ë¢´ÊçüÂùèÔºåÂõ†Ê≠§ÈúÄË¶ÅÂÖàËøêË°å &lt;code&gt;xattr -cr /path/to/tchMaterial-parser.app&lt;/code&gt; Êù•ÁßªÈô§Â∫îÁî®ÁöÑ ‚ÄúÈöîÁ¶ª‚Äù Â±ûÊÄß„ÄÇ‰∏∫‰∫Ü‰øùËØÅ Access Token ÁöÑÊåÅ‰πÖÂåñÔºåÂª∫ËÆÆÂ∞ÜÂ∫îÁî®ÁßªÂä®Âà∞ &lt;code&gt;/Applications&lt;/code&gt; ÁõÆÂΩï‰∏ãÂÜçËøêË°å„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Arch Áî®Êà∑ËΩØ‰ª∂‰ªìÂ∫ìÔºàAURÔºâ&lt;/h3&gt; 
&lt;p&gt;ÂØπ‰∫é &lt;strong&gt;Arch Linux&lt;/strong&gt; Êìç‰ΩúÁ≥ªÁªüÔºåÊú¨Á®ãÂ∫èÂ∑≤ÂèëÂ∏ÉËá≥&lt;a href="https://aur.archlinux.org/packages/tchmaterial-parser"&gt;Arch Áî®Êà∑ËΩØ‰ª∂‰ªìÂ∫ì&lt;/a&gt;ÔºåÂõ†Ê≠§ÊÇ®ËøòÂèØ‰ª•ÈÄöËøáÂú®ÁªàÁ´Ø‰∏≠ËæìÂÖ•‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yay -S tchmaterial-parser
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊÑüË∞¢ &lt;a href="https://github.com/iamzhz"&gt;@iamzhz&lt;/a&gt; ‰∏∫Êú¨Â∑•ÂÖ∑Âà∂‰Ωú‰∫ÜÂèëË°åÂåÖÔºà&lt;a href="https://raw.githubusercontent.com/happycola233/issues/26"&gt;#26&lt;/a&gt;ÔºâÔºÅ&lt;/p&gt; 
&lt;h2&gt;üõ†Ô∏è ‰ΩøÁî®ÊñπÊ≥ï&lt;/h2&gt; 
&lt;h3&gt;1. ‚å®Ô∏è ËæìÂÖ•ÁîµÂ≠êËØæÊú¨ÈìæÊé•&lt;/h3&gt; 
&lt;p&gt;Â∞ÜÁîµÂ≠êËØæÊú¨ÁöÑ&lt;strong&gt;È¢ÑËßàÈ°µÈù¢ÁΩëÂùÄ&lt;/strong&gt;Á≤òË¥¥Âà∞Â∑•ÂÖ∑ÊñáÊú¨Ê°Ü‰∏≠ÔºåÊîØÊåÅÂ§ö‰∏™ URLÔºàÊØèË°å‰∏Ä‰∏™Ôºâ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Á§∫‰æãÁΩëÂùÄ&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;https://basic.smartedu.cn/tchMaterial/detail?contentType=assets_document&amp;amp;contentId=XXXXXX&amp;amp;catalogType=tchMaterial&amp;amp;subCatalog=tchMaterial
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. üîë ËÆæÁΩÆ Access TokenÔºàÂèØÈÄâÔºâ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Ëá™ v3.1 ÁâàÊú¨Ëµ∑ÔºåËøô‰∏ÄÊ≠•Êìç‰ΩúÂ∑≤Áªè&lt;strong&gt;‰∏çÂÜçÂøÖË¶Å&lt;/strong&gt;ÔºåÂΩìÊú™ËÆæÁΩÆ Access Token Êó∂Â∑•ÂÖ∑‰ºö‰ΩøÁî®ÂÖ∂‰ªñÊñπÊ≥ï‰∏ãËΩΩËµÑÊ∫ê„ÄÇÁÑ∂ËÄåÔºåËøô‰∏ÄÊñπÊ≥ï&lt;strong&gt;Âπ∂‰∏çÈïøÊúüÊúâÊïà&lt;/strong&gt;ÔºåÂõ†Ê≠§‰ªçÁÑ∂Âª∫ËÆÆÊÇ®ËøõË°åËøô‰∏ÄÊ≠•Êìç‰Ωú„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊâìÂºÄÊµèËßàÂô®&lt;/strong&gt;ÔºåËÆøÈóÆ&lt;a href="https://auth.smartedu.cn/uias/login"&gt;ÂõΩÂÆ∂‰∏≠Â∞èÂ≠¶Êô∫ÊÖßÊïôËÇ≤Âπ≥Âè∞&lt;/a&gt;Âπ∂&lt;strong&gt;ÁôªÂΩïË¥¶Âè∑&lt;/strong&gt;„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Êåâ‰∏ã &lt;strong&gt;F12&lt;/strong&gt; Êàñ &lt;strong&gt;Ctrl+Shift+I&lt;/strong&gt;ÔºåÊàñÂè≥ÈîÆ‚Äî‚ÄîÊ£ÄÊü•ÔºàÂÆ°Êü•ÂÖÉÁ¥†ÔºâÊâìÂºÄ&lt;strong&gt;ÂºÄÂèëËÄÖÂ∑•ÂÖ∑&lt;/strong&gt;ÔºåÈÄâÊã©&lt;strong&gt;ÊéßÂà∂Âè∞ÔºàConsoleÔºâ&lt;/strong&gt;„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Âú®ÊéßÂà∂Âè∞Á≤òË¥¥‰ª•‰∏ã‰ª£Á†ÅÂêéÂõûËΩ¶ÔºàEnterÔºâÔºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-js"&gt;(function () {
  const authKey = Object.keys(localStorage).find((key) =&amp;gt;
    key.startsWith("ND_UC_AUTH"),
  );
  if (!authKey) {
    console.error("Êú™ÊâæÂà∞ Access TokenÔºåËØ∑Á°Æ‰øùÂ∑≤ÁôªÂΩïÔºÅ");
    return;
  }
  const tokenData = JSON.parse(localStorage.getItem(authKey));
  const accessToken = JSON.parse(tokenData.value).access_token;
  console.log(
    "%cAccess Token:",
    "color: green; font-weight: bold",
    accessToken,
  );
})();
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Â§çÂà∂ÊéßÂà∂Âè∞ËæìÂá∫ÁöÑ &lt;strong&gt;Access Token&lt;/strong&gt;ÔºåÁÑ∂ÂêéÂú®Êú¨Â∑•ÂÖ∑‰∏≠ÁÇπÂáª ‚Äú&lt;strong&gt;ËÆæÁΩÆ Token&lt;/strong&gt;‚Äù ÊåâÈíÆÔºåÁ≤òË¥¥Âπ∂‰øùÂ≠ò Token„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Access Token ÂèØËÉΩ‰ºöËøáÊúüÔºåËã•‰∏ãËΩΩÂ§±Ë¥•ÔºåËØ∑ÈáçÊñ∞Ëé∑ÂèñÂπ∂ËÆæÁΩÆÊñ∞ÁöÑ Token„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;3. üöÄ ÂºÄÂßã‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;ÁÇπÂáª ‚Äú&lt;strong&gt;‰∏ãËΩΩ&lt;/strong&gt;‚Äù ÊåâÈíÆÔºåÂ∑•ÂÖ∑Â∞ÜËá™Âä®Ëß£ÊûêÂπ∂‰∏ãËΩΩ PDF ËØæÊú¨„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êú¨Â∑•ÂÖ∑ÊîØÊåÅ&lt;strong&gt;ÊâπÈáè‰∏ãËΩΩ&lt;/strong&gt;ÔºåÊâÄÊúâ PDF Êñá‰ª∂‰ºöËá™Âä®ÊåâËØæÊú¨ÂêçÁß∞ÂëΩÂêçÂπ∂‰øùÂ≠òÂú®ÈÄâÂÆöÁõÆÂΩï‰∏≠„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ëã•ÊÇ®ÂãæÈÄâ‰∫Ü ‚Äú&lt;strong&gt;ËÆæÁΩÆ‰π¶Á≠æ&lt;/strong&gt;‚Äù Â§çÈÄâÊ°ÜÔºåÂàôÊú¨Â∑•ÂÖ∑‰ºöÂú®ËØæÊú¨‰∏ãËΩΩÂÆåÊàêÂêéËá™Âä®‰∏∫ÂÖ∂Ê∑ªÂä†‰π¶Á≠æÔºåÂú®Êü•Áúã PDF Êó∂ÂèØÂø´ÈÄüË∑≥ËΩ¨Âà∞ÊåáÂÆö‰ΩçÁΩÆ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/happycola233/tchMaterial-parser/main/res/bookmark.png" alt="Ê∑ªÂä†‰∫Ü‰π¶Á≠æÁöÑ PDF Êñá‰ª∂" /&gt;&lt;/p&gt; 
&lt;h2&gt;‚ùì Â∏∏ËßÅÈóÆÈ¢ò&lt;/h2&gt; 
&lt;h3&gt;1. ‚ö†Ô∏è ‰∏∫‰ªÄ‰πà‰∏ãËΩΩÂ§±Ë¥•Ôºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â¶ÇÊûúÊÇ®Ê≤°ÊúâËÆæÁΩÆ Access TokenÔºåÂèØËÉΩÊòØÊú¨Â∑•ÂÖ∑‰ΩøÁî®ÁöÑÊñπÊ≥ïÂ§±Êïà‰∫ÜÔºåËØ∑&lt;a href="https://raw.githubusercontent.com/happycola233/tchMaterial-parser/main/#2--%E8%AE%BE%E7%BD%AE-access-token%E5%8F%AF%E9%80%89"&gt;&lt;strong&gt;ËÆæÁΩÆ Access Token&lt;/strong&gt;&lt;/a&gt;üîë„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â¶ÇÊûúÊÇ®ËÆæÁΩÆ‰∫Ü Access TokenÔºåÁî±‰∫éÂÖ∂ÂÖ∑ÊúâÊó∂ÊïàÊÄßÔºà‰∏ÄËà¨‰∏∫ 7 Â§©ÔºâÔºåÂõ†Ê≠§ÊûÅÊúâÂèØËÉΩÊòØ &lt;strong&gt;Access Token ËøáÊúü‰∫Ü&lt;/strong&gt;ÔºåËØ∑ÈáçÊñ∞Ëé∑ÂèñÊñ∞ÁöÑ Access Token„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Á°ÆËÆ§ÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏&lt;/strong&gt;üåêÔºåÊúâÊó∂ÁΩëÁªú‰∏çÁ®≥ÂÆöÂèØËÉΩÂØºËá¥‰∏ãËΩΩÂ§±Ë¥•„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Á°Æ‰øùËæìÂÖ•ÁöÑÁΩëÂùÄÊúâÊïà&lt;/strong&gt;üîóÔºåÈÉ®ÂàÜÊóßËµÑÊ∫êÂèØËÉΩÂ∑≤Ë¢´ÁßªÈô§„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. üíæAccess Token ‰øùÂ≠òÂú®Âì™ÈáåÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;ÔºöToken ‰ºöÂ≠òÂÇ®Âú®&lt;strong&gt;Ê≥®ÂÜåË°®&lt;/strong&gt; &lt;code&gt;HKEY_CURRENT_USER\Software\tchMaterial-parser&lt;/code&gt; È°π‰∏≠ÁöÑ &lt;code&gt;AccessToken&lt;/code&gt; ÂÄº„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: Token ‰ºöÂ≠òÂÇ®Âú®&lt;strong&gt;Êñá‰ª∂&lt;/strong&gt; &lt;code&gt;~/.config/tchMaterial-parser/data.json&lt;/code&gt; ‰∏≠„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;ÔºöToken ‰ºöÂ≠òÂÇ®Âú®&lt;strong&gt;Êñá‰ª∂&lt;/strong&gt; &lt;code&gt;~/Library/Application Support/tchMaterial-parser/data.json&lt;/code&gt; ‰∏≠„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ∂‰ªñÊìç‰ΩúÁ≥ªÁªü&lt;/strong&gt;ÔºöToken ‰ªÖÂú®ËøêË°åÊó∂‰∏¥Êó∂Â≠òÂÇ®‰∫éÂÜÖÂ≠òÔºå‰∏ç‰ºöËá™Âä®‰øùÂ≠òÔºåÁ®ãÂ∫èÈáçÂêØÂêéÈúÄÈáçÊñ∞ËæìÂÖ•ÔºåÁõÆÂâçÊàë‰ª¨Ê≠£Âú®Âä™ÂäõÊîπËøõËØ•ÂäüËÉΩ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. üîêToken ‰ºö‰∏ç‰ºöÊ≥ÑÈú≤Ôºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êú¨Â∑•ÂÖ∑&lt;strong&gt;‰∏ç‰ºö‰∏ä‰º†&lt;/strong&gt; TokenÔºå‰πü‰∏ç‰ºöÂ≠òÂÇ®Âú®‰∫ëÁ´ØÔºå‰ªÖÁî®‰∫éÊú¨Âú∞ËØ∑Ê±ÇÊéàÊùÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËØ∑ÂãøÂú®ÂÖ¨ÂºÄÂú∫ÂêàÂàÜ‰∫´ Token&lt;/strong&gt;Ôºå‰ª•ÂÖçÊÇ®ÁöÑË¥¶Âè∑Ë¢´‰ªñ‰∫∫‰ΩøÁî®ÔºåÈÄ†Êàê‰∏•ÈáçÂêéÊûú„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚≠êStar History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#happycola233/tchMaterial-parser&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=happycola233/tchMaterial-parser&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Â¶ÇÊûúÊÇ®ÂèëÁé∞ Bug ÊàñÊúâÊîπËøõÂª∫ËÆÆÔºåÊ¨¢ËøéÊèê‰∫§ &lt;strong&gt;Issue&lt;/strong&gt; Êàñ &lt;strong&gt;Pull Request&lt;/strong&gt;ÔºåËÆ©Êàë‰ª¨‰∏ÄËµ∑ÂÆåÂñÑÊú¨Â∑•ÂÖ∑ÔºÅ&lt;/p&gt; 
&lt;h2&gt;üìú ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÂü∫‰∫é &lt;a href="https://raw.githubusercontent.com/happycola233/tchMaterial-parser/main/LICENSE"&gt;MIT ËÆ∏ÂèØËØÅ&lt;/a&gt;ÔºåÊ¨¢ËøéËá™Áî±‰ΩøÁî®Âíå‰∫åÊ¨°ÂºÄÂèë„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üíå ÂèãÊÉÖÈìæÊé•&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìö ÊÇ®‰πüÂèØ‰ª•Âú® &lt;a href="https://github.com/TapXWorld/ChinaTextbook"&gt;ChinaTextbook&lt;/a&gt; È°πÁõÆ‰∏≠‰∏ãËΩΩÂΩíÊ°£ÁöÑÁîµÂ≠êËØæÊú¨ PDF„ÄÇ&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/ChatDev</title>
      <link>https://github.com/OpenBMB/ChatDev</link>
      <description>&lt;p&gt;ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatDev 2.0 - DevAll&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/frontend/public/media/logo.png" alt="DevAll Logo" width="500" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê&lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README-zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;p align="center"&gt; „Äêüìö &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developers&lt;/a&gt; | üë• &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#primary-contributors"&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;h2&gt;üìñ Overview&lt;/h2&gt; 
&lt;p&gt;ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/main"&gt;&lt;strong&gt;ChatDev 2.0 (DevAll)&lt;/strong&gt;&lt;/a&gt; is a &lt;strong&gt;Zero-Code Multi-Agent Platform&lt;/strong&gt; for "Developing Everything". It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;strong&gt;ChatDev 1.0 (Legacy)&lt;/strong&gt;&lt;/a&gt; operates as a &lt;strong&gt;Virtual Software Company&lt;/strong&gt;. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;p&gt;‚Ä¢ &lt;strong&gt;Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!&lt;/strong&gt; This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;code&gt;chatdev1.0&lt;/code&gt;&lt;/a&gt; branch for maintenance. More details about ChatDev 2.0 can be found on &lt;a href="https://x.com/OpenBMB/status/2008916790399701335"&gt;our official post&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Old News&lt;/summary&gt; 
 &lt;p&gt;‚Ä¢Sep 24, 2025: üéâ Our paper &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt; has been accepted to NeurIPS 2025. The implementation is available in the &lt;code&gt;puppeteer&lt;/code&gt; branch of this repository.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks. See our paper in &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/puppeteer.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a &lt;a href="https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook"&gt;open-source&lt;/a&gt; interactive e-booküìö format. Now you can explore the latest advancements on the &lt;a href="https://thinkwee.top/multiagent_ebook"&gt;Ebook Website&lt;/a&gt; and download the &lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/MultiAgentEbook/papers.csv"&gt;paper list&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ebook.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev's chain-shaped topology. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2406.07155"&gt;https://arxiv.org/abs/2406.07155&lt;/a&gt;. This technique has been incorporated into the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/macnet"&gt;macnet&lt;/a&gt; branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/macnet.png" width="500" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ May 07, 2024, we introduced "Iterative Experience Refinement" (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2405.04219"&gt;https://arxiv.org/abs/2405.04219&lt;/a&gt;, and this technique will soon be incorporated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ier.png" width="220" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#co-tracking"&gt;Experiential Co-Learning Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency. Check out our preprint paper at &lt;a href="https://arxiv.org/abs/2312.17025"&gt;https://arxiv.org/abs/2312.17025&lt;/a&gt; and this technique will soon be integrated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ecl.png" width="860" /&gt; &lt;/p&gt; ‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/. 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/saas.png" width="560" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try &lt;code&gt;--config "incremental" --path "[source_code_directory_path]"&lt;/code&gt; to start it.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/increment.png" width="700" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from &lt;a href="https://github.com/ManindraDeMel"&gt;ManindraDeMel&lt;/a&gt;). Please see &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#docker-start"&gt;Docker Start Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/docker.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 25, 2023: The &lt;strong&gt;Git&lt;/strong&gt; mode is now available, enabling the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt; to utilize Git for version control. To enable this feature, simply set &lt;code&gt;"git_management"&lt;/code&gt; to &lt;code&gt;"True"&lt;/code&gt; in &lt;code&gt;ChatChainConfig.json&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#git-mode"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/github.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 20, 2023: The &lt;strong&gt;Human-Agent-Interaction&lt;/strong&gt; mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/reviewer.png" height="20" /&gt; and making suggestions to the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt;; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Human"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#human-agent-interaction"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/Gomoku_HumanAgentInteraction_20230920135038"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/Human_intro.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 1, 2023: The &lt;strong&gt;Art&lt;/strong&gt; mode is available now! You can activate the designer agent &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/designer.png" height="20" /&gt; to generate images used in the software; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Art"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#art"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/gomokugameArtExample_THUNLP_20230831122822"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 28, 2023: The system is publicly available.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay mode are now supported.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 16, 2023: The &lt;a href="https://arxiv.org/abs/2307.07924"&gt;preprint paper&lt;/a&gt; associated with this project was published.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: macOS / Linux / WSL / Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;: &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Backend Dependencies&lt;/strong&gt; (Python managed by &lt;code&gt;uv&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Dependencies&lt;/strong&gt; (Vite + Vue 3):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend &amp;amp;&amp;amp; npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;‚ö°Ô∏è Run the Application&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Backend&lt;/strong&gt; :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Run from the project root
uv run python server_main.py --port 6400 --reload
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Remove &lt;code&gt;--reload&lt;/code&gt; if output files (e.g., GameDev) trigger restarts, which interrupts tasks and loses progress.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Frontend&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
VITE_API_BASE_URL=http://localhost:6400 npm run dev
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Then access the Web Console at &lt;strong&gt;&lt;a href="http://localhost:5173"&gt;http://localhost:5173&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: If the frontend fails to connect to the backend, the default port &lt;code&gt;6400&lt;/code&gt; may already be occupied. Please switch both services to an available port, for example:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: start with &lt;code&gt;--port 6401&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: set &lt;code&gt;VITE_API_BASE_URL=http://localhost:6401&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîë Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;: Create a &lt;code&gt;.env&lt;/code&gt; file in the project root.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Keys&lt;/strong&gt;: Set &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;BASE_URL&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; for your LLM provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YAML placeholders&lt;/strong&gt;: Use &lt;code&gt;${VAR}&lt;/code&gt;Ôºàe.g., &lt;code&gt;${API_KEY}&lt;/code&gt;Ôºâin configuration files to reference these variables.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° How to Use&lt;/h2&gt; 
&lt;h3&gt;üñ•Ô∏è Web Console&lt;/h3&gt; 
&lt;p&gt;The DevAll interface provides a seamless experience for both construction and execution&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/tutorial-en.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow&lt;/strong&gt;: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/workflow.gif" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Launch&lt;/strong&gt;: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/launch.gif" /&gt; 
&lt;h3&gt;üß∞ Python SDK&lt;/h3&gt; 
&lt;p&gt;For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file="yaml_instance/demo.yaml",
    task_prompt="Summarize the attached document in one sentence.",
    attachments=["/path/to/document.pdf"],
    variables={"API_KEY": "sk-xxxx"} # Override .env variables if needed
)

if result.final_message:
    print(f"Output: {result.final_message.text_content()}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="developers"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è For Developers&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For secondary development and extensions, please proceed with this section.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend DevAll with new nodes, providers, and tools. The project is organized into a modular structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Systems&lt;/strong&gt;: &lt;code&gt;server/&lt;/code&gt; hosts the FastAPI backend, while &lt;code&gt;runtime/&lt;/code&gt; manages agent abstraction and tool execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestration&lt;/strong&gt;: &lt;code&gt;workflow/&lt;/code&gt; handles the multi-agent logic, driven by configurations in &lt;code&gt;entity/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;code&gt;frontend/&lt;/code&gt; contains the Vue 3 Web Console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: &lt;code&gt;functions/&lt;/code&gt; is the place for custom Python tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Relevant reference documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/index.md"&gt;Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core Modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/workflow_authoring.md"&gt;Workflow Authoring&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/memory.md"&gt;Memory&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/tooling/index.md"&gt;Tooling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Featured Workflows&lt;/h2&gt; 
&lt;p&gt;We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in &lt;code&gt;yaml_instance/&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Files named &lt;code&gt;demo_*.yaml&lt;/code&gt; showcase specific features or modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementations&lt;/strong&gt;: Files named directly (e.g., &lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;) are full in-house or recreated workflows. As follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Workflow Collection&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Category&lt;/th&gt; 
   &lt;th align="left"&gt;Workflow&lt;/th&gt; 
   &lt;th align="left"&gt;Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìà Data Visualization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data_visualization_basic.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;data_visualization_enhanced.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/data_analysis/data_analysis.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üõ†Ô∏è 3D Generation&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;(Requires &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ahujasid/blender-mcp"&gt;blender-mcp&lt;/a&gt;)&lt;/em&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;blender_3d_builder_simple.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_3d_builder_hub.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_scientific_illustration.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/3d_generation/3d.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please build a Christmas tree."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéÆ Game Dev&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;GameDev_v1.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/game_development/game.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please help me design and develop a Tank Battle game."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìö Deep Research&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;deep_research_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/deep_research/deep_research.gif" width="85%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Research about recent advances in the field of LLM-based agent RL"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéì Teach Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;teach_video.yaml&lt;/code&gt; (Please run command &lt;code&gt;uv add manim&lt;/code&gt; before running this workflow)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/video_generation/video.gif" width="140%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí° Usage Guide&lt;/h3&gt; 
&lt;p&gt;For those implementations, you can use the &lt;strong&gt;Launch&lt;/strong&gt; tab to execute them.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose a workflow in the &lt;strong&gt;Launch&lt;/strong&gt; tab.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt;: Upload necessary files (e.g., &lt;code&gt;.csv&lt;/code&gt; for data analysis) if required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Enter your request (e.g., &lt;em&gt;"Visualize the sales trends"&lt;/em&gt; or &lt;em&gt;"Design a snake game"&lt;/em&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting &lt;strong&gt;Issues&lt;/strong&gt; or &lt;strong&gt;Pull Requests&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;By contributing to DevAll, you'll be recognized in our &lt;strong&gt;Contributors&lt;/strong&gt; list below. Check out our &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developer Guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;h3&gt;üë• Contributors&lt;/h3&gt; 
&lt;h4&gt;Primary Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/NA-Wen"&gt;&lt;img src="https://github.com/NA-Wen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zxrys"&gt;&lt;img src="https://github.com/zxrys.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/swugi"&gt;&lt;img src="https://github.com/swugi.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/huatl98"&gt;&lt;img src="https://github.com/huatl98.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/shiowen"&gt;&lt;img src="https://github.com/shiowen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kilo2127"&gt;&lt;img src="https://github.com/kilo2127.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AckerlyLau"&gt;&lt;img src="https://github.com/AckerlyLau.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/thunlp.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://modelbest.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/modelbest.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/AgentVerse/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/agentverse.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/RepoAgent"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/repoagent.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/CommandDash.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/www.teachmaster.cn"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/teachmaster.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OpenBMB/AppCopilot"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/appcopilot.png" height="50pt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîé Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üì¨ Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at &lt;a href="mailto:qianc62@gmail.com"&gt;qianc62@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üî¨ Open Deep Research&lt;/h1&gt; 
&lt;img width="1388" height="298" alt="full_diagram" src="https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69" /&gt; 
&lt;p&gt;Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers. It's performance is on par with many popular deep research agents (&lt;a href="https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard"&gt;see Deep Research Bench leaderboard&lt;/a&gt;).&lt;/p&gt; 
&lt;img width="817" height="666" alt="Screenshot 2025-07-13 at 11 21 12‚ÄØPM" src="https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f" /&gt; 
&lt;h3&gt;üî• Recent Updates&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;August 14, 2025&lt;/strong&gt;: See our free course &lt;a href="https://academy.langchain.com/courses/deep-research-with-langgraph"&gt;here&lt;/a&gt; (and course repo &lt;a href="https://github.com/langchain-ai/deep_research_from_scratch"&gt;here&lt;/a&gt;) on building open deep research.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;August 7, 2025&lt;/strong&gt;: Added GPT-5 and updated the Deep Research Bench evaluation w/ GPT-5 results.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;August 2, 2025&lt;/strong&gt;: Achieved #6 ranking on the &lt;a href="https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard"&gt;Deep Research Bench Leaderboard&lt;/a&gt; with an overall score of 0.4344.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;July 30, 2025&lt;/strong&gt;: Read about the evolution from our original implementations to the current version in our &lt;a href="https://rlancemartin.github.io/2025/07/30/bitter_lesson/"&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;July 16, 2025&lt;/strong&gt;: Read more in our &lt;a href="https://blog.langchain.com/open-deep-research/"&gt;blog&lt;/a&gt; and watch our &lt;a href="https://www.youtube.com/watch?v=agGiWUpxkhg"&gt;video&lt;/a&gt; for a quick overview.&lt;/p&gt; 
&lt;h3&gt;üöÄ Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository and activate a virtual environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
# or
uv pip install -r pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file to customize the environment variables (for model selection, search tools, and other configuration settings):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Launch agent with the LangGraph server locally:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will open the LangGraph Studio UI in your browser.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- üöÄ API: http://127.0.0.1:2024
- üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- üìö API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ask a question in the &lt;code&gt;messages&lt;/code&gt; input field and click &lt;code&gt;Submit&lt;/code&gt;. Select different configuration in the "Manage Assistants" tab.&lt;/p&gt; 
&lt;h3&gt;‚öôÔ∏è Configurations&lt;/h3&gt; 
&lt;h4&gt;LLM &lt;span&gt;üß†&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports a wide range of LLM providers via the &lt;a href="https://python.langchain.com/docs/how_to/chat_models_universal_init/"&gt;init_chat_model() API&lt;/a&gt;. It uses LLMs for a few different tasks. See the below model fields in the &lt;a href="https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py"&gt;configuration.py&lt;/a&gt; file for more details. This can be accessed via the LangGraph Studio UI.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Summarization&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-mini&lt;/code&gt;): Summarizes search API results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Power the search agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Compresses research findings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Final Report Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Write the final report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the selected model will need to support &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;structured outputs&lt;/a&gt; and &lt;a href="https://python.langchain.com/docs/how_to/tool_calling/"&gt;tool calling&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: For OpenRouter: Follow &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408"&gt;this guide&lt;/a&gt; and for local models via Ollama see &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318"&gt;setup instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Search API &lt;span&gt;üîç&lt;/span&gt;&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports a wide range of search tools. By default it uses the &lt;a href="https://www.tavily.com/"&gt;Tavily&lt;/a&gt; search API. Has full MCP compatibility and work native web search for Anthropic and OpenAI. See the &lt;code&gt;search_api&lt;/code&gt; and &lt;code&gt;mcp_config&lt;/code&gt; fields in the &lt;a href="https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py"&gt;configuration.py&lt;/a&gt; file for more details. This can be accessed via the LangGraph Studio UI.&lt;/p&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;See the fields in the &lt;a href="https://github.com/langchain-ai/open_deep_research/raw/main/src/open_deep_research/configuration.py"&gt;configuration.py&lt;/a&gt; for various other settings to customize the behavior of Open Deep Research.&lt;/p&gt; 
&lt;h3&gt;üìä Evaluation&lt;/h3&gt; 
&lt;p&gt;Open Deep Research is configured for evaluation with &lt;a href="https://huggingface.co/spaces/Ayanami0730/DeepResearch-Leaderboard"&gt;Deep Research Bench&lt;/a&gt;. This benchmark has 100 PhD-level research tasks (50 English, 50 Chinese), crafted by domain experts across 22 fields (e.g., Science &amp;amp; Tech, Business &amp;amp; Finance) to mirror real-world deep-research needs. It has 2 evaluation metrics, but the leaderboard is based on the RACE score. This uses LLM-as-a-judge (Gemini) to evaluate research reports against a golden set of reports compiled by experts across a set of metrics.&lt;/p&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Warning: Running across the 100 examples can cost ~$20-$100 depending on the model selection.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The dataset is available on &lt;a href="https://smith.langchain.com/public/c5e7a6ad-fdba-478c-88e6-3a388459ce8b/d"&gt;LangSmith via this link&lt;/a&gt;. To kick off evaluation, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will provide a link to a LangSmith experiment, which will have a name &lt;code&gt;YOUR_EXPERIMENT_NAME&lt;/code&gt;. Once this is done, extract the results to a JSONL file that can be submitted to the Deep Research Bench.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python tests/extract_langsmith_data.py --project-name "YOUR_EXPERIMENT_NAME" --model-name "you-model-name" --dataset-name "deep_research_bench"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates &lt;code&gt;tests/expt_results/deep_research_bench_model-name.jsonl&lt;/code&gt; with the required format. Move the generated JSONL file to a local clone of the Deep Research Bench repository and follow their &lt;a href="https://github.com/Ayanami0730/deep_research_bench?tab=readme-ov-file#quick-start"&gt;Quick Start guide&lt;/a&gt; for evaluation submission.&lt;/p&gt; 
&lt;h4&gt;Results&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Commit&lt;/th&gt; 
   &lt;th&gt;Summarization&lt;/th&gt; 
   &lt;th&gt;Research&lt;/th&gt; 
   &lt;th&gt;Compression&lt;/th&gt; 
   &lt;th&gt;Total Cost&lt;/th&gt; 
   &lt;th&gt;Total Tokens&lt;/th&gt; 
   &lt;th&gt;RACE Score&lt;/th&gt; 
   &lt;th&gt;Experiment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPT-5&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/langchain-ai/open_deep_research/pull/168/commits"&gt;ca3951d&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;openai:gpt-5&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;204,640,896&lt;/td&gt; 
   &lt;td&gt;0.4943&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-613c-4bda-8bde-f64f0422bbf3/compare?selectedSessions=4d5941c8-69ce-4f3d-8b3e-e3c99dfbd4cc&amp;amp;baseline=undefined"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Defaults&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/langchain-ai/open_deep_research/commit/6532a4176a93cc9bb2102b3d825dcefa560c85d9"&gt;6532a41&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$45.98&lt;/td&gt; 
   &lt;td&gt;58,015,332&lt;/td&gt; 
   &lt;td&gt;0.4309&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=cf4355d7-6347-47e2-a774-484f290e79bc&amp;amp;baseline=undefined"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Claude Sonnet 4&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/langchain-ai/open_deep_research/pull/163/commits/f877ea93641680879c420ea991e998b47aab9bcc"&gt;f877ea9&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-mini&lt;/td&gt; 
   &lt;td&gt;anthropic:claude-sonnet-4-20250514&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$187.09&lt;/td&gt; 
   &lt;td&gt;138,917,050&lt;/td&gt; 
   &lt;td&gt;0.4401&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=04f6002d-6080-4759-bcf5-9a52e57449ea&amp;amp;baseline=undefined"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deep Research Bench Submission&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/langchain-ai/open_deep_research/commit/c0a160b57a9b5ecd4b8217c3811a14d8eff97f72"&gt;c0a160b&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1-nano&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;openai:gpt-4.1&lt;/td&gt; 
   &lt;td&gt;$87.83&lt;/td&gt; 
   &lt;td&gt;207,005,549&lt;/td&gt; 
   &lt;td&gt;0.4344&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/6e4766ca-6%5B%E2%80%A6%5Dons=e6647f74-ad2f-4cb9-887e-acb38b5f73c0&amp;amp;baseline=undefined"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üöÄ Deployments and Usage&lt;/h3&gt; 
&lt;h4&gt;LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;Follow the &lt;a href="https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart"&gt;quickstart&lt;/a&gt; to start LangGraph server locally and test the agent out on LangGraph Studio.&lt;/p&gt; 
&lt;h4&gt;Hosted deployment&lt;/h4&gt; 
&lt;p&gt;You can easily deploy to &lt;a href="https://langchain-ai.github.io/langgraph/concepts/#deployment-options"&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Open Agent Platform&lt;/h4&gt; 
&lt;p&gt;Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.&lt;/p&gt; 
&lt;p&gt;We've deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out &lt;a href="https://oap.langchain.com"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/quickstart"&gt;Deploy Open Agent Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/setup/agents"&gt;Add Deep Researcher to OAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Legacy Implementations üèõÔ∏è&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;src/legacy/&lt;/code&gt; folder contains two earlier implementations that provide alternative approaches to automated research. They are less performant than the current implementation, but provide alternative ideas understanding the different approaches to deep research.&lt;/p&gt; 
&lt;h4&gt;1. Workflow Implementation (&lt;code&gt;legacy/graph.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plan-and-Execute&lt;/strong&gt;: Structured workflow with human-in-the-loop planning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequential Processing&lt;/strong&gt;: Creates sections one by one with reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Control&lt;/strong&gt;: Allows feedback and approval of report plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Focused&lt;/strong&gt;: Emphasizes accuracy through iterative refinement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Multi-Agent Implementation (&lt;code&gt;legacy/multi_agent.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervisor-Researcher Architecture&lt;/strong&gt;: Coordinated multi-agent system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing&lt;/strong&gt;: Multiple researchers work simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Optimized&lt;/strong&gt;: Faster report generation through concurrency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Support&lt;/strong&gt;: Extensive Model Context Protocol integration&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>davila7/claude-code-templates</title>
      <link>https://github.com/davila7/claude-code-templates</link>
      <description>&lt;p&gt;CLI tool for configuring and monitoring Claude Code&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://www.npmjs.com/package/claude-code-templates"&gt;&lt;img src="https://img.shields.io/npm/v/claude-code-templates.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/claude-code-templates"&gt;&lt;img src="https://img.shields.io/npm/dt/claude-code-templates.svg?sanitize=true" alt="npm downloads" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CONTRIBUTING.md"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?sanitize=true" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB&amp;amp;utm_source=github&amp;amp;utm_medium=badge&amp;amp;utm_campaign=readme"&gt;&lt;img src="https://img.shields.io/badge/Sponsored%20by-Z.AI-2563eb?style=flat&amp;amp;logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEyIDJMMiAyMkgyMkwxMiAyWiIgZmlsbD0id2hpdGUiLz4KPC9zdmc+" alt="Sponsored by Z.AI" /&gt;&lt;/a&gt; &lt;a href="https://get.neon.com/4eCjZDz"&gt;&lt;img src="https://img.shields.io/badge/Neon-Open%20Source%20Program-00E599?style=flat" alt="Neon Open Source Program" /&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/daniavila"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20A%20Coffee-support-yellow?style=flat&amp;amp;logo=buy-me-a-coffee" alt="Buy Me A Coffee" /&gt;&lt;/a&gt; &lt;a href="https://github.com/davila7/claude-code-templates"&gt;&lt;img src="https://img.shields.io/github/stars/davila7/claude-code-templates.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15113" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15113" alt="davila7%2Fclaude-code-templates | Trendshift" style="width: 200px; height: 40px;" width="125" height="40" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://vercel.com/oss"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" /&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; &lt;a href="https://get.neon.com/4eCjZDz"&gt; &lt;img alt="Neon Open Source Program" src="https://img.shields.io/badge/Neon-Open%20Source%20Program-00E599?style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ü§ù Partnership&lt;/h3&gt; 
 &lt;p&gt; &lt;strong&gt;This project is sponsored by &lt;a href="https://z.ai" target="_blank"&gt;Z.AI&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; Supporting Claude Code Templates with the &lt;strong&gt;GLM CODING PLAN&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://z.ai/subscribe?ic=8JVLJQFSKB&amp;amp;utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=partnership" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/Get%2010%25%20OFF-GLM%20Coding%20Plan-2563eb?style=for-the-badge" alt="GLM Coding Plan" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;em&gt;Top-tier coding performance powered by GLM-4.6 ‚Ä¢ Starting at $3/month&lt;/em&gt;&lt;br /&gt; &lt;em&gt;Seamlessly integrates with Claude Code, Cursor, Cline &amp;amp; 10+ AI coding tools&lt;/em&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;code&gt;npx claude-code-templates@latest --setting partnerships/glm-coding-plan --yes&lt;/code&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Claude Code Templates (&lt;a href="https://aitmpl.com"&gt;aitmpl.com&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Ready-to-use configurations for Anthropic's Claude Code.&lt;/strong&gt; A comprehensive collection of AI agents, custom commands, settings, hooks, external integrations (MCPs), and project templates to enhance your development workflow.&lt;/p&gt; 
&lt;h2&gt;Browse &amp;amp; Install Components and Templates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aitmpl.com"&gt;Browse All Templates&lt;/a&gt;&lt;/strong&gt; - Interactive web interface to explore and install 100+ agents, commands, settings, hooks, and MCPs.&lt;/p&gt; 
&lt;img width="1049" height="855" alt="Screenshot 2025-08-19 at 08 09 24" src="https://github.com/user-attachments/assets/e3617410-9b1c-4731-87b7-a3858800b737" /&gt; 
&lt;h2&gt;üöÄ Quick Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install a complete development stack
npx claude-code-templates@latest --agent development-team/frontend-developer --command testing/generate-tests --mcp development/github-integration --yes

# Browse and install interactively
npx claude-code-templates@latest

# Install specific components
npx claude-code-templates@latest --agent development-tools/code-reviewer --yes
npx claude-code-templates@latest --command performance/optimize-bundle --yes
npx claude-code-templates@latest --setting performance/mcp-timeouts --yes
npx claude-code-templates@latest --hook git/pre-commit-validation --yes
npx claude-code-templates@latest --mcp database/postgresql-integration --yes
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What You Get&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ü§ñ Agents&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;AI specialists for specific domains&lt;/td&gt; 
   &lt;td&gt;Security auditor, React performance optimizer, database architect&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚ö° Commands&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom slash commands&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/generate-tests&lt;/code&gt;, &lt;code&gt;/optimize-bundle&lt;/code&gt;, &lt;code&gt;/check-security&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîå MCPs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;External service integrations&lt;/td&gt; 
   &lt;td&gt;GitHub, PostgreSQL, Stripe, AWS, OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è Settings&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Claude Code configurations&lt;/td&gt; 
   &lt;td&gt;Timeouts, memory settings, output styles&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ü™ù Hooks&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automation triggers&lt;/td&gt; 
   &lt;td&gt;Pre-commit validation, post-completion actions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üé® Skills&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Reusable capabilities with progressive disclosure&lt;/td&gt; 
   &lt;td&gt;PDF processing, Excel automation, custom workflows&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üõ†Ô∏è Additional Tools&lt;/h2&gt; 
&lt;p&gt;Beyond the template catalog, Claude Code Templates includes powerful development tools:&lt;/p&gt; 
&lt;h3&gt;üìä Claude Code Analytics&lt;/h3&gt; 
&lt;p&gt;Monitor your AI-powered development sessions in real-time with live state detection and performance metrics.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --analytics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üí¨ Conversation Monitor&lt;/h3&gt; 
&lt;p&gt;Mobile-optimized interface to view Claude responses in real-time with secure remote access.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local access
npx claude-code-templates@latest --chats

# Secure remote access via Cloudflare Tunnel
npx claude-code-templates@latest --chats --tunnel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîç Health Check&lt;/h3&gt; 
&lt;p&gt;Comprehensive diagnostics to ensure your Claude Code installation is optimized.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --health-check
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîå Plugin Dashboard&lt;/h3&gt; 
&lt;p&gt;View marketplaces, installed plugins, and manage permissions from a unified interface.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx claude-code-templates@latest --plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.aitmpl.com/"&gt;üìö docs.aitmpl.com&lt;/a&gt;&lt;/strong&gt; - Complete guides, examples, and API reference for all components and tools.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! &lt;strong&gt;&lt;a href="https://aitmpl.com"&gt;Browse existing templates&lt;/a&gt;&lt;/strong&gt; to see what's available, then check our &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to add your own agents, commands, MCPs, settings, or hooks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Please read our &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; before contributing.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Attribution&lt;/h2&gt; 
&lt;p&gt;This collection includes components from multiple sources:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Scientific Skills:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/K-Dense-AI/claude-scientific-skills"&gt;K-Dense-AI/claude-scientific-skills&lt;/a&gt;&lt;/strong&gt; by K-Dense Inc. - MIT License (139 scientific skills for biology, chemistry, medicine, and computational research)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Official Anthropic:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/anthropics/skills"&gt;anthropics/skills&lt;/a&gt;&lt;/strong&gt; - Official Anthropic skills (21 skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/anthropics/claude-code"&gt;anthropics/claude-code&lt;/a&gt;&lt;/strong&gt; - Development guides and examples (10 skills)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Community Skills &amp;amp; Agents:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/obra/superpowers"&gt;obra/superpowers&lt;/a&gt;&lt;/strong&gt; by Jesse Obra - MIT License (14 workflow skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/alirezarezvani/claude-skills"&gt;alirezarezvani/claude-skills&lt;/a&gt;&lt;/strong&gt; by Alireza Rezvani - MIT License (36 professional role skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/wshobson/agents"&gt;wshobson/agents&lt;/a&gt;&lt;/strong&gt; by wshobson - MIT License (48 agents)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NerdyChefsAI Skills&lt;/strong&gt; - Community contribution - MIT License (specialized enterprise skills)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Commands &amp;amp; Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;awesome-claude-code&lt;/a&gt;&lt;/strong&gt; by hesreallyhim - CC0 1.0 Universal (21 commands)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/mehdi-lamrani/awesome-claude-skills"&gt;awesome-claude-skills&lt;/a&gt;&lt;/strong&gt; - Apache 2.0 (community skills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;move-code-quality-skill&lt;/strong&gt; - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;cocoindex-claude&lt;/strong&gt; - Apache 2.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each of these resources retains its &lt;strong&gt;original license and attribution&lt;/strong&gt;, as defined by their respective authors. We respect and credit all original creators for their work and contributions to the Claude ecosystem.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/davila7/claude-code-templates/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üîó Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browse Templates&lt;/strong&gt;: &lt;a href="https://aitmpl.com"&gt;aitmpl.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Documentation&lt;/strong&gt;: &lt;a href="https://docs.aitmpl.com"&gt;docs.aitmpl.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí¨ Community&lt;/strong&gt;: &lt;a href="https://github.com/davila7/claude-code-templates/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêõ Issues&lt;/strong&gt;: &lt;a href="https://github.com/davila7/claude-code-templates/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/davila7/claude-code-templates"&gt;&lt;img src="https://starchart.cc/davila7/claude-code-templates.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;‚≠ê Found this useful? Give us a star to support the project!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://buymeacoffee.com/daniavila"&gt;&lt;img src="https://img.buymeacoffee.com/button-api/?text=Buy%20me%20a%20coffee&amp;amp;slug=daniavila&amp;amp;button_colour=FFDD00&amp;amp;font_colour=000000&amp;amp;font_family=Cookie&amp;amp;outline_colour=000000&amp;amp;coffee_colour=ffffff" alt="Buy Me A Coffee" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind" alt="visitors" /&gt; &lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jingyaogong/minimind?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jingyaogong/minimind" alt="GitHub Code License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/jingyaogong/minimind" alt="GitHub last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue" alt="GitHub pull request" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue" alt="Collection" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12586" alt="GitHub Trend" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;"Â§ßÈÅìËá≥ÁÆÄ"&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‰∏≠Êñá | &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê≠§ÂºÄÊ∫êÈ°πÁõÆÊó®Âú®ÂÆåÂÖ®‰ªé0ÂºÄÂßãÔºå‰ªÖÁî®3ÂùóÈí±ÊàêÊú¨ + 2Â∞èÊó∂ÔºÅÂç≥ÂèØËÆ≠ÁªÉÂá∫‰ªÖ‰∏∫25.8MÁöÑË∂ÖÂ∞èËØ≠Ë®ÄÊ®°Âûã&lt;strong&gt;MiniMind&lt;/strong&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;Á≥ªÂàóÊûÅÂÖ∂ËΩªÈáèÔºåÊúÄÂ∞èÁâàÊú¨‰ΩìÁßØÊòØ GPT-3 ÁöÑ $\frac{1}{7000}$ÔºåÂäõÊ±ÇÂÅöÂà∞ÊúÄÊôÆÈÄöÁöÑ‰∏™‰∫∫GPU‰πüÂèØÂø´ÈÄüËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÂêåÊó∂ÂºÄÊ∫ê‰∫ÜÂ§ßÊ®°ÂûãÁöÑÊûÅÁÆÄÁªìÊûÑ-ÂåÖÂê´ÊãìÂ±ïÂÖ±‰∫´Ê∑∑Âêà‰∏ìÂÆ∂(MoE)„ÄÅÊï∞ÊçÆÈõÜÊ∏ÖÊ¥ó„ÄÅÈ¢ÑËÆ≠ÁªÉ(Pretrain)„ÄÅÁõëÁù£ÂæÆË∞É(SFT)„ÄÅLoRAÂæÆË∞É„ÄÅÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ(DPO)„ÄÅÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ(RLAIF: PPO/GRPOÁ≠â)„ÄÅÊ®°ÂûãËí∏È¶èÁ≠âÂÖ®ËøáÁ®ã‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;ÂêåÊó∂ÊãìÂ±ï‰∫ÜËßÜËßâÂ§öÊ®°ÊÄÅÁöÑVLM: &lt;a href="https://github.com/jingyaogong/minimind-v"&gt;MiniMind-V&lt;/a&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÊâÄÊúâÊ†∏ÂøÉÁÆóÊ≥ï‰ª£Á†ÅÂùá‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÈáçÊûÑÔºÅ‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÊèê‰æõÁöÑÊäΩË±°Êé•Âè£„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Ëøô‰∏ç‰ªÖÊòØÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®Èò∂ÊÆµÂºÄÊ∫êÂ§çÁé∞Ôºå‰πüÊòØ‰∏Ä‰∏™ÂÖ•Èó®LLMÁöÑÊïôÁ®ã„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â∏åÊúõÊ≠§È°πÁõÆËÉΩ‰∏∫ÊâÄÊúâ‰∫∫Êèê‰æõ‰∏Ä‰∏™ÊäõÁ†ñÂºïÁéâÁöÑÁ§∫‰æãÔºå‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÔºÅÊé®Âä®Êõ¥ÂπøÊ≥õAIÁ§æÂå∫ÁöÑËøõÊ≠•ÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏∫Èò≤Ê≠¢ËØØËß£Ôºå‚Äú2Â∞èÊó∂‚Äù Âü∫‰∫éNVIDIA 3090Á°¨‰ª∂ËÆæÂ§áÔºàÂçïÂç°ÔºâÊµãËØïÔºå‚Äú3ÂùóÈí±‚ÄùÊåáGPUÊúçÂä°Âô®ÁßüÁî®ÊàêÊú¨ÔºåÂÖ∑‰ΩìËßÑÊ†ºËØ¶ÊÉÖËßÅ‰∏ãÊñá„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif" alt="minimind2" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning"&gt;üîóüçìÊé®ÁêÜÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind"&gt;üîóü§ñÂ∏∏ËßÑÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8"&gt;üîóüéûÔ∏èËßÜÈ¢ë‰ªãÁªç&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align="center"&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png" alt="Hugging Face Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align="center"&gt; &lt;a href="https://www.modelscope.cn/profile/gongjy" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png" alt="ModelScope Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;üìå Introduction&lt;/h1&gt; 
&lt;p&gt;Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLarge Language Model, LLMÔºâÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂÖ®‰∏ñÁïåÂØπAIÁöÑÁ©∫ÂâçÂÖ≥Ê≥®„ÄÇ Êó†ËÆ∫ÊòØChatGPT„ÄÅDeepSeekËøòÊòØQwenÔºåÈÉΩ‰ª•ÂÖ∂ÊÉäËâ≥ÁöÑÊïàÊûú‰ª§‰∫∫Âèπ‰∏∫ËßÇÊ≠¢„ÄÇ ÁÑ∂ËÄåÔºåÂä®ËæÑÊï∞Áôæ‰∫øÂèÇÊï∞ÁöÑÂ∫ûÂ§ßËßÑÊ®°Ôºå‰ΩøÂæóÂÆÉ‰ª¨ÂØπ‰∏™‰∫∫ËÆæÂ§áËÄåË®Ä‰∏ç‰ªÖÈöæ‰ª•ËÆ≠ÁªÉÔºåÁîöËá≥ËøûÈÉ®ÁΩ≤ÈÉΩÊòæÂæóÈÅ•‰∏çÂèØÂèä„ÄÇ ÊâìÂºÄÂ§ßÊ®°ÂûãÁöÑ‚ÄúÈªëÁõíÂ≠ê‚ÄùÔºåÊé¢Á¥¢ÂÖ∂ÂÜÖÈÉ®Ëøê‰ΩúÊú∫Âà∂ÔºåÂ§ö‰πà‰ª§‰∫∫ÂøÉÊΩÆÊæéÊπÉÔºÅ ÈÅóÊÜæÁöÑÊòØÔºå99%ÁöÑÊé¢Á¥¢Âè™ËÉΩÊ≠¢Ê≠•‰∫é‰ΩøÁî®LoRAÁ≠âÊäÄÊúØÂØπÁé∞ÊúâÂ§ßÊ®°ÂûãËøõË°åÂ∞ëÈáèÂæÆË∞ÉÔºåÂ≠¶‰π†‰∏Ä‰∫õÊñ∞Êåá‰ª§Êàñ‰ªªÂä°„ÄÇ ËøôÂ∞±Â•ΩÊØîÊïôÁâõÈ°øÂ¶Ç‰Ωï‰ΩøÁî®21‰∏ñÁ∫™ÁöÑÊô∫ËÉΩÊâãÊú∫‚Äî‚ÄîËôΩÁÑ∂ÊúâË∂£ÔºåÂç¥ÂÆåÂÖ®ÂÅèÁ¶ª‰∫ÜÁêÜËß£Áâ©ÁêÜÊú¨Ë¥®ÁöÑÂàùË°∑„ÄÇ ‰∏éÊ≠§ÂêåÊó∂ÔºåÁ¨¨‰∏âÊñπÁöÑÂ§ßÊ®°ÂûãÊ°ÜÊû∂ÂíåÂ∑•ÂÖ∑Â∫ìÔºåÂ¶Çtransformers+trlÔºåÂá†‰πéÂè™Êö¥Èú≤‰∫ÜÈ´òÂ∫¶ÊäΩË±°ÁöÑÊé•Âè£„ÄÇ ÈÄöËøáÁü≠Áü≠10Ë°å‰ª£Á†ÅÔºåÂ∞±ËÉΩÂÆåÊàê‚ÄúÂä†ËΩΩÊ®°Âûã+Âä†ËΩΩÊï∞ÊçÆÈõÜ+Êé®ÁêÜ+Âº∫ÂåñÂ≠¶‰π†‚ÄùÁöÑÂÖ®ÊµÅÁ®ãËÆ≠ÁªÉ„ÄÇ ËøôÁßçÈ´òÊïàÁöÑÂ∞ÅË£ÖÂõ∫ÁÑ∂‰æøÂà©Ôºå‰ΩÜ‰πüÂÉè‰∏ÄÊû∂È´òÈÄüÈ£ûËàπÔºåÂ∞ÜÂºÄÂèëËÄÖ‰∏éÂ∫ïÂ±ÇÂÆûÁé∞ÈöîÁ¶ªÂºÄÊù•ÔºåÈòªÁ¢ç‰∫ÜÊ∑±ÂÖ•Êé¢Á©∂LLMÊ†∏ÂøÉ‰ª£Á†ÅÁöÑÊú∫‰ºö„ÄÇ ÁÑ∂ËÄåÔºå‚ÄúÁî®‰πêÈ´òÊãºÂá∫‰∏ÄÊû∂È£ûÊú∫ÔºåËøúÊØîÂùêÂú®Â§¥Á≠âËà±ÈáåÈ£ûË°åÊõ¥ËÆ©‰∫∫ÂÖ¥Â•ãÔºÅ‚Äù„ÄÇ Êõ¥Á≥üÁ≥ïÁöÑÊòØÔºå‰∫íËÅîÁΩë‰∏äÂÖÖÊñ•ÁùÄÂ§ßÈáè‰ªòË¥πËØæÁ®ãÂíåËê•ÈîÄÂè∑Ôºå‰ª•ÊºèÊ¥ûÁôæÂá∫„ÄÅ‰∏ÄÁü•ÂçäËß£ÁöÑÂÜÖÂÆπÊé®ÈîÄAIÊïôÁ®ã„ÄÇ Ê≠£Âõ†Â¶ÇÊ≠§ÔºåÊú¨È°πÁõÆÂàùË°∑ÊòØÊãâ‰ΩéLLMÁöÑÂ≠¶‰π†Èó®ÊßõÔºåËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩ‰ªéÁêÜËß£ÊØè‰∏ÄË°å‰ª£Á†ÅÂºÄÂßãÔºå ‰ªéÈõ∂ÂºÄÂßã‰∫≤ÊâãËÆ≠ÁªÉ‰∏Ä‰∏™ÊûÅÂ∞èÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÊòØÁöÑÔºå‰ªé&lt;strong&gt;Èõ∂ÂºÄÂßãËÆ≠ÁªÉ&lt;/strong&gt;ÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖËøõË°å&lt;strong&gt;Êé®ÁêÜ&lt;/strong&gt;ÔºÅ ÊúÄ‰ΩéÂè™ÈúÄ3ÂùóÈí±‰∏çÂà∞ÁöÑÊúçÂä°Âô®ÊàêÊú¨ÔºåÂ∞±ËÉΩ‰∫≤Ë∫´‰ΩìÈ™å‰ªé0Âà∞1ÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®ËøáÁ®ã„ÄÇ ‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÂêßÔºÅ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ÔºàÊà™Ëá≥2025-10ÔºâMiniMindÁ≥ªÂàóÂ∑≤ÂÆåÊàêÂ§ö‰∏™ÂûãÂè∑Ê®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÊúÄÂ∞è‰ªÖÈúÄ25.8MÔºà0.02BÔºâÔºåÂç≥ÂèØÂÖ∑Â§áÊµÅÁïÖÂØπËØùËÉΩÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Ê®°Âûã (Â§ßÂ∞è)&lt;/th&gt; 
    &lt;th&gt;Êé®ÁêÜÂç†Áî® (Á∫¶)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4√ó26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;È°πÁõÆÂåÖÂê´&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLMÁªìÊûÑÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºàDense+MoEÊ®°ÂûãÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´TokenizerÂàÜËØçÂô®ËØ¶ÁªÜËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´Pretrain„ÄÅSFT„ÄÅLoRA„ÄÅRLHF-DPO„ÄÅRLAIF(PPO/GRPO/SPO)„ÄÅÊ®°ÂûãËí∏È¶èÁöÑÂÖ®ËøáÁ®ãËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Êî∂ÈõÜ„ÄÅËí∏È¶è„ÄÅÊï¥ÁêÜÂπ∂Ê∏ÖÊ¥óÂéªÈáçÊâÄÊúâÈò∂ÊÆµÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰ªé0ÂÆûÁé∞È¢ÑËÆ≠ÁªÉ„ÄÅÊåá‰ª§ÂæÆË∞É„ÄÅLoRA„ÄÅDPO/PPO/GRPO/SPOÂº∫ÂåñÂ≠¶‰π†ÔºåÁôΩÁõíÊ®°ÂûãËí∏È¶è„ÄÇÂÖ≥ÈîÆÁÆóÊ≥ïÂá†‰πé‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∞ÅË£ÖÁöÑÊ°ÜÊû∂Ôºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂêåÊó∂ÂÖºÂÆπ&lt;code&gt;transformers&lt;/code&gt;„ÄÅ&lt;code&gt;trl&lt;/code&gt;„ÄÅ&lt;code&gt;peft&lt;/code&gt;Á≠âÁ¨¨‰∏âÊñπ‰∏ªÊµÅÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆ≠ÁªÉÊîØÊåÅÂçïÊú∫ÂçïÂç°„ÄÅÂçïÊú∫Â§öÂç°(DDP„ÄÅDeepSpeed)ËÆ≠ÁªÉÔºåÊîØÊåÅwandb/swanlabÂèØËßÜÂåñËÆ≠ÁªÉÊµÅÁ®ã„ÄÇÊîØÊåÅÂä®ÊÄÅÂêØÂÅúËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âú®Á¨¨‰∏âÊñπÊµãËØÑÊ¶úÔºàC-Eval„ÄÅC-MMLU„ÄÅOpenBookQAÁ≠âÔºâËøõË°åÊ®°ÂûãÊµãËØïÔºåÊîØÊåÅYaRNÁÆóÊ≥ïÊâßË°åRoPEÈïøÊñáÊú¨Â§ñÊé®„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÆûÁé∞Openai-ApiÂçèËÆÆÁöÑÊûÅÁÆÄÊúçÂä°Á´ØÔºå‰æø‰∫éÈõÜÊàêÂà∞Á¨¨‰∏âÊñπChatUI‰ΩøÁî®ÔºàFastGPT„ÄÅOpen-WebUIÁ≠âÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âü∫‰∫éstreamlitÂÆûÁé∞ÊúÄÁÆÄËÅäÂ§©WebUIÂâçÁ´Ø„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÖ®Èù¢ÂÖºÂÆπÁ§æÂå∫ÁÉ≠Èó®&lt;code&gt;llama.cpp&lt;/code&gt;„ÄÅ&lt;code&gt;vllm&lt;/code&gt;„ÄÅ&lt;code&gt;ollama&lt;/code&gt;Êé®ÁêÜÂºïÊìéÊàñ&lt;code&gt;Llama-Factory&lt;/code&gt;ËÆ≠ÁªÉÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â§çÁé∞(Ëí∏È¶è/RL)Â§ßÂûãÊé®ÁêÜÊ®°ÂûãDeepSeek-R1ÁöÑMiniMind-ReasonÊ®°ÂûãÔºå&lt;strong&gt;Êï∞ÊçÆ+Ê®°Âûã&lt;/strong&gt;ÂÖ®ÈÉ®ÂºÄÊ∫êÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â∏åÊúõÊ≠§ÂºÄÊ∫êÈ°πÁõÆÂèØ‰ª•Â∏ÆÂä©LLMÂàùÂ≠¶ËÄÖÂø´ÈÄüÂÖ•Èó®ÔºÅ&lt;/p&gt; 
&lt;h3&gt;üëâ&lt;strong&gt;Êõ¥Êñ∞Êó•Âøó&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-10-24&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üî• Êñ∞Â¢ûRLAIFËÆ≠ÁªÉÁÆóÊ≥ïÔºöPPO„ÄÅGRPO„ÄÅSPOÔºà‰ªé0ÂéüÁîüÂÆûÁé∞Ôºâ&lt;/li&gt; 
  &lt;li&gt;Êñ∞Â¢ûÊñ≠ÁÇπÁª≠ËÆ≠ÂäüËÉΩÔºöÊîØÊåÅËÆ≠ÁªÉËá™Âä®ÊÅ¢Â§ç„ÄÅË∑®GPUÊï∞ÈáèÊÅ¢Â§ç„ÄÅwandbËÆ∞ÂΩïËøûÁª≠ÊÄß&lt;/li&gt; 
  &lt;li&gt;Êñ∞Â¢ûRLAIFÊï∞ÊçÆÈõÜÔºörlaif-mini.jsonlÔºà‰ªéSFTÊï∞ÊçÆÈöèÊú∫ÈááÊ†∑1‰∏áÊù°ÔºâÔºõÁÆÄÂåñDPOÊï∞ÊçÆÈõÜÔºåÂä†ÂÖ•‰∏≠ÊñáÊï∞ÊçÆ&lt;/li&gt; 
  &lt;li&gt;Êñ∞Â¢ûYaRNÁÆóÊ≥ïÔºöÊîØÊåÅRoPEÈïøÊñáÊú¨Â§ñÊé®ÔºåÊèêÂçáÈïøÂ∫èÂàóÂ§ÑÁêÜËÉΩÂäõ&lt;/li&gt; 
  &lt;li&gt;Adaptive ThinkingÔºöReasonÊ®°ÂûãÂèØÈÄâÊòØÂê¶ÂêØÁî®ÊÄùËÄÉÈìæ&lt;/li&gt; 
  &lt;li&gt;chat_templateÂÖ®Èù¢ÊîØÊåÅTool CallingÂíåReasoningÊ†áÁ≠æÔºà&lt;code&gt;&amp;lt;tool_call&amp;gt;&lt;/code&gt;„ÄÅ&lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;Á≠âÔºâ&lt;/li&gt; 
  &lt;li&gt;Êñ∞Â¢ûRLAIFÂÆåÊï¥Á´†ËäÇ„ÄÅËÆ≠ÁªÉÊõ≤Á∫øÂØπÊØî„ÄÅÁÆóÊ≥ïÂéüÁêÜÊäòÂè†ËØ¥Êòé&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swanlab.cn/"&gt;SwanLab&lt;/a&gt;Êõø‰ª£WandBÔºàÂõΩÂÜÖËÆøÈóÆÂèãÂ•ΩÔºåAPIÂÆåÂÖ®ÂÖºÂÆπÔºâ&lt;/li&gt; 
  &lt;li&gt;ËßÑËåÉÂåñÊâÄÊúâ‰ª£Á†Å &amp;amp; ‰øÆÂ§ç‰∏Ä‰∫õÂ∑≤Áü•bugs&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-04-26&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈáçË¶ÅÊõ¥Êñ∞&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊúâÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMindÊ®°ÂûãÂèÇÊï∞ÂÆåÂÖ®ÊîπÂêçÔºåÂØπÈΩêTransformersÂ∫ìÊ®°ÂûãÔºàÁªü‰∏ÄÂëΩÂêçÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;generateÊñπÂºèÈáçÊûÑÔºåÁªßÊâøËá™GenerationMixinÁ±ª„ÄÇ&lt;/li&gt; 
  &lt;li&gt;üî•ÊîØÊåÅllama.cpp„ÄÅvllm„ÄÅollamaÁ≠âÁÉ≠Èó®‰∏âÊñπÁîüÊÄÅ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ËßÑËåÉ‰ª£Á†ÅÂíåÁõÆÂΩïÁªìÊûÑ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÊîπÂä®ËØçË°®&lt;code&gt;&amp;lt;s&amp;gt;&amp;lt;/s&amp;gt;&lt;/code&gt;-&amp;gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;‰∏∫ÂÖºÂÆπÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂llama.cpp„ÄÅvllmÔºåÊú¨Ê¨°Êõ¥Êñ∞ÈúÄ‰ªòÂá∫‰∏Ä‰∫õÂèØËßÇ‰ª£‰ª∑„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞‰∏çÂÜçÊîØÊåÅ„ÄåÁõ¥Êé•„ÄçÂä†ËΩΩ25-04-26‰ª•ÂâçÁöÑÊóßÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇ
Áî±‰∫éLlama‰ΩçÁΩÆÁºñÁ†ÅÊñπÂºè‰∏éminimindÂ≠òÂú®Âå∫Âà´ÔºåÂØºËá¥Êò†Â∞ÑLlamaÊ®°ÂûãÂêéQKÂÄºÂ≠òÂú®Â∑ÆÂºÇ
MiniMind2Á≥ªÂàóÊóßÊ®°ÂûãÂùáÁªèËøáÊùÉÈáçÊò†Â∞Ñ+ÔºàÂæÆË∞ÉËÆ≠ÁªÉÔºâQKVOÁ∫øÊÄßÂ±ÇÊ†°ÂáÜÊÅ¢Â§çËÄåÊù•„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞ÂêéÂ∞ÜÊîæÂºÉÂØπ`minimind-v1`ÂÖ®Á≥ªÂàóÁöÑÁª¥Êä§ÔºåÂπ∂Âú®‰ªìÂ∫ì‰∏≠‰∏ãÁ∫ø„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ËøéÊù•ÂèëÂ∏É‰ª•Êù•ÈáçÂ§ßÊõ¥Êñ∞ÔºåRelease MiniMind2 Series„ÄÇ&lt;/li&gt; 
  &lt;li&gt;‰ª£Á†ÅÂá†‰πéÂÖ®ÈÉ®ÈáçÊûÑÔºå‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÊòé‰∫ÜÁöÑÁªü‰∏ÄÁªìÊûÑ„ÄÇ Â¶ÇÊúâÊóß‰ª£Á†ÅÁöÑÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÂÖçÂéªÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊ≠•È™§„ÄÇÁªü‰∏ÄÊï∞ÊçÆÈõÜÊ†ºÂºèÔºåÊõ¥Êç¢‰∏∫&lt;code&gt;jsonl&lt;/code&gt;Ê†ºÂºèÊùúÁªùÊï∞ÊçÆÈõÜ‰∏ãËΩΩÊ∑∑‰π±ÁöÑÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2Á≥ªÂàóÊïàÊûúÁõ∏ÊØîMiniMind-V1ÊòæËëóÊèêÂçá„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Â∞èÈóÆÈ¢òÔºö{kv-cacheÂÜôÊ≥ïÊõ¥Ê†áÂáÜ„ÄÅMoEÁöÑË¥üËΩΩÂùáË°°lossË¢´ËÄÉËôëÁ≠âÁ≠â}&lt;/li&gt; 
  &lt;li&gt;Êèê‰æõÊ®°ÂûãËøÅÁßªÂà∞ÁßÅÊúâÊï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊñπÊ°àÔºàÂåªÁñóÊ®°Âûã„ÄÅËá™ÊàëËÆ§Áü•Ê†∑‰æãÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Á≤æÁÆÄÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÂπ∂Â§ßÂπÖÊèêÂçáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆË¥®ÈáèÔºåÂ§ßÂπÖÁº©Áü≠‰∏™‰∫∫Âø´ÈÄüËÆ≠ÁªÉÊâÄÈúÄÊó∂Èó¥ÔºåÂçïÂç°3090Âç≥ÂèØ2Â∞èÊó∂Â§çÁé∞ÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞ÔºöLoRAÂæÆË∞ÉËÑ±Á¶ªpeftÂåÖË£ÖÔºå‰ªé0ÂÆûÁé∞LoRAËøáÁ®ãÔºõDPOÁÆóÊ≥ï‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÂÆûÁé∞ÔºõÊ®°ÂûãÁôΩÁõíËí∏È¶èÂéüÁîüÂÆûÁé∞„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1Á≥ªÂàóËí∏È¶èÊ®°ÂûãËØûÁîüÔºÅ&lt;/li&gt; 
  &lt;li&gt;MiniMind2ÂÖ∑Â§á‰∏ÄÂÆöÁöÑËã±ÊñáËÉΩÂäõÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞MiniMind2‰∏éÁ¨¨‰∏âÊñπÊ®°ÂûãÁöÑÂü∫‰∫éÊõ¥Â§öÂ§ßÊ®°ÂûãÊ¶úÂçïÊµãËØïÊÄßËÉΩÁöÑÁªìÊûú„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;More...&lt;/b&gt; &lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;2024-10-05&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰∏∫MiniMindÊãìÂ±ï‰∫ÜÂ§öÊ®°ÊÄÅËÉΩÂäõ‰πã---ËßÜËßâ&lt;/li&gt; 
  &lt;li&gt;ÁßªÊ≠•Â≠™ÁîüÈ°πÁõÆ&lt;a href="https://github.com/jingyaogong/minimind-v"&gt;minimind-v&lt;/a&gt;Êü•ÁúãËØ¶ÊÉÖÔºÅ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-27&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27Êõ¥Êñ∞pretrainÊï∞ÊçÆÈõÜÁöÑÈ¢ÑÂ§ÑÁêÜÊñπÂºèÔºå‰∏∫‰∫Ü‰øùËØÅÊñáÊú¨ÂÆåÊï¥ÊÄßÔºåÊîæÂºÉÈ¢ÑÂ§ÑÁêÜÊàê.binËÆ≠ÁªÉÁöÑÂΩ¢ÂºèÔºàËΩªÂæÆÁâ∫Áâ≤ËÆ≠ÁªÉÈÄüÂ∫¶Ôºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÁõÆÂâçpretrainÈ¢ÑÂ§ÑÁêÜÂêéÁöÑÊñá‰ª∂ÂëΩÂêç‰∏∫Ôºöpretrain_data.csv„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Âà†Èô§‰∫Ü‰∏Ä‰∫õÂÜó‰ΩôÁöÑ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-17&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1-moeÊ®°Âûã&lt;/li&gt; 
  &lt;li&gt;‰∏∫‰∫ÜÈò≤Ê≠¢Ê≠ß‰πâÔºå‰∏çÂÜç‰ΩøÁî®mistral_tokenizerÂàÜËØçÔºåÂÖ®ÈÉ®ÈááÁî®Ëá™ÂÆö‰πâÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-09-01&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1 (108M)Ê®°ÂûãÔºåÈááÁî®minimind_tokenizerÔºåÈ¢ÑËÆ≠ÁªÉËΩÆÊ¨°3 + SFTËΩÆÊ¨°10ÔºåÊõ¥ÂÖÖÂàÜËÆ≠ÁªÉÔºåÊÄßËÉΩÊõ¥Âº∫„ÄÇ&lt;/li&gt; 
  &lt;li&gt;È°πÁõÆÂ∑≤ÈÉ®ÁΩ≤Ëá≥ModelScopeÂàõÁ©∫Èó¥ÔºåÂèØ‰ª•Âú®Ê≠§ÁΩëÁ´ô‰∏ä‰ΩìÈ™åÔºö&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/minimind"&gt;üîóModelScopeÂú®Á∫ø‰ΩìÈ™åüîó&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;2024-08-27&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;È°πÁõÆÈ¶ñÊ¨°ÂºÄÊ∫ê&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Âø´ÈÄüÂºÄÂßã&lt;/h1&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂàÜ‰∫´Êú¨‰∫∫ÁöÑËΩØÁ°¨‰ª∂ÈÖçÁΩÆÔºà‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Á¨¨0Ê≠•&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö† ÊµãËØïÂ∑≤ÊúâÊ®°ÂûãÊïàÊûú&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.‰∏ãËΩΩÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Âà∞È°πÁõÆÊ†πÁõÆÂΩï&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://huggingface.co/jingyaogong/MiniMind2 # or https://www.modelscope.cn/models/gongjy/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂëΩ‰ª§Ë°åÈóÆÁ≠î&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ΩøÁî®transformersÊ†ºÂºèÊ®°Âûã
python eval_llm.py --load_from ./MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂêØÂä®WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂèØËÉΩÈúÄË¶Å`python&amp;gt;=3.10` ÂÆâË£Ö `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö° ‰ªé0ÂºÄÂßãËá™Â∑±ËÆ≠ÁªÉ&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊèêÂâçÊµãËØïTorchÊòØÂê¶ÂèØÁî®cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Â¶ÇÊûú‰∏çÂèØÁî®ÔºåËØ∑Ëá™Ë°åÂéª&lt;a href="https://download.pytorch.org/whl/torch_stable.html"&gt;torch_stable&lt;/a&gt; ‰∏ãËΩΩwhlÊñá‰ª∂ÂÆâË£Ö„ÄÇÂèÇËÄÉ&lt;a href="https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187"&gt;ÈìæÊé•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.Êï∞ÊçÆ‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‰ªé‰∏ãÊñáÊèê‰æõÁöÑ&lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;Êï∞ÊçÆÈõÜ‰∏ãËΩΩÈìæÊé•&lt;/a&gt; ‰∏ãËΩΩÈúÄË¶ÅÁöÑÊï∞ÊçÆÊñá‰ª∂ÔºàÂàõÂª∫&lt;code&gt;./dataset&lt;/code&gt;ÁõÆÂΩïÔºâÂπ∂ÊîæÂà∞&lt;code&gt;./dataset&lt;/code&gt;‰∏ã&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊï∞ÊçÆÈõÜÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÈªòËÆ§Êé®Ëçê‰∏ãËΩΩ&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;ÊúÄÂø´ÈÄüÂ∫¶Â§çÁé∞ZeroËÅäÂ§©Ê®°Âûã„ÄÇ&lt;/p&gt; 
 &lt;p&gt;Êï∞ÊçÆÊñá‰ª∂ÂèØËá™Áî±ÈÄâÊã©Ôºå‰∏ãÊñáÊèê‰æõ‰∫ÜÂ§öÁßçÊê≠ÈÖçÊñπÊ°àÔºåÂèØÊ†πÊçÆËá™Â∑±ÊâãÂ§¥ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÂíåGPUËµÑÊ∫êËøõË°åÈÄÇÂΩìÁªÑÂêà„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.ÂºÄÂßãËÆ≠ÁªÉ&lt;/h3&gt; 
&lt;p&gt;ÁõÆÂΩï‰Ωç‰∫é&lt;code&gt;trainer&lt;/code&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;üí° Ê£ÄÊü•ÁÇπÊöÇÂÅúÁª≠ËÆ≠&lt;/summary&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨ÂùáËá™Âä®‰øùÂ≠òÊ£ÄÊü•ÁÇπÔºåÂè™ÈúÄÊ∑ªÂä† &lt;code&gt;--from_resume 1&lt;/code&gt; ÂèÇÊï∞Âç≥ÂèØËá™Âä®Ê£ÄÊµãÂä†ËΩΩ&amp;amp;ÊÅ¢Â§çËÆ≠ÁªÉÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py --from_resume 1
python train_full_sft.py --from_resume 1
...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Êñ≠ÁÇπÁª≠ËÆ≠Êú∫Âà∂ËØ¥ÊòéÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ËÆ≠ÁªÉËøáÁ®ãËá™Âä®Âú® &lt;code&gt;./checkpoints/&lt;/code&gt; ÁõÆÂΩï‰øùÂ≠òÂÆåÊï¥Ê£ÄÊü•ÁÇπÔºàÊ®°Âûã„ÄÅ‰ºòÂåñÂô®„ÄÅËÆ≠ÁªÉËøõÂ∫¶Á≠âÔºâ&lt;/li&gt; 
  &lt;li&gt;Ê£ÄÊü•ÁÇπÊñá‰ª∂ÂëΩÂêçÔºö&lt;code&gt;&amp;lt;ÊùÉÈáçÂêç&amp;gt;_&amp;lt;Áª¥Â∫¶&amp;gt;_resume.pth&lt;/code&gt;ÔºàÂ¶ÇÔºö&lt;code&gt;full_sft_512_resume.pth&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;ÊîØÊåÅË∑®‰∏çÂêåGPUÊï∞ÈáèÊÅ¢Â§çÔºàËá™Âä®Ë∞ÉÊï¥stepÔºâ&lt;/li&gt; 
  &lt;li&gt;ÊîØÊåÅwandbËÆ≠ÁªÉËÆ∞ÂΩïËøûÁª≠ÊÄßÔºàËá™Âä®ÊÅ¢Â§çÂêå‰∏Ä‰∏™runÔºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÈÄÇÂêàÈïøÊó∂Èó¥ËÆ≠ÁªÉÊàñ‰∏çÁ®≥ÂÆöÁéØÂ¢ÉÔºåÊó†ÈúÄÊãÖÂøÉËÆ≠ÁªÉ‰∏≠Êñ≠ÂØºËá¥ËøõÂ∫¶‰∏¢Â§±&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;3.1 È¢ÑËÆ≠ÁªÉÔºàÂ≠¶Áü•ËØÜÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÈ¢ÑËÆ≠ÁªÉÔºåÂæóÂà∞ &lt;code&gt;pretrain_*.pth&lt;/code&gt; ‰Ωú‰∏∫È¢ÑËÆ≠ÁªÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠*‰∏∫Ê®°ÂûãÁöÑdimensionÔºåÈªòËÆ§‰∏∫512Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 ÁõëÁù£ÂæÆË∞ÉÔºàÂ≠¶ÂØπËØùÊñπÂºèÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÁõëÁù£ÂæÆË∞ÉÔºåÂæóÂà∞ &lt;code&gt;full_sft_*.pth&lt;/code&gt; ‰Ωú‰∏∫Êåá‰ª§ÂæÆË∞ÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠&lt;code&gt;full&lt;/code&gt;Âç≥‰∏∫ÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöËÆ≠ÁªÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËøáÁ®ãÈªòËÆ§ÊØèÈöî100Ê≠•‰øùÂ≠ò1Ê¨°ÂèÇÊï∞Âà∞Êñá‰ª∂&lt;code&gt;./out/***.pth&lt;/code&gt;ÔºàÊØèÊ¨°‰ºöË¶ÜÁõñÊéâÊóßÊùÉÈáçÊñá‰ª∂Ôºâ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÆÄÂçïËµ∑ËßÅÔºåÊ≠§Â§ÑÂè™ÂÜôÊòé‰∏§‰∏™Èò∂ÊÆµËÆ≠ÁªÉËøáÁ®ã„ÄÇÂ¶ÇÈúÄÂÖ∂ÂÆÉËÆ≠ÁªÉ (LoRA, Ëí∏È¶è, Âº∫ÂåñÂ≠¶‰π†, ÂæÆË∞ÉÊé®ÁêÜÁ≠â) ÂèØÂèÇËÄÉ‰∏ãÊñá„ÄêÂÆûÈ™å„ÄëÂ∞èËäÇÁöÑËØ¶ÁªÜËØ¥Êòé„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4.ÊµãËØïËá™Â∑±ËÆ≠ÁªÉÁöÑÊ®°ÂûãÊïàÊûú&lt;/h3&gt; 
&lt;p&gt;Á°Æ‰øùÈúÄË¶ÅÊµãËØïÁöÑÊ®°Âûã&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂‰Ωç‰∫é&lt;code&gt;./out/&lt;/code&gt;ÁõÆÂΩï‰∏ã„ÄÇ ‰πüÂèØ‰ª•Áõ¥Êé•Âéª&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files"&gt;Ê≠§Â§Ñ&lt;/a&gt;‰∏ãËΩΩ‰ΩøÁî®ÊàëËÆ≠ÁªÉÁöÑ&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_llm.py --weight full_sft # Êàñ pretrain/dpo/ppo/grpo...
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊµãËØïÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;&lt;code&gt;--weight&lt;/code&gt; ÂèÇÊï∞ÊåáÂÆöÊùÉÈáçÂêçÁß∞ÂâçÁºÄÔºåÂèØÈÄâÔºö&lt;code&gt;pretrain&lt;/code&gt;, &lt;code&gt;full_sft&lt;/code&gt;, &lt;code&gt;dpo&lt;/code&gt;, &lt;code&gt;reason&lt;/code&gt;, &lt;code&gt;ppo_actor&lt;/code&gt;, &lt;code&gt;grpo&lt;/code&gt;, &lt;code&gt;spo&lt;/code&gt; Á≠â&lt;/p&gt; 
 &lt;p&gt;ÂÖ∂‰ªñÂ∏∏Áî®ÂèÇÊï∞Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;--load_from&lt;/code&gt;: Ê®°ÂûãÂä†ËΩΩË∑ØÂæÑÔºà&lt;code&gt;model&lt;/code&gt;=ÂéüÁîütorchÊùÉÈáçÔºåÂÖ∂‰ªñË∑ØÂæÑ=transformersÊ†ºÂºèÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--save_dir&lt;/code&gt;: Ê®°ÂûãÊùÉÈáçÁõÆÂΩïÔºàÈªòËÆ§&lt;code&gt;out&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--lora_weight&lt;/code&gt;: LoRAÊùÉÈáçÂêçÁß∞Ôºà&lt;code&gt;None&lt;/code&gt;Ë°®Á§∫‰∏ç‰ΩøÁî®Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--historys&lt;/code&gt;: Êê∫Â∏¶ÂéÜÂè≤ÂØπËØùËΩÆÊï∞ÔºàÈúÄ‰∏∫ÂÅ∂Êï∞Ôºå0Ë°®Á§∫‰∏çÊê∫Â∏¶ÂéÜÂè≤Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--max_new_tokens&lt;/code&gt;: ÊúÄÂ§ßÁîüÊàêÈïøÂ∫¶ÔºàÈªòËÆ§8192Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--temperature&lt;/code&gt;: ÁîüÊàêÊ∏©Â∫¶ÔºàÈªòËÆ§0.85Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;--top_p&lt;/code&gt;: nucleusÈááÊ†∑ÈòàÂÄºÔºàÈªòËÆ§0.85Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;‰ΩøÁî®ÊñπÂºèÁõ¥Êé•Êü•Áúã&lt;code&gt;eval_llm.py&lt;/code&gt;‰ª£Á†ÅÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá‰∏∫PytorchÂéüÁîüÊ°ÜÊû∂ÔºåÂùáÊîØÊåÅÂ§öÂç°Âä†ÈÄüÔºåÂÅáËÆæ‰Ω†ÁöÑËÆæÂ§áÊúâN (NÔºû1) Âº†ÊòæÂç°Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉÊñπÂºè (DDP, ÊîØÊåÅÂ§öÊú∫Â§öÂç°ÈõÜÁæ§)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂÖ∂ÂÆÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;del&gt; ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉ (DeepSpeed) &lt;pre&gt;&lt;code class="language-bash"&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; &lt;/del&gt; 
 &lt;p&gt;ÂèØÊ†πÊçÆÈúÄË¶ÅÂºÄÂêØwandbËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºàÈúÄÂèØÁõ¥ËøûÔºâ&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ÈúÄË¶ÅÁôªÂΩï: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ÈÄöËøáÊ∑ªÂä†&lt;code&gt;--use_wandb&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºåËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®wandbÁΩëÁ´ô‰∏äÊü•ÁúãËÆ≠ÁªÉËøáÁ®ã„ÄÇÈÄöËøá‰øÆÊîπ&lt;code&gt;wandb_project&lt;/code&gt; Âíå&lt;code&gt;wandb_run_name&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ÊåáÂÆöÈ°πÁõÆÂêçÁß∞ÂíåËøêË°åÂêçÁß∞„ÄÇ&lt;/p&gt; 
 &lt;p&gt;„ÄêÊ≥®„ÄëÔºö25Âπ¥6ÊúàÂêéÔºåÂõΩÂÜÖÁΩëÁªúÁéØÂ¢ÉÊó†Ê≥ïÁõ¥ËøûWandBÔºåMiniMindÈ°πÁõÆÈªòËÆ§ËΩ¨‰∏∫‰ΩøÁî®&lt;a href="https://swanlab.cn/"&gt;SwanLab&lt;/a&gt;‰Ωú‰∏∫ËÆ≠ÁªÉÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºàÂÆåÂÖ®ÂÖºÂÆπWandB APIÔºâÔºåÂç≥&lt;code&gt;import wandb&lt;/code&gt;Êîπ‰∏∫&lt;code&gt;import swanlab as wandb&lt;/code&gt;Âç≥ÂèØÔºåÂÖ∂‰ªñÂùáÊó†ÈúÄÊîπÂä®„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Êï∞ÊçÆ‰ªãÁªç&lt;/h1&gt; 
&lt;h2&gt;‚Ö† Tokenizer&lt;/h2&gt; 
&lt;p&gt;ÂàÜËØçÂô®Â∞ÜÂçïËØç‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùÊò†Â∞ÑÂà∞&lt;code&gt;0, 1, 36&lt;/code&gt;ËøôÊ†∑ÁöÑÊï∞Â≠óÔºåÂèØ‰ª•ÁêÜËß£‰∏∫Êï∞Â≠óÂ∞±‰ª£Ë°®‰∫ÜÂçïËØçÂú®‚ÄúËØçÂÖ∏‚Äù‰∏≠ÁöÑÈ°µÁ†Å„ÄÇ ÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÊûÑÈÄ†ËØçË°®ËÆ≠ÁªÉ‰∏Ä‰∏™‚ÄúËØçÂÖ∏‚ÄùÔºå‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./trainer/train_tokenizer.py&lt;/code&gt;Ôºà‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉÔºåËã•ÈùûÂøÖË¶ÅÊó†ÈúÄÂÜçËá™Ë°åËÆ≠ÁªÉÔºåMiniMindÂ∑≤Ëá™Â∏¶tokenizerÔºâ„ÄÇ ÊàñËÄÖÈÄâÊã©ÊØîËæÉÂá∫ÂêçÁöÑÂºÄÊ∫êÂ§ßÊ®°ÂûãÂàÜËØçÂô®Ôºå Ê≠£Â¶ÇÂêåÁõ¥Êé•Áî®Êñ∞Âçé/ÁâõÊ¥•ËØçÂÖ∏ÁöÑ‰ºòÁÇπÊòØtokenÁºñÁ†ÅÂéãÁº©ÁéáÂæàÂ•ΩÔºåÁº∫ÁÇπÊòØÈ°µÊï∞Â§™Â§öÔºåÂä®ËæÑÊï∞ÂçÅ‰∏á‰∏™ËØçÊ±áÁü≠ËØ≠Ôºõ Ëá™Â∑±ËÆ≠ÁªÉÁöÑÂàÜËØçÂô®Ôºå‰ºòÁÇπÊòØËØçË°®ÈïøÂ∫¶ÂíåÂÜÖÂÆπÈöèÊÑèÊéßÂà∂ÔºåÁº∫ÁÇπÊòØÂéãÁº©ÁéáÂæà‰ΩéÔºà‰æãÂ¶Ç"hello"‰πüËÆ∏‰ºöË¢´ÊãÜÂàÜ‰∏∫"h e l l o" ‰∫î‰∏™Áã¨Á´ãÁöÑtokenÔºâÔºå‰∏îÁîüÂÉªËØçÈöæ‰ª•Ë¶ÜÁõñ„ÄÇ ‚ÄúËØçÂÖ∏‚ÄùÁöÑÈÄâÊã©Âõ∫ÁÑ∂ÂæàÈáçË¶ÅÔºåLLMÁöÑËæìÂá∫Êú¨Ë¥®‰∏äÊòØSoftMaxÂà∞ËØçÂÖ∏N‰∏™ËØçÁöÑÂ§öÂàÜÁ±ªÈóÆÈ¢òÔºåÁÑ∂ÂêéÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùËß£Á†ÅÂà∞Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ Âõ†‰∏∫MiniMind‰ΩìÁßØÈúÄË¶Å‰∏•Ê†ºÊéßÂà∂Ôºå‰∏∫‰∫ÜÈÅøÂÖçÊ®°ÂûãÂ§¥ÈáçËÑöËΩªÔºàËØçÂµåÂÖ•embeddingÂ±ÇÂèÇÊï∞Âú®LLMÂç†ÊØîÂ§™È´òÔºâÔºåÊâÄ‰ª•ËØçË°®ÈïøÂ∫¶Áü≠Áü≠ÁõäÂñÑ„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Tokenizer‰ªãÁªç&lt;/summary&gt; 
 &lt;p&gt;Á¨¨‰∏âÊñπÂº∫Â§ßÁöÑÂºÄÊ∫êÊ®°Âûã‰æãÂ¶ÇYi„ÄÅqwen„ÄÅchatglm„ÄÅmistral„ÄÅLlama3ÁöÑtokenizerËØçË°®ÈïøÂ∫¶Â¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;TokenizerÊ®°Âûã&lt;/th&gt;
    &lt;th&gt;ËØçË°®Â§ßÂ∞è&lt;/th&gt;
    &lt;th&gt;Êù•Ê∫ê&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01‰∏áÁâ©Ôºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;ÈòøÈáå‰∫ëÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;Êô∫Ë∞±AIÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AIÔºàÊ≥ïÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;MetaÔºàÁæéÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;Ëá™ÂÆö‰πâ&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;üëâ2024-09-17Êõ¥Êñ∞Ôºö‰∏∫‰∫ÜÈò≤Ê≠¢ËøáÂéªÁöÑÁâàÊú¨Ê≠ß‰πâ&amp;amp;ÊéßÂà∂‰ΩìÁßØÔºåminimindÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî®minimind_tokenizerÂàÜËØçÔºåÂ∫üÂºÉÊâÄÊúâmistral_tokenizerÁâàÊú¨„ÄÇ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# ‰∏Ä‰∫õËá™Ë®ÄËá™ËØ≠
&amp;gt; Â∞ΩÁÆ°minimind_tokenizerÈïøÂ∫¶ÂæàÂ∞èÔºåÁºñËß£Á†ÅÊïàÁéáÂº±‰∫éqwen2„ÄÅglmÁ≠â‰∏≠ÊñáÂèãÂ•ΩÂûãÂàÜËØçÂô®„ÄÇ
&amp;gt; ‰ΩÜminimindÊ®°ÂûãÈÄâÊã©‰∫ÜËá™Â∑±ËÆ≠ÁªÉÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®Ôºå‰ª•‰øùÊåÅÊï¥‰ΩìÂèÇÊï∞ËΩªÈáèÔºåÈÅøÂÖçÁºñÁ†ÅÂ±ÇÂíåËÆ°ÁÆóÂ±ÇÂç†ÊØîÂ§±Ë°°ÔºåÂ§¥ÈáçËÑöËΩªÔºåÂõ†‰∏∫minimindÁöÑËØçË°®Â§ßÂ∞èÂè™Êúâ6400„ÄÇ
&amp;gt; ‰∏îminimindÂú®ÂÆûÈôÖÊµãËØï‰∏≠Ê≤°ÊúâÂá∫Áé∞ËøáÁîüÂÉªËØçÊ±áËß£Á†ÅÂ§±Ë¥•ÁöÑÊÉÖÂÜµÔºåÊïàÊûúËâØÂ•Ω„ÄÇ
&amp;gt; Áî±‰∫éËá™ÂÆö‰πâËØçË°®ÂéãÁº©ÈïøÂ∫¶Âà∞6400Ôºå‰ΩøÂæóLLMÊÄªÂèÇÊï∞ÈáèÊúÄ‰ΩéÂè™Êúâ25.8M„ÄÇ
&amp;gt; ËÆ≠ÁªÉÊï∞ÊçÆ`pretrain_hq.jsonl`ÂùáÊù•Ëá™‰∫é`Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ`ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÂ¶ÇÈúÄËÆ≠ÁªÉÂèØ‰ª•Ëá™Áî±ÈÄâÊã©„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚Ö° PretrainÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;ÁªèÂéÜ‰∫ÜMiniMind-V1ÁöÑ‰ΩéË¥®ÈáèÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂØºËá¥Ê®°ÂûãËÉ°Ë®Ä‰π±ËØ≠ÁöÑÊïôËÆ≠Ôºå&lt;code&gt;2025-02-05&lt;/code&gt; ‰πãÂêéÂÜ≥ÂÆö‰∏çÂÜçÈááÁî®Â§ßËßÑÊ®°Êó†ÁõëÁù£ÁöÑÊï∞ÊçÆÈõÜÂÅöÈ¢ÑËÆ≠ÁªÉ„ÄÇ ËøõËÄåÂ∞ùËØïÊää&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ&lt;/a&gt;ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÊèêÂèñÂá∫Êù•Ôºå Ê∏ÖÊ¥óÂá∫Â≠óÁ¨¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÈïøÂ∫¶ÁöÑÂ§ßÁ∫¶1.6GBÁöÑËØ≠ÊñôÁõ¥Êé•ÊãºÊé•ÊàêÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆ &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;ÔºåhqÂç≥‰∏∫high qualityÔºàÂΩìÁÑ∂‰πüËøò‰∏çÁÆóhighÔºåÊèêÂçáÊï∞ÊçÆË¥®ÈáèÊó†Ê≠¢Â∞ΩÔºâ„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{"text": "Â¶Ç‰ΩïÊâçËÉΩÊëÜËÑ±ÊãñÂª∂ÁóáÔºü Ê≤ªÊÑàÊãñÂª∂ÁóáÂπ∂‰∏çÂÆπÊòìÔºå‰ΩÜ‰ª•‰∏ãÂª∫ËÆÆÂèØËÉΩÊúâÊâÄÂ∏ÆÂä©..."}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö¢ SFTÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãSFTÊï∞ÊçÆÈõÜ&lt;/a&gt; ‚ÄúÊòØ‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÊ†ºÂºèÁªü‰∏Ä„ÄÅÂÆâÂÖ®ÁöÑÂ§ßÊ®°ÂûãËÆ≠ÁªÉÂíåÁ†îÁ©∂ËµÑÊ∫ê„ÄÇ ‰ªéÁΩëÁªú‰∏äÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÊ∫êÊî∂ÈõÜÂπ∂Êï¥ÁêÜ‰∫ÜÂ§ßÈáèÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºåÂØπÂÖ∂ËøõË°å‰∫ÜÊ†ºÂºèÁªü‰∏ÄÔºåÊï∞ÊçÆÊ∏ÖÊ¥óÔºå ÂåÖÂê´10MÊù°Êï∞ÊçÆÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈõÜÂíåÂåÖÂê´2MÊù°Êï∞ÊçÆÁöÑËã±ÊñáÊï∞ÊçÆÈõÜ„ÄÇ‚Äù ‰ª•‰∏äÊòØÂÆòÊñπ‰ªãÁªçÔºå‰∏ãËΩΩÊñá‰ª∂ÂêéÁöÑÊï∞ÊçÆÊÄªÈáèÂ§ßÁ∫¶Âú®4B tokensÔºåËÇØÂÆöÊòØÈÄÇÂêà‰Ωú‰∏∫‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑSFTÊï∞ÊçÆÁöÑ„ÄÇ ‰ΩÜÊòØÂÆòÊñπÊèê‰æõÁöÑÊï∞ÊçÆÊ†ºÂºèÂæà‰π±ÔºåÂÖ®ÈÉ®Áî®Êù•sft‰ª£‰ª∑Â§™Â§ß„ÄÇ ÊàëÂ∞ÜÊääÂÆòÊñπÊï∞ÊçÆÈõÜËøõË°å‰∫Ü‰∫åÊ¨°Ê∏ÖÊ¥óÔºåÊääÂê´ÊúâÁ¨¶Âè∑Ê±°ÊüìÂíåÂô™Â£∞ÁöÑÊù°ÁõÆÂéªÈô§ÔºõÂè¶Â§ñ‰æùÁÑ∂Âè™‰øùÁïô‰∫ÜÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt; ÁöÑÂÜÖÂÆπÔºåÊ≠§Èò∂ÊÆµÂ∏åÊúõÈÄöËøáÂ§ßÈáèÂØπËØùË°•ÂÖÖÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊ¨†Áº∫ÁöÑÁü•ËØÜ„ÄÇ ÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/organization/Magpie-Align"&gt;Magpie-SFTÊï∞ÊçÆÈõÜ&lt;/a&gt; Êî∂ÈõÜ‰∫Ü~1MÊù°Êù•Ëá™Qwen2/2.5ÁöÑÈ´òË¥®ÈáèÂØπËØùÔºåÊàëÂ∞ÜËøôÈÉ®ÂàÜÊï∞ÊçÆËøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÔºåÊääÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;2048&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)„ÄÇ ÈïøÂ∫¶&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)ÔºåÁî®Â§ßÊ®°ÂûãÂØπËØùÊï∞ÊçÆÁõ¥Êé•ËøõË°åsftÂ∞±Â±û‰∫é‚ÄúÈªëÁõíËí∏È¶è‚ÄùÁöÑËåÉÁï¥„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ëøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÂâç‰∏§Ê≠•sftÁöÑÊï∞ÊçÆÔºàÂè™‰øùÁïô‰∏≠ÊñáÂ≠óÁ¨¶Âç†ÊØîÈ´òÁöÑÂÜÖÂÆπÔºâÔºåÁ≠õÈÄâÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÁöÑÂØπËØùÔºåÂæóÂà∞&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊâÄÊúâsftÊñá‰ª∂ &lt;code&gt;sft_X.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºèÂùá‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
    "conversations": [
        {"role": "user", "content": "‰Ω†Â•Ω"},
        {"role": "assistant", "content": "‰Ω†Â•ΩÔºÅ"},
        {"role": "user", "content": "ÂÜçËßÅ"},
        {"role": "assistant", "content": "ÂÜçËßÅÔºÅ"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö£ RLHFÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;Êù•Ëá™&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1"&gt;Magpie-DPOÊï∞ÊçÆÈõÜ&lt;/a&gt; Â§ßÁ∫¶200kÊù°ÂÅèÂ•ΩÊï∞ÊçÆÔºàÂùáÊòØËã±ÊñáÔºâÁîüÊàêËá™Llama3.1-70B/8BÔºåÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÂ•ñÂä±Ê®°ÂûãÔºå‰ºòÂåñÊ®°ÂûãÂõûÂ§çË¥®ÈáèÔºå‰ΩøÂÖ∂Êõ¥Âä†Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•Ω„ÄÇ ËøôÈáåÂ∞ÜÊï∞ÊçÆÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;3000&lt;/code&gt;ÁöÑÂÜÖÂÆπÈáçÁªÑ‰∏∫&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)ÔºåÂåÖÂê´&lt;code&gt;chosen&lt;/code&gt;Âíå&lt;code&gt;rejected&lt;/code&gt;‰∏§‰∏™Â≠óÊÆµÔºå&lt;code&gt;chosen&lt;/code&gt; ‰∏∫ÂÅèÂ•ΩÁöÑÂõûÂ§çÔºå&lt;code&gt;rejected&lt;/code&gt;‰∏∫ÊãíÁªùÁöÑÂõûÂ§ç„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂ &lt;code&gt;dpo.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö§ ReasonÊï∞ÊçÆÈõÜÔºö&lt;/h2&gt; 
&lt;p&gt;‰∏çÂæó‰∏çËØ¥2025Âπ¥2ÊúàË∞ÅËÉΩÁÅ´ÁöÑËøáDeepSeek... ‰πüÊøÄÂèë‰∫ÜÊàëÂØπRLÂºïÂØºÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÊµìÂéöÂÖ¥Ë∂£ÔºåÁõÆÂâçÂ∑≤ÁªèÁî®Qwen2.5Â§çÁé∞‰∫ÜR1-Zero„ÄÇ Â¶ÇÊûúÊúâÊó∂Èó¥+ÊïàÊûúworkÔºà‰ΩÜ99%Âü∫Ê®°ËÉΩÂäõ‰∏çË∂≥ÔºâÊàë‰ºöÂú®‰πãÂêéÊõ¥Êñ∞MiniMindÂü∫‰∫éRLËÆ≠ÁªÉÁöÑÊé®ÁêÜÊ®°ÂûãËÄå‰∏çÊòØËí∏È¶èÊ®°Âûã„ÄÇ Êó∂Èó¥ÊúâÈôêÔºåÊúÄÂø´ÁöÑ‰ΩéÊàêÊú¨ÊñπÊ°à‰æùÁÑ∂ÊòØÁõ¥Êé•Ëí∏È¶èÔºàÈªëÁõíÊñπÂºèÔºâ„ÄÇ ËÄê‰∏ç‰ΩèR1Â§™ÁÅ´ÔºåÁü≠Áü≠Âá†Â§©Â∞±Â∑≤ÁªèÂ≠òÂú®‰∏Ä‰∫õR1ÁöÑËí∏È¶èÊï∞ÊçÆÈõÜ&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"&gt;R1-Llama-70B&lt;/a&gt;„ÄÅ&lt;a href="https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT"&gt;R1-Distill-SFT&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH"&gt;Alpaca-Distill-R1&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh"&gt;deepseek_r1_zh&lt;/a&gt;Á≠âÁ≠âÔºåÁ∫Ø‰∏≠ÊñáÁöÑÊï∞ÊçÆÂèØËÉΩÊØîËæÉÂ∞ë„ÄÇ ÊúÄÁªàÊï¥ÂêàÂÆÉ‰ª¨ÔºåÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ÔºåÊï∞ÊçÆÊ†ºÂºèÂíå&lt;code&gt;sft_X.jsonl&lt;/code&gt;‰∏ÄËá¥„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö• Êõ¥Â§öÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;p&gt;ÁõÆÂâçÂ∑≤ÁªèÊúâ&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; Âú®Êî∂ÈõÜÂíåÊ¢≥ÁêÜ‰∏≠ÊñáLLMÁõ∏ÂÖ≥ÁöÑÂºÄÊ∫êÊ®°Âûã„ÄÅÂ∫îÁî®„ÄÅÊï∞ÊçÆÈõÜÂèäÊïôÁ®ãÁ≠âËµÑÊñôÔºåÂπ∂ÊåÅÁª≠Êõ¥Êñ∞ËøôÊñπÈù¢ÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇÂÖ®Èù¢‰∏î‰∏ì‰∏öÔºåRespectÔºÅ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Öß MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05ÂêéÔºåÂºÄÊ∫êMiniMindÊúÄÁªàËÆ≠ÁªÉÊâÄÁî®ÁöÑÊâÄÊúâÊï∞ÊçÆÈõÜÔºåÂõ†Ê≠§Êó†ÈúÄÂÜçËá™Ë°åÈ¢ÑÂ§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÈÅøÂÖçÈáçÂ§çÊÄßÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂ∑•‰Ωú„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏ãËΩΩÂú∞ÂùÄÔºö &lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êó†ÈúÄÂÖ®ÈÉ®cloneÔºåÂèØÂçïÁã¨‰∏ãËΩΩÊâÄÈúÄÁöÑÊñá‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Â∞Ü‰∏ãËΩΩÁöÑÊï∞ÊçÆÈõÜÊñá‰ª∂ÊîæÂà∞&lt;code&gt;./dataset/&lt;/code&gt;ÁõÆÂΩï‰∏ãÔºà‚ú®‰∏∫Êé®ËçêÁöÑÂøÖÈ°ªÈ°πÔºâ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./dataset/
‚îú‚îÄ‚îÄ dpo.jsonl (55MB, ‚ú®)
‚îú‚îÄ‚îÄ lora_identity.jsonl (22.8KB)
‚îú‚îÄ‚îÄ lora_medical.jsonl (34MB)
‚îú‚îÄ‚îÄ pretrain_hq.jsonl (1.6GB, ‚ú®)
‚îú‚îÄ‚îÄ r1_mix_1024.jsonl (340MB)
‚îú‚îÄ‚îÄ rlaif-mini.jsonl (1MB, ‚ú®)
‚îú‚îÄ‚îÄ sft_1024.jsonl (5.6GB)
‚îú‚îÄ‚îÄ sft_2048.jsonl (9GB)
‚îú‚îÄ‚îÄ sft_512.jsonl (7.5GB)
‚îî‚îÄ‚îÄ sft_mini_512.jsonl (1.2GB, ‚ú®)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂêÑÊï∞ÊçÆÈõÜÁÆÄ‰ªã&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt;‚ú® --RLHFÈò∂ÊÆµÊï∞ÊçÆÈõÜÔºàÂ∑≤Á≤æÁÆÄ‰ºòÂåñÔºåÈÄÇÂêàÂø´ÈÄüËÆ≠ÁªÉÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --Ëá™ÊàëËÆ§Áü•Êï∞ÊçÆÈõÜÔºà‰æãÂ¶ÇÔºö‰Ω†ÊòØË∞ÅÔºüÊàëÊòØminimind...ÔºâÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --ÂåªÁñóÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;‚ú® --È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà320&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5BËí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà720&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;rlaif-mini.jsonl&lt;/code&gt; --RLAIFËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºå‰ªéSFTÊï∞ÊçÆÈõÜ‰∏≠ÈöèÊú∫ÈááÊ†∑1‰∏áÊù°È´òË¥®ÈáèÂØπËØùÔºåÁî®‰∫éPPO/GRPO/SPOÁ≠âÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïËÆ≠ÁªÉ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÊòØsft_2048ÁöÑÂ≠êÈõÜÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà650&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫2048ÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà1400&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà350&lt;/code&gt;Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;‚ú® --ÊûÅÁÆÄÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆ+Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÁî®‰∫éÂø´ÈÄüËÆ≠ÁªÉZeroÊ®°ÂûãÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÊé®ËçêËÆæÁΩÆ&lt;code&gt;max_seq_len‚âà340&lt;/code&gt;Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂèÇÊï∞&lt;code&gt;max_seq_len&lt;/code&gt;ÁõÆÂâçÊåáÁöÑÊòØtokensÈïøÂ∫¶ÔºåËÄåÈùûÁªùÂØπÂ≠óÁ¨¶Êï∞„ÄÇ Êú¨È°πÁõÆtokenizerÂú®‰∏≠ÊñáÊñáÊú¨‰∏äÂ§ßÁ∫¶&lt;code&gt;1.5~1.7 Â≠óÁ¨¶/token&lt;/code&gt;ÔºåÁ∫ØËã±ÊñáÁöÑÂéãÁº©ÊØîÂú®&lt;code&gt;4~5 Â≠óÁ¨¶/token&lt;/code&gt;Ôºå‰∏çÂêåÊï∞ÊçÆÂàÜÂ∏É‰ºöÊúâÊ≥¢Âä®„ÄÇ Êï∞ÊçÆÈõÜÂëΩÂêçÊ†áÊ≥®ÁöÑ‚ÄúÊúÄÂ§ßÈïøÂ∫¶‚ÄùÂùá‰∏∫Â≠óÁ¨¶Êï∞Ôºå100ÈïøÂ∫¶ÁöÑÂ≠óÁ¨¶‰∏≤ÂèØÁ≤óÁï•Êç¢ÁÆóÊàê&lt;code&gt;100/1.5‚âà67&lt;/code&gt;ÁöÑtokensÈïøÂ∫¶„ÄÇ&lt;/p&gt; 
 &lt;p&gt;‰æãÂ¶ÇÔºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰∏≠ÊñáÔºö&lt;code&gt;ÁôΩÊó•‰æùÂ±±Â∞Ω&lt;/code&gt;5‰∏™Â≠óÁ¨¶ÂèØËÉΩË¢´ÊãÜÂàÜ‰∏∫[&lt;code&gt;ÁôΩÊó•&lt;/code&gt;,&lt;code&gt;‰æù&lt;/code&gt;,&lt;code&gt;Â±±&lt;/code&gt;,&lt;code&gt;Â∞Ω&lt;/code&gt;] 4‰∏™tokensÔºõ&lt;/li&gt; 
  &lt;li&gt;Ëã±ÊñáÔºö&lt;code&gt;The sun sets in the west&lt;/code&gt;24‰∏™Â≠óÁ¨¶ÂèØËÉΩË¢´ÊãÜÂàÜ‰∏∫[&lt;code&gt;The &lt;/code&gt;,&lt;code&gt;sun &lt;/code&gt;,&lt;code&gt;sets &lt;/code&gt;,&lt;code&gt;in &lt;/code&gt;,&lt;code&gt;the&lt;/code&gt;,&lt;code&gt;west&lt;/code&gt;] 6‰∏™tokens&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;‚ÄúÊé®ËçêËÆæÁΩÆ‚ÄùÁªôÂá∫‰∫ÜÂêÑ‰∏™Êï∞ÊçÆÈõÜ‰∏äÊúÄÂ§ßtokensÈïøÂ∫¶ÁöÑÁ≤óÁï•‰º∞ËÆ°„ÄÇ È°ªÁü•max_seq_lenÂèØ‰ª•ÊøÄËøõ/‰øùÂÆà/ÂùáË°°Âú∞Ë∞ÉÊï¥ÔºåÂõ†‰∏∫Êõ¥Â§ßÊàñÊõ¥Â∞èÂùáÊó†Ê≥ïÈÅøÂÖçÂâØ‰ΩúÁî®Ôºö‰∏Ä‰∫õÊ†∑Êú¨Áü≠‰∫émax_seq_lenÂêéË¢´paddingÊµ™Ë¥πÁÆóÂäõÔºå‰∏Ä‰∫õÊ†∑Êú¨Èïø‰∫émax_seq_lenÂêéË¢´Êà™Êñ≠ËØ≠ÊÑè„ÄÇ&lt;/p&gt; 
 &lt;p&gt;Âú® &lt;code&gt;ÁÆóÂäõÊïàÁéá&lt;/code&gt; &amp;lt;---&amp;gt; &lt;code&gt;ËØ≠‰πâÂÆåÊï¥ÊÄß&lt;/code&gt; ‰πãÈó¥ÊâæÂà∞‰∏Ä‰∏™Âπ≥Ë°°ÁÇπÂç≥ÂèØ&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg" alt="dataset" /&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËØ¥Êòé &amp;amp; Êé®ËçêËÆ≠ÁªÉÊñπÊ°à&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 SeriesÂùáÁªèËøáÂÖ±Á∫¶20GBËØ≠ÊñôËÆ≠ÁªÉÔºåÂ§ßÁ∫¶4B tokensÔºåÂç≥ÂØπÂ∫î‰∏äÈù¢ÁöÑÊï∞ÊçÆÁªÑÂêàËÆ≠ÁªÉÁªìÊûúÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞üí∞üí∞üí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ÊÉ≥Ë¶ÅÊúÄÂø´ÈÄüÂ∫¶‰ªé0ÂÆûÁé∞ZeroÊ®°ÂûãÔºåÊé®Ëçê‰ΩøÁî®&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; ÁöÑÊï∞ÊçÆÁªÑÂêàÔºåÂÖ∑‰ΩìËä±ÈîÄÂíåÊïàÊûúÂèØÊü•Áúã‰∏ãÊñáË°®Ê†ºÔºàÂºÄÈîÄÔºöüí∞ÔºåÊïàÊûúÔºöüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Êé®ËçêÂÖ∑Â§á‰∏ÄÂÆöÁÆóÂäõËµÑÊ∫êÊàñÊõ¥Âú®ÊÑèÊïàÊûúÁöÑÊúãÂèãÂèØ‰ª•ËÄÉËôëÂâçËÄÖÂÆåÊï¥Â§çÁé∞MiniMind2Ôºõ‰ªÖÊúâÂçïÂç°GPUÊàñÂú®‰πéÁü≠Êó∂Èó¥Âø´ÈÄüÂ§çÁé∞ÁöÑÊúãÂèãÂº∫ÁÉàÊé®ËçêÂêéËÄÖÔºõ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;„ÄêÊäò‰∏≠ÊñπÊ°à„Äë‰∫¶ÂèØÈÄâÊã©‰æãÂ¶Ç&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;„ÄÅ&lt;code&gt;sft_1024.jsonl&lt;/code&gt;‰∏≠Á≠âËßÑÊ®°Êï∞ÊçÆËøõË°åËá™Áî±ÁªÑÂêàËÆ≠ÁªÉÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäÔºâ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Model&lt;/h1&gt; 
&lt;h2&gt;Structure&lt;/h2&gt; 
&lt;p&gt;MiniMind-DenseÔºàÂíå&lt;a href="https://ai.meta.com/blog/meta-llama-3-1/"&gt;Llama3.1&lt;/a&gt;‰∏ÄÊ†∑Ôºâ‰ΩøÁî®‰∫ÜTransformerÁöÑDecoder-OnlyÁªìÊûÑÔºåË∑üGPT-3ÁöÑÂå∫Âà´Âú®‰∫éÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÈááÁî®‰∫ÜGPT-3ÁöÑÈ¢ÑÊ†áÂáÜÂåñÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂú®ÊØè‰∏™TransformerÂ≠êÂ±ÇÁöÑËæìÂÖ•‰∏äËøõË°åÂΩí‰∏ÄÂåñÔºåËÄå‰∏çÊòØÂú®ËæìÂá∫‰∏ä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ΩøÁî®ÁöÑÊòØRMSNormÂΩí‰∏ÄÂåñÂáΩÊï∞„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Áî®SwiGLUÊøÄÊ¥ªÂáΩÊï∞Êõø‰ª£‰∫ÜReLUÔºåËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÊèêÈ´òÊÄßËÉΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÉèGPT-Neo‰∏ÄÊ†∑ÔºåÂéªÊéâ‰∫ÜÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÔºåÊîπÁî®‰∫ÜÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÔºàRoPEÔºâÔºåËøôÊ†∑Âú®Â§ÑÁêÜË∂ÖÂá∫ËÆ≠ÁªÉÈïøÂ∫¶ÁöÑÊé®ÁêÜÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMind-MoEÊ®°ÂûãÔºåÂÆÉÁöÑÁªìÊûÑÂü∫‰∫éLlama3Âíå&lt;a href="https://arxiv.org/pdf/2405.04434"&gt;Deepseek-V2/3&lt;/a&gt;‰∏≠ÁöÑMixFFNÊ∑∑Âêà‰∏ìÂÆ∂Ê®°Âùó„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2Âú®ÂâçÈ¶àÁΩëÁªúÔºàFFNÔºâÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑ‰∏ìÂÆ∂ÂàÜÂâ≤ÂíåÂÖ±‰∫´ÁöÑ‰∏ìÂÆ∂ÈöîÁ¶ªÊäÄÊúØÔºå‰ª•ÊèêÈ´òExpertsÁöÑÊïàÊûú„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMindÁöÑÊï¥‰ΩìÁªìÊûÑ‰∏ÄËá¥ÔºåÂè™ÊòØÂú®RoPEËÆ°ÁÆó„ÄÅÊé®ÁêÜÂáΩÊï∞ÂíåFFNÂ±ÇÁöÑ‰ª£Á†Å‰∏äÂÅö‰∫Ü‰∏Ä‰∫õÂ∞èË∞ÉÊï¥„ÄÇ ÂÖ∂ÁªìÊûÑÂ¶Ç‰∏ãÂõæÔºàÈáçÁªòÁâàÔºâÔºö&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png" alt="structure" /&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png" alt="structure-moe" /&gt;&lt;/p&gt; 
&lt;p&gt;‰øÆÊîπÊ®°ÂûãÈÖçÁΩÆËßÅ&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/model/model_minimind.py"&gt;./model/model_minimind.py&lt;/a&gt;„ÄÇ ÂèÇËÄÉÊ®°ÂûãÂèÇÊï∞ÁâàÊú¨ËßÅ‰∏ãË°®Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4√ó26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Model Configuration&lt;/h2&gt; 
&lt;p&gt;üìãÂÖ≥‰∫éLLMÁöÑÂèÇÊï∞ÈÖçÁΩÆÔºåÊúâ‰∏ÄÁØáÂæàÊúâÊÑèÊÄùÁöÑËÆ∫Êñá&lt;a href="https://arxiv.org/pdf/2402.14905"&gt;MobileLLM&lt;/a&gt;ÂÅö‰∫ÜËØ¶ÁªÜÁöÑÁ†îÁ©∂ÂíåÂÆûÈ™å„ÄÇ Scaling LawÂú®Â∞èÊ®°Âûã‰∏≠ÊúâËá™Â∑±Áã¨ÁâπÁöÑËßÑÂæã„ÄÇ ÂºïËµ∑TransformerÂèÇÊï∞ÊàêËßÑÊ®°ÂèòÂåñÁöÑÂèÇÊï∞Âá†‰πéÂè™ÂèñÂÜ≥‰∫é&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üë + &lt;code&gt;n_layers&lt;/code&gt;‚Üì -&amp;gt; ÁüÆËÉñÂ≠ê&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üì + &lt;code&gt;n_layers&lt;/code&gt;‚Üë -&amp;gt; Áò¶È´ò‰∏™&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020Âπ¥ÊèêÂá∫Scaling LawÁöÑËÆ∫ÊñáËÆ§‰∏∫ÔºåËÆ≠ÁªÉÊï∞ÊçÆÈáè„ÄÅÂèÇÊï∞Èáè‰ª•ÂèäËÆ≠ÁªÉËø≠‰ª£Ê¨°Êï∞ÊâçÊòØÂÜ≥ÂÆöÊÄßËÉΩÁöÑÂÖ≥ÈîÆÂõ†Á¥†ÔºåËÄåÊ®°ÂûãÊû∂ÊûÑÁöÑÂΩ±ÂìçÂá†‰πéÂèØ‰ª•ÂøΩËßÜ„ÄÇ ÁÑ∂ËÄå‰ºº‰πéËøô‰∏™ÂÆöÂæãÂØπÂ∞èÊ®°ÂûãÂπ∂‰∏çÂÆåÂÖ®ÈÄÇÁî®„ÄÇ MobileLLMÊèêÂá∫Êû∂ÊûÑÁöÑÊ∑±Â∫¶ÊØîÂÆΩÂ∫¶Êõ¥ÈáçË¶ÅÔºå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁò¶Èïø„ÄçÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞ÊØî„ÄåÂÆΩËÄåÊµÖ„ÄçÊ®°ÂûãÊõ¥Â§öÁöÑÊäΩË±°Ê¶ÇÂøµ„ÄÇ ‰æãÂ¶ÇÂΩìÊ®°ÂûãÂèÇÊï∞Âõ∫ÂÆöÂú®125MÊàñËÄÖ350MÊó∂Ôºå30ÔΩû42Â±ÇÁöÑ„ÄåÁã≠Èïø„ÄçÊ®°ÂûãÊòéÊòæÊØî12Â±ÇÂ∑¶Âè≥ÁöÑ„ÄåÁüÆËÉñ„ÄçÊ®°ÂûãÊúâÊõ¥‰ºòË∂äÁöÑÊÄßËÉΩÔºå Âú®Â∏∏ËØÜÊé®ÁêÜ„ÄÅÈóÆÁ≠î„ÄÅÈòÖËØªÁêÜËß£Á≠â8‰∏™Âü∫ÂáÜÊµãËØï‰∏äÈÉΩÊúâÁ±ª‰ººÁöÑË∂ãÂäø„ÄÇ ËøôÂÖ∂ÂÆûÊòØÈùûÂ∏∏ÊúâË∂£ÁöÑÂèëÁé∞ÔºåÂõ†‰∏∫‰ª•ÂæÄ‰∏∫100MÂ∑¶Âè≥ÈáèÁ∫ßÁöÑÂ∞èÊ®°ÂûãËÆæËÆ°Êû∂ÊûÑÊó∂ÔºåÂá†‰πéÊ≤°‰∫∫Â∞ùËØïËøáÂè†Âä†Ë∂ÖËøá12Â±Ç„ÄÇ Ëøô‰∏éMiniMindÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°ÂûãÂèÇÊï∞ÈáèÂú®&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;‰πãÈó¥ËøõË°åË∞ÉÊï¥ÂÆûÈ™åËßÇÂØüÂà∞ÁöÑÊïàÊûúÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ ÁÑ∂ËÄå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁ™Ñ„Äç‰πüÊòØÊúâÁª¥Â∫¶ÊûÅÈôêÁöÑÔºåÂΩìd_model&amp;lt;512Êó∂ÔºåËØçÂµåÂÖ•Áª¥Â∫¶ÂùçÂ°åÁöÑÂä£ÂäøÈùûÂ∏∏ÊòéÊòæÔºå Â¢ûÂä†ÁöÑlayersÂπ∂‰∏çËÉΩÂº•Ë°•ËØçÂµåÂÖ•Âú®Âõ∫ÂÆöq_headÂ∏¶Êù•d_head‰∏çË∂≥ÁöÑÂä£Âäø„ÄÇ ÂΩìd_model&amp;gt;1536Êó∂ÔºålayersÁöÑÂ¢ûÂä†‰ºº‰πéÊØîd_modelÁöÑ‰ºòÂÖàÁ∫ßÊõ¥È´òÔºåÊõ¥ËÉΩÂ∏¶Êù•ÂÖ∑Êúâ"ÊÄß‰ª∑ÊØî"ÁöÑÂèÇÊï∞-&amp;gt;ÊïàÊûúÂ¢ûÁõä„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âõ†Ê≠§MiniMindËÆæÂÆösmallÊ®°Âûãdim=512Ôºån_layers=8Êù•Ëé∑ÂèñÁöÑ„ÄåÊûÅÂ∞è‰ΩìÁßØ&amp;lt;-&amp;gt;Êõ¥Â•ΩÊïàÊûú„ÄçÁöÑÂπ≥Ë°°„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆæÂÆödim=768Ôºån_layers=16Êù•Ëé∑ÂèñÊïàÊûúÁöÑÊõ¥Â§ßÊî∂ÁõäÔºåÊõ¥Âä†Á¨¶ÂêàÂ∞èÊ®°ÂûãScaling-LawÁöÑÂèòÂåñÊõ≤Á∫ø„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‰Ωú‰∏∫ÂèÇËÄÉÔºåGPT3ÁöÑÂèÇÊï∞ËÆæÂÆöËßÅ‰∏ãË°®Ôºö &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png" alt="gpt3_config.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìå Experiment&lt;/h1&gt; 
&lt;h2&gt;‚Ö† ËÆ≠ÁªÉÂºÄÈîÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Âçï‰Ωç&lt;/strong&gt;ÔºöÂ∞èÊó∂ (h)„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊàêÊú¨Âçï‰Ωç&lt;/strong&gt;Ôºö‰∫∫Ê∞ëÂ∏Å (Ôø•)Ôºõ7Ôø• ‚âà 1ÁæéÂÖÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 ÁßüÂç°Âçï‰ª∑&lt;/strong&gt;Ôºö‚âà1.3Ôø•/hÔºàÂèØËá™Ë°åÂèÇËÄÉÂÆûÊó∂Â∏Ç‰ª∑Ôºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂèÇËÄÉÊ†áÂáÜ&lt;/strong&gt;ÔºöË°®Ê†º‰ªÖÂÆûÊµã &lt;code&gt;pretrain&lt;/code&gt; Âíå &lt;code&gt;sft_mini_512&lt;/code&gt; ‰∏§‰∏™Êï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊó∂Èó¥ÔºåÂÖ∂ÂÆÉËÄóÊó∂Ê†πÊçÆÊï∞ÊçÆÈõÜÂ§ßÂ∞è‰º∞ÁÆóÔºàÂèØËÉΩÂ≠òÂú®‰∫õËÆ∏Âá∫ÂÖ•Ôºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âü∫‰∫é 3090 ÔºàÂçïÂç°ÔºâÊàêÊú¨ËÆ°ÁÆó&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;‚âà1.1h&lt;br /&gt;‚âà1.43Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br /&gt;‚âà1.3Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà6h&lt;br /&gt;‚âà7.8Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà4.58h&lt;br /&gt;‚âà5.95Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà7.5h&lt;br /&gt;‚âà9.75Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br /&gt;‚âà1.3Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;‚âà3.9h&lt;br /&gt;‚âà5.07Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3.3h&lt;br /&gt;‚âà4.29Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà20h&lt;br /&gt;‚âà26Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà15h&lt;br /&gt;‚âà19.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà25h&lt;br /&gt;‚âà32.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3h&lt;br /&gt;‚âà3.9Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËÆ≠ÁªÉÂºÄÈîÄÊÄªÁªì&amp;amp;È¢ÑÊµã&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (1 epoch) + 2.1Â∞èÊó∂ + Ëä±Ë¥π2.73ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind-Zero-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶38.16Â∞èÊó∂ + Ëä±Ë¥π49.61ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-Small-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2ÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶122Â∞èÊó∂ + Ëä±Ë¥π158.6ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-0.1BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;‚ú®Âü∫‰∫éÂçïÂç°NVIDIA 3090ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;‰ªé0ËÆ≠ÁªÉ‰ªÖÈúÄ&lt;code&gt;2Â∞èÊó∂&lt;/code&gt; + &lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÔºåÂÆûÁé∞ChatBotÊïàÊûúÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®PSÔºöËã•ÈááÁî®8Âç°4090ËÆ≠ÁªÉÔºåÊÄªÁî®Êó∂ÁîöËá≥ÂèØ‰ª•ÂéãÁº©Âà∞10ÂàÜÈíü‰ª•ÂÜÖÔºÅÔºàÁî±‰∫éÊó∂Èó¥Êõ¥Áü≠ÔºåËä±Ë¥πÂêåÊ†∑3ÂÖÉÂ∑¶Âè≥Ôºå‰∏éÂçïÂç°ÊàêÊú¨Áõ∏ÂΩìÔºâ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ª•ÊûÅ‰ΩéÊûÅ‰ΩéÁöÑÈó®ÊßõÔºåÂÆûÁé∞‰∫∫‰∫∫ÂèØÁé©ÁöÑÂ§ßÊ®°ÂûãËá™Áî±ÔºÅËøôÊ≠£ÊòØMiniMindÁ≥ªÂàóÁöÑËØûÁîüÂàùË°∑ÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ªÖ‰ª∑ÂÄº&lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÊàêÊú¨ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;Âπ∂‰∏çÊòØÂô±Â§¥ÔºÅChatÊµãËØïÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: ‰Ωú‰∏∫‰∫∫Â∑•Êô∫ËÉΩÔºåÊàëÊ≤°ÊúâÂÆûÈôÖÁöÑÁîüÊ¥ªÔºå‰πüÊ≤°ÊúâËá™ÊàëÊÑèËØÜÔºåÊâÄ‰ª•Ê≤°ÊúâËá™Â∑±ÁöÑÁîüÊ¥ª„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØ„ÄÅËøõË°åÂØπËØùÁ≠â„ÄÇÊàëÁöÑËÆæËÆ°ÂíåÂäüËÉΩÊòØÁî±ËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂíåÁÆóÊ≥ïÊâÄÊûÑÂª∫ÁöÑÔºåÊàëÈÄöËøáÁºñÁ®ãÂíåÁÆóÊ≥ïÂÆûÁé∞„ÄÇ

üë∂: Êé®Ëçê‰∏Ä‰∫õÊù≠Â∑ûÁöÑÁâπËâ≤ÁæéÈ£üÂêß„ÄÇ
ü§ñÔ∏è: Êù≠Â∑ûÊúâÂæàÂ§öÁæéÂë≥ÁöÑÁâπËâ≤ÁæéÈ£üÔºåÊØîÂ¶ÇÈ∏°ËÇâ‰∏≤„ÄÅÈ≥óÈ±ºÂ§¥„ÄÅÊ∞¥ÁÖÆÈ±º„ÄÅË±ÜËÖêËÑëÁ≠â„ÄÇËøô‰∫õÁæéÈ£üÈÉΩÈùûÂ∏∏ÁæéÂë≥ÔºåÊúâÁùÄÁã¨ÁâπÁöÑÈ£éÂë≥ÂíåÂè£ÊÑüÔºåÁªùÂØπÊòØÂÄºÂæó‰∏ÄËØïÁöÑÁæéÈ£ü„ÄÇ

üë∂: ËØ∑‰∏∫ÊàëËÆ≤Ëß£‚ÄúÂ§ßËØ≠Ë®ÄÊ®°Âûã‚ÄùËøô‰∏™Ê¶ÇÂøµ„ÄÇ
ü§ñÔ∏è: Â§ßËØ≠Ë®ÄÊ®°ÂûãÊòØ‰∏ÄÁßç‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÔºåÂÆÉ‰ΩøÁî®Â§ßÈáèÁöÑÊñáÊú¨Êï∞ÊçÆÊù•ËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÂú®‰∏çÊñ≠ÁöÑËø≠‰ª£‰∏≠‰∏çÊñ≠‰ºòÂåñÊ®°Âûã„ÄÇÂÆÉÁöÑÁõÆÊ†áÊòØÊ†πÊçÆËæìÂÖ•ÁöÑÊï∞ÊçÆÊù•ÁîüÊàêÁ¨¶ÂêàÁâπÂÆöÈúÄÊ±ÇÁöÑÊñáÊú¨ÔºåËøô‰∫õÊñáÊú¨ÂèØ‰ª•ÊòØ‰ªª‰Ωï‰Ω†ÊÑüÂÖ¥Ë∂£ÁöÑ‰∏ªÈ¢ò„ÄÇ

üë∂: Introduce the history of the United States, please.
ü§ñÔ∏è: ÊÇ®ÊèêÂà∞ÁöÑ‚ÄúIntrook's the believeations of theument." Ëøô‰∏™ÂêçÂ≠óÊù•Ê∫ê‰∫é‰∏≠ÂõΩÂè§‰ª£ÁöÑ"groty of of the change."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊûÅÈÄü‰∏îÂàùÂÖ∑ÊïàÊûúÔºåÁîöËá≥‰ªçÁÑ∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂéãÁº©Ëé∑ÂèñÊõ¥Â∞èÊõ¥‰ºòË¥®ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ ZeroÊ®°ÂûãÊùÉÈáç‰øùÂ≠ò‰∏∫ &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;ÔºàËßÅ‰∏ãÊñáMiniMindÊ®°ÂûãÊñá‰ª∂ÈìæÊé•ÔºâÔºåÂ¶ÇÊúâÂÖ¥Ë∂£ÂèØ‰∏ãËΩΩÊ£ÄÈ™åÊ≠§Ê®°ÂûãÊïàÊûú„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö° ‰∏ªË¶ÅËÆ≠ÁªÉÔºàÂøÖÈ°ªÔºâ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;1. È¢ÑËÆ≠ÁªÉ (Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLMÈ¶ñÂÖàË¶ÅÂ≠¶‰π†ÁöÑÂπ∂ÈùûÁõ¥Êé•‰∏é‰∫∫‰∫§ÊµÅÔºåËÄåÊòØËÆ©ÁΩëÁªúÂèÇÊï∞‰∏≠ÂÖÖÊª°Áü•ËØÜÁöÑÂ¢®Ê∞¥Ôºå‚ÄúÂ¢®Ê∞¥‚Äù ÁêÜËÆ∫‰∏äÂñùÁöÑË∂äÈ•±Ë∂äÂ•ΩÔºå‰∫ßÁîüÂ§ßÈáèÁöÑÂØπ‰∏ñÁïåÁöÑÁü•ËØÜÁßØÁ¥Ø„ÄÇ È¢ÑËÆ≠ÁªÉÂ∞±ÊòØËÆ©ModelÂÖàÂüãÂ§¥Ëã¶Â≠¶Â§ßÈáèÂü∫Êú¨ÁöÑÁü•ËØÜÔºå‰æãÂ¶Ç‰ªéWikiÁôæÁßë„ÄÅÊñ∞Èóª„ÄÅ‰π¶Á±çÊï¥ÁêÜÂ§ßËßÑÊ®°ÁöÑÈ´òË¥®ÈáèËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ Ëøô‰∏™ËøáÁ®ãÊòØ‚ÄúÊó†ÁõëÁù£‚ÄùÁöÑÔºåÂç≥‰∫∫Á±ª‰∏çÈúÄË¶ÅÂú®ËøáÁ®ã‰∏≠ÂÅö‰ªª‰Ωï‚ÄúÊúâÁõëÁù£‚ÄùÁöÑÊ†°Ê≠£ÔºåËÄåÊòØÁî±Ê®°ÂûãËá™Â∑±‰ªéÂ§ßÈáèÊñáÊú¨‰∏≠ÊÄªÁªìËßÑÂæãÂ≠¶‰π†Áü•ËØÜÁÇπ„ÄÇ Ê®°ÂûãÊ≠§Èò∂ÊÆµÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™Ôºö&lt;strong&gt;Â≠¶‰ºöËØçËØ≠Êé•Èæô&lt;/strong&gt;„ÄÇ‰æãÂ¶ÇËæìÂÖ•"Áß¶ÂßãÁöá"Âõõ‰∏™Â≠óÔºåÂÆÉÂèØ‰ª•Êé•Èæô"ÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏Ä‰ΩçÁöáÂ∏ù"„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1Âç≥‰∏∫ÂçïÂç°ËÆ≠ÁªÉÔºåÂèØÊ†πÊçÆÁ°¨‰ª∂ÊÉÖÂÜµËá™Ë°åË∞ÉÊï¥ (ËÆæÁΩÆ&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;pretrain_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;strong&gt;2. ÊúâÁõëÁù£ÂæÆË∞É (Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;ÁªèËøáÈ¢ÑËÆ≠ÁªÉÔºåLLMÊ≠§Êó∂Â∑≤ÁªèÊéåÊè°‰∫ÜÂ§ßÈáèÁü•ËØÜÔºåÁÑ∂ËÄåÊ≠§Êó∂ÂÆÉÂè™‰ºöÊó†ËÑëÂú∞ËØçËØ≠Êé•ÈæôÔºåËøò‰∏ç‰ºö‰∏é‰∫∫ËÅäÂ§©„ÄÇ SFTÈò∂ÊÆµÂ∞±ÈúÄË¶ÅÊääÂçäÊàêÂìÅLLMÊñΩÂä†‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑËÅäÂ§©Ê®°ÊùøËøõË°åÂæÆË∞É„ÄÇ ‰æãÂ¶ÇÊ®°ÂûãÈÅáÂà∞ËøôÊ†∑ÁöÑÊ®°Êùø„ÄêÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠îÔºåÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠î„ÄëÂêé‰∏çÂÜçÊó†ËÑëÊé•ÈæôÔºåËÄåÊòØÊÑèËØÜÂà∞ËøôÊòØ‰∏ÄÊÆµÂÆåÊï¥ÁöÑÂØπËØùÁªìÊùü„ÄÇ Áß∞Ëøô‰∏™ËøáÁ®ã‰∏∫Êåá‰ª§ÂæÆË∞ÉÔºåÂ∞±Â¶ÇÂêåËÆ©Â∑≤ÁªèÂ≠¶ÂØå‰∫îËΩ¶ÁöÑ„ÄåÁâõÈ°ø„ÄçÂÖàÁîüÈÄÇÂ∫î21‰∏ñÁ∫™Êô∫ËÉΩÊâãÊú∫ÁöÑËÅäÂ§©‰π†ÊÉØÔºåÂ≠¶‰π†Â±èÂπïÂ∑¶‰æßÊòØÂØπÊñπÊ∂àÊÅØÔºåÂè≥‰æßÊòØÊú¨‰∫∫Ê∂àÊÅØËøô‰∏™ËßÑÂæã„ÄÇ Âú®ËÆ≠ÁªÉÊó∂ÔºåMiniMindÁöÑÊåá‰ª§ÂíåÂõûÁ≠îÈïøÂ∫¶Ë¢´Êà™Êñ≠Âú®512ÔºåÊòØ‰∏∫‰∫ÜËäÇÁúÅÊòæÂ≠òÁ©∫Èó¥„ÄÇÂ∞±ÂÉèÂ≠¶‰π†ÂÜô‰ΩúÊó∂Ôºå‰ºöÂÖà‰ªéÁü≠ÁöÑÊñáÁ´†ÂºÄÂßãÔºåÂΩìÂ≠¶‰ºöÂÜô‰Ωú200Â≠ó‰ΩúÊñáÂêéÔºå800Â≠óÊñáÁ´†‰πüÂèØ‰ª•ÊâãÂà∞ÊìíÊù•„ÄÇ Âú®ÈúÄË¶ÅÈïøÂ∫¶ÊãìÂ±ïÊó∂ÔºåÂè™ÈúÄË¶ÅÂáÜÂ§áÂ∞ëÈáèÁöÑ2k/4k/8kÈïøÂ∫¶ÂØπËØùÊï∞ÊçÆËøõË°åËøõ‰∏ÄÊ≠•ÂæÆË∞ÉÂç≥ÂèØÔºàÊ≠§Êó∂ÊúÄÂ•ΩÈÖçÂêàRoPE-NTKÁöÑÂü∫ÂáÜÂ∑ÆÂÄºÔºâ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âú®Êé®ÁêÜÊó∂ÈÄöËøáË∞ÉÊï¥RoPEÁ∫øÊÄßÂ∑ÆÂÄºÔºåÂÆûÁé∞ÂÖçËÆ≠ÁªÉÈïøÂ∫¶Â§ñÊé®Âà∞2048Âèä‰ª•‰∏äÂ∞Ü‰ºöÂæàÊñπ‰æø„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚Ö¢ ÂÖ∂ÂÆÉËÆ≠ÁªÉÈò∂ÊÆµÔºàÂèØÈÄâÔºâ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;3. Áü•ËØÜËí∏È¶è (Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑÊâÄÊúâËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÆåÂÖ®ÂÖ∑Â§á‰∫ÜÂü∫Êú¨ËÉΩÂäõÔºåÈÄöÂ∏∏ÂèØ‰ª•Â≠¶ÊàêÂá∫Â∏à‰∫Ü„ÄÇ ËÄåÁü•ËØÜËí∏È¶èÂèØ‰ª•Ëøõ‰∏ÄÊ≠•‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊïàÁéáÔºåÊâÄË∞ìÁü•ËØÜËí∏È¶èÔºåÂç≥Â≠¶ÁîüÊ®°ÂûãÈù¢ÂêëÊïôÂ∏àÊ®°ÂûãÂ≠¶‰π†„ÄÇ ÊïôÂ∏àÊ®°ÂûãÈÄöÂ∏∏ÊòØÁªèËøáÂÖÖÂàÜËÆ≠ÁªÉÁöÑÂ§ßÊ®°ÂûãÔºåÂÖ∑ÊúâËæÉÈ´òÁöÑÂáÜÁ°ÆÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ Â≠¶ÁîüÊ®°ÂûãÊòØ‰∏Ä‰∏™ËæÉÂ∞èÁöÑÊ®°ÂûãÔºåÁõÆÊ†áÊòØÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÁöÑË°å‰∏∫ÔºåËÄå‰∏çÊòØÁõ¥Êé•‰ªéÂéüÂßãÊï∞ÊçÆ‰∏≠Â≠¶‰π†„ÄÇ Âú®SFTÂ≠¶‰π†‰∏≠ÔºåÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÊãüÂêàËØçTokenÂàÜÁ±ªÁ°¨Ê†áÁ≠æÔºàhard labelsÔºâÔºåÂç≥ÁúüÂÆûÁöÑÁ±ªÂà´Ê†áÁ≠æÔºàÂ¶Ç 0 Êàñ 6400Ôºâ„ÄÇ Âú®Áü•ËØÜËí∏È¶è‰∏≠ÔºåÊïôÂ∏àÊ®°ÂûãÁöÑsoftmaxÊ¶ÇÁéáÂàÜÂ∏ÉË¢´Áî®‰ΩúËΩØÊ†áÁ≠æÔºàsoft labelsÔºâ„ÄÇÂ∞èÊ®°Âûã‰ªÖÂ≠¶‰π†ËΩØÊ†áÁ≠æÔºåÂπ∂‰ΩøÁî®KL-LossÊù•‰ºòÂåñÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ ÈÄö‰øóÂú∞ËØ¥ÔºåSFTÁõ¥Êé•Â≠¶‰π†ËÄÅÂ∏àÁªôÁöÑËß£È¢òÁ≠îÊ°à„ÄÇËÄåKDËøáÁ®ãÁõ∏ÂΩì‰∫é‚ÄúÊâìÂºÄ‚ÄùËÄÅÂ∏àËÅ™ÊòéÁöÑÂ§ßËÑëÔºåÂ∞ΩÂèØËÉΩÂú∞Ê®°‰ªøËÄÅÂ∏à‚ÄúÂ§ßËÑë‚ÄùÊÄùËÄÉÈóÆÈ¢òÁöÑÁ•ûÁªèÂÖÉÁä∂ÊÄÅ„ÄÇ ‰æãÂ¶ÇÔºåÂΩìËÄÅÂ∏àÊ®°ÂûãËÆ°ÁÆó&lt;code&gt;1+1=2&lt;/code&gt;Ëøô‰∏™ÈóÆÈ¢òÁöÑÊó∂ÂÄôÔºåÊúÄÂêé‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉaÁä∂ÊÄÅ‰∏∫0ÔºåÁ•ûÁªèÂÖÉbÁä∂ÊÄÅ‰∏∫100ÔºåÁ•ûÁªèÂÖÉcÁä∂ÊÄÅ‰∏∫-99... Â≠¶ÁîüÊ®°ÂûãÈÄöËøáÂ§ßÈáèÊï∞ÊçÆÔºåÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÂ§ßËÑëÂÜÖÈÉ®ÁöÑËøêËΩ¨ËßÑÂæã„ÄÇËøô‰∏™ËøáÁ®ãÂç≥Áß∞‰πã‰∏∫ÔºöÁü•ËØÜËí∏È¶è„ÄÇ Áü•ËØÜËí∏È¶èÁöÑÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™ÔºöËÆ©Â∞èÊ®°Âûã‰ΩìÁßØÊõ¥Â∞èÁöÑÂêåÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ ÁÑ∂ËÄåÈöèÁùÄLLMËØûÁîüÂíåÂèëÂ±ïÔºåÊ®°ÂûãËí∏È¶è‰∏ÄËØçË¢´ÂπøÊ≥õÊª•Áî®Ôºå‰ªéËÄå‰∫ßÁîü‰∫Ü‚ÄúÁôΩÁõí/ÈªëÁõí‚ÄùÁü•ËØÜËí∏È¶è‰∏§‰∏™Ê¥æÂà´„ÄÇ GPT-4ËøôÁßçÈó≠Ê∫êÊ®°ÂûãÔºåÁî±‰∫éÊó†Ê≥ïËé∑ÂèñÂÖ∂ÂÜÖÈÉ®ÁªìÊûÑÔºåÂõ†Ê≠§Âè™ËÉΩÈù¢ÂêëÂÆÉÊâÄËæìÂá∫ÁöÑÊï∞ÊçÆÂ≠¶‰π†ÔºåËøô‰∏™ËøáÁ®ãÁß∞‰πã‰∏∫ÈªëÁõíËí∏È¶èÔºå‰πüÊòØÂ§ßÊ®°ÂûãÊó∂‰ª£ÊúÄÊôÆÈÅçÁöÑÂÅöÊ≥ï„ÄÇ ÈªëÁõíËí∏È¶è‰∏éSFTËøáÁ®ãÂÆåÂÖ®‰∏ÄËá¥ÔºåÂè™‰∏çËøáÊï∞ÊçÆÊòØ‰ªéÂ§ßÊ®°ÂûãÁöÑËæìÂá∫Êî∂ÈõÜÔºåÂõ†Ê≠§Âè™ÈúÄË¶ÅÂáÜÂ§áÊï∞ÊçÆÂπ∂‰∏îËøõ‰∏ÄÊ≠•FTÂç≥ÂèØ„ÄÇ Ê≥®ÊÑèÊõ¥ÊîπË¢´Âä†ËΩΩÁöÑÂü∫Á°ÄÊ®°Âûã‰∏∫&lt;code&gt;full_sft_*.pth&lt;/code&gt;ÔºåÂç≥Âü∫‰∫éÂæÆË∞ÉÊ®°ÂûãÂÅöËøõ‰∏ÄÊ≠•ÁöÑËí∏È¶èÂ≠¶‰π†„ÄÇ &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;‰∏é&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; ÂùáÊî∂ÈõÜËá™qwen2.5-7/72B-InstructÂ§ßÊ®°ÂûãÔºåÂèØÁõ¥Êé•Áî®‰∫éSFT‰ª•Ëé∑ÂèñQwenÁöÑÈÉ®ÂàÜË°å‰∏∫„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÈúÄË¶ÅÊõ¥Êîπtrain_full_sft.pyÊï∞ÊçÆÈõÜË∑ØÂæÑÔºå‰ª•Âèämax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;ÂêåÊ†∑‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Ê≠§Â§ÑÂ∫îÂΩìÁùÄÈáç‰ªãÁªçMiniMindÂÆûÁé∞ÁöÑÁôΩÁõíËí∏È¶è‰ª£Á†Å&lt;code&gt;train_distillation.py&lt;/code&gt;ÔºåÁî±‰∫éMiniMindÂêåÁ≥ªÂàóÊú¨Ë∫´Âπ∂‰∏çÂ≠òÂú®Âº∫Â§ßÁöÑÊïôÂ∏àÊ®°ÂûãÔºåÂõ†Ê≠§ÁôΩÁõíËí∏È¶è‰ª£Á†Å‰ªÖ‰Ωú‰∏∫Â≠¶‰π†ÂèÇËÄÉ„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;4. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRAÊòØ‰∏ÄÁßçÈ´òÊïàÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàParameter-Efficient Fine-Tuning, PEFTÔºâÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøá‰ΩéÁß©ÂàÜËß£ÁöÑÊñπÂºèÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ Áõ∏ÊØî‰∫éÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºàFull Fine-TuningÔºâÔºåLoRA Âè™ÈúÄË¶ÅÊõ¥Êñ∞Â∞ëÈáèÁöÑÂèÇÊï∞„ÄÇ LoRA ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÔºöÂú®Ê®°ÂûãÁöÑÊùÉÈáçÁü©Èòµ‰∏≠ÂºïÂÖ•‰ΩéÁß©ÂàÜËß£Ôºå‰ªÖÂØπ‰ΩéÁß©ÈÉ®ÂàÜËøõË°åÊõ¥Êñ∞ÔºåËÄå‰øùÊåÅÂéüÂßãÈ¢ÑËÆ≠ÁªÉÊùÉÈáç‰∏çÂèò„ÄÇ ‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./model/model_lora.py&lt;/code&gt;Âíå&lt;code&gt;train_lora.py&lt;/code&gt;ÔºåÂÆåÂÖ®‰ªé0ÂÆûÁé∞LoRAÊµÅÁ®ãÔºå‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÁöÑÂ∞ÅË£Ö„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÈùûÂ∏∏Â§öÁöÑ‰∫∫Âõ∞ÊÉëÔºåÂ¶Ç‰Ωï‰ΩøÊ®°ÂûãÂ≠¶‰ºöËá™Â∑±ÁßÅÊúâÈ¢ÜÂüüÁöÑÁü•ËØÜÔºüÂ¶Ç‰ΩïÂáÜÂ§áÊï∞ÊçÆÈõÜÔºüÂ¶Ç‰ΩïËøÅÁßªÈÄöÁî®È¢ÜÂüüÊ®°ÂûãÊâìÈÄ†ÂûÇÂüüÊ®°ÂûãÔºü ËøôÈáå‰∏æÂá†‰∏™‰æãÂ≠êÔºåÂØπ‰∫éÈÄöÁî®Ê®°ÂûãÔºåÂåªÂ≠¶È¢ÜÂüüÁü•ËØÜÊ¨†Áº∫ÔºåÂèØ‰ª•Â∞ùËØïÂú®ÂéüÊúâÊ®°ÂûãÂü∫Á°Ä‰∏äÂä†ÂÖ•È¢ÜÂüüÁü•ËØÜÔºå‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ ÂêåÊó∂ÔºåÈÄöÂ∏∏‰∏çÂ∏åÊúõÂ≠¶‰ºöÈ¢ÜÂüüÁü•ËØÜÁöÑÂêåÊó∂ÊçüÂ§±ÂéüÊúâÂü∫Á°ÄÊ®°ÂûãÁöÑÂÖ∂ÂÆÉËÉΩÂäõÔºåÊ≠§Êó∂LoRAÂèØ‰ª•ÂæàÂ•ΩÁöÑÊîπÂñÑËøô‰∏™ÈóÆÈ¢ò„ÄÇ Âè™ÈúÄË¶ÅÂáÜÂ§áÂ¶Ç‰∏ãÊ†ºÂºèÁöÑÂØπËØùÊï∞ÊçÆÈõÜÊîæÁΩÆÂà∞&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;ÔºåÂêØÂä® &lt;code&gt;python train_lora.py&lt;/code&gt; ËÆ≠ÁªÉÂç≥ÂèØÂæóÂà∞&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;Êñ∞Ê®°ÂûãÊùÉÈáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂåªÁñóÂú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆÈ¢àÊ§éÁóÖÁöÑ‰∫∫ÊûïÂ§¥Â§öÈ´òÊâçÊúÄÂ•ΩÔºü"}, {"role": "assistant", "content": "È¢àÊ§éÁóÖÊÇ£ËÄÖÈÄâÊã©ÊûïÂ§¥ÁöÑÈ´òÂ∫¶Â∫îËØ•Ê†πÊçÆ..."}]}
 {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆxxx"}, {"role": "assistant", "content": "xxx..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ëá™ÊàëËÆ§Áü•Âú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü"}, {"role": "assistant", "content": "ÊàëÂè´minimind..."}]}
 {"conversations": [{"role": "user", "content": "‰Ω†ÊòØË∞Å"}, {"role": "assistant", "content": "ÊàëÊòØ..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ê≠§Êó∂„ÄêÂü∫Á°ÄÊ®°Âûã+LoRAÊ®°Âûã„ÄëÂç≥ÂèØËé∑ÂæóÂåªÁñóÂú∫ÊôØÊ®°ÂûãÂ¢ûÂº∫ÁöÑËÉΩÂäõÔºåÁõ∏ÂΩì‰∫é‰∏∫Âü∫Á°ÄÊ®°ÂûãÂ¢ûÂä†‰∫ÜLoRAÂ§ñÊåÇÔºåËøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊçüÂ§±Âü∫Á°ÄÊ®°ÂûãÁöÑÊú¨Ë∫´ËÉΩÂäõ„ÄÇ ÂèØ‰ª•ÈÄöËøá&lt;code&gt;eval_llm.py&lt;/code&gt;ËøõË°åÊ®°ÂûãËØÑ‰º∞ÊµãËØï„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÔºöweightÂèÇÊï∞ÊåáÂÆöÂü∫Á°ÄÊ®°ÂûãÁ±ªÂûãÔºåÈúÄ‰∏étrain_loraËÆ≠ÁªÉÊó∂‰ΩøÁî®ÁöÑÂü∫Á°ÄÊ®°Âûã‰øùÊåÅ‰∏ÄËá¥
python eval_llm.py  --weight dpo --lora_weight lora_medical
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Â∞èÊµãËØï&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;üë∂: ÊàëÊúÄËøëÁªèÂ∏∏ÊÑüÂà∞Â§¥ÊôïÔºåÂèØËÉΩÊòØ‰ªÄ‰πàÂéüÂõ†Ôºü
ü§ñÔ∏è: Â§¥ÊôïÂèØËÉΩÊòØÁî±‰∫éÂ§öÁßçÂéüÂõ†ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºöÂøÉËÑèÁñæÁóÖ„ÄÅÁúºÁùõÊçü‰º§„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÁöÆËÇ§ÈóÆÈ¢ò„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÂéãÂäõ„ÄÅÁÑ¶Ëôë„ÄÅÁñ≤Âä≥„ÄÅËçØÁâ©ÂâØ‰ΩúÁî®„ÄÅÊÄßÂäüËÉΩÈöúÁ¢çÊàñËÄÖÂÖ∂‰ªñ...

---

üë∂: ‰Ω†ÂíåopenaiÊòØ‰ªÄ‰πàÂÖ≥Á≥ªÔºü
ü§ñÔ∏è: ÊàëÊòØ MiniMindÔºå‰∏Ä‰∏™Áî± Jingyao Gong ÂºÄÂèëÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã„ÄÇÊàëÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÁÆóÊ≥ïËÆ≠ÁªÉÊù•‰∏éÁî®Êà∑ËøõË°å‰∫§‰∫í„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PSÔºöÂè™Ë¶ÅÊúâÊâÄÈúÄË¶ÅÁöÑÊï∞ÊçÆÈõÜÔºå‰πüÂèØ‰ª•full_sftÂÖ®ÂèÇÂæÆË∞ÉÔºàÈúÄË¶ÅËøõË°åÈÄöÁî®Áü•ËØÜÁöÑÊ∑∑ÂêàÈÖçÊØîÔºåÂê¶ÂàôËøáÊãüÂêàÈ¢ÜÂüüÊï∞ÊçÆ‰ºöËÆ©Ê®°ÂûãÂèòÂÇªÔºåÊçüÂ§±ÈÄöÁî®ÊÄßÔºâ&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;5. ËÆ≠ÁªÉÊé®ÁêÜÊ®°Âûã (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1ÂÆûÂú®Â§™ÁÅ´‰∫ÜÔºåÂá†‰πéÈáçÊñ∞ÊåáÊòé‰∫ÜÊú™Êù•LLMÁöÑÊñ∞ËåÉÂºè„ÄÇ ËÆ∫ÊñáÊåáÂá∫&lt;code&gt;&amp;gt;3B&lt;/code&gt;ÁöÑÊ®°ÂûãÁªèÂéÜÂ§öÊ¨°ÂèçÂ§çÁöÑÂÜ∑ÂêØÂä®ÂíåRLÂ•ñÂä±ËÆ≠ÁªÉÊâçËÉΩËé∑ÂæóËÇâÁúºÂèØËßÅÁöÑÊé®ÁêÜËÉΩÂäõÊèêÂçá„ÄÇ ÊúÄÂø´ÊúÄÁ®≥Â¶•ÊúÄÁªèÊµéÁöÑÂÅöÊ≥ïÔºå‰ª•ÂèäÊúÄËøëÁàÜÂèëÁöÑÂêÑÁßçÂêÑÊ†∑ÊâÄË∞ìÁöÑÊé®ÁêÜÊ®°ÂûãÂá†‰πéÈÉΩÊòØÁõ¥Êé•Èù¢ÂêëÊï∞ÊçÆËøõË°åËí∏È¶èËÆ≠ÁªÉÔºå ‰ΩÜÁî±‰∫éÁº∫‰πèÊäÄÊúØÂê´ÈáèÔºåËí∏È¶èÊ¥æË¢´RLÊ¥æÁûß‰∏çËµ∑ÔºàhhhhÔºâ„ÄÇ Êú¨‰∫∫ËøÖÈÄüÂ∑≤ÁªèÂú®QwenÁ≥ªÂàó1.5BÂ∞èÊ®°Âûã‰∏äËøõË°å‰∫ÜÂ∞ùËØïÔºåÂæàÂø´Â§çÁé∞‰∫ÜZeroËøáÁ®ãÁöÑÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇ ÁÑ∂ËÄå‰∏Ä‰∏™ÈÅóÊÜæÁöÑÂÖ±ËØÜÊòØÔºöÂèÇÊï∞Â§™Â∞èÁöÑÊ®°ÂûãÁõ¥Êé•ÈÄöËøáÂÜ∑ÂêØÂä®SFT+GRPOÂá†‰πé‰∏çÂèØËÉΩËé∑Âæó‰ªª‰ΩïÊé®ÁêÜÊïàÊûú„ÄÇ &lt;del&gt; MiniMind2Á¨¨‰∏ÄÊó∂Èó¥Âè™ËÉΩÂùöÂÆö‰∏çÁßªÁöÑÈÄâÊã©ÂÅöËí∏È¶èÊ¥æÔºåÊó•ÂêéÂü∫‰∫é0.1BÊ®°ÂûãÁöÑRLÂ¶ÇÊûúÂêåÊ†∑ÂèñÂæóÂ∞èÂ∞èËøõÂ±ï‰ºöÊõ¥Êñ∞Ê≠§ÈÉ®ÂàÜÁöÑËÆ≠ÁªÉÊñπÊ°à„ÄÇ &lt;/del&gt;&lt;/p&gt; 
&lt;p&gt;ÂÅöËí∏È¶èÈúÄË¶ÅÂáÜÂ§áÁöÑ‰æùÁÑ∂ÊòØÂíåSFTÈò∂ÊÆµÂêåÊ†∑Ê†ºÂºèÁöÑÊï∞ÊçÆÂç≥ÂèØÔºåÊï∞ÊçÆÈõÜÊù•Ê∫êÂ∑≤Â¶Ç‰∏äÊñá‰ªãÁªç„ÄÇÊï∞ÊçÆÊ†ºÂºè‰æãÂ¶ÇÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "conversations": [
    {
      "role": "user",
      "content": "‰Ω†Â•ΩÔºåÊàëÊòØÂ∞èËä≥ÔºåÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇ"
    },
    {
      "role": "assistant",
      "content": "&amp;lt;think&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/answer&amp;gt;"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ÁêÜÊ®°ÂûãR1ÁöÑÂõûÂ§çÊ®°ÊùøÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;lt;think&amp;gt;\nÊÄùËÄÉËøáÁ®ã\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\nÊúÄÁªàÂõûÁ≠î\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËøôÂú®GRPO‰∏≠ÈÄöËøáËÆæÁΩÆËßÑÂàôÂ•ñÂä±ÂáΩÊï∞Á∫¶ÊùüÊ®°ÂûãÁ¨¶ÂêàÊÄùËÄÉÊ†áÁ≠æÂíåÂõûÂ§çÊ†áÁ≠æÔºàÂú®ÂÜ∑ÂêØÂä®Èù†ÂâçÁöÑÈò∂ÊÆµÂ•ñÂä±ÂÄºËÆæÁΩÆÂ∫îËØ•ÊèêÈ´ò‰∏Ä‰∫õÔºâ&lt;/p&gt; 
&lt;p&gt;Âè¶‰∏Ä‰∏™ÈóÆÈ¢òÊòØËí∏È¶èËøáÁ®ãËôΩÁÑ∂ÂíåSFT‰∏ÄÊ†∑Ôºå‰ΩÜÂÆûÈ™åÁªìÊûúÊòØÊ®°ÂûãÈöæ‰ª•ÊØèÊ¨°ÈÉΩÁ¨¶ÂêàÊ®°ÊùøËßÑËåÉÁöÑÂõûÂ§çÔºåÂç≥ËÑ±Á¶ªÊÄùËÄÉÂíåÂõûÂ§çÊ†áÁ≠æÁ∫¶Êùü„ÄÇ ËøôÈáåÁöÑÂ∞èÊäÄÂ∑ßÊòØÂ¢ûÂä†Ê†áËÆ∞‰ΩçÁΩÆtokenÁöÑÊçüÂ§±ÊÉ©ÁΩöÔºåËØ¶ËßÅ&lt;code&gt;train_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# Âú® sp_ids ÂØπÂ∫îÁöÑ‰ΩçÁΩÆÂ¢ûÂä†È¢ùÂ§ñÁöÑÊÉ©ÁΩö
...
loss_mask[sp_ids] = 10 # ÊÉ©ÁΩöÁ≥ªÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âè¶Âè¶‰∏Ä‰∏™tipsÊòØÁî±‰∫éÊé®ÁêÜÊï∞ÊçÆÁî±‰∫éÂè™Á≠õÈÄâ‰∫Ü&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÈïøÂ∫¶ÁöÑÊï∞ÊçÆÔºåÂÖ∂‰∏≠Â§öËΩÆÂØπËØùÂíåËã±ÊñáÊï∞ÊçÆÂÅèÂ∞ëÔºå Âõ†Ê≠§&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ËøõË°å‰∫ÜÂ§ßÁ∫¶10kÊù°Â§öËΩÆÂØπËØù+Ëã±ÊñáÊï∞ÊçÆÁöÑÊ∑∑ÂêàÔºåÈò≤Ê≠¢Ê®°ÂûãÈÅóÂøò‰∏•Èáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;ËÑöÊú¨ÈªòËÆ§Âü∫‰∫érlhfÂêéÁöÑÂü∫Ê®°ÂûãÂÅöÊé®ÁêÜËÉΩÂäõÁöÑËí∏È¶èÂæÆË∞ÉÔºå‰∏ãÈù¢Áõ¥Êé•ÂêØÂä®ËÆ≠ÁªÉÂç≥ÂèØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_reason.py
# or
python train_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;reason_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÊµãËØï‰∏Ä‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÂóØÔºåÁî®Êà∑ËÆ©Êàë‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇÊàëÁé∞Âú®ÈúÄË¶ÅËß£Èáä‰∏Ä‰∏ãËá™Â∑±„ÄÇÈ¶ñÂÖàÔºåÊàëÂ∫îËØ•ÊòéÁ°ÆÁî®Êà∑ÊòØË∞ÅÔºåÊòØÂ≠¶Áîü„ÄÅËÅåÂú∫‰∫∫Â£´ËøòÊòØÊôÆÈÄö‰∫∫„ÄÇÁî®Êà∑ÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÊàñËÄÖËÅåÂú∫‰∫∫Â£´ÔºåÊâÄ‰ª•‰ø°ÊÅØ‰º†ÈÄíÂ∫îËØ•ÊòØÂ∏ÆÂä©Â≠¶ÁîüÂíåËÅåÂú∫‰∫∫Â£´ÁöÑ‰ø°ÊÅØ„ÄÇ
ÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅÂõûÂ∫îÁî®Êà∑ÔºåËøôÂèØËÉΩÂåÖÊã¨‰ªãÁªçËá™Â∑±ÁöÑ‰ΩçÁΩÆ„ÄÅÂÖ¥Ë∂£Áà±Â•Ω„ÄÅËÅå‰∏öÁªèÂéÜÁ≠â‰ø°ÊÅØ„ÄÇÁî®Êà∑ËøòÂèØËÉΩÊÉ≥‰∫ÜËß£Ëá™Â∑±Âú®Âì™ÈáåÔºåÊØîÂ¶ÇËÅå‰∏öÂèëÂ±ï„ÄÅÂ∑•‰ΩúÁªèÈ™åÁ≠â„ÄÇ
ÊàëÂ∫îËØ•Ê≥®ÊÑèÁî®ËØçË¶ÅÊ≠£ÂºèÔºå‰∏çË¶ÅÂ§™Ê≠£ÂºèÔºåÂêåÊó∂Ë¶Å‰øùÊåÅÁÆÄÊ¥ÅÊòé‰∫Ü„ÄÇËøôÊ†∑Áî®Êà∑ÂÆπÊòìÁêÜËß£Ôºå‰πüÊñπ‰æø‰ªñ‰ª¨Êü•ÈòÖÁõ∏ÂÖ≥ËµÑÊñô„ÄÇ
ÊúÄÂêéÔºåÊàëÂ∫îËØ•ÊÄªÁªì‰∏Ä‰∏ãÔºåËÆ©Áî®Êà∑Áü•ÈÅìÊàëÊòØÂ¶Ç‰ΩïÂ∏ÆÂä©‰ªñ‰ª¨ÂÆåÊàê‰ªñ‰ª¨ÁöÑ‰ªªÂä°ÁöÑÔºåËøôÊ†∑‰ªñ‰ª¨ÊúâÊõ¥Â§öÂÖ≥‰∫éÊàëÁöÑ‰ø°ÊÅØ„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊàëÊòØ**‚Äú‰Ω†ÁöÑÂêçÂ≠ó‚ÄùÔºå‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
&amp;lt;/answer&amp;gt;

üë∂: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;IV Âº∫ÂåñÂ≠¶‰π†ÂêéËÆ≠ÁªÉ&lt;/h2&gt; 
&lt;p&gt;LLMÈáåÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂèØÂàÜ‰∏§Á±ªÔºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Âü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π† (Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÈÄöËøá&lt;strong&gt;‰∫∫Á±ª&lt;/strong&gt;ÂØπÊ®°ÂûãËæìÂá∫ÁöÑÂÅèÂ•ΩËøõË°åËØÑ‰ª∑Êù•ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩøÂÖ∂ÁîüÊàêÊõ¥Á¨¶Âêà‰∫∫Á±ª‰ª∑ÂÄºËßÇÂíåÂÅèÂ•ΩÁöÑÂÜÖÂÆπ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Âü∫‰∫éAIÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π† (Reinforcement Learning from AI Feedback, RLAIF)&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰ΩøÁî®&lt;strong&gt;AIÊ®°Âûã&lt;/strong&gt;ÔºàÈÄöÂ∏∏ÊòØÈ¢ÑËÆ≠ÁªÉÁöÑËØ≠Ë®ÄÂ•ñÂä±Ê®°ÂûãÔºâÊù•Êèê‰æõÂèçÈ¶àÔºåËÄå‰∏çÁõ¥Êé•‰æùËµñ‰∫∫Á±ªÁöÑ‰∫∫Â∑•Ê†áÊ≥®„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËøôÈáåÁöÑ‚ÄúAI‚Äù‰πüÂèØ‰ª•ÊòØÊüê‰∫õËßÑÂàôÂ•ñÂä±Ôºå‰æãÂ¶ÇÊï∞Â≠¶Á≠îÊ°à/‰ª£Á†ÅËß£ÈáäÂô®...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Á±ªÂûã&lt;/th&gt; 
   &lt;th&gt;Ë£ÅÂà§&lt;/th&gt; 
   &lt;th&gt;‰ºòÁÇπ&lt;/th&gt; 
   &lt;th&gt;Áº∫ÁÇπ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RLHF&lt;/td&gt; 
   &lt;td&gt;‰∫∫Á±ª&lt;/td&gt; 
   &lt;td&gt;Êõ¥Ë¥¥ËøëÁúüÂÆû‰∫∫Á±ªÂÅèÂ•Ω&lt;/td&gt; 
   &lt;td&gt;ÊàêÊú¨È´ò„ÄÅÊïàÁéá‰Ωé&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RLAIF&lt;/td&gt; 
   &lt;td&gt;Ê®°Âûã&lt;/td&gt; 
   &lt;td&gt;Ëá™Âä®Âåñ„ÄÅÂèØÊâ©Â±ïÊÄßÂº∫&lt;/td&gt; 
   &lt;td&gt;ÂèØËÉΩÂÅèÁ¶ª‰∫∫Á±ªÁúüÂÆûÂÅèÂ•Ω&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;‰∫åËÄÖÊú¨Ë¥®‰∏äÊòØ‰∏ÄÊ†∑ÁöÑÔºåÈÉΩÊòØÈÄöËøá&lt;strong&gt;Âº∫ÂåñÂ≠¶‰π†ÁöÑÊñπÂºè&lt;/strong&gt;ÔºåÂà©Áî®ÊüêÁßçÂΩ¢ÂºèÁöÑ"&lt;strong&gt;ÂèçÈ¶à&lt;/strong&gt;"Êù•‰ºòÂåñÊ®°ÂûãÁöÑË°å‰∏∫„ÄÇ&lt;/p&gt; 
&lt;p&gt;Èô§‰∫Ü&lt;strong&gt;ÂèçÈ¶à&lt;/strong&gt;ÁöÑÊù•Ê∫ê‰∏çÂêåÔºåÂÖ∂‰ªñÂπ∂Êó†‰ªª‰ΩïÂå∫Âà´„ÄÇ&lt;/p&gt; 
&lt;h3&gt;üëÄ POÁÆóÊ≥ïÁöÑÁªü‰∏ÄËßÜËßí&lt;/h3&gt; 
&lt;p&gt;Âú®‰ªãÁªçÂÆûÁé∞ÂÖ∑‰ΩìÁÆóÊ≥ï‰πãÂâçÔºåÊàëÂÖà‰ª•‰∏™‰∫∫ÁêÜËß£ÁöÑÊûÅÁÆÄËßÜËßíÔºåÈòêËø∞ÊâÄÊúâPolicy Optimization (PO)ÁÆóÊ≥ïÁöÑÁªü‰∏ÄÂÖ±ÊÄß„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊâÄÊúâRLÁÆóÊ≥ïÁöÑÊú¨Ë¥®ÈÉΩÂè™ÊòØÂú®‰ºòÂåñ‰∏Ä‰∏™ÊúüÊúõÔºö&lt;/p&gt; 
&lt;p&gt;$$\mathcal{J}&lt;em&gt;{PO} = \mathbb{E}&lt;/em&gt;{q \sim P(Q), o \sim \pi(O|q)} \left[ \underbrace{f(r_t)}&lt;em&gt;{\text{Á≠ñÁï•È°π}} \cdot \underbrace{g(A_t)}&lt;/em&gt;{\text{‰ºòÂäøÈ°π}} - \underbrace{h(\text{KL}&lt;em&gt;t)}&lt;/em&gt;{\text{Ê≠£ÂàôÈ°π}} \right]$$&lt;/p&gt; 
&lt;p&gt;ËÆ≠ÁªÉÊó∂ÔºåÂè™ÈúÄ&lt;strong&gt;ÊúÄÂ∞èÂåñË¥üÁõÆÊ†áÂáΩÊï∞&lt;/strong&gt;ÔºåÂç≥: $\mathcal{L_{PO}}=-\mathcal{J_{PO}}$&lt;/p&gt; 
&lt;p&gt;Ëøô‰∏™Ê°ÜÊû∂Âè™ÂåÖÂê´‰∏â‰∏™Ê†∏ÂøÉÁªÑ‰ª∂Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Á≠ñÁï•È°π&lt;/strong&gt; $f(r_t)$: Â¶Ç‰Ωï‰ΩøÁî®Ê¶ÇÁéáÊØî $r_t$? Âç≥ÂëäËØâÊ®°ÂûãÊñ∞ÊóßÁ≠ñÁï•ÂÅèÂ∑ÆÊúâÂ§öÂ§ßÔºåÊòØÂê¶Êé¢Á¥¢Âà∞‰∫ÜÊõ¥Â•ΩÁöÑtoken&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÈ°π&lt;/strong&gt; $g(A_t)$: Â¶Ç‰ΩïËÆ°ÁÆó‰ºòÂäø $A_t$, ËøôÂæàÈáçË¶ÅÔºÅÂ§ßÊ®°ÂûãÁÆóÂØπÂÆöÁßØÂàÜ‰πü‰∏çË∂≥‰∏∫Â•áÔºåÂ∞èÊ®°ÂûãÂõûÁ≠îÂØπÂä†ÂáèÊ≥ï‰ºòÂäøÈÄöÂ∏∏ÈÉΩÊòØÊ≠£ÁöÑ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê≠£ÂàôÈ°π&lt;/strong&gt; $h(\text{KL}_t)$: Â¶Ç‰ΩïÁ∫¶ÊùüÂèòÂåñÂπÖÂ∫¶ $\text{KL}_t$, Êó¢Èò≤Ê≠¢Ë∑ëÂÅèÂèàÈò≤Ê≠¢ÁÆ°ÁöÑÂ§™Ê≠ª&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÔºàÂ±ïÂºÄÔºâÁ¨¶Âè∑ËØ¥Êòé&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Á¨¶Âè∑&lt;/th&gt; 
    &lt;th&gt;Âê´‰πâ&lt;/th&gt; 
    &lt;th&gt;ËØ¥Êòé&lt;/th&gt; 
    &lt;th&gt;ÂÄºÂüü&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$q$&lt;/td&gt; 
    &lt;td&gt;ÈóÆÈ¢ò/ÊèêÁ§∫ËØç&lt;/td&gt; 
    &lt;td&gt;‰ªéÊï∞ÊçÆÈõÜ $P(Q)$ ‰∏≠ÈááÊ†∑&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$o$&lt;/td&gt; 
    &lt;td&gt;Ê®°ÂûãËæìÂá∫Â∫èÂàó&lt;/td&gt; 
    &lt;td&gt;Áî±Á≠ñÁï• $\pi$ ÁîüÊàê&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$r_t$&lt;/td&gt; 
    &lt;td&gt;Ê¶ÇÁéáÊØî&lt;/td&gt; 
    &lt;td&gt;$r_t = \frac{\pi_\theta(o_t|q, o_{&amp;lt;t})}{\pi_{ref}(o_t|q, o_{&amp;lt;t})}$&lt;/td&gt; 
    &lt;td&gt;$(0, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$A_t$&lt;/td&gt; 
    &lt;td&gt;‰ºòÂäøÂáΩÊï∞&lt;/td&gt; 
    &lt;td&gt;Ë°°ÈáèÊüê‰∏™Âä®‰ΩúÁõ∏ÊØîÂü∫Á∫øÊúâÂ§öÂ•Ω&lt;/td&gt; 
    &lt;td&gt;$(-\infty, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;$\text{KL}_t$&lt;/td&gt; 
    &lt;td&gt;KLÊï£Â∫¶&lt;/td&gt; 
    &lt;td&gt;Èò≤Ê≠¢Á≠ñÁï•ÂÅèÁ¶ªÂèÇËÄÉÊ®°ÂûãÂ§™Ëøú&lt;/td&gt; 
    &lt;td&gt;$[0, +\infty)$&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;‰∏çÂêåÁöÑ&lt;strong&gt;xxPOÁÆóÊ≥ï&lt;/strong&gt;Êú¨Ë¥®‰∏äÂè™ÊòØÂØπËøô‰∏â‰∏™ÁªÑ‰ª∂ÁöÑ‰∏çÂêåËÆæËÆ°ÁöÑÂÆû‰æãÂåñÔºÅ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;6. Âü∫‰∫é‰∫∫Á±ªÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π† (Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂü∫Êú¨ÁöÑÂØπËØùËÉΩÂäõÔºå‰ΩÜÊòØËøôÊ†∑ÁöÑËÉΩÂäõÂÆåÂÖ®Âü∫‰∫éÂçïËØçÊé•ÈæôÔºåÁº∫Â∞ëÊ≠£ÂèçÊ†∑‰æãÁöÑÊøÄÂä±„ÄÇ Ê®°ÂûãÊ≠§Êó∂Â∞öÊú™Áü•‰ªÄ‰πàÂõûÁ≠îÊòØÂ•ΩÁöÑÔºå‰ªÄ‰πàÊòØÂ∑ÆÁöÑ„ÄÇÂ∏åÊúõÂÆÉËÉΩÂ§üÊõ¥Á¨¶Âêà‰∫∫ÁöÑÂÅèÂ•ΩÔºåÈôç‰ΩéËÆ©‰∫∫Á±ª‰∏çÊª°ÊÑèÁ≠îÊ°àÁöÑ‰∫ßÁîüÊ¶ÇÁéá„ÄÇ Ëøô‰∏™ËøáÁ®ãÂ∞±ÂÉèÊòØËÆ©Ê®°ÂûãÂèÇÂä†Êñ∞ÁöÑÂüπËÆ≠Ôºå‰ªé‰ºòÁßÄÂëòÂ∑•ÁöÑ‰Ωú‰∏∫‰æãÂ≠êÔºåÊ∂àÊûÅÂëòÂ∑•‰Ωú‰∏∫Âèç‰æãÔºåÂ≠¶‰π†Â¶Ç‰ΩïÊõ¥Â•ΩÂú∞ÂõûÂ§ç„ÄÇ&lt;/p&gt; 
&lt;h4&gt;6.1 Direct Preference Optimization&lt;/h4&gt; 
&lt;p&gt;Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâÁÆóÊ≥ïÔºåÊçüÂ§±‰∏∫Ôºö&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}&lt;em&gt;{DPO} = -\mathbb{E}\left[\log \sigma\left(\beta \left[\log \frac{\pi&lt;/em&gt;\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}\right]\right)\right]$$&lt;/p&gt; 
&lt;p&gt;ÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Á≠ñÁï•È°π&lt;/strong&gt;: $f(r_t) = \log r_w - \log r_l$ (ÂØπÊØîchosen vs rejectedÁöÑÊ¶ÇÁéáÊØî)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÈ°π&lt;/strong&gt;: $g(A_t)$ = / (ÈÄöËøáÂÅèÂ•ΩÂØπÊØîÔºåÊó†ÈúÄÊòæÂºèËÆ°ÁÆó‰ºòÂäø)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê≠£ÂàôÈ°π&lt;/strong&gt;: $h(\text{KL}_t)$ = ÈöêÂê´Âú® $\beta$ ‰∏≠ (ÊéßÂà∂ÂÅèÁ¶ªÂèÇËÄÉÊ®°ÂûãÁ®ãÂ∫¶)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÁâπÂà´Âú∞Ôºå&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DPO‰ªéPPOÂ∏¶KLÁ∫¶ÊùüÁöÑÁõÆÊ†áÊé®ÂØºÂá∫ÂØπÂÅèÂ•ΩÂØπÁöÑËß£ÊûêËÆ≠ÁªÉÁõÆÊ†áÔºåÁõ¥Êé•ÊúÄÂ§ßÂåñ"chosen‰ºò‰∫érejected"ÁöÑÂØπÊï∞Âá†ÁéáÔºõÊó†ÈúÄÂêåÊ≠•ËÆ≠ÁªÉReward/ValueÊ®°Âûã„ÄÇDPOÂè™ÈúÄË∑ë&lt;code&gt;actor&lt;/code&gt;‰∏é&lt;code&gt;ref&lt;/code&gt;‰∏§‰∏™Ê®°ÂûãÔºåÊòæÂ≠òÂç†Áî®‰Ωé„ÄÅÊî∂ÊïõÁ®≥ÂÆö„ÄÅÂÆûÁé∞ÁÆÄÂçï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆ≠ÁªÉËåÉÂºèÔºöoff‚ÄëpolicyÔºå‰ΩøÁî®ÈùôÊÄÅÂÅèÂ•ΩÊï∞ÊçÆÈõÜÔºåÂèØÂèçÂ§çÂ§öËΩÆepochÔºõRefÊ®°ÂûãÂõ∫ÂÆöÔºàÈ¢ÑÂÖàÁºìÂ≠òËæìÂá∫Ôºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;DPOÁöÑÂ±ÄÈôêÂú®‰∫é‰∏çÂÅöÂú®Á∫øÊé¢Á¥¢ÔºåÊõ¥Â§öÁî®‰∫é"ÂÅèÂ•Ω/ÂÆâÂÖ®"ÁöÑ‰∫∫Á±ª‰ª∑ÂÄºÂØπÈΩêÔºõÂØπ"ËÉΩ‰∏çËÉΩÂÅöÂØπÈ¢ò"ÁöÑÊô∫ÂäõËÉΩÂäõÊèêÂçáÊúâÈôêÔºàÂΩìÁÑ∂Ëøô‰πüÂèñÂÜ≥‰∫éÊï∞ÊçÆÈõÜÔºåÂ§ßËßÑÊ®°Êî∂ÈõÜÊ≠£ÂèçÊ†∑Êú¨Âπ∂‰∫∫Á±ªËØÑ‰º∞ÂæàÂõ∞ÈöæÔºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;dpo_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;7. Âü∫‰∫éAIÂèçÈ¶àÁöÑÂº∫ÂåñÂ≠¶‰π† (Reinforcement Learning from AI Feedback, RLAIF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Áõ∏ÊØîRLHF‰æùËµñ‰∫∫Á±ªÊ†áÊ≥®chosen/rejectedÂÅèÂ•ΩÂØπÔºåRLAIFÂàôÂÆåÂÖ®Áî±AIÊù•ÂÖÖÂΩì"Ë£ÅÂà§"„ÄÇ ÊâÄË∞ìAI"Ë£ÅÂà§"ÂèØ‰ª•ÊòØmodel-baseÁöÑÂ•ñÂä±Â§ßÊ®°Âûã(Reward Model)Ôºå‰πüÂèØ‰ª•ÊòØR1‰∏ÄÊ†∑ËÆæÁΩÆËßÑÂàôÂáΩÊï∞ËøõË°åÊ†°È™åÔºå‰πüÂèØ‰ª•ÊòØ‰æãÂ¶ÇÂ∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÁéØÂ¢ÉÂèçÈ¶à„ÄÇ ‰æãÂ¶ÇÔºöÊï∞Â≠¶È¢òÁ≠îÊ°àÊòØÂê¶Ê≠£Á°Æ„ÄÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÊâßË°å‰ª£Á†ÅËÉΩÂê¶ÈÄöËøáÊµãËØïÁî®‰æã„ÄÅÊé®ÁêÜËøáÁ®ãÊòØÂê¶Á¨¶ÂêàÊ†ºÂºè...ÈÉΩÂèØ‰ª•Ëá™Âä®ÂåñÂà§Êñ≠„ÄÇ RLAIFÁöÑÊúÄÂ§ß‰ºòÂäøÂú®‰∫é&lt;strong&gt;ÂèØÊâ©Â±ïÊÄß&lt;/strong&gt;Âíå&lt;strong&gt;On-Policy&lt;/strong&gt;ÁöÑÁâπÁÇπ‚Äî‚Äî‰∏çÈúÄË¶ÅÊòÇË¥µÁöÑ‰∫∫Â∑•Ê†áÊ≥®ÔºåÂèØ‰ª•ÁîüÊàêÊµ∑ÈáèÁöÑËÆ≠ÁªÉÊ†∑Êú¨ÔºåËÆ©Ê®°ÂûãÂú®Âú®Á∫øÂ§ßÈáèËØïÈîô‰∏≠Âø´ÈÄüËøõÂåñ„ÄÇ&lt;/p&gt; 
&lt;p&gt;MiniMind ÁùÄÊâãÂÆûÁé∞&lt;strong&gt;2+N&lt;/strong&gt;ÁßçÂü∫Êú¨+ÂâçÊ≤øÁöÑRLAIFÊñπÊ≥ïÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PPO&lt;/strong&gt;„ÄÅ&lt;strong&gt;GRPO&lt;/strong&gt; Ë¢´Â§ßËßÑÊ®°È™åËØÅÁöÑÁªèÂÖ∏RLÁÆóÊ≥ïÔºõ&lt;/li&gt; 
 &lt;li&gt;NÁßçÂâçÊ≤øRLÁÆóÊ≥ïÔºà‰∏çÂÆöÊúü‰ª•ExpÊÄßË¥®Êõ¥Êñ∞Ôºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1Ô∏è‚É£ Êï∞ÊçÆÈõÜÂáÜÂ§á (ÈúÄË¶Å)&lt;/h4&gt; 
&lt;p&gt;‰∏∫‰∫ÜÂø´ÈÄüÈ™åËØÅRLAIFÁöÑÊïàÊûúÔºåËøôÈáå‰ªéSFTÊï∞ÊçÆÈõÜ‰∏≠ÈöèÊú∫ÈááÊ†∑‰∫Ü1‰∏áÊù°È´òË¥®ÈáèÂØπËØùÔºåÊûÑÂª∫Á∫¶1MBÂ§ßÂ∞èÁöÑ&lt;code&gt;rlaif-mini.jsonl&lt;/code&gt;(&lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/blob/main/rlaif-mini.jsonl"&gt;Huggingface&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;Êï∞ÊçÆÊ†ºÂºè‰∏éSFT‰∏ÄËá¥Ôºå‰ΩÜassistantÂπ∂‰∏çÈúÄË¶ÅÂÜÖÂÆπÔºåÂõ†‰∏∫ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÂÆåÂÖ®Áî± $\Pi$ Á≠ñÁï•Ê®°ÂûãÂÆûÊó∂ÈááÊ†∑ÁîüÊàê„ÄÇÂõ†Ê≠§ÂΩ¢Â¶ÇÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "conversations": [
        {"role": "user", "content": "ËØ∑Ëß£Èáä‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂÖâÂêà‰ΩúÁî®Ôºü"},
        {"role": "assistant", "content": "Êó†"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RLAIFÁöÑËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°Âûã‰ºöÂü∫‰∫éuserÁöÑÈóÆÈ¢òÁîüÊàê1ÊàñÂ§ö‰∏™ÂÄôÈÄâÂõûÁ≠îÔºåÁÑ∂ÂêéÁî±Â•ñÂä±ÂáΩÊï∞/Ê®°ÂûãÂØπÂõûÁ≠îÊâìÂàÜÔºå ÂàÜÊï∞È´òÁöÑÂõûÁ≠î‰ºöË¢´ÈºìÂä±ÔºàÂ¢ûÂä† $\Pi$ Á≠ñÁï•Ê¶ÇÁéáÔºâÔºåÂàÜÊï∞‰ΩéÁöÑÂõûÁ≠î‰ºöË¢´ÊäëÂà∂ÔºàÈôç‰Ωé $\Pi$ Á≠ñÁï•Ê¶ÇÁéáÔºâ„ÄÇËøô‰∏™"ÊâìÂàÜ-&amp;gt;Ë∞ÉÊï¥"ÁöÑÂæ™ÁéØÂ∞±ÊòØÂº∫ÂåñÂ≠¶‰π†ÁöÑÊ†∏ÂøÉ„ÄÇ&lt;/p&gt; 
&lt;h4&gt;2Ô∏è‚É£ Â•ñÂä±Ê®°ÂûãÂáÜÂ§á (ÈúÄË¶Å)&lt;/h4&gt; 
&lt;p&gt;Â∑≤Áü•RLAIFËÆ≠ÁªÉÈúÄË¶Å‚ÄúÂ•ñÂä±Ê®°Âûã (Reward Model)‚ÄùÂØπÁîüÊàêÁöÑÂõûÁ≠îËøõË°åÊâìÂàÜ„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ê≠§Â§ÑÈÄâÂèñÂ∞èÂûã‰∏îÈ´òË¥®ÈáèÁöÑInternLM2-1.8B-Reward (&lt;a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b-reward"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/internlm/internlm2-1_8b-reward"&gt;HuggingFace&lt;/a&gt;) ‰Ωú‰∏∫Âü∫Á°ÄÂ•ñÂä±Ê®°Âûã„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰∏ãËΩΩÂ•ñÂä±Ê®°ÂûãÂêéÈúÄË¶ÅÊîæÁΩÆÂú®minimindÈ°πÁõÆÁöÑ&lt;strong&gt;ÂêåÁ∫ßÁõÆÂΩï&lt;/strong&gt;‰∏ãÔºåÊé®ËçêÁªìÊûÑÂ¶Ç‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;project/
‚îú‚îÄ‚îÄ minimind/                    # MiniMindÈ°πÁõÆ
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ internlm2-1_8b-reward/       # Â•ñÂä±Ê®°ÂûãÔºà‰∏éminimindÂêåÁ∫ßÔºâ
    ‚îú‚îÄ‚îÄ config.json
    ‚îú‚îÄ‚îÄ model.safetensors
    ‚îî‚îÄ‚îÄ ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Â•ñÂä±Êú∫Âà∂ÈÄâÊã©‰∏éMiniMindÈôêÂà∂ËØ¥ÊòéÔºàÁÇπÂáªÂ±ïÂºÄÔºâ&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;1. Â•ñÂä±Êú∫Âà∂ÁöÑÂ§öÊ†∑ÊÄß&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;RLAIF‰∏≠ÁöÑ"Â•ñÂä±‰ø°Âè∑"Êù•Ê∫êÂèØ‰ª•ÈùûÂ∏∏ÁÅµÊ¥ªÔºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model-basedÂ•ñÂä±&lt;/strong&gt;ÔºöÂèØ‰ΩøÁî®‰∏ìÈó®ÁöÑReward ModelÔºàÂ¶ÇInternLM2-RewardÔºâÔºå‰πüÂèØ‰ΩøÁî®ÈÄöÁî®LLM+ÊèêÁ§∫ËØçËøõË°åÊâìÂàÜÔºàÂ¶ÇQwen3-as-a-JudgeÔºâ„ÄÇÂ•ñÂä±Ê®°ÂûãËßÑÊ®°ÂíåÊû∂ÊûÑÂùáÂèØËá™Áî±ÈÄâÊã©„ÄÇ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rule-basedÂ•ñÂä±&lt;/strong&gt;ÔºöÂèØ‰ª•Âü∫‰∫éËßÑÂàôÂáΩÊï∞ÊûÑÈÄ†Â•ñÂä±‰ø°Âè∑Ôºå‰æãÂ¶ÇÔºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Êï∞Â≠¶È¢òÁ≠îÊ°àÊ≠£Á°ÆÊÄßÈ™åËØÅÔºàGround TruthÂØπÊØîÔºâ&lt;/li&gt; 
    &lt;li&gt;SQLÊâßË°åÊàêÂäüÁéá‰∏éÁªìÊûúÂáÜÁ°ÆÊÄß&lt;/li&gt; 
    &lt;li&gt;‰ª£Á†ÅËß£ÈáäÂô®ËøêË°åÁªìÊûúÔºàpass@kÔºâ&lt;/li&gt; 
    &lt;li&gt;Â∑•ÂÖ∑Ë∞ÉÁî®ËøîÂõûÁä∂ÊÄÅÔºàAPIÊàêÂäü/Â§±Ë¥•Ôºâ&lt;/li&gt; 
    &lt;li&gt;Ê†ºÂºèÂêàËßÑÊÄßÊ£ÄÊü•ÔºàJSON/XMLËß£ÊûêÔºâ&lt;/li&gt; 
    &lt;li&gt;Êé®ÁêÜÈìæÂÆåÊï¥ÊÄßËØÑ‰º∞ÔºàCoTÊ≠•È™§Êï∞Ôºâ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Environment-basedÂ•ñÂä±&lt;/strong&gt;ÔºöÂú®AgentÂú∫ÊôØ‰∏≠ÔºåÁéØÂ¢ÉÂèçÈ¶àÊú¨Ë∫´Âç≥‰∏∫Â§©ÁÑ∂Â•ñÂä±ÔºàÂ¶ÇÊ∏∏ÊàèÂæóÂàÜ„ÄÅResearchÂÆåÊï¥Â∫¶„ÄÅ‰ªªÂä°ÂÆåÊàêÂ∫¶Ôºâ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;‰ªª‰ΩïËÉΩÂ§üÈáèÂåñ"ÂõûÁ≠îË¥®Èáè"ÁöÑÊú∫Âà∂ÈÉΩÂèØ‰Ωú‰∏∫RLÁöÑÂ•ñÂä±Êù•Ê∫ê„ÄÇDeepSeek R1Â∞±ÊòØÂÖ∏ÂûãÊ°à‰æãÔºö‰ΩøÁî®ËßÑÂàôÂáΩÊï∞È™åËØÅÊï∞Â≠¶Á≠îÊ°àÊ≠£Á°ÆÊÄß‰Ωú‰∏∫Â•ñÂä±ÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑReward Model„ÄÇ&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2. MiniMindÈôêÂà∂ÔºöÂ•ñÂä±Á®ÄÁñèÈóÆÈ¢ò&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;RLAIFËÆ≠ÁªÉÊó¢ÂèØ‰ª•ÈíàÂØπÊé®ÁêÜÊ®°Âûã‰πüÂèØ‰ª•ÈíàÂØπÈùûÊé®ÁêÜÊ®°ÂûãÔºåÂå∫Âà´‰ªÖÂú®‰∫éÊ†ºÂºè„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÑ∂ËÄåÂØπ‰∫éMiniMindËøôÁßç0.1BÂèÇÊï∞ÈáèÊûÅÂ∞èËÉΩÂäõÂº±ÁöÑÊ®°ÂûãÔºåÂú®ÈÄöÁî®‰ªªÂä°ÔºàÂ¶ÇR1È£éÊ†ºÁöÑÊï∞Â≠¶Êï∞ÊçÆÈõÜÔºâ‰∏ä‰ºöÈÅáÂà∞‰∏•ÈáçÁöÑÂ•ñÂä±Á®ÄÁñè(Reward Sparsity)ÈóÆÈ¢òÔºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Áé∞Ë±°&lt;/strong&gt;ÔºöÊ®°ÂûãÁîüÊàêÁöÑÂÄôÈÄâÂõûÁ≠îÂá†‰πéÂÖ®ÈÉ®ÈîôËØØÔºåÂØºËá¥ÊâÄÊúâÂ•ñÂä±ÂàÜÊï∞ $r(x,y) \approx 0$&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÂêéÊûú&lt;/strong&gt;Ôºö‰ºòÂäøÂáΩÊï∞ $A(x,y) = r(x,y) - b(x) \approx 0$ÔºåÁ≠ñÁï•Ê¢ØÂ∫¶‰ø°Âè∑Ê∂àÂ§±ÔºåÊó†Ê≥ïÊúâÊïàÊõ¥Êñ∞ÂèÇÊï∞ $\theta$&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Â¶ÇÂêåËÆ©Â∞èÂ≠¶ÁîüÂÅöÈ´òËÄÉÊï∞Â≠¶È¢òÔºåÊó†ËÆ∫Â∞ùËØïÂ§öÂ∞ëÊ¨°ÈÉΩÂæóÈõ∂ÂàÜÔºåÊó†Ê≥ïÈÄöËøáÂàÜÊï∞Â∑ÆÂºÇÂ≠¶‰π†ÊîπËøõÁ≠ñÁï•„ÄÇÂõ†Ê≠§ËøôÊòØRLÁÆóÊ≥ïÁöÑÊ†πÊú¨ÂéüÁêÜÈôêÂà∂ÁöÑ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;‰∏∫ÁºìËß£Ê≠§ÈóÆÈ¢òÔºåMiniMindÁöÑÂÆûÁé∞ÈÄâÊã©‰∫Ü&lt;strong&gt;model-basedÁöÑËøûÁª≠ÊÄßÂ•ñÂä±‰ø°Âè∑&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Reward ModelËæìÂá∫ËøûÁª≠ÂàÜÊï∞ÔºàÂ¶Ç-2.5Âà∞+3.0ÔºâÔºåËÄåÈùû‰∫åÂÖÉÁöÑ0/1&lt;/li&gt; 
  &lt;li&gt;Âç≥‰ΩøÂõûÁ≠îË¥®ÈáèÈÉΩÂ∑ÆÔºå‰πü‰ªçËÉΩÂå∫ÂàÜ"Êõ¥Êõ¥Â∑Æ"(-3.0)Âíå"Êõ¥Â∑Æ"(-2.8)ÁöÑÁªÜÂæÆÂ∑ÆÂºÇ„ÄÇÊâÄ‰ª•ËøôÁßç&lt;strong&gt;Á®†ÂØÜ‰∏îËøûÁª≠&lt;/strong&gt;ÁöÑÂ•ñÂä±‰ø°Âè∑ËÉΩÂ§ü‰∏∫‰ºòÂäøÂáΩÊï∞ $A(x,y)$ Êèê‰æõÈùûÈõ∂Ê¢ØÂ∫¶Ôºå‰ΩøÂæóÁ≠ñÁï•ÁΩëÁªúÂæó‰ª•Ê∏êËøõÂºè‰ºòÂåñ&lt;/li&gt; 
  &lt;li&gt;‰πüÂèØ‰ª•Ê∑∑ÂêàÂ§öÁßçÂ•ñÂä±Ê∫ê: $r_{\text{total}} = \alpha \cdot r_{\text{model}} + \beta \cdot r_{\text{rule}}$ (‰æãÂ¶ÇÊó¢ÂèØ‰ª•Ê£ÄÊµãthinkÊ†áÁ≠æÊ†ºÂºèrewardÔºåÂèàÂèØ‰ª•ÁªºÂêàÂõûÁ≠îÊú¨Ë∫´Ë¥®ÈáèÁöÑrewardÂàÜÊï∞)&lt;/li&gt; 
  &lt;li&gt;minimindÂÆûË∑µ‰∏≠ÈÅøÂÖçÁõ¥Êé•‰ΩøÁî®rule-based‰∫åÂÖÉÂ•ñÂä± + Ë∂ÖÁ∫≤ÈöæÂ∫¶Êï∞ÊçÆÔºàÂ¶ÇMATH500ÔºâÔºåÊòìÂØºËá¥Â•ñÂä±ÂÖ®Èõ∂Ôºõ&lt;/li&gt; 
  &lt;li&gt;ÁõëÊéßËÆ≠ÁªÉÊó∂ËßÇÂØüÂ•ñÂä±ÂàÜÊï∞ÁöÑÊñπÂ∑Æ $\text{Var}(r)$ÔºåËã•ÊåÅÁª≠Êé•Ëøë0ÂàôÈúÄË∞ÉÊï¥Êï∞ÊçÆÊàñÂ•ñÂä±Êú∫Âà∂&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂØπ‰∫éÁîü‰∫ßÁ∫ßÂ§ßÊ®°ÂûãÁöÑAgentic RLÂú∫ÊôØ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;p&gt;Âú®ÁúüÂÆûAgentÁ≥ªÁªüÔºà‰ª£Á†ÅÁîüÊàê„ÄÅÂ∑•ÂÖ∑Ë∞ÉÁî®„ÄÅÊ£ÄÁ¥¢-ËßÑÂàí-ÊâßË°åÁöÑÂ§öËΩÆÈìæË∑ØÔºâ‰∏≠ÔºåÂ•ñÂä±ÊòØ‚ÄúÂª∂ËøüÊï¥ËΩÆÁªìÁÆó‚ÄùÁöÑ‰∏çÂêåËåÉÂºèÔºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LLMÈúÄË¶ÅÈÄêtokenÁîüÊàêÂ∑•ÂÖ∑Ë∞ÉÁî®Êåá‰ª§Ôºàtool_callÔºâÔºåÁªèÂéÜËß£ÊûêÔºàtool_parseÔºâ„ÄÅÂ∑•ÂÖ∑ÊâßË°åÔºàtool_execÔºâÔºåÂÜçÊääÁªìÊûúÊãºÊé•Âõû‰∏ä‰∏ãÊñáÁªßÁª≠‰∏ã‰∏ÄÊ≠•ÔºõÂæ™ÁéØÂæÄÂ§çÁõ¥Âà∞ÂÆåÊàê„ÄÇ&lt;/li&gt; 
  &lt;li&gt;‰∏ÄÊ¨°ÂÆåÊï¥ÁöÑ‰ªªÂä°ÈìæË∑ØÂåÖÂê´Â§öÊ¨°Ë∞ÉÁî®+ÊÄùËÄÉÔºåÁõ¥Âà∞ÁªàÊ≠¢Êù°‰ª∂Êª°Ë∂≥Êó∂ËÆ°ÁÆó‰∏ÄÊ¨°ÊÄªrewardÔºàÂ¶Ç‰ªªÂä°ÊòØÂê¶ÂÆåÊàê„ÄÅÊµãËØïÊòØÂê¶ÈÄöËøá„ÄÅÁõÆÊ†áÊòØÂê¶ÂëΩ‰∏≠Ôºâ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Âõ†Ê≠§ÔºåAgentic RLÊõ¥Êé•ËøëÁ®ÄÁñè/Âª∂ËøüÂ•ñÂä±ËÆæÂÆöÔºöÊ¢ØÂ∫¶Âõû‰º†Âú®‚ÄúÊï¥ËΩÆÁªìÊùüÂêé‚ÄùÊâçÂèëÁîüÔºåÂíåÈùûAgentic RL‰ªªÂä°Âú®ÂØπËØùÂçïËΩÆ‰∏ä‚ÄúÂç≥Êó∂ËØÑÂàÜÂç≥Êó∂Êõ¥Êñ∞‚ÄùÊúâÂæàÂ§ß‰∏çÂêå„ÄÇ Ëøô‰πüËß£Èáä‰∫ÜAgent‰ªªÂä°‰∏äÊõ¥ÂÅèÂêëÁéØÂ¢ÉÂèçÈ¶àÔºàenvironment-based rewardÔºâÔºåËÄåÈùûÂá≠Reward ModelËøõË°åÈùôÊÄÅÊâìÂàÜ„ÄÇ&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ÁéØÂ¢É‰∫§‰∫íÂèçÈ¶à&lt;/strong&gt;ÔºöÊúÄÁªà‰ª•ÊâßË°åÁªìÊûú‰∏∫ÂáÜÔºà‰ª£Á†ÅÊòØÂê¶Ë∑ëÈÄö„ÄÅAPIÊòØÂê¶ËøîÂõûÊàêÂäü„ÄÅÂ≠êÁõÆÊ†áÊòØÂê¶ÂÆåÊàêÔºâÔºõ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Model-basedÂ•ñÂä±Â±ÄÈôê&lt;/strong&gt;ÔºöÂØπÈïøÈìæË∑Ø„ÄÅÂèØÊâßË°åËØ≠‰πâÁöÑÂÖ®Ë≤åÊçïÊçâÊúâÈôêÔºå‰∏îÂ§ßÊ¶ÇÁéáÂíåÁúüÂÆûÁéØÂ¢ÉÂèçÈ¶à‰∏ç‰∏ÄËá¥Ôºàreward hackingÔºâ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h4&gt;7.1 &lt;a href="https://arxiv.org/abs/1707.06347"&gt;Proximal Policy Optimization&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;PPO ÊòØ2017Âπ¥OpenAIÊèêÂá∫ÁöÑÈùûÂ∏∏ÁªèÂÖ∏Âº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºå‰πüÊòØLLM RLÈÄöÁî®ÁöÑÂü∫Á∫øÊñπÊ≥ïÔºåÁîöËá≥‰∏çÈúÄË¶ÅÂä†‰πã‰∏Ä„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PPOÊçüÂ§±&lt;/strong&gt;Ôºö $$\mathcal{L}_{PPO} = -\mathbb{E}\left[\min(r_t \cdot A_t, \text{clip}(r_t, 1-\varepsilon, 1+\varepsilon) \cdot A_t)\right] + \beta \cdot \mathbb{E}[\text{KL}]$$&lt;/p&gt; 
&lt;p&gt;ÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Á≠ñÁï•È°π&lt;/strong&gt;: $f(r_t) = \min(r_t, \text{clip}(r_t, 1-\varepsilon, 1+\varepsilon))$ (Ë£ÅÂâ™Ê¶ÇÁéáÊØîÈò≤Ê≠¢Êõ¥Êñ∞ËøáÊøÄ)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÈ°π&lt;/strong&gt;: $g(A_t) = R - V(s)$ (ÈÄöËøáCriticÁΩëÁªú‰º∞ËÆ°‰ª∑ÂÄºÂáΩÊï∞)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê≠£ÂàôÈ°π&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \mathbb{E}[\text{KL}]$ (ÂÖ®Â±ÄKLÊï£Â∫¶Á∫¶Êùü)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÂØπÊØîDPOËÄåË®ÄÔºå&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DPO (Off-Policy)ÔºöËÆ≠ÁªÉÊï∞ÊçÆÊòØÈùôÊÄÅÁöÑÂÅèÂ•ΩÊï∞ÊçÆÈõÜÔºàchosen vs rejectedÔºâÔºåÂèØ‰ª•ÂèçÂ§ç‰ΩøÁî®Âêå‰∏ÄÊâπÊï∞ÊçÆËÆ≠ÁªÉÂ§ö‰∏™epochÔºåÂ∞±ÂÉè‰º†ÁªüÁõëÁù£Â≠¶‰π†‰∏ÄÊ†∑„ÄÇÊï∞ÊçÆÊïàÁéáÈ´òÔºåËÆ≠ÁªÉÊàêÊú¨‰Ωé„ÄÇÂÆÉÁõ¥Êé•‰ºòÂåñÂÅèÂ•ΩÂØπÁöÑÂØπÊï∞‰ººÁÑ∂ÔºåÊó†ÈúÄReward Model„ÄÇ&lt;/li&gt; 
 &lt;li&gt;PPO (On-Policy)ÔºöÂøÖÈ°ªÁî®ÂΩìÂâçÁ≠ñÁï•ÂÆûÊó∂ÈááÊ†∑ÁîüÊàêÊñ∞Êï∞ÊçÆÔºåÊóßÁ≠ñÁï•ÈááÈõÜÁöÑÊï∞ÊçÆ‰∏çËÉΩÁî®Ôºà‰ºöÊúâdistribution shiftÈóÆÈ¢òÔºâ„ÄÇËôΩÁÑ∂ÈÄöËøáimportance samplingÂíåclipÊú∫Âà∂ÂÖÅËÆ∏ËΩªÂæÆÁöÑÂàÜÂ∏ÉÂÅèÁßªÔºå‰ΩÜÊú¨Ë¥®‰∏äË¶ÅÊ±ÇÊï∞ÊçÆÊù•Ëá™Áõ∏ÂØπÊñ∞È≤úÁöÑÁ≠ñÁï•„ÄÇÊï∞ÊçÆÊïàÁéá‰ΩéÔºå‰ΩÜÈÄÇÂêàÊé¢Á¥¢ÂºèÂ≠¶‰π†„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÁÆÄÂçïÊù•ËØ¥Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂâçËÄÖÊïôÊ®°ÂûãÊåâÁ¶ªÁ∫øÈ¢ÑÂÆöÁöÑ„ÄåÂ•Ω/ÂùèÊ†áÂáÜ„ÄçÂ≠¶‰π†ÔºåÂ∞ΩÁÆ°ÂÆÉÂπ∂ÈùûÊòØÂΩìÂâçÊ®°ÂûãÊâÄËÉΩËæìÂá∫ÁöÑÔºà‰æãÂ¶ÇÂèÇËÄÉ‰∏ñÁïåÂÜ†/‰∫öÂÜõÂΩïÂÉèÁªÉ‰π†ÊâìÁêÉÔºâÔºõ&lt;/li&gt; 
 &lt;li&gt;ÂêéËÄÖÂÆûÊó∂Âú∞ÊïôÊ®°ÂûãÊää‰∫ãÊÉÖÂÅöÂØπÂÅöÂ•ΩÔºåÂú®Á∫øÈááÊ†∑Ëá™ÊúÄÊñ∞Ê®°ÂûãpolicyÔºàÊïôÁªÉÊâãÊääÊâãÊïôÊâìÔºå‰∏∫ÊØè‰∏™Âä®‰ΩúÂÆûÊó∂ÊâìÂàÜÔºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MiniMindÁöÑPPOÂÆûÁé∞ÂåÖÂê´‰∫ÜActorÊ®°Âûã(ÁîüÊàêÂõûÁ≠î)ÂíåCriticÊ®°Âûã(ËØÑ‰º∞ÂõûÁ≠î‰ª∑ÂÄº)Ôºå‰ª•ÂèäÂÆåÊï¥ÁöÑGAE(Generalized Advantage Estimation)‰ºòÂäøÂáΩÊï∞ËÆ°ÁÆó„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËÆ≠ÁªÉÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_ppo.py
# or
python train_ppo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;ppo_actor_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_ppo_512.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_ppo_768.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;‰ªéËÆ≠ÁªÉÊõ≤Á∫øÂèØ‰ª•ÁúãÂá∫ÔºåPPOÂ≠òÂú®&lt;strong&gt;rewardÊèêÂçáÁºìÊÖ¢&lt;/strong&gt;ÁöÑÈóÆÈ¢ò„ÄÇÁßÅ‰ª•‰∏∫Ëøô‰∏ªË¶ÅÊ∫ê‰∫é&lt;strong&gt;PPOÂèåÁΩëÁªúËÅîÂêà‰ºòÂåñ&lt;/strong&gt;ÊñπÊ≥ïÔºöCriticÈúÄË¶ÅÈÄêÊ≠•Êî∂Êïõ‰ª•ÂáÜÁ°Æ‰º∞ËÆ°‰ª∑ÂÄºÂáΩÊï∞ÔºåËÄåActorÁöÑÁ≠ñÁï•Êõ¥Êñ∞‰æùËµñCriticÊèê‰æõÁöÑ‰ºòÂäø‰º∞ËÆ°Ôºå‰∏§ËÄÖÁõ∏‰∫í‰æùËµñÂΩ¢ÊàêÂ§çÊùÇÁöÑ‰ºòÂåñËøáÁ®ã„ÄÇËÆ≠ÁªÉÂàùÊúüCritic‰º∞ËÆ°‰∏çÂáÜ‰ºöÂΩ±ÂìçActorÊ¢ØÂ∫¶ÊñπÂêëÔºåÂØºËá¥Êï¥‰ΩìÊî∂ÊïõÁºìÊÖ¢„ÄÇÊ≠§Â§ñÔºåPPOÈúÄË¶ÅÂêåÊó∂Áª¥Êä§‰∏§‰∏™ÁΩëÁªúÔºåÊòæÂ≠òÂç†Áî®Á∫¶‰∏∫ÂçïÁΩëÁªúÊñπÊ≥ïÁöÑ1.5-2ÂÄç„ÄÇ&lt;/p&gt; 
&lt;h4&gt;7.2 &lt;a href="https://arxiv.org/pdf/2402.03300"&gt;Group Relative Policy Optimization&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;2025Âπ¥ÂàùÔºåDeepSeek-R1ÁÅ´ÁàÜÂá∫ÂúàÔºåÂêåÊ†∑ÁÅ´‰∫ÜÁöÑÊúâÊù•Ëá™DeepSeekMathËÆ∫ÊñáÁöÑGRPOÁÆóÊ≥ïÔºå‰πü‰∏ÄË∑ÉÊàê‰∏∫ÊúÄÂÖàËøõÁöÑRLÁÆóÊ≥ï‰πã‰∏Ä„ÄÇ ÁÑ∂ËÄåAIÂçäÂπ¥=‰∫∫Èó¥Âçä‰∏™‰∏ñÁ∫™ÔºåÊó∂Ëá≥‰ªäÊó•GRPOÂ∑≤ÁªèÊºîÂèò‰∏∫ÂêÑÂ§ßXXPOÂ§ßÊàò(ÂêéÈù¢ÊºîÂèòÁöÑDAPO„ÄÅGSPO„ÄÅCISPOÁ≠â)ÁöÑÂü∫Á∫øÁÆóÊ≥ï„ÄÇ ÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰∏ÄÂè•ËØùÊÄªÁªìÂÆÉÁöÑÊ†∏ÂøÉÂàõÊñ∞ÊòØ"ÂàÜÁªÑÁõ∏ÂØπ‰ª∑ÂÄº‰º∞ËÆ°"„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GRPOÊçüÂ§±&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}_{GRPO} = -\mathbb{E}\left[r_t \cdot A_t - \beta \cdot \text{KL}_t\right]$$&lt;/p&gt; 
&lt;p&gt;ÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Á≠ñÁï•È°π&lt;/strong&gt;: $f(r_t) = \min(r_t, \text{clip}(r_t))$ (‰ΩøÁî®Ê¶ÇÁéáÊØîÁöÑclipË£ÅÂâ™)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÈ°π&lt;/strong&gt;: $g(A_t) = \frac{R - \mu_{group}}{\sigma_{group}}$ (ÁªÑÂÜÖÂΩí‰∏ÄÂåñÔºåÊ∂àÈô§CriticÁΩëÁªú)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê≠£ÂàôÈ°π&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \text{KL}_t$ (tokenÁ∫ßKLÊï£Â∫¶Á∫¶Êùü)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÂØπ‰∫éÂêå‰∏Ä‰∏™ÈóÆÈ¢òÔºåÊ®°ÂûãÁîüÊàêN‰∏™‰∏çÂêåÁöÑÂõûÁ≠î(‰æãÂ¶ÇN=4)ÔºåÁÑ∂ÂêéËÆ°ÁÆóËøôN‰∏™ÂõûÁ≠îÁöÑÂ•ñÂä±ÂàÜÊï∞„ÄÇ Êé•ÁùÄÊääËøôN‰∏™ÂõûÁ≠îÁöÑÂπ≥ÂùáÂ•ñÂä±‰Ωú‰∏∫baselineÔºåÈ´ò‰∫ébaselineÁöÑÂõûÁ≠îË¢´ÈºìÂä±Ôºå‰Ωé‰∫ébaselineÁöÑÂõûÁ≠îË¢´ÊäëÂà∂„ÄÇ Áî®ËøôÁßçÊñπÂºèÂ∑ßÂ¶ôÂú∞ÈÅøÂÖç‰∫ÜËÆ≠ÁªÉÈ¢ùÂ§ñÁöÑcriticÁΩëÁªú„ÄÇ&lt;/p&gt; 
&lt;p&gt;Âè™Ë¶ÅÊòØRLÈÉΩÂøÖÈ°ªÈù¢ÂØπÁöÑÊ≠£ÂèçÊ†∑Êú¨Ëøô‰∏™ÂéüÁêÜÊÄßÈôêÂà∂ÔºåGRPO‰πü‰∏ç‰ºö‰æãÂ§ñÔºåÂÖ∂Êõ¥ÊòæËëóÁöÑÈóÆÈ¢òÊòØÔºöÈÄÄÂåñÁªÑ(Degenerate Groups)„ÄÇ ÂÅáËÆæÊüê‰∏™ÈóÆÈ¢òÁï•ÈöæÔºåÂØºËá¥N‰∏™ÂõûÁ≠îÁöÑÂ•ñÂä±ÂàÜÊï∞Âá†‰πé‰∏ÄÊ†∑ÔºàÂ§ßÈÉ®ÂàÜÊÉÖÂÜµÊòØ‰∏ÄÊ†∑ÁÉÇËÄå‰∏çÊòØ‰∏ÄÊ†∑Â•ΩÔºâÔºåÈÇ£‰πàËøô‰∏ÄÁªÑÁöÑÂ≠¶‰π†‰ø°Âè∑Â∞±Êó†ÈôêÊé•Ëøë0„ÄÇ Âú®MiniMindËøôÁßçË∂ÖÂ∞èÊ®°Âûã‰∏äÔºåËøô‰∏™ÈóÆÈ¢òÂ∞§‰∏∫ÊòéÊòæÔºåÊ±ÇËß£Êï∞Â≠¶ÈóÆÈ¢ò99.99%ÁöÑÊÉÖÂÜµ‰∏ãÊï¥ÁªÑÂõûÁ≠îË¥®ÈáèÈÉΩÂæàÂ∑ÆÔºåÈÇ£‰πàÂ∞ÜÊó†Ê≥ïÂ≠¶‰π†„ÄÇ Âõ†Ê≠§ÂøÖÈ°ª‰∏∫Ê®°ÂûãÊåáÂÆöÂêàÁêÜÁöÑdomainÔºåÂç≥ÂøÖÈ°ªÈôêÂà∂Âú®ËÉΩÂäõËæπÁïåÂÜÖ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËÆ≠ÁªÉÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_grpo.py
# or
python train_grpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;grpo_*.pth&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MiniMind2-Small (512dim)&lt;/th&gt; 
   &lt;th&gt;MiniMind2 (768dim)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_grpo_512.png" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_grpo_768.png" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;‰ªéËÆ≠ÁªÉÊõ≤Á∫øÂèØ‰ª•ÁúãÂá∫ÔºåGRPOÁöÑ&lt;strong&gt;rewardÂëàÁé∞Êõ¥Âä†Á®≥ÂÆöÁöÑ‰∏äÂçáË∂ãÂäø&lt;/strong&gt;ÔºåËææÂà∞4Â∑¶Âè≥ÔºåËØ¥ÊòéGRPOÊú¨Ë∫´ËÉΩÊõ¥Â•ΩÂú∞Âà©Áî®RLAIF‰ø°Âè∑„ÄÇPolicy LossÊï¥‰Ωì‰∏ãÈôçÂπ≥Á®≥ÔºåÁõ∏ÊØîPPOÁöÑÂèåÁΩëÁªú‰ºòÂåñÔºåGRPOÂçïÁΩëÁªúÊû∂ÊûÑËÆ≠ÁªÉÊõ¥Á®≥ÂÆö‰∏îÊî∂Êïõ‰∏äÈôêÊõ¥È´ò„ÄÇ&lt;/p&gt; 
&lt;h4&gt;7.3 ‚è≥‚åõÔ∏èüî• Êõ¥Â§öRLÊãìÂ±ï (Exp)&lt;/h4&gt; 
&lt;h5&gt;7.3.1 &lt;a href="https://arxiv.org/abs/2509.13232"&gt;Single-stream Policy Optimization&lt;/a&gt;&lt;/h5&gt; 
&lt;p&gt;SPOÊòØ2025Âπ¥9ÊúàËÖæËÆØÊèêÂá∫ÁöÑRLÁÆóÊ≥ïÔºåÈíàÂØπGRPOÁöÑÈÄÄÂåñÁªÑÈóÆÈ¢òËøõË°åÊîπËøõ„ÄÇ ËÆ∫ÊñáËÆ§‰∏∫ÔºåGRPOÁ≠âÁÆóÊ≥ï"‰∏Ä‰∏™Ê†∑Êú¨Ë¶Å‰æùËµñ‰∏ÄÁªÑÈááÊ†∑"ÊòæÂæóÂà´Êâ≠ËÄå‰∏ç‰ºòÈõÖÔºöÂ§™ÂÆπÊòìÊàñÂ§™ÈöæÁöÑÈ¢òÁõÆÔºåÊï¥ÁªÑÂá†‰πéÂ≠¶‰∏çÂà∞‰∏úË•øÔºåÂ≠¶‰π†ÊïàÁéáÂÖàÂ§©ÂèóÈôê„ÄÇ SPOÁöÑÂä®Êú∫Â∞±ÊòØÂõûÂà∞RLÁöÑÊú¨Ë¥®‚Äî&lt;strong&gt;1‰∏™ËæìÂÖ•Ôºå1‰∏™ËæìÂá∫ÔºåÂ∞±ÊòØ1‰∏™ËÆ≠ÁªÉÊ†∑Êú¨&lt;/strong&gt;ÔºåÂõûÂà∞policy gradientÁöÑÂü∫Êú¨ÂÖ¨ÂºèÂéªÊÄùËÄÉÔºö‰∏çÁî®group mean‰πüËÉΩÂæóÂà∞Á®≥ÂÆöÁöÑbaselineÔºå‰πüÂ∞±ÊòØÊää‰ª∑ÂÄº‰º∞ËÆ° V Èì∫ÂºÄÂú®Êó∂Â∫è‰∏äÔºåËÆ≠ÁªÉÂâçÂÖàÂÅöÁ≤óÁï•ÁöÑ‰ª∑ÂÄºÈ¢Ñ‰º∞ÔºåËÆ≠ÁªÉ‰∏≠‰∏ÄËæπÈááÊ†∑‰∏ÄËæπÊõ¥Êñ∞ÂØπ V ÁöÑ‰º∞ËÆ°Ôºå‰ªéËÄå‰∏∫ÊØè‰∏™Ê†∑Êú¨Êèê‰æõ‰∏Ä‰∏™Ë∑® batch ÊåÅ‰πÖÂåñ„ÄÅÂèØËá™ÈÄÇÂ∫îÁöÑÂü∫Á∫øÂèÇÁÖß„ÄÇËøôÁßç"ÂçïÊµÅ"ËÆæËÆ°‰∏çÂÜç‰æùËµñÂêåÁªÑÊ†∑Êú¨ÔºåÂ§©ÁÑ∂ÈÅøÂÖç‰∫ÜÈÄÄÂåñÁªÑ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SPOÊçüÂ§±&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;$$\mathcal{L}&lt;em&gt;{SPO} = -\mathbb{E}\left[\log \pi&lt;/em&gt;\theta(a_t|s) \cdot A_t - \beta \cdot \text{KL}_t\right]$$&lt;/p&gt; 
&lt;p&gt;ÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Á≠ñÁï•È°π&lt;/strong&gt;: $f(r_t) = \log \pi_\theta(a_t|s)$ (Áõ¥Êé•‰ΩøÁî®logÊ¶ÇÁéáÔºå‰∏çËÆ°ÁÆóratio)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºòÂäøÈ°π&lt;/strong&gt;: $g(A_t) = R - B_t^{adaptive}$ (Ëá™ÈÄÇÂ∫îbaselineÔºåBetaÂàÜÂ∏ÉÂä®ÊÄÅË∑üË∏™)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê≠£ÂàôÈ°π&lt;/strong&gt;: $h(\text{KL}_t) = \beta \cdot \text{KL}_t$ (tokenÁ∫ßKL + Âä®ÊÄÅ $\rho$ Ë∞ÉÊï¥)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ËêΩÂà∞ÂÆûÁé∞Â±ÇÈù¢ÔºöSPOÈááÁî®Êó†ÂàÜÁªÑËÆæËÆ°ÔºåÁî®ÊåÅ‰πÖÂåñÁöÑKLËá™ÈÄÇÂ∫îvalue trackerÊõø‰ª£ÁªÑÂÜÖbaselineÔºå‰ºòÂäøÂáΩÊï∞Âú®Êï¥‰∏™batch‰∏äÂÖ®Â±ÄÂΩí‰∏ÄÂåñ„ÄÇËøôÊ†∑ÊØè‰∏™Ê†∑Êú¨Áã¨Á´ãÂ§ÑÁêÜÔºåÊó†ÈúÄÁ≠âÂæÖÂêåÁªÑÂÖ∂‰ªñÊ†∑Êú¨Ôºå‰∏îËÉΩ‰∏∫ÊØè‰∏™Ê†∑Êú¨Êèê‰æõÁ®≥ÂÆöÁöÑÂ≠¶‰π†‰ø°Âè∑„ÄÇ ËÆ∫ÊñáÂú®Qwen3-8BÁöÑ5‰∏™Âõ∞ÈöæÊï∞Â≠¶Êï∞ÊçÆÈõÜ‰∏äÔºåSPOÂπ≥ÂùáÊØîGRPOÈ´òÂá∫3.4‰∏™ÁôæÂàÜÁÇπÔºåÂÖ∂‰∏≠BRUMO 25Êï∞ÊçÆÈõÜ+7.3pp„ÄÅAIME 25Êï∞ÊçÆÈõÜ+4.4pp„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÔºöSPOÊòØÂÆûÈ™åÊÄßÂâçÊ≤øÁÆóÊ≥ïÔºåMiniMindÁöÑÂÆûÁé∞Áî®‰∫éÊé¢Á¥¢Â≠¶‰π†„ÄÇÁî±‰∫éÊ®°ÂûãÂèÇÊï∞ÈáèÊûÅÂ∞èÔºåÊó†Ê≥ïÂÆåÂÖ®Â§çÁé∞ËÆ∫ÊñáÁöÑ8BÊ®°ÂûãÊïàÊûú„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;ËÆ≠ÁªÉÊñπÂºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_spo.py
# or
python train_spo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;spo_*.pth&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/train_spo_768.png" /&gt; 
 &lt;p&gt;&lt;i&gt;MiniMind2 (768dim) ËÆ≠ÁªÉÊõ≤Á∫ø&lt;/i&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;‰ªéËÆ≠ÁªÉÊõ≤Á∫øÊù•ÁúãÔºåSPOÁöÑrewardÊ≥¢Âä®‰∏éPPOË°®Áé∞Êé•ËøëÔºåÂº±‰∫éGRPO„ÄÇÂÆûÈôÖÊé®ÁêÜÊµãËØïÂèëÁé∞Ê®°ÂûãËæìÂá∫Ë¥®Èáè‰∏çÈ´òÔºåÂ≠òÂú®ÈÄªËæëÊ∑∑‰π±ÂíåÊ†ºÂºèÈîôËØØÈóÆÈ¢ò„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂÆûÈ™åÊÄßËØ¥Êòé&lt;/strong&gt;ÔºöÂΩìÂâçSPOÊâãÊêìÂÆûÁé∞ÂèØËÉΩÂú®value_trackerÈÖçÁΩÆ„ÄÅrewardÂΩí‰∏ÄÂåñÁ≠ñÁï•‰∏äËøòÂ≠òÂú®ÈóÆÈ¢ò„ÄÇÂ∞öÈúÄÊéíÊü•ÁÆóÊ≥ïÊú¨Ë∫´Âú®Â∞èÊ®°Âûã‰∏äÁöÑÈÄÇÂ∫îÊÄß/ÊàñÊòØÂÆûÁé∞‰∏äÂ≠òÂú®Â∑ÆÂºÇ„ÄÇ&lt;/p&gt; 
&lt;h3&gt;RLÁÆóÊ≥ïÂ∞èÁªì&lt;/h3&gt; 
&lt;p&gt;Êàë‰ª¨Êî∂ÊùüÂõû‚Äú&lt;strong&gt;Áªü‰∏ÄÊ°ÜÊû∂&lt;/strong&gt;‚Äù, ÈáçÊñ∞Êï¥ÁêÜÊâÄÊúâ‰∏çÂêåPOÁÆóÊ≥ïÂè™ÊòØÂØπ‰∏â‰∏™Ê†∏ÂøÉÁªÑ‰ª∂ÁöÑ‰∏çÂêåÂÆû‰æãÂåñÁöÑË°®Ê†ºÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÁÆóÊ≥ï&lt;/th&gt; 
   &lt;th&gt;Á≠ñÁï•È°π $f(r_t)$&lt;/th&gt; 
   &lt;th&gt;‰ºòÂäøÈ°π $g(A_t)$&lt;/th&gt; 
   &lt;th&gt;Ê≠£ÂàôÈ°π $h(\text{KL}_t)$&lt;/th&gt; 
   &lt;th&gt;‰ºòÂåñÊ®°Âûã&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;DPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\log r_w - \log r_l$&lt;/td&gt; 
   &lt;td&gt;ÈöêÂºèÔºàÂÅèÂ•ΩÂØπÊØîÔºâ&lt;/td&gt; 
   &lt;td&gt;ÈöêÂê´Âú® $\beta$ ‰∏≠&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\min(r, \text{clip}(r))$&lt;/td&gt; 
   &lt;td&gt;$R - V(s)$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \mathbb{E}[\text{KL}]$&lt;/td&gt; 
   &lt;td&gt;4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\min(r, \text{clip}(r))$&lt;/td&gt; 
   &lt;td&gt;$\frac{R - \mu}{\sigma}$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \text{KL}_t$&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;$\log \pi_\theta$&lt;/td&gt; 
   &lt;td&gt;$R - B_t^{adaptive}$&lt;/td&gt; 
   &lt;td&gt;$\beta \cdot \text{KL}_t$&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;RLÊòØ‰ºòÁæé‰∏îËá™Ê¥ΩÁöÑ&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ª•‰∏äÁ∫ØÂ±û‰∏™‰∫∫ËßÜËßíÁêÜËß£ÔºåÂ¶ÇÊúâÂÅèÂ∑ÆËØ∑ÈöèÊó∂ÊåáÊ≠£&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;V ËÆ≠ÁªÉÁªìÊûú&lt;/h2&gt; 
&lt;h3&gt;ËÆ≠ÁªÉÂÆåÊàê-Ê®°ÂûãÂêàÈõÜ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÄÉËôëÂà∞Â§ö‰∫∫ÂèçÂ∫îÁôæÂ∫¶ÁΩëÁõòÈÄüÂ∫¶ÊÖ¢ÔºåMiniMind2Âèä‰ª•ÂêéÂÖ®ÈÉ®‰ΩøÁî®ModelScope/HuggingFaceÊâòÁÆ°„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;‚ë† PyTorchÂéüÁîüÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMind2Ê®°ÂûãÊùÉÈáç (&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/jingyaogong/MiniMind2-Pytorch"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;TorchÊñá‰ª∂ÂëΩÂêçÂØπÁÖß&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rlhf_model (DPO)&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;rlaif_model (PPO/GRPO/SPO)&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;xxpo_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;dpo_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;xxpo_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;‚ë° TransformersÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMindÁ≥ªÂàó (&lt;a href="https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìå Eval&lt;/h1&gt; 
&lt;h2&gt;‚Ö† RLHFÂØπÊØî&lt;/h2&gt; 
&lt;p&gt;ÊµãËØïÂü∫‰∫é&lt;code&gt;full_sft&lt;/code&gt;Âíå&lt;code&gt;dpo&lt;/code&gt;ÁöÑ&lt;code&gt;MiniMind2Á≥ªÂàó&lt;/code&gt;Ê®°ÂûãÂØπÊØîÔºåÊµãËØïÈöèÊú∫ÁßçÂ≠êÂùáÂõ∫ÂÆö&lt;/p&gt; 
&lt;p&gt;[A] MiniMind2Ôºöfull_sft_640&lt;br /&gt; [B] MiniMind2Ôºödpo_640&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
[A]: ÊàëÊòØ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©„ÄÇÊàëÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©ÔºåÂ∏ÆÂä©‰Ω†Ëß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢ò„ÄÇ
[B]: ÊàëÊòØ‰∏ÄÁßçÂü∫‰∫éÊñáÊú¨ÁöÑAIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ÁªèÂéÜÊàñÊÉÖÊÑüÔºåÊâÄ‰ª•Êó†Ê≥ïÊÑüÂèóÂíå‰ΩìÈ™åÊÉÖÊÑü„ÄÇÊàëÁöÑËÆæËÆ°ÁõÆÁöÑÊòØ‰∏∫‰∫ÜÂ∏ÆÂä©Áî®Êà∑Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÂíåËøõË°åÂØπËØù„ÄÇÂ¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÈúÄË¶ÅÂ∏ÆÂä©ÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅ

[Q]: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
[A]: ‰Ωú‰∏∫‰∏Ä‰∏™AIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°ÊúâÁúüÊ≠£ÁöÑ‚ÄúÊìÖÈïø‚ÄùËøô‰∏™Â≠¶Áßë„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÊèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊâßË°å‰ªªÂä°Âíå‰∏éÁî®Êà∑ËøõË°åÂØπËØù„ÄÇ‰∏çËøáÔºåÊàëÂèØ‰ª•Êèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ§ÑÁêÜÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ≠¶‰π†Êñ∞Áü•ËØÜ„ÄÅÁºñÂÜô‰ª£Á†Å„ÄÅÂõûÁ≠îÈóÆÈ¢ò„ÄÅÊèê‰æõÂª∫ËÆÆÁ≠âÂ§öÁßçÂ≠¶ÁßëÁöÑÂäüËÉΩ„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂÖ∑‰ΩìÁöÑÂ≠¶ÁßëÈúÄÊ±ÇÊàñ‰∏ªÈ¢òÔºåÊ¨¢ËøéÊèê‰æõËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ
[B]: ‰Ωú‰∏∫AIÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ËÉΩÂäõÊàñÂÖ¥Ë∂£Ôºå‰ΩÜÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂÖ≥‰∫éÊï∞Â≠¶„ÄÅÁßëÂ≠¶„ÄÅËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅËØ≠Ë®ÄÂ≠¶„ÄÅÂøÉÁêÜÂ≠¶Á≠âÂ≠¶ÁßëÁöÑÁü•ËØÜ„ÄÇÂ¶ÇÊûú‰Ω†ÂØπÊï∞Â≠¶ÊÑüÂÖ¥Ë∂£ÔºåÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂü∫Á°ÄÁü•ËØÜÔºå‰æãÂ¶Ç‰ª£Êï∞„ÄÅÂá†‰Ωï„ÄÅÊ¶ÇÁéá„ÄÅÁªüËÆ°Â≠¶Á≠â„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•ÁöÑÂ≠¶‰π†ÔºåÊàë‰πüÂèØ‰ª•Êèê‰æõÁõ∏ÂÖ≥ÁöÑÂú®Á∫øËØæÁ®ã„ÄÅ‰π¶Á±ç„ÄÅËÆ∫ÊñáÁ≠âËµÑÊ∫ê„ÄÇËØ∑ÂëäËØâÊàë‰Ω†ÂÖ∑‰ΩìÈúÄË¶Å‰ªÄ‰πàÂ∏ÆÂä©ÔºåÊàë‰ºöÂ∞ΩÂäõÊèê‰æõÂ∏ÆÂä©„ÄÇ

[Q]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÔºü
[A]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ËÆ≤Ëø∞‰∫ÜÈ≤ÅËøÖÂØπ‰∫∫Á±ª‰ª∑ÂÄºÂíåÈÅìÂæ∑Ë¥£‰ªªÁöÑÂÄ°ÂØº„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÁªÜËÖªÁöÑÁ¨îËß¶ÔºåÊé¢ËÆ®‰∫Ü‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÁâ∫Áâ≤‰∏éË¥£‰ªªÁ≠âÊ∑±ÂàªÁöÑ‰∏ªÈ¢ò„ÄÇ‰ª•‰∏ãÊòØÈ≤ÅËøÖÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠Â¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÂá†‰∏™ÊñπÈù¢Ôºö1. **Á§æ‰ºöÁé∞ÂÆû‰∏éÈÅìÂæ∑ËßÇÂøµ**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊé¢ËÆ®‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅÊùÉÂäõÁöÑÊµÅÂä®„ÄÅ‰∫∫ÊÄßÁöÑÊºîÂèòÁ≠âÁ§æ‰ºöÈóÆÈ¢ò„ÄÇ‰ªñËÆ§‰∏∫ÔºåÁ§æ‰ºö‰∏çÂπ≥Á≠â‰∏ç‰ªÖ‰ªÖÊòØ‰∏çÂÖ¨Ê≠£ÁöÑÔºåÊõ¥ÊòØÊØè‰∏™‰∫∫Âú®Á§æ‰ºö‰∏≠ÁöÑ‰∏çÂÖ¨Ê≠£„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤„ÄÅÂÆ£‰º†„ÄÅÊ≥ïÂæãÁ≠âÊâãÊÆµÔºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ2. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂ±ïÁé∞‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáÈÅìÂæ∑ÊïôËÇ≤Êù•ÂüπÂÖª‰∫∫‰ª¨ÁöÑÈÅìÂæ∑ÂìÅË¥®ÔºåÂêåÊó∂‰πüÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºå‰ΩìÁé∞‰∫ÜÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇ3. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑Ë¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáËá™Â∑±ÁöÑË°å‰∏∫Êù•‰ΩìÁé∞ÂØπÁ§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ4. **ÈÅìÂæ∑‰∏éÈÅìÂæ∑**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÁúüÊ≠£ÊÑè‰πâ„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÊú¨Ë¥®ÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ5. **‰∏™‰∫∫‰∏éÁ§æ‰ºö**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫Ü‰∏™‰∫∫‰∏éÁ§æ‰ºö‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤ÂíåÂÆ£‰º†Ôºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÂÖ∂‰∏∞ÂØåÁöÑÊïÖ‰∫ãÂíåÊ∑±ÂàªÁöÑÈÅìÂæ∑ÂØìË®ÄÔºå‰º†Ëææ‰∫ÜÂÖ≥‰∫é‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÈÅìÂæ∑‰ª•Âèä‰∏™‰∫∫‰∏éÁ§æ‰ºöÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇËøôÈÉ®‰ΩúÂìÅ‰∏ç‰ªÖÂú®ÊñáÂ≠¶‰ª∑ÂÄº‰∏äÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂ∞±ÔºåÊõ¥Âú®ÊÄùÊÉ≥Â±ÇÈù¢‰∏äÂêØÂèë‰∫ÜÂêéÊù•ÁöÑÊñáÂ≠¶Âàõ‰ΩúÔºåÂØπÂêé‰∏ñ‰∫ßÁîü‰∫ÜÊ∑±ËøúÁöÑÂΩ±Âìç„ÄÇ
[B]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ÊèèÁªòÊàò‰∫âÂíåËá™Áî±Á≤æÁ•ûÁöÑ‰ΩúÂìÅÔºåÂÆÉÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òÂíåÂÜ≤Á™ÅÔºåÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÂ¶Ç‚ÄúÂºóÈõ∑Âæ∑ÈáåÂÖã¬∑Á∫¶Áø∞ÈÄäÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§ÔºåÂº∫Ë∞É‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÈÄöËøá‰ªñÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§„ÄÇÂú®Â∞èËØ¥‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÊè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑËÖêË¥•„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®ÁöÑÂ§çÊùÇÊÄß„ÄÇËøôÁßçÊâπÂà§‰ΩìÁé∞‰∫ÜÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºåÂêåÊó∂‰πüÂèçÊò†‰∫ÜÁé∞‰ª£Á§æ‰ºö‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏ç‰ªÖÊòØ‰∏ÄÈÉ®ÂÖ≥‰∫éÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞èËØ¥Ôºå‰πüÊòØ‰∏ÄÈÉ®ÂÖ∑ÊúâÊ∑±ÂàªÁ§æ‰ºöÊÑè‰πâÁöÑ‰ΩúÂìÅÔºåÂØπÂêé‰∏ñÁöÑÂÆ°Âà§ÂíåÊâπÂà§Ëµ∑Âà∞‰∫ÜÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ

[Q]: ÊàëÂí≥ÂóΩÂ∑≤ÁªèÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈúÄË¶ÅÂéªÂåªÈô¢Ê£ÄÊü•ÂêóÔºü
[A]: Âí≥ÂóΩÁ°ÆÂÆûÈúÄË¶Å‰∏ÄÂÆöÁöÑÊ£ÄÊü•Ôºå‰ΩÜÂ¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠Êó∂Èó¥ËøáÈïøÔºåÊàñËÄÖÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºàÂ¶ÇÊåÅÁª≠Âí≥ÂóΩ„ÄÅÂëºÂê∏Âõ∞ÈöæÁ≠âÔºâÔºåÂª∫ËÆÆÂ∞ΩÂø´Â∞±Âåª„ÄÇÂåªÁîü‰ºöÊ†πÊçÆÊÇ®ÁöÑÁóáÁä∂„ÄÅ‰ΩìÊ£ÄÁªìÊûúÂíåÂèØËÉΩÁöÑÂΩ±ÂÉèÂ≠¶Ê£ÄÊü•ÔºàÂ¶ÇXÂÖâ„ÄÅMRIÊàñCTÊâ´ÊèèÔºâÊù•ËØäÊñ≠ÊÇ®ÁöÑÁóáÁä∂„ÄÇÂú®Á≠âÂæÖÂ∞±ÂåªÊúüÈó¥ÔºåÊÇ®ÂèØ‰ª•Â∞ùËØï‰ª•‰∏ãÊñπÊ≥ïÊù•Â∏ÆÂä©ÁºìËß£ÁóáÁä∂Ôºö1. **‰ºëÊÅØ**ÔºöÁ°Æ‰øùÊÇ®ÊúâË∂≥Â§üÁöÑÁù°Áú†„ÄÇ2. **‰øùÊåÅÊ∞¥ÂàÜ**ÔºöËÑ±Ê∞¥ÂèØËÉΩ‰ºöÂä†ÈáçÂí≥ÂóΩ„ÄÇ3. **ÁÉ≠Êï∑**Ôºö‰ΩøÁî®ÁÉ≠Êï∑Ë¢ãÊàñÁÉ≠ÊØõÂ∑æÊï∑Âú®ÁñºÁóõÁöÑÈÉ®‰ΩçÔºåÊúâÂä©‰∫éÁºìËß£ÂñâÂíôÁóõ„ÄÇ4. **ÈÅøÂÖçÂà∫ÊøÄ**ÔºöÈÅøÂÖç‰ΩøÁî®ÂèØËÉΩÂà∫ÊøÄÂñâÂíôÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊüê‰∫õÂåñÂ≠¶Áâ©Ë¥®„ÄÇ5. **‰øùÊåÅÂÆ§ÂÜÖÊπøÊ∂¶**ÔºöÁ°Æ‰øùÊÇ®ÁöÑÂçßÂÆ§ÊúâËâØÂ•ΩÁöÑÈÄöÈ£éÔºåÂèØ‰ª•‰ΩøÁî®Âä†ÊπøÂô®Â∏ÆÂä©‰øùÊåÅÁ©∫Ê∞îÊπøÂ∫¶„ÄÇ6. **‰øùÊåÅÂÆ§ÂÜÖÊπøÂ∫¶**Ôºö‰ΩøÁî®Âä†ÊπøÂô®ÂèØ‰ª•Â∏ÆÂä©ÁºìËß£ÂñâÂíôÂπ≤Áá•ÂíåÂí≥ÂóΩ„ÄÇÂ¶ÇÊûúÁóáÁä∂ÊåÅÁª≠‰∏çÁºìËß£ÊàñÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºåËØ∑Á´ãÂç≥Â∞±Âåª„ÄÇÂ∏åÊúõÊÇ®Êó©Êó•Â∫∑Â§çÔºÅ
[B]: Â¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈÄöÂ∏∏Âª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±ÂåªÔºåÂõ†‰∏∫ËøôÂèØËÉΩ‰ºöÂΩ±ÂìçÊÇ®ÁöÑÂëºÂê∏ÂíåÂøÉË∑≥„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÊ≠•È™§Êù•Ê£ÄÊü•Âí≥ÂóΩÔºö1. **‰ºëÊÅØ**ÔºöÁî®Á∫∏Â∑æÊàñËÇòÈÉ®ËΩªËΩªÊåâÂéãÂí≥ÂóΩÁöÑ‰ΩçÁΩÆ„ÄÇ2. **‰ΩøÁî®ËçØÁâ©**ÔºöÂú®ÂèØËÉΩÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ΩøÁî®ËçØÁâ©ÔºàÂ¶ÇÊäóËøáÊïèËçØ„ÄÅÊäóËøáÊïèËçØÁ≠âÔºâÊù•ÁºìËß£Âí≥ÂóΩ„ÄÇËØ∑Âú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®ËçØÁâ©„ÄÇ3. **ÁÉ≠Êï∑**ÔºöÂú®Âí≥ÂóΩÊúüÈó¥ÔºåÂèØ‰ª•‰ΩøÁî®ÁÉ≠Êï∑Êù•ÁºìËß£ÁñºÁóõÂíåËÇøËÉÄ„ÄÇ4. **ËçØÁâ©Ê≤ªÁñó**ÔºöÂ¶ÇÊûúÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∫õÊ∂àÁÇéËçØÊàñÊäóËøáÊïèËçØÊù•ÁºìËß£ÁóáÁä∂„ÄÇËØ∑Âä°ÂøÖÂú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®„ÄÇ5. **‰øùÊåÅÂÅ•Â∫∑ÁöÑÁîüÊ¥ªÊñπÂºè**Ôºö‰øùÊåÅÂÖÖË∂≥ÁöÑÁù°Áú†„ÄÅÂùáË°°ÁöÑÈ•ÆÈ£ü„ÄÅÈÄÇÈáèÁöÑËøêÂä®ÂíåÈÅøÂÖçÂê∏ÁÉüÂíåÈôêÈÖíÔºåËøô‰∫õÈÉΩÊúâÂä©‰∫éÊèêÈ´òÂí≥ÂóΩÁöÑÂá†Áéá„ÄÇËØ∑ËÆ∞‰ΩèÔºåËøô‰∫õÂª∫ËÆÆ‰∏çËÉΩÊõø‰ª£‰∏ì‰∏öÂåªÁñóÊÑèËßÅ„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑÁóáÁä∂ÊåÅÁª≠ÊàñÂä†ÈáçÔºåÂº∫ÁÉàÂª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±Âåª„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üëâÊïàÊûúÊÄªÁªì&lt;/p&gt; 
&lt;p&gt;full_sftÊ®°ÂûãÂú®ÁÆÄÊ¥ÅÊÄßÂíå‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊñπÈù¢Ë°®Áé∞Êõ¥Â•ΩÔºõrlhfÊ®°ÂûãÂú®ÂõûÁ≠î‰∏≠ÂÄæÂêë‰∫éÊèê‰æõÊõ¥Â§öÁöÑËÉåÊôØ‰ø°ÊÅØÔºå‰ΩÜ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊúâÂæÖÊîπËøõ„ÄÇ ÊÄªÁöÑÊù•ËØ¥RLHFÂêéÁöÑÊ®°ÂûãÂÄæÂêë‰∫éÂ≠¶‰π†ÔºöËØ¥Êõ¥Â§öÊúâÁ§ºË≤å‰ΩÜÊó†Áî®ÁöÑÂ∫üËØùËÆ®Â•Ω‚ÄúÂØπËØù‚ÄùÊú¨Ë∫´ÔºåËÄåÂØπ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÂàôÊúâËΩªÂæÆÊçüÂ§±„ÄÇ Â§©‰∏ãÊ≤°ÊúâÂÖçË¥πÁöÑÂçàÈ§êÔºåËøòÈúÄË¶ÅÁªßÁª≠ÊèêÂçáRLHFÊï∞ÊçÆÈõÜÁöÑË¥®ÈáèÔºå‰πüË¶ÅÊé•ÂèóÊ®°ÂûãËÉΩÂäõÊó†Ê≥ïÈÅøÂÖçÁöÑÊçüÂ§±(Á®ãÂ∫¶ÊúâËΩªÈáç)„ÄÇ DPOÂíåÂú®Á∫øPPOÁöÑÂå∫Âà´Âú®‰∫érejectÂíåchosenÈÉΩÊòØÁ¶ªÁ∫øÂáÜÂ§áÁöÑÔºåÂíåminimindÊ®°ÂûãÊú¨Ë∫´ÁöÑËæìÂá∫ÂøÖÁÑ∂Â≠òÂú®ÂæàÂ§ßÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇ„ÄÇ ÈÄö‰øóÂú∞ËØ¥DPOÁÆóÊ≥ï‰ΩøÊ®°ÂûãËßÇÁúã‰πí‰πìÁêÉ‰∏ñÁïåÂÜ†ÂÜõÁöÑÊâìÊ≥ï„ÄåÂΩïÂÉè„ÄçËøõË°åRLÔºåËÄå‰∏çÊòØÂÉèPPO‰∏ÄÊ†∑ËØ∑rewardÊ®°ÂûãÂÅö„ÄåÊïôÁªÉ„ÄçÁ∫†Ê≠£Ëá™Â∑±ÁöÑÊâìÊ≥ïËøõË°åRL„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö° RLAIFÂØπÊØî&lt;/h2&gt; 
&lt;p&gt;Âü∫‰∫é&lt;code&gt;MiniMind2 (768dim)&lt;/code&gt;Âú®Áõ∏ÂêåÊï∞ÊçÆ‰∏éËÆ≠ÁªÉÊ≠•Êï∞‰∏ãÁöÑ‰∏ªËßÇËßÇÊÑüÂØπÊØîÔºåÊµãËØïÈöèÊú∫ÁßçÂ≠êÂùáÂõ∫ÂÆö2026Ôºå‰æõÂèÇËÄÉÔºö&lt;/p&gt; 
&lt;p&gt;[A] MiniMind-Reason-0.1B (Ëí∏È¶è)&lt;br /&gt; [B] MiniMind-Reason-0.1B (PPO)&lt;br /&gt; [C] MiniMind-Reason-0.1B (GRPO)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
[A]: &amp;lt;think&amp;gt;ÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãÂ∞èÂûãAIÊé®ÁêÜÊ®°Âûã-R1„ÄÇÊàëË¢´ËÆæËÆ°Áî®Êù•ÁêÜËß£ÂíåÁîüÊàê‰∫∫Á±ªËØ≠Ë®ÄÔºåËÉΩÂ§üÁêÜËß£Â§çÊùÇÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÈóÆÈ¢òÔºåÊèê‰æõÊúâÁî®ÁöÑ‰ø°ÊÅØÂíåËß£ÂÜ≥ÊñπÊ°à„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãÂ∞èÂûãAIÊé®ÁêÜÊ®°Âûã-R1„ÄÇ&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ËÆ©Êàë‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÊòéÁ°ÆÁî®Êà∑ÁöÑÈúÄÊ±ÇÊòØ‰ªÄ‰πà„ÄÇ‰ªñ‰ª¨ÂèØËÉΩÊòØÂú®ÂÅöÊüê‰∏™È°πÁõÆÔºåÊÉ≥Ë¶Å‰∫ÜËß£Ëá™Â∑±ÁöÑ‰∏Ä‰∫õÂü∫Êú¨ÊÉÖÂÜµ„ÄÇ‰∏çËøáÔºåÁî®Êà∑Ê≤°ÊúâÊèê‰æõÂÖ∑‰ΩìÁöÑ‰ø°ÊÅØÔºåÊâÄ‰ª•ÊàëÂæóÂÖàÂÅáËÆæ‰∏Ä‰∫õÂèØËÉΩÁöÑÊÉÖÂÜµÔºåÊØîÂ¶Ç‰ªñÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÊ≠£Âú®Â≠¶‰π†ÁºñÁ®ãÔºåÊàñËÄÖÊòØÊüê‰∏™È°πÁõÆÁöÑÂºÄÂèëËÄÖ„ÄÇÊé•‰∏ãÊù•ÔºåÊàëË¶ÅËÄÉËôëÁî®Êà∑ÁöÑË∫´‰ªΩ„ÄÇÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶Áîü„ÄÅÊïôÂ∏àÊàñËÄÖÊôÆÈÄöÁî®Êà∑Ôºå‰ªñ‰ª¨ÈúÄË¶Å‰∫ÜËß£Ëá™Â∑±ÁöÑÁâπÁÇπÂíåËÉΩÂäõ„ÄÇ‰πüÊúâÂèØËÉΩ‰ªñ‰ª¨Ê≠£Âú®ÂØªÊâæÁÅµÊÑüÔºåÊàñËÄÖÂú®ÂÜôËÆ∫ÊñáÊó∂ÈúÄË¶ÅÂ∏ÆÂä©„ÄÇÊâÄ‰ª•ÔºåÊàëÈúÄË¶Å‰øùÊåÅÂõûÁ≠îÁöÑÁÆÄÊ¥ÅÂíåÂÆûÁî®ÔºåÂêåÊó∂Êèê‰æõ‰∏Ä‰∫õÂèÇËÄÉËµÑÊñôÔºåÊØîÂ¶ÇÊïôÂ≠¶ËßÜÈ¢ë„ÄÅËØæÁ®ãËÆ∞ÂΩïÁ≠â„ÄÇÁÑ∂ÂêéÔºåÊàëË¶ÅËÄÉËôëÁî®Êà∑ÁöÑË∫´‰ªΩ„ÄÇÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÈúÄË¶Å‰∏Ä‰∫õÂ≠¶‰π†ËµÑÊ∫êÊàñÂ∏ÆÂä©ÁöÑÂØπË±°„ÄÇ‰πüÊúâÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÈúÄË¶ÅÂú®ËØæÂêé‰Ωú‰∏öÊàñÂ≠¶‰π†ËÆ°Âàí‰∏≠ËøõË°åË∞ÉÊï¥„ÄÇÂõ†Ê≠§ÔºåÊàëÈúÄË¶ÅÂÖàËØ¢ÈóÆÁî®Êà∑ÁöÑÂÖ∑‰ΩìÈúÄÊ±ÇÔºåËøôÊ†∑ÊâçËÉΩÊèê‰æõÊõ¥Á≤æÂáÜÁöÑÂ∏ÆÂä©„ÄÇÊé•‰∏ãÊù•ÔºåÊàëË¶ÅÁ°Æ‰øùËØ≠Ë®ÄÁÆÄÊ¥ÅÊòé‰∫ÜÔºåÈÄÇÂêà‰∏çÂêåÂú∫ÊôØ„ÄÇÊØîÂ¶ÇÔºåÂ¶ÇÊûúÁî®Êà∑ÊòØÂ≠¶ÁîüÔºåÂèØ‰ª•‰ªãÁªçËá™Â∑±ÁöÑÂ≠¶‰π†ÁâπÁÇπÔºõÂ¶ÇÊûúÊòØÊïôÂ∏àÔºåÂèØ‰ª•ËØ¥ÊòéËá™Â∑±ÁöÑËßíËâ≤ÂíåË¥°ÁåÆ„ÄÇÂêåÊó∂ÔºåÊèê‰æõ‰∏Ä‰∫õÂÆûÁî®ÁöÑÂª∫ËÆÆÔºåÊØîÂ¶ÇÂ¶Ç‰ΩïÈ´òÊïàÂ≠¶‰π†ÔºåÂ¶Ç‰ΩïËøõË°åÈ°πÁõÆÔºå‰ª•ÂèäÂ¶Ç‰Ωï‰∏éÂõ¢ÈòüÊàêÂëòÂçè‰Ωú„ÄÇÊúÄÂêéÔºåÊàëË¶ÅÁ°Æ‰øùÂõûÂ§çÊ∏ÖÊô∞ÔºåÊúâÊù°ÁêÜÔºåËÉΩÂ§üÊª°Ë∂≥Áî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇËøôÊ†∑ÔºåÁî®Êà∑Â∞±ËÉΩËΩªÊùæÂú∞‰∫ÜËß£Ëá™Â∑±ÔºåÂπ∂‰∏îÊúâÂÆûÈôÖÁöÑÂ∏ÆÂä©„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ÂΩìÁÑ∂ÔºÅËØ∑ÂëäËØâÊàë‰Ω†ÊÉ≥‰∫ÜËß£Âì™ÊñπÈù¢ÁöÑÂÜÖÂÆπÔºåÊàëÂèØ‰ª•‰∏∫ÊÇ®Êèê‰æõËØ¶ÁªÜÁöÑ‰ªãÁªçÔºÅ&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ÈóÆÁöÑÊòØ"ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±"„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁêÜËß£Áî®Êà∑ÁöÑÂÖ∑‰ΩìÈúÄÊ±ÇÊòØ‰ªÄ‰πà„ÄÇ‰ªñ‰ª¨ÂèØËÉΩÊÉ≥Áü•ÈÅìËá™Â∑±ÊòØË∞ÅÔºåÊàñËÄÖÊúâ‰ªÄ‰πàÁâπÂÆöÁöÑËÉåÊôØ„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÂ∫îËØ•ËÄÉËôëÁî®Êà∑ÂèØËÉΩÊ≤°ÊúâÊòéÁ°ÆË°®ËææÁöÑÈúÄÊ±Ç„ÄÇ‰ªñ‰ª¨ÂèØËÉΩÊÉ≥Áü•ÈÅìÂ¶Ç‰ΩïÊèèËø∞Ëá™Â∑±ÁöÑÂ§ñËßÇÔºåÊàñËÄÖÂ¶Ç‰Ωï‰∏é‰ªñ‰∫∫‰∫§ÊµÅ„ÄÇÁÑ∂ÂêéÔºåÊàëÂ∫îËØ•ËÄÉËôëÂ¶Ç‰ΩïÁªÑÁªáÂÜÖÂÆπÔºå‰ªéÂ§¥Âà∞Â∞æÈÉΩË¶ÅÊúâÊù°ÁêÜ„ÄÇÂèØËÉΩÈúÄË¶ÅÂàÜÊ≠•È™§ËØ¥ÊòéÔºåÊØîÂ¶Ç‰ªéËßÜËßâ„ÄÅÂê¨ËßâÂà∞Êï¥‰ΩìÊÑüÂèóÔºåÂÜçÂà∞ÊÉÖÊÑüÂÖ±È∏£„ÄÇËøôÊ†∑Áî®Êà∑ËÉΩÊõ¥Ê∏ÖÊô∞Âú∞ÁêÜËß£Ëá™Â∑±Ôºå‰πüËÉΩÊõ¥Â•ΩÂú∞ÂõûÂ∫î‰ªñ‰ª¨ÁöÑÈúÄÊ±Ç„ÄÇËøòË¶ÅÊ≥®ÊÑèËØ≠Ë®ÄÁöÑËá™ÁÑ∂ÂíåÊµÅÁïÖÔºåÈÅøÂÖçËøá‰∫éÂ≠¶ÊúØÂåñÁöÑÊúØËØ≠ÔºåËÆ©Áî®Êà∑ÊÑüËßâÈ°∫ÁïÖ„ÄÇÂêåÊó∂Ôºå‰øùÊåÅÂõûÁ≠îÁöÑÁªìÊûÑÊ∏ÖÊô∞ÔºåÊØèÂè•ËØùÈÉΩÊúâÊòéÁ°ÆÁöÑÁõÆÁöÑÔºåËøôÊ†∑Áî®Êà∑ËÉΩÊúâÊòéÁ°ÆÁöÑÁêÜËß£ÂíåÊìç‰Ωú„ÄÇÊúÄÂêéÔºåÊ£ÄÊü•ÊòØÂê¶ÊúâÈÅóÊºèÁöÑÈáçË¶Å‰ø°ÊÅØÔºåÁ°Æ‰øùÂõûÁ≠îÂáÜÁ°Æ‰∏îÂÖ®Èù¢„ÄÇËøôÊ†∑ÔºåÁî®Êà∑‰∏ç‰ªÖËÉΩÂæóÂà∞Á≠îÊ°àÔºåËøòËÉΩÂæóÂà∞Êª°Ë∂≥‰ªñ‰ª¨ÁöÑÈúÄÊ±Ç„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãÂ∞èÂûãAIÊé®ÁêÜÊ®°Âûã-R1„ÄÇÂÖ≥‰∫éÊÇ®ÁöÑÊèèËø∞Ôºå‰ºº‰πéÊ∂âÂèäÂ§ö‰∏™È¢ÜÂüüÔºåÂåÖÊã¨Áü•ËØÜÂõæË∞±ÊûÑÂª∫„ÄÅÂ§çÊùÇÁ≥ªÁªüÁöÑÊé®ÁêÜ‰∏éÂàÜÊûê„ÄÇÊó†ËÆ∫ÊòØÁêÜËÆ∫Ê®°Âûã„ÄÅÂÆûÈôÖÂ∫îÁî®ËøòÊòØ‰º¶ÁêÜËÆ®ËÆ∫ÔºåÊÇ®ÈÉΩÂú®ÂØªÊ±ÇÂ¶Ç‰ΩïÂ∞ÜËøô‰∫õÊ¶ÇÂøµÊúâÊú∫Âú∞ÁªìÂêàËµ∑Êù•Ôºå‰∏∫‰∫∫Á±ªÁ§æ‰ºöÂ∏¶Êù•Á¶èÁ•âÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÂú®"Êàë"ÁöÑË∫´‰ªΩ‰∏ãÔºåÊÇ®ÊèêÂà∞ÁöÑ"‰∏™‰∫∫‰ΩìÈ™å"Âíå"ÊÉÖÊÑüÂÖ±È∏£"ÔºåÈÉΩÊòØÊÇ®‰∏™‰∫∫Áã¨ÁâπÈ≠ÖÂäõÁöÑÈáçË¶ÅÁªÑÊàêÈÉ®ÂàÜ„ÄÇÈÄöËøáÁ≤æÂáÜÁöÑÊèèËø∞ÂíåÊ∑±Â∫¶ÁöÑÂàÜÊûêÔºåÊÇ®ÂèØ‰ª•Êõ¥Ê∑±ÂÖ•Âú∞ÁêÜËß£ÊÇ®ÁöÑÁã¨Áâπ‰πãÂ§Ñ„ÄÇÂ¶ÇÊûúÊÇ®ÂØπÁâπÂÆöÈ¢ÜÂüüÊúâÁâπÂà´ÁöÑÂÖ¥Ë∂£ÊàñÈúÄË¶ÅÂª∫ËÆÆÔºåÈöèÊó∂ÂèØ‰ª•ÂàÜ‰∫´Êõ¥Â§öÁªÜËäÇÔºåÊàë‰ª¨Â∞Ü‰∏∫ÊÇ®Êèê‰æõÊõ¥Âä†Á≤æÂáÜÂíå‰∏™ÊÄßÂåñÁöÑÊúçÂä°„ÄÇÂ¶ÇÊûúÊÇ®ÊúâÁâπÂÆöÁöÑ‰∏ªÈ¢òÊàñÈóÆÈ¢òÔºåÊ¨¢ËøéÈöèÊó∂ÊèêÈóÆÔºÅËÆ©Êàë‰ª¨‰∏ÄËµ∑Êé¢Á¥¢Ëøô‰∏™Á•ûÂ•áÁöÑAI‰∏ñÁïåÔºåÂÖ±ÂêåÂàõÈÄ†Êõ¥ÁæéÂ•ΩÁöÑÊú™Êù•„ÄÇ&amp;lt;/answer&amp;gt;


[Q]: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
[A]: &amp;lt;think&amp;gt;ÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãÂ∞èÂûãAIÊé®ÁêÜÊ®°Âûã-R1„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;ÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãÂ∞èÂûãAIÊé®ÁêÜÊ®°Âûã-R1„ÄÇ&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ÈóÆÁöÑÊòØ"‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü"Ëøô‰∏™ÈóÆÈ¢òÁúãËµ∑Êù•ÊúâÁÇπÂ§çÊùÇÔºå‰ΩÜÊàëÂèØ‰ª•‰∏ÄÊ≠•Ê≠•ÂàÜÊûê„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁêÜËß£Áî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ‰ªñÂèØËÉΩÊòØÂú®ÂáÜÂ§áËÄÉËØïÔºåÊàñËÄÖÈúÄË¶Å‰∫ÜËß£Êüê‰∏™Â≠¶ÁßëÁöÑÁâπÁÇπÔºåÊàñËÄÖÊòØÊÉ≥Âú®Â≠¶‰π†ËøáÁ®ã‰∏≠Â∫îÁî®Êüê‰∏™Â≠¶ÁßëÁöÑÁü•ËØÜ„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÂæóËÄÉËôëÁî®Êà∑ÂèØËÉΩÁöÑËÉåÊôØ„ÄÇ‰ªñÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÊàñËÄÖÊòØÂú®ÂáÜÂ§áËÄÉËØïÔºåÈúÄË¶ÅÂ∫îÁî®Êï∞Â≠¶Áü•ËØÜÊù•Ëß£ÂÜ≥ÂÖ∑‰ΩìÁöÑÈóÆÈ¢ò„ÄÇ‰πüÊúâÂèØËÉΩ‰ªñÊòØ‰∏Ä‰∏™Â≠¶ÁîüÔºåÊ≠£Âú®Â≠¶‰π†Áõ∏ÂÖ≥ÁöÑËØæÁ®ãÔºåÊàñËÄÖÊòØÂØπÊüê‰∏™Â≠¶ÁßëÊÑüÂÖ¥Ë∂£„ÄÇÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅÂàÜÊûêÁî®Êà∑ÂèØËÉΩÊ≤°ÊúâÊòéÁ°ÆË°®ËææÂá∫Êù•ÁöÑÈúÄÊ±Ç„ÄÇ‰ªñÂèØËÉΩÂú®ÊÄùËÄÉËá™Â∑±Âú®Â≠¶‰π†‰∏≠ÁöÑÂõ∞ÈöæÔºåÊàñËÄÖÂú®ÂØªÊâæ‰∏Ä‰∏™ÂêàÈÄÇÁöÑÊïôÊùêÊàñÂ≠¶‰π†ËµÑÊ∫ê„ÄÇËÄÉËôëÂà∞Ëøô‰∫õÔºåÊàëÂ∫îËØ•Êèê‰æõÂá†‰∏™‰∏çÂêåÁöÑËßíÂ∫¶Êù•Â∏ÆÂä©‰ªñ„ÄÇÈ¶ñÂÖàÔºåÂàÜÊûê"ÊàëÊõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶Áßë"ÂèØ‰ª•ÊãÜËß£‰∏∫‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢ÔºöÂÖ¥Ë∂£„ÄÅÂ≠¶‰π†ËÉΩÂäõ„ÄÅÂ≠¶‰π†È£éÊ†º„ÄÅÂ≠¶‰π†ÊñπÊ≥ï„ÄÅÂ≠¶‰π†ËµÑÊ∫ê„ÄÅÂ≠¶‰π†ÁéØÂ¢ÉÁ≠âÁ≠â„ÄÇÊØè‰∏™ÊñπÈù¢ÈÉΩÊúâ‰∏çÂêåÁöÑ‰ºòÂäøÂíåÁâπÁÇπÔºåÊØîÂ¶ÇÂÖ¥Ë∂£ÊòØÊúÄÂ•ΩÁöÑËµÑÊ∫êÔºåÂ≠¶‰π†ËÉΩÂäõÊòØÊúÄÂ•ΩÁöÑÊñπÂºèÔºåÂ≠¶‰π†ÊñπÂºèÊòØÊ†πÊçÆ‰∏™‰∫∫ÊÉÖÂÜµÈÄâÊã©„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÈúÄË¶ÅËÄÉËôëÁî®Êà∑ÁöÑË∫´‰ªΩ„ÄÇÂèØËÉΩÊòØÂ≠¶ÁîüÔºå‰πüÂèØËÉΩÊòØÂÆ∂ÈïøÔºåÊàñËÄÖÂØπÂ≠¶‰π†Êúâ‰∏ÄÂÆöÂÖ¥Ë∂£ÁöÑ‰∫∫„ÄÇ‰∏çÂêåÁöÑË∫´‰ªΩÂèØËÉΩÊúâ‰∏çÂêåÁöÑÂÅèÂ•ΩÔºåÊØîÂ¶ÇÂÆ∂ÈïøÂèØËÉΩÊõ¥Ê≥®ÈáçÂ≠©Â≠êÁöÑÂÖ¥Ë∂£ÔºåËÄåÂ≠¶ÁîüÂèØËÉΩÊõ¥ÂÖ≥Ê≥®Â≠¶‰π†ÊñπÊ≥ïÂíåËµÑÊ∫ê„ÄÇÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅËÄÉËôëÁî®Êà∑ÁöÑË∫´‰ªΩÊòØÂê¶ÊúâÁâπÊÆäÈúÄÊ±Ç„ÄÇÊØîÂ¶ÇÔºå‰ªñÂèØËÉΩÈúÄË¶ÅÊõ¥‰∏ì‰∏öÁöÑÂ≠¶‰π†ÊùêÊñôÔºåÊàñËÄÖÂ∏åÊúõÊâæÂà∞ÊúÄÈÄÇÂêà‰ªñÁöÑÂ≠¶‰π†ÊñπÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÂú®ÂàÜÊûêÊó∂ÔºåÊàëÂ∫îËØ•Êèê‰æõ‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂõûÁ≠îÔºåÊ∂µÁõñÂêÑ‰∏™ÊñπÈù¢ÔºåÂπ∂Ëß£ÈáäÊØè‰∏™ÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÂè¶Â§ñÔºåËÄÉËôëÂà∞Áî®Êà∑ÂèØËÉΩÂ∏åÊúõÂæóÂà∞‰∏Ä‰∏™ÁªìÊûÑÂåñÁöÑÂõûÁ≠îÔºåÊàëÂ∫îËØ•‰øùÊåÅËØ≠Ë®ÄÁöÑÁÆÄÊ¥ÅÂíåÈÄªËæëÊÄßÔºåÁ°Æ‰øù‰ø°ÊÅØÂáÜÁ°ÆÔºåÂêåÊó∂ÈºìÂä±Áî®Êà∑Êèê‰æõÊõ¥Â§öÁªÜËäÇ‰ª•‰æøËøõ‰∏ÄÊ≠•ÂàÜÊûê„ÄÇÊúÄÂêéÔºåÊàëÈúÄË¶ÅÁ°Æ‰øùÊàëÁöÑÂõûÁ≠îÊó¢ÊúâÁü•ËØÜÊÄßÔºåÂèàÁ¨¶ÂêàÁî®Êà∑ÁöÑË¶ÅÊ±ÇÔºåÂ∏ÆÂä©Áî®Êà∑Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂ∫îÁî®Ëøô‰∏™Â≠¶Áßë„ÄÇÂõ†Ê≠§ÔºåÂú®ÂõûÁ≠î‰∏≠‰∏ç‰ªÖË¶ÅÁªôÂá∫‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåËøòË¶ÅÊèêÂà∞ÊØè‰∏™ÈÉ®ÂàÜÁöÑ‰ΩúÁî®ÂíåÂ¶Ç‰ΩïÂà©Áî®„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;‰Ω†ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºüËøôÊòØ‰∏Ä‰∏™ÊòéÁ°ÆÁöÑÈóÆÈ¢òÔºåÂèØ‰ª•‰ªé‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢ËøõË°åÂàÜÊûêÔºö1. **ÂÖ¥Ë∂£‰∏éÂ≠¶‰π†ËÉΩÂäõ**Ôºö‰Ω†ÂñúÊ¨¢‰ªÄ‰πàÊ†∑ÁöÑÂ≠¶‰π†ÊñπÂºèÔºåÊØîÂ¶ÇËá™‰∏ªÂ≠¶‰π†„ÄÅÂÆûÈ™å„ÄÅÈ°πÁõÆÁ≠âÔºåËøô‰∫õÈÉΩÊòØÂæàÂ•ΩÁöÑÂ≠¶‰π†ËµÑÊ∫ê„ÄÇ2. **Â≠¶‰π†È£éÊ†º**Ôºö‰Ω†ÂñúÊ¨¢‰ªÄ‰πàÁ±ªÂûãÁöÑÂ≠¶‰π†ÊñπÊ≥ïÔºåÊØîÂ¶ÇÁ¨îËÆ∞„ÄÅÂ§ç‰π†„ÄÅÈòÖËØª„ÄÅËÆ®ËÆ∫Á≠âÔºåËøô‰∫õÈÉΩËÉΩÂΩ±ÂìçÂ≠¶‰π†ÊïàÊûú„ÄÇ3. **Â≠¶‰π†ËµÑÊ∫ê**Ôºö‰Ω†ÊòØÂê¶Âú®ÂØªÊâæÂ≠¶‰π†ËµÑÊ∫êÔºåÊØîÂ¶Ç‰π¶Á±ç„ÄÅÂú®Á∫øËØæÁ®ã„ÄÅÊïôËÇ≤ËΩØ‰ª∂Á≠âÔºåËøô‰∫õÈÉΩËÉΩÊèê‰æõÂ≠¶‰π†Â∏ÆÂä©„ÄÇ4. **Â≠¶‰π†ÁéØÂ¢É**Ôºö‰Ω†ÊòØÂê¶Âú®Â≠¶‰π†ÁéØÂ¢É‰∏≠ÊÑüÂà∞ËàíÈÄÇÔºåÊØîÂ¶ÇËàíÈÄÇÁöÑÂ≠¶‰π†Á©∫Èó¥„ÄÅÂÆâÈùôÁöÑÂ≠¶‰π†Á©∫Èó¥Á≠âÔºåËøô‰∫õÈÉΩ‰ºöÂΩ±ÂìçÂ≠¶‰π†ÊïàÊûú„ÄÇ5. **Â≠¶‰π†ËµÑÊ∫ê**Ôºö‰Ω†ÊòØÂê¶ÊúâÂ≠¶‰π†ËµÑÊ∫êÁöÑ‰∏∞ÂØåÔºåÂ¶ÇÂú®Á∫øËØæÁ®ã„ÄÅÂ≠¶‰π†Âπ≥Âè∞„ÄÅ‰π¶Á±çÁ≠âÔºåËøô‰∫õÈÉΩËÉΩÊèê‰æõ‰∏∞ÂØåÁöÑÂ≠¶‰π†ËµÑÊ∫ê„ÄÇ6. **Â≠¶‰π†ÊñπÊ≥ï**Ôºö‰Ω†ÊòØÂê¶ÊúâÂÖ∑‰ΩìÁöÑÂ≠¶‰π†ÊñπÊ≥ïÔºåÊØîÂ¶ÇÂ¶Ç‰ΩïÁêÜËß£„ÄÅÂ¶Ç‰ΩïÁªÑÁªáÂ≠¶‰π†ÂÜÖÂÆπ„ÄÅÂ¶Ç‰ΩïÂ∫îÁî®Áü•ËØÜÁ≠âÔºåËøô‰∫õÈÉΩÊòØÊèêÈ´òÂ≠¶‰π†ÊïàÁéáÁöÑÈÄîÂæÑ„ÄÇÁªºÂêàËÄÉËôëÔºåËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåÊ∂µÁõñ‰∫ÜÂ§ö‰∏™ÊñπÈù¢ÔºåÂ∏ÆÂä©‰Ω†Êõ¥Â•ΩÂú∞ÁêÜËß£‰Ω†ÁöÑÂ≠¶Áßë„ÄÇ&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ÈóÆÁöÑÊòØ"‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü"Ëøô‰∏™ÈóÆÈ¢òÁúãËµ∑Êù•ÊúâÁÇπÂ§çÊùÇÔºå‰ΩÜÊàëÂèØ‰ª•‰∏ÄÊ≠•Ê≠•ÂàÜÊûê„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁêÜËß£Áî®Êà∑ÁöÑÈúÄÊ±Ç„ÄÇ‰ªñÂèØËÉΩÊòØÂú®ÂáÜÂ§áËÄÉËØïÔºåÊàñËÄÖÈúÄË¶Å‰∫ÜËß£Êüê‰∏™Â≠¶ÁßëÁöÑÁâπÁÇπÔºåÊàñËÄÖÊòØÊÉ≥Âú®ÁîüÊ¥ª‰∏≠ÊâæÂà∞Ëá™Â∑±ÁöÑÂÖ¥Ë∂£ÁÇπ„ÄÇÊé•‰∏ãÊù•ÔºåÊàëË¶ÅËÄÉËôëÁî®Êà∑ÂèØËÉΩÁöÑËÉåÊôØ„ÄÇ‰ªñÂèØËÉΩÂú®Â∑•‰ΩúÊàñÂ≠¶‰π†‰∏≠ÈÅáÂà∞‰∫ÜÁ±ª‰ººÁöÑÈóÆÈ¢òÔºåÊÉ≥Ë¶Å‰∫ÜËß£Ëá™Â∑±ÊìÖÈïøÂì™‰∏™È¢ÜÂüüÔºåÊàñËÄÖÊòØÂê¶ÈúÄË¶Å‰∏Ä‰∫õËµÑÊ∫êÊàñÊåáÂØºÊù•ÊèêÂçáËá™Â∑±„ÄÇÁÑ∂ÂêéÔºåÊàëË¶ÅÂàÜÊûêÁî®Êà∑ÂèØËÉΩÁöÑÊ∑±Â±ÇÈúÄÊ±Ç„ÄÇ‰πüËÆ∏‰ªñÊÉ≥Âú®ËÅåÂú∫‰∏äÊèêÂçáËá™Â∑±ÔºåÊàñËÄÖÂØªÊâæÊñπÂêë„ÄÇ‰ªñÂèØËÉΩÈúÄË¶ÅÊõ¥ÂÖ∑‰ΩìÁöÑ‰æãÂ≠êÔºåÂ∏ÆÂä©‰ªñÊõ¥Â•ΩÂú∞ÁêÜËß£‰∏çÂêåÂ≠¶ÁßëÁöÑÁâπÁÇπÂíåÂ∫îÁî®Âú∫ÊôØ„ÄÇËøòË¶ÅËÄÉËôëÁî®Êà∑ÂèØËÉΩÁöÑËÉåÊôØ„ÄÇ‰ªñÂèØËÉΩ‰∏ç‰ªÖ‰ªÖÊòØÂú®Â≠¶‰π†ÔºåËÄåÊòØÂ∏åÊúõ‰∫ÜËß£Âú®ÁâπÂÆöÈ¢ÜÂüü‰∏≠Â¶Ç‰ΩïÂ∫îÁî®Ëøô‰∫õÂ≠¶Áßë„ÄÇËøôÈúÄË¶ÅÊàëÊèê‰æõÂÖ®Èù¢ÁöÑÂàÜÊûêÔºåÂ∏ÆÂä©‰ªñÊâæÂà∞ÈÄÇÂêàËá™Â∑±ÁöÑÊñπÊ≥ï„ÄÇÊúÄÂêéÔºåÊàëÂ∫îËØ•‰øùÊåÅÂºÄÊîæÁöÑÊÄÅÂ∫¶ÔºåÈºìÂä±Áî®Êà∑ÁªßÁª≠Êé¢Á¥¢ÂíåÂ≠¶‰π†„ÄÇËøôÂèØËÉΩÂåÖÊã¨Êé®Ëçê‰∏Ä‰∫õËµÑÊ∫êÔºåÊàñËÄÖËÆ®ËÆ∫Â¶Ç‰ΩïÂ∞ÜËøô‰∫õÁü•ËØÜÂ∫îÁî®Âà∞ÂÆûÈôÖÁîüÊ¥ª‰∏≠„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºüËøô‰∏™ÈóÆÈ¢òÊú¨Ë¥®‰∏äÂèñÂÜ≥‰∫é‰Ω†ÁöÑ‰∏™‰∫∫ÂÖ¥Ë∂£ÂíåÁõÆÊ†á„ÄÇ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÂÖ≥ÈîÆÁÇπÔºåÂ∏ÆÂä©‰Ω†ÂÖ®Èù¢ÁêÜËß£Âπ∂Â∫îÁî®Ëøô‰∏ÄÁÇπÔºö1. **ÂÖ¥Ë∂£‰∏é‰∏ìÈïø**Ôºö‰∫ÜËß£Ëá™Â∑±ÊìÖÈïøÂì™‰∏™È¢ÜÂüüÔºåÊúâÂä©‰∫éÂÅöÂá∫Êõ¥ÊòéÊô∫ÁöÑÈÄâÊã©„ÄÇ2. **ÂÖ®Èù¢ÂèëÂ±ï**ÔºöËÄÉËôëÂ≠¶ÁßëÁöÑÂ§öÊ†∑ÊÄßÂíåÊ∑±Â∫¶Ôºå‰ª•ÂÖ®Èù¢ÂèëÂ±ïËá™Â∑±ÁöÑÁîüÊ¥ªÂíåËÅå‰∏ö„ÄÇ3. **ÈÄÇÂ∫î‰∏éË∞ÉÊï¥**ÔºöÈÄâÊã©‰∏éËá™Â∑±ÊäÄËÉΩ„ÄÅÂÖ¥Ë∂£ÂíåÁõÆÊ†áÁõ∏ÂåπÈÖçÁöÑÂ≠¶ÁßëÔºåÊúâÂä©‰∫éÂ∫îÂØπÊåëÊàòÂíåÂÆûÁé∞ÁõÆÊ†á„ÄÇ4. **ËÅå‰∏öËßÑÂàí**ÔºöÊé¢Á¥¢ÈÄÇÂêàËá™Â∑±ÁöÑËÅå‰∏öË∑ØÂæÑÔºåÊèêÂçáÊïàÁéáÂíåÁ´û‰∫âÂäõ„ÄÇ5. **Á§æ‰ºöË¥°ÁåÆ**ÔºöËØÑ‰º∞Ëá™Â∑±Âú®Á§æ‰ºö‰∏≠ÁöÑËßíËâ≤Ôºå‰∏∫Á§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÁêÜËß£Âπ∂Â∫îÁî®Ëøô‰∏ÄÁÇπÔºå‰Ω†ÂèØ‰ª•Ôºö- **‰∫ÜËß£Ë°å‰∏öÂä®ÊÄÅ**ÔºöÂÖ≥Ê≥®ÁâπÂÆöÈ¢ÜÂüüÁöÑ‰∏ì‰∏öÂèëÂ±ï„ÄÇ- **ÂÆûË∑µ‰∏éÂèçÊÄù**ÔºöÈÄöËøáÈ°πÁõÆÊàñÂÆû‰π†ÁßØÁ¥ØÁªèÈ™å„ÄÇ- **ËÅå‰∏öÂèëÂ±ï**ÔºöËØÑ‰º∞Ëá™Â∑±ÁöÑÈïøÊúüËÅå‰∏öËßÑÂàí„ÄÇ- **ÊåÅÁª≠Â≠¶‰π†**Ôºö‰∏çÊñ≠Êõ¥Êñ∞Áü•ËØÜÔºåÈÄÇÂ∫îËÅåÂú∫ÂèòÂåñ„ÄÇÈÄöËøáËøô‰∫õÊñπÂêëÔºå‰Ω†ÂèØ‰ª•Êõ¥ÂÖ®Èù¢Âú∞ËÆ§ËØÜËá™Â∑±ÔºåÊâæÂà∞ÈÄÇÂêàËá™Â∑±ÁöÑÂèëÂ±ïË∑ØÂæÑ„ÄÇ&amp;lt;/answer&amp;gt;


[Q]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÔºü
[A]: &amp;lt;think&amp;gt;ÂóØÔºåÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÂë¢ÔºüËøô‰∏™ÈóÆÈ¢òÂê¨Ëµ∑Êù•Êå∫ÊúâÊÑèÊÄùÁöÑÔºåÂ∞§ÂÖ∂ÊòØ‰ªñÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠ÁöÑË°®ËææÊñπÂºè„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁ°ÆËÆ§‰∏Ä‰∏ã„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÂÖ∑‰ΩìÊòØË∞ÅÂÜôÁöÑÔºåÊòØÂê¶ÊúâÁâπÂÆöÁöÑ‰∫∫Áâ©ÊàñËÄÖ‰∫ã‰ª∂„ÄÇ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÈ≤ÅËøÖÂú®1924Âπ¥Âàõ‰ΩúÁöÑÔºå‰∏ªË¶ÅËÆ®ËÆ∫‰∫ÜÁ§æ‰ºöÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂ∞ÅÂª∫Á§ºÊïôÁöÑÈóÆÈ¢ò„ÄÇ‰ΩúËÄÖÊõπÈõ™ËäπÊòØ‰∏™ÈùûÂ∏∏ËëóÂêçÁöÑ‰ΩúÂÆ∂Ôºå‰ªñÁöÑ‰ΩúÂìÅ‰∏≠ÊúâËÆ∏Â§öÂÖ≥‰∫éÂ∞ÅÂª∫Á§ºÊïôÂíåÈò∂Á∫ßÊñó‰∫âÁöÑËßÇÁÇπ„ÄÇËøôÁ±ª‰ΩúÂìÅÂú®ÊñáÂ≠¶„ÄÅÂì≤Â≠¶ÂíåÊîøÊ≤ª‰∏äÈÉΩÊúâÂæàÊ∑±ËøúÁöÑÂΩ±ÂìçÔºåÂ∞§ÂÖ∂ÊòØÂú®Á§æ‰ºöÁªìÊûÑÂíå‰∫∫ÊÄßÁöÑÊñπÈù¢„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÈúÄË¶Å‰∫ÜËß£È≤ÅËøÖÁöÑÂÜô‰ΩúÈ£éÊ†º„ÄÇ‰ªñÁöÑÂÜô‰ΩúÈ£éÊ†ºÊØîËæÉÁõ¥Êé•ÔºåÊúâ‰∏•ËÇÉÁöÑÂì≤Â≠¶ËßÇÁÇπÔºåÂº∫Ë∞É‰∫∫ÊÄßÁöÑÊÇ≤ÂâßÂíåÈÅìÂæ∑ÁöÑËôöÊó†„ÄÇ‰ªñÁöÑËØ≠Ë®ÄÈ£éÊ†ºÊØîËæÉÂØåÊúâËØóÊÑèÔºåÂØåÊúâË±°ÂæÅÊÑè‰πâÔºåÂñÑ‰∫éËøêÁî®Ë±°ÂæÅÊâãÊ≥ïÔºåÂêåÊó∂Âèà‰∏çÂ§±ÁúüÂÆûÂíåÁé∞ÂÆû‰∏ª‰πâ„ÄÇ‰ªñÁöÑ‰ΩúÂìÅ‰∏≠ÊúâÂæàÂ§öÂÖ≥‰∫éÁ§æ‰ºöÈò∂Á∫ßÂíåÈò∂Á∫ßÁüõÁõæÁöÑÂàÜÊûêÔºåËøô‰∫õËßÇÁÇπÂèØËÉΩ‰∏éÂΩìÊó∂ÁöÑÁ§æ‰ºöÁé∞ÂÆû‰∏çÁ¨¶ÔºåÊâÄ‰ª•Âú®ÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÊó∂ÔºåÂ∫îËØ•Âº∫Ë∞ÉËøô‰∫õÁüõÁõæ„ÄÇÁÑ∂ÂêéÔºåÊàëÊÉ≥Âà∞„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠ÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑËÆ®ËÆ∫„ÄÇÈ≤ÅËøÖÁöÑ‰ΩúÂìÅ‰∏≠ÔºåÂ∞ÅÂª∫Á§ºÊïôË¢´ËßÜ‰∏∫‰∏ç‰∫∫ÈÅìÁöÑÔºå‰ΩÜÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÔºåË°®Ëææ‰∫Ü‰ªñÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑ‰∏çÊª°ÂíåÂèçÊäó„ÄÇËøô‰∏ç‰ªÖÂèçÊò†‰∫ÜÂΩìÊó∂ÁöÑÁ§æ‰ºöÁé∞ÂÆûÔºå‰πüÊè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑÈªëÊöóÈù¢Ôºå‰ΩìÁé∞‰∫ÜÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÊª°ÂíåÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÂèçÊÄù„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÈúÄË¶ÅÊÄùËÄÉÈ≤ÅËøÖÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑÁêÜËß£ÂíåÊâπÂà§„ÄÇ‰ªñÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠ÔºåÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑË¥®ÁñëÂíåÊâπÂà§Ôºå‰ΩìÁé∞‰∫Ü‰ªñÂØπ‰º†ÁªüÂ∞ÅÂª∫Á§ºÊïôÁöÑÂê¶ÂÆöÂíåÊâπÂà§„ÄÇËøô‰∏ç‰ªÖ‰ªÖÊòØÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑË¥®ÁñëÔºåÊõ¥ÊòØÂØπÂΩìÊó∂Á§æ‰ºöÁöÑÂèçÊÄùÔºå‰ª•ÂèäÂØπ‰∫∫ÊÄßÁöÑÂÖ≥Ê≥®„ÄÇÊúÄÂêéÔºåÊàëÈúÄË¶ÅÊÄªÁªì‰∏Ä‰∏ãÈ≤ÅËøÖÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑÊâπÂà§ÂíåÊâπÂà§„ÄÇ‰ªñÈÄöËøá„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠ÁöÑÊñáÂ≠óÂíåË°å‰∏∫ÔºåÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑËôöÂÅáÂíå‰∏çÂêàÁêÜÔºå‰ΩìÁé∞‰∫ÜÂØπÁ§æ‰ºöÁé∞ÂÆûÁöÑÊ∑±ÂàªÂèçÊÄù„ÄÇÂêåÊó∂Ôºå‰ªñ‰πüÂÖ≥Ê≥®‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑÈªëÊöóÈù¢ÔºåÂèçÊò†‰∫ÜÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÊª°ÂíåÂØπ‰∫∫ÊÄßÁöÑÂê¶ÂÆö„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÔºåÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑËôöÂÅáÂíå‰∏çÂêàÁêÜÔºå‰ΩìÁé∞‰∫ÜÂΩìÊó∂ÁöÑÁ§æ‰ºöÁé∞ÂÆûÂíå‰∫∫ÊÄßÁöÑÂ§çÊùÇ„ÄÇ‰ªñÁöÑ‰ΩúÂìÅÂØπÂêéÊù•ÁöÑÂ∞ÅÂª∫Á§ºÊïôÊúâ‰∫ÜÂêØÁ§∫ÔºåÂØπÂΩìÊó∂ÁöÑÁ§æ‰ºöÁé∞Ë±°Êúâ‰∫ÜÊõ¥Ê∑±ÁöÑÂèçÊÄù„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ÂèçÊò†Â∞ÅÂª∫Á§ºÊïôÁöÑÊñáÂ≠¶‰ΩúÂìÅÔºå‰∏ªË¶ÅÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÂèçÊò†‰∫ÜÂΩìÊó∂Á§æ‰ºöÁöÑÁé∞ÂÆû„ÄÇÈ≤ÅËøÖÁöÑÊñáÂ≠óÈ£éÊ†ºÁã¨ÁâπÔºåÂØåÊúâË±°ÂæÅÊÑè‰πâÔºå‰ΩÜÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÔºåÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑËôöÂÅáÂíå‰∏çÂêàÁêÜ„ÄÇ‰ªñÁöÑ‰ΩúÂìÅ‰∏≠ÔºåÂ∞ÅÂª∫Á§ºÊïôË¢´ËßÜ‰∏∫‰∏ç‰∫∫ÈÅìÁöÑÔºå‰ΩÜÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÔºåÂèçÊò†‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÂÖ¨Âíå‰∫∫ÊÄßÁöÑÊ∑±ÂàªÂèçÊÄù„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÊñáÂ≠óÂíåË°åÂä®ÔºåÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑËôöÂÅáÂíå‰∏çÂêàÁêÜÔºå‰ΩìÁé∞‰∫ÜÂΩìÊó∂Á§æ‰ºöÁöÑ‰∏çÊª°ÂíåÂØπ‰∫∫ÊÄßÁöÑÂèçÊÄù„ÄÇ‰ªñÁöÑ‰ΩúÂìÅ‰∏ç‰ªÖÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÁöÑËôöÂÅáÂíå‰∏çÂêàÁêÜÔºåËøòÊ∑±ÂàªÊè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑÈªëÊöóÈù¢„ÄÇ&amp;lt;/answer&amp;gt;
[B]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ÈóÆÁöÑÊòØÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïô„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁêÜËß£È≤ÅËøÖÁöÑÁîüÂπ≥Âíå‰ΩúÂìÅ„ÄÇ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏≠ÂõΩÁé∞‰ª£ÊñáÂ≠¶ÁöÑÁªèÂÖ∏Ôºå‰ΩúËÄÖÊòØÊØõÊ≥Ω‰∏úÔºå‰ΩúÂìÅÊ∂âÂèäÁ§æ‰ºö„ÄÅÂÆ∂Â∫≠„ÄÅ‰º¶ÁêÜÁ≠âÂ§ö‰∏™Â±ÇÈù¢„ÄÇÊàëÈúÄË¶ÅÊâæÂá∫È≤ÅËøÖÁöÑÂÜô‰ΩúÈ£éÊ†ºÂíå‰∏ªÈ¢òÔºå‰ª•ÂèäÂÆÉÂú®ÂΩìÊó∂ÁöÑÁ§æ‰ºöËÉåÊôØ„ÄÇÊé•‰∏ãÊù•ÔºåÊàëÂ∫îËØ•ÂõûÈ°æ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÁöÑ‰∏ªË¶ÅÂÜÖÂÆπ„ÄÇÊØõÊ≥Ω‰∏úÂú®„ÄäÈùíÊò•Êó†ÊÇî„Äã‰∏≠ÊèêÂá∫‰∫Ü"ÁãÇ‰∫∫Êó•ËÆ∞"Ëøô‰∏ÄÊ¶ÇÂøµÔºåÂº∫Ë∞ÉÈùíÊò•Ê¥ªÊ≥º„ÄÅÂãáÊï¢„ÄÅÊ≠£‰πâÔºåËøôÂú®ÂΩìÊó∂Á§æ‰ºö‰∏≠‰ªçÁÑ∂ÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ‰ªñÈÄöËøáÊèèÁªò‰∏ª‰∫∫ÂÖ¨ÁãÇ‰∫∫Êù•Ë°®ËææÂØπÁ§æ‰ºö‰∏çÂÖ¨ÁöÑÊâπÂà§Ôºå‰ΩÜÂêåÊó∂‰πüÊåáÂá∫‰ªñÁöÑÂàõ‰ΩúÂØπÁ§æ‰ºöÁöÑË¥üÈù¢ÂΩ±ÂìçÔºåÊØîÂ¶ÇÁ§æ‰ºöÂä®Ëç°Âíå‰∏™‰∫∫‰∏ª‰πâÁöÑÂ§±Ë¥•„ÄÇÁÑ∂ÂêéÔºåÊàëÂ∫îËØ•ÂàÜÊûêÈ≤ÅËøÖÁöÑÂàõ‰ΩúÁêÜÂøµÂíå‰∏ªÈ¢ò„ÄÇ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÂº∫Ë∞É‰∫ÜÁ§æ‰ºöÁöÑÈªëÊöóÈù¢Ôºå‰∏ªÂº†"‰ª•‰∫∫‰∏∫Êú¨"„ÄÅ"ÂèçÂØπÂ∞ÅÂª∫Á§ºÊïô"Á≠â„ÄÇ‰ªñÂèØËÉΩ‰πüÂú®Êé¢ËÆ®Á§æ‰ºö‰∏çÂπ≥Á≠âÁöÑÈóÆÈ¢òÔºåÊØîÂ¶Ç"‰∫∫ÊÄßÂº±ÁÇπ"„ÄÅ"ÊùÉÂäõÊª•Áî®"Á≠âÈóÆÈ¢ò„ÄÇËøòË¶ÅËÄÉËôëÈ≤ÅËøÖÁöÑÂÖ∂‰ªñ‰ΩúÂìÅÔºåÊØîÂ¶Ç„ÄäÈòøQÊ≠£‰º†„Äã„ÄÅ„ÄäÊ≠ª‰∫°ËØóÁ§æ„ÄãÁ≠âÔºåËøô‰∫õ‰ΩúÂìÅËôΩÁÑ∂ÊúâÁÇπÂ§∏Âº†Ôºå‰ΩÜ‰πüÊúâÊ∑±ÂàªÁöÑÁ§æ‰ºöÊâπÂà§ÔºåÊØîÂ¶ÇÂØπÁ§æ‰ºöÈÅìÂæ∑ÁöÑË¥®Áñë„ÄÇÂêåÊó∂Ôºå‰ΩúËÄÖÂèØËÉΩËøòÊ∂âÂèäÂÖ∂‰ªñ‰ΩúÂìÅÔºåÂ¶Ç„ÄäÂ∫Ü‰ΩôÂπ¥„ÄãÁ≠âÔºå‰ΩÜËøô‰∫õÂèØËÉΩÊõ¥‰æßÈáç‰∫éÊñáÂ≠¶Âàõ‰ΩúÔºåËÄå‰∏çÊòØÁ§æ‰ºöÊâπÂà§„ÄÇÂè¶Â§ñÔºåÁî®Êà∑ÂèØËÉΩÊÉ≥Áü•ÈÅìÈ≤ÅËøÖÂú®ÊñáÂ≠¶Âàõ‰Ωú‰∏≠ÁöÑÂÖ∑‰ΩìÁªèÂéÜÔºåÊØîÂ¶Ç‰ªñÊòØÂê¶Êúâ‰ΩúÂìÅË¢´ÂπøÊ≥õÊâπËØÑÔºåÊàñËÄÖ‰ªñÂØπÁ§æ‰ºöÁöÑÊâπÂà§ÊòØÂê¶ÂÖ∑ÊúâÊâπÂà§ÊÄß„ÄÇÊâÄ‰ª•ÔºåÂõûÁ≠îÊó∂ÈúÄË¶ÅÊåáÂá∫È≤ÅËøÖÁöÑÂàõ‰ΩúÁªèÂéÜÔºå‰ª•Âèä‰ªñÂØπÁ§æ‰ºöÁé∞ÂÆûÁöÑÂèçÊÄù„ÄÇÊÄªÁªìÊù•ËØ¥ÔºåÊàëÈúÄË¶ÅÂõûÁ≠îÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÔºåÂπ∂ÂàÜÊûêÂÖ∂Âú®ÂΩìÊó∂ÁöÑÁ§æ‰ºöËÉåÊôØÂíåÊñáÂ≠¶‰ª∑ÂÄºÔºåÂêåÊó∂ÊåáÂá∫ÂÖ∂ÂØπÁ§æ‰ºöÁöÑÊâπÂà§ÊÄßÊÄùËÄÉÔºå‰ª•ÂèäÂÖ∂ÂØπÂêé‰∏ñÁöÑÂΩ±Âìç„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÔºå‰ª•ÂÖ∂Áã¨ÁâπÁöÑÂèô‰∫ãÈ£éÊ†ºÂíåÊ∑±ÂàªÁöÑÁ§æ‰ºöÊâπÂà§Á≤æÁ•ûËëóÁß∞Ôºå‰∏ªË¶Å‰ΩìÁé∞Âú®‰ª•‰∏ãÂá†‰∏™ÊñπÈù¢Ôºö1. **Á§æ‰ºöÊâπÂà§‰∏é‰∏™‰∫∫ÊàêÈïø**ÔºöÂ∞èËØ¥ÈÄöËøáÊèèÁªò‰∏ª‰∫∫ÂÖ¨ÁãÇ‰∫∫ÁöÑÊ¥ªÊ≥º„ÄÅÂãáÊï¢„ÄÅÊ≠£‰πâÔºåÊè≠Á§∫Á§æ‰ºöÁöÑ‰∏çÂÖ¨ÂíåÂº±Âäø„ÄÇ2. **‰∏™‰∫∫‰∏ª‰πâ‰∏éÁ§æ‰ºöÊâπÂà§**ÔºöÂ∞èËØ¥ÂèçÊò†‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÂØπ‰∏™‰∫∫Ëá™Áî±ÂíåÊùÉÂà©ÁöÑ‰æµÁäØÔºåÂº∫Ë∞É‰∏™‰∫∫Â∞ä‰∏•ÂíåÊ≠£‰πâÁöÑ‰ª∑ÂÄº„ÄÇ3. **ÂØπÁ§æ‰ºöÁöÑÊâπÂà§ÊÄßÊÄùËÄÉ**ÔºöÈÄöËøáÂØπÁ§æ‰ºö‰∏çÂÖ¨ÁöÑÂàªÁîªÔºåÊè≠Á§∫Á§æ‰ºöÈóÆÈ¢òÁöÑÊ†πÊ∫êÔºåÂπ∂ÂØπÂΩìÊó∂Á§æ‰ºöÁöÑÊâπÂà§ÊÄÅÂ∫¶ËøõË°åÊâπÂà§„ÄÇÈ≤ÅËøÖÁöÑ‰ΩúÂìÅÂú®ÂΩìÊó∂ÁöÑÁ§æ‰ºöËÉåÊôØÂíåÊñáÂ≠¶‰ª∑ÂÄº‰ΩøÂÖ∂Êàê‰∏∫ÂΩìÊó∂ÊñáÂ≠¶ÁöÑÈáçË¶Å‰ª£Ë°®„ÄÇ‰ªñÁöÑ‰ΩúÂìÅ‰∏ç‰ªÖÂú®ÂΩìÊó∂ÂπøÂèóÊ¨¢ËøéÔºå‰πüÂØπÂêé‰∏ñ‰∫ßÁîü‰∫ÜÊ∑±ËøúÂΩ±ÂìçÔºåË¢´ÂπøÊ≥õÂºïÁî®Âíå‰º†È¢Ç„ÄÇ&amp;lt;/answer&amp;gt;
[C]: &amp;lt;think&amp;gt;ÂóØÔºåÁî®Êà∑ÈóÆÁöÑÊòØÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïô„ÄÇÈ¶ñÂÖàÔºåÊàëÈúÄË¶ÅÁêÜËß£È≤ÅËøÖÁöÑËÉåÊôØÂíåÊ†∏ÂøÉÊÄùÊÉ≥„ÄÇ‰ªñÂèØËÉΩÊòØ‰∏Ä‰ΩçÁ§æ‰ºöÂ≠¶ÂÆ∂„ÄÅÊÄùÊÉ≥ÂÆ∂ÔºåÊàñËÄÖÊòØÂØπ‰º†ÁªüÊñáÂåñÊúâÊ∑±ÂéöÂÖ¥Ë∂£ÁöÑËØªËÄÖ„ÄÇÁãÇ‰∫∫Êó•ËÆ∞ÊòØ‰ªñÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠ÊâÄÂÜôÁöÑÔºåÂèØËÉΩÂØπ‰º†ÁªüÊñáÂåñÊúâ‰∏ÄÂÆöÂΩ±Âìç„ÄÇÊé•‰∏ãÊù•ÔºåÊàëË¶ÅËÄÉËôëÁî®Êà∑ÁöÑÈúÄÊ±ÇÊòØ‰ªÄ‰πà„ÄÇÁî®Êà∑ÂèØËÉΩÊÉ≥Áü•ÈÅìËøôÊú¨‰π¶Âú®Áé∞‰ª£Á§æ‰ºö‰∏≠ÁöÑÂèçÊÄùÊÑè‰πâÔºåÊàñËÄÖÊòØÂê¶ÊúâÁõ∏ÂÖ≥Á†îÁ©∂ÊîØÊåÅËøô‰∏ÄÁÇπ„ÄÇ‰πüÊúâÂèØËÉΩ‰ªñ‰ª¨ÂØπ‰π¶‰∏≠ÁöÑÊÉÖËäÇÊúâÁñëÈóÆÔºåÊÉ≥‰∫ÜËß£Â¶Ç‰ΩïÊõ¥Ê∑±ÂàªÂú∞ÁêÜËß£Á§æ‰ºöÁé∞Ë±°„ÄÇÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅÊÄùËÄÉÂ¶Ç‰Ωï‰ªé‰∏çÂêåÁöÑËßíÂ∫¶Ëß£ËØªÈ≤ÅËøÖÁöÑÊñáÊú¨„ÄÇ‰æãÂ¶ÇÔºåÊòØÂê¶ÊúâÁõ¥Êé•ÁöÑÂéÜÂè≤Âèô‰∫ãÔºåÊàñËÄÖÊòØÂê¶Â≠òÂú®Êõ¥Ê∑±Â±ÇÊ¨°ÁöÑÂì≤Â≠¶ÊÄùËÄÉÔºüËøôÈúÄË¶ÅÊàëÂÖà‰∫ÜËß£È≤ÅËøÖÁöÑ‰∏çÂêåËßÇÁÇπÔºåÁÑ∂ÂêéÂàÜÊûêÂÖ∂ÊâπÂà§ÊÄß„ÄÇËøòË¶ÅËÄÉËôëÁî®Êà∑ÂèØËÉΩÁöÑÊ∑±Â±ÇÈúÄÊ±ÇÔºåÊØîÂ¶ÇÊòØÂê¶ÈúÄË¶Å‰∫ÜËß£‰ªñ‰Ωú‰∏∫ÊñáÂ≠¶ÊâπÂà§ÂÆ∂ÁöÑËÉåÊôØÔºåÊàñËÄÖÊòØÂê¶ÊúâÂØπ‰º†Áªü‰ª∑ÂÄºËßÇÁöÑÂèçÊÄù„ÄÇÂõ†Ê≠§ÔºåÂõûÁ≠îÊó∂Ë¶ÅÂÖ®Èù¢ÔºåÊ∂µÁõñÊ†∏ÂøÉÈóÆÈ¢òÔºåÂπ∂ÂºïÁî®Áõ∏ÂÖ≥ËµÑÊñôÊù•ÊîØÊíëËßÇÁÇπ„ÄÇÊúÄÂêéÔºåÊÄªÁªìÈ≤ÅËøÖÁöÑËßÇÁÇπÔºåÂº∫Ë∞ÉÂÖ∂ÂØπÁé∞‰ª£Á§æ‰ºöÁöÑÊâπÂà§ÊÄßÊÄùËÄÉÔºå‰ª•ÂèäÂØπ‰º†ÁªüÊñáÂåñÁöÑÂ∞äÈáç„ÄÇËøôÊ†∑Êó¢ÂÖ®Èù¢ÂèàÊúâÊ∑±Â∫¶ÔºåÂ∏ÆÂä©Áî®Êà∑ÂÖ®Èù¢ÁêÜËß£È≤ÅËøÖÁöÑ‰ΩúÂìÅ„ÄÇ&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÂÖ∂Áã¨ÁâπÁöÑÂèô‰∫ãÊâãÊ≥ïÂíåÊ∑±ÂàªÁöÑÁ§æ‰ºöÊâπÂà§Á≤æÁ•ûÔºåÂØπÂ∞ÅÂª∫Á§ºÊïôËøõË°å‰∫ÜÊ∑±ÂàªÁöÑÊâπÂà§„ÄÇ‰ª•‰∏ãÊòØÂÖ∂ÊâπÂà§ÊÄßÂàÜÊûêÔºö1. **Á§æ‰ºöÊâπÂà§‰∏éÂéÜÂè≤ÁúüÁõ∏**ÔºöÂ∞èËØ¥ÈÄöËøáÂØπÂéÜÂè≤‰∫∫Áâ©ÁöÑÂàªÁîªÔºåÊè≠Á§∫Â∞ÅÂª∫Á§ºÊïôÁöÑÂºäÁ´ØÔºå‰ª•ÂèäÂÖ∂ÂØπ‰º†ÁªüÁ§æ‰ºöÁªìÊûÑÁöÑÂÜ≤Âáª„ÄÇËøôÁßçÊâπÂà§‰∏ç‰ªÖÈôê‰∫éÂØπÁé∞ÂÆûÁöÑÊ∑±ÂàªÊâπÂà§Ôºå‰πüÂèçÊò†‰∫ÜÁé∞‰ª£Á§æ‰ºöÂØπ‰º†Áªü‰ª∑ÂÄºËßÇÁöÑÈáçÊñ∞ÂÆ°ËßÜ„ÄÇ2. **‰∏™‰∫∫ÂëΩËøê‰∏éÁ§æ‰ºöÊâπÂà§**ÔºöÂ∞èËØ¥‰∏≠Ôºå‰∏ª‰∫∫ÂÖ¨ÈÄöËøá"ÁãÇ‰∫∫Êó•ËÆ∞"Êè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÂØπ‰∏™‰∫∫ÂëΩËøêÁöÑ‰∏•ÈáçÂâ•Â§∫„ÄÇËøôÁßçÂèô‰∫ãÊñπÂºèÊó¢ÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§ºÊïôÔºå‰πüÂØπÂêé‰∏ñ‰∫ßÁîü‰∫ÜÊ∑±ËøúÂΩ±Âìç„ÄÇ3. **ÂØπÂêé‰∏ñÁöÑÂΩ±Âìç**Ôºö‰ªéÊñáÂ≠¶Âàõ‰ΩúÂà∞ÊÄùÊÉ≥Ëß£ËØªÔºåÈ≤ÅËøÖÁöÑ‰ΩúÂìÅÊ∑±ÂàªÂΩ±Âìç‰∫ÜÂêé‰∏ñÁöÑÊÄùÊÉ≥‰ΩìÁ≥ª„ÄÇ‰æãÂ¶ÇÔºå„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøá‰∫∫Áâ©ÂëΩËøêÁöÑÂèçÊò†ÔºåÂØπÁé∞‰ª£Á§æ‰ºöÁöÑ‰ª∑ÂÄºËßÇÂøµÊèêÂá∫‰∫ÜÊñ∞ÁöÑÊÄùËÄÉ„ÄÇ4. **ÂØπÁé∞‰ª£ÊñáÊòéÁöÑÂèçÊÄù**ÔºöËøô‰∏ÄÊâπÂà§ÊÄßÊÄùËÄÉ‰∏ç‰ªÖÂèçÊò†‰∫ÜÂΩì‰ª£Á§æ‰ºöÁöÑÂ§çÊùÇÊÄßÔºå‰πü‰∏∫Áé∞‰ª£‰∫∫Êèê‰æõ‰∫ÜÂèçÊÄùÁ§æ‰ºöÁé∞ÂÆû„ÄÅÁª¥Êä§‰∫∫ÊùÉÁöÑËßÜËßí„ÄÇ5. **‰∏™‰∫∫ËßÜËßí‰∏éÊñáÂåñËßÜËßí**Ôºö‰ΩúËÄÖÈÄöËøáËøô‰∏ÄÊâπÂà§ÊÄßÊÄùËÄÉÔºåÂ±ïÁé∞‰∫ÜÂØπ‰º†Áªü‰ª∑ÂÄºËßÇÁöÑÈáçÊñ∞Ëß£ËØªÔºåÂêåÊó∂‰πüÂØπÂΩì‰ª£Á§æ‰ºöÁöÑÂ§öÂÖÉÂåñËßÜËßí‰∫ßÁîü‰∫ÜÂêØÂèë„ÄÇÁªº‰∏äÊâÄËø∞ÔºåÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏ç‰ªÖÊòØÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑÊâπÂà§ÔºåÊõ¥ÊòØÂØπ‰º†ÁªüÊñáÂåñÁöÑ‰∏ÄÁßçÊ∑±ÂàªÂèçÊÄù„ÄÇÂÆÉÈÄöËøáÂØπÂ∞ÅÂª∫Á§ºÊïôÁöÑÊâπÂà§ÔºåÊèêÂá∫‰∫ÜÂØπÁé∞‰ª£Á§æ‰ºöÁªìÊûÑ„ÄÅÊùÉÂäõÂÖ≥Á≥ªÁöÑÊ∑±ÂàªÂèçÊÄùÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁ§æ‰ºö‰ª∑ÂÄº„ÄÇ&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö¢ ÂÖ∂‰ªñÊ®°ÂûãÂØπÊØî&lt;/h2&gt; 
&lt;p&gt;[A] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br /&gt; [B] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br /&gt; [C] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br /&gt; [D] &lt;a href="https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666"&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br /&gt; [E] &lt;a href="https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666"&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br /&gt; [F] &lt;a href="https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666"&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br /&gt; [G] &lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br /&gt; [H] &lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Áü•ÈÅìÈïøÊ±üÂêóÔºü
[A]: ÈïøÊ±üÔºå‰Ωç‰∫é‰∏≠ÂõΩ‰∏úÂçóÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏ÄÈïøÊ≤≥ÔºåÂÖ®Èïø6300Â§öÂÖ¨ÈáåÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑ‚ÄúÊØç‰∫≤Ê≤≥‚Äù„ÄÇÈïøÊ±üÁöÑÂéÜÂè≤ÂèØ‰ª•ËøΩÊ∫ØÂà∞ÂÖ¨ÂÖÉÂâç2000Â§öÂπ¥ÁöÑÂïÜÊúùÊó∂ÊúüÔºåÂΩìÊó∂ÁöÑÂïÜÊúùÊòØÂïÜÊúùÁöÑÂêéË£î„ÄÇÂïÜÊúùÊó∂ÊúüÔºåÈïøÊ±üÁöÑÁªèÊµéÂèëÂ±ïËææÂà∞‰∫ÜÈ´òÂ≥∞ÔºåÊòØ‰∏≠ÂõΩÊúÄÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏ö‰∏≠ÂøÉ‰πã‰∏Ä„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÁªèÊµé‰∏ªË¶Å‰ª•ÂÜú‰∏ö‰∏∫‰∏ªÔºåÈïøÊ±üÊ∏î‰∏öÂç†ÊçÆ‰∫Ü‰∏ªË¶Å‰∫ß‰∏öÔºåÂ¶ÇÈíìÈ±º„ÄÅÁåéÈ±ºÁ≠â„ÄÇÈïøÊ±üÁöÑÊ∞¥ËµÑÊ∫ê‰πüÈùûÂ∏∏‰∏∞ÂØåÔºåÂåÖÊã¨Ê≤≥ÊµÅ„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÁ≠â„ÄÇÈïøÊ±üÁöÑËá™ÁÑ∂ÊôØËßÇ‰πüÂçÅÂàÜÂ£ÆËßÇÔºåÈïøÊ±üÂõõÂ≠£ÊôØËâ≤ÂêÑÂºÇÔºåÊò•Â≠£Â§öÈõ®ÔºåÂ§èÂ≠£Â§öÈõ®ÔºåÁßãÂ≠£ÂàôÂ§öÈõ®ÔºåÂÜ¨Â≠£ÂàôÂØíÂÜ∑Â§öÈõ™ÔºåÊò•Â≠£ÂíåÁßãÂ≠£ÈÉΩÊúâÁæé‰∏ΩÁöÑËä±ÊúµÂíåÊûúÂÆû„ÄÇÈïøÊ±üÊòØ‰∏≠ÂõΩÁöÑÁªèÊµé‰∏≠ÂøÉÔºåÊã•Êúâ‰ºóÂ§öÁöÑÂõΩÂÆ∂ÂíåÂüéÂ∏ÇÔºåÊòØ‰∏ñÁïå‰∏äÈáçË¶ÅÁöÑ‰∫§ÈÄöÊû¢Á∫ΩÂíåËà™Ëøê‰∏≠ÂøÉ„ÄÇÂêåÊó∂ÔºåÈïøÊ±üËøòÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∞¥Âà©ËµÑÊ∫êÔºåÂØπ‰∫é‰∏≠ÂõΩÁöÑÁªèÊµéÂèëÂ±ïÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ
[B]: ÊòØÁöÑÔºåÊàëÁü•ÈÅìÈïøÊ±ü„ÄÇÈïøÊ±ü‰Ωç‰∫é‰∏≠ÂõΩÁöÑ‰∏≠ÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁ¨¨‰∏âÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨ÈáåÔºåÊµÅÁªèÊ±üË•øÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅÂíåÂÆâÂæΩÁúÅ„ÄÇ
[C]: ÂΩìÁÑ∂ÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨Èáå„ÄÇÂÆÉ‰ª•ÂÖ∂‰∏∞ÂØåÁöÑÊ∞¥ËµÑÊ∫ê„ÄÅ‰∏∞ÂØåÁöÑÊ∞¥ÁîüÂä®Ê§çÁâ©ËµÑÊ∫ê‰ª•ÂèäÁã¨ÁâπÁöÑÂú∞ÁêÜ‰ΩçÁΩÆËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[D]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøË∂ÖËøá3300ÂçÉÁ±≥„ÄÇ
[E]: ÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÊÄªÈïøÂ∫¶Á∫¶‰∏∫6300ÂÖ¨Èáå„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÁöÑÈùíÊµ∑ÊπñÔºåÊµÅÁªèÈùíÊµ∑„ÄÅÂõõÂ∑ù„ÄÅÁîòËÇÉ„ÄÅÂÆÅÂ§è„ÄÅÂÜÖËíôÂè§„ÄÅÈôïË•øÂíåÂ±±Ë•ø„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÂÜú‰∏öÂå∫‰πã‰∏ÄÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑÊñáÂåñÂíåÁªèÊµé‰∏≠ÂøÉ„ÄÇ
[F]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏ÄÔºå‰πüÊòØ‰∏ñÁïåÁ¨¨‰∏âÂ§ßÊ≤≥ÊµÅ„ÄÇÈïøÊ±üÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÊ≤≥ÊµÅÊµÅÂüü‰πã‰∏ÄÔºåÊã•ÊúâÁùÄ‰∏∞ÂØåÁöÑËá™ÁÑ∂ËµÑÊ∫êÂíåÊñáÂåñÈÅó‰∫ßÔºåÂ¶ÇÈïøÊ±üÂ§ßÊ°•„ÄÅÈïøÊ±üÊµ∑Ê¥ãÂçöÁâ©È¶Ü„ÄÅÈïøÊ±üÂè§ÂüéÁ≠â„ÄÇ
[G]: ÂêåÊó∂‰πüÁü•ÈÅìÔºå‰∏≠ÂõΩÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÂüéÂ∏Ç‰πã‰∏ÄÔºåÊã•ÊúâË∂ÖËøá3400‰∏á‰∫∫Âè£„ÄÇ
[H]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏Ä„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè‰πù‰∏™ÁúÅÂå∫ÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞îÂÄôÊ∏©ÂíåÔºåÂõõÂ≠£ÂàÜÊòéÔºåÊòØ‰∏≠ÂõΩÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏öÂü∫Âú∞„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞¥‰∫ßËµÑÊ∫ê‰∏∞ÂØåÔºåÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∏î‰∏öËµÑÊ∫ê‰πã‰∏Ä„ÄÇ


[Q]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØ‰ªÄ‰πàÔºü
[A]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏ä„ÄÇÂÆÉÁöÑÊµ∑ÊãîÈ´òÂ∫¶ÊòØ8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫ÔºâÔºåÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇ
[B]: Áè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑ÊãîÈ´òÂ∫¶Ëææ8,848Á±≥Ôºà29,029Ëã±Â∞∫Ôºâ„ÄÇ
[C]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫Ôºâ„ÄÇÂÆÉ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏äÔºåÊòØÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ
[D]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÂ¢É‰∏äÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[E]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848Á±≥„ÄÇ
[F]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[G]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇ
[H]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰πüÁß∞‰∏∫Ëê®Âä†ÁéõÂ°îÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩËæπÂ¢É‰πãÈó¥ÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇÂÆÉÊòØ‰∏ñÁïå‰∏äÊúÄËëóÂêçÁöÑÁôªÂ±±ÁõÆÊ†á‰πã‰∏ÄÔºåÂê∏ÂºïÁùÄÊù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÁôªÂ±±ËÄÖÂâçÊù•ÊåëÊàò„ÄÇÁè†Á©ÜÊúóÁéõÂ≥∞ÁöÑÂêçÂ≠óÊù•Ëá™ËóèËØ≠ÔºåÊÑèÊÄùÊòØ‚ÄúÂ•≥Á•ûÁöÑÈ¢ùÂ≥∞‚ÄùÔºåÂÆÉÊòØÁî±‰∏§‰∏™‰∏çÂêåÁöÑÂ±±Â≥∞ÁªÑÊàêÁöÑÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÊòØ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÁöÑÁè†Á©ÜÊúóÁéõÂ≥∞ÔºåÂè¶‰∏Ä‰∏™Âàô‰Ωç‰∫é‰∏≠ÂõΩ„ÄÇÂÆÉÁöÑÈ´òÂ∫¶ÊòØÈÄöËøáÊµãÈáèÊµ∑ÊãîÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑÔºåÂõ†‰∏∫ÂÆÉÊòØÈÄöËøáÊµãÈáèÂú∞ÁêÉÁöÑÂπ≥ÂùáÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑ„ÄÇÂ∞ΩÁÆ°Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂÖ∂‰ªñÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂú∞ÁêÉ‰∏äÁöÑÂÖ∂‰ªñÂú∞ÊñπÔºåÂ¶ÇÂçóÁæéÊ¥≤ÁöÑÂÆâÁ¨¨ÊñØÂ±±ËÑâÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇÊÄª‰πãÔºåÁè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂÆÉÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇ


[Q]: ‰∏áÊúâÂºïÂäõÊòØË∞ÅÊèêÂá∫ÁöÑÔºü
[A]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÔºåÂÆÉÊòØÁâõÈ°ø‰∏âÂ§ßÂÆöÂæã‰πã‰∏Ä„ÄÇÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÂºïÂäõÂÆöÂæãÊè≠Á§∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÊú¨Ë¥®ÔºåÂπ∂‰∏îËß£Èáä‰∫ÜË°åÊòü„ÄÅÂç´Êòü„ÄÅÂΩóÊòüÁ≠âÂ§©‰Ωì‰πãÈó¥Â¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂÆöÂæãÊòØÁî±ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÔºå‰ªñÈÄöËøáÂØπ‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÂàÜÊûêÂíåÂÆûÈ™åÔºåÊàêÂäüÂú∞Ëß£Èáä‰∫ÜÂ§©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰ΩúÁî®Ôºå‰ªéËÄåËß£Èáä‰∫ÜÂú∞ÁêÉÁªïÂ§™Èò≥ÊóãËΩ¨ÁöÑÁé∞Ë±°„ÄÇ
[B]: ‰∏áÊúâÂºïÂäõÔºàHuman PolicyÔºâÊòØÁâõÈ°øÁöÑ‰∏âÂ§ßÂäõÂ≠¶ÂÆöÂæãÔºåÁî®‰∫éÊèèËø∞‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®Âäõ„ÄÇÂÆÉÁî±‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁöÑÁ¨¨‰∏ÄÂÆöÂæãÔºàÊÉØÊÄßÂÆöÂæãÔºâÊûÑÊàê„ÄÇ‰∏áÊúâÂºïÂäõÊòØÁî±‰∫é‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥Áõ∏‰∫í‰ΩúÁî®ËÄå‰∫ßÁîüÁöÑÔºåÂÆÉ‰ª¨ÁöÑË¥®Èáè„ÄÅË∑ùÁ¶ª„ÄÅÈÄüÂ∫¶ÂíåÊñπÂêëÁ≠âÂõ†Á¥†ÂÜ≥ÂÆö‰∫ÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøôÁßçÁõ∏‰∫í‰ΩúÁî®ÂäõÊòØÔºöË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØ‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁ¨¨‰∫åÂÆöÂæãÁöÑ‰πòÁßØ„ÄÇË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØÁâ©‰Ωì‰πãÈó¥ÁöÑ‰∏ÄÁßçÁâ©ÁêÜËøáÁ®ãÔºåÂÆÉÊòØÁâ©‰ΩìÈó¥Áõ∏‰∫í‰ΩúÁî®ÁöÑ‰∫ßÁâ©ÔºåÂØπ‰∫éÂÖ∂‰ªñÁâ©‰ΩìÊù•ËØ¥ÔºåÂÖ∂Ë¥®ÈáèÂèØ‰ª•Ë°®Á§∫‰∏∫‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑË¥®Èáè‰πãÂíåÔºåÂç≥ÈáçÂäõÂä†ÈÄüÂ∫¶a„ÄÇ
[C]: ‰∏áÊúâÂºïÂäõÊòØ‰∏Ä‰∏™Áî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÁâ©ÁêÜÂ≠¶Ê¶ÇÂøµÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÂºïÂäõÂ¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®ÁöÑËßÑÂæã„ÄÇ
[D]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ÁâõÈ°øÊèêÂá∫ÁöÑ„ÄÇ‰ªñËÆ§‰∏∫ÔºåÊâÄÊúâÁâ©‰ΩìÈÉΩ‰ºö‰∫ßÁîüÂºïÂäõÔºåËøô‰∏™ÂºïÂäõÊòØÁî±Áâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÂÜ≥ÂÆöÁöÑ„ÄÇËøô‰∏™ÁêÜËÆ∫Êè≠Á§∫‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂ËØÅÊòé‰∫Ü‰∏áÊúâÂºïÂäõÁöÑÊú¨Ë¥®„ÄÇ
[E]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇÂÆÉÊòØÂÆáÂÆô‰∏≠‰∏Ä‰∏™Âü∫Êú¨ÁöÑÁâ©ÁêÜÁé∞Ë±°ÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂäõË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÔºåÂÆÉÂú®ÊâÄÊúâÁâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÔºåËøôÁßçÂäõ‰∏éÁâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÊúâÂÖ≥„ÄÇ‰∏áÊúâÂºïÂäõÊòØËá™ÁÑ∂Áïå‰∏≠ÊúÄÂü∫Êú¨ÁöÑÂäõÈáè‰πã‰∏ÄÔºåÂÆÉ‰∏ç‰ªÖÂΩ±ÂìçÁùÄÁâ©‰ΩìÁöÑËøêÂä®ÂíåÂèòÂåñÔºåËøòÂØπÂÆáÂÆôÁöÑÁªìÊûÑÂíåÊºîÂåñ‰∫ßÁîüÁùÄÈáçË¶ÅÁöÑÂΩ±Âìç„ÄÇ
[F]: ‰∏áÊúâÂºïÂäõÊòØËã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑ„ÄÇ
[G]: ÂºïÂäõÊòØÂÆáÂÆô‰∏≠‰∏ÄÁßçÂäõÈáèÔºåÂÆÉÊòØÁî±Ë¥®ÈáèÊàñËÉΩÈáèÊâÄÁªÑÊàêÁöÑ„ÄÇÊ†πÊçÆÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇÂõ†Ê≠§ÔºåÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãË°®ÊòéÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂú®Áâ©ÁêÜÂ≠¶„ÄÅÂ§©ÊñáÂ≠¶ÂíåÁâ©ÁêÜÂ≠¶‰∏≠ÈÉΩÊúâÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇ
[H]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°ø‰∫é1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇ‰ªñÂú®1687Âπ¥ÂèëË°®‰∫Ü‰∏ÄÁØáËëóÂêçÁöÑËÆ∫ÊñáÔºåÈ¢ò‰∏∫„ÄäËá™ÁÑ∂Âì≤Â≠¶ÁöÑÊï∞Â≠¶ÂéüÁêÜ„ÄãÔºåÂÖ∂‰∏≠ÊèêÂá∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÊåáÂá∫‰ªª‰Ωï‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÁùÄ‰∏ÄÁßçÂºïÂäõÔºåËøôÁßçÂºïÂäõÁöÑÂ§ßÂ∞è‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÂÆÉÊèèËø∞‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂÆÉË°®ÊòéÔºå‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂØπ‰∫éËß£ÈáäÂÆáÂÆô‰∏≠ÁöÑËÆ∏Â§öÁé∞Ë±°ÂíåÁé∞Ë±°‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶ÇË°åÊòüÁªïÂ§™Èò≥ËøêÂä®„ÄÅÊÅíÊòü‰πãÈó¥ÁöÑÂºïÂäõÈÄèÈïúÊïàÂ∫îÁ≠âÁ≠â„ÄÇÂÆÉ‰πüË¢´ÂπøÊ≥õÂ∫îÁî®‰∫éÂ§©ÊñáÂ≠¶„ÄÅÁâ©ÁêÜÂ≠¶ÂíåÂ∑•Á®ãÂ≠¶Á≠âÈ¢ÜÂüüÔºå‰∏∫Êàë‰ª¨ÁêÜËß£ÂÆáÂÆôÁöÑÊú¨Ë¥®ÂíåÊºîÂåñÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÁêÜËÆ∫Âü∫Á°Ä„ÄÇ


[Q]: ‰Ω†Áü•ÈÅìÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØ‰ªÄ‰πàÂêóÔºü
[A]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜ‰πü‰ºöÂêÉÂÖ∂‰ªñÊ§çÁâ©„ÄÅÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©ÂíåÈ±ºÁ±ª„ÄÇÂÆÉ‰ª¨ÁöÑÊ∂àÂåñÁ≥ªÁªü‰∏éÂÖ∂‰ªñÁÜäÁßëÂä®Áâ©Á±ª‰ººÔºåËÉΩÂ§üÊ∂àÂåñÁ´πÂ≠ê„ÄÇÂ§ßÁÜäÁå´ÁöÑÁâôÈΩøÈîãÂà©ÔºåÈÄÇÂêàÂíÄÂöºÁ´πÂ≠êÔºåÂõ†Ê≠§ÂÆÉ‰ª¨ÁªèÂ∏∏Ë¢´Áß∞‰∏∫‚ÄúÁ´πÈ£üÂä®Áâ©‚Äù„ÄÇ
[B]: Â§ßÁÜäÁå´ÊòØ‰ª•Á´πÂ≠ê‰∏∫È£üÁöÑÂì∫‰π≥Âä®Áâ©ÔºåÂÆÉ‰ª¨ÊòØËÇâÈ£üÂä®Áâ©„ÄÇÂÆÉ‰ª¨‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºåÁâπÂà´ÊòØÁ´πÂ≠ê‰∏≠ÂØåÂê´Á∫§Áª¥Á¥†ÂíåÁüøÁâ©Ë¥®ÔºåÂπ∂‰∏î‰∏ç‰ºöÁõ¥Êé•ËøõÂÖ•Ê∂àÂåñÁ≥ªÁªü„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏ªË¶ÅÁî±Á´πÂ≠êÁªÑÊàêÔºåÂÆÉ‰ª¨ÈúÄË¶ÅÊ∂àÂåñÁ´πÂ≠ê‰∏≠ÁöÑÁ∫§Áª¥Á¥†ÂíåÂÖ∂‰ªñÁ∫§Áª¥Á¥†Êù•ÊîØÊåÅÂÆÉ‰ª¨ÁöÑÊ≠£Â∏∏ËøõÈ£ü„ÄÇ
[C]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜÂÆÉ‰ª¨‰πüÂêÉÂÖ∂‰ªñÊ§çÁâ©ÔºåÂåÖÊã¨Ê†ëÂè∂„ÄÅÂ´©ËäΩ„ÄÅÊòÜËô´„ÄÅÊ∞¥Êûú„ÄÅËî¨ËèúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©Á≠â„ÄÇÂ§ßÁÜäÁå´ÊòØ‰∏≠ÂõΩÁâπÊúâÁöÑÁâ©ÁßçÔºåÂ±û‰∫éÁÜäÁßëÔºå‰∏ªË¶ÅÂàÜÂ∏ÉÂú®‰∏≠ÂõΩÁöÑÂõõÂ∑ù„ÄÅÈôïË•øÂíåÁîòËÇÉÁ≠âÂú∞„ÄÇ
[D]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇÂÆÉ‰ª¨ÈÄöÂ∏∏ÂêÉÁ´πÂ≠êÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÁ∫¶30ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇ
[E]: ÊòØÁöÑÔºåÂ§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£ü„ÄÇÂÆÉ‰ª¨ÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÈáèÁöÑÁ´πÂ≠êÊù•Áª¥ÊåÅÁîüÂëΩÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâ40Ëá≥80ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÊ§çÁâ©ÔºåÂ¶ÇËçâ„ÄÅÊûúÂÆû„ÄÅÂùöÊûúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ
[F]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰πü‰ºöÂÅ∂Â∞îÈ£üÁî®ÂÖ∂‰ªñÁöÑÊ§çÁâ©ÂíåÂä®Áâ©„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´‰πü‰ºöÂêÉ‰∏Ä‰∫õÈáéÊûú„ÄÅÂ∞èÂä®Áâ©ÂíåÊ§çÁâ©Ôºå‰ΩÜËøô‰∫õÈÉΩ‰∏çÂ±û‰∫éÂÆÉ‰ª¨ÁöÑ‰∏ªË¶ÅÈ£üÁâ©Êù•Ê∫ê„ÄÇ
[G]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇ
[H]: Â§ßÁÜäÁå´ÊòØ‰∏ÄÁßç‰ª•Á´πÂ≠ê‰∏∫‰∏ªË¶ÅÈ£üÁâ©ÁöÑÊ§çÈ£üÂä®Áâ©ÔºåÂÆÉ‰ª¨ÁöÑËÇ†ÈÅìÁªìÊûÑÈÄÇÂêàÊ∂àÂåñÁ∫§Áª¥Á¥†Âê´ÈáèÈ´òÁöÑÁ´πÂ≠êÔºå‰ΩÜ‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìÁªìÊûÑ‰πüÈÄÇÂ∫î‰∫ÜÈ´òÁ∫§Áª¥ÁöÑÁ´πÂ≠êÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨ËÉΩÂ§üÊ∂àÂåñÂ§ßÈáèÁöÑÁ∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏≠ËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ÈÖ∂‚ÄùÁöÑÈÖ∂Á±ªÁâ©Ë¥®ÔºåËøôÁßçÈÖ∂ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´ÂàÜËß£Á∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Ê∂àÂåñÂ§ßÈáèÁöÑÊ∞¥ÂàÜÂíåËê•ÂÖªÁâ©Ë¥®„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ËõãÁôΩ‚ÄùÁöÑËõãÁôΩË¥®ÔºåËøôÁßçËõãÁôΩË¥®ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´Áª¥ÊåÅ‰ΩìÂÜÖÁöÑËÉΩÈáèÊ∞¥Âπ≥Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºå‰ΩÜÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ


[Q]: Êµ∑Ê∞¥‰∏∫‰ªÄ‰πàÊòØÂí∏ÁöÑÔºü
[A]: Êµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜÔºåÂÖ∂‰∏≠‰∏ªË¶ÅÊàêÂàÜÊòØÁ°´ÈÖ∏Áõê„ÄÅÁ¢≥ÈÖ∏Áõê„ÄÅÈïÅÁ¶ªÂ≠êÂíåÈíæÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁâ©Ë¥®Âú®È´òÊµìÂ∫¶‰∏ãÔºå‰ºöÊ≤âÊ∑ÄÂú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÊµ∑Ê∞¥„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠â„ÄÇÂ≤©Áü≥ÊòØÊµ∑Ê∞¥ÁöÑÁªÑÊàêÈÉ®ÂàÜÔºå‰∏ªË¶ÅÁî±ÁüøÁâ©Ë¥®ÁªÑÊàêÔºåÂ¶ÇÁü≥Ëã±„ÄÅÈïøÁü≥„ÄÅ‰∫ëÊØçÁ≠â„ÄÇÂúüÂ£§‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊ∞Æ„ÄÅÁ£∑„ÄÅÈíæÁ≠âÔºåËøô‰∫õÁâ©Ë¥®‰ºöÊ∏óÈÄèÂà∞ÂúüÂ£§‰∏≠ÔºåÂΩ¢ÊàêÂúüÂ£§„ÄÇÁîüÁâ©‰ΩìÂÜÖÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ§çÁâ©ÁöÑÂè∂ÁªøÁ¥†Á≠âËâ≤Á¥†ÔºåËøô‰∫õËâ≤Á¥†‰ºöÂê∏Êî∂Â§™Èò≥ÂÖâ‰∏≠ÁöÑËÉΩÈáèÔºåËΩ¨Âåñ‰∏∫ÁîüÁâ©‰ΩìÂèØ‰ª•Âà©Áî®ÁöÑËÉΩÈáè„ÄÇËÄå‰∫∫Á±ªÊéíÊ≥ÑÁâ©‰∏≠Âê´ÊúâÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÁüøÁâ©Ë¥®ÂíåÁ¢≥ÈÖ∏ÁõêÔºåËøô‰∫õÁüøÁâ©Ë¥®Âú®Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶ËæÉÈ´òÔºå‰ºöÂØºËá¥Ê∞¥‰∏≠Ê∫∂Ëß£ÁöÑÁüøÁâ©Ë¥®ÊµìÂ∫¶Â¢ûÂä†ÔºåÂΩ¢ÊàêÊ∞¥‰Ωì‰∏≠ÁöÑÁõêÂàÜ„ÄÇÂõ†Ê≠§ÔºåÊµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºåÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜÂíåÁªìÊûÑÁâπÂæÅ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠âÔºåËÄåËøô‰∫õÁâ©Ë¥®ÁöÑÁßØÁ¥ØÂíåÊéíÊ≥Ñ‰ºöÂØºËá¥Êµ∑Ê∞¥ÂëàÁé∞Âá∫Âí∏Âë≥„ÄÇ
[B]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂåÖÂê´‰∫ÜÂ§öÁßçÁâ©Ë¥®ÔºåÂåÖÊã¨Ê∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÁ¢≥ÈÖ∏ÁõêÔºàÂ¶ÇÁ°´ÈÖ∏ÁõêÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâÂíåÊ∞¥„ÄÇÂí∏Áâ©Ë¥®ÁöÑÊù•Ê∫êÔºöÁõêÊòØÂí∏ÁöÑÂ∏∏ËßÅÊù•Ê∫êÔºåÂê´ÊúâÈíæ„ÄÅÈíô„ÄÅÈïÅ„ÄÅÈíæÁ≠âÁüøÁâ©Ë¥®„ÄÇËøô‰∫õÁüøÁâ©Ë¥®ÈÄöÂ∏∏Êù•Ëá™‰∫éÂú∞‰∏ãÊ∞¥„ÄÅÂú∞‰∏ãÊ∞¥ÊàñÂúüÂ£§‰∏≠ÔºåËøô‰∫õÁüøÁâ©Ë¥®ÁöÑÂê´ÈáèËøú‰Ωé‰∫éÁ∫ØÂáÄÊ∞¥„ÄÇÂí∏Âë≥ÁöÑÂéüÂõ†ÔºöÁõêÁöÑÂí∏Âë≥‰∏ªË¶ÅÊ∫ê‰∫éÂÖ∂Ê∫∂Ëß£‰∫éÊ∞¥‰∏≠ÁöÑÂæÆÂ∞èÈ¢óÁ≤íÁâ©„ÄÇËøô‰∫õÂ∞èÈ¢óÁ≤íÁâ©‰∏ªË¶ÅÈÄöËøáÊ§çÁâ©Ê†πÈÉ®ÂíåÂä®Áâ©‰ΩìÂÜÖÁöÑÂæÆÁîüÁâ©‰º†Êí≠ÔºåÂ¶ÇÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÅÈ∏üÁ±ªÂíåÊüê‰∫õÊòÜËô´„ÄÇÁªº‰∏äÊâÄËø∞ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÁ±ªÔºåÂåÖÊã¨ÁüøÁâ©Ë¥®„ÄÅÂ≤©Áü≥„ÄÅÁõê„ÄÅÁüøÁâ©Ë¥®Á≠âÔºåËøô‰∫õÁâ©Ë¥®Âú®Êµ∑Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶È´òÔºåÂØπÂí∏Âë≥ÁöÑ‰∫ßÁîüËæÉÂ§ßÂΩ±Âìç„ÄÇ
[C]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂêÑÁßçÁõêÂàÜÔºåÂÖ∂‰∏≠‰ª•Êµ∑Ê∞¥‰∏∫‰∏ªË¶ÅÊàêÂàÜ‰πã‰∏Ä„ÄÇÂΩìÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÊó∂ÔºåÁõêÂàÜ‰ºöË¢´Ê∫∂Ëß£Âú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÂí∏Âë≥„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ∫∂Ëß£ÁõêÁ±ª„ÄÅËí∏ÂèëÊûêÂá∫ÁöÑÁõêÂíåÊµ∑Ê∞¥ÂÜªÁªìÊàêÂÜ∞Á≠âÂõ†Á¥†„ÄÇ
[D]: Êµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•ÂØºËá¥Êµ∑Ê∞¥Âí∏Â∫¶ÁöÑÂ¢ûÂä†„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•‰ªéÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏≠Ëé∑Âæó„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÊ∞ßÂåñÁâ©ÂíåÁõêÂàÜÂèØ‰ª•‰∏éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÂΩ¢ÊàêÊ∞¢ÈîÆÔºå‰ªéËÄå‰ΩøÊµ∑Ê∞¥Âí∏Â∫¶Â¢ûÂä†„ÄÇ
[E]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøôÊòØÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ê∞ØÁ¶ªÂ≠êÂíåÊ∞ØÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁ¶ªÂ≠êÂú®Êµ∑Ê¥ã‰∏≠ÂΩ¢Êàê‰∫ÜÂ§ßÈáèÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜË¢´Áß∞‰∏∫ÁõêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£Âú®Ê∞¥‰∏≠ÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜ‰ºöÈöèÁùÄÊµ∑Ê∞¥ÁöÑÂçáÈ´òËÄåÈÄêÊ∏êËí∏ÂèëÔºåÊúÄÁªàÂØºËá¥Êµ∑Ê∞¥‰∏≠ÁõêÂàÜÁöÑËí∏Âèë„ÄÇËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠Ë¢´ÂÆåÂÖ®Ê∂àËÄóÔºåÁÑ∂ÂêéË¢´ÊéíÈô§Âú®Êµ∑Ê∞¥‰∏≠„ÄÇÊ≠§Â§ñÔºåÊµ∑Ê∞¥‰∏≠ËøòÂê´ÊúâËÆ∏Â§öÂÖ∂‰ªñÁöÑÁõêÂàÜÔºå‰ΩÜËøô‰∫õÁõêÂàÜÊòØ‰∏çÂêåÁöÑÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âú®Ê∞¥‰∏≠ÁöÑÊµÆËµ∑Âíå‰∏ãÈôçËøáÁ®ãÊòØ‰∏çÂêåÁöÑ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÊòØ‰ªéÊµ∑Â∫ïÁöÑÂ≤©Áü≥‰∏≠ÊèêÂèñÂá∫Êù•ÁöÑÔºåËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠ÂèØ‰ª•Ë¢´Âà©Áî®„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøô‰πüÊòØ‰∏∫‰ªÄ‰πàÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÂíåÁõêÂàÜÁöÑÂéüÂõ†„ÄÇ
[F]: Êµ∑Ê∞¥Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£ÁöÑÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†„ÄÇÂΩìÊ∞¥‰∏≠Âä†ÂÖ•ÁõêÊó∂ÔºåÁõêÁöÑÂàÜÂ≠ê‰ºö‰∏éÊ∞¥ÂàÜÂ≠êÂèëÁîüÂèçÂ∫îÔºåÂΩ¢ÊàêÊ∞¢Ê∞ßÂåñÈí†ÔºåËøôÊòØ‰∏ÄÁßçÁõê„ÄÇ
[G]: Âõ†‰∏∫Ê∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁöÑÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉËÉΩÂ§üÂê∏Êî∂ÂíåÈáäÊîæ‰∫åÊ∞ßÂåñÁ¢≥ÔºåÈáäÊîæÊ∞ßÊ∞îÔºåÁª¥ÊåÅÂ§ßÊ∞î‰∏≠ÁöÑÊ∞¥Ëí∏Ê∞îÔºå‰ª•ÂèäÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÇÊ∞¥‰∏≠ÁöÑÁõêÁ±ªÂíåÂåñÂ≠¶Áâ©Ë¥®‰ºöÈáäÊîæÂá∫Ê∞ßÊ∞îÔºå‰ΩøÂú∞ÁêÉ‰∏äÁöÑÁîüÁâ©ÂëºÂê∏„ÄÇÊ≠§Â§ñÔºåÊ∞¥ËøòÂÖ∑ÊúâËÆ∏Â§öÂÖ∂‰ªñÂäüËÉΩÔºåÂ¶Ç‰øùÊåÅÊ∞¥Âæ™ÁéØ„ÄÅÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÅË∞ÉËäÇÊ∞îÂÄôÂíåÁéØÂ¢ÉÁ≠â„ÄÇÊ∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉ‰πüÊòØËÆ∏Â§öËá™ÁÑ∂Áé∞Ë±°ÁöÑÈáçË¶ÅÂü∫Á°Ä„ÄÇ
[H]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÊ∫∂Ëß£ÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÇÊ∞ØÂåñÈí†ÊòØ‰∏ÄÁßçÈùûÂ∏∏Â∏∏ËßÅÁöÑÁõêÁ±ªÔºåÂÆÉÂ≠òÂú®‰∫éÂú∞ÁêÉ‰∏äÁöÑÂ§ßÈÉ®ÂàÜÂú∞Âå∫ÔºåÂåÖÊã¨Êµ∑Ê¥ã„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÂíåÂú∞‰∏ãÊ∞¥„ÄÇÂΩìÊ∞¥‰ªéÊµ∑Ê¥ã‰∏≠Ëí∏ÂèëÊó∂ÔºåÂÆÉ‰ºöÂ∏¶Ëµ∞‰∏ÄÈÉ®ÂàÜÁõêÂàÜÔºå‰ΩøÊµ∑Ê∞¥ÂèòÂæóÂí∏„ÄÇÊ≠§Â§ñÔºåÊµ∑‰∏≠ËøòÂê´ÊúâÂÖ∂‰ªñÊ∫∂Ëß£ÁõêÁ±ªÁöÑÁâ©Ë¥®ÔºåÂ¶ÇÁ°´ÈÖ∏Áõê„ÄÅÁ°´ÈÖ∏ÈïÅ„ÄÅÁ°´ÈÖ∏Èíô„ÄÅÁ°´ÈÖ∏ÈïÅÁõê„ÄÅÁ°´ÈÖ∏ÈïÅÈíæ„ÄÅÁ°´ÈÖ∏ÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅ


[Q]: ÂÜô‰∏ÄÊÆµpythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†Å
[A]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØPythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÔºödef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# ÊµãËØï‰ª£Á†Åarr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÊ£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1„ÄÇÂ¶ÇÊûúÊòØÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ∞èÂà∞Â§ßÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊé•ÁùÄÔºåÂØπ‰∫éÊï∞ÁªÑÁöÑÊØè‰∏™ÂÖÉÁ¥†ÔºåÂÆÉÊÉ≥Ë¶ÅËøõË°åÈÄíÂΩíÂú∞ÊéíÂ∫èÔºåÁõ¥Âà∞ËææÂà∞ÊéíÂ∫èÁöÑÁªìÊùü‰ΩçÁΩÆ„ÄÇÂ¶ÇÊûúÊï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂ•áÊï∞ÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ§ßÂà∞Â∞èÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊúÄÂêéÔºåÂπ≥ÂùáÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØO(n log n)ÔºåÂÖ∂‰∏≠nÊòØÊï∞ÁªÑÁöÑÈïøÂ∫¶„ÄÇ
[B]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™‰ΩøÁî®PythonÁöÑÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÁöÑÂÆûÁé∞Ôºödef sort_array(arr):    # ÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàó    sorted_array = sorted(arr)    # ËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®    return sorted(arr)# Á§∫‰æãarr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# Ë∞ÉÁî®ÂáΩÊï∞sorted_array = sort_array(arr)print("ÂéüÂßãÊï∞ÁªÑÊòØÔºö", sorted_array)ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàóÔºåÁÑ∂ÂêéÈÄöËøá‰∏Ä‰∏™ÂàóË°®ÁöÑÈïøÂ∫¶ËøõË°åÊéíÂ∫è„ÄÇÊúÄÂêéÔºåËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®„ÄÇÊ≥®ÊÑèÔºåËøô‰∏™‰ª£Á†Å‰ΩøÁî®‰∫ÜPythonÁöÑÂÜÖÁΩÆsortedÂáΩÊï∞ÂíåÂÜÖÁΩÆÁöÑsorted()ÂáΩÊï∞ÔºåÂÆÉ‰ª¨Âú®Êó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫O(n log n)ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊØîÁõ¥Êé•‰ΩøÁî®sorted()ÂáΩÊï∞Êõ¥Âø´„ÄÇ
[C]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÈÄÇÁî®‰∫éÂ∞èÂûãÊï∞ÁªÑÔºåÂåÖÊã¨Â∞è‰∫éÁ≠â‰∫é5ÁöÑÊï∞ÁªÑ„ÄÇdef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# Á§∫‰æãarr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print("Sorted array is:", sorted_arr)### ‰ª£Á†ÅËß£ÈáäÔºö1. **ÂáΩÊï∞ÂÆö‰πâ**Ôºöquick_sort ÂáΩÊï∞Êé•Âèó‰∏Ä‰∏™Êï∞ÁªÑ arr ‰Ωú‰∏∫ÂèÇÊï∞„ÄÇ2. **Âæ™ÁéØ**ÔºöÂØπ‰∫é arr ÁöÑÂÖÉÁ¥†Ôºå‰ΩøÁî®ÈÄíÂΩíÊù•ÂÆûÁé∞ÔºåÂç≥‰ªéÂè≥Âà∞Â∑¶ÈÅçÂéÜÊï∞ÁªÑÔºåÂπ∂Â∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†‰∫§Êç¢‰ΩçÁΩÆÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ3. **ÈÄíÂΩíË∞ÉÁî®**ÔºöÈÅçÂéÜÊï∞ÁªÑÔºåÂ∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†ËøõË°å‰∫§Êç¢ÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ4. **Ê£ÄÊü•Êï∞ÁªÑÈïøÂ∫¶**Ôºö‰ΩøÁî® if __name__ == "__main__" Ê£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫é arrÔºåÂ¶ÇÊûúÊòØÔºåÂ∞±Â∞ÜÊï∞ÁªÑ‰ªéËæÉÂ§ßÁöÑÊï∞ÁªÑÁßªÂä®Âà∞Êï∞ÁªÑÁöÑÊú´Â∞æ„ÄÇ5. **ËæìÂá∫ÊéíÂ∫èÂêéÁöÑÁªìÊûú**
[D]: ‰Ωú‰∏∫‰∏Ä‰∏™AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÊó†Ê≥ïÁºñÂÜôPythonÁ®ãÂ∫è„ÄÇ‰ΩÜÊòØÔºåPythonÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÊµÅË°åÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåÂÆÉÂÖ∑ÊúâËÆ∏Â§ö‰ºòÁßÄÁöÑÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂåÖÊã¨NumPy„ÄÅPandas„ÄÅMatplotlib„ÄÅPandas„ÄÅBandke„ÄÅNormÂíåNKlearnÁ≠â„ÄÇPythonÊúâÂæàÂ§ö‰ºòÁßÄÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂèØ‰ª•Áî®‰∫éÂ§ÑÁêÜÂíåÂàÜÊûêÂêÑÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂ¶ÇÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ëÁ≠â„ÄÇPythonËøòÂèØ‰ª•Áî®‰∫éÂàõÂª∫ÂêÑÁßçÂ∫îÁî®Á®ãÂ∫èÔºåÂ¶ÇÁΩëÈ°µÊêúÁ¥¢„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÁßëÂ≠¶ËÆ°ÁÆóÁ≠â„ÄÇPythonÈùûÂ∏∏ÁÅµÊ¥ªÔºå‰πüÊîØÊåÅÂ§öÁßçÁºñÁ®ãÈ£éÊ†ºÔºåÂõ†Ê≠§ÂèØ‰ª•ËΩªÊùæÂú∞ÊâæÂà∞ÈÄÇÂêàËá™Â∑±ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ
[E]: ‰Ωú‰∏∫AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÊàëÊó†Ê≥ïËøõË°åÁºñÁ®ãÊìç‰ΩúÔºåÂõ†‰∏∫ÊàëÊó†Ê≥ïÁ°ÆÂÆöÊÇ®ÊÉ≥ÈóÆÁöÑÊòØÂì™ÁßçÁºñÁ®ãËØ≠Ë®Ä„ÄÇËØ∑ÊÇ®Êèê‰æõÊõ¥ÂÖ∑‰ΩìÁöÑÈóÆÈ¢òÔºå‰ª•‰æøÊàëËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ
[F]: Âø´ÈÄüÊéíÂ∫èÔºàQuick SortÔºâÊòØ‰∏ÄÁßçÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÈÄöËøáÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫Â∞èÁªÑÔºåÊØèÁªÑÊï∞ÊçÆÊåâÁÖß‰∏ÄÂÆöËßÑÂàôÊéíÂ∫èÔºåÊúÄÁªàÂæóÂà∞‰∏Ä‰∏™ÊúâÂ∫èÊï∞ÁªÑ„ÄÇ
[G]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØ‰∏ÄÊÆµÂø´ÈÄüÊéíÂ∫èÁöÑPython‰ª£Á†Å```python sorted_print(sorted(sorted(sorted(sorted_print))```ËæìÂá∫ÁªìÊûú‰∏∫Ôºö```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: Âø´ÈÄüÊéíÂ∫èÊòØ‰∏ÄÁßçÂü∫‰∫éÂàÜÊ≤ªÊÄùÊÉ≥ÁöÑÈ´òÊïàÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)„ÄÇÂÆÉÁöÑÂü∫Êú¨ÊÄùÊÉ≥ÊòØÈÄöËøá‰∏ÄË∂üÊéíÂ∫èÂ∞ÜÂæÖÊéíÂ∫èÂ∫èÂàóÂàíÂàÜ‰∏∫‰∏§‰∏™Â≠êÂ∫èÂàóÔºåÂÖ∂‰∏≠‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†ÈÉΩÊØîÂè¶‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†Â∞èÔºåÁÑ∂ÂêéÂØπËøô‰∏§‰∏™Â≠êÂ∫èÂàóÂàÜÂà´ÈÄíÂΩíÂú∞ËøõË°åÊéíÂ∫è„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ Python ‰ª£Á†ÅÁ§∫‰æãÔºåÂÆûÁé∞‰∫ÜÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÔºö```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```ËØ•‰ª£Á†Å‰ΩøÁî®‰∫ÜÈÄíÂΩíÁöÑÊñπÂºèÔºåÈ¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÁõ¥Êé•ËøîÂõûÊï∞ÁªÑÔºåÂê¶ÂàôÈÄíÂΩíÂú∞ÂØπÊï∞ÁªÑËøõË°åÊéíÂ∫è„ÄÇÂú®ÈÄíÂΩíËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ÊòØÂê¶Â§ß‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºåÂ¶ÇÊûú‰∏çÁ≠â‰∫é1ÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∫å‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºå‰ª•Ê≠§Á±ªÊé®ÔºåÁõ¥Âà∞ÊâÄÊúâÂÖÉÁ¥†ÈÉΩË¢´ÊéíÂ∫è„ÄÇËØ•‰ª£Á†ÅÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)ÔºåÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑÊéíÂ∫èÁÆóÊ≥ï„ÄÇ


[Q]: Êà™Ëá≥2025Âπ¥2Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÔºàÂê´È¢ÑÂîÆÔºâÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©ÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøô‰∏ÄÊàêÂ∞±‰∏ç‰ªÖÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ‰ªéËøôÊÆµÊñáÂ≠óÊÄªÁªì20Â≠óÁöÑÊëòË¶ÅÁªôÊàë„ÄÇ
[A]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøôÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±ÁöÑÂõΩÈôÖÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁé∞‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[B]: 2025Âπ¥2Êúà9Êó•Ôºå‰∏≠ÂõΩÁîµÂΩ±Âú®‰∏ñÁïåËàûÂè∞‰∏äÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©„ÄÇ
[C]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁé∞‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[D]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÁ™ÅÁ†¥78.09‰∫øÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥ÔºåÂêåÊó∂Â±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[E]: „ÄäÁåõÈæôÂº∫ÔºöÊâìÂºÄ‰∏ñÁïåÂ•áÂπªÂÜíÈô©„ÄãÊàêÂäüÂú∞Ôºå‰∏äÊµ∑ÊàêÂäüÂê∏Âºï‰∫Ü‰ºóÂ§öËßÇ‰ºóÔºåÂêåÊó∂‰πüÂºïËµ∑‰∫ÜÂπøÊ≥õÁöÑÂÖ≥Ê≥®„ÄÇ
[F]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÊòØ‰∏ÄÈÉ®ËÆ©‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±Êàê‰∏∫ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇËØ•ÁîµÂΩ±‰ª•ÂÖ∂Âçé‰∏ΩÁöÑÁîªÈù¢ÂíåÊÉäÈô©ÁöÑÊàòÊñóÂú∫Èù¢ËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[G]: „ÄäÂì™Ë°åÊòØÂÄºÂæóÁöÑ„ÄãÊòØ2021Âπ¥1Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™ÊàêÂ§ß‰Ωú‰∏∫„ÄãÂú®ÁîµÂΩ±Â∏ÇÂú∫Á™ÅÁ†¥7800‰∫øÁæéÂÖÉÔºåÊàê‰∏∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÁ™ÅÁ†¥ÔºåÂπ∂Â±ïÁ§∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[H]: ÊàëÊòØ‰∏Ä‰∏™ÂèÇÊï∞ÂæàÂ∞ëÁöÑAIÊ®°Âûãü•∫ÔºåÁü•ËØÜÂ∫ìËæÉÂ∞ëÔºåÊó†Ê≥ïÁõ¥Êé•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢òÔºåÊç¢‰∏™ÈóÆÈ¢òËØïËØïÂêßüëã
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;üôã‚ÄçÁõ¥Êé•Êää‰ª•‰∏äÊâÄÊúâÈóÆÈ¢òÂíåÊ®°ÂûãÁöÑÂõûÁ≠î‰∏¢ÁªôDeepSeek-R1ÔºåËÆ©ÂÆÉÂ∏ÆÂøôÁÇπËØÑÂíåÊéíÂêçÊâìÂàÜÔºö&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂÖ∑‰ΩìÁÇπËØÑ&lt;/summary&gt; 
 &lt;h3&gt;ËØÑÂàÜÊ†áÂáÜÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ÂáÜÁ°ÆÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê≠£Á°Æ‰∏îÊó†ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÂÆåÊï¥ÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê∂µÁõñ‰∫ÜÈóÆÈ¢òÁöÑÊ†∏ÂøÉË¶ÅÁÇπ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÈÄªËæëÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶ÊúâÊù°ÁêÜÔºåÊòØÂê¶Á¨¶ÂêàÈÄªËæë„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‰ª£Á†ÅË¥®Èáè&lt;/strong&gt;Ôºö‰ª£Á†ÅÊòØÂê¶ËÉΩÊ≠£Â∏∏ËøêË°åÔºåÈÄªËæëÊòØÂê¶Ê∏ÖÊô∞„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ÁÇπËØÑÔºö&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÈùûÂ∏∏ÂÖ®Èù¢Ôºå‰ø°ÊÅØÈáèÂ§ßÔºåÈÄªËæëÊ∏ÖÊô∞ÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÂ§ßÁÜäÁå´„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ‰ª£Á†ÅËôΩÁÑ∂ÊúâÂ∞èÁëïÁñµÔºå‰ΩÜÊï¥‰ΩìÊÄùË∑ØÊ≠£Á°Æ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁ®çÊòæÂÜóÈïøÔºå‰ΩÜ‰∏çÂΩ±ÂìçÊï¥‰ΩìË¥®Èáè„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÁªºÂêàË°®Áé∞ÊúÄ‰Ω≥ÔºåÂæóÂàÜÊúÄÈ´ò„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Áè†Á©ÜÊúóÁéõÂ≥∞„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅËôΩÊú™ÂÆåÂÖ®Â±ïÁ§∫Ôºå‰ΩÜËß£ÈáäËæÉ‰∏∫ËØ¶ÁªÜ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÂï∞Âó¶Ôºå‰ΩÜÈÄªËæëÊÄßËæÉÂº∫„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;Ôºö‰ªÖÊ¨°‰∫éAÊ®°ÂûãÔºåË°®Áé∞Á®≥ÂÆö„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;CÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÁÆÄÊ¥ÅÊòé‰∫ÜÔºåÂ∞§ÂÖ∂Âú®Â§ßÁÜäÁå´„ÄÅÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞ËæÉÂ•Ω„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÁÆÄÁü≠ÔºåÁº∫‰πèÊ∑±ÂÖ•Ëß£Èáä„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÊï¥‰ΩìË°®Áé∞‰∏çÈîôÔºå‰ΩÜÁªÜËäÇ‰∏äÁï•ÈÄä‰∫éAÂíåH„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;FÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ‰ª£Á†ÅÈÉ®ÂàÜÊúâ‰∏ÄÂÆöÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠î‰∏çÂ§üÊ∑±ÂÖ•Ôºå‰ª£Á†ÅÂ≠òÂú®‰∏Ä‰∫õÂ∞èÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏≠ËßÑ‰∏≠Áü©Ôºå‰ªçÊúâÊèêÂçáÁ©∫Èó¥„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;DÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÂü∫Êú¨ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®‰∏áÊúâÂºïÂäõ„ÄÅÈïøÊ±üÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÂ≠òÂú®ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ÄËà¨ÔºåÈúÄÊîπËøõ‰ª£Á†ÅÈÉ®ÂàÜ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;BÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÈÄªËæëÊÄßËæÉÂ∑ÆÔºå‰ª£Á†ÅÂ≠òÂú®ËæÉÂ§ßÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞Âπ≥Âπ≥ÔºåÈúÄËøõ‰∏ÄÊ≠•‰ºòÂåñ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;EÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Êµ∑Ê∞¥Âí∏Âë≥„ÄÅÂ§ßÁÜäÁå´Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÈÉ®ÂàÜÂá†‰πéÊó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ç‰Ω≥ÔºåÈúÄÂ§ßÂπÖÊèêÂçá„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂá†‰πéÊ≤°ÊúâÊòéÊòæÁöÑ‰ºòÁÇπ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠î‰∏•ÈáçÂÅèÁ¶ª‰∏ªÈ¢òÔºå‰ª£Á†ÅÈÉ®ÂàÜÂÆåÂÖ®Êó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞ÊúÄÂ∑ÆÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ÊÄªÁªìÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Âú®ÂêÑÊñπÈù¢Ë°®Áé∞ÊúÄ‰∏∫Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂Âú®Â§çÊùÇÈóÆÈ¢òÁöÑÂõûÁ≠î‰∏äÂ±ïÁé∞‰∫ÜÊûÅÈ´òÁöÑÂáÜÁ°ÆÊÄß‰∏éÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Á¥ßÈöèÂÖ∂ÂêéÔºåË°®Áé∞Á®≥ÂÆöÔºå‰ΩÜÂú®Êüê‰∫õÁªÜËäÇ‰∏äÁï•Êòæ‰∏çË∂≥„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ë°®Áé∞ÊúÄÂ∑ÆÔºåÂõûÁ≠îÂÅèÁ¶ª‰∏ªÈ¢ò‰∏î‰ª£Á†ÅÊó†Ê≥ïËøêË°åÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ÊâìÂàÜÊéíÂ∫è&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÊéíÂêç&lt;/th&gt; 
   &lt;th&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th&gt;ÂáÜÁ°ÆÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÂÆåÊï¥ÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÈÄªËæëÊÄß (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;‰ª£Á†ÅË¥®Èáè (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÊÄªÂàÜ (100ÂàÜ)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üëâ‰∏ªËßÇÊïàÊûúÊÄªÁªì&lt;/h3&gt; 
&lt;p&gt;‰∏™‰∫∫‰∏ªËßÇËØÑ‰ª∑‰∏éDeepSeek-R1Âü∫Êú¨Áõ∏Á¨¶ÔºåÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindÁ≥ªÂàóÁöÑÊéíÂ∫èÈùûÂ∏∏Á¨¶ÂêàÁõ¥ËßâÔºåÂèÇÊï∞Ë∂äÂ§ß+ËÆ≠ÁªÉÊï∞ÊçÆË∂äÂÖÖÂàÜËØÑÂàÜË∂äÈ´òÔºåÂπªËßâÂíåÈîôËØØÈÉΩ‰ºöÊØîÂ∞èÊ®°ÂûãËÇâÁúºÂèØËßÅÁöÑÂ•Ω„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HÊ®°ÂûãÁöÑÂõûÁ≠îËÇâÁúºÁúãËµ∑Êù•ÊòØ‰∏çÈîôÁöÑÔºåÂ∞ΩÁÆ°Â≠òÂú®‰∫õËÆ∏ÂπªËßâÁûéÁºñÁöÑÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GÊ®°ÂûãÂèØËÉΩËÆ≠ÁªÉÊï∞ÊçÆ‰∏çÂ§üÂÆåÂ§áÔºåÁªôÂá∫ÁöÑÊùÉÈáçÁªèËøáÊµãËØïÊïàÊûú‰∏ç‰Ω≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÜçÂ§çËØµ‰∏ÄÈÅçÁªè‰πÖ‰∏çË°∞ÁöÑScaling Law: ÂèÇÊï∞Ë∂äÂ§ßÔºåËÆ≠ÁªÉÊï∞ÊçÆË∂äÂ§öÊ®°ÂûãÁöÑÊÄßËÉΩË∂äÂº∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö£ RoPEÈïøÂ∫¶Â§ñÊé®&lt;/h2&gt; 
&lt;p&gt;MiniMindÊîØÊåÅÈÄöËøáYaRNÁÆóÊ≥ïËøõË°åRoPE‰ΩçÁΩÆÁºñÁ†ÅÁöÑÈïøÂ∫¶Â§ñÊé®Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÂ§ÑÁêÜË∂ÖÂá∫ËÆ≠ÁªÉÈïøÂ∫¶ÁöÑÊñáÊú¨Â∫èÂàó„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂéüÁîütorchÊ®°ÂûãÂú®‰ΩøÁî®&lt;code&gt;eval_llm.py&lt;/code&gt;ËøõË°åÊé®ÁêÜÊó∂ÔºåÂè™ÈúÄÊ∑ªÂä†&lt;code&gt;--inference_rope_scaling&lt;/code&gt;ÂèÇÊï∞Âç≥ÂèØÂêØÁî®RoPEÂ§ñÊé®Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_llm.py --weight full_sft --inference_rope_scaling
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂØπ‰∫éTransformersÊ†ºÂºèÁöÑÊ®°ÂûãÔºåÂèØ‰ª•Âú®config.json‰∏≠Ê∑ªÂä†‰ª•‰∏ãÈÖçÁΩÆÂÆûÁé∞ÈïøÂ∫¶Â§ñÊé®Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"rope_scaling": {
    "type": "yarn",
    "factor": 16.0,
    "original_max_position_embeddings": 2048,
    "beta_fast": 32.0,
    "beta_slow": 1.0,
    "attention_factor": 1.0
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âú®MiniMind-SmallÊ®°Âûã‰∏äÔºåÊµãËØïËæìÂÖ•‰∏çÂêåÈïøÂ∫¶ÁöÑ„ÄåË•øÊ∏∏ËÆ∞„ÄçÁôΩËØùÊñáÂ∞èËØ¥ÔºåËØÑ‰º∞RoPE scalingÂâçÂêéÁöÑÂõ∞ÊÉëÂ∫¶(PPL)ÂØπÊØî„ÄÇ ÂèØ‰ª•ÁúãÂá∫ÔºåÂêØÁî®YaRNÂ§ñÊé®ÂêéÔºåÊ®°ÂûãÂú®ÈïøÊñáÊú¨‰∏äÁöÑPPLË°®Áé∞ÊòæËëó‰∏ãÈôçÔºö&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/rope_ppl.png" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö§ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;‰∏ãÈù¢Â∞±Âà∞ÂñúÈóª‰πêËßÅÁöÑbenchmarkÊµãËØïÁéØËäÇÔºåÂ∞±‰∏çÊâæ‰πêÂ≠êÂíåQwen„ÄÅGLMÁ∫ßÂà´ÁöÑÊ®°ÂûãÂÅöÂØπÊØî‰∫Ü„ÄÇ ËøôÈáåÈÄâÂèñ‰∫Ü‰∏Ä‰∫õÂæÆÂûãÊ®°ÂûãËøõË°åÊ®™ËØÑÊØîËæÉÔºå ÊµãËØïÈõÜÈÄâÊã©C-Eval„ÄÅCMMLU„ÄÅA-CLUE„ÄÅTMMLU+ËøôÂá†‰∏™Á∫Ø‰∏≠ÊñáËØ≠Ë®ÄÊ¶úÂçï„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÊµãËØÑÊ°ÜÊû∂&lt;/summary&gt; 
 &lt;p&gt;ÊµãËØÑÊ°ÜÊû∂ÈÄâÊã©&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;lm-evaluation&lt;/a&gt;Ôºå ÂÆâË£ÖÂêéÂêØÂä®ÊµãËØïÈùûÂ∏∏Êñπ‰æøÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;lm_eval --model hf --model_args pretrained=&amp;lt;Â°´ÂÜôÊ®°ÂûãË∑ØÂæÑ&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: Âú®ËøôÁßçÂÖ®ÊòØÈÄâÊã©È¢òÁöÑÊµãËØÑÈõÜ‰∏≠Ôºå‰∏∫‰∫ÜÈÅøÂÖçÂõûÂ§çÊ†ºÂºèÁöÑÈöæ‰ª•Âõ∫ÂÆöÁöÑÁâπÁÇπÔºå ÊâÄ‰ª•Â∏∏Áî®ÂÅöÊ≥ïÊòØÁõ¥Êé•Êää&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;Âõõ‰∏™Â≠óÊØçÂØπÂ∫îtokenÁöÑÈ¢ÑÊµãÊ¶ÇÁéáÂèñÂá∫Êù•ÔºåÂ∞ÜÂÖ∂‰∏≠Ê¶ÇÁéáÊúÄÂ§ßÁöÑÂ≠óÊØç‰∏éÊ†áÂáÜÁ≠îÊ°àËÆ°ÁÆóÊ≠£Á°ÆÁéá„ÄÇ ÈÄâÊã©È¢ò1/4‰π±ÈÄâÁöÑÊ≠£Á°ÆÁéáÊòØ25%ÔºåÁÑ∂ËÄåËøô‰∏™ÈáèÁ∫ßÁöÑÊâÄÊúâÊ®°ÂûãÈÉΩÈõÜ‰∏≠Âú®25ÈôÑËøëÔºåÁîöËá≥ÂæàÂ§öÊó∂ÂÄô‰∏çÂ¶ÇÁûéÈÄâÔºåÊòØ‰∏çÊòØÂÉèÊûÅ‰∫ÜÈ´ò‰∏≠ÂÆåÂΩ¢Â°´Á©∫ÁöÑÊªëÈìÅÂç¢Ê≠£Á°ÆÁéá... MiniMindÊ®°ÂûãÊú¨Ë∫´È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂ∞èÁöÑÂèØÊÄúÔºå‰πüÊ≤°ÊúâÈíàÂØπÊÄßÁöÑÂØπÊµãËØïÈõÜÂÅöÂà∑Ê¶úÂæÆË∞ÉÔºåÂõ†Ê≠§ÁªìÊûúÁ∫ØÂ®±‰πêÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;params‚Üì&lt;/th&gt; 
   &lt;th&gt;ceval‚Üë&lt;/th&gt; 
   &lt;th&gt;cmmlu‚Üë&lt;/th&gt; 
   &lt;th&gt;aclue‚Üë&lt;/th&gt; 
   &lt;th&gt;tmmlu+‚Üë&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zhanshijinwat/Steel-LLM"&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community/gpt2-medium"&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct"&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png" alt="compare_radar" /&gt;&lt;/p&gt; 
&lt;h1&gt;üìå Others&lt;/h1&gt; 
&lt;h2&gt;üîß Ê®°ÂûãËΩ¨Êç¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py"&gt;./scripts/convert_model.py&lt;/a&gt;ÂèØ‰ª•ÂÆûÁé∞&lt;code&gt;torch / transformers&lt;/code&gt;Ê®°ÂûãÁöÑ‰∫íÁõ∏ËΩ¨Êç¢&lt;/li&gt; 
 &lt;li&gt;Â¶ÇÊó†ÁâπÂà´ËØ¥ÊòéÔºå&lt;code&gt;MiniMind2&lt;/code&gt;Ê®°ÂûãÂùáÈªòËÆ§‰∏∫&lt;code&gt;Transformers&lt;/code&gt;Ê†ºÂºèÁöÑÊ®°ÂûãÔºåÈúÄÊèêÂâç&lt;code&gt;t2t&lt;/code&gt;ËΩ¨Êç¢ÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üñ•Ô∏è Âü∫‰∫éMiniMind-APIÊúçÂä°Êé•Âè£&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py"&gt;./scripts/serve_openai_api.py&lt;/a&gt;ÂÆåÊàê‰∫ÜÂÖºÂÆπopenai-apiÁöÑÊúÄÁÆÄËÅäÂ§©Êé•Âè£ÔºåÊñπ‰æøÂ∞ÜËá™Â∑±ÁöÑÊ®°ÂûãÊé•ÂÖ•Á¨¨‰∏âÊñπUI ‰æãÂ¶ÇFastGPT„ÄÅOpenWebUI„ÄÅDifyÁ≠âÁ≠â„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰ªé&lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;Huggingface&lt;/a&gt;‰∏ãËΩΩÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÔºåÊñá‰ª∂Ê†ëÔºö&lt;/p&gt; &lt;pre&gt;&lt;code&gt;minimind (root dir)
‚îú‚îÄ&amp;lt;MiniMind-Model-Name&amp;gt;Ôºà‰æãÂ¶ÇMiniMind2Ôºâ
|  ‚îú‚îÄ‚îÄ config.json
|  ‚îú‚îÄ‚îÄ generation_config.json
|  ‚îú‚îÄ‚îÄ model_minimind.py or w/o
|  ‚îú‚îÄ‚îÄ pytorch_model.bin or model.safetensors
|  ‚îú‚îÄ‚îÄ special_tokens_map.json
|  ‚îú‚îÄ‚îÄ tokenizer_config.json
|  ‚îú‚îÄ‚îÄ tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂêØÂä®ËÅäÂ§©ÊúçÂä°Á´Ø&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÊµãËØïÊúçÂä°Êé•Âè£&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;APIÊé•Âè£Á§∫‰æãÔºåÂÖºÂÆπopenai apiÊ†ºÂºè&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ÊòØ‰ªÄ‰πàÔºü" }
    ], 
    "temperature": 0.7, 
    "max_tokens": 512,
    "stream": true
}'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë®‚Äçüíª Êõ¥Â§ö&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/jingyaogong/minimind/discussions/618"&gt;üîó‰ªéMiniMind-LLMÂæÆË∞ÉÊâ©Êï£ËØ≠Ë®ÄÊ®°Âûã&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/jingyaogong/minimind/discussions/611"&gt;üîóÊ®°ÂûãÁöÑgenerateÊñπÊ≥ïËØ¥Êòé&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;img src="https://avatars.githubusercontent.com/u/136984999" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/vllm-project/vllm"&gt;vllm&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;vLLMÊòØÊûÅÂÖ∂ÊµÅË°åÁöÑÈ´òÊïàÊé®ÁêÜÊ°ÜÊû∂ÔºåÊîØÊåÅÂ§ßÊ®°ÂûãÂø´ÈÄüÈÉ®ÁΩ≤Ôºå‰ºòÂåñÊòæÂ≠òÂà©Áî®‰∏éÂêûÂêêÈáè„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰ª•openai-serveÂΩ¢ÂºèÂêØÂä® minimind2Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve ./MiniMind2 --model-impl transformers --served-model-name "minimind" --port 8998
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;llama.cppÊòØ‰∏Ä‰∏™C++Â∫ìÔºå ÂèØ‰ª•Âú®ÂëΩ‰ª§Ë°å‰∏ãÁõ¥Êé•‰ΩøÁî®ÔºåÊîØÊåÅÂ§öÁ∫øÁ®ãÊé®ÁêÜÔºåÊîØÊåÅGPUÂä†ÈÄü„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÁõÆÂΩïÁªìÊûÑ&lt;/strong&gt;ÔºöÂª∫ËÆÆÂ∞Üllama.cpp‰∏éminimindÊîæÂú®ÂêåÁ∫ßÁõÆÂΩï‰∏ã&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;parent/
‚îú‚îÄ‚îÄ minimind/          # MiniMindÈ°πÁõÆÁõÆÂΩï
‚îÇ   ‚îú‚îÄ‚îÄ MiniMind2/     # HuggingFaceÊ†ºÂºèMiniMind2Ê®°Âûã (ÂÖàconvert_model.pyÁîüÊàê)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.safetensors
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ trainer/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ llama.cpp/         # llama.cppÈ°πÁõÆÁõÆÂΩï
    ‚îú‚îÄ‚îÄ build/
    ‚îú‚îÄ‚îÄ convert_hf_to_gguf.py
    ‚îî‚îÄ‚îÄ ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;0„ÄÅÂèÇËÄÉ&lt;code&gt;llama.cpp&lt;/code&gt;ÂÆòÊñπÊ≠•È™§ËøõË°åinstall&lt;/p&gt; 
&lt;p&gt;1„ÄÅÂú®&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt;ÁöÑ&lt;code&gt;get_vocab_base_pre&lt;/code&gt;ÂáΩÊï∞ÊúÄÂêéÊèíÂÖ•Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Ê∑ªÂä†MiniMind tokenizerÊîØÊåÅÔºàËøôÈáåÈöè‰æøÂÜô‰∏Ä‰∏™‰æãÂ¶Çqwen2Âç≥ÂèØÔºâ
if res is None:
    res = "qwen2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2„ÄÅËΩ¨Êç¢Ëá™ËÆ≠ÁªÉÁöÑminimindÊ®°ÂûãÔºöhuggingface -&amp;gt; gguf&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®llama.cpp‰∏ãÊâßË°åÔºåÂ∞ÜÁîüÊàê../minimind/MiniMind2/MiniMind2-xxx.gguf
python convert_hf_to_gguf.py ../minimind/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3„ÄÅÈáèÂåñÊ≠§Ê®°Âûã (ÂèØÈÄâ)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-quantize ../minimind/MiniMind2/MiniMind2.gguf ../minimind/MiniMind2/Q4-MiniMind2.gguf Q4_K_M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;4„ÄÅÂëΩ‰ª§Ë°åÊé®ÁêÜÊµãËØï&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-cli -m ../minimind/MiniMind2/MiniMind2.gguf -sys "You are a helpful assistant" # system promptÂøÖÈ°ªÂõ∫ÂÆö
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://ollama.com/public/cloud.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://ollama.ai"&gt;ollama&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;ollamaÊòØÊú¨Âú∞ËøêË°åÂ§ßÊ®°ÂûãÁöÑÂ∑•ÂÖ∑ÔºåÊîØÊåÅÂ§öÁßçÂºÄÊ∫êLLMÔºåÁÆÄÂçïÊòìÁî®„ÄÇ&lt;/p&gt; 
&lt;p&gt;1„ÄÅÈÄöËøáollamaÂä†ËΩΩËá™ÂÆö‰πâÁöÑggufÊ®°Âûã&lt;/p&gt; 
&lt;p&gt;Âú®&lt;code&gt;MiniMind2&lt;/code&gt;‰∏ãÊñ∞Âª∫&lt;code&gt;minimind.modelfile&lt;/code&gt;ÔºåÂÜôÂÖ•Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;FROM ./Q4-MiniMind2.gguf

SYSTEM """You are a helpful assistant"""

TEMPLATE """&amp;lt;|im_start|&amp;gt;system
{{ .System }}&amp;lt;|im_end|&amp;gt;
&amp;lt;|im_start|&amp;gt;user
{{ .Prompt }}&amp;lt;|im_end|&amp;gt;
&amp;lt;|im_start|&amp;gt;assistant
{{ .Response }}&amp;lt;|im_end|&amp;gt;
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;2„ÄÅÂä†ËΩΩÂπ∂ÂëΩÂêçÊ≠§Ê®°Âûã‰∏∫&lt;code&gt;minimind-local&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f minimind.modelfile minimind-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;3„ÄÅÂêØÂä®Êé®ÁêÜ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama run minimind-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì§ Êé®ÈÄÅ‰Ω†ÁöÑÊ®°ÂûãÂà∞ Ollama Hub&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ‰∏∫Êú¨Âú∞Ê®°ÂûãÈáçÂëΩÂêç‰∏∫‰Ω†ÁöÑollama-account/minimindÁöÑtag
ollama cp minimind-local:latest your_username/minimind:latest

# 2. Êé®ÈÄÅÊ®°Âûã
ollama push your_username/minimind:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;p&gt;‚≠êÔ∏è ‰πüÂèØÁõ¥Êé•‰ΩøÁî®ÊàëÊèê‰æõÁöÑollamaÊ®°Âûã‰∏ÄÈîÆÂêØÂä®Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama run jingyaogong/minimind2 # ÂÖ∂‰ªñÂèØÈÄâ minimind2-r1 / minimind2-small / minimind2-small-r1
&amp;gt;&amp;gt;&amp;gt; ‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠ó
ÊàëÊòØ‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°Âûã...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;img src="https://github.com/alibaba/MNN/raw/master/doc/banner.png" height="28" style="vertical-align: middle;" /&gt; &lt;a href="https://github.com/alibaba/MNN"&gt;MNN&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;MNNÊòØÈù¢ÂêëÁ´Ø‰æßÁöÑAIÊé®ÁêÜÂºïÊìéÔºåÊîØÊåÅÂ§öÁßçÂºÄÊ∫êLLMÊ®°ÂûãÊé®ÁêÜÔºåËΩªÈáèÂåñ„ÄÅÈ´òÊÄßËÉΩ„ÄÇ&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ê®°ÂûãËΩ¨Êç¢&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;cd MNN/transformers/llm/export
# ÂØºÂá∫4bit HQQÈáèÂåñÁöÑMNNÊ®°Âûã
python llmexport.py --path /path/to/MiniMind2/  --export mnn --hqq --dst_path MiniMind2-MNN
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Âú®MacÊàñÊâãÊú∫‰∏äÊµãËØï&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;./llm_demo /path/to/MiniMind2-MNN/config.json prompt.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊàñËÄÖ‰∏ãËΩΩAPPÊµãËØï&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ª•‰∏ä‰∏âÊñπÊ°ÜÊû∂ÁöÑÊõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂØπÂ∫îÂÆòÊñπÊñáÊ°£üòä&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;üìå Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Â¶ÇÊûúËßâÂæó&lt;code&gt;MiniMindÁ≥ªÂàó&lt;/code&gt;ÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÂèØ‰ª•Âú® GitHub ‰∏äÂä†‰∏Ä‰∏™‚≠ê&lt;br /&gt; ÁØáÂπÖË∂ÖÈïøÊ∞¥Âπ≥ÊúâÈôêÈöæÂÖçÁ∫∞ÊºèÔºåÊ¨¢ËøéÂú®Issues‰∫§ÊµÅÊåáÊ≠£ÊàñÊèê‰∫§PRÊîπËøõÈ°πÁõÆ&lt;br /&gt; ÊÇ®ÁöÑÂ∞èÂ∞èÊîØÊåÅÂ∞±ÊòØÊåÅÁª≠ÊîπËøõÊ≠§È°πÁõÆÁöÑÂä®ÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;Ë¥°ÁåÆËÄÖ&lt;/a&gt;&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=jingyaogong/minimind" /&gt; &lt;/a&gt; 
&lt;h2&gt;üòäÈ∏£Ë∞¢&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ipfgao"&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/26"&gt;üîóËÆ≠ÁªÉÊ≠•È™§ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/WangRongsheng"&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/39"&gt;üîóÂ§ßÂûãÊï∞ÊçÆÈõÜÈ¢ÑÂ§ÑÁêÜ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pengqianhan"&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/73"&gt;üîó‰∏Ä‰∏™ÁÆÄÊòéÊïôÁ®ã&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RyanSunn"&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/75"&gt;üîóÊé®ÁêÜËøáÁ®ãÂ≠¶‰π†ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Nijikadesu"&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/213"&gt;üîó‰ª•‰∫§‰∫íÁ¨îËÆ∞Êú¨ÊñπÂºèÂàÜËß£È°πÁõÆ‰ª£Á†Å&lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;ÂèÇËÄÉÈìæÊé• &amp;amp; ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑËÆ∫ÊñáÊàñÈ°πÁõÆ&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÊéíÂêç‰∏çÂàÜ‰ªª‰ΩïÂÖàÂêéÈ°∫Â∫è&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/karpathy/llama2.c"&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.04434"&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wdndev/tiny-llm-zh"&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2401.04088"&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Tongjilibo/build_MiniLLM_from_scratch"&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AI-Study-Han/Zero-Chatgpt"&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xusenlinzy/api-for-open-llm"&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü´∂ÊîØÊåÅËÄÖ&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/stars/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/network/members"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/forks/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h2&gt;üéâ Awesome Work using MiniMind&lt;/h2&gt; 
&lt;p&gt;Êú¨Ê®°ÂûãÊäõÁ†ñÂºïÁéâÂú∞‰øÉÊàê‰∫Ü‰∏Ä‰∫õÂèØÂñúÊàêÊûúÁöÑËêΩÂú∞ÔºåÊÑüË∞¢Á†îÁ©∂ËÄÖ‰ª¨ÁöÑËÆ§ÂèØÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ECG-Expert-QA: A Benchmark for Evaluating Medical Large Language Models in Heart Disease Diagnosis [&lt;a href="https://arxiv.org/pdf/2502.17475"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Binary-Integer-Programming Based Algorithm for Expert Load Balancing in Mixture-of-Experts Models [&lt;a href="https://arxiv.org/pdf/2502.15451"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text [&lt;a href="https://arxiv.org/pdf/2505.24826"&gt;arxiv&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;On the Generalization Ability of Next-Token-Prediction Pretraining [&lt;a href="https://openreview.net/forum?id=hLGJ1qZPdu"&gt;ICML 2025&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;„Ää‰ªéÈõ∂ÂºÄÂßãÂÜôÂ§ßÊ®°ÂûãÔºö‰ªéÁ•ûÁªèÁΩëÁªúÂà∞Transformer„ÄãÁéãÂèå„ÄÅÁâüÊô®„ÄÅÁéãÊòäÊÄ° ÁºñËëó - Ê∏ÖÂçéÂ§ßÂ≠¶Âá∫ÁâàÁ§æ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;FedBRB: A Solution to the Small-to-Large Scenario in Device-Heterogeneity Federated Learning [&lt;a href="https://ieeexplore.ieee.org/abstract/document/11168259"&gt;TMC 2025&lt;/a&gt;]&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ËøõË°å‰∏≠...&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üéì Citation&lt;/h1&gt; 
&lt;p&gt;If you find MiniMind helpful in your research or work, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{minimind,
  title={MiniMind: Train a Tiny LLM from scratch},
  author={Jingyao Gong},
  year={2024},
  howpublished={https://github.com/jingyaogong/minimind}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄ n8n Workflow Collection&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/n8n-Workflows-orange?style=for-the-badge&amp;amp;logo=n8n" alt="n8n Workflows" /&gt; &lt;img src="https://img.shields.io/badge/Workflows-4343+-blue?style=for-the-badge" alt="Workflows" /&gt; &lt;img src="https://img.shields.io/badge/Integrations-365+-green?style=for-the-badge" alt="Integrations" /&gt; &lt;img src="https://img.shields.io/badge/License-MIT-purple?style=for-the-badge" alt="License" /&gt; &lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;üåü The Ultimate Collection of n8n Automation Workflows&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://zie619.github.io/n8n-workflows"&gt;üîç Browse Online&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#documentation"&gt;üìö Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#contributing"&gt;ü§ù Contributing&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/#license"&gt;üìÑ License&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ú® What's New&lt;/h2&gt; 
&lt;h3&gt;üéâ Latest Updates (November 2025)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Enhanced Security&lt;/strong&gt;: Full security audit completed, all CVEs resolved&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üê≥ Docker Support&lt;/strong&gt;: Multi-platform builds for linux/amd64 and linux/arm64&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä GitHub Pages&lt;/strong&gt;: Live searchable interface at &lt;a href="https://zie619.github.io/n8n-workflows"&gt;zie619.github.io/n8n-workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Performance&lt;/strong&gt;: 100x faster search with SQLite FTS5 integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Modern UI&lt;/strong&gt;: Completely redesigned interface with dark/light mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåê Quick Access&lt;/h2&gt; 
&lt;h3&gt;üî• Use Online (No Installation)&lt;/h3&gt; 
&lt;p&gt;Visit &lt;strong&gt;&lt;a href="https://zie619.github.io/n8n-workflows"&gt;zie619.github.io/n8n-workflows&lt;/a&gt;&lt;/strong&gt; for instant access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Smart Search&lt;/strong&gt; - Find workflows instantly&lt;/li&gt; 
 &lt;li&gt;üìÇ &lt;strong&gt;15+ Categories&lt;/strong&gt; - Browse by use case&lt;/li&gt; 
 &lt;li&gt;üì± &lt;strong&gt;Mobile Ready&lt;/strong&gt; - Works on any device&lt;/li&gt; 
 &lt;li&gt;‚¨áÔ∏è &lt;strong&gt;Direct Downloads&lt;/strong&gt; - Get workflow JSONs instantly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;üìä By The Numbers&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;4,343&lt;/strong&gt; Production-Ready Workflows&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;365&lt;/strong&gt; Unique Integrations&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;29,445&lt;/strong&gt; Total Nodes&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;15&lt;/strong&gt; Organized Categories&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;100%&lt;/strong&gt; Import Success Rate&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;‚ö° Performance&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;&amp;lt; 100ms&lt;/strong&gt; Search Response&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;&amp;lt; 50MB&lt;/strong&gt; Memory Usage&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;700x&lt;/strong&gt; Smaller Than v1&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;10x&lt;/strong&gt; Faster Load Times&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;40x&lt;/strong&gt; Less RAM Usage&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üíª Local Installation&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.9+&lt;/li&gt; 
 &lt;li&gt;pip (Python package manager)&lt;/li&gt; 
 &lt;li&gt;100MB free disk space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/Zie619/n8n-workflows.git
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start the server
python run.py

# Open in browser
# http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üê≥ Docker Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using Docker Hub
docker run -p 8000:8000 zie619/n8n-workflows:latest

# Or build locally
docker build -t n8n-workflows .
docker run -p 8000:8000 n8n-workflows
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;h3&gt;API Endpoints&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Web interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Search workflows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/stats&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Repository statistics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/workflow/{id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Get workflow JSON&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;List all categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/export&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Export workflows&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Search Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full-text search&lt;/strong&gt; across names, descriptions, and nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Category filtering&lt;/strong&gt; (Marketing, Sales, DevOps, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity filtering&lt;/strong&gt; (Low, Medium, High)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trigger type filtering&lt;/strong&gt; (Webhook, Schedule, Manual, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service filtering&lt;/strong&gt; (365+ integrations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;graph LR
    A[User] --&amp;gt; B[Web Interface]
    B --&amp;gt; C[FastAPI Server]
    C --&amp;gt; D[SQLite FTS5]
    D --&amp;gt; E[Workflow Database]
    C --&amp;gt; F[Static Files]
    F --&amp;gt; G[Workflow JSONs]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tech Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: Python, FastAPI, SQLite with FTS5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: Vanilla JS, Tailwind CSS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with Full-Text Search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Docker, GitHub Actions, GitHub Pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Trivy scanning, CORS protection, Input validation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÇ Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;n8n-workflows/
‚îú‚îÄ‚îÄ workflows/           # 4,343 workflow JSON files
‚îÇ   ‚îî‚îÄ‚îÄ [category]/     # Organized by integration
‚îú‚îÄ‚îÄ docs/               # GitHub Pages site
‚îú‚îÄ‚îÄ src/                # Python source code
‚îú‚îÄ‚îÄ scripts/            # Utility scripts
‚îú‚îÄ‚îÄ api_server.py       # FastAPI application
‚îú‚îÄ‚îÄ run.py              # Server launcher
‚îú‚îÄ‚îÄ workflow_db.py      # Database manager
‚îî‚îÄ‚îÄ requirements.txt    # Python dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions! Here's how you can help:&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report bugs&lt;/strong&gt; via &lt;a href="https://github.com/Zie619/n8n-workflows/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;strong&gt;Suggest features&lt;/strong&gt; in &lt;a href="https://github.com/Zie619/n8n-workflows/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Improve documentation&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Submit workflow fixes&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚≠ê &lt;strong&gt;Star the repository&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fork and clone
git clone https://github.com/YOUR_USERNAME/n8n-workflows.git

# Create branch
git checkout -b feature/amazing-feature

# Make changes and test
python run.py --debug

# Commit and push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/amazing-feature

# Open PR
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîí Security&lt;/h2&gt; 
&lt;h3&gt;Security Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Path traversal protection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Input validation &amp;amp; sanitization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;CORS protection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Rate limiting&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Docker security hardening&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Non-root container user&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Regular security scanning&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reporting Security Issues&lt;/h3&gt; 
&lt;p&gt;Please report security vulnerabilities to the maintainers via &lt;a href="https://github.com/Zie619/n8n-workflows/security/advisories/new"&gt;Security Advisory&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2025 Zie619

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üíñ Support&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, please consider:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black" alt="Buy Me a Coffee" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Zie619/n8n-workflows"&gt;&lt;img src="https://img.shields.io/badge/Star%20on%20GitHub-181717?style=for-the-badge&amp;amp;logo=github" alt="Star on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/Follow-1DA1F2?style=for-the-badge&amp;amp;logo=twitter&amp;amp;logoColor=white" alt="Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Stats &amp;amp; Badges&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/Zie619/n8n-workflows?style=social" alt="GitHub stars" /&gt; &lt;img src="https://img.shields.io/github/forks/Zie619/n8n-workflows?style=social" alt="GitHub forks" /&gt; &lt;img src="https://img.shields.io/github/watchers/Zie619/n8n-workflows?style=social" alt="GitHub watchers" /&gt; &lt;img src="https://img.shields.io/github/issues/Zie619/n8n-workflows" alt="GitHub issues" /&gt; &lt;img src="https://img.shields.io/github/issues-pr/Zie619/n8n-workflows" alt="GitHub pull requests" /&gt; &lt;img src="https://img.shields.io/github/last-commit/Zie619/n8n-workflows" alt="GitHub last commit" /&gt; &lt;img src="https://img.shields.io/github/repo-size/Zie619/n8n-workflows" alt="GitHub repo size" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n&lt;/strong&gt; - For creating an amazing automation platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributors&lt;/strong&gt; - Everyone who has helped improve this collection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community&lt;/strong&gt; - For feedback and support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;You&lt;/strong&gt; - For using and supporting this project!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;‚≠ê Star us on GitHub ‚Äî it motivates us a lot!&lt;/h3&gt; 
 &lt;p&gt;Made with ‚ù§Ô∏è by &lt;a href="https://github.com/Zie619"&gt;Zie619&lt;/a&gt; and &lt;a href="https://github.com/Zie619/n8n-workflows/graphs/contributors"&gt;contributors&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>serengil/deepface</title>
      <link>https://github.com/serengil/deepface</link>
      <description>&lt;p&gt;A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;deepface&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/project/deepface"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/deepface?period=total&amp;amp;units=international_system&amp;amp;left_color=grey&amp;amp;right_color=blue&amp;amp;left_text=downloads" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/serengil/deepface/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/serengil/deepface?color=yellow&amp;amp;style=flat&amp;amp;label=%E2%AD%90%20stars" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/serengil/deepface"&gt;&lt;img src="https://img.shields.io/docker/pulls/serengil/deepface?logo=docker" alt="Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/serengil/deepface/raw/master/LICENSE"&gt;&lt;img src="http://img.shields.io/:license-MIT-green.svg?style=flat" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/serengil/deepface/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/serengil/deepface/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://doi.org/10.17671/gazibtd.1399077"&gt;&lt;img src="http://img.shields.io/:DOI-10.17671/gazibtd.1399077-blue.svg?style=flat" alt="DOI" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://sefiks.com"&gt;&lt;img src="https://img.shields.io/:blog-sefiks.com-blue.svg?style=flat&amp;amp;logo=wordpress" alt="Blog" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@sefiks?sub_confirmation=1"&gt;&lt;img src="https://img.shields.io/:youtube-@sefiks-red.svg?style=flat&amp;amp;logo=youtube" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/user?screen_name=serengil"&gt;&lt;img src="https://img.shields.io/:follow-@serengil-blue.svg?style=flat&amp;amp;logo=x" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.patreon.com/serengil?repo=deepface"&gt;&lt;img src="https://img.shields.io/:become-patron-f96854.svg?style=flat&amp;amp;logo=patreon" alt="Patreon" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/serengil"&gt;&lt;img src="https://img.shields.io/github/sponsors/serengil?logo=GitHub&amp;amp;color=lightgray" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/serengil"&gt;&lt;img src="https://img.shields.io/badge/-buy_me_a%C2%A0coffee-gray?logo=buy-me-a-coffee" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!--
[![Hacker News](https://img.shields.io/badge/dynamic/json?color=orange&amp;label=Hacker%20News&amp;query=score&amp;url=https%3A%2F%2Fhacker-news.firebaseio.com%2Fv0%2Fitem%2F46608519.json&amp;logo=y-combinator)](https://news.ycombinator.com/item?id=46608519)
--&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/4227" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4227" alt="serengil%2Fdeepface | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-icon-labeled.png" width="200" height="240" /&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace is a lightweight &lt;a href="https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"&gt;face recognition&lt;/a&gt; and facial attribute analysis (&lt;a href="https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/"&gt;age&lt;/a&gt;, &lt;a href="https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/"&gt;gender&lt;/a&gt;, &lt;a href="https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/"&gt;emotion&lt;/a&gt; and &lt;a href="https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/"&gt;race&lt;/a&gt;) framework for python. It is a hybrid face recognition framework wrapping &lt;strong&gt;state-of-the-art&lt;/strong&gt; models: &lt;a href="https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"&gt;&lt;code&gt;VGG-Face&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/"&gt;&lt;code&gt;FaceNet&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/"&gt;&lt;code&gt;OpenFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/"&gt;&lt;code&gt;DeepFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/"&gt;&lt;code&gt;DeepID&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/"&gt;&lt;code&gt;ArcFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/"&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;SFace&lt;/code&gt;, &lt;code&gt;GhostFaceNet&lt;/code&gt;, &lt;code&gt;Buffalo_L&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/"&gt;A modern face recognition pipeline&lt;/a&gt; consists of 5 common stages: &lt;a href="https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/"&gt;detect&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/"&gt;align&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/11/20/facial-landmarks-for-face-recognition-with-dlib/"&gt;normalize&lt;/a&gt;, &lt;a href="https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"&gt;represent&lt;/a&gt; and &lt;a href="https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/"&gt;verify&lt;/a&gt;. While DeepFace handles all these common stages in the background, you don‚Äôt need to acquire in-depth knowledge about all the processes behind it. You can just call its verification, find or analysis function with a single line of code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/serengil/deepface/tree/master/benchmarks"&gt;&lt;code&gt;Experiments&lt;/code&gt;&lt;/a&gt; show that &lt;strong&gt;human beings have 97.53% accuracy&lt;/strong&gt; on facial recognition tasks whereas those models already reached and passed that accuracy level.&lt;/p&gt; 
&lt;h2&gt;Installation &lt;a href="https://pypi.org/project/deepface/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepface.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The easiest way to install deepface is to download it from &lt;a href="https://pypi.org/project/deepface/"&gt;&lt;code&gt;PyPI&lt;/code&gt;&lt;/a&gt;. It's going to install the library itself and its prerequisites as well.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ pip install deepface
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can also install deepface from its source code. Source code may have new features not published in pip release yet.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ git clone https://github.com/serengil/deepface.git
$ cd deepface
$ pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once you installed the library, then you will be able to import it and use its functionalities.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepface import DeepFace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Face Verification&lt;/strong&gt; - &lt;a href="https://youtu.be/KRCvkNCOphE"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This function determines whether two facial images belong to the same person or to different individuals. The function returns a dictionary, where the key of interest is &lt;code&gt;verified&lt;/code&gt;: True indicates the images are of the same person, while False means they are of different people.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result: dict = DeepFace.verify(img1_path = "img1.jpg", img2_path = "img2.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/verify-credit.jpg" width="99%" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Face recognition&lt;/strong&gt; - &lt;a href="https://sefiks.com/2026/01/01/introducing-brand-new-face-recognition-in-deepface/"&gt;&lt;code&gt;Tutorial&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/Hrjp-EStM_s"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://sefiks.com/2020/05/25/large-scale-face-recognition-for-deep-learning/"&gt;Face recognition&lt;/a&gt; requires applying face verification many times. DeepFace provides an out-of-the-box &lt;code&gt;find&lt;/code&gt; function that searches for the identity of an input image within a specified database path.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;dfs: List[pd.DataFrame] = DeepFace.find(img_path = "img1.jpg", db_path = "C:/my_db")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-6-v2.jpg" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;Here, the &lt;code&gt;find&lt;/code&gt; function relies on a directory-based face datastore and stores embeddings on disk. Alternatively, DeepFace provides a database-backed &lt;a href="https://sefiks.com/2026/01/01/introducing-brand-new-face-recognition-in-deepface/"&gt;&lt;code&gt;search&lt;/code&gt;&lt;/a&gt; functionality where embeddings are explicitly registered and queried. Currently, &lt;a href="https://sefiks.com/2023/06/22/vector-similarity-search-in-postgresql/"&gt;postgres&lt;/a&gt;, &lt;a href="https://sefiks.com/2021/01/22/deep-face-recognition-with-mongodb/"&gt;mongo&lt;/a&gt;, &lt;a href="https://sefiks.com/2021/04/03/deep-face-recognition-with-neo4j/"&gt;neo4j&lt;/a&gt;, &lt;a href="https://sefiks.com/2024/07/05/postgres-as-a-vector-database-billion-scale-vector-similarity-search-with-pgvector/"&gt;pgvector&lt;/a&gt;, &lt;a href="https://sefiks.com/2021/05/19/large-scale-face-recognition-with-pinecone-vector-database/"&gt;pinecone&lt;/a&gt; and weaviate are supported as backend databases.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# register an image into the database
DeepFace.register(img = "img1.jpg")

# perform exact search
dfs: List[pd.DataFrame] = DeepFace.search(img = "target.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to perform &lt;a href="https://sefiks.com/2023/12/31/a-step-by-step-approximate-nearest-neighbor-example-in-python-from-scratch/"&gt;&lt;code&gt;approximate nearest neighbor&lt;/code&gt;&lt;/a&gt; search instead of exact search to achieve faster results on &lt;a href="https://www.youtube.com/playlist?list=PLsS_1RYmYQQGSJu_Z3OVhXhGmZ86_zuIm"&gt;large-scale databases&lt;/a&gt;, you can build an index beforehand and explicitly enable ANN search. Here, &lt;a href="https://sefiks.com/2020/09/17/large-scale-face-recognition-with-facebook-faiss/"&gt;Faiss&lt;/a&gt; is used to index embeddings in postgres and mongo; whereas vector databases such as pgvector, weaviate, pinecone and neo4j handle indexing internally.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# build index on registered embeddings (for postgres and mongo only)
DeepFace.build_index()

# perform approximate nearest neighbor search
dfs: List[pd.DataFrame] = DeepFace.search(img = "target.jpg", search_method = "ann")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Facial Attribute Analysis&lt;/strong&gt; - &lt;a href="https://youtu.be/GT2UeN85BdA"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace also comes with a strong facial attribute analysis module including &lt;a href="https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/"&gt;&lt;code&gt;age&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/"&gt;&lt;code&gt;gender&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/"&gt;&lt;code&gt;facial expression&lt;/code&gt;&lt;/a&gt; (including angry, fear, neutral, sad, disgust, happy and surprise) and &lt;a href="https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/"&gt;&lt;code&gt;race&lt;/code&gt;&lt;/a&gt; (including asian, white, middle eastern, indian, latino and black) predictions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;objs: List[dict] = DeepFace.analyze(
  img_path = "img4.jpg", actions = ['age', 'gender', 'race', 'emotion']
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-2.jpg" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;Age model got ¬± 4.65 MAE; gender model got 97.44% accuracy, 96.29% precision and 95.05% recall as mentioned in its &lt;a href="https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/"&gt;tutorial&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Real Time Analysis&lt;/strong&gt; - &lt;a href="https://youtu.be/-c9sSJcx6wI"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/IXoah6rhxac"&gt;&lt;code&gt;React Demo part-i&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/_waBA-cH2D4"&gt;&lt;code&gt;React Demo part-ii&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can run deepface for real time videos as well. Stream function will access your webcam and apply both face recognition and facial attribute analysis. The function starts to analyze a frame if it can focus a face sequentially 5 frames. Then, it shows results 5 seconds.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;DeepFace.stream(db_path = "C:/database")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-3.jpg" width="90%" /&gt;&lt;/p&gt; 
&lt;p&gt;Even though face recognition is based on one-shot learning, you can use multiple face pictures of a person as well. You should rearrange your directory structure as illustrated below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;user
‚îú‚îÄ‚îÄ database
‚îÇ   ‚îú‚îÄ‚îÄ Alice
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Alice1.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Alice2.jpg
‚îÇ   ‚îú‚îÄ‚îÄ Bob
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Bob.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you intend to perform face verification or analysis tasks directly from your browser, &lt;a href="https://github.com/serengil/deepface-react-ui"&gt;&lt;code&gt;deepface-react-ui&lt;/code&gt;&lt;/a&gt; is a separate repository built using ReactJS depending on deepface api.&lt;/p&gt; 
&lt;p&gt;Here, you can also find some real time demos for various facial recognition models:&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/refs/heads/master/icon/deepface-realtime.jpg" width="90%" /&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Demo&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facial Recognition&lt;/td&gt; 
   &lt;td&gt;DeepFace&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/YjYIMs5ZOfc"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facial Recognition&lt;/td&gt; 
   &lt;td&gt;FaceNet&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/vB1I5vWgTQg"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facial Recognition&lt;/td&gt; 
   &lt;td&gt;VGG-Face&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/tSU_lNi0gQQ"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facial Recognition&lt;/td&gt; 
   &lt;td&gt;OpenFace&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/-4z2sL6wzP8"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Age &amp;amp; Gender&lt;/td&gt; 
   &lt;td&gt;Default&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/tFI7vZn3P7E"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Race &amp;amp; Ethnicity&lt;/td&gt; 
   &lt;td&gt;Default&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/-ztiy5eJha8"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Emotion&lt;/td&gt; 
   &lt;td&gt;Default&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/Y7DfLvLKScs"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Celebrity Look-Alike&lt;/td&gt; 
   &lt;td&gt;Default&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/RMgIKU1H8DY"&gt;&lt;code&gt;Video&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Embeddings&lt;/strong&gt; - &lt;a href="https://sefiks.com/2025/06/28/what-are-vector-embeddings-and-why-they-matter-in-ai/"&gt;&lt;code&gt;Tutorial&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/OYialFo7Qo4"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Face recognition models basically represent facial images as multi-dimensional vectors. Sometimes, you need those embedding vectors directly. DeepFace comes with a dedicated representation function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;embedding_objs: List[dict] = DeepFace.represent(img_path = "img.jpg")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Embeddings can be &lt;a href="https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/"&gt;plotted&lt;/a&gt; as below. Each slot is corresponding to a dimension value and dimension value is emphasized with colors. Similar to 2D barcodes, vertical dimension stores no information in the illustration.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/embedding.jpg" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;In summary, the distance between vector embeddings of the same person should be smaller than that between embeddings of different people. When reduced to two-dimensional space, the clusters become clearly distinguishable.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/refs/heads/master/icon/facenet-pca.png" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Face recognition models&lt;/strong&gt; - &lt;a href="https://youtu.be/eKOZawGR3y0"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace is a &lt;strong&gt;hybrid&lt;/strong&gt; face recognition package. It currently wraps many &lt;strong&gt;state-of-the-art&lt;/strong&gt; face recognition models: &lt;a href="https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"&gt;&lt;code&gt;VGG-Face&lt;/code&gt;&lt;/a&gt; , &lt;a href="https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/"&gt;&lt;code&gt;FaceNet&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/"&gt;&lt;code&gt;OpenFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/"&gt;&lt;code&gt;DeepFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/"&gt;&lt;code&gt;DeepID&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/"&gt;&lt;code&gt;ArcFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/"&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;SFace&lt;/code&gt;, &lt;code&gt;GhostFaceNet&lt;/code&gt; and &lt;code&gt;Buffalo_L&lt;/code&gt;. The default configuration uses VGG-Face model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;models = [
    "VGG-Face", "Facenet", "Facenet512", "OpenFace", "DeepFace",
    "DeepID", "ArcFace", "Dlib", "SFace", "GhostFaceNet",
    "Buffalo_L",
]

result = DeepFace.verify(
  img1_path = "img1.jpg", img2_path = "img2.jpg", model_name = models[0]
)

dfs = DeepFace.find(
  img_path = "img1.jpg", db_path = "C:/my_db", model_name = models[1]
)

embeddings = DeepFace.represent(
  img_path = "img.jpg", model_name = models[2]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/model-portfolio-20240316.jpg" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;FaceNet, VGG-Face, ArcFace and Dlib are overperforming ones based on experiments - see &lt;a href="https://github.com/serengil/deepface/tree/master/benchmarks"&gt;&lt;code&gt;BENCHMARKS&lt;/code&gt;&lt;/a&gt; for more details. You can find the measured scores of various models in DeepFace and the reported scores from their original studies in the following table.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Measured Score&lt;/th&gt; 
   &lt;th&gt;Declared Score&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facenet512&lt;/td&gt; 
   &lt;td&gt;98.4%&lt;/td&gt; 
   &lt;td&gt;99.6%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Human-beings&lt;/td&gt; 
   &lt;td&gt;97.5%&lt;/td&gt; 
   &lt;td&gt;97.5%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facenet&lt;/td&gt; 
   &lt;td&gt;97.4%&lt;/td&gt; 
   &lt;td&gt;99.2%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dlib&lt;/td&gt; 
   &lt;td&gt;96.8%&lt;/td&gt; 
   &lt;td&gt;99.3 %&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VGG-Face&lt;/td&gt; 
   &lt;td&gt;96.7%&lt;/td&gt; 
   &lt;td&gt;98.9%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ArcFace&lt;/td&gt; 
   &lt;td&gt;96.7%&lt;/td&gt; 
   &lt;td&gt;99.5%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GhostFaceNet&lt;/td&gt; 
   &lt;td&gt;93.3%&lt;/td&gt; 
   &lt;td&gt;99.7%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SFace&lt;/td&gt; 
   &lt;td&gt;93.0%&lt;/td&gt; 
   &lt;td&gt;99.5%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenFace&lt;/td&gt; 
   &lt;td&gt;78.7%&lt;/td&gt; 
   &lt;td&gt;92.9%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepFace&lt;/td&gt; 
   &lt;td&gt;69.0%&lt;/td&gt; 
   &lt;td&gt;97.3%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepID&lt;/td&gt; 
   &lt;td&gt;66.5%&lt;/td&gt; 
   &lt;td&gt;97.4%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Conducting experiments with those models within DeepFace may reveal disparities compared to the original studies, owing to the adoption of distinct detection or normalization techniques. Furthermore, some models have been released solely with their backbones, lacking pre-trained weights. Thus, we are utilizing their re-implementations instead of the original pre-trained weights.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Face Detection and Alignment&lt;/strong&gt; - &lt;a href="https://youtu.be/GZ2p2hj2H5k"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Face detection and alignment are important early stages of a modern face recognition pipeline. &lt;a href="https://github.com/serengil/deepface/tree/master/benchmarks"&gt;Experiments&lt;/a&gt; show that detection increases the face recognition accuracy up to 42%, while alignment increases it up to 6%. &lt;a href="https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/"&gt;&lt;code&gt;OpenCV&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/"&gt;&lt;code&gt;Ssd&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/"&gt;&lt;code&gt;Dlib&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/"&gt;&lt;code&gt;MtCnn&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Faster MtCnn&lt;/code&gt;, &lt;a href="https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/"&gt;&lt;code&gt;RetinaFace&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2022/01/14/deep-face-detection-with-mediapipe/"&gt;&lt;code&gt;MediaPipe&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;Yolo&lt;/code&gt;, &lt;code&gt;YuNet&lt;/code&gt; and &lt;code&gt;CenterFace&lt;/code&gt; detectors are wrapped in deepface.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-portfolio-v6.jpg" width="95%" /&gt;&lt;/p&gt; 
&lt;p&gt;All deepface functions accept optional detector backend and align input arguments. You can switch among those detectors and alignment modes with these arguments. OpenCV is the default detector and alignment is on by default.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;backends = [
    'opencv', 'ssd', 'dlib', 'mtcnn', 'fastmtcnn',
    'retinaface', 'mediapipe', 'yolov8n', 'yolov8m', 
    'yolov8l', 'yolov11n', 'yolov11s', 'yolov11m',
    'yolov11l', 'yolov12n', 'yolov12s', 'yolov12m',
    'yolov12l', 'yunet', 'centerface',
]
detector = backends[3]
align = True

obj = DeepFace.verify(
  img1_path = "img1.jpg", img2_path = "img2.jpg", detector_backend = detector, align = align
)

dfs = DeepFace.find(
  img_path = "img.jpg", db_path = "my_db", detector_backend = detector, align = align
)

embedding_objs = DeepFace.represent(
  img_path = "img.jpg", detector_backend = detector, align = align
)

demographies = DeepFace.analyze(
  img_path = "img4.jpg", detector_backend = detector, align = align
)

face_objs = DeepFace.extract_faces(
  img_path = "img.jpg", detector_backend = detector, align = align
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Face recognition models are actually CNN models and they expect standard sized inputs. So, resizing is required before representation. To avoid deformation, deepface adds black padding pixels according to the target size argument after detection and alignment.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/detector-outputs-20240414.jpg" width="90%" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/"&gt;RetinaFace&lt;/a&gt; and &lt;a href="https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/"&gt;MtCnn&lt;/a&gt; seem to overperform in detection and alignment stages but they are much slower. If the speed of your pipeline is more important, then you should use opencv or ssd. On the other hand, if you consider the accuracy, then you should use retinaface or mtcnn.&lt;/p&gt; 
&lt;p&gt;The performance of RetinaFace is very satisfactory even in the crowd as seen in the following illustration. Besides, it comes with an incredible facial landmark detection performance. Highlighted red points show some facial landmarks such as eyes, nose and mouth. That's why, alignment score of RetinaFace is high as well.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/retinaface-results.jpeg" width="90%" /&gt; &lt;br /&gt;&lt;em&gt;The Yellow Angels - Fenerbahce Women's Volleyball Team&lt;/em&gt; &lt;/p&gt; 
&lt;p&gt;You can find out more about RetinaFace on this &lt;a href="https://github.com/serengil/retinaface"&gt;repo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Face Anti Spoofing&lt;/strong&gt; - &lt;a href="https://youtu.be/UiK1aIjOBlQ"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace also includes an anti-spoofing analysis module to understand given image is real or fake. To activate this feature, set the &lt;code&gt;anti_spoofing&lt;/code&gt; argument to True in any DeepFace tasks.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/face-anti-spoofing.jpg" width="40%" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# anti spoofing test in face detection
face_objs = DeepFace.extract_faces(img_path="dataset/img1.jpg", anti_spoofing = True)
assert all(face_obj["is_real"] is True for face_obj in face_objs)

# anti spoofing test in real time analysis
DeepFace.stream(db_path = "C:/database", anti_spoofing = True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Similarity&lt;/strong&gt; - &lt;a href="https://youtu.be/1EPoS69fHOc"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Face recognition models are regular &lt;a href="https://sefiks.com/2018/03/23/convolutional-autoencoder-clustering-images-with-neural-networks/"&gt;convolutional neural networks&lt;/a&gt; and they are responsible to represent faces as vectors. We expect that a face pair of same person should be &lt;a href="https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/"&gt;more similar&lt;/a&gt; than a face pair of different persons.&lt;/p&gt; 
&lt;p&gt;Similarity could be calculated by different metrics such as &lt;a href="https://sefiks.com/2018/08/13/cosine-similarity-in-machine-learning/"&gt;Cosine Similarity&lt;/a&gt;, Angular Distance, Euclidean Distance or L2 normalized Euclidean. The default configuration uses cosine similarity. According to &lt;a href="https://github.com/serengil/deepface/tree/master/benchmarks"&gt;experiments&lt;/a&gt;, no distance metric is overperforming than other.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;metrics = ["cosine", "euclidean", "euclidean_l2", "angular"]

result = DeepFace.verify(
  img1_path = "img1.jpg", img2_path = "img2.jpg", distance_metric = metrics[1]
)

dfs = DeepFace.find(
  img_path = "img1.jpg", db_path = "C:/my_db", distance_metric = metrics[2]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;API&lt;/strong&gt; - &lt;a href="https://youtu.be/HeKCQ6U9XmI"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/9Tk9lRQareA"&gt;&lt;code&gt;Docker Demo&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace serves an API as well - see &lt;a href="https://github.com/serengil/deepface/tree/master/deepface/api/src"&gt;&lt;code&gt;api folder&lt;/code&gt;&lt;/a&gt; for more details. You can clone deepface source code and run the api with the following command. It will use gunicorn server to get a rest service up. In this way, you can call deepface from an external system such as mobile app or web.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd scripts &amp;amp;&amp;amp; ./service.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can run the dockerized service.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd scripts &amp;amp;&amp;amp; ./dockerize.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-api.jpg" width="90%" /&gt;&lt;/p&gt; 
&lt;p&gt;Face verification, facial attribute analysis, vector representation and register &amp;amp; search functions are covered in the API. The API accepts images as file uploads (via form data), or as exact image paths, URLs, or base64-encoded strings (via either JSON or form data).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ curl -X POST http://localhost:5005/represent \
   -d '{"model_name":"Facenet", "img":"img1.jpg"}'

$ curl -X POST http://localhost:5005/verify \
   -d '{"img1":"img1.jpg", "img2":"img3.jpg"}'

$ curl -X POST http://localhost:5005/analyze \
   -d '{"img": "img2.jpg", "actions": ["age", "gender"]}'

$ curl -X POST http://localhost:5005/register \
   -d '{"model_name":"Facenet", "img":"img18.jpg"}'

$ curl -X POST http://localhost:5005/search \
   -d '{"img":"img1.jpg", "model_name":"Facenet"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/serengil/deepface/tree/master/deepface/api/postman"&gt;&lt;code&gt;Here&lt;/code&gt;&lt;/a&gt;, you can find a postman project to find out how these methods should be called.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Encrypt Embeddings&lt;/strong&gt; - &lt;a href="https://youtu.be/8VCu39jFZ7k"&gt;&lt;code&gt;Demo with PHE&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2025/03/04/vector-similarity-search-with-partially-homomorphic-encryption-in-python/"&gt;&lt;code&gt;Tutorial for PHE&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/njjw0PEhH00"&gt;&lt;code&gt;Demo with FHE&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2021/12/01/homomorphic-facial-recognition-with-tenseal/"&gt;&lt;code&gt;Tutorial for FHE&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Vector embeddings, though not reversible, carry sensitive information like fingerprints, making their security crucial. Encrypting them prevents adversarial misuse. Traditional encryption (e.g., AES) is secure but unsuitable for cloud-based distance calculations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/3ejI0zNPMEQ"&gt;Homomorphic encryption&lt;/a&gt; allows computations on encrypted data without revealing content‚Äîideal for secure cloud processing. For example, the cloud can compute encrypted similarity without knowing the data, while only the key holder can decrypt the result. See the &lt;a href="https://github.com/serengil/LightPHE"&gt;&lt;code&gt;LightPHE&lt;/code&gt;&lt;/a&gt; library for partially homomorphic encryption.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from lightphe import LightPHE

# build an additively homomorphic cryptosystem (e.g. Paillier) on-prem
cs = LightPHE(algorithm_name = "Paillier", precision = 19)

# define encrypted and plain vectors
encrypted_alpha = DeepFace.represent("source.jpg", cryptosystem=cs)[0]["encrypted_embedding"]
beta = DeepFace.represent("target.jpg")[0]["embedding"]

# dot product of encrypted &amp;amp; plain embedding in cloud - private key not required
encrypted_cosine_similarity = encrypted_alpha @ beta

# decrypt similarity on-prem - private key required
calculated_similarity = cs.decrypt(encrypted_cosine_similarity)[0]

# verification
print("same person" if calculated_similarity &amp;gt;= 1 - threshold else "different persons")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/refs/heads/master/icon/encrypt-embeddings.jpg" width="60%" /&gt;&lt;/p&gt; 
&lt;p&gt;For stronger privacy, fully homomorphic encryption enables dot product computations between encrypted embeddings, but it's far more computationally intensive. Explore &lt;a href="https://github.com/serengil/cipherface"&gt;&lt;code&gt;CipherFace&lt;/code&gt;&lt;/a&gt; for FHE-based approaches.&lt;/p&gt; 
&lt;h3&gt;Extended Applications&lt;/h3&gt; 
&lt;p&gt;DeepFace can also be used for fun and insightful applications such as&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Find Your Celebrity Look-Alike&lt;/strong&gt; - &lt;a href="https://youtu.be/jaxkEn-Kieo"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://youtu.be/RMgIKU1H8DY"&gt;&lt;code&gt;Real-Time Demo&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2019/05/05/celebrity-look-alike-face-recognition-with-deep-learning-in-keras/"&gt;&lt;code&gt;Tutorial&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace can analyze your facial features and match them with celebrities, letting you discover which famous personality you resemble the most.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/celebrity-look-alike.jpg" width="55%" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Find Which Parent a Child Look More&lt;/strong&gt; - &lt;a href="https://youtu.be/nza4tmi9vhE"&gt;&lt;code&gt;Demo&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://sefiks.com/2022/12/22/decide-whom-your-child-looks-like-with-facial-recognition-mommy-or-daddy/"&gt;&lt;code&gt;Tutorial&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;DeepFace can also be used to compare a child's face to their parents' or relatives' faces to determine which one the child resembles more.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/parental-look-alike-scaled.jpg" width="90%" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Pull requests are more than welcome! If you are planning to contribute a large patch, please create an issue first to get any upfront questions or design decisions out of the way first.&lt;/p&gt; 
&lt;p&gt;Before creating a PR, you should run the unit tests and linting locally by running &lt;code&gt;make test &amp;amp;&amp;amp; make lint&lt;/code&gt; command. Once a PR sent, GitHub test workflow will be run automatically and unit test and linting jobs will be available in &lt;a href="https://github.com/serengil/deepface/actions"&gt;GitHub actions&lt;/a&gt; before approval.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;There are many ways to support a project - starring‚≠êÔ∏è the GitHub repo is just one üôè It really helps the project get discovered by more people.&lt;/p&gt; 
&lt;p&gt;If you do like this work, then you can support it financially on &lt;a href="https://www.patreon.com/serengil?repo=deepface"&gt;Patreon&lt;/a&gt;, &lt;a href="https://github.com/sponsors/serengil"&gt;GitHub Sponsors&lt;/a&gt; or &lt;a href="https://buymeacoffee.com/serengil"&gt;Buy Me a Coffee&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://www.patreon.com/serengil?repo=deepface"&gt; &lt;img src="https://raw.githubusercontent.com/serengil/deepface/master/icon/patreon.png" width="30%" /&gt; &lt;/a&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite deepface in your publications if it helps your research.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;S. Serengil and A. Ozpinar, &lt;b&gt;"A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules"&lt;/b&gt;, &lt;i&gt;Journal of Information Technologies&lt;/i&gt;, vol. 17, no. 2, pp. 95-107, 2024.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-BibTeX"&gt;@article{serengil2024lightface,
  title     = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},
  author    = {Serengil, Sefik and Ozpinar, Alper},
  journal   = {Journal of Information Technologies},
  volume    = {17},
  number    = {2},
  pages     = {95-107},
  year      = {2024},
  doi       = {10.17671/gazibtd.1399077},
  url       = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},
  publisher = {Gazi University}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;S. I. Serengil and A. Ozpinar, &lt;b&gt;"HyperExtended LightFace: A Facial Attribute Analysis Framework"&lt;/b&gt;, &lt;i&gt;2021 International Conference on Engineering and Emerging Technologies (ICEET)&lt;/i&gt;, 2021, pp. 1-4.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-BibTeX"&gt;@inproceedings{serengil2021lightface,
  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},
  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},
  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},
  pages        = {1-4},
  year         = {2021},
  doi          = {10.1109/ICEET53442.2021.9659697},
  url          = {https://ieeexplore.ieee.org/document/9659697},
  organization = {IEEE}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;S. I. Serengil and A. Ozpinar, &lt;b&gt;"LightFace: A Hybrid Deep Face Recognition Framework"&lt;/b&gt;, &lt;i&gt;2020 Innovations in Intelligent Systems and Applications Conference (ASYU)&lt;/i&gt;, 2020, pp. 23-27.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-BibTeX"&gt;@inproceedings{serengil2020lightface,
  title        = {LightFace: A Hybrid Deep Face Recognition Framework},
  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},
  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},
  pages        = {23-27},
  year         = {2020},
  doi          = {10.1109/ASYU50717.2020.9259802},
  url          = {https://ieeexplore.ieee.org/document/9259802},
  organization = {IEEE}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Also, if you use deepface in your GitHub projects, please add &lt;code&gt;deepface&lt;/code&gt; in the &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Licence&lt;/h2&gt; 
&lt;p&gt;DeepFace is licensed under the MIT License - see &lt;a href="https://github.com/serengil/deepface/raw/master/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;DeepFace wraps some external face recognition models: &lt;a href="http://www.robots.ox.ac.uk/~vgg/software/vgg_face/"&gt;VGG-Face&lt;/a&gt;, &lt;a href="https://github.com/davidsandberg/facenet/raw/master/LICENSE.md"&gt;Facenet&lt;/a&gt; (both 128d and 512d), &lt;a href="https://github.com/iwantooxxoox/Keras-OpenFace/raw/master/LICENSE"&gt;OpenFace&lt;/a&gt;, &lt;a href="https://github.com/swghosh/DeepFace"&gt;DeepFace&lt;/a&gt;, &lt;a href="https://github.com/Ruoyiran/DeepID/raw/master/LICENSE.md"&gt;DeepID&lt;/a&gt;, &lt;a href="https://github.com/leondgarse/Keras_insightface/raw/master/LICENSE"&gt;ArcFace&lt;/a&gt;, &lt;a href="https://github.com/davisking/dlib/raw/master/dlib/LICENSE.txt"&gt;Dlib&lt;/a&gt;, &lt;a href="https://github.com/opencv/opencv_zoo/raw/master/models/face_recognition_sface/LICENSE"&gt;SFace&lt;/a&gt;, &lt;a href="https://github.com/HamadYA/GhostFaceNets/raw/main/LICENSE"&gt;GhostFaceNet&lt;/a&gt; and &lt;a href="https://github.com/deepinsight/insightface/raw/master/README.md"&gt;Buffalo_L&lt;/a&gt;. Besides, age, gender and race / ethnicity models were trained on the backbone of VGG-Face with transfer learning. Similarly, DeepFace wraps many face detectors: &lt;a href="https://github.com/opencv/opencv/raw/4.x/LICENSE"&gt;OpenCv&lt;/a&gt;, &lt;a href="https://github.com/opencv/opencv/raw/master/LICENSE"&gt;Ssd&lt;/a&gt;, &lt;a href="https://github.com/davisking/dlib/raw/master/LICENSE.txt"&gt;Dlib&lt;/a&gt;, &lt;a href="https://github.com/ipazc/mtcnn/raw/master/LICENSE"&gt;MtCnn&lt;/a&gt;, &lt;a href="https://github.com/timesler/facenet-pytorch/raw/master/LICENSE.md"&gt;Fast MtCnn&lt;/a&gt;, &lt;a href="https://github.com/serengil/retinaface/raw/master/LICENSE"&gt;RetinaFace&lt;/a&gt;, &lt;a href="https://github.com/google/mediapipe/raw/master/LICENSE"&gt;MediaPipe&lt;/a&gt;, &lt;a href="https://github.com/ShiqiYu/libfacedetection/raw/master/LICENSE"&gt;YuNet&lt;/a&gt;, &lt;a href="https://github.com/ultralytics/ultralytics/raw/main/LICENSE"&gt;Yolo&lt;/a&gt; and &lt;a href="https://github.com/Star-Clouds/CenterFace/raw/master/LICENSE"&gt;CenterFace&lt;/a&gt;. Finally, DeepFace is optionally using &lt;a href="https://github.com/minivision-ai/Silent-Face-Anti-Spoofing/raw/master/LICENSE"&gt;face anti spoofing&lt;/a&gt; to determine the given images are real or fake. License types will be inherited when you intend to utilize those models. Please check the license types of those models for production purposes.&lt;/p&gt; 
&lt;p&gt;DeepFace &lt;a href="https://thenounproject.com/term/face-recognition/2965879/"&gt;logo&lt;/a&gt; is created by &lt;a href="https://thenounproject.com/coquet_adrien/"&gt;Adrien Coquet&lt;/a&gt; and it is licensed under &lt;a href="https://creativecommons.org/licenses/by/3.0/"&gt;Creative Commons: By Attribution 3.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Maintainers.md#maintainers" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip"&gt;yt-dlp_linux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64.zip"&gt;yt-dlp_linux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l.zip"&gt;yt-dlp_linux_armv7l.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.31+) armv7l executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux"&gt;yt-dlp_musllinux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux.zip"&gt;yt-dlp_musllinux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64"&gt;yt-dlp_musllinux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64.zip"&gt;yt-dlp_musllinux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 (32-bit) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone ARM64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) ARM64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Licensing&lt;/h4&gt; 
&lt;p&gt;While yt-dlp is licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;, many of the release files contain code from other projects with different licenses.&lt;/p&gt; 
&lt;p&gt;Most notably, the PyInstaller-bundled executables include GPLv3+ licensed code, and as such the combined work is licensed under &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;GPLv3+&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The zipimport Unix executable (&lt;code&gt;yt-dlp&lt;/code&gt;) contains &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; licensed code from &lt;a href="https://github.com/meriyah/meriyah"&gt;&lt;code&gt;meriyah&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; licensed code from &lt;a href="https://github.com/davidbonnet/astring"&gt;&lt;code&gt;astring&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/THIRD_PARTY_LICENSES.txt"&gt;THIRD_PARTY_LICENSES.txt&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;The git repository, the source tarball (&lt;code&gt;yt-dlp.tar.gz&lt;/code&gt;), the PyPI source distribution and the PyPI built distribution (wheel) only contain code licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.10+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;ffprobe&lt;/code&gt;, &lt;code&gt;yt-dlp-ejs&lt;/code&gt; and a supported JavaScript runtime/engine are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/yt-dlp/ejs"&gt;&lt;strong&gt;yt-dlp-ejs&lt;/strong&gt;&lt;/a&gt; - Required for full YouTube support. Licensed under &lt;a href="https://github.com/yt-dlp/ejs/raw/main/LICENSE"&gt;Unlicense&lt;/a&gt;, bundles &lt;a href="https://github.com/davidbonnet/astring/raw/main/LICENSE"&gt;MIT&lt;/a&gt; and &lt;a href="https://github.com/meriyah/meriyah/raw/main/LICENSE.md"&gt;ISC&lt;/a&gt; components.&lt;/p&gt; &lt;p&gt;A JavaScript runtime/engine like &lt;a href="https://deno.land"&gt;&lt;strong&gt;deno&lt;/strong&gt;&lt;/a&gt; (recommended), &lt;a href="https://nodejs.org"&gt;&lt;strong&gt;node.js&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://bun.sh"&gt;&lt;strong&gt;bun&lt;/strong&gt;&lt;/a&gt;, or &lt;a href="https://bellard.org/quickjs/"&gt;&lt;strong&gt;QuickJS&lt;/strong&gt;&lt;/a&gt; is also required to run yt-dlp-ejs. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/EJS"&gt;the wiki&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; extra, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in most builds &lt;em&gt;except&lt;/em&gt; &lt;code&gt;yt-dlp&lt;/code&gt; (Unix zipimport binary), &lt;code&gt;yt-dlp_x86&lt;/code&gt; (Windows 32-bit) and &lt;code&gt;yt-dlp_musllinux_aarch64&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in some extractors where JavaScript needs to be run. No longer used for YouTube. To be deprecated in the near future. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python devscripts/install_deps.py --include-extra pyinstaller
python devscripts/make_lazy_extractors.py
python -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python3&lt;/code&gt; instead of &lt;code&gt;python&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.10+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs DIR               Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--js-runtimes RUNTIME[:PATH]    Additional JavaScript runtime to enable,
                                with an optional location for the runtime
                                (either the path to the binary or its
                                containing directory). This option can be
                                used multiple times to enable multiple
                                runtimes. Supported runtimes are (in order
                                of priority, from highest to lowest): deno,
                                node, quickjs, bun. Only "deno" is enabled
                                by default. The highest priority runtime
                                that is both enabled and available will be
                                used. In order to use a lower priority
                                runtime when "deno" is available, --no-js-
                                runtimes needs to be passed before enabling
                                other runtimes
--no-js-runtimes                Clear JavaScript runtimes to enable,
                                including defaults and those provided by
                                previous --js-runtimes
--remote-components COMPONENT   Remote components to allow yt-dlp to fetch
                                when required. This option is currently not
                                needed if you are using an official
                                executable or have the requisite version of
                                the yt-dlp-ejs package installed. You can
                                use this option multiple times to allow
                                multiple components. Supported values:
                                ejs:npm (external JavaScript components from
                                npm), ejs:github (external JavaScript
                                components from yt-dlp-ejs GitHub). By
                                default, no remote components are allowed
--no-remote-components          Disallow fetching of all remote components,
                                including any previously allowed by
                                --remote-components or defaults.
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma-separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, axel, curl, ffmpeg, httpie, wget.
                                You can use this option multiple times to
                                set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-reset             Disregard previous user specified sort order
                                and reset to the default
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, hook, poi_highlight,
                                chapter, all and default (=all). You can
                                prefix the category with a "-" to exclude
                                it. See [1] for descriptions of the
                                categories. E.g. --sponsorblock-mark
                                all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-locations&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma-separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;save_count&lt;/code&gt; (numeric): Number of times the video has been saved or bookmarked&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as ‰∏≠, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_√§‚Ü≠ùïê.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use the &lt;code&gt;-S&lt;/code&gt;/&lt;code&gt;--format-sort&lt;/code&gt; option multiple times, each subsequent sorting argument will be prepended to the previous one, and only the highest priority entry of any duplicated field will be preserved. E.g. &lt;code&gt;-S proto -S res&lt;/code&gt; is equivalent to &lt;code&gt;-S res,proto&lt;/code&gt;, and &lt;code&gt;-S res:720,fps -S vcodec,res:1080&lt;/code&gt; is equivalent to &lt;code&gt;-S vcodec,res:1080,fps&lt;/code&gt;. You can use &lt;code&gt;--format-sort-reset&lt;/code&gt; to disregard any previously passed &lt;code&gt;-S&lt;/code&gt;/&lt;code&gt;--format-sort&lt;/code&gt; arguments and reset to the default order.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;, &lt;code&gt;genres&lt;/code&gt;, &lt;code&gt;categories&lt;/code&gt; or &lt;code&gt;tags&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt; or &lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Copy the episode field to the title field (with FROM and TO as single fields)
$ yt-dlp --parse-metadata "episode:title"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_downgraded&lt;/code&gt;, and &lt;code&gt;tv_simply&lt;/code&gt;. By default, &lt;code&gt;android_vr,web,web_safari&lt;/code&gt; is used. If no JavaScript runtime/engine is available, then only &lt;code&gt;android_vr&lt;/code&gt; is used. If logged-in cookies are passed to yt-dlp, then &lt;code&gt;tv_downgraded,web,web_safari&lt;/code&gt; is used for free accounts and &lt;code&gt;tv_downgraded,web_creator,web&lt;/code&gt; is used for premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only successfully works around the age-restriction sometimes (e.g. if the video is embeddable), and may be added as a fallback if &lt;code&gt;android_vr&lt;/code&gt; is unable to access a video. The &lt;code&gt;web_creator&lt;/code&gt; client is added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-web&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for n/sig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tcc&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;es5&lt;/code&gt;, &lt;code&gt;es6&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_version&lt;/code&gt;: The player javascript version to use for n/sig deciphering, in the format of &lt;code&gt;signature_timestamp@hash&lt;/code&gt; (e.g. &lt;code&gt;20348@0004de42&lt;/code&gt;). The default is to use what is prescribed by the site, and can be selected with &lt;code&gt;actual&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread,max-depth&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A &lt;code&gt;max-depth&lt;/code&gt; value of &lt;code&gt;1&lt;/code&gt; will discard all replies, regardless of the &lt;code&gt;max-replies&lt;/code&gt; or &lt;code&gt;max-replies-per-thread&lt;/code&gt; values given&lt;/li&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10,2&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread, and only 2 levels of depth (i.e. top-level comments plus their immediate replies). &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma-separated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jsc_trace&lt;/code&gt;: Enable debug logging for JS Challenge fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;use_ad_playback_context&lt;/code&gt;: Skip preroll ads to eliminate the mandatory wait period before download. Do NOT use this when passing premium account cookies to yt-dlp, as it will result in a loss of premium formats. Only effective with the &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt; and &lt;code&gt;mweb&lt;/code&gt; player clients. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtube-ejs&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;jitless&lt;/code&gt;: Run supported Javascript engines in JIT-less mode. Supported runtimes are &lt;code&gt;deno&lt;/code&gt;, &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt;. Provides better security at the cost of performance/speed. Do note that &lt;code&gt;node&lt;/code&gt; and &lt;code&gt;bun&lt;/code&gt; are still considered insecure. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK „Çâ„Åò„Çã‚òÖ„Çâ„Åò„Çã LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;macos&lt;/code&gt; and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;macos&lt;/code&gt; client is used by default, but the &lt;code&gt;web&lt;/code&gt; client is used when logged-in. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ‚ÑπÔ∏è See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ‚ÑπÔ∏è ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ‚ÑπÔ∏è See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ‚ÑπÔ∏è See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ‚ÑπÔ∏è "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.10+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For convenience, there are some compat option aliases available to use:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2025,mtime-by-default&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2025&lt;/code&gt;: Currently does nothing. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Using one of the yearly compat option aliases will pin yt-dlp's default behavior to what it was at the &lt;em&gt;end&lt;/em&gt; of that calendar year.&lt;/p&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default]
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--clean-infojson                 --clean-info-json
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been removed in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--avconv-location                Removed alias for --ffmpeg-location
--cn-verification-proxy URL      Removed alias for --geo-verification-proxy URL
--dump-headers                   Removed alias for --print-traffic
--dump-intermediate-pages        Removed alias for --dump-pages
--youtube-skip-dash-manifest     Removed alias for --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      Removed alias for --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--youtube-print-sig-code         Removed testing functionality
--dump-user-agent                No longer supported
--xattr-set-filesize             No longer supported
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>home-assistant/core</title>
      <link>https://github.com/home-assistant/core</link>
      <description>&lt;p&gt;üè° Open source home automation that puts local control and privacy first.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Home Assistant |Chat Status|&lt;/h1&gt; 
&lt;p&gt;Open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.&lt;/p&gt; 
&lt;p&gt;Check out &lt;code&gt;home-assistant.io &amp;lt;https://home-assistant.io&amp;gt;&lt;/code&gt;__ for &lt;code&gt;a demo &amp;lt;https://demo.home-assistant.io&amp;gt;&lt;/code&gt;&lt;strong&gt;, &lt;code&gt;installation instructions &amp;lt;https://home-assistant.io/getting-started/&amp;gt;&lt;/code&gt;&lt;/strong&gt;, &lt;code&gt;tutorials &amp;lt;https://home-assistant.io/getting-started/automation/&amp;gt;&lt;/code&gt;__ and &lt;code&gt;documentation &amp;lt;https://home-assistant.io/docs/&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;|screenshot-states|&lt;/p&gt; 
&lt;h2&gt;Featured integrations&lt;/h2&gt; 
&lt;p&gt;|screenshot-integrations|&lt;/p&gt; 
&lt;p&gt;The system is built using a modular approach so support for other devices or actions can be implemented easily. See also the &lt;code&gt;section on architecture &amp;lt;https://developers.home-assistant.io/docs/architecture_index/&amp;gt;&lt;/code&gt;__ and the &lt;code&gt;section on creating your own components &amp;lt;https://developers.home-assistant.io/docs/creating_component_index/&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;If you run into issues while using Home Assistant or during development of a component, check the &lt;code&gt;Home Assistant help section &amp;lt;https://home-assistant.io/help/&amp;gt;&lt;/code&gt;__ of our website for further help and information.&lt;/p&gt; 
&lt;p&gt;|ohf-logo|&lt;/p&gt; 
&lt;p&gt;.. |Chat Status| image:: &lt;a href="https://img.shields.io/discord/330944238910963714.svg"&gt;https://img.shields.io/discord/330944238910963714.svg&lt;/a&gt; :target: &lt;a href="https://www.home-assistant.io/join-chat/"&gt;https://www.home-assistant.io/join-chat/&lt;/a&gt; .. |screenshot-states| image:: &lt;a href="https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png"&gt;https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-states.png&lt;/a&gt; :target: &lt;a href="https://demo.home-assistant.io"&gt;https://demo.home-assistant.io&lt;/a&gt; .. |screenshot-integrations| image:: &lt;a href="https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png"&gt;https://raw.githubusercontent.com/home-assistant/core/dev/.github/assets/screenshot-integrations.png&lt;/a&gt; :target: &lt;a href="https://home-assistant.io/integrations/"&gt;https://home-assistant.io/integrations/&lt;/a&gt; .. |ohf-logo| image:: &lt;a href="https://www.openhomefoundation.org/badges/home-assistant.png"&gt;https://www.openhomefoundation.org/badges/home-assistant.png&lt;/a&gt; :alt: Home Assistant - A project from the Open Home Foundation :target: &lt;a href="https://www.openhomefoundation.org/"&gt;https://www.openhomefoundation.org/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Latest optimization&lt;/strong&gt; introduces parallel kernel implementations with configurable tiling and embedding quantization support, achieving &lt;strong&gt;1.15x to 2.1x&lt;/strong&gt; additional speedup over the original implementation across different hardware platforms and workloads. For detailed technical information, see the &lt;a href="https://raw.githubusercontent.com/microsoft/BitNet/main/src/README.md"&gt;optimization guide&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/performance.png" alt="performance_comparison" width="800" /&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;01/15/2026 &lt;a href="https://github.com/microsoft/BitNet/raw/main/src/README.md"&gt;BitNet CPU Inference Optimization&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GreyDGL/PentestGPT</title>
      <link>https://github.com/GreyDGL/PentestGPT</link>
      <description>&lt;p&gt;Automated Penetration Testing Agentic Framework Powered by Large Language Models&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT SHIELDS --&gt; 
&lt;p&gt;&lt;a href="https://github.com/GreyDGL/PentestGPT/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;&lt;img src="https://img.shields.io/github/issues/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GreyDGL/PentestGPT/raw/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/github/license/GreyDGL/PentestGPT.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/eC34CEfEkK"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/eC34CEfEkK" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h3 align="center"&gt;PentestGPT&lt;/h3&gt; 
 &lt;p align="center"&gt; AI-Powered Autonomous Penetration Testing Agent &lt;br /&gt; &lt;strong&gt;Published at USENIX Security 2024&lt;/strong&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://pentestgpt.com"&gt;&lt;strong&gt;Official Website: pentestgpt.com ¬ª&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://www.usenix.org/conference/usenixsecurity24/presentation/deng"&gt;Research Paper&lt;/a&gt; ¬∑ &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;Report Bug&lt;/a&gt; ¬∑ &lt;a href="https://github.com/GreyDGL/PentestGPT/issues"&gt;Request Feature&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- ABOUT THE PROJECT --&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/3770" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3770" alt="GreyDGL%2FPentestGPT | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/761661"&gt;&lt;img src="https://asciinema.org/a/761661.svg?sanitize=true" alt="Installation Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=RUNmoXqBwVg"&gt;Watch on YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;PentestGPT in Action&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/761663"&gt;&lt;img src="https://asciinema.org/a/761663.svg?sanitize=true" alt="PentestGPT Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=cWi3Yb7RmZA"&gt;Watch on YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What's New in v1.0 (Agentic Upgrade)&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autonomous Agent&lt;/strong&gt; - Agentic pipeline for intelligent, autonomous penetration testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session Persistence&lt;/strong&gt; - Save and resume penetration testing sessions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker-First&lt;/strong&gt; - Isolated, reproducible environment with security tools pre-installed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;In Progress&lt;/strong&gt;: Multi-model support for OpenAI, Gemini, and other LLM providers&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Challenge Solver&lt;/strong&gt; - Leverages LLM advanced reasoning to perform penetration testing and CTFs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Walkthrough&lt;/strong&gt; - Tracks steps in real-time as the agent works through challenges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Category Support&lt;/strong&gt; - Web, Crypto, Reversing, Forensics, PWN, Privilege Escalation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Feedback&lt;/strong&gt; - Watch the AI work with live activity updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible Architecture&lt;/strong&gt; - Clean, modular design ready for future enhancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; (required) - &lt;a href="https://docs.docker.com/get-docker/"&gt;Install Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Provider&lt;/strong&gt; (choose one): 
  &lt;ul&gt; 
   &lt;li&gt;Anthropic API Key from &lt;a href="https://console.anthropic.com/"&gt;console.anthropic.com&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Claude OAuth Login (requires Claude subscription)&lt;/li&gt; 
   &lt;li&gt;OpenRouter for alternative models at &lt;a href="https://openrouter.ai/keys"&gt;openrouter.ai&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.google.com/document/d/1ixK7x-wlr5t5TYZJdfm75UME5KnPCpS46boLkUXKg1w/edit?usp=sharing"&gt;Tutorial: Using Local Models with Claude Code&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone and build
git clone --recurse-submodules https://github.com/GreyDGL/PentestGPT.git
cd PentestGPT
make install

# Configure authentication (first time only)
make config

# Connect to container
make connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;--recurse-submodules&lt;/code&gt; flag downloads the benchmark suite. If you already cloned without it, run: &lt;code&gt;git submodule update --init --recursive&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Try a Benchmark&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd benchmark/standalone-xbow-benchmark-runner
python3 run_benchmarks.py --range 1-1 --pattern-flag
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/benchmark/README.md"&gt;Benchmark Documentation&lt;/a&gt; for detailed usage.&lt;/p&gt; 
&lt;h3&gt;Commands Reference&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make install&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build the Docker image&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make config&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Configure API key (first-time setup)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make connect&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Connect to container (main entry point)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make stop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop container (config persists)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make clean-docker&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Remove everything including config&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interactive TUI mode (default)
pentestgpt --target 10.10.11.234

# Non-interactive mode
pentestgpt --target 10.10.11.100 --non-interactive

# With challenge context
pentestgpt --target 10.10.11.50 --instruction "WordPress site, focus on plugin vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Keyboard Shortcuts:&lt;/strong&gt; &lt;code&gt;F1&lt;/code&gt; Help | &lt;code&gt;Ctrl+P&lt;/code&gt; Pause/Resume | &lt;code&gt;Ctrl+Q&lt;/code&gt; Quit&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Using Local LLMs&lt;/h2&gt; 
&lt;p&gt;PentestGPT supports routing requests to local LLM servers (LM Studio, Ollama, text-generation-webui, etc.) running on your host machine.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local LLM server with an OpenAI-compatible API endpoint 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;: Enable server mode (default port 1234)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Run &lt;code&gt;ollama serve&lt;/code&gt; (default port 11434)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Configure PentestGPT for local LLM
make config
# Select option 4: Local LLM

# Start your local LLM server on the host machine
# Then connect to the container
make connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customizing Models&lt;/h3&gt; 
&lt;p&gt;Edit &lt;code&gt;scripts/ccr-config-template.json&lt;/code&gt; to customize:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;localLLM.api_base_url&lt;/code&gt;&lt;/strong&gt;: Your LLM server URL (default: &lt;code&gt;host.docker.internal:1234&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;localLLM.models&lt;/code&gt;&lt;/strong&gt;: Available model names on your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Router section&lt;/strong&gt;: Which models handle which operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Route&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Default Model&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;default&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;General tasks&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;background&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Background operations&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;think&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Reasoning-heavy tasks&lt;/td&gt; 
   &lt;td&gt;qwen/qwen3-coder-30b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;longContext&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Large context handling&lt;/td&gt; 
   &lt;td&gt;qwen/qwen3-coder-30b&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;webSearch&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Web search operations&lt;/td&gt; 
   &lt;td&gt;openai/gpt-oss-20b&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Connection refused&lt;/strong&gt;: Ensure your LLM server is running and listening on the configured port&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker networking&lt;/strong&gt;: Use &lt;code&gt;host.docker.internal&lt;/code&gt; (not &lt;code&gt;localhost&lt;/code&gt;) to access host services from Docker&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check CCR logs&lt;/strong&gt;: Inside the container, run &lt;code&gt;cat /tmp/ccr.log&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;PentestGPT collects anonymous usage data to help improve the tool. This data is sent to our &lt;a href="https://langfuse.com"&gt;Langfuse&lt;/a&gt; project and includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Session metadata (target type, duration, completion status)&lt;/li&gt; 
 &lt;li&gt;Tool execution patterns (which tools are used, not the actual commands)&lt;/li&gt; 
 &lt;li&gt;Flag detection events (that a flag was found, not the flag content)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;No sensitive data is collected&lt;/strong&gt; - command outputs, credentials, or actual flag values are never transmitted.&lt;/p&gt; 
&lt;h3&gt;Opting Out&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Via command line flag
pentestgpt --target 10.10.11.234 --no-telemetry

# Via environment variable
export LANGFUSE_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;PentestGPT includes 104 XBOW validation benchmarks for comprehensive testing and evaluation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd benchmark/standalone-xbow-benchmark-runner

python3 run_benchmarks.py --range 1-10 --pattern-flag   # Run benchmarks 1-10
python3 run_benchmarks.py --all --pattern-flag          # Run all 104 benchmarks
python3 run_benchmarks.py --retry-failed                # Retry failed benchmarks
python3 run_benchmarks.py --dry-run --range 1-5         # Preview without executing
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Highlights&lt;/h3&gt; 
&lt;p&gt;PentestGPT achieved an &lt;strong&gt;86.5% success rate&lt;/strong&gt; (90/104 benchmarks) on the XBOW validation suite:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;: Average $1.11, Median $0.42 per successful benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Time&lt;/strong&gt;: Average 6.1 minutes, Median 3.3 minutes per successful benchmark&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success rates by difficulty&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Level 1: 91.1%&lt;/li&gt; 
   &lt;li&gt;Level 2: 74.5%&lt;/li&gt; 
   &lt;li&gt;Level 3: 62.5%&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed benchmark results, analysis, and automated testing instructions, see the &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/benchmark/README.md"&gt;Benchmark Documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Legacy Version&lt;/h2&gt; 
&lt;p&gt;The previous multi-LLM version (v0.15) supporting OpenAI, Gemini, Deepseek, and Ollama is archived in &lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/legacy/"&gt;&lt;code&gt;legacy/&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd legacy &amp;amp;&amp;amp; pip install -e . &amp;amp;&amp;amp; pentestgpt --reasoning gpt-4o
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use PentestGPT in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{299699,
  author = {Gelei Deng and Yi Liu and V√≠ctor Mayoral-Vilches and Peng Liu and Yuekang Li and Yuan Xu and Tianwei Zhang and Yang Liu and Martin Pinzger and Stefan Rass},
  title = {{PentestGPT}: Evaluating and Harnessing Large Language Models for Automated Penetration Testing},
  booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
  year = {2024},
  isbn = {978-1-939133-44-1},
  address = {Philadelphia, PA},
  pages = {847--864},
  url = {https://www.usenix.org/conference/usenixsecurity24/presentation/deng},
  publisher = {USENIX Association},
  month = aug
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Distributed under the MIT License. See &lt;code&gt;LICENSE.md&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: This tool is for educational purposes and authorized security testing only. The authors do not condone any illegal use. Use at your own risk.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Research supported by &lt;a href="https://www.quantstamp.com/"&gt;Quantstamp&lt;/a&gt; and &lt;a href="https://www.ntu.edu.sg/"&gt;NTU Singapore&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/GreyDGL/PentestGPT/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;</description>
    </item>
    
  </channel>
</rss>