<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Wed, 31 Dec 2026 01:34:42 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>spf13/viper</title>
      <link>https://github.com/spf13/viper</link>
      <description>&lt;p&gt;Go configuration with fangs&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;h2&gt;Viper v2 Feedback&lt;/h2&gt; 
 &lt;p&gt;Viper is heading towards v2 and we would love to hear what &lt;em&gt;&lt;strong&gt;you&lt;/strong&gt;&lt;/em&gt; would like to see in it. Share your thoughts here: &lt;a href="https://forms.gle/R6faU74qPRPAzchZ9"&gt;https://forms.gle/R6faU74qPRPAzchZ9&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Thank you!&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/acae9193-2974-41f3-808d-2d433f5ada5e" alt="viper logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/avelino/awesome-go#configuration"&gt;&lt;img src="https://awesome.re/mentioned-badge-flat.svg?sanitize=true" alt="Mentioned in Awesome Go" /&gt;&lt;/a&gt; &lt;a href="https://repl.it/@sagikazarmark/Viper-example#main.go"&gt;&lt;img src="https://repl.it/badge/github/sagikazarmark/Viper-example" alt="run on repl.it" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spf13/viper/actions?query=workflow%3ACI"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/spf13/viper/ci.yaml?branch=master&amp;amp;style=flat-square" alt="GitHub Workflow Status" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/spf13/viper?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge"&gt;&lt;img src="https://badges.gitter.im/Join%20Chat.svg?sanitize=true" alt="Join the chat at https://gitter.im/spf13/viper" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/spf13/viper"&gt;&lt;img src="https://goreportcard.com/badge/github.com/spf13/viper?style=flat-square" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/go%20version-%3E=1.23-61CFDD.svg?style=flat-square" alt="Go Version" /&gt; &lt;a href="https://pkg.go.dev/mod/github.com/spf13/viper"&gt;&lt;img src="https://pkg.go.dev/badge/mod/github.com/spf13/viper" alt="PkgGoDev" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Go configuration with fangs!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Many Go projects are built using Viper including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://gohugo.io"&gt;Hugo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://rexray.readthedocs.org/en/stable/"&gt;EMC RexRay&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Imgur/incus"&gt;Imgur’s Incus&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nanobox-io/nanobox"&gt;Nanobox&lt;/a&gt;/&lt;a href="https://github.com/nanopack"&gt;Nanopack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/docker/Notary"&gt;Docker Notary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.bloomapi.com/"&gt;BloomApi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/digitalocean/doctl"&gt;doctl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jgsqware/clairctl"&gt;Clairctl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mercure.rocks"&gt;Mercure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meshery/meshery"&gt;Meshery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bearer/bearer"&gt;Bearer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/coder/coder"&gt;Coder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vitess.io/"&gt;Vitess&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/spf13/viper
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; Viper uses &lt;a href="https://go.dev/wiki/Modules"&gt;Go Modules&lt;/a&gt; to manage dependencies.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why use Viper?&lt;/h2&gt; 
&lt;p&gt;Viper is a complete configuration solution for Go applications including &lt;a href="https://12factor.net/#the_twelve_factors"&gt;12-Factor apps&lt;/a&gt;. It is designed to work within any application, and can handle all types of configuration needs and formats. It supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;setting defaults&lt;/li&gt; 
 &lt;li&gt;setting explicit values&lt;/li&gt; 
 &lt;li&gt;reading config files&lt;/li&gt; 
 &lt;li&gt;dynamic discovery of config files across multiple locations&lt;/li&gt; 
 &lt;li&gt;reading from environment variables&lt;/li&gt; 
 &lt;li&gt;reading from remote systems (e.g. Etcd or Consul)&lt;/li&gt; 
 &lt;li&gt;reading from command line flags&lt;/li&gt; 
 &lt;li&gt;reading from buffers&lt;/li&gt; 
 &lt;li&gt;live watching and updating configuration&lt;/li&gt; 
 &lt;li&gt;aliasing configuration keys for easy refactoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Viper can be thought of as a registry for all of your applications' configuration needs.&lt;/p&gt; 
&lt;h2&gt;Putting Values in Viper&lt;/h2&gt; 
&lt;p&gt;Viper can read from multiple configuration sources and merges them together into one set of configuration keys and values.&lt;/p&gt; 
&lt;p&gt;Viper uses the following precedence for merging:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;explicit call to &lt;code&gt;Set&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;flags&lt;/li&gt; 
 &lt;li&gt;environment variables&lt;/li&gt; 
 &lt;li&gt;config files&lt;/li&gt; 
 &lt;li&gt;external key/value stores&lt;/li&gt; 
 &lt;li&gt;defaults&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; Viper configuration keys are case insensitive.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Reading Config Files&lt;/h3&gt; 
&lt;p&gt;Viper requires minimal configuration to load config files. Viper currently supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JSON&lt;/li&gt; 
 &lt;li&gt;TOML&lt;/li&gt; 
 &lt;li&gt;YAML&lt;/li&gt; 
 &lt;li&gt;INI&lt;/li&gt; 
 &lt;li&gt;envfile&lt;/li&gt; 
 &lt;li&gt;Java Propeties&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;A single Viper instance only supports a single configuration file, but multiple paths may be searched for one.&lt;/p&gt; 
&lt;p&gt;Here is an example of how to use Viper to search for and read a configuration file. At least one path should be provided where a configuration file is expected.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Name of the config file without an extension (Viper will intuit the type
// from an extension on the actual file)
viper.SetConfigName("config")

// Add search paths to find the file
viper.AddConfigPath("/etc/appname/")
viper.AddConfigPath("$HOME/.appname")
viper.AddConfigPath(".")

// Find and read the config file
err := viper.ReadInConfig()

// Handle errors
if err != nil {
	panic(fmt.Errorf("fatal error config file: %w", err))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can handle the specific case where no config file is found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;var fileLookupError viper.FileLookupError
if err := viper.ReadInConfig(); err != nil {
    if errors.As(err, &amp;amp;fileLookupError) {
        // Indicates an explicitly set config file is not found (such as with
        // using `viper.SetConfigFile`) or that no config file was found in
        // any search path (such as when using `viper.AddConfigPath`)
    } else {
        // Config file was found but another error was produced
    }
}

// Config file found and successfully parsed
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE (since 1.6)&lt;/strong&gt; You can also have a file without an extension and specify the format programmatically, which is useful for files that naturally have no extension (e.g., &lt;code&gt;.bashrc&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Writing Config Files&lt;/h3&gt; 
&lt;p&gt;At times you may want to store all configuration modifications made during run time.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Writes current config to the path set by `AddConfigPath` and `SetConfigName`
viper.WriteConfig()
viper.SafeWriteConfig() // Like the above, but will error if the config file exists

// Writes current config to a specific place
viper.WriteConfigAs("/path/to/my/.config")

// Will error since it has already been written
viper.SafeWriteConfigAs("/path/to/my/.config")

viper.SafeWriteConfigAs("/path/to/my/.other_config")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As a rule of the thumb, methods prefixed with &lt;code&gt;Safe&lt;/code&gt; won't overwrite any existing file, while other methods will.&lt;/p&gt; 
&lt;h3&gt;Watching and Re-reading Config Files&lt;/h3&gt; 
&lt;p&gt;Gone are the days of needing to restart a server to have a config take effect--Viper powered applications can read an update to a config file while running and not miss a beat.&lt;/p&gt; 
&lt;p&gt;It's also possible to provide a function for Viper to run each time a change occurs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// All config paths must be defined prior to calling `WatchConfig()`
viper.AddConfigPath("$HOME/.appname")

viper.OnConfigChange(func(e fsnotify.Event) {
	fmt.Println("Config file changed:", e.Name)
})

viper.WatchConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Reading Config from &lt;code&gt;io.Reader&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Viper predefines many configuration sources but you can also implement your own required configuration source.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.SetConfigType("yaml")

var yamlExample = []byte(`
hacker: true
hobbies:
- skateboarding
- snowboarding
- go
name: steve
`)

viper.ReadConfig(bytes.NewBuffer(yamlExample))

viper.Get("name") // "steve"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setting Defaults&lt;/h3&gt; 
&lt;p&gt;A good configuration system will support default values, which are used if a key hasn't been set in some other way.&lt;/p&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.SetDefault("ContentDir", "content")
viper.SetDefault("LayoutDir", "layouts")
viper.SetDefault("Taxonomies", map[string]string{"tag": "tags", "category": "categories"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setting Overrides&lt;/h3&gt; 
&lt;p&gt;Viper allows explict setting of configuration, such as from your own application logic.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.Set("verbose", true)
viper.Set("host.port", 5899) // Set an embedded key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Registering and Using Aliases&lt;/h3&gt; 
&lt;p&gt;Aliases permit a single value to be referenced by multiple keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.RegisterAlias("loud", "Verbose")

viper.Set("verbose", true) // Same result as next line
viper.Set("loud", true)    // Same result as prior line

viper.GetBool("loud")    // true
viper.GetBool("verbose") // true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Working with Environment Variables&lt;/h3&gt; 
&lt;p&gt;Viper has full support for environment variables.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; Unlike other configuration sources, environment variables are case sensitive.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Tells Viper to use this prefix when reading environment variables
viper.SetEnvPrefix("spf")

// Viper will look for "SPF_ID", automatically uppercasing the prefix and key
viper.BindEnv("id")

// Alternatively, we can search for any environment variable prefixed and load
// them in
viper.AutomaticEnv()

os.Setenv("SPF_ID", "13")

id := viper.Get("id") // 13
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;By default, empty environment variables are considered unset and will fall back to the next configuration source, unless &lt;code&gt;AllowEmptyEnv&lt;/code&gt; is used.&lt;/li&gt; 
 &lt;li&gt;Viper does not "cache" environment variables--the value will be read each time it is accessed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SetEnvKeyReplacer&lt;/code&gt; and &lt;code&gt;EnvKeyReplacer&lt;/code&gt; allow you to rewrite environment variable keys, which is useful to merge SCREAMING_SNAKE_CASE environment variables with kebab-cased configuration values from other sources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Working with Flags&lt;/h3&gt; 
&lt;p&gt;Viper has the ability to bind to flags. Specifically, Viper supports &lt;a href="https://github.com/spf13/pflag/"&gt;pflag&lt;/a&gt; as used in the &lt;a href="https://github.com/spf13/cobra"&gt;Cobra&lt;/a&gt; library.&lt;/p&gt; 
&lt;p&gt;Like environment variables, the value is not set when the binding method is called, but when it is accessed.&lt;/p&gt; 
&lt;p&gt;For individual flags, the &lt;code&gt;BindPFlag&lt;/code&gt; method provides this functionality.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;serverCmd.Flags().Int("port", 1138, "Port to run Application server on")

viper.BindPFlag("port", serverCmd.Flags().Lookup("port"))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also bind an existing set of pflags.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;pflag.Int("flagname", 1234, "help message for flagname")
pflag.Parse()

viper.BindPFlags(pflag.CommandLine)

i := viper.GetInt("flagname") // Retrieve values from viper instead of pflag
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The standard library &lt;a href="https://golang.org/pkg/flag/"&gt;flag&lt;/a&gt; package is not directly supported, but may be parsed through pflag.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"flag"

	"github.com/spf13/pflag"
)

func main() {
	// Using standard library "flag" package
	flag.Int("flagname", 1234, "help message for flagname")

    // Pass standard library flags to pflag
	pflag.CommandLine.AddGoFlagSet(flag.CommandLine)
	pflag.Parse()

    // Viper takes over
	viper.BindPFlags(pflag.CommandLine)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use of pflag may be avoided entirely by implementing the &lt;code&gt;FlagValue&lt;/code&gt; and &lt;code&gt;FlagValueSet&lt;/code&gt; interfaces.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Implementing FlagValue

type myFlag struct {}
func (f myFlag) HasChanged() bool { return false }
func (f myFlag) Name() string { return "my-flag-name" }
func (f myFlag) ValueString() string { return "my-flag-value" }
func (f myFlag) ValueType() string { return "string" }

viper.BindFlagValue("my-flag-name", myFlag{})

// Implementing FlagValueSet

type myFlagSet struct {
	flags []myFlag
}
func (f myFlagSet) VisitAll(fn func(FlagValue)) {
	for _, flag := range flags {
		fn(flag)
	}
}

fSet := myFlagSet{
	flags: []myFlag{myFlag{}, myFlag{}},
}
viper.BindFlagValues("my-flags", fSet)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Remote Key/Value Store Support&lt;/h3&gt; 
&lt;p&gt;To enable remote support in Viper, do a blank import of the &lt;code&gt;viper/remote&lt;/code&gt; package.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import _ "github.com/spf13/viper/remote"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Viper supports the following remote key/value stores. Examples for each are provided below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Etcd and Etcd3&lt;/li&gt; 
 &lt;li&gt;Consul&lt;/li&gt; 
 &lt;li&gt;Firestore&lt;/li&gt; 
 &lt;li&gt;NATS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Viper will read a config string retrieved from a path in a key/value store.&lt;/p&gt; 
&lt;p&gt;Viper supports multiple hosts separated by &lt;code&gt;;&lt;/code&gt;. For example: &lt;code&gt;http://127.0.0.1:4001;http://127.0.0.1:4002&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Encryption&lt;/h4&gt; 
&lt;p&gt;Viper uses &lt;a href="https://github.com/sagikazarmark/crypt"&gt;crypt&lt;/a&gt; to retrieve configuration from the key/value store, which means that you can store your configuration values encrypted and have them automatically decrypted if you have the correct GPG keyring. Encryption is optional.&lt;/p&gt; 
&lt;p&gt;Crypt has a command-line helper that you can use to put configurations in your key/value store.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ go get github.com/sagikazarmark/crypt/bin/crypt
$ crypt set -plaintext /config/hugo.json /Users/hugo/settings/config.json
$ crypt get -plaintext /config/hugo.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the Crypt documentation for examples of how to set encrypted values, or how to use Consul.&lt;/p&gt; 
&lt;h3&gt;Remote Key/Value Store Examples (Unencrypted)&lt;/h3&gt; 
&lt;h4&gt;etcd&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddRemoteProvider("etcd", "http://127.0.0.1:4001","/config/hugo.json")
viper.SetConfigType("json") // because there is no file extension in a stream of bytes, supported extensions are "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv"
err := viper.ReadRemoteConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;etcd3&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddRemoteProvider("etcd3", "http://127.0.0.1:4001","/config/hugo.json")
viper.SetConfigType("json") // because there is no file extension in a stream of bytes, supported extensions are "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv"
err := viper.ReadRemoteConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Consul&lt;/h4&gt; 
&lt;p&gt;Given a Consul key &lt;code&gt;MY_CONSUL_KEY&lt;/code&gt; with the value:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "port": 8080,
    "hostname": "myhostname.com"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddRemoteProvider("consul", "localhost:8500", "MY_CONSUL_KEY")
viper.SetConfigType("json") // Need to explicitly set this to json
err := viper.ReadRemoteConfig()

fmt.Println(viper.Get("port")) // 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Firestore&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddRemoteProvider("firestore", "google-cloud-project-id", "collection/document")
viper.SetConfigType("json") // Config's format: "json", "toml", "yaml", "yml"
err := viper.ReadRemoteConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Of course, you're allowed to use &lt;code&gt;SecureRemoteProvider&lt;/code&gt; also.&lt;/p&gt; 
&lt;h4&gt;NATS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddRemoteProvider("nats", "nats://127.0.0.1:4222", "myapp.config")
viper.SetConfigType("json")
err := viper.ReadRemoteConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Remote Key/Value Store Examples (Encrypted)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;viper.AddSecureRemoteProvider("etcd","http://127.0.0.1:4001","/config/hugo.json","/etc/secrets/mykeyring.gpg")
viper.SetConfigType("json") // because there is no file extension in a stream of bytes,  supported extensions are "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv"
err := viper.ReadRemoteConfig()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Watching Key/Value Store Changes&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Alternatively, you can create a new viper instance
var runtime_viper = viper.New()

runtime_viper.AddRemoteProvider("etcd", "http://127.0.0.1:4001", "/config/hugo.yml")
runtime_viper.SetConfigType("yaml") // because there is no file extension in a stream of bytes, supported extensions are "json", "toml", "yaml", "yml", "properties", "props", "prop", "env", "dotenv"

// Read from remote config the first time
err := runtime_viper.ReadRemoteConfig()

// Unmarshal config
runtime_viper.Unmarshal(&amp;amp;runtime_conf)

// Open a goroutine to watch remote changes forever
go func(){
	for {
		time.Sleep(time.Second * 5) // delay after each request

		// Currently, only tested with Etcd support
		err := runtime_viper.WatchRemoteConfig()
		if err != nil {
			log.Errorf("unable to read remote config: %v", err)
			continue
		}

		// Unmarshal new config into our runtime config struct
		runtime_viper.Unmarshal(&amp;amp;runtime_conf)
	}
}()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting Values From Viper&lt;/h2&gt; 
&lt;p&gt;The simplest way to retrieve configuration values from Viper is to use &lt;code&gt;Get*&lt;/code&gt; functions. &lt;code&gt;Get&lt;/code&gt; will return an any type, but specific types may be retrieved with &lt;code&gt;Get&amp;lt;Type&amp;gt;&lt;/code&gt; functions.&lt;/p&gt; 
&lt;p&gt;Note that each &lt;code&gt;Get*&lt;/code&gt; function will return a zero value if it’s key is not found. To check if a key exists, use the &lt;code&gt;IsSet&lt;/code&gt; method.&lt;/p&gt; 
&lt;p&gt;Nested keys use &lt;code&gt;.&lt;/code&gt; as a delimiter and numbers for array indexes. Given the following configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;{
    "datastore": {
        "metric": {
            "host": "127.0.0.1",
            "ports": [
                5799,
                6029
            ]
        }
    }
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;GetString("datastore.metric.host") // "127.0.0.1"
GetInt("host.ports.1") // 6029
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; Viper &lt;em&gt;does not&lt;/em&gt; deep merge configuration values. Complex values that are overridden will be entirely replaced.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If there exists a key that matches the delimited key path, its value will be returned instead.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;{
    "datastore.metric.host": "0.0.0.0",
    "datastore": {
        "metric": {
            "host": "127.0.0.1"
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;GetString("datastore.metric.host") // "0.0.0.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration Subsets&lt;/h3&gt; 
&lt;p&gt;It's often useful to extract a subset of configuration (e.g., when developing a reusable module which should accept specific sections of configuration).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;cache:
  cache1:
    item-size: 64
    max-items: 100
  cache2:
    item-size: 80
    max-items: 200
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func NewCache(v *Viper) *Cache {
	return &amp;amp;Cache{
		ItemSize: v.GetInt("item-size"),
		MaxItems: v.GetInt("max-items"),
	}
}

cache1Config := viper.Sub("cache.cache1")

if cache1Config == nil {
    // Sub returns nil if the key cannot be found
	panic("cache configuration not found")
}

cache1 := NewCache(cache1Config)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Unmarshaling&lt;/h3&gt; 
&lt;p&gt;You also have the option of unmarshaling configuration to a struct, map, etc., using &lt;code&gt;Unmarshal*&lt;/code&gt; methods.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type config struct {
	Port int
	Name string
	PathMap string `mapstructure:"path_map"`
}

var C config

err := viper.Unmarshal(&amp;amp;C)
if err != nil {
	t.Fatalf("unable to decode into struct, %v", err)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to unmarshal configuration where the keys themselves contain &lt;code&gt;.&lt;/code&gt; (the default key delimiter), you can change the delimiter.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;v := viper.NewWithOptions(viper.KeyDelimiter("::"))

v.SetDefault("chart::values", map[string]any{
	"ingress": map[string]any{
		"annotations": map[string]any{
			"traefik.frontend.rule.type":                 "PathPrefix",
			"traefik.ingress.kubernetes.io/ssl-redirect": "true",
		},
	},
})

type config struct {
	Chart struct{
		Values map[string]any
	}
}

var C config

v.Unmarshal(&amp;amp;C)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Viper also supports unmarshaling into embedded structs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;/*
Example config:

module:
    enabled: true
    token: 89h3f98hbwf987h3f98wenf89ehf
*/
type config struct {
	Module struct {
		Enabled bool

		moduleConfig `mapstructure:",squash"`
	}
}

type moduleConfig struct {
	Token string
}

var C config

err := viper.Unmarshal(&amp;amp;C)
if err != nil {
	t.Fatalf("unable to decode into struct, %v", err)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Viper uses &lt;a href="https://github.com/go-viper/mapstructure"&gt;github.com/go-viper/mapstructure&lt;/a&gt; under the hood for unmarshaling values which uses &lt;code&gt;mapstructure&lt;/code&gt; tags, by default.&lt;/p&gt; 
&lt;h3&gt;Marshalling to String&lt;/h3&gt; 
&lt;p&gt;You may need to marshal all the settings held in Viper into a string. You can use your favorite format's marshaller with the config returned by &lt;code&gt;AllSettings&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
	yaml "go.yaml.in/yaml/v3"
)

func yamlStringSettings() string {
	c := viper.AllSettings()
	bs, err := yaml.Marshal(c)
	if err != nil {
		log.Fatalf("unable to marshal config to YAML: %v", err)
	}
	return string(bs)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Decoding Custom Formats&lt;/h3&gt; 
&lt;p&gt;A frequently requested feature is adding more value formats and decoders (for example; parsing character delimited strings into slices. This is already available in Viper using mapstructure decode hooks.&lt;/p&gt; 
&lt;p&gt;Read more in &lt;a href="https://sagikazarmark.hu/blog/decoding-custom-formats-with-viper/"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why is it called “Viper”?&lt;/h3&gt; 
&lt;p&gt;Viper is designed to be a &lt;a href="http://en.wikipedia.org/wiki/Viper_(G.I._Joe)"&gt;companion&lt;/a&gt; to &lt;a href="https://github.com/spf13/cobra"&gt;Cobra&lt;/a&gt;. While both can operate completely independently, together they make a powerful pair to handle much of your application foundation needs.&lt;/p&gt; 
&lt;h3&gt;I found a bug or want a feature, should I file an issue or a PR?&lt;/h3&gt; 
&lt;p&gt;Yes, but there are two things to be aware of.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The Viper project is currently prioritizing backwards compatibility and stability over features.&lt;/li&gt; 
 &lt;li&gt;Features may be deferred until Viper 2 forms.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Can multiple Viper instances be used?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; Yes.&lt;/p&gt; 
&lt;p&gt;Each will have its own unique configuration and can read from a different configuration source. All of the functions that the Viper package supports are mirrored as methods on a Viper instance.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;x := viper.New()
y := viper.New()

x.SetDefault("ContentDir", "content")
y.SetDefault("ContentDir", "foobar")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Should Viper be a global singleton or passed around?&lt;/h3&gt; 
&lt;p&gt;The best practice is to initialize a Viper instance and pass that around when necessary.&lt;/p&gt; 
&lt;p&gt;Viper comes with a global instance (singleton) out of the box. Although it makes setting up configuration easy, using it is generally discouraged as it makes testing harder and can lead to unexpected behavior.&lt;/p&gt; 
&lt;p&gt;The global instance may be deprecated in the future. See &lt;a href="https://github.com/spf13/viper/issues/1855"&gt;#1855&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Does Viper support case sensitive keys?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; No.&lt;/p&gt; 
&lt;p&gt;Viper merges configuration from various sources, many of which are either case insensitive or use different casing than other sources (e.g., env vars). In order to provide the best experience when using multiple sources, all keys are made case insensitive.&lt;/p&gt; 
&lt;p&gt;There has been several attempts to implement case sensitivity, but unfortunately it's not trivial. We might take a stab at implementing it in &lt;a href="https://github.com/spf13/viper/issues/772"&gt;Viper v2&lt;/a&gt;, but despite the initial noise, it does not seem to be requested that much.&lt;/p&gt; 
&lt;p&gt;You can vote for case sensitivity by filling out this feedback form: &lt;a href="https://forms.gle/R6faU74qPRPAzchZ9"&gt;https://forms.gle/R6faU74qPRPAzchZ9&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Is it safe to concurrently read and write to a Viper instance?&lt;/h3&gt; 
&lt;p&gt;No, you will need to synchronize access to Viper yourself (for example by using the &lt;code&gt;sync&lt;/code&gt; package). Concurrent reads and writes can cause a panic.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/spf13/viper/master/TROUBLESHOOTING.md"&gt;TROUBLESHOOTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For an optimal developer experience, it is recommended to install &lt;a href="https://nixos.org/download.html"&gt;Nix&lt;/a&gt; and &lt;a href="https://direnv.net/docs/installation.html"&gt;direnv&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Alternatively, install &lt;a href="https://go.dev/dl/"&gt;Go&lt;/a&gt; on your computer then run &lt;code&gt;make deps&lt;/code&gt; to install the rest of the dependencies.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Run the test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run linters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make lint # pass -j option to run them in parallel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Some linter violations can automatically be fixed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make fmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The project is licensed under the &lt;a href="https://raw.githubusercontent.com/spf13/viper/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cexll/myclaude</title>
      <link>https://github.com/cexll/myclaude</link>
      <description>&lt;p&gt;Claude Code and Codex orchestration workflow&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/README_CN.md"&gt;中文&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/README.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Claude Code Multi-Agent Workflow System&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://smithery.ai/skills?ns=cexll&amp;amp;utm_source=github&amp;amp;utm_medium=badge"&gt;&lt;img src="https://smithery.ai/badge/skills/cexll" alt="Run in Smithery" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-AGPL_v3-blue.svg?sanitize=true" alt="License: AGPL-3.0" /&gt;&lt;/a&gt; &lt;a href="https://claude.ai/code"&gt;&lt;img src="https://img.shields.io/badge/Claude-Code-blue" alt="Claude Code" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cexll/myclaude"&gt;&lt;img src="https://img.shields.io/badge/Version-5.2-green" alt="Version" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AI-powered development automation with multi-backend execution (Codex/Claude/Gemini)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Core Concept: Multi-Backend Architecture&lt;/h2&gt; 
&lt;p&gt;This system leverages a &lt;strong&gt;dual-agent architecture&lt;/strong&gt; with pluggable AI backends:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Role&lt;/th&gt; 
   &lt;th&gt;Agent&lt;/th&gt; 
   &lt;th&gt;Responsibility&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Claude Code&lt;/td&gt; 
   &lt;td&gt;Planning, context gathering, verification, user interaction&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;codeagent-wrapper&lt;/td&gt; 
   &lt;td&gt;Code editing, test execution (Codex/Claude/Gemini backends)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why this separation?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude Code excels at understanding context and orchestrating complex workflows&lt;/li&gt; 
 &lt;li&gt;Specialized backends (Codex for code, Claude for reasoning, Gemini for prototyping) excel at focused execution&lt;/li&gt; 
 &lt;li&gt;Backend selection via &lt;code&gt;--backend codex|claude|gemini&lt;/code&gt; matches the model to the task&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start(Please execute in Powershell on Windows)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/cexll/myclaude.git
cd myclaude
python3 install.py --install-dir ~/.claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workflows Overview&lt;/h2&gt; 
&lt;h3&gt;1. Dev Workflow (Recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The primary workflow for most development tasks.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/dev "implement user authentication with JWT"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;6-Step Process:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Requirements Clarification&lt;/strong&gt; - Interactive Q&amp;amp;A to clarify scope&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Codex Deep Analysis&lt;/strong&gt; - Codebase exploration and architecture decisions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dev Plan Generation&lt;/strong&gt; - Structured task breakdown with test requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Execution&lt;/strong&gt; - Codex executes tasks concurrently&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Coverage Validation&lt;/strong&gt; - Enforce ≥90% test coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Completion Summary&lt;/strong&gt; - Report with file changes and coverage stats&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude Code orchestrates, Codex executes all code changes&lt;/li&gt; 
 &lt;li&gt;Automatic task parallelization for speed&lt;/li&gt; 
 &lt;li&gt;Mandatory 90% test coverage gate&lt;/li&gt; 
 &lt;li&gt;Rollback on failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best For:&lt;/strong&gt; Feature development, refactoring, bug fixes with tests&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;2. BMAD Agile Workflow&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Full enterprise agile methodology with 6 specialized agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/bmad-pilot "build e-commerce checkout system"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Agents:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Agent&lt;/th&gt; 
   &lt;th&gt;Role&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Product Owner&lt;/td&gt; 
   &lt;td&gt;Requirements &amp;amp; user stories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Architect&lt;/td&gt; 
   &lt;td&gt;System design &amp;amp; tech decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tech Lead&lt;/td&gt; 
   &lt;td&gt;Sprint planning &amp;amp; task breakdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Developer&lt;/td&gt; 
   &lt;td&gt;Implementation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code Reviewer&lt;/td&gt; 
   &lt;td&gt;Quality assurance&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Engineer&lt;/td&gt; 
   &lt;td&gt;Testing &amp;amp; validation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Requirements → Architecture → Sprint Plan → Development → Review → QA
     ↓              ↓             ↓            ↓          ↓       ↓
   PRD.md      DESIGN.md     SPRINT.md     Code      REVIEW.md  TEST.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Best For:&lt;/strong&gt; Large features, team coordination, enterprise projects&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;3. Requirements-Driven Workflow&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Lightweight requirements-to-code pipeline.&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/requirements-pilot "implement API rate limiting"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Requirements generation with quality scoring&lt;/li&gt; 
 &lt;li&gt;Implementation planning&lt;/li&gt; 
 &lt;li&gt;Code generation&lt;/li&gt; 
 &lt;li&gt;Review and testing&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Best For:&lt;/strong&gt; Quick prototypes, well-defined features&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4. Development Essentials&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Direct commands for daily coding tasks.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/code&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Implement a feature&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/debug&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Debug an issue&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/test&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Write tests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/review&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Code review&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Performance optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/refactor&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Code refactoring&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/docs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Documentation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Best For:&lt;/strong&gt; Quick tasks, no workflow overhead needed&lt;/p&gt; 
&lt;h2&gt;Enterprise Workflow Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-backend execution:&lt;/strong&gt; &lt;code&gt;codeagent-wrapper --backend codex|claude|gemini&lt;/code&gt; (default &lt;code&gt;codex&lt;/code&gt;) so you can match the model to the task without changing workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub workflow commands:&lt;/strong&gt; &lt;code&gt;/gh-create-issue "short need"&lt;/code&gt; creates structured issues; &lt;code&gt;/gh-issue-implement 123&lt;/code&gt; pulls issue #123, drives development, and prepares the PR.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Skills + hooks activation:&lt;/strong&gt; .claude/hooks run automation (tests, reviews), while &lt;code&gt;.claude/skills/skill-rules.json&lt;/code&gt; auto-suggests the right skills. Keep hooks enabled in &lt;code&gt;.claude/settings.json&lt;/code&gt; to activate the enterprise workflow helpers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Version Requirements&lt;/h2&gt; 
&lt;h3&gt;Codex CLI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Minimum version:&lt;/strong&gt; Check compatibility with your installation&lt;/p&gt; 
&lt;p&gt;The codeagent-wrapper uses these Codex CLI features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;codex e&lt;/code&gt; - Execute commands (shorthand for &lt;code&gt;codex exec&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--skip-git-repo-check&lt;/code&gt; - Skip git repository validation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--json&lt;/code&gt; - JSON stream output format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-C &amp;lt;workdir&amp;gt;&lt;/code&gt; - Set working directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resume &amp;lt;session_id&amp;gt;&lt;/code&gt; - Resume previous sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Verify Codex CLI is installed:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;which codex
codex --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude CLI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Minimum version:&lt;/strong&gt; Check compatibility with your installation&lt;/p&gt; 
&lt;p&gt;Required features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--output-format stream-json&lt;/code&gt; - Streaming JSON output format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--setting-sources&lt;/code&gt; - Control setting sources (prevents infinite recursion)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; - Skip permission prompts (use with caution)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt; - Prompt input flag&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-r &amp;lt;session_id&amp;gt;&lt;/code&gt; - Resume sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Security Note:&lt;/strong&gt; The wrapper only adds &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; for Claude when explicitly enabled (e.g. &lt;code&gt;--skip-permissions&lt;/code&gt; / &lt;code&gt;CODEAGENT_SKIP_PERMISSIONS=true&lt;/code&gt;). Keep it disabled unless you understand the risk.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Verify Claude CLI is installed:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;which claude
claude --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Gemini CLI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Minimum version:&lt;/strong&gt; Check compatibility with your installation&lt;/p&gt; 
&lt;p&gt;Required features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-o stream-json&lt;/code&gt; - JSON stream output format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-y&lt;/code&gt; - Auto-approve prompts (non-interactive mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-r &amp;lt;session_id&amp;gt;&lt;/code&gt; - Resume sessions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt; - Prompt input flag&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Verify Gemini CLI is installed:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;which gemini
gemini --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Modular Installation (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install all enabled modules (dev + essentials by default)
python3 install.py --install-dir ~/.claude

# Install specific module
python3 install.py --module dev

# List available modules
python3 install.py --list-modules

# Force overwrite existing files
python3 install.py --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Available Modules&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dev&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;✓ Enabled&lt;/td&gt; 
   &lt;td&gt;Dev workflow + Codex integration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;essentials&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;✓ Enabled&lt;/td&gt; 
   &lt;td&gt;Core development commands&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bmad&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disabled&lt;/td&gt; 
   &lt;td&gt;Full BMAD agile workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;requirements&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Disabled&lt;/td&gt; 
   &lt;td&gt;Requirements-driven workflow&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;What Gets Installed&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;~/.claude/
├── bin/
│   └── codeagent-wrapper    # Main executable
├── CLAUDE.md                # Core instructions and role definition
├── commands/                # Slash commands (/dev, /code, etc.)
├── agents/                  # Agent definitions
├── skills/
│   └── codex/
│       └── SKILL.md         # Codex integration skill
├── config.json              # Configuration
└── installed_modules.json   # Installation status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Customizing Installation Directory&lt;/h3&gt; 
&lt;p&gt;By default, myclaude installs to &lt;code&gt;~/.claude&lt;/code&gt;. You can customize this using the &lt;code&gt;INSTALL_DIR&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install to custom directory
INSTALL_DIR=/opt/myclaude bash install.sh

# Update your PATH accordingly
export PATH="/opt/myclaude/bin:$PATH"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Directory Structure:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;$INSTALL_DIR/bin/&lt;/code&gt; - codeagent-wrapper binary&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$INSTALL_DIR/skills/&lt;/code&gt; - Skill definitions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$INSTALL_DIR/config.json&lt;/code&gt; - Configuration file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$INSTALL_DIR/commands/&lt;/code&gt; - Slash command definitions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$INSTALL_DIR/agents/&lt;/code&gt; - Agent definitions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When using a custom installation directory, ensure that &lt;code&gt;$INSTALL_DIR/bin&lt;/code&gt; is added to your &lt;code&gt;PATH&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Edit &lt;code&gt;config.json&lt;/code&gt; to customize:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "version": "1.0",
  "install_dir": "~/.claude",
  "modules": {
    "dev": {
      "enabled": true,
      "operations": [
        {"type": "merge_dir", "source": "dev-workflow"},
        {"type": "copy_file", "source": "memorys/CLAUDE.md", "target": "CLAUDE.md"},
        {"type": "copy_file", "source": "skills/codex/SKILL.md", "target": "skills/codex/SKILL.md"},
        {"type": "run_command", "command": "bash install.sh"}
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Operation Types:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;merge_dir&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Merge subdirs (commands/, agents/) into install dir&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;copy_dir&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy entire directory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;copy_file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copy single file to target path&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;run_command&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Execute shell command&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Codex Integration&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;codex&lt;/code&gt; skill enables Claude Code to delegate code execution to Codex CLI.&lt;/p&gt; 
&lt;h3&gt;Usage in Workflows&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Codex is invoked via the skill
codeagent-wrapper - &amp;lt;&amp;lt;'EOF'
implement @src/auth.ts with JWT validation
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Parallel Execution&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeagent-wrapper --parallel &amp;lt;&amp;lt;'EOF'
---TASK---
id: backend_api
workdir: /project/backend
---CONTENT---
implement REST endpoints for /api/users

---TASK---
id: frontend_ui
workdir: /project/frontend
dependencies: backend_api
---CONTENT---
create React components consuming the API
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install Codex Wrapper&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Automatic (via dev module)
python3 install.py --module dev

# Manual
bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;p&gt;Windows installs place &lt;code&gt;codeagent-wrapper.exe&lt;/code&gt; in &lt;code&gt;%USERPROFILE%\bin&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# PowerShell (recommended)
powershell -ExecutionPolicy Bypass -File install.ps1

# Batch (cmd)
install.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Add to PATH&lt;/strong&gt; (if installer doesn't detect it):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# PowerShell - persistent for current user
[Environment]::SetEnvironmentVariable('PATH', "$HOME\bin;" + [Environment]::GetEnvironmentVariable('PATH','User'), 'User')

# PowerShell - current session only
$Env:PATH = "$HOME\bin;$Env:PATH"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-batch"&gt;REM cmd.exe - persistent for current user
setx PATH "%USERPROFILE%\bin;%PATH%"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Workflow Selection Guide&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Recommended Workflow&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;New feature with tests&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/dev&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quick bug fix&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/debug&lt;/code&gt; or &lt;code&gt;/code&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Large multi-sprint feature&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/bmad-pilot&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prototype or POC&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/requirements-pilot&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Code review&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/review&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Performance issue&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Codex wrapper not found:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Installer auto-adds PATH, check if configured
if [[ ":$PATH:" != *":$HOME/.claude/bin:"* ]]; then
    echo "PATH not configured. Reinstalling..."
    bash install.sh
fi

# Or manually add (idempotent command)
[[ ":$PATH:" != *":$HOME/.claude/bin:"* ]] &amp;amp;&amp;amp; echo 'export PATH="$HOME/.claude/bin:$PATH"' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Permission denied:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 install.py --install-dir ~/.claude --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Module not loading:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Check installation status
cat ~/.claude/installed_modules.json

# Reinstall specific module
python3 install.py --module dev --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Version Compatibility Issues&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Backend CLI not found:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Check if backend CLIs are installed
which codex
which claude
which gemini

# Install missing backends
# Codex: Follow installation instructions at https://codex.docs
# Claude: Follow installation instructions at https://claude.ai/docs
# Gemini: Follow installation instructions at https://ai.google.dev/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Unsupported CLI flags:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you see errors like "unknown flag" or "invalid option"

# Check backend CLI version
codex --version
claude --version
gemini --version

# For Codex: Ensure it supports `e`, `--skip-git-repo-check`, `--json`, `-C`, and `resume`
# For Claude: Ensure it supports `--output-format stream-json`, `--setting-sources`, `-r`
# For Gemini: Ensure it supports `-o stream-json`, `-y`, `-r`, `-p`

# Update your backend CLI to the latest version if needed
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;JSON parsing errors:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you see "failed to parse JSON output" errors

# Verify the backend outputs stream-json format
codex e --json "test task"  # Should output newline-delimited JSON
claude --output-format stream-json -p "test"  # Should output stream JSON

# If not, your backend CLI version may be too old or incompatible
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Infinite recursion with Claude backend:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The wrapper prevents this with `--setting-sources ""` flag
# If you still see recursion, ensure your Claude CLI supports this flag

claude --help | grep "setting-sources"

# If flag is not supported, upgrade Claude CLI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Session resume failures:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Check if session ID is valid
codex history  # List recent sessions
claude history

# Ensure backend CLI supports session resumption
codex resume &amp;lt;session_id&amp;gt; "test"  # Should continue from previous session
claude -r &amp;lt;session_id&amp;gt; "test"

# If not supported, use new sessions instead of resume mode
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;FAQ (Frequently Asked Questions)&lt;/h2&gt; 
&lt;h3&gt;Q1: &lt;code&gt;codeagent-wrapper&lt;/code&gt; execution fails with "Unknown event format"&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Unknown event format: {"type":"turn.started"}
Unknown event format: {"type":"assistant", ...}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; This is a logging event format display issue and does not affect actual functionality. It will be fixed in the next version. You can ignore these log outputs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Related Issue:&lt;/strong&gt; &lt;a href="https://github.com/cexll/myclaude/issues/96"&gt;#96&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Q2: Gemini cannot read files ignored by &lt;code&gt;.gitignore&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; When using &lt;code&gt;codeagent-wrapper --backend gemini&lt;/code&gt;, files in directories like &lt;code&gt;.claude/&lt;/code&gt; that are ignored by &lt;code&gt;.gitignore&lt;/code&gt; cannot be read.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Option 1:&lt;/strong&gt; Remove &lt;code&gt;.claude/&lt;/code&gt; from your &lt;code&gt;.gitignore&lt;/code&gt; file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Option 2:&lt;/strong&gt; Ensure files that need to be read are not in &lt;code&gt;.gitignore&lt;/code&gt; list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Related Issue:&lt;/strong&gt; &lt;a href="https://github.com/cexll/myclaude/issues/75"&gt;#75&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Q3: &lt;code&gt;/dev&lt;/code&gt; command parallel execution is very slow&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Using &lt;code&gt;/dev&lt;/code&gt; command for simple features takes too long (over 30 minutes) with no visibility into task progress.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Check logs:&lt;/strong&gt; Review &lt;code&gt;C:\Users\User\AppData\Local\Temp\codeagent-wrapper-*.log&lt;/code&gt; to identify bottlenecks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adjust backend:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try faster models like &lt;code&gt;gpt-5.1-codex-max&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Running in WSL may be significantly faster&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workspace:&lt;/strong&gt; Use a single repository instead of monorepo with multiple sub-projects&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Related Issue:&lt;/strong&gt; &lt;a href="https://github.com/cexll/myclaude/issues/77"&gt;#77&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Q4: Codex permission denied with new Go version&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; After upgrading to the new Go-based Codex implementation, execution fails with permission denied errors.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Add the following configuration to &lt;code&gt;~/.codex/config.yaml&lt;/code&gt; (Windows: &lt;code&gt;c:\user\.codex\config.toml&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;model = "gpt-5.1-codex-max"
model_reasoning_effort = "high"
model_reasoning_summary = "detailed"
approval_policy = "never"
sandbox_mode = "workspace-write"
disable_response_storage = true
network_access = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;approval_policy = "never"&lt;/code&gt; - Remove approval restrictions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sandbox_mode = "workspace-write"&lt;/code&gt; - Allow workspace write access&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;network_access = true&lt;/code&gt; - Enable network access&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Related Issue:&lt;/strong&gt; &lt;a href="https://github.com/cexll/myclaude/issues/31"&gt;#31&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Still having issues?&lt;/strong&gt; Visit &lt;a href="https://github.com/cexll/myclaude/issues"&gt;GitHub Issues&lt;/a&gt; to search or report new issues.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/docs/CODEAGENT-WRAPPER.md"&gt;Codeagent-Wrapper Guide&lt;/a&gt;&lt;/strong&gt; - Multi-backend execution wrapper&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/docs/HOOKS.md"&gt;Hooks Documentation&lt;/a&gt;&lt;/strong&gt; - Custom hooks and automation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/install.log"&gt;Installation Log&lt;/a&gt;&lt;/strong&gt; - Installation history and troubleshooting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;AGPL-3.0 License - see &lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/cexll/myclaude/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/cexll/myclaude/master/docs/"&gt;docs/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Claude Code + Codex = Better Development&lt;/strong&gt; - Orchestration meets execution.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dgraph-io/badger</title>
      <link>https://github.com/dgraph-io/badger</link>
      <description>&lt;p&gt;Fast key-value DB in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;BadgerDB&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/dgraph-io/badger/v4"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/dgraph-io/badger/v4.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/dgraph-io/badger/v4"&gt;&lt;img src="https://goreportcard.com/badge/github.com/dgraph-io/badger/v4" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/dgraph-io/badger?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/dgraph-io/badger/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-tests.yml"&gt;&lt;img src="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-tests.yml/badge.svg?sanitize=true" alt="ci-badger-tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests.yml"&gt;&lt;img src="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests.yml/badge.svg?sanitize=true" alt="ci-badger-bank-tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests-nightly.yml"&gt;&lt;img src="https://github.com/dgraph-io/badger/actions/workflows/ci-badger-bank-tests-nightly.yml/badge.svg?sanitize=true" alt="ci-badger-bank-tests-nightly" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/dgraph-io/badger/main/images/diggy-shadow.png" alt="Badger mascot" /&gt;&lt;/p&gt; 
&lt;p&gt;BadgerDB is an embeddable, persistent and fast key-value (KV) database written in pure Go. It is the underlying database for &lt;a href="https://github.com/dgraph-io/dgraph"&gt;Dgraph&lt;/a&gt;, a fast, distributed graph database. It's meant to be a performant alternative to non-Go-based key-value stores like RocksDB.&lt;/p&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;Badger is stable and is being used to serve data sets worth hundreds of terabytes. Badger supports concurrent ACID transactions with serializable snapshot isolation (SSI) guarantees. A Jepsen-style bank test runs nightly for 8h, with &lt;code&gt;--race&lt;/code&gt; flag and ensures the maintenance of transactional guarantees. Badger has also been tested to work with filesystem level anomalies, to ensure persistence and consistency. Badger is being used by a number of projects which includes Dgraph, Jaeger Tracing, UsenetExpress, and many more.&lt;/p&gt; 
&lt;p&gt;The list of projects using Badger can be found &lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#projects-using-badger"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please consult the &lt;a href="https://github.com/dgraph-io/badger/raw/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt; for more detailed information on releases.&lt;/p&gt; 
&lt;p&gt;Note: Badger is built with go 1.23 and we refrain from bumping this version to minimize downstream effects of those using Badger in applications built with older versions of Go.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#badgerdb"&gt;BadgerDB&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#project-status"&gt;Project Status&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#installing"&gt;Installing&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#installing-badger-command-line-tool"&gt;Installing Badger Command Line Tool&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#choosing-a-version"&gt;Choosing a version&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#badger-documentation"&gt;Badger Documentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#resources"&gt;Resources&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#blog-posts"&gt;Blog Posts&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#design"&gt;Design&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#comparisons"&gt;Comparisons&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#projects-using-badger"&gt;Projects Using Badger&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Installing&lt;/h3&gt; 
&lt;p&gt;To start using Badger, install Go 1.23 or above. Badger v3 and above needs go modules. From your project, run the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get github.com/dgraph-io/badger/v4
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will retrieve the library.&lt;/p&gt; 
&lt;h4&gt;Installing Badger Command Line Tool&lt;/h4&gt; 
&lt;p&gt;Badger provides a CLI tool which can perform certain operations like offline backup/restore. To install the Badger CLI, retrieve the repository and checkout the desired version. Then run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd badger
go install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install the badger command line utility into your $GOBIN path.&lt;/p&gt; 
&lt;h2&gt;Badger Documentation&lt;/h2&gt; 
&lt;p&gt;Badger Documentation is available at &lt;a href="https://badger.dgraph.io"&gt;https://badger.dgraph.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;Blog Posts&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://hypermode.com/blog/badger/"&gt;Introducing Badger: A fast key-value store written natively in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hypermode.com/blog/alice/"&gt;Make Badger crash resilient with ALICE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hypermode.com/blog/badger-lmdb-boltdb/"&gt;Badger vs LMDB vs BoltDB: Benchmarking key-value databases in Go&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hypermode.com/blog/badger-txn/"&gt;Concurrent ACID Transactions in Badger&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;Badger was written with these design goals in mind:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Write a key-value database in pure Go.&lt;/li&gt; 
 &lt;li&gt;Use latest research to build the fastest KV database for data sets spanning terabytes.&lt;/li&gt; 
 &lt;li&gt;Optimize for SSDs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Badger’s design is based on a paper titled &lt;em&gt;&lt;a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf"&gt;WiscKey: Separating Keys from Values in SSD-conscious Storage&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt; 
&lt;h3&gt;Comparisons&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Badger&lt;/th&gt; 
   &lt;th&gt;RocksDB&lt;/th&gt; 
   &lt;th&gt;BoltDB&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design&lt;/td&gt; 
   &lt;td&gt;LSM tree with value log&lt;/td&gt; 
   &lt;td&gt;LSM tree only&lt;/td&gt; 
   &lt;td&gt;B+ tree&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High Read throughput&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;High Write throughput&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Designed for SSDs&lt;/td&gt; 
   &lt;td&gt;Yes (with latest research &lt;sup&gt;1&lt;/sup&gt;)&lt;/td&gt; 
   &lt;td&gt;Not specifically &lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embeddable&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sorted KV access&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pure Go (no Cgo)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transactions&lt;/td&gt; 
   &lt;td&gt;Yes, ACID, concurrent with SSI&lt;sup&gt;3&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Yes (but non-ACID)&lt;/td&gt; 
   &lt;td&gt;Yes, ACID&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Snapshots&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TTL support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3D access (key-value-version)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;sup&gt;4&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; The &lt;a href="https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf"&gt;WISCKEY paper&lt;/a&gt; (on which Badger is based) saw big wins with separating values from keys, significantly reducing the write amplification compared to a typical LSM tree.&lt;/p&gt; 
&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; RocksDB is an SSD optimized version of LevelDB, which was designed specifically for rotating disks. As such RocksDB's design isn't aimed at SSDs.&lt;/p&gt; 
&lt;p&gt;&lt;sup&gt;3&lt;/sup&gt; SSI: Serializable Snapshot Isolation. For more details, see the blog post &lt;a href="https://hypermode.com/blog/badger-txn/"&gt;Concurrent ACID Transactions in Badger&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;sup&gt;4&lt;/sup&gt; Badger provides direct access to value versions via its Iterator API. Users can also specify how many versions to keep per key via Options.&lt;/p&gt; 
&lt;h3&gt;Benchmarks&lt;/h3&gt; 
&lt;p&gt;We have run comprehensive benchmarks against RocksDB, Bolt and LMDB. The benchmarking code, and the detailed logs for the benchmarks can be found in the &lt;a href="https://github.com/dgraph-io/badger-bench"&gt;badger-bench&lt;/a&gt; repo. More explanation, including graphs can be found the blog posts (linked above).&lt;/p&gt; 
&lt;h2&gt;Projects Using Badger&lt;/h2&gt; 
&lt;p&gt;Below is a list of known projects that use Badger:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dgraph-io/dgraph"&gt;Dgraph&lt;/a&gt; - Distributed graph database.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jaegertracing/jaeger"&gt;Jaeger&lt;/a&gt; - Distributed tracing platform.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ipfs/go-ipfs"&gt;go-ipfs&lt;/a&gt; - Go client for the InterPlanetary File System (IPFS), a new hypermedia distribution protocol.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-ego/riot"&gt;Riot&lt;/a&gt; - An open-source, distributed search engine.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emitter-io/emitter"&gt;emitter&lt;/a&gt; - Scalable, low latency, distributed pub/sub broker with message storage, uses MQTT, gossip and badger.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cube2222/octosql"&gt;OctoSQL&lt;/a&gt; - Query tool that allows you to join, analyse and transform data from multiple databases using SQL.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dkron.io/"&gt;Dkron&lt;/a&gt; - Distributed, fault tolerant job scheduling system.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/smallstep/certificates"&gt;smallstep/certificates&lt;/a&gt; - Step-ca is an online certificate authority for secure, automated certificate management.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/celrenheit/sandglass"&gt;Sandglass&lt;/a&gt; - distributed, horizontally scalable, persistent, time sorted message queue.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grab/talaria"&gt;TalariaDB&lt;/a&gt; - Grab's Distributed, low latency time-series database.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/salesforce/sloop"&gt;Sloop&lt;/a&gt; - Salesforce's Kubernetes History Visualization Project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://usenetexpress.com/"&gt;Usenet Express&lt;/a&gt; - Serving over 300TB of data with Badger.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt; - A push notification server written in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zero-os/0-stor"&gt;0-stor&lt;/a&gt; - Single device object store.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dispatchlabs/disgo"&gt;Dispatch Protocol&lt;/a&gt; - Blockchain protocol for distributed application data analytics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/valinurovam/garagemq"&gt;GarageMQ&lt;/a&gt; - AMQP server written in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://alash3al.github.io/redix/"&gt;RedixDB&lt;/a&gt; - A real-time persistent key-value store with the same redis protocol.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BBVA/raft-badger"&gt;BBVA&lt;/a&gt; - Raft backend implementation using BadgerDB for Hashicorp raft.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Fantom-foundation/go-lachesis"&gt;Fantom&lt;/a&gt; - aBFT Consensus platform for distributed applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/decred/dcrdata"&gt;decred&lt;/a&gt; - An open, progressive, and self-funding cryptocurrency with a system of community-based governance integrated into its blockchain.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opennetsys/c3-go"&gt;OpenNetSys&lt;/a&gt; - Create useful dApps in any software language.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/honeytrap/honeytrap"&gt;HoneyTrap&lt;/a&gt; - An extensible and opensource system for running, monitoring and managing honeypots.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/insolar/insolar"&gt;Insolar&lt;/a&gt; - Enterprise-ready blockchain platform.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iotexproject/iotex-core"&gt;IoTeX&lt;/a&gt; - The next generation of the decentralized network for IoT powered by scalability- and privacy-centric blockchains.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kataras/go-sessions"&gt;go-sessions&lt;/a&gt; - The sessions manager for Go net/http and fasthttp.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mosaicnetworks/babble"&gt;Babble&lt;/a&gt; - BFT Consensus platform for distributed applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpincas/tormenta"&gt;Tormenta&lt;/a&gt; - Embedded object-persistence layer / simple JSON database for Go projects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/timshannon/badgerhold"&gt;BadgerHold&lt;/a&gt; - An embeddable NoSQL store for querying Go types built on Badger&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/didil/goblero"&gt;Goblero&lt;/a&gt; - Pure Go embedded persistent job queue backed by BadgerDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.surfline.com"&gt;Surfline&lt;/a&gt; - Serving global wave and weather forecast data with Badger.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mosuka/cete"&gt;Cete&lt;/a&gt; - Simple and highly available distributed key-value store built on Badger. Makes it easy bringing up a cluster of Badger with Raft consensus algorithm by hashicorp/raft.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://volument.com/"&gt;Volument&lt;/a&gt; - A new take on website analytics backed by Badger.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kvdb.io/"&gt;KVdb&lt;/a&gt; - Hosted key-value store and serverless platform built on top of Badger.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/asad-awadia/terminotes"&gt;Terminotes&lt;/a&gt; - Self hosted notes storage and search server - storage powered by BadgerDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyroscope-io/pyroscope"&gt;Pyroscope&lt;/a&gt; - Open source continuous profiling platform built with BadgerDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bgokden/veri"&gt;Veri&lt;/a&gt; - A distributed feature store optimized for Search and Recommendation tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MikkelHJuul/bIter"&gt;bIter&lt;/a&gt; - A library and Iterator interface for working with the &lt;code&gt;badger.Iterator&lt;/code&gt;, simplifying from-to, and prefix mechanics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MikkelHJuul/ld"&gt;ld&lt;/a&gt; - (Lean Database) A very simple gRPC-only key-value database, exposing BadgerDB with key-range scanning semantics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/darkweak/Souin"&gt;Souin&lt;/a&gt; - A RFC compliant HTTP cache with lot of other features based on Badger for the storage. Compatible with all existing reverse-proxies.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xuperchain/xupercore"&gt;Xuperchain&lt;/a&gt; - A highly flexible blockchain architecture with great transaction performance.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qichengzx/m2"&gt;m2&lt;/a&gt; - A simple http key/value store based on the raft protocol.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChainSafe/chaindb"&gt;chaindb&lt;/a&gt; - A blockchain storage layer used by &lt;a href="https://chainsafe.github.io/gossamer/"&gt;Gossamer&lt;/a&gt;, a Go client for the &lt;a href="https://polkadot.network/"&gt;Polkadot Network&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vitalvas/vxdb"&gt;vxdb&lt;/a&gt; - Simple schema-less Key-Value NoSQL database with simplest API interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opacity/storage-node"&gt;Opacity&lt;/a&gt; - Backend implementation for the Opacity storage project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vaccovecrana/vephar"&gt;Vephar&lt;/a&gt; - A minimal key/value store using hashicorp-raft for cluster coordination and Badger for data storage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nlnwa/gowarcserver"&gt;gowarcserver&lt;/a&gt; - Open-source server for warc files. Can be used in conjunction with pywb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/onflow/flow-go"&gt;flow-go&lt;/a&gt; - A fast, secure, and developer-friendly blockchain built to support the next generation of games, apps and the digital assets that power them.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.wrgl.co"&gt;Wrgl&lt;/a&gt; - A data version control system that works like Git but specialized to store and diff CSV.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/loggie-io/loggie"&gt;Loggie&lt;/a&gt; - A lightweight, cloud-native data transfer agent and aggregator.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rfyiamcool/raft-badger"&gt;raft-badger&lt;/a&gt; - raft-badger implements LogStore and StableStore Interface of hashcorp/raft. it is used to store raft log and metadata of hashcorp/raft.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/janelia-flyem/dvid"&gt;DVID&lt;/a&gt; - A dataservice for branched versioning of a variety of data types. Originally created for large-scale brain reconstructions in Connectomics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tauraamui/kvs"&gt;KVS&lt;/a&gt; - A library for making it easy to persist, load and query full structs into BadgerDB, using an ownership hierarchy model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Boc-chi-no/LLS"&gt;LLS&lt;/a&gt; - LLS is an efficient URL Shortener that can be used to shorten links and track link usage. Support for BadgerDB and MongoDB. Improved performance by more than 30% when using BadgerDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/treeverse/lakeFS"&gt;lakeFS&lt;/a&gt; - lakeFS is an open-source data version control that transforms your object storage to Git-like repositories. lakeFS uses BadgerDB for its underlying local metadata KV store implementation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/smegg99/Goptivum"&gt;Goptivum&lt;/a&gt; - Goptivum is a better frontend and API for the Vulcan Optivum schedule program&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mftlabs.io/actionmanager"&gt;ActionManager&lt;/a&gt; - A dynamic entity manager based on rjsf schema and badger db&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/thisisdevelopment/mightymap"&gt;MightyMap&lt;/a&gt; - Mightymap: Conveys both robustness and high capability, fitting for a powerful concurrent map.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/link-society/flowg"&gt;FlowG&lt;/a&gt; - A low-code log processing facility&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/blinklabs-io/bluefin"&gt;Bluefin&lt;/a&gt; - Bluefin is a TUNA Proof of Work miner for the Fortuna smart contract on the Cardano blockchain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/blinklabs-io/cdnsd"&gt;cDNSd&lt;/a&gt; - A Cardano blockchain backed DNS server daemon&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/blinklabs-io/dingo"&gt;Dingo&lt;/a&gt; - A Cardano blockchain data node&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using Badger in a project please send a pull request to add it to the list.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you're interested in contributing to Badger see &lt;a href="https://raw.githubusercontent.com/dgraph-io/badger/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please use &lt;a href="https://github.com/dgraph-io/badger/issues"&gt;Github issues&lt;/a&gt; for filing bugs.&lt;/li&gt; 
 &lt;li&gt;Please use &lt;a href="https://github.com/orgs/dgraph-io/discussions"&gt;Discussions&lt;/a&gt; for questions, discussions, and feature requests.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>henrygd/beszel</title>
      <link>https://github.com/henrygd/beszel</link>
      <description>&lt;p&gt;Lightweight server monitoring hub with historical data, docker stats, and alerts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Beszel&lt;/h1&gt; 
&lt;p&gt;Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.&lt;/p&gt; 
&lt;p&gt;It has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/henrygd/beszel-agent"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&amp;amp;label=agent%20image%20size" alt="agent Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/henrygd/beszel"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&amp;amp;label=hub%20image%20size" alt="hub Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/henrygd/beszel/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/henrygd/beszel?color=%239944ee" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/beszel"&gt;&lt;img src="https://badges.crowdin.net/beszel/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png" alt="Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system." /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Smaller and less resource-intensive than leading solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy setup with little manual configuration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker stats&lt;/strong&gt;: Tracks CPU, memory, and network usage history for each container.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;: Users manage their own systems. Admins can share systems across users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OAuth / OIDC&lt;/strong&gt;: Supports many OAuth2 providers. Password auth can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic backups&lt;/strong&gt;: Save to and restore from disk or S3-compatible storage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - **REST API**: Use or update your data in your own scripts and applications. --&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Beszel consists of two main components: the &lt;strong&gt;hub&lt;/strong&gt; and the &lt;strong&gt;agent&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hub&lt;/strong&gt;: A web application built on &lt;a href="https://pocketbase.io/"&gt;PocketBase&lt;/a&gt; that provides a dashboard for viewing and managing connected systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: Runs on each system you want to monitor and communicates system metrics to the hub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://beszel.dev/guide/getting-started"&gt;quick start guide&lt;/a&gt; and other documentation is available on our website, &lt;a href="https://beszel.dev"&gt;beszel.dev&lt;/a&gt;. You'll be up and running in a few minutes.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://beszel.dev/image/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://beszel.dev/image/system-full.png" alt="System page" /&gt; &lt;img src="https://beszel.dev/image/settings-notifications.png" alt="Notification Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;Supported metrics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU usage&lt;/strong&gt; - Host system and Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory usage&lt;/strong&gt; - Host system and containers. Includes swap and ZFS ARC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk usage&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk I/O&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network usage&lt;/strong&gt; - Host system and containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Load average&lt;/strong&gt; - Host system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; - Host system sensors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU usage / power draw&lt;/strong&gt; - Nvidia, AMD, and Intel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt; - Host system battery charge.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Containers&lt;/strong&gt; - Status and metrics of all running Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S.M.A.R.T.&lt;/strong&gt; - Host system disk health.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Help and discussion&lt;/h2&gt; 
&lt;p&gt;Please search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.&lt;/p&gt; 
&lt;h4&gt;Bug reports and feature requests&lt;/h4&gt; 
&lt;p&gt;Bug reports and feature requests can be posted on &lt;a href="https://github.com/henrygd/beszel/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Support and general discussion&lt;/h4&gt; 
&lt;p&gt;Support requests and general discussion can be posted on &lt;a href="https://github.com/henrygd/beszel/discussions"&gt;GitHub discussions&lt;/a&gt; or the community-run &lt;a href="https://matrix.to/#/#beszel:matrix.org"&gt;Matrix room&lt;/a&gt;: &lt;code&gt;#beszel:matrix.org&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Beszel is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/henrygd/beszel/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FiloSottile/age</title>
      <link>https://github.com/FiloSottile/age</link>
      <description>&lt;p&gt;A simple, modern and secure encryption tool (and Go library) with small explicit keys, no config options, and UNIX-style composability.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/FiloSottile/age/blob/main/logo/logo_white.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/FiloSottile/age/blob/main/logo/logo.svg" /&gt; 
  &lt;img alt="The age logo, a wireframe of St. Peters dome in Rome, with the text: age, file encryption" width="600" src="https://github.com/FiloSottile/age/raw/main/logo/logo.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/filippo.io/age"&gt;&lt;img src="https://pkg.go.dev/badge/filippo.io/age.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://filippo.io/age/age.1"&gt;&lt;img src="https://img.shields.io/badge/age(1)-man%20page-lightgrey" alt="man page" /&gt;&lt;/a&gt; &lt;a href="https://age-encryption.org/v1"&gt;&lt;img src="https://img.shields.io/badge/%C2%A7%23-specification-blueviolet" alt="C2SP specification" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;age is a simple, modern and secure file encryption tool, format, and Go library.&lt;/p&gt; 
&lt;p&gt;It features small explicit keys, post-quantum support, no config options, and UNIX-style composability.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age-keygen -o key.txt
Public key: age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p
$ tar cvz ~/data | age -r age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p &amp;gt; data.tar.gz.age
$ age --decrypt -i key.txt data.tar.gz.age &amp;gt; data.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;📜 The format specification is at &lt;a href="https://age-encryption.org/v1"&gt;age-encryption.org/v1&lt;/a&gt;. age was designed by &lt;a href="https://github.com/benjojo"&gt;@benjojo&lt;/a&gt; and &lt;a href="https://github.com/FiloSottile"&gt;@FiloSottile&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;🦀 An alternative interoperable Rust implementation is available at &lt;a href="https://github.com/str4d/rage"&gt;github.com/str4d/rage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;🌍 &lt;a href="https://github.com/FiloSottile/typage"&gt;Typage&lt;/a&gt; is a TypeScript implementation. It works in the browser, Node.js, Deno, and Bun.&lt;/p&gt; 
&lt;p&gt;🔑 Hardware PIV tokens such as YubiKeys are supported through the &lt;a href="https://github.com/str4d/age-plugin-yubikey"&gt;age-plugin-yubikey&lt;/a&gt; plugin.&lt;/p&gt; 
&lt;p&gt;✨ For more plugins, implementations, tools, and integrations, check out the &lt;a href="https://github.com/FiloSottile/awesome-age"&gt;awesome age&lt;/a&gt; list.&lt;/p&gt; 
&lt;p&gt;💬 The author pronounces it &lt;code&gt;[aɡe̞]&lt;/code&gt; &lt;a href="https://translate.google.com/?sl=it&amp;amp;text=aghe"&gt;with a hard &lt;em&gt;g&lt;/em&gt;&lt;/a&gt;, like GIF, and it's always spelled lowercase.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;Homebrew (macOS or Linux)&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;brew install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MacPorts&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;port install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;winget install --id FiloSottile.age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alpine Linux v3.15+&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;apk add age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arch Linux&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;pacman -S age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Debian 12+ (Bookworm)&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;apt install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Debian 11 (Bullseye)&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;apt install age/bullseye-backports&lt;/code&gt; (&lt;a href="https://backports.debian.org/Instructions/#index2h2"&gt;enable backports&lt;/a&gt; for age v1.0.0+) &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fedora 33+&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;dnf install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gentoo Linux&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;emerge app-crypt/age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Guix System&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;guix package -i age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;NixOS / Nix&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;nix-env -i age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openSUSE Tumbleweed&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;zypper install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ubuntu 22.04+&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;apt install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Void Linux&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;xbps-install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;FreeBSD&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;pkg install age&lt;/code&gt; (security/age) &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenBSD 6.7+&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;pkg_add age&lt;/code&gt; (security/age) &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chocolatey (Windows)&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;choco install age.portable&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Scoop (Windows)&lt;/td&gt; 
   &lt;td&gt; &lt;code&gt;scoop bucket add extras &amp;amp;&amp;amp; scoop install age&lt;/code&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;On Windows, Linux, macOS, and FreeBSD you can use the pre-built binaries.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://dl.filippo.io/age/latest?for=linux/amd64
https://dl.filippo.io/age/v1.3.0?for=darwin/arm64
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you download the pre-built binaries, you can check their &lt;a href="https://raw.githubusercontent.com/FiloSottile/age/main/SIGSUM.md"&gt;Sigsum proofs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If your system has &lt;a href="https://go.dev/dl/"&gt;a supported version of Go&lt;/a&gt;, you can build from source.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install filippo.io/age/cmd/...@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Help from new packagers is very welcome.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;For the full documentation, read &lt;a href="https://filippo.io/age/age.1"&gt;the age(1) man page&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Usage:
    age [--encrypt] (-r RECIPIENT | -R PATH)... [--armor] [-o OUTPUT] [INPUT]
    age [--encrypt] --passphrase [--armor] [-o OUTPUT] [INPUT]
    age --decrypt [-i PATH]... [-o OUTPUT] [INPUT]

Options:
    -e, --encrypt               Encrypt the input to the output. Default if omitted.
    -d, --decrypt               Decrypt the input to the output.
    -o, --output OUTPUT         Write the result to the file at path OUTPUT.
    -a, --armor                 Encrypt to a PEM encoded format.
    -p, --passphrase            Encrypt with a passphrase.
    -r, --recipient RECIPIENT   Encrypt to the specified RECIPIENT. Can be repeated.
    -R, --recipients-file PATH  Encrypt to recipients listed at PATH. Can be repeated.
    -i, --identity PATH         Use the identity file at PATH. Can be repeated.

INPUT defaults to standard input, and OUTPUT defaults to standard output.
If OUTPUT exists, it will be overwritten.

RECIPIENT can be an age public key generated by age-keygen ("age1...")
or an SSH public key ("ssh-ed25519 AAAA...", "ssh-rsa AAAA...").

Recipient files contain one or more recipients, one per line. Empty lines
and lines starting with "#" are ignored as comments. "-" may be used to
read recipients from standard input.

Identity files contain one or more secret keys ("AGE-SECRET-KEY-1..."),
one per line, or an SSH key. Empty lines and lines starting with "#" are
ignored as comments. Passphrase encrypted age files can be used as
identity files. Multiple key files can be provided, and any unused ones
will be ignored. "-" may be used to read identities from standard input.

When --encrypt is specified explicitly, -i can also be used to encrypt to an
identity file symmetrically, instead or in addition to normal recipients.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiple recipients&lt;/h3&gt; 
&lt;p&gt;Files can be encrypted to multiple recipients by repeating &lt;code&gt;-r/--recipient&lt;/code&gt;. Every recipient will be able to decrypt the file.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age -o example.jpg.age -r age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p \
    -r age1lggyhqrw2nlhcxprm67z43rta597azn8gknawjehu9d9dl0jq3yqqvfafg example.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Recipient files&lt;/h4&gt; 
&lt;p&gt;Multiple recipients can also be listed one per line in one or more files passed with the &lt;code&gt;-R/--recipients-file&lt;/code&gt; flag.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat recipients.txt
# Alice
age1ql3z7hjy54pw3hyww5ayyfg7zqgvc7w3j2elw8zmrj2kg5sfn9aqmcac8p
# Bob
age1lggyhqrw2nlhcxprm67z43rta597azn8gknawjehu9d9dl0jq3yqqvfafg
$ age -R recipients.txt example.jpg &amp;gt; example.jpg.age
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the argument to &lt;code&gt;-R&lt;/code&gt; (or &lt;code&gt;-i&lt;/code&gt;) is &lt;code&gt;-&lt;/code&gt;, the file is read from standard input.&lt;/p&gt; 
&lt;h3&gt;Post-quantum keys&lt;/h3&gt; 
&lt;p&gt;To generate hybrid post-quantum keys, which are secure against future quantum computer attacks, use the &lt;code&gt;-pq&lt;/code&gt; flag with &lt;code&gt;age-keygen&lt;/code&gt;. This may become the default in the future.&lt;/p&gt; 
&lt;p&gt;Post-quantum identities start with &lt;code&gt;AGE-SECRET-KEY-PQ-1...&lt;/code&gt; and recipients with &lt;code&gt;age1pq1...&lt;/code&gt;. The recipients are unfortunately ~2000 characters long.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age-keygen -pq -o key.txt
$ age-keygen -y key.txt &amp;gt; recipient.txt
$ age -R recipient.txt example.jpg &amp;gt; example.jpg.age
$ age -d -i key.txt example.jpg.age &amp;gt; example.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Support for post-quantum keys is built into age v1.3.0 and later. Alternatively, the &lt;code&gt;age-plugin-pq&lt;/code&gt; binary can be installed and placed in &lt;code&gt;$PATH&lt;/code&gt; to add support to any version and implementation of age that supports plugins. Recipients will work out of the box, while identities will have to be converted to plugin identities with &lt;code&gt;age-plugin-pq -identity&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Passphrases&lt;/h3&gt; 
&lt;p&gt;Files can be encrypted with a passphrase by using &lt;code&gt;-p/--passphrase&lt;/code&gt;. By default age will automatically generate a secure passphrase. Passphrase protected files are automatically detected at decrypt time.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age -p secrets.txt &amp;gt; secrets.txt.age
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase "release-response-step-brand-wrap-ankle-pair-unusual-sword-train".
$ age -d secrets.txt.age &amp;gt; secrets.txt
Enter passphrase:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Passphrase-protected key files&lt;/h3&gt; 
&lt;p&gt;If an identity file passed to &lt;code&gt;-i&lt;/code&gt; is a passphrase encrypted age file, it will be automatically decrypted.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age-keygen | age -p &amp;gt; key.age
Public key: age1yhm4gctwfmrpz87tdslm550wrx6m79y9f2hdzt0lndjnehwj0ukqrjpyx5
Enter passphrase (leave empty to autogenerate a secure one):
Using the autogenerated passphrase "hip-roast-boring-snake-mention-east-wasp-honey-input-actress".
$ age -r age1yhm4gctwfmrpz87tdslm550wrx6m79y9f2hdzt0lndjnehwj0ukqrjpyx5 secrets.txt &amp;gt; secrets.txt.age
$ age -d -i key.age secrets.txt.age &amp;gt; secrets.txt
Enter passphrase for identity file "key.age":
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Passphrase-protected identity files are not necessary for most use cases, where access to the encrypted identity file implies access to the whole system. However, they can be useful if the identity file is stored remotely.&lt;/p&gt; 
&lt;h3&gt;SSH keys&lt;/h3&gt; 
&lt;p&gt;As a convenience feature, age also supports encrypting to &lt;code&gt;ssh-rsa&lt;/code&gt; and &lt;code&gt;ssh-ed25519&lt;/code&gt; SSH public keys, and decrypting with the respective private key file. (&lt;code&gt;ssh-agent&lt;/code&gt; is not supported.)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age -R ~/.ssh/id_ed25519.pub example.jpg &amp;gt; example.jpg.age
$ age -d -i ~/.ssh/id_ed25519 example.jpg.age &amp;gt; example.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that SSH key support employs more complex cryptography, and embeds a public key tag in the encrypted file, making it possible to track files that are encrypted to a specific public key.&lt;/p&gt; 
&lt;h4&gt;Encrypting to a GitHub user&lt;/h4&gt; 
&lt;p&gt;Combining SSH key support and &lt;code&gt;-R&lt;/code&gt;, you can easily encrypt a file to the SSH keys listed on a GitHub profile.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ curl https://github.com/benjojo.keys | age -R - example.jpg &amp;gt; example.jpg.age
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Keep in mind that people might not protect SSH keys long-term, since they are revokable when used only for authentication, and that SSH keys held on YubiKeys can't be used to decrypt files.&lt;/p&gt; 
&lt;h3&gt;Inspecting encrypted files&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;age-inspect&lt;/code&gt; command can display metadata about an encrypted file without decrypting it, including the recipient types, whether it uses post-quantum encryption, and the payload size.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ age-inspect secrets.age
secrets.age is an age file, version "age-encryption.org/v1".

This file is encrypted to the following recipient types:
  - "mlkem768x25519"

This file uses post-quantum encryption.

Size breakdown (assuming it decrypts successfully):

    Header                      1627 bytes
    Encryption overhead           32 bytes
    Payload                       42 bytes
                        -------------------
    Total                       1701 bytes

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For scripting, use &lt;code&gt;--json&lt;/code&gt; to get machine-readable output.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dagger/dagger</title>
      <link>https://github.com/dagger/dagger</link>
      <description>&lt;p&gt;An open-source runtime for composable workflows. Great for AI agents and CI/CD.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;What is Dagger?&lt;/h2&gt; 
&lt;p&gt;Dagger is an open-source runtime for composable workflows. It's perfect for systems with many moving parts and a strong need for &lt;strong&gt;repeatability&lt;/strong&gt;, &lt;strong&gt;modularity&lt;/strong&gt;, &lt;strong&gt;observability&lt;/strong&gt; and &lt;strong&gt;cross-platform support&lt;/strong&gt;. This makes it a great choice for AI agents and CI/CD workflows.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/dagger-factory.jpg" width="75%" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Containerized Workflow Execution:&lt;/strong&gt; Transform code into containerized, composable operations. Build reproducible workflows in any language with custom environments, parallel processing, and seamless chaining.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Universal Type System:&lt;/strong&gt; Mix and match components from any language with type-safe connections. Use the best tools from each ecosystem without translation headaches.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Artifact Caching:&lt;/strong&gt; Operations produce cacheable, immutable artifacts — even for LLMs and API calls. Your workflows run faster and cost less.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Built-in Observability:&lt;/strong&gt; Full visibility into operations with tracing, logs, and metrics. Debug complex workflows and know exactly what's happening.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/cloud-trace.gif" width="60%" /&gt; &lt;/p&gt;
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open Platform:&lt;/strong&gt; Works with any compute platform and tech stack — today and tomorrow. Ship faster, experiment freely, and don’t get locked into someone else's choices.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Augmentation:&lt;/strong&gt; Native integration of any LLM that automatically discovers and uses available functions in your workflow. Ship mind-blowing agents in just a few dozen lines of code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive Terminal:&lt;/strong&gt; Directly interact with your workflow or agents in real-time through your terminal. Prototype, test, debug, and ship even faster.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/da-robots-white-box.svg?sanitize=true" width="60%" /&gt; &lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.dagger.io/ai-agents"&gt;Dagger for AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.dagger.io/quickstart"&gt;Dagger for CI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join the community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://discord.gg/NpzVhsGnZu"&gt;Dagger community server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/dagger_io"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;a href="https://dagger.io/community"&gt;community activities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read more in our &lt;a href="https://docs.dagger.io"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing or building dagger from scratch? See &lt;a href="https://github.com/dagger/dagger/tree/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href="https://github.com/hashicorp/vault/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hashicorp/vault/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise"&gt;&lt;img src="https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000" alt="vault enterprise" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault's security and our users' trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/vault"&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href="https://groups.google.com/group/hashicorp-announce"&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href="https://discuss.hashicorp.com/c/vault"&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/vault/tutorials"&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href="https://developer.hashicorp.com/certifications/security-automation"&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation source: &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;https://github.com/hashicorp/web-unified-docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width="300" alt="Vault Logo" src="https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png" /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, &lt;a href="https://www.consul.io"&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're new to Vault and want to get started with security automation, please check out our &lt;a href="https://learn.hashicorp.com/collections/vault/getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/vault"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href="https://github.com/hashicorp/vault-examples"&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href="https://github.com/hashicorp/hello-vault-go"&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/collections/vault/certification"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href="https://pkg.go.dev/cmd/go#hdr-Environment_variables"&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for 'https://github.com'&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ git config --global --add url."git@github.com:".insteadOf "https://github.com/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/hashicorp/vault/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise"&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault", // or "hashicorp/vault-enterprise"
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault-enterprise",
    ImageTag:  "latest",
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn't become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>rishikanthc/Scriberr</title>
      <link>https://github.com/rishikanthc/Scriberr</link>
      <description>&lt;p&gt;Self-hosted AI audio transcription&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/logo.svg?sanitize=true" height="90" style="vertical-align: middle;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/logo-text.svg?sanitize=true" height="80" style="vertical-align: middle;" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; Scriberr is an open-source, and completely offline audio transcription application designed for self-hosters who value privacy and performance. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://scriberr.app"&gt;Website&lt;/a&gt; • &lt;a href="https://scriberr.app/docs/"&gt;Docs&lt;/a&gt; • &lt;a href="https://scriberr.app/api"&gt;API Reference&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://ko-fi.com/H2H41KQZA3" target="_blank"&gt;&lt;img height="36" style="border:0px;height:36px;" src="https://storage.ko-fi.com/cdn/kofi6.png?v=6" border="0" alt="Buy Me a Coffee at ko-fi.com" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/hero.png" alt="Scriberr Desktop App" width="800" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://cdn.prod.website-files.com/620d732b1f1f7b244ac89f0e/66b294e51ee15f18dd2b171e_recall-logo.svg?sanitize=true" alt="recall.ai-logo" /&gt; Meeting Transcription API&lt;br /&gt; If you're looking for a transcription API for meetings, consider checking out &lt;a href="https://www.recall.ai/?utm_source=github&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=rishikanthc-scriberr"&gt;Recall.ai&lt;/a&gt;, an API that works with Zoom, Google Meet, Microsoft Teams, and more. Recall.ai diarizes by pulling the speaker data and seperate audio streams from the meeting platforms, which means 100% accurate speaker diarization with actual speaker names.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;At its core, Scriberr allows you to transcribe audio and video locally on your machine, ensuring no data is ever sent to a third-party cloud provider. Leveraging state-of-the-art machine learning models (such as &lt;strong&gt;NVIDIA Parakeet&lt;/strong&gt;, and &lt;strong&gt;Canary&lt;/strong&gt;) or the older more popular &lt;strong&gt;Whisper&lt;/strong&gt; models, it delivers high-accuracy text with word-level timing.&lt;/p&gt; 
&lt;p&gt;Scriberr goes beyond simple transcription and provides various advanced capabilities. It combines powerful under-the-hood AI with a polished, fluid user interface that makes managing your recordings feel effortless. Whether you are sorting through voice notes or analyzing long meetings, Scriberr provides a beautiful environment to get work done:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Speaker Detection&lt;/strong&gt;: Scriberr automatically detects different speakers (Diarization) and labels exactly who said what.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat with your Audio&lt;/strong&gt;: Connect seamlessly with Ollama or OpenAI API compatible providers. You can generate summaries, ask questions, or have a full conversation with your transcripts right inside the app.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built for your Workflow&lt;/strong&gt;: With extensive APIs and Folder Watcher that automatically processes new files in a folder, Scriberr fits right into your existing automations (like n8n).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Capture &amp;amp; Organize&lt;/strong&gt;: Use the built-in audio recorder to capture thoughts on the fly, and the integrated note-taking features to annotate your transcripts as you listen.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native Experience everywhere&lt;/strong&gt;: Scriberr supports PWA (Progressive Web App) installation, giving you a native app experience on your desktop or mobile device.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A Polished UI&lt;/strong&gt;: I’ve focused on the little UI niceties that make the app feel responsive and satisfying to use.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://scriberr.app/docs/features"&gt;View full list of features →&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Why I built this&lt;/h3&gt; 
&lt;p&gt;The inspiration for Scriberr was born out of privacy paranoia and not wanting to pay for subscription. About a year ago, I purchased a &lt;a href="https://www.plaud.ai/"&gt;Plaud Note&lt;/a&gt; for recording voice memos. I loved the device itself; the form factor, microphone quality, and workflow were excellent.&lt;/p&gt; 
&lt;p&gt;However, transcription was done on their cloud servers. As someone who is paranoid about privacy I wasn't comfortable with uploading my recordings to a third party provider. Moreover I was hit with subscription costs: $100 a year for 20 hours of transcription per month, or $240 a year for unlimited access. As an avid self-hoster with a background in ML and AI, it felt wrong to pay such a premium for a service I knew I could engineer myself.&lt;/p&gt; 
&lt;p&gt;I decided to build Scriberr to bridge that gap, creating a powerful, private, and free alternative for everyone.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to expand&lt;/summary&gt; 
 &lt;p align="center"&gt; &lt;img alt="Transcript view" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/transcript-light.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Transcript reader with playback follow‑along and seek‑from‑text.&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="Chat with Audio" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/chat.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Chat with your transcripts using local LLMs or OpenAI.&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="Notes and Highlights" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/notes.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Highlight key moments and take notes while listening.&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="AI Summaries" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/ai-summary.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Generate comprehensive summaries of your recordings.&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;strong style="font-size: 1.2em;"&gt;Dark Mode&lt;/strong&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="Homepage Dark Mode" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/homepage-dark.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Homepage in Dark Mode.&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="Transcript Dark Mode" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/transcript-dark.png" width="720" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Transcript view in Dark Mode.&lt;/em&gt;&lt;/p&gt; 
 &lt;h3&gt;Mobile&lt;/h3&gt; 
 &lt;p align="center"&gt; &lt;img alt="Mobile Homepage" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/homepage-mobile.PNG" width="300" /&gt; &lt;img alt="Mobile Homepage Dark" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/homepage-mobile-dark.PNG" width="300" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;PWA mobile app (Light &amp;amp; Dark).&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img alt="Mobile Transcript" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/transcript-mobile.PNG" width="300" /&gt; &lt;img alt="Mobile Transcript Dark" src="https://raw.githubusercontent.com/rishikanthc/Scriberr/main/screenshots/transcript-mobile-dark.PNG" width="300" /&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;em&gt;Mobile transcript reading experience.&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Get Scriberr running on your system in a few minutes.&lt;/p&gt; 
&lt;h3&gt;Migrating from v1.1.0&lt;/h3&gt; 
&lt;p&gt;If you are upgrading from v1.1.0, please follow these steps to ensure a smooth transition. Version 1.2.0 introduces a separation between application data (database, uploads) and model data (Python environments).&lt;/p&gt; 
&lt;h4&gt;1. Update Volume Mounts&lt;/h4&gt; 
&lt;p&gt;You will need to update your Docker volume configuration to split your data:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Application Data:&lt;/strong&gt; Bind your existing data folder (containing &lt;code&gt;scriberr.db&lt;/code&gt;, &lt;code&gt;jwt_secret&lt;/code&gt;, &lt;code&gt;transcripts/&lt;/code&gt;, and &lt;code&gt;uploads/&lt;/code&gt;) to &lt;code&gt;/app/data&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Environment:&lt;/strong&gt; Create a &lt;strong&gt;new, empty folder&lt;/strong&gt; and bind it to &lt;code&gt;/app/whisperx-env&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Clean Up Old Environments&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;CRITICAL:&lt;/strong&gt; You must delete any existing &lt;code&gt;whisperx-env&lt;/code&gt; folder from your previous installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The Python environment and models need to be reinitialized for v1.2.0. If the application detects an old environment, it may attempt to use it, leading to compatibility errors. Starting with a fresh &lt;code&gt;/app/whisperx-env&lt;/code&gt; volume ensures the correct dependencies are installed.&lt;/p&gt; 
&lt;h3&gt;Install with Homebrew (macOS &amp;amp; Linux)&lt;/h3&gt; 
&lt;p&gt;The easiest way to install Scriberr is using Homebrew. If you don’t have Homebrew installed, &lt;a href="https://brew.sh/"&gt;get it here first&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Add the Scriberr tap
brew tap rishikanthc/scriberr

# Install Scriberr (automatically installs UV dependency)
brew install scriberr

# Start the server
scriberr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Scriberr works out of the box. However, for Homebrew or manual installations, you can customize the application behavior using environment variables or a &lt;code&gt;.env&lt;/code&gt; file placed in the same directory as the binary (or where you run the command from).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Docker Users:&lt;/strong&gt; You can ignore this section if you are using &lt;code&gt;docker-compose.yml&lt;/code&gt;, as these values are already configured with sane defaults.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Variable&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Default&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The port the server listens on.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;8080&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The interface to bind to.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;APP_ENV&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Application environment (&lt;code&gt;development&lt;/code&gt; or &lt;code&gt;production&lt;/code&gt;).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;development&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;ALLOWED_ORIGINS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CORS allowed origins (comma separated).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;http://localhost:5173,http://localhost:8080&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABASE_PATH&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Path to the SQLite database file.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data/scriberr.db&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;UPLOAD_DIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Directory for storing uploaded files.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data/uploads&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TRANSCRIPTS_DIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Directory for storing transcripts.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data/transcripts&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;WHISPERX_ENV&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Path to the managed Python environment for models.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data/whisperx-env&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API Key for OpenAI (optional).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;""&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;JWT_SECRET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Secret for signing JWTs. Auto-generated if not set.&lt;/td&gt; 
   &lt;td align="left"&gt;Auto-generated&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Example &lt;code&gt;.env&lt;/code&gt; file:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Server settings
HOST=localhost
PORT=8080
APP_ENV=production

# Paths
DATABASE_PATH=/var/lib/scriberr/data/scriberr.db
UPLOAD_DIR=/var/lib/scriberr/data/uploads

# Security
JWT_SECRET=your-super-secret-key-change-this
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Deployment&lt;/h3&gt; 
&lt;p&gt;For a containerized setup, you can use Docker. We provide two configurations: one for standard CPU usage and one optimized for NVIDIA GPUs (CUDA).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Permissions:&lt;/strong&gt; Ensure you set the &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; environment variables to your host user's UID and GID (typically &lt;code&gt;1000&lt;/code&gt; on Linux) to avoid permission issues with the SQLite database. You can find your UID/GID by running &lt;code&gt;id&lt;/code&gt; on your host.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP vs HTTPS:&lt;/strong&gt; By default, Scriberr enables &lt;strong&gt;Secure Cookies&lt;/strong&gt; in production. If you are accessing the app via plain HTTP (not HTTPS), you MUST set &lt;code&gt;SECURE_COOKIES=false&lt;/code&gt; in your environment variables, otherwise you will encounter "Unable to load audio stream" errors.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Standard Deployment (CPU)&lt;/h4&gt; 
&lt;p&gt;Use this configuration for running Scriberr on any machine without a dedicated NVIDIA GPU.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a file named &lt;code&gt;docker-compose.yml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  scriberr:
    image: ghcr.io/rishikanthc/scriberr:v1.2.0
    ports:
      - "8080:8080"
    volumes:
      - scriberr_data:/app/data # volume for data
      - env_data:/app/whisperx-env # volume for models and python envs
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - APP_ENV=production # DO NOT CHANGE THIS
      # CORS: comma-separated list of allowed origins for production
      # - ALLOWED_ORIGINS=https://your-domain.com
      # - SECURE_COOKIES=false # Uncomment this ONLY if you are not using SSL
    restart: unless-stopped

volumes:
  scriberr_data: {}
  env_data: {}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run the container:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;NVIDIA GPU Deployment (CUDA)&lt;/h4&gt; 
&lt;p&gt;If you have a compatible NVIDIA GPU, this configuration enables hardware acceleration for significantly faster transcription.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ensure you have the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"&gt;NVIDIA Container Toolkit&lt;/a&gt; installed.&lt;/li&gt; 
 &lt;li&gt;Create a file named &lt;code&gt;docker-compose.cuda.yml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  scriberr:
    image: ghcr.io/rishikanthc/scriberr-cuda:v1.2.0
    ports:
      - "8080:8080"
    volumes:
      - scriberr_data:/app/data # volume for data
      - env_data:/app/whisperx-env # volume for models and python envs
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - APP_ENV=production # DO NOT CHANGE THIS
      # CORS: comma-separated list of allowed origins for production
      # - ALLOWED_ORIGINS=https://your-domain.com
      # - SECURE_COOKIES=false # Uncomment this ONLY if you are not using SSL

volumes:
  scriberr_data: {}
  env_data: {}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Run the container with the CUDA configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.cuda.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;GPU Compatibility&lt;/h4&gt; 
&lt;p&gt;Scriberr provides separate Docker images for different NVIDIA GPU generations due to CUDA/PyTorch compatibility requirements:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;GPU Generation&lt;/th&gt; 
   &lt;th align="left"&gt;Compute Capability&lt;/th&gt; 
   &lt;th align="left"&gt;Docker Image&lt;/th&gt; 
   &lt;th align="left"&gt;Docker Compose File&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;GTX 10-series (Pascal)&lt;/td&gt; 
   &lt;td align="left"&gt;sm_61&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scriberr-cuda&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;docker-compose.cuda.yml&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RTX 20-series (Turing)&lt;/td&gt; 
   &lt;td align="left"&gt;sm_75&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scriberr-cuda&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;docker-compose.cuda.yml&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RTX 30-series (Ampere)&lt;/td&gt; 
   &lt;td align="left"&gt;sm_86&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scriberr-cuda&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;docker-compose.cuda.yml&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;RTX 40-series (Ada Lovelace)&lt;/td&gt; 
   &lt;td align="left"&gt;sm_89&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scriberr-cuda&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;docker-compose.cuda.yml&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;RTX 50-series (Blackwell)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;sm_120&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scriberr-cuda-blackwell&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;docker-compose.blackwell.yml&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;RTX 50-series users (RTX 5080, 5090, etc.):&lt;/strong&gt; You must use the Blackwell-specific image. The standard CUDA image will not work due to PyTorch CUDA compatibility requirements. Use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.blackwell.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for local builds:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.build.blackwell.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;App Startup&lt;/h3&gt; 
&lt;p&gt;When you run Scriberr for the first time, it may take several minutes to start. This is normal!&lt;/p&gt; 
&lt;p&gt;The application needs to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Initialize the Python environments.&lt;/li&gt; 
 &lt;li&gt;Download the necessary machine learning models (Whisper, PyAnnote, NVIDIA NeMo).&lt;/li&gt; 
 &lt;li&gt;Configure the database.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Subsequent runs will be much faster&lt;/strong&gt; because all models and environments are persisted to the &lt;code&gt;env_data&lt;/code&gt; volume (or your local mapped folders).&lt;/p&gt; 
&lt;p&gt;You will know the application is ready when you see the line: &lt;code&gt;msg="Scriberr is ready" url=http://0.0.0.0:8080&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;h4&gt;1. SQLite OOM Error (out of memory)&lt;/h4&gt; 
&lt;p&gt;If you see an "out of memory (14)" error from SQLite (specifically &lt;code&gt;SQLITE_CANTOPEN&lt;/code&gt;), it usually means a permissions issue. The database engine cannot create temporary files in the data directory.&lt;/p&gt; 
&lt;p&gt;You can fix this by setting the &lt;code&gt;PUID&lt;/code&gt; and &lt;code&gt;PGID&lt;/code&gt; in your &lt;code&gt;docker-compose.yml&lt;/code&gt; to match your host user's UID and GID, or by manually changing the ownership of the mapped folders on your host:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you used a named volume (e.g., 'scriberr_scriberr_data'):
sudo chown -R 1000:1000 /var/lib/docker/volumes/scriberr_scriberr_data/_data

# If you mapped a specific host folder (e.g., ./scriberr_data):
sudo chown -R 1000:1000 ./scriberr_data
sudo chown -R 1000:1000 ./env_data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;1000&lt;/code&gt; with the value you set for &lt;code&gt;PUID&lt;/code&gt;/&lt;code&gt;PGID&lt;/code&gt; (default is &lt;code&gt;1000&lt;/code&gt;).&lt;/p&gt; 
&lt;h4&gt;2. "Unable to load audio stream"&lt;/h4&gt; 
&lt;p&gt;If the application loads but you cannot play or see the audio waveform (receiving "Unable to load audio stream"), this is often due to the &lt;strong&gt;Secure Cookies&lt;/strong&gt; security flag.&lt;/p&gt; 
&lt;p&gt;By default, when &lt;code&gt;APP_ENV=production&lt;/code&gt;, Scriberr enables &lt;code&gt;SECURE_COOKIES=true&lt;/code&gt;. This prevents cookies from being sent over insecure (HTTP) connections.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Recommended:&lt;/strong&gt; Deploy Scriberr behind a Reverse Proxy (like Nginx, Caddy, or Traefik) and use SSL/TLS (HTTPS).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alternative:&lt;/strong&gt; If you must access over plain HTTP, set the following environment variable in your &lt;code&gt;docker-compose.yml&lt;/code&gt;: &lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  - SECURE_COOKIES=false
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Post installation&lt;/h2&gt; 
&lt;p&gt;Once you have Scriberr up and running:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Configure Diarization&lt;/strong&gt;: To enable speaker identification, visit the &lt;a href="https://scriberr.app/docs/configuration"&gt;Configuration page&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Usage Guide&lt;/strong&gt;: For a detailed usage guide, visit &lt;a href="https://scriberr.app/docs/usage"&gt;https://scriberr.app/docs/usage&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;LLM Disclosure&lt;/h2&gt; 
&lt;p&gt;This project was developed using AI agents as pair programmer. It was NOT vibe coded. For context I’m a ML/AI researcher by profession and I have been programming for over a decade now. The codebase follows software engineering best practices and principles and all architecture decisions were made by me. All code generated by LLMs was reviewed and tested to the best of my abilities.&lt;/p&gt; 
&lt;h2&gt;Donating&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/H2H41KQZA3" target="_blank"&gt;&lt;img height="36" style="border:0px;height:36px;" src="https://storage.ko-fi.com/cdn/kofi6.png?v=6" border="0" alt="Buy Me a Coffee at ko-fi.com" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="官方网站" src="https://img.shields.io/badge/官方网站-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="微信对话开放平台" src="https://img.shields.io/badge/微信对话开放平台-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;简体中文&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;日本語&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;💡 WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;📌 Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;🔌 &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🔒 Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🏗️ Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;🎯 Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🧠 Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📚 Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌐 Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔌 MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚙️ Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔒 Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📊 Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🧩 Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;✅ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;✅ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;✅ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;✅ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;✅ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;✅ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;✅ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;✅ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;✅ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;✅ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;✅ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;✅ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;✅ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;✅ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;✅ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;✅ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;h3&gt;🛠 Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📦 Installation&lt;/h3&gt; 
&lt;h4&gt;① Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;③.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;④ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🌐 Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔌 Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔗 Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1️⃣ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2️⃣ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🔧 Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ①② and go directly to steps ③④.&lt;/p&gt; 
&lt;h3&gt;① Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;② Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;③ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;④ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;📱 Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;📘 API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🧭 Developer Guide&lt;/h2&gt; 
&lt;h3&gt;⚡ Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;✅ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;✅ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;✅ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;📁 Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
├── client/      # go client
├── cmd/         # Main entry point
├── config/      # Configuration files
├── docker/      # docker images files
├── docreader/   # Document parsing app
├── docs/        # Project documentation
├── frontend/    # Frontend app
├── internal/    # Core business logic
├── mcp-server/  # MCP server
├── migrations/  # DB migration scripts
└── scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;🎯 How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;✨ &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;🧪 &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📋 Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;🎨 Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;📝 Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;👥 Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;📈 Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png" /&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status" /&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack" /&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br /&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br /&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br /&gt; &lt;/strong&gt; &lt;br /&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2"&gt;https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP ports: &lt;strong&gt;3478&lt;/strong&gt;, &lt;strong&gt;49152-65535&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/about-netbird/high-level-dia.png" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)" /&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuard®&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>projectdiscovery/katana</title>
      <link>https://github.com/projectdiscovery/katana</link>
      <description>&lt;p&gt;A next-generation crawling and spidering framework.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/8293321/196779266-421c79d4-643a-4f73-9b54-3da379bbac09.png" alt="katana" width="200px" /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h4 align="center"&gt;A next-generation crawling and spidering framework&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://goreportcard.com/report/github.com/projectdiscovery/katana"&gt;&lt;img src="https://goreportcard.com/badge/github.com/projectdiscovery/katana" /&gt;&lt;/a&gt; &lt;a href="https://github.com/projectdiscovery/katana/issues"&gt;&lt;img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat" /&gt;&lt;/a&gt; &lt;a href="https://github.com/projectdiscovery/katana/releases"&gt;&lt;img src="https://img.shields.io/github/release/projectdiscovery/katana" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/pdiscoveryio"&gt;&lt;img src="https://img.shields.io/twitter/follow/pdiscoveryio.svg?logo=twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/projectdiscovery"&gt;&lt;img src="https://img.shields.io/discord/695645237418131507.svg?logo=discord" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#features"&gt;Features&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#installation"&gt;Installation&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#usage"&gt;Usage&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#scope-control"&gt;Scope&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#crawler-configuration"&gt;Config&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#filters"&gt;Filters&lt;/a&gt; • &lt;a href="https://discord.gg/projectdiscovery"&gt;Join Discord&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/8293321/199371558-daba03b6-bf9c-4883-8506-76497c6c3a44.png" alt="image" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fast And fully configurable web crawling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt; and &lt;strong&gt;Headless&lt;/strong&gt; mode&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt; parsing / crawling&lt;/li&gt; 
 &lt;li&gt;Customizable &lt;strong&gt;automatic form filling&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scope control&lt;/strong&gt; - Preconfigured field / Regex&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable output&lt;/strong&gt; - Preconfigured fields&lt;/li&gt; 
 &lt;li&gt;INPUT - &lt;strong&gt;STDIN&lt;/strong&gt;, &lt;strong&gt;URL&lt;/strong&gt; and &lt;strong&gt;LIST&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;OUTPUT - &lt;strong&gt;STDOUT&lt;/strong&gt;, &lt;strong&gt;FILE&lt;/strong&gt; and &lt;strong&gt;JSON&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;katana requires Go 1.24+ to install successfully. If you encounter any installation issues, we recommend trying with the latest available version of Go, as the minimum required version may have changed. Run the command below or download a pre-compiled binary from the &lt;a href="https://github.com/projectdiscovery/katana/releases"&gt;release page&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;CGO_ENABLED=1 go install github.com/projectdiscovery/katana/cmd/katana@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;More options to install / run katana-&lt;/strong&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Docker&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;To install / update docker to latest tag -&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker pull projectdiscovery/katana:latest
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;To run katana in standard mode using docker -&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker run projectdiscovery/katana:latest -u https://tesla.com
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;To run katana in headless mode using docker -&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;docker run projectdiscovery/katana:latest -u https://tesla.com -system-chrome -headless
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Ubuntu&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;It's recommended to install the following prerequisites -&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt update
sudo snap refresh
sudo apt install zip curl wget git
sudo snap install golang --classic
wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add - 
sudo sh -c 'echo "deb http://dl.google.com/linux/chrome/deb/ stable main" &amp;gt;&amp;gt; /etc/apt/sources.list.d/google.list'
sudo apt update 
sudo apt install google-chrome-stable
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;install katana -&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/projectdiscovery/katana/cmd/katana@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will display help for the tool. Here are all the switches it supports.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;Katana is a fast crawler focused on execution in automation
pipelines offering both headless and non-headless crawling.

Usage:
  ./katana [flags]

Flags:
INPUT:
   -u, -list string[]     target url / list to crawl
   -resume string         resume scan using resume.cfg
   -e, -exclude string[]  exclude host matching specified filter ('cdn', 'private-ips', cidr, ip, regex)

CONFIGURATION:
   -r, -resolvers string[]       list of custom resolver (file or comma separated)
   -d, -depth int                maximum depth to crawl (default 3)
   -jc, -js-crawl                enable endpoint parsing / crawling in javascript file
   -jsl, -jsluice                enable jsluice parsing in javascript file (memory intensive)
   -ct, -crawl-duration value    maximum duration to crawl the target for (s, m, h, d) (default s)
   -kf, -known-files string      enable crawling of known files (all,robotstxt,sitemapxml), a minimum depth of 3 is required to ensure all known files are properly crawled.
   -mrs, -max-response-size int  maximum response size to read (default 4194304)
   -timeout int                  time to wait for request in seconds (default 10)
   -aff, -automatic-form-fill    enable automatic form filling (experimental)
   -fx, -form-extraction         extract form, input, textarea &amp;amp; select elements in jsonl output
   -retry int                    number of times to retry the request (default 1)
   -proxy string                 http/socks5 proxy to use
   -td, -tech-detect             enable technology detection
   -H, -headers string[]         custom header/cookie to include in all http request in header:value format (file)
   -config string                path to the katana configuration file
   -fc, -form-config string      path to custom form configuration file
   -flc, -field-config string    path to custom field configuration file
   -s, -strategy string          Visit strategy (depth-first, breadth-first) (default "depth-first")
   -iqp, -ignore-query-params    Ignore crawling same path with different query-param values
   -tlsi, -tls-impersonate       enable experimental client hello (ja3) tls randomization
   -dr, -disable-redirects       disable following redirects (default false)

DEBUG:
   -health-check, -hc        run diagnostic check up
   -elog, -error-log string  file to write sent requests error log
   -pprof-server             enable pprof server

HEADLESS:
   -hl, -headless                    enable headless hybrid crawling (experimental)
   -sc, -system-chrome               use local installed chrome browser instead of katana installed
   -sb, -show-browser                show the browser on the screen with headless mode
   -ho, -headless-options string[]   start headless chrome with additional options
   -nos, -no-sandbox                 start headless chrome in --no-sandbox mode
   -cdd, -chrome-data-dir string     path to store chrome browser data
   -scp, -system-chrome-path string  use specified chrome browser for headless crawling
   -noi, -no-incognito               start headless chrome without incognito mode
   -cwu, -chrome-ws-url string       use chrome browser instance launched elsewhere with the debugger listening at this URL
   -xhr, -xhr-extraction             extract xhr request url,method in jsonl output

SCOPE:
   -cs, -crawl-scope string[]       in scope url regex to be followed by crawler
   -cos, -crawl-out-scope string[]  out of scope url regex to be excluded by crawler
   -fs, -field-scope string         pre-defined scope field (dn,rdn,fqdn) or custom regex (e.g., '(company-staging.io|company.com)') (default "rdn")
   -ns, -no-scope                   disables host based default scope
   -do, -display-out-scope          display external endpoint from scoped crawling

FILTER:
   -mr, -match-regex string[]             regex or list of regex to match on output url (cli, file)
   -fr, -filter-regex string[]            regex or list of regex to filter on output url (cli, file)
   -f, -field string                      field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir) (Deprecated: use -output-template instead)
   -sf, -store-field string               field to store in per-host output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)
   -em, -extension-match string[]         match output for given extension (eg, -em php,html,js)
   -ef, -extension-filter string[]        filter output for given extension (eg, -ef png,css)
   -ndef, -no-default-ext-filter bool     remove default extensions from the filter list
   -mdc, -match-condition string          match response with dsl based condition
   -fdc, -filter-condition string         filter response with dsl based condition
   -duf, -disable-unique-filter           disable duplicate content filtering

RATE-LIMIT:
   -c, -concurrency int          number of concurrent fetchers to use (default 10)
   -p, -parallelism int          number of concurrent inputs to process (default 10)
   -rd, -delay int               request delay between each request in seconds
   -rl, -rate-limit int          maximum requests to send per second (default 150)
   -rlm, -rate-limit-minute int  maximum number of requests to send per minute

UPDATE:
   -up, -update                 update katana to latest version
   -duc, -disable-update-check  disable automatic katana update check

OUTPUT:
   -o, -output string                file to write output to
   -ot, -output-template string      custom output template
   -sr, -store-response              store http requests/responses
   -srd, -store-response-dir string  store http requests/responses to custom directory
   -ncb, -no-clobber                 do not overwrite output file
   -sfd, -store-field-dir string     store per-host field to custom directory
   -or, -omit-raw                    omit raw requests/responses from jsonl output
   -ob, -omit-body                   omit response body from jsonl output
   -lof, -list-output-fields         list available fields for jsonl output format
   -eof, -exclude-output-fields      exclude fields from jsonl output
   -j, -jsonl                        write output in jsonl format
   -nc, -no-color                    disable output content coloring (ANSI escape codes)
   -silent                           display output only
   -v, -verbose                      display verbose output
   -debug                            display debug output
   -version                          display project version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running Katana&lt;/h2&gt; 
&lt;h3&gt;Input for katana&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;katana&lt;/strong&gt; requires &lt;strong&gt;url&lt;/strong&gt; or &lt;strong&gt;endpoint&lt;/strong&gt; to crawl and accepts single or multiple inputs.&lt;/p&gt; 
&lt;p&gt;Input URL can be provided using &lt;code&gt;-u&lt;/code&gt; option, and multiple values can be provided using comma-separated input, similarly &lt;strong&gt;file&lt;/strong&gt; input is supported using &lt;code&gt;-list&lt;/code&gt; option and additionally piped input (stdin) is also supported.&lt;/p&gt; 
&lt;h4&gt;URL Input&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;katana -u https://tesla.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Multiple URL Input (comma-separated)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;katana -u https://tesla.com,https://google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;List Input&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cat url_list.txt

https://tesla.com
https://google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;katana -list url_list.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;STDIN (piped) Input&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;echo https://tesla.com | katana
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cat domains | httpx | katana
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example running katana -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://youtube.com

   __        __                
  / /_____ _/ /____ ____  ___ _
 /  '_/ _  / __/ _  / _ \/ _  /
/_/\_\\_,_/\__/\_,_/_//_/\_,_/ v0.0.1                     

      projectdiscovery.io

[WRN] Use with caution. You are responsible for your actions.
[WRN] Developers assume no liability and are not responsible for any misuse or damage.
https://www.youtube.com/
https://www.youtube.com/about/
https://www.youtube.com/about/press/
https://www.youtube.com/about/copyright/
https://www.youtube.com/t/contact_us/
https://www.youtube.com/creators/
https://www.youtube.com/ads/
https://www.youtube.com/t/terms
https://www.youtube.com/t/privacy
https://www.youtube.com/about/policies/
https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&amp;amp;utm_source=ythp&amp;amp;utm_medium=LeftNav&amp;amp;utm_content=txt&amp;amp;u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen
https://www.youtube.com/new
https://m.youtube.com/
https://www.youtube.com/s/desktop/4965577f/jsbin/desktop_polymer.vflset/desktop_polymer.js
https://www.youtube.com/s/desktop/4965577f/cssbin/www-main-desktop-home-page-skeleton.css
https://www.youtube.com/s/desktop/4965577f/cssbin/www-onepick.css
https://www.youtube.com/s/_/ytmainappweb/_/ss/k=ytmainappweb.kevlar_base.0Zo5FUcPkCg.L.B1.O/am=gAE/d=0/rs=AGKMywG5nh5Qp-BGPbOaI1evhF5BVGRZGA
https://www.youtube.com/opensearch?locale=en_GB
https://www.youtube.com/manifest.webmanifest
https://www.youtube.com/s/desktop/4965577f/cssbin/www-main-desktop-watch-page-skeleton.css
https://www.youtube.com/s/desktop/4965577f/jsbin/web-animations-next-lite.min.vflset/web-animations-next-lite.min.js
https://www.youtube.com/s/desktop/4965577f/jsbin/custom-elements-es5-adapter.vflset/custom-elements-es5-adapter.js
https://www.youtube.com/s/desktop/4965577f/jsbin/webcomponents-sd.vflset/webcomponents-sd.js
https://www.youtube.com/s/desktop/4965577f/jsbin/intersection-observer.min.vflset/intersection-observer.min.js
https://www.youtube.com/s/desktop/4965577f/jsbin/scheduler.vflset/scheduler.js
https://www.youtube.com/s/desktop/4965577f/jsbin/www-i18n-constants-en_GB.vflset/www-i18n-constants.js
https://www.youtube.com/s/desktop/4965577f/jsbin/www-tampering.vflset/www-tampering.js
https://www.youtube.com/s/desktop/4965577f/jsbin/spf.vflset/spf.js
https://www.youtube.com/s/desktop/4965577f/jsbin/network.vflset/network.js
https://www.youtube.com/howyoutubeworks/
https://www.youtube.com/trends/
https://www.youtube.com/jobs/
https://www.youtube.com/kids/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Crawling Mode&lt;/h2&gt; 
&lt;h3&gt;Standard Mode&lt;/h3&gt; 
&lt;p&gt;Standard crawling modality uses the standard go http library under the hood to handle HTTP requests/responses. This modality is much faster as it doesn't have the browser overhead. Still, it analyzes HTTP responses body as is, without any javascript or DOM rendering, potentially missing post-dom-rendered endpoints or asynchronous endpoint calls that might happen in complex web applications depending, for example, on browser-specific events.&lt;/p&gt; 
&lt;h3&gt;Headless Mode&lt;/h3&gt; 
&lt;p&gt;Headless mode hooks internal headless calls to handle HTTP requests/responses directly within the browser context. This offers two advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The HTTP fingerprint (TLS and user agent) fully identify the client as a legitimate browser&lt;/li&gt; 
 &lt;li&gt;Better coverage since the endpoints are discovered analyzing the standard raw response, as in the previous modality, and also the browser-rendered one with javascript enabled.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Headless crawling is optional and can be enabled using &lt;code&gt;-headless&lt;/code&gt; option.&lt;/p&gt; 
&lt;p&gt;Here are other headless CLI options -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h headless

Flags:
HEADLESS:
   -hl, -headless                    enable headless hybrid crawling (experimental)
   -sc, -system-chrome               use local installed chrome browser instead of katana installed
   -sb, -show-browser                show the browser on the screen with headless mode
   -ho, -headless-options string[]   start headless chrome with additional options
   -nos, -no-sandbox                 start headless chrome in --no-sandbox mode
   -cdd, -chrome-data-dir string     path to store chrome browser data
   -scp, -system-chrome-path string  use specified chrome browser for headless crawling
   -noi, -no-incognito               start headless chrome without incognito mode
   -cwu, -chrome-ws-url string       use chrome browser instance launched elsewhere with the debugger listening at this URL
   -xhr, -xhr-extraction             extract xhr requests
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-sandbox&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Runs headless chrome browser with &lt;strong&gt;no-sandbox&lt;/strong&gt; option, useful when running as root user.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -headless -no-sandbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-incognito&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Runs headless chrome browser without incognito mode, useful when using the local browser.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -headless -no-incognito
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-headless-options&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;When crawling in headless mode, additional chrome options can be specified using &lt;code&gt;-headless-options&lt;/code&gt;, for example -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -headless -system-chrome -headless-options --disable-gpu,proxy-server=http://127.0.0.1:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Scope Control&lt;/h2&gt; 
&lt;p&gt;Crawling can be endless if not scoped, as such katana comes with multiple support to define the crawl scope.&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-field-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Most handy option to define scope with predefined field name, &lt;code&gt;rdn&lt;/code&gt; being default option for field scope.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;rdn&lt;/code&gt; - crawling scoped to root domain name and all subdomains (e.g. &lt;code&gt;*example.com&lt;/code&gt;) (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fqdn&lt;/code&gt; - crawling scoped to given sub(domain) (e.g. &lt;code&gt;www.example.com&lt;/code&gt; or &lt;code&gt;api.example.com&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dn&lt;/code&gt; - crawling scoped to domain name keyword (e.g. &lt;code&gt;example&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -fs dn
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;For advanced scope control, &lt;code&gt;-cs&lt;/code&gt; option can be used that comes with &lt;strong&gt;regex&lt;/strong&gt; support.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -cs login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For multiple in scope rules, file input with multiline string / regex can be passed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cat in_scope.txt

login/
admin/
app/
wordpress/
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -cs in_scope.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-out-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;For defining what not to crawl, &lt;code&gt;-cos&lt;/code&gt; option can be used and also support &lt;strong&gt;regex&lt;/strong&gt; input.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -cos logout
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For multiple out of scope rules, file input with multiline string / regex can be passed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cat out_of_scope.txt

/logout
/log_out
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -cos out_of_scope.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Katana is default to scope &lt;code&gt;*.domain&lt;/code&gt;, to disable this &lt;code&gt;-ns&lt;/code&gt; option can be used and also to crawl the internet.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-display-out-scope&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;As default, when scope option is used, it also applies for the links to display as output, as such &lt;strong&gt;external URLs are default to exclude&lt;/strong&gt; and to overwrite this behavior, &lt;code&gt;-do&lt;/code&gt; option can be used to display all the external URLs that exist in targets scoped URL / Endpoint.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -do
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is all the CLI options for the scope control -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h scope

Flags:
SCOPE:
   -cs, -crawl-scope string[]       in scope url regex to be followed by crawler
   -cos, -crawl-out-scope string[]  out of scope url regex to be excluded by crawler
   -fs, -field-scope string         pre-defined scope field (dn,rdn,fqdn) (default "rdn")
   -ns, -no-scope                   disables host based default scope
   -do, -display-out-scope          display external endpoint from scoped crawling
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Crawler Configuration&lt;/h2&gt; 
&lt;p&gt;Katana comes with multiple options to configure and control the crawl as the way we want.&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-depth&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to define the &lt;code&gt;depth&lt;/code&gt; to follow the urls for crawling, the more depth the more number of endpoint being crawled + time for crawl.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -d 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-js-crawl&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to enable JavaScript file parsing + crawling the endpoints discovered in JavaScript files, disabled as default.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -jc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-crawl-duration&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to predefined crawl duration, disabled as default.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -ct 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-known-files&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to enable crawling &lt;code&gt;robots.txt&lt;/code&gt; and &lt;code&gt;sitemap.xml&lt;/code&gt; file, disabled as default.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -kf robotstxt,sitemapxml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-automatic-form-fill&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to enable automatic form filling for known / unknown fields, known field values can be customized as needed by updating form config file at &lt;code&gt;$HOME/.config/katana/form-config.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Automatic form filling is experimental feature.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -aff
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authenticated Crawling&lt;/h2&gt; 
&lt;p&gt;Authenticated crawling involves including custom headers or cookies in HTTP requests to access protected resources. These headers provide authentication or authorization information, allowing you to crawl authenticated content / endpoint. You can specify headers directly in the command line or provide them as a file with katana to perform authenticated crawling.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: User needs to be manually perform the authentication and export the session cookie / header to file to use with katana.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-headers&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Option to add a custom header or cookie to the request.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Syntax of &lt;a href="https://datatracker.ietf.org/doc/html/rfc7230#section-3.2"&gt;headers&lt;/a&gt; in the HTTP specification&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Here is an example of adding a cookie to the request:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -H 'Cookie: usrsess=AmljNrESo'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It is also possible to supply headers or cookies as a file. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cat cookie.txt

Cookie: PHPSESSIONID=XXXXXXXXX
X-API-KEY: XXXXX
TOKEN=XX
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -H cookie.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are more options to configure when needed, here is all the config related CLI options -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h config

Flags:
CONFIGURATION:
   -r, -resolvers string[]       list of custom resolver (file or comma separated)
   -d, -depth int                maximum depth to crawl (default 3)
   -jc, -js-crawl                enable endpoint parsing / crawling in javascript file
   -ct, -crawl-duration int      maximum duration to crawl the target for
   -kf, -known-files string      enable crawling of known files (all,robotstxt,sitemapxml)
   -mrs, -max-response-size int  maximum response size to read (default 9223372036854775807)
   -timeout int                  time to wait for request in seconds (default 10)
   -aff, -automatic-form-fill    enable automatic form filling (experimental)
   -fx, -form-extraction         enable extraction of form, input, textarea &amp;amp; select elements
   -retry int                    number of times to retry the request (default 1)
   -proxy string                 http/socks5 proxy to use
   -H, -headers string[]         custom header/cookie to include in request
   -config string                path to the katana configuration file
   -fc, -form-config string      path to custom form configuration file
   -flc, -field-config string    path to custom field configuration file
   -s, -strategy string          Visit strategy (depth-first, breadth-first) (default "depth-first")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting to Active Browser Session&lt;/h3&gt; 
&lt;p&gt;Katana can also connect to active browser session where user is already logged in and authenticated. and use it for crawling. The only requirement for this is to start browser with remote debugging enabled.&lt;/p&gt; 
&lt;p&gt;Here is an example of starting chrome browser with remote debugging enabled and using it with katana -&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;step 1) First Locate path of chrome executable&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;Chromium Executable Location&lt;/th&gt; 
   &lt;th&gt;Google Chrome Executable Location&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows (64-bit)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C:\Program Files (x86)\Google\Chromium\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C:\Program Files (x86)\Google\Chrome\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows (32-bit)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C:\Program Files\Google\Chromium\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;C:\Program Files\Google\Chrome\Application\chrome.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/Applications/Chromium.app/Contents/MacOS/Chromium&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/usr/bin/chromium&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/usr/bin/google-chrome&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;step 2) Start chrome with remote debugging enabled and it will return websocker url. For example, on MacOS, you can start chrome with remote debugging enabled using following command&lt;/strong&gt; -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --remote-debugging-port=9222


DevTools listening on ws://127.0.0.1:9222/devtools/browser/c5316c9c-19d6-42dc-847a-41d1aeebf7d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Now login to the website you want to crawl and keep the browser open.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;step 3) Now use the websocket url with katana to connect to the active browser session and crawl the website&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -headless -u https://tesla.com -cwu ws://127.0.0.1:9222/devtools/browser/c5316c9c-19d6-42dc-847a-41d1aeebf7d6 -no-incognito
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: you can use &lt;code&gt;-cdd&lt;/code&gt; option to specify custom chrome data directory to store browser data and cookies but that does not save session data if cookie is set to &lt;code&gt;Session&lt;/code&gt; only or expires after certain time.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Filters&lt;/h2&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-field&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Deprecated: use &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#-output-template"&gt;&lt;strong&gt;&lt;code&gt;-output-template&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt; instead. The field flag is still supported for backward compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Katana comes with built in fields that can be used to filter the output for the desired information, &lt;code&gt;-f&lt;/code&gt; option can be used to specify any of the available fields.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;   -f, -field string  field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,key,value,kv,dir,udir)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a table with examples of each field and expected output when used -&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;FIELD&lt;/th&gt; 
   &lt;th&gt;DESCRIPTION&lt;/th&gt; 
   &lt;th&gt;EXAMPLE&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;url&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL Endpoint&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;qurl&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL including query param&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login.php?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;qpath&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path including query param&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/login?user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL Path&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/login&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;fqdn&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Fully Qualified Domain name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;admin.projectdiscovery.io&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rdn&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Root Domain name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;projectdiscovery.io&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rurl&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Root URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ufile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL with File&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/login.js&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;file&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Filename in URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;login.php&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;key&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Parameter keys in URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;user,password&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;value&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Parameter values in URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;admin,admin&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kv&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Keys=Values in URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;user=admin&amp;amp;password=admin&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dir&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL Directory name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/admin/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;udir&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL with Directory&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://admin.projectdiscovery.io/admin/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Here is an example of using field option to only display all the urls with query parameter in it -&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -f qurl -silent

https://shop.tesla.com/en_au?redirect=no
https://shop.tesla.com/en_nz?redirect=no
https://shop.tesla.com/product/men_s-raven-lightweight-zip-up-bomber-jacket?sku=1740250-00-A
https://shop.tesla.com/product/tesla-shop-gift-card?sku=1767247-00-A
https://shop.tesla.com/product/men_s-chill-crew-neck-sweatshirt?sku=1740176-00-A
https://www.tesla.com/about?redirect=no
https://www.tesla.com/about/legal?redirect=no
https://www.tesla.com/findus/list?redirect=no
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Custom Fields&lt;/h3&gt; 
&lt;p&gt;You can create custom fields to extract and store specific information from page responses using regex rules. These custom fields are defined using a YAML config file and are loaded from the default location at &lt;code&gt;$HOME/.config/katana/field-config.yaml&lt;/code&gt;. Alternatively, you can use the &lt;code&gt;-flc&lt;/code&gt; option to load a custom field config file from a different location. Here is example custom field.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: email
  type: regex
  regex:
  - '([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9_-]+)'
  - '([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9_-]+)'

- name: phone
  type: regex
  regex:
  - '\d{3}-\d{8}|\d{4}-\d{7}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When defining custom fields, following attributes are supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;name&lt;/strong&gt; (required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The value of &lt;strong&gt;name&lt;/strong&gt; attribute is used as the &lt;code&gt;-field&lt;/code&gt; cli option value.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;type&lt;/strong&gt; (required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The type of custom attribute, currently supported option - &lt;code&gt;regex&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;part&lt;/strong&gt; (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The part of the response to extract the information from. The default value is &lt;code&gt;response&lt;/code&gt;, which includes both the header and body. Other possible values are &lt;code&gt;header&lt;/code&gt; and &lt;code&gt;body&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;group (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can use this attribute to select a specific matched group in regex, for example: &lt;code&gt;group: 1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Running katana using custom field:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://tesla.com -f email,phone
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-store-field&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;To compliment &lt;code&gt;field&lt;/code&gt; option which is useful to filter output at run time, there is &lt;code&gt;-sf, -store-fields&lt;/code&gt; option which works exactly like field option except instead of filtering, it stores all the information on the disk under &lt;code&gt;katana_field&lt;/code&gt; directory sorted by target url. Use &lt;code&gt;-sfd&lt;/code&gt; or &lt;code&gt;-store-field-dir&lt;/code&gt; to store data in a different location.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -sf key,fqdn,qurl -silent
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ls katana_field/

https_www.tesla.com_fqdn.txt
https_www.tesla.com_key.txt
https_www.tesla.com_qurl.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;-store-field&lt;/code&gt; option can be useful for collecting information to build a targeted wordlist for various purposes, including but not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identifying the most commonly used parameters&lt;/li&gt; 
 &lt;li&gt;Discovering frequently used paths&lt;/li&gt; 
 &lt;li&gt;Finding commonly used files&lt;/li&gt; 
 &lt;li&gt;Identifying related or unknown subdomains&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Katana Filters&lt;/h3&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-extension-match&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Crawl output can be easily matched for specific extension using &lt;code&gt;-em&lt;/code&gt; option to ensure to display only output containing given extension.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -silent -em js,jsp,json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-extension-filter&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Crawl output can be easily filtered for specific extension using &lt;code&gt;-ef&lt;/code&gt; option which ensure to remove all the urls containing given extension.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -silent -ef css,txt,md

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-no-default-ext-filter&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;Katana filters several extensions by default. This can be disabled with the &lt;code&gt;-ndef&lt;/code&gt; option.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -silent -ndef
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-match-regex&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-match-regex&lt;/code&gt; or &lt;code&gt;-mr&lt;/code&gt; flag allows you to filter output URLs using regular expressions. When using this flag, only URLs that match the specified regular expression will be printed in the output.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -mr 'https://shop\.tesla\.com/*' -silent
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-filter-regex&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-filter-regex&lt;/code&gt; or &lt;code&gt;-fr&lt;/code&gt; flag allows you to filter output URLs using regular expressions. When using this flag, it will skip the URLs that are match the specified regular expression.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -fr 'https://www\.tesla\.com/*' -silent
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advance Filtering&lt;/h3&gt; 
&lt;p&gt;Katana supports DSL-based expressions for advanced matching and filtering capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To match endpoints with a 200 status code:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;katana -u https://www.hackerone.com -mdc 'status_code == 200'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;To match endpoints that contain "default" and have a status code other than 403:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;katana -u https://www.hackerone.com -mdc 'contains(endpoint, "default") &amp;amp;&amp;amp; status_code != 403'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;To match endpoints with PHP technologies:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;katana -u https://www.hackerone.com -mdc 'contains(to_lower(technologies), "php")'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;To filter out endpoints running on Cloudflare:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;katana -u https://www.hackerone.com -fdc 'contains(to_lower(technologies), "cloudflare")'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;DSL functions can be applied to any keys in the jsonl output. For more information on available DSL functions, please visit the &lt;a href="https://github.com/projectdiscovery/dsl"&gt;dsl project&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Here are additional filter options -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h filter

Flags:
FILTER:
   -mr, -match-regex string[]             regex or list of regex to match on output url (cli, file)
   -fr, -filter-regex string[]            regex or list of regex to filter on output url (cli, file)
   -f, -field string                      field to display in output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)
   -sf, -store-field string               field to store in per-host output (url,path,fqdn,rdn,rurl,qurl,qpath,file,ufile,key,value,kv,dir,udir)
   -em, -extension-match string[]         match output for given extension (eg, -em php,html,js)
   -ef, -extension-filter string[]        filter output for given extension (eg, -ef png,css)
   -ndef, -no-default-ext-filter bool     remove default extensions from the filter list
   -mdc, -match-condition string          match response with dsl based condition
   -fdc, -filter-condition string         filter response with dsl based condition
   -duf, -disable-unique-filter           disable duplicate content filtering
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Rate Limit&lt;/h2&gt; 
&lt;p&gt;It's easy to get blocked / banned while crawling if not following target websites limits, katana comes with multiple option to tune the crawl to go as fast / slow we want.&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-delay&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;option to introduce a delay in seconds between each new request katana makes while crawling, disabled as default.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -delay 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-concurrency&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;option to control the number of urls per target to fetch at the same time.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -c 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-parallelism&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;option to define number of target to process at same time from list input.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -p 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-rate-limit&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;option to use to define max number of request can go out per second.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -rl 100
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-rate-limit-minute&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;option to use to define max number of request can go out per minute.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;katana -u https://tesla.com -rlm 500
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is all long / short CLI options for rate limit control -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h rate-limit

Flags:
RATE-LIMIT:
   -c, -concurrency int          number of concurrent fetchers to use (default 10)
   -p, -parallelism int          number of concurrent inputs to process (default 10)
   -rd, -delay int               request delay between each request in seconds
   -rl, -rate-limit int          maximum requests to send per second (default 150)
   -rlm, -rate-limit-minute int  maximum number of requests to send per minute
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Output&lt;/h2&gt; 
&lt;p&gt;Katana support both file output in plain text format as well as JSON which includes additional information like, &lt;code&gt;source&lt;/code&gt;, &lt;code&gt;tag&lt;/code&gt;, and &lt;code&gt;attribute&lt;/code&gt; name to co-related the discovered endpoint.&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-output&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;By default, katana outputs the crawled endpoints in plain text format. The results can be written to a file by using the -output option.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://example.com -no-scope -output example_endpoints.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-output-template&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-output-template&lt;/code&gt; option allows you to customize the output format using template, providing flexibility in defining the output structure. This option replaces the deprecated &lt;code&gt;-field&lt;/code&gt; flag for filtering output. Instead of relying on predefined fields, you can specify a custom template directly in the command line to control how the extracted data is presented.&lt;/p&gt; 
&lt;p&gt;Example of using the &lt;code&gt;-output-template&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;katana -u https://example.com -output-template '{{email}} - {{url}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, &lt;code&gt;email&lt;/code&gt; represents a &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/#custom-fields"&gt;custom field&lt;/a&gt; that extracts and displays email addresses found within the source &lt;code&gt;url&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If a specified field does not exist or does not contain a value, it will simply be omitted from the output.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This option can effectively structure the output in a way that best suits your use case, making data extraction more intuitive and customizable.&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-jsonl&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://example.com -jsonl | jq .
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "timestamp": "2023-03-20T16:23:58.027559+05:30",
  "request": {
    "method": "GET",
    "endpoint": "https://example.com",
    "raw": "GET / HTTP/1.1\r\nHost: example.com\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\r\nAccept-Encoding: gzip\r\n\r\n"
  },
  "response": {
    "status_code": 200,
    "headers": {
      "accept_ranges": "bytes",
      "expires": "Mon, 27 Mar 2023 10:53:58 GMT",
      "last_modified": "Thu, 17 Oct 2019 07:18:26 GMT",
      "content_type": "text/html; charset=UTF-8",
      "server": "ECS (dcb/7EA3)",
      "vary": "Accept-Encoding",
      "etag": "\"3147526947\"",
      "cache_control": "max-age=604800",
      "x_cache": "HIT",
      "date": "Mon, 20 Mar 2023 10:53:58 GMT",
      "age": "331239"
    },
    "body": "&amp;lt;!doctype html&amp;gt;\n&amp;lt;html&amp;gt;\n&amp;lt;head&amp;gt;\n    &amp;lt;title&amp;gt;Example Domain&amp;lt;/title&amp;gt;\n\n    &amp;lt;meta charset=\"utf-8\" /&amp;gt;\n    &amp;lt;meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /&amp;gt;\n    &amp;lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&amp;gt;\n    &amp;lt;style type=\"text/css\"&amp;gt;\n    body {\n        background-color: #f0f0f2;\n        margin: 0;\n        padding: 0;\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n        \n    }\n    div {\n        width: 600px;\n        margin: 5em auto;\n        padding: 2em;\n        background-color: #fdfdff;\n        border-radius: 0.5em;\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n    }\n    a:link, a:visited {\n        color: #38488f;\n        text-decoration: none;\n    }\n    @media (max-width: 700px) {\n        div {\n            margin: 0 auto;\n            width: auto;\n        }\n    }\n    &amp;lt;/style&amp;gt;    \n&amp;lt;/head&amp;gt;\n\n&amp;lt;body&amp;gt;\n&amp;lt;div&amp;gt;\n    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;\n    &amp;lt;p&amp;gt;This domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.&amp;lt;/p&amp;gt;\n    &amp;lt;p&amp;gt;&amp;lt;a href=\"https://www.iana.org/domains/example\"&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;\n&amp;lt;/div&amp;gt;\n&amp;lt;/body&amp;gt;\n&amp;lt;/html&amp;gt;\n",
    "technologies": [
      "Azure",
      "Amazon ECS",
      "Amazon Web Services",
      "Docker",
      "Azure CDN"
    ],
    "raw": "HTTP/1.1 200 OK\r\nContent-Length: 1256\r\nAccept-Ranges: bytes\r\nAge: 331239\r\nCache-Control: max-age=604800\r\nContent-Type: text/html; charset=UTF-8\r\nDate: Mon, 20 Mar 2023 10:53:58 GMT\r\nEtag: \"3147526947\"\r\nExpires: Mon, 27 Mar 2023 10:53:58 GMT\r\nLast-Modified: Thu, 17 Oct 2019 07:18:26 GMT\r\nServer: ECS (dcb/7EA3)\r\nVary: Accept-Encoding\r\nX-Cache: HIT\r\n\r\n&amp;lt;!doctype html&amp;gt;\n&amp;lt;html&amp;gt;\n&amp;lt;head&amp;gt;\n    &amp;lt;title&amp;gt;Example Domain&amp;lt;/title&amp;gt;\n\n    &amp;lt;meta charset=\"utf-8\" /&amp;gt;\n    &amp;lt;meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /&amp;gt;\n    &amp;lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&amp;gt;\n    &amp;lt;style type=\"text/css\"&amp;gt;\n    body {\n        background-color: #f0f0f2;\n        margin: 0;\n        padding: 0;\n        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n        \n    }\n    div {\n        width: 600px;\n        margin: 5em auto;\n        padding: 2em;\n        background-color: #fdfdff;\n        border-radius: 0.5em;\n        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n    }\n    a:link, a:visited {\n        color: #38488f;\n        text-decoration: none;\n    }\n    @media (max-width: 700px) {\n        div {\n            margin: 0 auto;\n            width: auto;\n        }\n    }\n    &amp;lt;/style&amp;gt;    \n&amp;lt;/head&amp;gt;\n\n&amp;lt;body&amp;gt;\n&amp;lt;div&amp;gt;\n    &amp;lt;h1&amp;gt;Example Domain&amp;lt;/h1&amp;gt;\n    &amp;lt;p&amp;gt;This domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.&amp;lt;/p&amp;gt;\n    &amp;lt;p&amp;gt;&amp;lt;a href=\"https://www.iana.org/domains/example\"&amp;gt;More information...&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;\n&amp;lt;/div&amp;gt;\n&amp;lt;/body&amp;gt;\n&amp;lt;/html&amp;gt;\n"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-store-response&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-store-response&lt;/code&gt; option allows for writing all crawled endpoint requests and responses to a text file. When this option is used, text files including the request and response will be written to the &lt;strong&gt;katana_response&lt;/strong&gt; directory. If you would like to specify a custom directory, you can use the &lt;code&gt;-store-response-dir&lt;/code&gt; option.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://example.com -no-scope -store-response
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cat katana_response/index.txt

katana_response/example.com/327c3fda87ce286848a574982ddd0b7c7487f816.txt https://example.com (200 OK)
katana_response/www.iana.org/bfc096e6dd93b993ca8918bf4c08fdc707a70723.txt http://www.iana.org/domains/reserved (200 OK)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;code&gt;-store-response&lt;/code&gt; option is not supported in &lt;code&gt;-headless&lt;/code&gt; mode.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-list-output-fields&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-list-output-fields&lt;/code&gt; or &lt;code&gt;-lof&lt;/code&gt; flag displays all available fields that can be used in JSONL output format. This is useful for understanding what data is available when using custom output templates or when excluding specific fields.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -lof
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;em&gt;&lt;code&gt;-exclude-output-fields&lt;/code&gt;&lt;/em&gt;&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;-exclude-output-fields&lt;/code&gt; or &lt;code&gt;-eof&lt;/code&gt; flag allows you to exclude specific fields from the JSONL output. This is useful for reducing output size or focusing on specific data by removing unwanted fields.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -u https://example.com -jsonl -eof raw,body
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here are additional CLI options related to output -&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;katana -h output

OUTPUT:
   -o, -output string                file to write output to
   -sr, -store-response              store http requests/responses
   -srd, -store-response-dir string  store http requests/responses to custom directory
   -lof, -list-output-fields         list available fields for jsonl output format
   -eof, -exclude-output-fields      exclude fields from jsonl output
   -j, -json                         write output in JSONL(ines) format
   -nc, -no-color                    disable output content coloring (ANSI escape codes)
   -silent                           display output only
   -v, -verbose                      display verbose output
   -version                          display project version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Katana as a library&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;katana&lt;/code&gt; can be used as a library by creating an instance of the &lt;code&gt;Option&lt;/code&gt; struct and populating it with the same options that would be specified via CLI. Using the options you can create &lt;code&gt;crawlerOptions&lt;/code&gt; and so standard or hybrid &lt;code&gt;crawler&lt;/code&gt;. &lt;code&gt;crawler.Crawl&lt;/code&gt; method should be called to crawl the input.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"math"

	"github.com/projectdiscovery/gologger"
	"github.com/projectdiscovery/katana/pkg/engine/standard"
	"github.com/projectdiscovery/katana/pkg/output"
	"github.com/projectdiscovery/katana/pkg/types"
)

func main() {
	options := &amp;amp;types.Options{
		MaxDepth:     3,             // Maximum depth to crawl
		FieldScope:   "rdn",         // Crawling Scope Field
		BodyReadSize: math.MaxInt,   // Maximum response size to read
		Timeout:      10,            // Timeout is the time to wait for request in seconds
		Concurrency:  10,            // Concurrency is the number of concurrent crawling goroutines
		Parallelism:  10,            // Parallelism is the number of urls processing goroutines
		Delay:        0,             // Delay is the delay between each crawl requests in seconds
		RateLimit:    150,           // Maximum requests to send per second
		Strategy:     "depth-first", // Visit strategy (depth-first, breadth-first)
		OnResult: func(result output.Result) { // Callback function to execute for result
			gologger.Info().Msg(result.Request.URL)
		},
	}
	crawlerOptions, err := types.NewCrawlerOptions(options)
	if err != nil {
		gologger.Fatal().Msg(err.Error())
	}
	defer crawlerOptions.Close()
	crawler, err := standard.New(crawlerOptions)
	if err != nil {
		gologger.Fatal().Msg(err.Error())
	}
	defer crawler.Close()
	var input = "https://www.hackerone.com"
	err = crawler.Crawl(input)
	if err != nil {
		gologger.Warning().Msgf("Could not crawl %s: %s", input, err.Error())
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Reporting Issues &amp;amp; Feature Requests&lt;/h2&gt; 
&lt;p&gt;To maintain issue tracking and improve triage efficiency:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;All reports start as &lt;a href="https://github.com/projectdiscovery/katana/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bug Reports&lt;/strong&gt; → &lt;a href="https://github.com/projectdiscovery/katana/discussions/new?category=q-a"&gt;Start a Q&amp;amp;A Discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Requests&lt;/strong&gt; → &lt;a href="https://github.com/projectdiscovery/katana/discussions/new?category=ideas"&gt;Start an Ideas Discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Questions&lt;/strong&gt; → &lt;a href="https://github.com/projectdiscovery/katana/discussions/new?category=q-a"&gt;Start a Q&amp;amp;A Discussion&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Why Discussions First?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Community can help&lt;/strong&gt; with quick questions and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better triage&lt;/strong&gt; - confirmed bugs/features become tracked issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cleaner issue tracker&lt;/strong&gt; - focus on actionable items only&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Maintainers will convert discussions to issues when appropriate after proper review.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;katana is made with ❤️ by the &lt;a href="https://projectdiscovery.io"&gt;projectdiscovery&lt;/a&gt; team and distributed under &lt;a href="https://raw.githubusercontent.com/projectdiscovery/katana/dev/LICENSE.md"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/projectdiscovery"&gt;&lt;img src="https://raw.githubusercontent.com/projectdiscovery/nuclei-burp-plugin/main/static/join-discord.png" width="300" alt="Join Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Maintenance Mode&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;This project is currently under maintenance and is not accepting new changes.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The codebase is in a maintenance-only state&lt;/li&gt; 
 &lt;li&gt;No new features, enhancements, or pull requests will be accepted&lt;/li&gt; 
 &lt;li&gt;Critical security fixes may be evaluated on a case-by-case basis&lt;/li&gt; 
 &lt;li&gt;Existing issues and pull requests will not be actively reviewed&lt;/li&gt; 
 &lt;li&gt;Community support continues on a best-effort basis through &lt;a href="https://slack.min.io"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise support and actively maintained versions, please see &lt;a href="https://www.min.io/product/aistor"&gt;MinIO AIStor&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible – Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics – Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance – Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/"&gt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>grafana/mcp-grafana</title>
      <link>https://github.com/grafana/mcp-grafana</link>
      <description>&lt;p&gt;MCP server for Grafana&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Grafana MCP server&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/unit.yml/badge.svg?sanitize=true" alt="Unit Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/integration.yml/badge.svg?sanitize=true" alt="Integration Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml"&gt;&lt;img src="https://github.com/grafana/mcp-grafana/actions/workflows/e2e.yml/badge.svg?sanitize=true" alt="E2E Tests" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/grafana/mcp-grafana"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/grafana/mcp-grafana.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://archestra.ai/mcp-catalog/grafana__mcp-grafana"&gt;&lt;img src="https://archestra.ai/mcp-catalog/api/badge/quality/grafana/mcp-grafana" alt="MCP Catalog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol&lt;/a&gt; (MCP) server for Grafana.&lt;/p&gt; 
&lt;p&gt;This provides access to your Grafana instance and the surrounding ecosystem.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Grafana version 9.0 or later&lt;/strong&gt; is required for full functionality. Some features, particularly datasource-related operations, may not work correctly with earlier versions due to missing API endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;The following features are currently available in MCP server. This list is for informational purposes only and does not represent a roadmap or commitment to future features.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search for dashboards:&lt;/strong&gt; Find dashboards by title or other metadata&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard by UID:&lt;/strong&gt; Retrieve full dashboard details using its unique identifier. &lt;em&gt;Warning: Large dashboards can consume significant context window space.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard summary:&lt;/strong&gt; Get a compact overview of a dashboard including title, panel count, panel types, variables, and metadata without the full JSON to minimize context window usage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get dashboard property:&lt;/strong&gt; Extract specific parts of a dashboard using JSONPath expressions (e.g., &lt;code&gt;$.title&lt;/code&gt;, &lt;code&gt;$.panels[*].title&lt;/code&gt;) to fetch only needed data and reduce context window consumption&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update or create a dashboard:&lt;/strong&gt; Modify existing dashboards or create new ones. &lt;em&gt;Warning: Requires full dashboard JSON which can consume large amounts of context window space.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patch dashboard:&lt;/strong&gt; Apply specific changes to a dashboard without requiring the full JSON, significantly reducing context window usage for targeted modifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get panel queries and datasource info:&lt;/strong&gt; Get the title, query string, and datasource information (including UID and type, if available) from every panel in a dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Context Window Management&lt;/h4&gt; 
&lt;p&gt;The dashboard tools now include several strategies to manage context window usage effectively (&lt;a href="https://github.com/grafana/mcp-grafana/issues/101"&gt;issue #101&lt;/a&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;get_dashboard_summary&lt;/code&gt;&lt;/strong&gt; for dashboard overview and planning modifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use &lt;code&gt;get_dashboard_property&lt;/code&gt;&lt;/strong&gt; with JSONPath when you only need specific dashboard parts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Avoid &lt;code&gt;get_dashboard_by_uid&lt;/code&gt;&lt;/strong&gt; unless you specifically need the complete dashboard JSON&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Datasources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and fetch datasource information:&lt;/strong&gt; View all configured datasources and retrieve detailed information about each. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;em&gt;Supported datasource types: Prometheus, Loki.&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prometheus Querying&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Prometheus:&lt;/strong&gt; Execute PromQL queries (supports both instant and range metric queries) against Prometheus datasources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Prometheus metadata:&lt;/strong&gt; Retrieve metric metadata, metric names, label names, and label values from Prometheus datasources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Loki Querying&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Loki logs and metrics:&lt;/strong&gt; Run both log queries and metric queries using LogQL against Loki datasources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Loki metadata:&lt;/strong&gt; Retrieve label names, label values, and stream statistics from Loki datasources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Incidents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search, create, and update incidents:&lt;/strong&gt; Manage incidents in Grafana Incident, including searching, creating, and adding activities to incidents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Sift Investigations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List Sift investigations:&lt;/strong&gt; Retrieve a list of Sift investigations, with support for a limit parameter.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Sift investigation:&lt;/strong&gt; Retrieve details of a specific Sift investigation by its UUID.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Sift analyses:&lt;/strong&gt; Retrieve a specific analysis from a Sift investigation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Find error patterns in logs:&lt;/strong&gt; Detect elevated error patterns in Loki logs using Sift.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Find slow requests:&lt;/strong&gt; Detect slow requests using Sift (Tempo).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Alerting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and fetch alert rule information:&lt;/strong&gt; View alert rules and their statuses (firing/normal/error/etc.) in Grafana. Supports both Grafana-managed rules and datasource-managed rules from Prometheus or Loki datasources.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List contact points:&lt;/strong&gt; View configured notification contact points in Grafana. Supports both Grafana-managed contact points and receivers from external Alertmanager datasources (Prometheus Alertmanager, Mimir, Cortex).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Grafana OnCall&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List and manage schedules:&lt;/strong&gt; View and manage on-call schedules in Grafana OnCall.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get shift details:&lt;/strong&gt; Retrieve detailed information about specific on-call shifts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get current on-call users:&lt;/strong&gt; See which users are currently on call for a schedule.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List teams and users:&lt;/strong&gt; View all OnCall teams and users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List alert groups:&lt;/strong&gt; View and filter alert groups from Grafana OnCall by various criteria including state, integration, labels, and time range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get alert group details:&lt;/strong&gt; Retrieve detailed information about a specific alert group by its ID.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Admin&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Admin tools are &lt;strong&gt;disabled by default&lt;/strong&gt;. To enable them, include &lt;code&gt;admin&lt;/code&gt; in your &lt;code&gt;--enabled-tools&lt;/code&gt; flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;List teams:&lt;/strong&gt; View all configured teams in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List Users:&lt;/strong&gt; View all users in an organization in Grafana.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List all roles:&lt;/strong&gt; List all Grafana roles, with an optional filter for delegatable roles.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get role details:&lt;/strong&gt; Get details for a specific Grafana role by UID.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List assignments for a role:&lt;/strong&gt; List all users, teams, and service accounts assigned to a role.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List roles for users:&lt;/strong&gt; List all roles assigned to one or more users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List roles for teams:&lt;/strong&gt; List all roles assigned to one or more teams.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List permissions for a resource:&lt;/strong&gt; List all permissions defined for a specific resource (dashboard, datasource, folder, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Describe a Grafana resource:&lt;/strong&gt; List available permissions and assignment capabilities for a resource type.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Navigation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Generate deeplinks:&lt;/strong&gt; Create accurate deeplink URLs for Grafana resources instead of relying on LLM URL guessing. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Dashboard links:&lt;/strong&gt; Generate direct links to dashboards using their UID (e.g., &lt;code&gt;http://localhost:3000/d/dashboard-uid&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Panel links:&lt;/strong&gt; Create links to specific panels within dashboards with viewPanel parameter (e.g., &lt;code&gt;http://localhost:3000/d/dashboard-uid?viewPanel=5&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Explore links:&lt;/strong&gt; Generate links to Grafana Explore with pre-configured datasources (e.g., &lt;code&gt;http://localhost:3000/explore?left={"datasource":"prometheus-uid"}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Time range support:&lt;/strong&gt; Add time range parameters to links (&lt;code&gt;from=now-1h&amp;amp;to=now&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Custom parameters:&lt;/strong&gt; Include additional query parameters like dashboard variables or refresh intervals&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Annotations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Get Annotations:&lt;/strong&gt; Query annotations with filters. Supports time range, dashboard UID, tags, and match mode.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create Annotation:&lt;/strong&gt; Create a new annotation on a dashboard or panel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create Graphite Annotation:&lt;/strong&gt; Create annotations using Graphite format (&lt;code&gt;what&lt;/code&gt;, &lt;code&gt;when&lt;/code&gt;, &lt;code&gt;tags&lt;/code&gt;, &lt;code&gt;data&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update Annotation:&lt;/strong&gt; Replace all fields of an existing annotation (full update).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patch Annotation:&lt;/strong&gt; Update only specific fields of an annotation (partial update).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Get Annotation Tags:&lt;/strong&gt; List available annotation tags with optional filtering.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The list of tools is configurable, so you can choose which tools you want to make available to the MCP client. This is useful if you don't use certain functionality or if you don't want to take up too much of the context window. To disable a category of tools, use the &lt;code&gt;--disable-&amp;lt;category&amp;gt;&lt;/code&gt; flag when starting the server. For example, to disable the OnCall tools, use &lt;code&gt;--disable-oncall&lt;/code&gt;, or to disable navigation deeplink generation, use &lt;code&gt;--disable-navigation&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;RBAC Permissions&lt;/h4&gt; 
&lt;p&gt;Each tool requires specific RBAC permissions to function properly. When creating a service account for the MCP server, ensure it has the necessary permissions based on which tools you plan to use. The permissions listed are the minimum required actions - you may also need appropriate scopes (e.g., &lt;code&gt;datasources:*&lt;/code&gt;, &lt;code&gt;dashboards:*&lt;/code&gt;, &lt;code&gt;folders:*&lt;/code&gt;) depending on your use case.&lt;/p&gt; 
&lt;p&gt;Tip: If you're not familiar with Grafana RBAC or you want a quicker, simpler setup instead of configuring many granular scopes, you can assign a built-in role such as &lt;code&gt;Editor&lt;/code&gt; to the service account. The &lt;code&gt;Editor&lt;/code&gt; role grants broad read/write access that will allow most MCP server operations; it is less granular (and therefore less restrictive) than manually-applied scopes, so use it only when convenience is more important than strict least-privilege access.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Grafana Incident and Sift tools use basic Grafana roles instead of fine-grained RBAC permissions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Viewer role:&lt;/strong&gt; Required for read-only operations (list incidents, get investigations)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editor role:&lt;/strong&gt; Required for write operations (create incidents, modify investigations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about Grafana RBAC, see the &lt;a href="https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;RBAC Scopes&lt;/h4&gt; 
&lt;p&gt;Scopes define the specific resources that permissions apply to. Each action requires both the appropriate permission and scope combination.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Common Scope Patterns:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Broad access:&lt;/strong&gt; Use &lt;code&gt;*&lt;/code&gt; wildcards for organization-wide access&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;datasources:*&lt;/code&gt; - Access to all datasources&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;dashboards:*&lt;/code&gt; - Access to all dashboards&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;folders:*&lt;/code&gt; - Access to all folders&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;teams:*&lt;/code&gt; - Access to all teams&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Limited access:&lt;/strong&gt; Use specific UIDs or IDs to restrict access to individual resources&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt; - Access only to a specific Prometheus datasource&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt; - Access only to dashboard with UID &lt;code&gt;abc123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;folders:uid:xyz789&lt;/code&gt; - Access only to folder with UID &lt;code&gt;xyz789&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;teams&lt;span&gt;🆔&lt;/span&gt;5&lt;/code&gt; - Access only to team with ID &lt;code&gt;5&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;global.users&lt;span&gt;🆔&lt;/span&gt;123&lt;/code&gt; - Access only to user with ID &lt;code&gt;123&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Full MCP server access:&lt;/strong&gt; Grant broad permissions for all tools&lt;/p&gt; &lt;pre&gt;&lt;code&gt;datasources:* (datasources:read, datasources:query)
dashboards:* (dashboards:read, dashboards:create, dashboards:write)
folders:* (for dashboard creation and alert rules)
teams:* (teams:read)
global.users:* (users:read)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Limited datasource access:&lt;/strong&gt; Only query specific Prometheus and Loki instances&lt;/p&gt; &lt;pre&gt;&lt;code&gt;datasources:uid:prometheus-prod (datasources:query)
datasources:uid:loki-prod (datasources:query)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dashboard-specific access:&lt;/strong&gt; Read only specific dashboards&lt;/p&gt; &lt;pre&gt;&lt;code&gt;dashboards:uid:monitoring-dashboard (dashboards:read)
dashboards:uid:alerts-dashboard (dashboards:read)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required RBAC Permissions&lt;/th&gt; 
   &lt;th&gt;Required Scopes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_teams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List all teams&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;teams:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;teams:*&lt;/code&gt; or &lt;code&gt;teams&lt;span&gt;🆔&lt;/span&gt;1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_users_by_org&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List all users in an organization&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;users:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;global.users:*&lt;/code&gt; or &lt;code&gt;global.users&lt;span&gt;🆔&lt;/span&gt;123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_all_roles&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List all Grafana roles&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_role_details&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;Get details for a Grafana role&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:uid:editor&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_role_assignments&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List assignments for a role&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:uid:editor&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_user_roles&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List roles for users&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;global.users&lt;span&gt;🆔&lt;/span&gt;123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_team_roles&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List roles for teams&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;roles:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;teams&lt;span&gt;🆔&lt;/span&gt;7&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_resource_permissions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;List permissions for a resource&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;permissions:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abcd1234&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_resource_description&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Admin&lt;/td&gt; 
   &lt;td&gt;Describe a Grafana resource type&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;permissions:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;search_dashboards&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Search&lt;/td&gt; 
   &lt;td&gt;Search for dashboards&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:*&lt;/code&gt; or &lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get a dashboard by uid&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;update_dashboard&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Update or create a new dashboard&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:create&lt;/code&gt;, &lt;code&gt;dashboards:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:*&lt;/code&gt;, &lt;code&gt;folders:*&lt;/code&gt; or &lt;code&gt;folders:uid:xyz789&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_panel_queries&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get panel title, queries, datasource UID and type from a dashboard&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_property&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Extract specific parts of a dashboard using JSONPath expressions&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_dashboard_summary&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dashboard&lt;/td&gt; 
   &lt;td&gt;Get a compact summary of a dashboard without full JSON&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dashboards:uid:abc123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_datasources&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;List datasources&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_datasource_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;Get a datasource by uid&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_datasource_by_name&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Datasources&lt;/td&gt; 
   &lt;td&gt;Get a datasource by name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:*&lt;/code&gt; or &lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_prometheus&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;Execute a query against a Prometheus datasource&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_metric_metadata&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List metric metadata&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_metric_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List available metric names&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List label names matching a selector&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_prometheus_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prometheus&lt;/td&gt; 
   &lt;td&gt;List values for a specific label&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:prometheus-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_incidents&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;List incidents in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Create an incident in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;add_activity_to_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Add an activity item to an incident in Grafana Incident&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_incident&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Incident&lt;/td&gt; 
   &lt;td&gt;Get a single incident by ID&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_loki_logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;Query and retrieve logs using LogQL (either log or metric queries)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_loki_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;List all available label names in logs&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_loki_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;List values for a specific log label&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;query_loki_stats&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Loki&lt;/td&gt; 
   &lt;td&gt;Get statistics about log streams&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:loki-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_alert_rules&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;List alert rules&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.rules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;folders:*&lt;/code&gt; or &lt;code&gt;folders:uid:alerts-folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_alert_rule_by_uid&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;Get alert rule by UID&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.rules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;folders:uid:alerts-folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_contact_points&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Alerting&lt;/td&gt; 
   &lt;td&gt;List notification contact points (Grafana-managed and Alertmanager)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;alert.notifications:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Global scope&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_schedules&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List schedules from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_oncall_shift&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get details for a specific OnCall shift&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_current_oncall_users&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get users currently on-call for a specific schedule&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.schedules:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_teams&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List teams from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.user-settings:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_oncall_users&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List users from Grafana OnCall&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.user-settings:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_alert_groups&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;List alert groups from Grafana OnCall with filtering options&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.alert-groups:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_alert_group&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OnCall&lt;/td&gt; 
   &lt;td&gt;Get a specific alert group from Grafana OnCall by its ID&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;grafana-oncall-app.alert-groups:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_sift_investigation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve an existing Sift investigation by its UUID&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_sift_analysis&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve a specific analysis from a Sift investigation&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_sift_investigations&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Retrieve a list of Sift investigations with an optional limit&lt;/td&gt; 
   &lt;td&gt;Viewer role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;find_error_pattern_logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Finds elevated error patterns in Loki logs.&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;find_slow_requests&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sift&lt;/td&gt; 
   &lt;td&gt;Finds slow requests from the relevant tempo datasources.&lt;/td&gt; 
   &lt;td&gt;Editor role&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_label_names&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List label names matching a selector&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_label_values&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List label values matching a selector for a label name&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;list_pyroscope_profile_types&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;List available profile types&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;fetch_pyroscope_profile&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pyroscope&lt;/td&gt; 
   &lt;td&gt;Fetches a profile in DOT format for analysis&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;datasources:uid:pyroscope-uid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_assertions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Asserts&lt;/td&gt; 
   &lt;td&gt;Get assertion summary for a given entity&lt;/td&gt; 
   &lt;td&gt;Plugin-specific permissions&lt;/td&gt; 
   &lt;td&gt;Plugin-specific scopes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;generate_deeplink&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Navigation&lt;/td&gt; 
   &lt;td&gt;Generate accurate deeplink URLs for Grafana resources&lt;/td&gt; 
   &lt;td&gt;None (read-only URL generation)&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_annotations&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Fetch annotations with filters&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt; or &lt;code&gt;annotations&lt;span&gt;🆔&lt;/span&gt;123&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Create a new annotation on a dashboard or panel&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;create_graphite_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Create an annotation using Graphite format&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;update_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Replace all fields of an annotation (full update)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;patch_annotation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;Update only specific fields of an annotation (partial update)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:write&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;get_annotation_tags&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Annotations&lt;/td&gt; 
   &lt;td&gt;List annotation tags with optional filtering&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:read&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;annotations:*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;CLI Flags Reference&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp-grafana&lt;/code&gt; binary supports various command-line flags for configuration:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Transport Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-t, --transport&lt;/code&gt;: Transport type (&lt;code&gt;stdio&lt;/code&gt;, &lt;code&gt;sse&lt;/code&gt;, or &lt;code&gt;streamable-http&lt;/code&gt;) - default: &lt;code&gt;stdio&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--address&lt;/code&gt;: The host and port for SSE/streamable-http server - default: &lt;code&gt;localhost:8000&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--base-path&lt;/code&gt;: Base path for the SSE/streamable-http server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--endpoint-path&lt;/code&gt;: Endpoint path for the streamable-http server - default: &lt;code&gt;/&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debug and Logging:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--debug&lt;/code&gt;: Enable debug mode for detailed HTTP request/response logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Tool Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--enabled-tools&lt;/code&gt;: Comma-separated list of enabled categories - default: all categories except &lt;code&gt;admin&lt;/code&gt;, to enable admin tools, add &lt;code&gt;admin&lt;/code&gt; to the list (e.g., &lt;code&gt;"search,datasource,...,admin"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-search&lt;/code&gt;: Disable search tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-datasource&lt;/code&gt;: Disable datasource tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-incident&lt;/code&gt;: Disable incident tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-prometheus&lt;/code&gt;: Disable prometheus tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-write&lt;/code&gt;: Disable write tools (create/update operations)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-loki&lt;/code&gt;: Disable loki tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-alerting&lt;/code&gt;: Disable alerting tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-dashboard&lt;/code&gt;: Disable dashboard tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-oncall&lt;/code&gt;: Disable oncall tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-asserts&lt;/code&gt;: Disable asserts tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-sift&lt;/code&gt;: Disable sift tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-admin&lt;/code&gt;: Disable admin tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-pyroscope&lt;/code&gt;: Disable pyroscope tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--disable-navigation&lt;/code&gt;: Disable navigation tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Read-Only Mode&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;--disable-write&lt;/code&gt; flag provides a way to run the MCP server in read-only mode, preventing any write operations to your Grafana instance. This is useful for scenarios where you want to provide safe, read-only access such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using service accounts with limited read-only permissions&lt;/li&gt; 
 &lt;li&gt;Providing AI assistants with observability data without modification capabilities&lt;/li&gt; 
 &lt;li&gt;Running in production environments where write access should be restricted&lt;/li&gt; 
 &lt;li&gt;Testing and development scenarios where you want to prevent accidental modifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When &lt;code&gt;--disable-write&lt;/code&gt; is enabled, the following write operations are disabled:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Dashboard Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;update_dashboard&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Folder Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_folder&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Incident Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_incident&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;add_activity_to_incident&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Alerting Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_alert_rule&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;update_alert_rule&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;delete_alert_rule&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Annotation Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;create_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;create_graphite_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;update_annotation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;patch_annotation&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sift Tools:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;find_error_pattern_logs&lt;/code&gt; (creates investigations)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;find_slow_requests&lt;/code&gt; (creates investigations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All read operations remain available, allowing you to query dashboards, run PromQL/LogQL queries, list resources, and retrieve data.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Client TLS Configuration (for Grafana connections):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--tls-cert-file&lt;/code&gt;: Path to TLS certificate file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-key-file&lt;/code&gt;: Path to TLS private key file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-ca-file&lt;/code&gt;: Path to TLS CA certificate file for server verification&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-skip-verify&lt;/code&gt;: Skip TLS certificate verification (insecure)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Server TLS Configuration (streamable-http transport only):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-cert-file&lt;/code&gt;: Path to TLS certificate file for server HTTPS&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-key-file&lt;/code&gt;: Path to TLS private key file for server HTTPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;This MCP server works with both local Grafana instances and Grafana Cloud. For Grafana Cloud, use your instance URL (e.g., &lt;code&gt;https://myinstance.grafana.net&lt;/code&gt;) instead of &lt;code&gt;http://localhost:3000&lt;/code&gt; in the configuration examples below.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;If using service account token authentication, create a service account in Grafana with enough permissions to use the tools you want to use, generate a service account token, and copy it to the clipboard for use in the configuration file. Follow the &lt;a href="https://grafana.com/docs/grafana/latest/administration/service-accounts/#add-a-token-to-a-service-account-in-grafana"&gt;Grafana service account documentation&lt;/a&gt; for details on creating service account tokens. Tip: If you're not comfortable configuring fine-grained RBAC scopes, a simpler (but less restrictive) option is to assign the built-in &lt;code&gt;Editor&lt;/code&gt; role to the service account. This grants broad read/write access that covers most MCP server operations — use it when convenience outweighs strict least-privilege requirements.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The environment variable &lt;code&gt;GRAFANA_API_KEY&lt;/code&gt; is deprecated and will be removed in a future version. Please migrate to using &lt;code&gt;GRAFANA_SERVICE_ACCOUNT_TOKEN&lt;/code&gt; instead. The old variable name will continue to work for backward compatibility but will show deprecation warnings.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Multi-Organization Support&lt;/h3&gt; 
&lt;p&gt;You can specify which organization to interact with using either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment variable:&lt;/strong&gt; Set &lt;code&gt;GRAFANA_ORG_ID&lt;/code&gt; to the numeric organization ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP header:&lt;/strong&gt; Set &lt;code&gt;X-Grafana-Org-Id&lt;/code&gt; when using SSE or streamable HTTP transports (header takes precedence over environment variable - meaning you can set a default org as well).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When an organization ID is provided, the MCP server will set the &lt;code&gt;X-Grafana-Org-Id&lt;/code&gt; header on all requests to Grafana, ensuring that operations are performed within the specified organization context.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example with organization ID:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        "GRAFANA_ORG_ID": "2"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;You have several options to install &lt;code&gt;mcp-grafana&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Docker image&lt;/strong&gt;: Use the pre-built Docker image from Docker Hub.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: The Docker image's entrypoint is configured to run the MCP server in SSE mode by default, but most users will want to use STDIO mode for direct integration with AI assistants like Claude Desktop:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt;&lt;strong&gt;STDIO Mode&lt;/strong&gt;: For stdio mode you must explicitly override the default with &lt;code&gt;-t stdio&lt;/code&gt; and include the &lt;code&gt;-i&lt;/code&gt; flag to keep stdin open:&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
# For local Grafana:
docker run --rm -i -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t stdio
# For Grafana Cloud:
docker run --rm -i -e GRAFANA_URL=https://myinstance.grafana.net -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t stdio
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ol start="2"&gt; 
     &lt;li&gt;&lt;strong&gt;SSE Mode&lt;/strong&gt;: In this mode, the server runs as an HTTP server that clients connect to. You must expose port 8000 using the &lt;code&gt;-p&lt;/code&gt; flag:&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana
&lt;/code&gt;&lt;/pre&gt; 
    &lt;ol start="3"&gt; 
     &lt;li&gt;&lt;strong&gt;Streamable HTTP Mode&lt;/strong&gt;: In this mode, the server operates as an independent process that can handle multiple client connections. You must expose port 8000 using the &lt;code&gt;-p&lt;/code&gt; flag: For this mode you must explicitly override the default with &lt;code&gt;-t streamable-http&lt;/code&gt;&lt;/li&gt; 
    &lt;/ol&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8000:8000 -e GRAFANA_URL=http://localhost:3000 -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; mcp/grafana -t streamable-http
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For HTTPS streamable HTTP mode with server TLS certificates:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker pull mcp/grafana
docker run --rm -p 8443:8443 \
  -v /path/to/certs:/certs:ro \
  -e GRAFANA_URL=http://localhost:3000 \
  -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; \
  mcp/grafana \
  -t streamable-http \
  -addr :8443 \
  --server.tls-cert-file /certs/server.crt \
  --server.tls-key-file /certs/server.key
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download binary&lt;/strong&gt;: Download the latest release of &lt;code&gt;mcp-grafana&lt;/code&gt; from the &lt;a href="https://github.com/grafana/mcp-grafana/releases"&gt;releases page&lt;/a&gt; and place it in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build from source&lt;/strong&gt;: If you have a Go toolchain installed you can also build and install it from source, using the &lt;code&gt;GOBIN&lt;/code&gt; environment variable to specify the directory where the binary should be installed. This should also be in your &lt;code&gt;PATH&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;GOBIN="$HOME/go/bin" go install github.com/grafana/mcp-grafana/cmd/mcp-grafana@latest
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deploy to Kubernetes using Helm&lt;/strong&gt;: use the &lt;a href="https://github.com/grafana/helm-charts/tree/main/charts/grafana-mcp"&gt;Helm chart from the Grafana helm-charts repository&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;helm repo add grafana https://grafana.github.io/helm-charts
helm install --set grafana.apiKey=&amp;lt;Grafana_ApiKey&amp;gt; --set grafana.url=&amp;lt;GrafanaUrl&amp;gt; my-release grafana/grafana-mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add the server configuration to your client configuration file. For example, for Claude Desktop:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;If using the binary:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;",
        // If using username/password authentication
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        // Optional: specify organization ID for multi-org support
        "GRAFANA_ORG_ID": "1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: if you see &lt;code&gt;Error: spawn mcp-grafana ENOENT&lt;/code&gt; in Claude Desktop, you need to specify the full path to &lt;code&gt;mcp-grafana&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;If using Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio"
      ],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;",
        // If using username/password authentication
        "GRAFANA_USERNAME": "&amp;lt;your username&amp;gt;",
        "GRAFANA_PASSWORD": "&amp;lt;your password&amp;gt;",
        // Optional: specify organization ID for multi-org support
        "GRAFANA_ORG_ID": "1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: The &lt;code&gt;-t stdio&lt;/code&gt; argument is essential here because it overrides the default SSE mode in the Docker image.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Using VSCode with remote MCP server&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're using VSCode and running the MCP server in SSE mode (which is the default when using the Docker image without overriding the transport), make sure your &lt;code&gt;.vscode/settings.json&lt;/code&gt; includes the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"mcp": {
  "servers": {
    "grafana": {
      "type": "sse",
      "url": "http://localhost:8000/sse"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For HTTPS streamable HTTP mode with server TLS certificates:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"mcp": {
  "servers": {
    "grafana": {
      "type": "sse",
      "url": "https://localhost:8443/sse"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debug Mode&lt;/h3&gt; 
&lt;p&gt;You can enable debug mode for the Grafana transport by adding the &lt;code&gt;-debug&lt;/code&gt; flag to the command. This will provide detailed logging of HTTP requests and responses between the MCP server and the Grafana API, which can be helpful for troubleshooting.&lt;/p&gt; 
&lt;p&gt;To use debug mode with the Claude Desktop configuration, update your config as follows:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If using the binary:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": ["-debug"],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;If using Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio",
        "-debug"
      ],
      "env": {
        "GRAFANA_URL": "http://localhost:3000",  // Or "https://myinstance.grafana.net" for Grafana Cloud
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: As with the standard configuration, the &lt;code&gt;-t stdio&lt;/code&gt; argument is required to override the default SSE mode in the Docker image.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;TLS Configuration&lt;/h3&gt; 
&lt;p&gt;If your Grafana instance is behind mTLS or requires custom TLS certificates, you can configure the MCP server to use custom certificates. The server supports the following TLS configuration options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--tls-cert-file&lt;/code&gt;: Path to TLS certificate file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-key-file&lt;/code&gt;: Path to TLS private key file for client authentication&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-ca-file&lt;/code&gt;: Path to TLS CA certificate file for server verification&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--tls-skip-verify&lt;/code&gt;: Skip TLS certificate verification (insecure, use only for testing)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Example with client certificate authentication:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "mcp-grafana",
      "args": [
        "--tls-cert-file",
        "/path/to/client.crt",
        "--tls-key-file",
        "/path/to/client.key",
        "--tls-ca-file",
        "/path/to/ca.crt"
      ],
      "env": {
        "GRAFANA_URL": "https://secure-grafana.example.com",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example with Docker:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "grafana": {
      "command": "docker",
      "args": [
        "run",
        "--rm",
        "-i",
        "-v",
        "/path/to/certs:/certs:ro",
        "-e",
        "GRAFANA_URL",
        "-e",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN",
        "mcp/grafana",
        "-t",
        "stdio",
        "--tls-cert-file",
        "/certs/client.crt",
        "--tls-key-file",
        "/certs/client.key",
        "--tls-ca-file",
        "/certs/ca.crt"
      ],
      "env": {
        "GRAFANA_URL": "https://secure-grafana.example.com",
        "GRAFANA_SERVICE_ACCOUNT_TOKEN": "&amp;lt;your service account token&amp;gt;"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The TLS configuration is applied to all HTTP clients used by the MCP server, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The main Grafana OpenAPI client&lt;/li&gt; 
 &lt;li&gt;Prometheus datasource clients&lt;/li&gt; 
 &lt;li&gt;Loki datasource clients&lt;/li&gt; 
 &lt;li&gt;Incident management clients&lt;/li&gt; 
 &lt;li&gt;Sift investigation clients&lt;/li&gt; 
 &lt;li&gt;Alerting clients&lt;/li&gt; 
 &lt;li&gt;Asserts clients&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Direct CLI Usage Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For testing with self-signed certificates:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana --tls-skip-verify -debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With client certificate authentication:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana \
  --tls-cert-file /path/to/client.crt \
  --tls-key-file /path/to/client.key \
  --tls-ca-file /path/to/ca.crt \
  -debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With custom CA certificate only:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana --tls-ca-file /path/to/ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Programmatic Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you're using this library programmatically, you can also create TLS-enabled context functions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Using struct literals
tlsConfig := &amp;amp;mcpgrafana.TLSConfig{
    CertFile: "/path/to/client.crt",
    KeyFile:  "/path/to/client.key",
    CAFile:   "/path/to/ca.crt",
}
grafanaConfig := mcpgrafana.GrafanaConfig{
    Debug:     true,
    TLSConfig: tlsConfig,
}
contextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)

// Or inline
grafanaConfig := mcpgrafana.GrafanaConfig{
    Debug: true,
    TLSConfig: &amp;amp;mcpgrafana.TLSConfig{
        CertFile: "/path/to/client.crt",
        KeyFile:  "/path/to/client.key",
        CAFile:   "/path/to/ca.crt",
    },
}
contextFunc := mcpgrafana.ComposedStdioContextFunc(grafanaConfig)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server TLS Configuration (Streamable HTTP Transport Only)&lt;/h3&gt; 
&lt;p&gt;When using the streamable HTTP transport (&lt;code&gt;-t streamable-http&lt;/code&gt;), you can configure the MCP server to serve HTTPS instead of HTTP. This is useful when you need to secure the connection between your MCP client and the server itself.&lt;/p&gt; 
&lt;p&gt;The server supports the following TLS configuration options for the streamable HTTP transport:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-cert-file&lt;/code&gt;: Path to TLS certificate file for server HTTPS (required for TLS)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--server.tls-key-file&lt;/code&gt;: Path to TLS private key file for server HTTPS (required for TLS)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These flags are completely separate from the client TLS flags documented above. The client TLS flags configure how the MCP server connects to Grafana, while these server TLS flags configure how clients connect to the MCP server when using streamable HTTP transport.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example with HTTPS streamable HTTP server:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./mcp-grafana \
  -t streamable-http \
  --server.tls-cert-file /path/to/server.crt \
  --server.tls-key-file /path/to/server.key \
  -addr :8443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This would start the MCP server on HTTPS port 8443. Clients would then connect to &lt;code&gt;https://localhost:8443/&lt;/code&gt; instead of &lt;code&gt;http://localhost:8000/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker example with server TLS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -p 8443:8443 \
  -v /path/to/certs:/certs:ro \
  -e GRAFANA_URL=http://localhost:3000 \
  -e GRAFANA_SERVICE_ACCOUNT_TOKEN=&amp;lt;your service account token&amp;gt; \
  mcp/grafana \
  -t streamable-http \
  -addr :8443 \
  --server.tls-cert-file /certs/server.crt \
  --server.tls-key-file /certs/server.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Health Check Endpoint&lt;/h3&gt; 
&lt;p&gt;When using the SSE (&lt;code&gt;-t sse&lt;/code&gt;) or streamable HTTP (&lt;code&gt;-t streamable-http&lt;/code&gt;) transports, the MCP server exposes a health check endpoint at &lt;code&gt;/healthz&lt;/code&gt;. This endpoint can be used by load balancers, monitoring systems, or orchestration platforms to verify that the server is running and accepting connections.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Endpoint:&lt;/strong&gt; &lt;code&gt;GET /healthz&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Response:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Status Code: &lt;code&gt;200 OK&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Body: &lt;code&gt;ok&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Example usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For streamable HTTP or SSE transport on default port
curl http://localhost:8000/healthz

# With custom address
curl http://localhost:9090/healthz
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The health check endpoint is only available when using SSE or streamable HTTP transports. It is not available when using the stdio transport (&lt;code&gt;-t stdio&lt;/code&gt;), as stdio does not expose an HTTP server.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Grafana Version Compatibility&lt;/h3&gt; 
&lt;p&gt;If you encounter the following error when using datasource-related tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;get datasource by uid : [GET /datasources/uid/{uid}][400] getDataSourceByUidBadRequest {"message":"id is invalid"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This typically indicates that you are using a Grafana version earlier than 9.0. The &lt;code&gt;/datasources/uid/{uid}&lt;/code&gt; API endpoint was introduced in Grafana 9.0, and datasource operations will fail on earlier versions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Upgrade your Grafana instance to version 9.0 or later to resolve this issue.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please open an issue or submit a pull request if you have any suggestions or improvements.&lt;/p&gt; 
&lt;p&gt;This project is written in Go. Install Go following the instructions for your platform.&lt;/p&gt; 
&lt;p&gt;To run the server locally in STDIO mode (which is the default for local development), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the server locally in SSE mode, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go run ./cmd/mcp-grafana --transport sse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also run the server using the SSE transport inside a custom built Docker image. Just like the published Docker image, this custom image's entrypoint defaults to SSE mode. To build the image, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make build-image
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to run the image in SSE mode (the default), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it --rm -p 8000:8000 mcp-grafana:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need to run it in STDIO mode instead, override the transport setting:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -it --rm mcp-grafana:latest -t stdio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;There are three types of tests available:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Unit Tests (no external dependencies required):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-unit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also run unit tests with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Integration Tests (requires docker containers to be up and running):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-integration
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Cloud Tests (requires cloud Grafana instance and credentials):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-cloud
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Cloud tests are automatically configured in CI. For local development, you'll need to set up your own Grafana Cloud instance and credentials.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More comprehensive integration tests will require a Grafana instance to be running locally on port 3000; you can start one with Docker Compose:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The integration tests can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make test-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're adding more tools, please add integration tests for them. The existing tests should be a good starting point.&lt;/p&gt; 
&lt;h3&gt;Linting&lt;/h3&gt; 
&lt;p&gt;To lint the code, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This includes a custom linter that checks for unescaped commas in &lt;code&gt;jsonschema&lt;/code&gt; struct tags. The commas in &lt;code&gt;description&lt;/code&gt; fields must be escaped with &lt;code&gt;\\,&lt;/code&gt; to prevent silent truncation. You can run just this linter with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint-jsonschema
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/grafana/mcp-grafana/main/internal/linter/jsonschema/README.md"&gt;JSONSchema Linter documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/grafana/mcp-grafana/main/LICENSE"&gt;Apache License, Version 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>traefik/traefik</title>
      <link>https://github.com/traefik/traefik</link>
      <description>&lt;p&gt;The Cloud Native Application Proxy&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/content/assets/img/traefik.logo-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/content/assets/img/traefik.logo.png" /&gt; 
  &lt;img alt="Traefik" title="Traefik" src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik.logo.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://doc.traefik.io/traefik"&gt;&lt;img src="https://img.shields.io/badge/docs-current-brightgreen.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/traefik/traefik"&gt;&lt;img src="https://goreportcard.com/badge/traefik/traefik" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/traefik/traefik/raw/master/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the community support forum at https://community.traefik.io/" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=traefik"&gt;&lt;img src="https://img.shields.io/twitter/follow/traefik.svg?style=social" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Traefik (pronounced &lt;em&gt;traffic&lt;/em&gt;) is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy. Traefik integrates with your existing infrastructure components (&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, &lt;a href="https://docs.docker.com/engine/swarm/"&gt;Swarm mode&lt;/a&gt;, &lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/"&gt;Etcd&lt;/a&gt;, &lt;a href="https://rancher.com"&gt;Rancher v2&lt;/a&gt;, &lt;a href="https://aws.amazon.com/ecs"&gt;Amazon ECS&lt;/a&gt;, ...) and configures itself automatically and dynamically. Pointing Traefik at your orchestrator should be the &lt;em&gt;only&lt;/em&gt; configuration step you need.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#features"&gt;Features&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#supported-backends"&gt;Supported backends&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#web-ui"&gt;Web UI&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#documentation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;p&gt;. &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#support"&gt;Support&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#release-cycle"&gt;Release cycle&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#maintainers"&gt;Maintainers&lt;/a&gt;&lt;/strong&gt; . &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/#credits"&gt;Credits&lt;/a&gt;&lt;/strong&gt; .&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;span&gt;⚠&lt;/span&gt; When migrating to a new major version of Traefik, please refer to the &lt;a href="https://doc.traefik.io/traefik/migrate/v2-to-v3/"&gt;migration guide&lt;/a&gt; to ensure a smooth transition and to be aware of any breaking changes.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul). Now you want users to access these microservices, and you need a reverse proxy.&lt;/p&gt; 
&lt;p&gt;Traditional reverse-proxies require that you configure &lt;em&gt;each&lt;/em&gt; route that will connect paths and subdomains to &lt;em&gt;each&lt;/em&gt; microservice. In an environment where you add, remove, kill, upgrade, or scale your services &lt;em&gt;many&lt;/em&gt; times a day, the task of keeping the routes up to date becomes tedious.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This is when Traefik can help you!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Traefik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run Traefik and let it do the work for you!&lt;/strong&gt; &lt;em&gt;(But if you'd rather configure some of your routes manually, Traefik supports that too!)&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/traefik-architecture.png" alt="Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Continuously updates its configuration (No restarts!)&lt;/li&gt; 
 &lt;li&gt;Supports multiple load balancing algorithms&lt;/li&gt; 
 &lt;li&gt;Provides HTTPS to your microservices by leveraging &lt;a href="https://letsencrypt.org"&gt;Let's Encrypt&lt;/a&gt; (wildcard certificates support)&lt;/li&gt; 
 &lt;li&gt;Circuit breakers, retry&lt;/li&gt; 
 &lt;li&gt;See the magic through its clean web UI&lt;/li&gt; 
 &lt;li&gt;WebSocket, HTTP/2, gRPC ready&lt;/li&gt; 
 &lt;li&gt;Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB 2.X)&lt;/li&gt; 
 &lt;li&gt;Keeps access logs (JSON, CLF)&lt;/li&gt; 
 &lt;li&gt;Fast&lt;/li&gt; 
 &lt;li&gt;Exposes a Rest API&lt;/li&gt; 
 &lt;li&gt;Packaged as a single binary file (made with &lt;span&gt;❤️&lt;/span&gt; with go) and available as an &lt;a href="https://hub.docker.com/r/_/traefik/"&gt;official&lt;/a&gt; docker image&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Backends&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Docker&lt;/a&gt; / &lt;a href="https://doc.traefik.io/traefik/providers/docker/"&gt;Swarm mode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/kubernetes-crd/"&gt;Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/ecs/"&gt;ECS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.traefik.io/traefik/providers/file/"&gt;File&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get your hands on Traefik, you can use the &lt;a href="https://doc.traefik.io/traefik/getting-started/quick-start/"&gt;5-Minute Quickstart&lt;/a&gt; in our documentation (you will need Docker).&lt;/p&gt; 
&lt;h2&gt;Web UI&lt;/h2&gt; 
&lt;p&gt;You can access the simple HTML frontend of Traefik.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/assets/img/webui-dashboard.png" alt="Web UI Providers" /&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;You can find the complete documentation of Traefik v3 at &lt;a href="https://doc.traefik.io/traefik/"&gt;https://doc.traefik.io/traefik/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;To get community support, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;join the Traefik community forum: &lt;a href="https://community.traefik.io/"&gt;&lt;img src="https://img.shields.io/badge/style-register-green.svg?style=social&amp;amp;label=Discourse" alt="Join the chat at https://community.traefik.io/" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need commercial support, please contact &lt;a href="https://traefik.io"&gt;Traefik.io&lt;/a&gt; by mail: &lt;a href="mailto:support@traefik.io"&gt;mailto:support@traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grab the latest binary from the &lt;a href="https://github.com/traefik/traefik/releases"&gt;releases&lt;/a&gt; page and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./traefik --configFile=traefik.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or use the official tiny Docker image and run it with the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/traefik.sample.toml"&gt;sample configuration file&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Or get the sources:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/traefik/traefik
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Introductory Videos&lt;/h2&gt; 
&lt;p&gt;You can find high level and deep dive videos on &lt;a href="https://videos.traefik.io"&gt;videos.traefik.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;We are strongly promoting a philosophy of openness and sharing, and firmly standing against the elitist closed approach. Being part of the core team should be accessible to anyone who is motivated and want to be part of that journey! This &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers-guidelines.md"&gt;document&lt;/a&gt; describes how to be part of the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/docs/content/contributing/maintainers.md"&gt;maintainers' team&lt;/a&gt; as well as various responsibilities and guidelines for Traefik maintainers. You can also find more information on our process to review pull requests and manage issues &lt;a href="https://github.com/traefik/contributors-guide/raw/master/issue_triage.md"&gt;in this document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to contribute to the project, refer to the &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CONTRIBUTING.md"&gt;contributing documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/traefik/traefik/master/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;Release Cycle&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We usually release 3/4 new versions (e.g. 1.1.0, 1.2.0, 1.3.0) per year.&lt;/li&gt; 
 &lt;li&gt;Release Candidates are available before the release (e.g. 1.1.0-rc1, 1.1.0-rc2, 1.1.0-rc3, 1.1.0-rc4, before 1.1.0).&lt;/li&gt; 
 &lt;li&gt;Bug-fixes (e.g. 1.1.1, 1.1.2, 1.2.1, 1.2.3) are released as needed (no additional features are delivered in those versions, bug-fixes only).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each version is supported until the next one is released (e.g. 1.1.x will be supported until 1.2.0 is out).&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://semver.org/"&gt;Semantic Versioning&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Mailing Lists&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;General announcements, new releases: mail at &lt;a href="mailto:news+subscribe@traefik.io"&gt;news+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/news"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Security announcements: mail at &lt;a href="mailto:security+subscribe@traefik.io"&gt;security+subscribe@traefik.io&lt;/a&gt; or on &lt;a href="https://groups.google.com/a/traefik.io/forum/#!forum/security"&gt;the online viewer&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Kudos to &lt;a href="https://www.instagram.com/pierroks/"&gt;Peka&lt;/a&gt; for his awesome work on the gopher's logo!.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik is licensed under the Creative Commons 3.0 Attributions license.&lt;/p&gt; 
&lt;p&gt;The gopher's logo of Traefik was inspired by the gopher stickers made by &lt;a href="https://twitter.com/tenntenn"&gt;Takuya Ueda&lt;/a&gt;. The original Go gopher was designed by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renee French&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>distribution/distribution</title>
      <link>https://github.com/distribution/distribution</link>
      <description>&lt;p&gt;The toolkit to pack, ship, store, and deliver container content&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img style="align: center; padding-left: 10px; padding-right: 10px; padding-bottom: 10px;" width="238px" height="238px" src="https://raw.githubusercontent.com/distribution/distribution/main/distribution-logo.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/distribution/distribution/actions/workflows/build.yml?query=workflow%3Abuild"&gt;&lt;img src="https://github.com/distribution/distribution/workflows/build/badge.svg?branch=main&amp;amp;event=push" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/distribution/distribution"&gt;&lt;img src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache--2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/distribution/distribution"&gt;&lt;img src="https://codecov.io/gh/distribution/distribution/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fdistribution%2Fdistribution.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/distribution/distribution/actions?query=workflow%3Aconformance"&gt;&lt;img src="https://github.com/distribution/distribution/workflows/conformance/badge.svg?sanitize=true" alt="OCI Conformance" /&gt;&lt;/a&gt; &lt;a href="https://securityscorecards.dev/viewer/?uri=github.com/distribution/distribution"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/distribution/distribution/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The toolset to pack, ship, store, and deliver content.&lt;/p&gt; 
&lt;p&gt;This repository's main product is the Open Source Registry implementation for storing and distributing container images and other content using the &lt;a href="https://github.com/opencontainers/distribution-spec"&gt;OCI Distribution Specification&lt;/a&gt;. The goal of this project is to provide a simple, secure, and scalable base for building a large scale registry solution or running a simple private registry. It is a core library for many registry operators including Docker Hub, GitHub Container Registry, GitLab Container Registry and DigitalOcean Container Registry, as well as the CNCF Harbor Project, and VMware Harbor Registry.&lt;/p&gt; 
&lt;p&gt;This repository contains the following components:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;registry&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;An implementation of the &lt;a href="https://github.com/opencontainers/distribution-spec"&gt;OCI Distribution Specification&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;libraries&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;A rich set of libraries for interacting with distribution components. Please see &lt;a href="https://pkg.go.dev/github.com/distribution/distribution"&gt;godoc&lt;/a&gt; for details. &lt;strong&gt;Note&lt;/strong&gt;: The interfaces for these libraries are &lt;strong&gt;unstable&lt;/strong&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;documentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full documentation is available at &lt;a href="https://distribution.github.io/distribution/"&gt;https://distribution.github.io/distribution&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;How does this integrate with Docker, containerd, and other OCI client?&lt;/h3&gt; 
&lt;p&gt;Clients implement against the OCI specification and communicate with the registry using HTTP. This project contains a client implementation which is currently in use by Docker, however, it is deprecated for the &lt;a href="https://github.com/containerd/containerd/tree/master/remotes/docker"&gt;implementation in containerd&lt;/a&gt; and will not support new features.&lt;/p&gt; 
&lt;h3&gt;What are the long term goals of the Distribution project?&lt;/h3&gt; 
&lt;p&gt;The &lt;em&gt;Distribution&lt;/em&gt; project has the further long term goal of providing a secure tool chain for distributing content. The specifications, APIs and tools should be as useful with Docker as they are without.&lt;/p&gt; 
&lt;p&gt;Our goal is to design a professional grade and extensible content distribution system that allow users to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enjoy an efficient, secured and reliable way to store, manage, package and exchange content&lt;/li&gt; 
 &lt;li&gt;Hack/roll their own on top of healthy open-source components&lt;/li&gt; 
 &lt;li&gt;Implement their own home made solution through good specs, and solid extensions mechanism.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for details on how to contribute issues, fixes, and patches to this project. If you are contributing code, see the instructions for &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/BUILDING.md"&gt;building a development environment&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p&gt;For async communication and long running discussions please use issues and pull requests on the github repo. This will be the best place to discuss design and implementation.&lt;/p&gt; 
&lt;p&gt;For sync communication we have a #distribution channel in the &lt;a href="https://slack.cncf.io/"&gt;CNCF Slack&lt;/a&gt; that everyone is welcome to join and chat about development.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;The distribution codebase is released under the &lt;a href="https://raw.githubusercontent.com/distribution/distribution/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;. The README.md file, and files in the "docs" folder are licensed under the Creative Commons Attribution 4.0 International License. You may obtain a copy of the license, titled CC-BY-4.0, at &lt;a href="http://creativecommons.org/licenses/by/4.0/"&gt;http://creativecommons.org/licenses/by/4.0/&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>JanDeDobbeleer/oh-my-posh</title>
      <link>https://github.com/JanDeDobbeleer/oh-my-posh</link>
      <description>&lt;p&gt;The most customisable and low-latency cross platform/shell prompt renderer&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="400" src="https://raw.githubusercontent.com/jandedobbeleer/oh-my-posh/main/website/static/img/logo.png" alt="Oh My Posh logo – Prompt theme engine for any shell" /&gt; &lt;/p&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/license/JanDeDobbeleer/oh-my-posh.svg?sanitize=true" alt="MIT license badge" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/jandedobbeleer/oh-my-posh/release.yml?branch=main" alt="Build Status badge" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/jandedobbeleer/oh-my-posh?label=Release" alt="Release version number badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ohmyposh.dev"&gt;&lt;img src="https://img.shields.io/badge/Docs-ohmyposh.dev-blue" alt="Documentation link badge ohmyposh.dev" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/downloads/jandedobbeleer/oh-my-posh/total?color=pink&amp;amp;label=GitHub%20Downloads" alt="Number of GitHub Downloads badge" /&gt;&lt;/p&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/oh-my-posh"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/c21102f7-bab9-4344-a731-0cf6b341cab2" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/oh-my-posh"&gt;Warp, the intelligent terminal for developers&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/oh-my-posh"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;p&gt;This repo was made with love using GitKraken.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.gitkraken.com/invite/nQmDPR9D"&gt;&lt;img src="https://img.shields.io/badge/GitKraken-Legendary%20Git%20Tools-teal?style=plastic&amp;amp;logo=gitkraken" alt="GitKraken shield" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- markdownlint-disable first-header-h1 --&gt; 
&lt;h2&gt;Join the community&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/mastodon/follow/110275292073181892?domain=https%3A%2F%2Fhachyderm.io&amp;amp;label=Mastodon&amp;amp;style=social" alt="Mastodon badge" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/discord/1023597603331526656" alt="Discord badge" /&gt;&lt;/p&gt; 
&lt;p&gt;What started as the offspring of &lt;a href="https://github.com/JanDeDobbeleer/oh-my-posh2"&gt;oh-my-posh2&lt;/a&gt; for PowerShell resulted in a cross platform, highly customizable and extensible prompt theme engine. After 4 years of working on oh-my-posh, a modern and more efficient tool was needed to suit my personal needs.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;❤️&lt;/span&gt; Support &lt;span&gt;❤️&lt;/span&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://swag.ohmyposh.dev"&gt;&lt;img src="https://img.shields.io/badge/Swag-Get%20some!-blue" alt="Swag" /&gt;&lt;/a&gt; - Show your love with a t-shirt!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/JanDeDobbeleer"&gt;&lt;img src="https://img.shields.io/badge/-Sponsor-fafbfc?logo=GitHub%20Sponsors" alt="GitHub" /&gt;&lt;/a&gt; - One time support, or a recurring donation?&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/jandedobbeleer"&gt;&lt;img src="https://img.shields.io/badge/Ko--fi-Buy%20me%20a%20coffee!-%2346b798.svg?sanitize=true" alt="Ko-Fi" /&gt;&lt;/a&gt; - No coffee, no code.&lt;/p&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;a href="https://polar.sh/oh-my-posh"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://polar.sh/embed/tiers.svg?org=oh-my-posh&amp;amp;darkmode" /&gt; 
  &lt;img alt="Subscription Tiers on Polar" src="https://polar.sh/embed/tiers.svg?org=oh-my-posh" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;!-- markdownlint-enable --&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Shell and platform agnostic&lt;/li&gt; 
 &lt;li&gt;Easily configurable&lt;/li&gt; 
 &lt;li&gt;The &lt;strong&gt;most&lt;/strong&gt; configurable prompt utility&lt;/li&gt; 
 &lt;li&gt;Fast&lt;/li&gt; 
 &lt;li&gt;Secondary prompt&lt;/li&gt; 
 &lt;li&gt;Right prompt&lt;/li&gt; 
 &lt;li&gt;Transient prompt&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ohmyposh.dev"&gt;&lt;img src="https://img.shields.io/badge/Docs-ohmyposh.dev-blue" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Reviews&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://repo-reviews.github.io//reviews/2023-06-21_TameWizard_JanDeDobbeleer_oh-my-posh"&gt;Repo review&lt;/a&gt; by &lt;a href="https://github.com/TameWizard"&gt;TameWizard&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chrisbenti/PS-Config"&gt;Chris Benti&lt;/a&gt; providing the first influence to start oh-my-posh&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dahlbyk/posh-git"&gt;Keith Dahlby&lt;/a&gt; for creating posh-git and making life more enjoyable&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ohmyzsh/ohmyzsh"&gt;Robby Russell&lt;/a&gt; for creating oh-my-zsh, without him this would probably not be here&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/justjanne"&gt;Janne Mareike Koschinski&lt;/a&gt; for providing information on how to get certain information using Go (and the amazing &lt;a href="https://github.com/justjanne/powerline-go"&gt;README&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/starship/starship/raw/master/src/init/mod.rs"&gt;Starship&lt;/a&gt; for doing great things&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>siderolabs/talos</title>
      <link>https://github.com/siderolabs/talos</link>
      <description>&lt;p&gt;Talos Linux is a modern Linux distribution built for Kubernetes.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;Talos Linux&lt;/h1&gt; 
&lt;p align="center"&gt;A modern OS for Kubernetes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/talos-systems/talos/releases/latest"&gt;&lt;img alt="Release" src="https://img.shields.io/github/release/talos-systems/talos.svg?logo=github&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;a href="https://github.com/talos-systems/talos/releases/latest"&gt;&lt;img alt="Pre-release" src="https://img.shields.io/github/release-pre/talos-systems/talos.svg?label=pre-release&amp;amp;logo=GitHub&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/7340"&gt;&lt;img src="https://www.bestpractices.dev/projects/7340/badge" alt="OpenSSF badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Talos&lt;/strong&gt; is a modern OS for running Kubernetes: secure, immutable, and minimal. Talos is fully open source, production-ready, and supported by the people at &lt;a href="https://www.SideroLabs.com/"&gt;Sidero Labs&lt;/a&gt;. All system management is done via an API - there is no shell or interactive console. Benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Talos reduces your attack surface: It's minimal, hardened, and immutable. All API access is secured with mutual TLS (mTLS) authentication.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Predictability&lt;/strong&gt;: Talos eliminates configuration drift, reduces unknown factors by employing immutable infrastructure ideology, and delivers atomic updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evolvability&lt;/strong&gt;: Talos simplifies your architecture, increases your agility, and always delivers current stable Kubernetes and Linux versions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For instructions on deploying and managing Talos, see the &lt;a href="https://docs.siderolabs.com/talos"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support: Questions, bugs, feature requests &lt;a href="https://github.com/siderolabs/talos/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack: Join our &lt;a href="https://slack.dev.talos-systems.io"&gt;slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Forum: &lt;a href="https://groups.google.com/a/SideroLabs.com/forum/#!forum/community"&gt;community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Twitter: &lt;a href="https://twitter.com/SideroLabs"&gt;@SideroLabs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Email: &lt;a href="mailto:info@SideroLabs.com"&gt;info@SideroLabs.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you're interested in this project and would like to help in engineering efforts or have general usage questions, we are happy to have you! We hold a monthly meeting that all audiences are welcome to attend.&lt;/p&gt; 
&lt;p&gt;We would appreciate your feedback so that we can make Talos even better! To do so, you can take our &lt;a href="https://docs.google.com/forms/d/1TUna5YTYGCKot68Y9YN_CLobY6z9JzLVCq1G7DoyNjA/edit"&gt;survey&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Office Hours&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;When: Second Monday of every month at 16:30 UTC.&lt;/li&gt; 
 &lt;li&gt;Where: &lt;a href="https://meet.google.com/ivb-kjfm-jfc"&gt;Google Meet&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can subscribe to this meeting by joining the community forum above.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: You can convert the meeting hours to your &lt;a href="https://everytimezone.com/s/599e61d6"&gt;local time&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcomed and appreciated! See &lt;a href="https://raw.githubusercontent.com/siderolabs/talos/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; for our guidelines.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;a href="https://github.com/siderolabs/talos/raw/master/LICENSE"&gt; &lt;img alt="GitHub" src="https://img.shields.io/github/license/siderolabs/talos" /&gt; &lt;/a&gt; 
&lt;p&gt;Some software we distribute is under the General Public License family of licenses or other licenses that require we provide you with the source code. If you would like a copy of the source code for this software, please contact us via email: info at SideroLabs.com.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>looplj/axonhub</title>
      <link>https://github.com/looplj/axonhub</link>
      <description>&lt;p&gt;AxonHub is a modern AI gateway system that provides a unified OpenAI ( Chat Completion, Responses), Anthropic, Gemini and AI SDK compatible API&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;AxonHub - All-in-one AI Development Platform&lt;/h1&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/looplj/axonhub/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/looplj/axonhub/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/looplj/axonhub/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/looplj/axonhub/actions/workflows/lint.yml/badge.svg?sanitize=true" alt="Lint Status" /&gt;&lt;/a&gt; &lt;a href="https://golang.org/"&gt;&lt;img src="https://img.shields.io/github/go-mod/go-version/looplj/axonhub?logo=go&amp;amp;logoColor=white" alt="Go Version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://docker.com"&gt;&lt;img src="https://img.shields.io/badge/docker-ready-2496ED?logo=docker&amp;amp;logoColor=white" alt="Docker Ready" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/README.zh-CN.md"&gt;中文&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📖 Project Introduction&lt;/h2&gt; 
&lt;h3&gt;All-in-one AI Development Platform&lt;/h3&gt; 
&lt;p&gt;AxonHub is an all-in-one AI development platform that provides unified API gateway, project management, and comprehensive development tools. It offers OpenAI, Anthropic, and AI SDK compatible API layers, transforming requests to various AI providers through a transformer pipeline architecture. The platform features comprehensive tracing capabilities, project-based organization, and integrated playground for rapid prototyping, helping developers and enterprises better manage AI development workflows.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/axonhub-architecture-light.svg?sanitize=true" alt="AxonHub Architecture" width="700" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/api-reference/unified-api.md"&gt;&lt;strong&gt;Unified API&lt;/strong&gt;&lt;/a&gt;: OpenAI- and Anthropic-compatible interface with automatic API translation lets you use one API format to access any supported model provider.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/tracing.md"&gt;&lt;strong&gt;Tracing / Threads&lt;/strong&gt;&lt;/a&gt;: Thread-aware tracing captures full request timelines for deep observability and faster debugging.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/permissions.md"&gt;&lt;strong&gt;Fine-grained Permission&lt;/strong&gt;&lt;/a&gt;: RBAC-based policies help teams govern access, usage, and data segregation precisely.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/load-balance.md"&gt;&lt;strong&gt;Adaptive Load Balancing&lt;/strong&gt;&lt;/a&gt;: Intelligent multi-strategy load balancing automatically selects optimal AI channels based on health, performance, and session consistency.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📚 Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed technical documentation, API references, architecture design, and more, please visit&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://deepwiki.com/looplj/axonhub"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-looplj%2Faxonhub-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==" alt="DeepWiki" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zread.ai/looplj/axonhub"&gt;&lt;img src="https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&amp;amp;color=00b0aa&amp;amp;labelColor=000000&amp;amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&amp;amp;logoColor=ffffff" alt="zread" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🎯 Demo&lt;/h2&gt; 
&lt;p&gt;Try AxonHub live at our &lt;a href="https://axonhub.onrender.com"&gt;demo instance&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;：The demo instance currently configures Zhipu and OpenRouter free models.&lt;/p&gt; 
&lt;h3&gt;Demo Account&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href="mailto:demo@example.com"&gt;demo@example.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Password&lt;/strong&gt;: 12345678&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⭐ Features&lt;/h2&gt; 
&lt;h3&gt;📸 Screenshots&lt;/h3&gt; 
&lt;p&gt;Here are some screenshots of AxonHub in action:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-dashboard.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-dashboard.png" alt="System Dashboard" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; System Dashboard &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-channels.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-channels.png" alt="Channel Management" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; Channel Management &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-trace.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-trace.png" alt="Trace Viewer" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; Trace Viewer &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-requests.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-requests.png" alt="Request Monitoring" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; Request Monitoring &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-usage-logs.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-usage-logs.png" alt="Usage Logs" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; Usage Logs &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-system.png"&gt; &lt;img src="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/screenshots/axonhub-system.png" alt="System Dashboard" width="250" /&gt; &lt;/a&gt; &lt;br /&gt; System Setting &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🚀 API Types&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API Type&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Document&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Text Generation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Conversational interface&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/api-reference/unified-api.md"&gt;Unified API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Image Generation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;⚠️ Partial&lt;/td&gt; 
   &lt;td&gt;Image generation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/api-reference/image-generation.md"&gt;Image Generation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Rerank&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Results ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/api-reference/unified-api.md#rerank-api"&gt;Unified API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Embedding&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Vector embedding generation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/api-reference/unified-api.md#embedding-api"&gt;Unified API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Realtime&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;📝 Todo&lt;/td&gt; 
   &lt;td&gt;Live conversation capabilities&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🌐 Multi-Provider AI Gateway&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Technical Implementation&lt;/th&gt; 
   &lt;th&gt;Business Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Unified API Interface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI compatible standard, zero learning curve&lt;/td&gt; 
   &lt;td&gt;Avoid vendor lock-in, reduce migration risk&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Automatic Failover&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-channel retry + load balancing&lt;/td&gt; 
   &lt;td&gt;Service interruption time &amp;lt; 100ms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Stream Processing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Native SSE support, real-time response&lt;/td&gt; 
   &lt;td&gt;60% user experience improvement&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🧵 Threads &amp;amp; Tracing&lt;/h3&gt; 
&lt;p&gt;AxonHub records every request as part of a thread-aware trace without requiring you to adopt any vendor-specific SDK. Bring your existing OpenAI-compatible client, and AxonHub will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Require incoming &lt;code&gt;AH-Trace-Id&lt;/code&gt; headers to stitch multiple requests into the same trace. If the header is omitted, AxonHub will still record the request but cannot automatically link it to related activity.&lt;/li&gt; 
 &lt;li&gt;Link traces to threads so you can follow the entire conversation journey end to end&lt;/li&gt; 
 &lt;li&gt;Capture model metadata, prompt / response spans, and timing information for fast root-cause analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about how tracing works and how to integrate it in the &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/tracing.md"&gt;Tracing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;🔧 API Format Support&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Format&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Compatibility&lt;/th&gt; 
   &lt;th&gt;Modalities&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenAI Chat Completions&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Fully compatible&lt;/td&gt; 
   &lt;td&gt;Text, Image&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenAI Responses&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;⚠️ Partial&lt;/td&gt; 
   &lt;td&gt;No &lt;code&gt;previous_response_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Text&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Anthropic Messages&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Fully supported&lt;/td&gt; 
   &lt;td&gt;Text&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemini&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Done&lt;/td&gt; 
   &lt;td&gt;Fully supported&lt;/td&gt; 
   &lt;td&gt;Text, Image&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI SDK&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;⚠️ Partial&lt;/td&gt; 
   &lt;td&gt;Partially supported&lt;/td&gt; 
   &lt;td&gt;Text&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Feature&lt;/strong&gt;: Use OpenAI API to call Anthropic models, or Anthropic API to call OpenAI models - AxonHub handles automatic API translation!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🏢 Permission Control&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Security Feature&lt;/th&gt; 
   &lt;th&gt;Implementation&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Fine-grained Permission Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Role-based access control (RBAC)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Localization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configurable data storage policies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Key Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;JWT + scope control&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;h3&gt;1-click Deploy to Render&lt;/h3&gt; 
&lt;p&gt;Deploy AxonHub with 1-click on &lt;a href="https://render.com"&gt;Render&lt;/a&gt; for free.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://render.com/deploy?repo=https://github.com/looplj/axonhub"&gt; &lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Render" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Deployment Guide&lt;/h2&gt; 
&lt;h3&gt;💻 Personal Computer Deployment&lt;/h3&gt; 
&lt;p&gt;Perfect for individual developers and small teams. No complex configuration required.&lt;/p&gt; 
&lt;h4&gt;Quick Download &amp;amp; Run&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download the latest release&lt;/strong&gt; from &lt;a href="https://github.com/looplj/axonhub/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Choose the appropriate version for your operating system:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Extract and run&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Extract the downloaded file
unzip axonhub_*.zip
cd axonhub_*

# Add execution permissions (only for Linux/macOS)
chmod +x axonhub

# Run directly - default SQLite database

# Install AxonHub to system
sudo ./install.sh

# Start AxonHub service
./start.sh

# Stop AxonHub service
./stop.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the application&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;http://localhost:8090
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h3&gt;🖥️ Server Deployment&lt;/h3&gt; 
&lt;p&gt;For production environments, high availability, and enterprise deployments.&lt;/p&gt; 
&lt;h4&gt;Database Support&lt;/h4&gt; 
&lt;p&gt;AxonHub supports multiple databases to meet different scale deployment needs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Database&lt;/th&gt; 
   &lt;th&gt;Supported Versions&lt;/th&gt; 
   &lt;th&gt;Recommended Scenario&lt;/th&gt; 
   &lt;th&gt;Auto Migration&lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TiDB Cloud&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Starter&lt;/td&gt; 
   &lt;td&gt;Serverless, Free tier, Auto Scale&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.pingcap.com/tidb-cloud-starter/"&gt;TiDB Cloud&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TiDB Cloud&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dedicated&lt;/td&gt; 
   &lt;td&gt;Distributed deployment, large scale&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.pingcap.com/tidb-cloud-dedicated/"&gt;TiDB Cloud&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TiDB&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;V8.0+&lt;/td&gt; 
   &lt;td&gt;Distributed deployment, large scale&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tidb.io/"&gt;TiDB&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Neon DB&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Serverless, Free tier, Auto Scale&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://neon.com/"&gt;Neon DB&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;15+&lt;/td&gt; 
   &lt;td&gt;Production environment, medium-large deployments&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MySQL&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;8.0+&lt;/td&gt; 
   &lt;td&gt;Production environment, medium-large deployments&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.mysql.com/"&gt;MySQL&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;SQLite&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3.0+&lt;/td&gt; 
   &lt;td&gt;Development environment, small deployments&lt;/td&gt; 
   &lt;td&gt;✅ Supported&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.sqlite.org/index.html"&gt;SQLite&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Configuration&lt;/h4&gt; 
&lt;p&gt;AxonHub uses YAML configuration files with environment variable override support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# config.yml
server:
  port: 8090
  name: "AxonHub"
  debug: false

db:
  dialect: "tidb"
  dsn: "&amp;lt;USER&amp;gt;.root:&amp;lt;PASSWORD&amp;gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true"

log:
  level: "info"
  encoding: "json"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AXONHUB_SERVER_PORT=8090
AXONHUB_DB_DIALECT="tidb"
AXONHUB_DB_DSN="&amp;lt;USER&amp;gt;.root:&amp;lt;PASSWORD&amp;gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true"
AXONHUB_LOG_LEVEL=info
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed configuration instructions, please refer to &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/deployment/configuration.md"&gt;configuration documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Docker Compose Deployment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone project
git clone https://github.com/looplj/axonhub.git
cd axonhub

# Set environment variables
export AXONHUB_DB_DIALECT="tidb"
export AXONHUB_DB_DSN="&amp;lt;USER&amp;gt;.root:&amp;lt;PASSWORD&amp;gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true"

# Start services
docker-compose up -d

# Check status
docker-compose ps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Virtual Machine Deployment&lt;/h4&gt; 
&lt;p&gt;Download the latest release from &lt;a href="https://github.com/looplj/axonhub/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Extract and run
unzip axonhub_*.zip
cd axonhub_*

# Set environment variables
export AXONHUB_DB_DIALECT="tidb"
export AXONHUB_DB_DSN="&amp;lt;USER&amp;gt;.root:&amp;lt;PASSWORD&amp;gt;@tcp(gateway01.us-west-2.prod.aws.tidbcloud.com:4000)/axonhub?tls=true"

sudo ./install.sh

# Configuration file check
axonhub config check

# Start service
#  For simplicity, we recommend managing AxonHub with the helper scripts:

# Start
./start.sh

# Stop
./stop.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📖 Usage Guide&lt;/h2&gt; 
&lt;h3&gt;Unified API Overview&lt;/h3&gt; 
&lt;p&gt;AxonHub provides a unified API gateway that supports both OpenAI Chat Completions and Anthropic Messages APIs. This means you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use OpenAI API to call Anthropic models&lt;/strong&gt; - Keep using your OpenAI SDK while accessing Claude models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Anthropic API to call OpenAI models&lt;/strong&gt; - Use Anthropic's native API format with GPT models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use Gemini API to call OpenAI models&lt;/strong&gt; - Use Gemini's native API format with GPT models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic API translation&lt;/strong&gt; - AxonHub handles format conversion automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero code changes&lt;/strong&gt; - Your existing OpenAI or Anthropic client code continues to work&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Initial Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access Management Interface&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;http://localhost:8090
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure AI Providers&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Add API keys in the management interface&lt;/li&gt; 
   &lt;li&gt;Test connections to ensure correct configuration&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create Users and Roles&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Set up permission management&lt;/li&gt; 
   &lt;li&gt;Assign appropriate access permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. Channel Configuration&lt;/h3&gt; 
&lt;p&gt;Configure AI provider channels in the management interface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# OpenAI channel example
name: "openai"
type: "openai"
base_url: "https://api.openai.com/v1"
credentials:
  api_key: "your-openai-key"
supported_models: ["gpt-5", "gpt-4o"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2.1 Test Connection&lt;/h4&gt; 
&lt;p&gt;Click the test button. If the test is successful, the configuration is correct.&lt;/p&gt; 
&lt;h4&gt;2.2 Enable Channel&lt;/h4&gt; 
&lt;p&gt;After successful testing, click the enable button to activate the channel.&lt;/p&gt; 
&lt;h4&gt;2.3 Model Mappings&lt;/h4&gt; 
&lt;p&gt;Use model mappings when the requested model name differs from the upstream provider's supported names. AxonHub transparently rewrites the request model before it leaves the gateway.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Map unsupported or legacy model IDs to the closest available alternative&lt;/li&gt; 
 &lt;li&gt;Implement failover by configuring multiple channels with different providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Example: map product-specific aliases to upstream models
settings:
  modelMappings:
    - from: "gpt-4o-mini"
      to: "gpt-4o"
    - from: "claude-3-sonnet"
      to: "claude-3.5-sonnet"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AxonHub only accepts mappings where the &lt;code&gt;to&lt;/code&gt; model is already declared in &lt;code&gt;supported_models&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;2.4 Override Parameters&lt;/h4&gt; 
&lt;p&gt;Override parameters let you enforce channel-specific defaults regardless of incoming request payloads. Provide a JSON object that will be merged into every outbound request.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports top-level settings (for example &lt;code&gt;temperature&lt;/code&gt;, &lt;code&gt;max_tokens&lt;/code&gt;, &lt;code&gt;top_p&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Supports dot-notation keys for nested fields such as &lt;code&gt;response_format.type&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Invalid JSON logs a warning and falls back to the original payload&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Example: enforce deterministic JSON responses
settings:
  overrideParameters: |
    {
      "temperature": 0.3,
      "max_tokens": 1024,
      "response_format.type": "json_object"
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Add Users&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create user accounts&lt;/li&gt; 
 &lt;li&gt;Assign roles and permissions&lt;/li&gt; 
 &lt;li&gt;Create API keys&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;4. Claude Code/Codex Integration&lt;/h3&gt; 
&lt;p&gt;See the dedicated &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/claude-code-integration.md"&gt;Claude Code &amp;amp; Codex Integration Guide&lt;/a&gt; for detailed setup steps, troubleshooting, and tips on combining these tools with AxonHub model profiles.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;5. SDK Usage&lt;/h3&gt; 
&lt;h4&gt;Python SDK - OpenAI API Format&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(
    api_key="your-axonhub-api-key",
    base_url="http://localhost:8090/v1"
)

# Call OpenAI model
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Hello!"}]
)
print(response.choices[0].message.content)

# Call Anthropic model using OpenAI API
response = client.chat.completions.create(
    model="claude-3-5-sonnet",
    messages=[{"role": "user", "content": "Hello, Claude!"}]
)
print(response.choices[0].message.content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python SDK - Anthropic API Format&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import requests

# Call Anthropic model
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-axonhub-api-key"
    },
    json={
        "model": "claude-3-5-sonnet",
        "max_tokens": 512,
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Hello, Claude!"}]
            }
        ]
    }
)
print(response.json()["content"][0]["text"])

# Call OpenAI model using Anthropic API
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-axonhub-api-key"
    },
    json={
        "model": "gpt-4o",
        "max_tokens": 512,
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Hello, GPT!"}]
            }
        ]
    }
)
print(response.json()["content"][0]["text"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Node.js SDK&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: "your-axonhub-api-key",
  baseURL: "http://localhost:8090/v1",
});

const completion = await openai.chat.completions.create({
  messages: [{ role: "user", content: "Hello!" }],
  model: "gpt-4o",
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🛠️ Development Guide&lt;/h2&gt; 
&lt;p&gt;For detailed development instructions, architecture design, and contribution guidelines, please see &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/docs/en/guides/development.md"&gt;docs/en/guides/development.md&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🙏 &lt;a href="https://github.com/musistudio/llms"&gt;musistudio/llms&lt;/a&gt; - LLM transformation framework, source of inspiration&lt;/li&gt; 
 &lt;li&gt;🎨 &lt;a href="https://github.com/satnaing/shadcn-admin"&gt;satnaing/shadcn-admin&lt;/a&gt; - Admin interface template&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;a href="https://github.com/99designs/gqlgen"&gt;99designs/gqlgen&lt;/a&gt; - GraphQL code generation&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;a href="https://github.com/gin-gonic/gin"&gt;gin-gonic/gin&lt;/a&gt; - HTTP framework&lt;/li&gt; 
 &lt;li&gt;🗄️ &lt;a href="https://github.com/ent/ent"&gt;ent/ent&lt;/a&gt; - ORM framework&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;a href="https://github.com/air-verse/air"&gt;air-verse/air&lt;/a&gt; - Auto reload Go service&lt;/li&gt; 
 &lt;li&gt;☁️ &lt;a href="https://render.com"&gt;Render&lt;/a&gt; - Free cloud deployment platform for hosting our demo&lt;/li&gt; 
 &lt;li&gt;🗃️ &lt;a href="https://www.pingcap.com/tidb-cloud/"&gt;TiDB Cloud&lt;/a&gt; - Serverless database platform for demo deployment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is open source under the MIT License. See &lt;a href="https://raw.githubusercontent.com/looplj/axonhub/unstable/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;AxonHub&lt;/strong&gt; - All-in-one AI Development Platform, making AI development simpler&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/looplj/axonhub"&gt;🏠 Homepage&lt;/a&gt; • &lt;a href="https://deepwiki.com/looplj/axonhub"&gt;📚 Documentation&lt;/a&gt; • &lt;a href="https://github.com/looplj/axonhub/issues"&gt;🐛 Issue Feedback&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Built with ❤️ by the AxonHub team&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>